{
  "title": "Long time behavior of semi-Markov modulated perpetuity and some related\n  processes",
  "sections": [
    {
      "section_id": 0,
      "text": "#### Abstract\n\nExamples of stochastic processes whose state space representations involve functions of an integral type structure\n\n$$\nI_{t}^{(a, b)}:=\\int_{0}^{t} b\\left(Y_{s}\\right) e^{-\\int_{s}^{t} a\\left(Y_{s}\\right) d r} d s, \\quad t \\geq 0\n$$\n\nare studied under an ergodic semi-Markovian environment described by an $S$ valued jump type process $Y:=\\left(Y_{s}: s \\in \\mathbb{R}^{+}\\right)$that is ergodic with a limiting distribution $\\pi \\in \\mathcal{P}(S)$. Under different assumptions on signs of $E_{\\pi} a(\\cdot):=\\sum_{j \\in S} \\pi_{j} a(j)$ and tail properties of the sojourn times of $Y$ we obtain different long time limit results for $I^{(a, b)}:=\\left(I_{t}^{(a, b)}: t \\geq 0\\right)$. In all cases mixture type of laws emerge which are naturally represented through an affine stochastic recurrence equation (SRE) $X \\stackrel{d}{=} A X+B$, $X \\nmid(A, B)$. Examples include explicit long-time representations of pitchfork bifurcation, and regimeswitching diffusions under semi-Markov modulated environments, etc.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 1,
      "text": "## 1 Introduction and the integral process\n\nWe study some dynamical systems (both stochastic and deterministic) whose parameters characterizing their overall stability, are not fixed constants, instead, they switch their values driven by some hidden jump-type process mechanisms. These models are abundantly seen in directions of econometrics, finance, biological systems, statistical physics etc. We focus on regime-switching diffusion processes, pitchfork bifurcation examples where the key parameter is stochastically varying through different regimes. Common theme of all these processes is that they have an explicit state-space representation in terms of a following integral type of bivariate process $\\left(\\Phi^{(a)}, I^{(a, b)}\\right):=\\left(\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}\\right): t \\geq 0\\right)$ where\n\n$$\n\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}\\right):=\\left(e^{-\\int_{0}^{t} a\\left(Y_{s}\\right) d r}, \\int_{0}^{t} b\\left(Y_{s}\\right) e^{-\\int_{s}^{t} a\\left(Y_{s}\\right) d r} d s\\right) \\quad \\forall t>0\n$$\n\nfor some given functions $a, b: S \\rightarrow \\mathbb{R}$ and some $S$-valued process $Y:=\\left(Y_{t}: t \\geq 0\\right)$ where $S$ is a countable set. Let the common filtration of the regime-switching dynamics be defined by $\\mathcal{F}_{t}^{Y}:=\\sigma\\left\\{Y_{s}: s \\leq t\\right\\}$. Main content of this article is to understand how various parametrizations of the dynamics $Y$ influence the time-asymptotic behaviors of $\\left(\\Phi^{(a)}, I^{(a, b)}\\right)$ and their applications in different examples.\nThe integral process $I^{(a, b)}$ is known as perpetuity in the actuarial science. Several previous works, e.g. Gjessing and Paulsen [32], Bertoin and Yor [13], Maulik and Zwart [48], Behme and Lindner [8], Chapter 2 of Iksanov [40], Zhang et al. [64] and Feng et al. [28] studied this perpetuity in line with exponential functionals of L\u00e9vy processes defined by $J_{t}:=\\int_{0}^{t} e^{-P_{s}} d Q_{s}$, where $\\left(P_{t}, Q_{t}: t \\geq 0\\right)$ jointly constitutes a L\u00e9vy process in an appropriate state space. These works addressed distributional properties, including moments and asymptotic behaviors of tail events, etc. In our context, this implies if we let $\\int_{0}^{t} a\\left(Y_{s}\\right) d s$\n\n[^0]\n[^0]:    *University of Reading\n\nbe a Levy process instead of an integral of a semi-Markov process, subsequent analysis gets relatively simpler due to the stationary, independent increment properties. In a recent work (Behme \\& Sideris [7]), authors considered $\\left(P_{t}, Q_{t}\\right)$ as a Markov additive process and give sharp existence uniqueness conditions motivated by Alsmeyer [2], that entails the foundation of stability for affine stochastic recurrence equation in a Markovian environment. Contrary to Markov-switching, semi-Markovian switching framework driven by $Y$ will exhibit a natural auto-regulatory control on the law of sojourn time that depends on the future regime state as well as the current one, which is extremely useful for implementing control-related formulations into the latent state dynamics. The theoretical foundation of the Semi-Markov process and its time asymptotic behaviors were explored long back in Cinlar [20] along with Cinlar [21],[22] etc. [42] reviewed subsequent developments along with other references therein. Still, for \"perpetuity\" type of path-based functionals $I^{(a, b)}$, there were no exact long-term results available in the literature for a semi-Markovian $Y$, to the best of our knowledge.\n\nRegime-switching processes have a rich history of applications in econometrics, actuarial mathematics, mathematical biology, and quantitative finance. Examples of such uses include Ang and Timmermann [3], BenSaida [10], Fink et al. [29], and Genon-Catalot et al. [31], who have used it in the context of stochastic volatility modeling in financial markets. Additionally, Zhang et al. [64] have considered stochastic interest rate models with Markov switching, while Hardy [36], Lin et al. [45], and Shen and Kuen Siu [57] have studied the long-term behavior of stock returns and bond pricing. Similar to quantitative finance, such processes are commonly used in actuarial science for solvency investigations (e.g., Abourashchi et al. [1]), mortality modeling (e.g., Gao et al. [30]), and in the context of disability insurance (e.g., Djehiche and L\u00f6fdahl [24]). In all of the above references, the sojourn times for the regime-switching process have been considered to be Exponential (to make $Y$ Markovian), although it may not be ideal.\n![img-0.jpeg](img-0.jpeg)\n\nFigure 1: BNP Paribas stock price daily returns and Markov-switching environments predicted in [53] assuming $|S|=2$.\n\nFor example, in Salhi et al. [53], assuming that there is a Markovian regime-switching with only two latent states, the underlying environments were predicted in the time evolution of BNP stock returns (as shown in the Figure 1). It is observed that the sojourn time of the \"steady\" period from 2003 Q1 to 2007 Q2 is more than four years, which is around seven times higher than the average length of other \"steady\" state sojourn times. This event is highly unlikely when the underlying regime switching dynamics is Markovian, as the sojourn times of a particular state are iid exponentials (hence has an exponentially decaying tail making that event significantly rare). However, the aforementioned event may not be rare if the distribution of sojourn times is modeled as Pareto or any other heavy-tailed distributions, as it fits the notion of having a few large jumps in a handful sample size. This motivates the use of a general semi-Markovian regime-switching process, as the sojourn time distributions can be flexible with any laws. Several recent works such as Apergis et al. [4], Qin et al. [51], Wang et al. [61] have demonstrated the superior performance of semi-Markovian regime-switching models compared to their Markov-switching counterparts in various applications including energy consumption forecasting, stock price modeling, and historical S\\&P 500 analysis. Availability of computational tools, such as the R packages hsmm [15] and mhsmm [50], has facilitated the practical implementation of semi-Markov switching models. Despite empirical success, a rigorous theoretical understanding of the long-term behavior of semi-Markov modulated processes remains\n\nan open problem. While foundational properties, such as existence \\& uniqueness, recurrence \\& transience, ergodicity are well-established in the works of Yin \\& Zhu [63], Mao [47], Shao [56], and Zhang [64] in contexts of general hybrid regime switching models including long-term asymptotics of switching diffusions, jump processes etc., explicit asymptotic characterizations are lacking, making it difficult to assess the sensitivity of limiting distributions to latent switching dynamics $Y$. Beyond finance, semi-Markovian models have been applied in disability insurance [58] to relax Markovian assumptions and in interest rate modeling [25] to allow sojourn times to depend on both current and future states. These applications highlight the growing importance of processes with semi-Markovian latent structures, and a need for a deeper theoretical exploration of their time-asymptotic properties.\n\nBeyond providing long-term characterizations of $\\left(\\Phi^{(a)}, I^{(a, b)}\\right)$, we consider two examples where the processes of interest after some transformations, admit an exact state-space representation either in terms of a linear combination of $\\left\\{\\Phi_{t}^{(a)}, I_{t}^{(a, b)}\\right\\}$ or $\\left\\{\\Phi_{t}^{(a)},\\left|I_{t}^{(m a, b)}\\right|^{1 / m}\\right\\}$. Corollary 4.5 aids in establishing the limit results of such functionals, within the divergent framework. First application where we use the long-term behavior of $(\\Phi, I)$, is the deterministic pitchfork bifurcation model in polar coordinates $(\\rho, \\phi):=\\left(\\left(\\rho_{t}, \\phi_{t}\\right): t \\geq 0\\right)$ satisfying\n\n$$\n\\frac{d \\rho_{t}}{d t}=\\rho_{t}\\left(a\\left(Y_{t}\\right)-b\\left(Y_{t}\\right) \\rho_{t}^{2}\\right), \\quad \\frac{d \\phi_{t}}{d t}=1\n$$\n\nwhere $a(\\cdot)$ and $b(\\cdot)$ are functions of the underlying semi-Markov process $Y$, rather than fixed parameters. Note that if $a$ and $b$ are constants with $b>0$, then for $a \\leq 0$, the state 0 would be a stable steady state, while for $a>0$, it becomes an unstable one. If $a(\\cdot)$ switches its values changing its signs over time, it is interesting to see under varying stochastic environment $Y$, how the limiting measure of $\\rho$ behaves around 0 , if that exists. For $|S|>2$ and semi-Markovian $Y$, the long-term behavior of $\\rho$ is also not known in the literature, which we will address explicitly in Theorem 5, in different cases.\n\nAnother major application, discussed in the Section 5, involves the long-term behavior of an $\\mathbb{R}$-valued regime-switching Ornstein-Uhlenbeck process, denoted by $X=\\left(X_{t}\\right)_{t \\geq 0}$, under a semi-Markovian $Y$. It is defined as the weak solution to the SDE\n\n$$\nd X_{t}=\\left(c\\left(Y_{t}\\right)-a\\left(Y_{t}\\right) X_{t}\\right) d t+b\\left(Y_{t}\\right) d L_{t}, \\quad Y_{0}=y_{0} \\in \\mathbb{R}\n$$\n\nwhere $a(\\cdot), b(\\cdot), c(\\cdot): S \\rightarrow \\mathbb{R}$ are arbitrary functions, and $\\left(L_{t}\\right)_{t \\geq 0}$ is either a standard stable- $\\alpha$ L\u00e9vy process or a Brownian motion, independent of the background $S$-valued process $Y$.\n\nIn context of Markov modulated Ornstein-Uhlenbeck process, Zhang \\& Wang [65] studies for two-states (i.e when $|S|=2$ ) regime process. It is possible to compute the stationary distribution under the stable regime since the possible transitions are only of $1 \\rightarrow 2$ and $2 \\rightarrow 1$ type which makes studying $(\\Phi, I)$ tractable. However if $|S|>2$, there will be many different transitions between other states, and generalizing that approach becomes infeasible. The regime-switching process is also deeply connected with Piecewise Deterministic Markov processes (PDMP) and related applications. In similar contexts, Cloez and Hairer [35] studied a class of general regime switching Markov processes where sufficient conditions ensure exponential ergodicity of the observed process under Wasserstein distance. Benaim et al. [9] showed that survival or extinction of competing species in a Lotka-Volterra model is heavily influenced by switching rate parameters using Lyapunov drift type criteria (Section 4 or Theorem 4.1 of [9]). That generalized a set of Lyapunov-type approaches for cases where no explicit temporal representation of the overall process is available. In more recent works, Behme and Sideris [6] characterized the stationarity of a Markov-modulated generalized Ornstein-Uhlenbeck process with applications in Risk theory. However, the results on time-limiting behaviour are not available in explicit form.\n\nIn contrast to all works mentioned above, [46] addressed a similar problem to (1.3) in a diffusion setting with Markov switching, providing several long-time limit results. However, when the sojourn times of $Y$ are non-exponential and depend on the future state (determined by an independent state-determining Markov chain), the analysis for non-Markovian $Y$ becomes more complex. This is because the residual time $\\left(t-\\tau_{g_{l}^{l}}\\right)$ in (9.3) does not factor out as it does in the Markovian case (as noted after display (6.9) in [46]), creating difficulties. To address this, a modification via a limiting argument is required, exploiting the regenerative structure of $Y$, as performed in step 2 of Lemma 6.1. Lemma 6.1 is crucial for our semi-Markovian framework, as it can be used to study time asymptotic behaviors of any functionals of $Y$ satisfying the conditions of $H_{t}$ in (6.1). Lemma 6.1 is then applied to establish all subsequent time\n\nasymptotic results in Theorems 1- 6. Unlike the Markovian switching context [46], long-term limit results here in the divergent cases (i.e, $E_{\\pi} a(\\cdot) \\leq 0$ ) are found to be further subdivided based on whether\n\n$$\n\\sigma_{j}^{2}:=\\operatorname{Var}\\left(\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s\\right)\n$$\n\nis finite, infinite or equal to 0 (where $\\tau_{0}^{j}, \\tau_{1}^{j}$ are time instants of two successive hitting times of $Y$ to state $j$ (validated under Assumption 1)), which is mostly due to the general sojourn time distributions of $Y$. The flexibility in controlling the sojourn time dynamics gives diverse modeling opportunities and will have an additional impact on the scaling limits in all cases, which along with different applications, are the main contributions of this article.\n\nAs semi-Markov modulated processes, all results in these examples are novel, but two surprising takeaways are following:\n(a) In the Pitchfork Bifurcation example (1.2), under stability domain (i.e., when $E_{\\pi} a(\\cdot)>0$ ), the limiting distribution $\\mathcal{L}\\left(\\rho_{\\infty}^{2}\\right)$ is not known for $|S|>2$. Specifically, if $\\inf _{j \\in S} a(j)<0$, how $\\mathcal{L}\\left(\\rho_{\\infty}^{2}\\right)$ behaves under a stable domain and concentrates around 0 has remained an open question. Along with an explicit characterization of $\\mathcal{L}\\left(\\rho_{\\infty}^{2}\\right)$ (see Theorem 5(A)), we found that there exist constants $\\nu^{*}$ and $c>0$, explicitly determined by the dynamics of $Y$, such that the following small-ball asymptotic limit holds:\n\n$$\n\\lim _{\\epsilon \\rightarrow 0^{+}} \\epsilon^{-\\nu^{*}} P\\left[\\rho_{\\infty}^{2}<\\epsilon\\right]=c\n$$\n\n(as shown by setting $x=1 / \\epsilon$ in Remark 5.1) which is quite surprising, as it shows how $P\\left[\\rho_{\\infty}^{2}<\\epsilon\\right]$ scales when $\\epsilon$ is close to 0 . The constant $c$ is related to the Goldie-Kesten constant [16].\n(b) In diffusion example (1.3) (with $c=0$ ), or more generally in (5.9) or in (5.16), we observe that the noise process influences weak limit of the long-term behavior of the original process only in following two cases:\n\n- in the stable case, i.e., when $E_{\\pi} a(\\cdot)>0$, corresponding to Theorem 6 (A), and\n- in a specific divergent case where $\\sigma_{j}^{2}=0, \\forall j \\in S$ (as described in Theorem 6 (D)).\n\nIn other divergent cases (i.e., where $\\sigma_{j}^{2}<\\infty$ or $\\sigma_{j}^{2}=\\infty$ for all $j \\in S$, corresponding to Theorem 6 (B) and (C), respectively), given certain integrability conditions, the weak limits of original process after scaling and transformation are found to be universal and they do not depend on the noise processes (see Remark 5.3), which is quite fascinating. This entails how impactful features of the latent dynamics are, in governing different time-asymptotic behaviours of the overall process $X$.\n\nThis paper is organized as follows. Section 2 sets the structure of the regime process $Y$ along with preliminary assumptions and necessary definitions. In Section 3, exact long-time characterizations for the process $\\left(\\Phi^{(a)}, I^{(a, b)}\\right.$ ), and different generalizations, are presented under assumptions corresponding to the stable regime. Section 4 presents long time results for a scaled version of $\\left(\\Phi^{(a)}, I^{(a, b)}\\right)$ in the divergent and critical regimes i.e, when $E_{\\pi} a(\\cdot) \\leq 0$. Section 5 contains applications of the findings in Sections 3 and 4 to (1.2) \\& (1.3). In Section 6 we present the Lemma 6.1 regarding asymptotic independence of the residual time and a specific functional $\\left(H_{t}: t \\geq 0\\right)$ satisfying (6.1) which is the heart of this work as it is used in proving all the key results. We end the article through Section 7 by giving some conclusions, future directions, and some open questions. The proofs will be found in Section 8 and in the subsequent sections.",
      "tables": {},
      "images": {
        "img-0.jpeg": "data:image/jpeg;base64,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"
      }
    },
    {
      "section_id": 2,
      "text": "# 2 Preliminaries and Assumptions \n\n$Y$ is an $S$-valued, where $S$ is a countable set, jump-type semi-Markov process that will be introduced here along with some underlying structures and relevant assumptions. Consider an $S \\times \\mathbb{R}_{+}$valued timehomogeneous Markov chain $(J, T):=\\left(J_{n}, T_{n}\\right)_{n \\in \\mathbb{N}}$ following the transition kernel\n\n$$\nQ_{i j}(t):=P\\left[J_{n+1}=j, T_{n+1} \\leq t \\mid J_{n}=i, T_{n}=s\\right] \\quad \\forall n \\in \\mathbb{N}, \\quad \\forall s, t \\geq 0\n$$\n\nwith initial distribution $P\\left[J_{0}=i, T_{0}=0\\right]=p_{i} \\forall i \\in S$, with $\\sum_{i \\in S} p_{i}=1$, and further structures of $\\left(Q_{i j}(\\cdot): i, j \\in S\\right)$ are following. As in definition of $Q$ in (2.1) suggests that $Q_{i j}(t)$ does not depend on $T_{n}=s$ in the conditioning part so one can write\n\n$$\nQ_{i j}(t)=P\\left[J_{n+1}=j, T_{n+1} \\leq t \\mid J_{n}=i\\right]\n$$\n\nwithout any problem. Let $\\sum_{i=0}^{n} T_{i}$ be denoted by $S_{n}$ for $n \\in \\mathbb{N}$.\nWe define the the $S$-valued regime switching dynamics $Y:=\\left(Y_{t}: t \\geq 0\\right)$ as\n\n$$\nY_{t}:=J_{N_{t}} \\quad \\text { where } \\quad N_{t}:=\\operatorname{ess} \\sup \\left\\{n: S_{n} \\leq t\\right\\}\n$$\n\nClearly (2.2) suggests that $T_{n}$ denotes the sojourn time of $Y$ at state $J_{n-1}$ for $n \\geq 1$, and $T_{0}:=0$. Let $J:=\\left(J_{n}: n \\in \\mathbb{N}\\right)$ marginally be a discrete-time $S$-valued Markov chain (independent of everything else) with transition kernel $P:=\\left(P_{i j}: i, j \\in S\\right)$ such that\n\n$$\nP_{i j}:=P\\left[J_{n+1}=j \\mid J_{n}=i\\right] \\quad \\text { and } \\quad P_{i i}:=0, \\forall i \\in S\n$$\n\nrepresenting the marginal dynamics of the embedded chain $J$. Note that $Y$ can be seen as the marginal of the Markov renewal process $\\left(S_{n}, J_{n}\\right)$ which is alternatively known as the semi-Markov process in the literature [20] (which is not necessarily Markovian).\n\nLet\n\n$$\n\\mathcal{G}:=\\left\\{F_{i j} \\in \\mathcal{P}\\left(\\mathbb{R}_{+}\\right): i, j \\in S, i \\neq j, \\text { and } P_{i j}>0, F_{i j}(0)=0, F_{i j}(\\infty)=1\\right\\}\n$$\n\nbe the set of probability distributions (having no atoms at 0 ) of sojourn times of $Y$ where particularly $F_{i j}$ denotes the law of the sojourn time of $Y$ at state $i$ when the future state will be $j \\in S$, or more precisely\n\n$$\nF_{i j}(t):=P\\left[T_{n+1} \\leq t \\mid J_{n}=i, J_{n+1}=j\\right]\n$$\n\nClearly with above definitions one can decompose $Q_{i j}(t)$ in following fashion\n\n$$\n\\begin{aligned}\nQ_{i j}(t) & =P\\left[J_{n+1}=j \\mid J_{n}=i\\right] P\\left[T_{n+1} \\leq t \\mid J_{n+1}=j, J_{n}=i\\right] \\\\\n& =P_{i j} F_{i j}(t)\n\\end{aligned}\n$$\n\nGiven the transition kernel $P$, the set $\\mathcal{G}$ and the initial distribution $\\left\\{p_{i}: i \\in S\\right\\}$ the dynamics of $(J, T)$ is completely specified and well defined as well as the process $Y$ defined in (2.2). Observe that semi-Markov process $Y$ exhibits much more dependence structure than continuous time Markov chain which is obtained as a special case $F_{i j}(t):=1-e^{-\\lambda_{i} t}$ for some $\\lambda_{i}>0$ for all $i, j \\in S$. The semi-Markov formulation gives much more flexibilities and control on the sojourn time distributions that may depend on the next state with more general than just Exponential distribution. This opens up a huge number of modelling opportunities for underlying regime switching mechanisms.\n\nThe semi-Markov process $Y$ will be called conservative at state $j \\in S$, if one has\n\n$$\nP\\left[N_{t}<\\infty \\mid Y_{0}=j\\right]=1, \\quad \\forall t \\in[0, \\infty)\n$$\n\nwhich is a regularity condition (Page 150 of [20]) implying that $Y$ is non-explosive or that the number of transitions in a finite time is finite with probability 1 starting from a specific state $j \\in S$.\n\nAssumption 1. Following assumptions are about the dynamics of the process $(J, T)$ :\n(a) The embedded chain $J$ is a time-homogeneous, irreducible, aperiodic, and positive recurrent Markov chain, taking values in $S$ and evolving in discrete time. It is independent of all other variables. The transition matrix $P$ satisfies the properties $P_{i i}=0, P_{i j} \\in[0,1]$, and $\\sum_{j \\in S} P_{i j}=1$ for all $i, j \\in S$. Additionally, the chain admits a unique stationary distribution $\\mu \\in \\mathcal{P}(S)$, which satisfies the measurevalued equation $\\mu=\\mu P$.\n\n(b) The set $\\mathcal{G}$ is defined such that, for all $i, j \\in S$, the distribution functions $F_{i j}$ satisfy $F_{i j}(0)=0$ and contain no atoms in $\\mathbb{R}_{\\geq 0}$. In other words, each $F_{i j}$ is absolutely continuous with respect to the Lebesgue measure on $\\mathbb{R}_{\\geq 0}$. For each pair $i, j \\in S$, define the mean of the random variables distributed according to $F_{i j}(\\cdot)$ as\n\n$$\nm_{i j}:=\\int_{0}^{\\infty}\\left(1-F_{i j}(t)\\right) d t\n$$\n\nWe assume that $\\sup _{i, j \\in S} m_{i j}<\\infty$, ensuring that the expected sojourn times are uniformly bounded.\n(c) The conditional probability\n\n$$\nP\\left[J_{n+1}=j, T_{n+1} \\leq t \\mid J_{n}=i, T_{n}=s\\right]\n$$\n\ndoes not depend on $s$. As a result, $s$ is omitted in the notation for the distribution function $Q_{i j}(t)$ used in the definition (2.1).\n(d) The semi-Markov process $Y$ is conservative for all $j \\in S$, meaning that it does not explode in finite time.\n\nFor any $i, j \\in S$, let $W_{i j}$ be defined as the $F_{i j}$ distributed random variable denoting the sojourn time of $Y$ at state $i$ conditioned on the future state $j$. Then we define the distribution of sojourn time at state $i$ unconditional on the future value as\n\n$$\nP\\left[T_{n+1}<t \\mid J_{n}=i\\right]=\\sum_{j \\in S} P_{i j} F_{i j}(t)=: F_{i}(t)\n$$\n\ndenoted by $F_{i}(\\cdot)$ and denote the corresponding random variable by $W_{i}$. For each $i \\in S$, by $m_{i}$ we denote the mean of $W_{i}$ as\n\n$$\nm_{i}:=E W_{i}=\\int_{0}^{\\infty}\\left(1-F_{i}(t)\\right) d t=\\int_{0}^{\\infty}\\left(1-\\sum_{j \\in S} P_{i j} F_{i j}(t)\\right) d t=\\sum_{j \\in S} P_{i j} m_{i j}\n$$\n\nAssumption 1(a) suggests that for each $j \\in S, \\mu_{j}>0$ and positive recurrence for $J$ implies that there exist hitting times at state $j$ defined as\n\n$$\nN_{0}^{j}:=\\inf \\left\\{n \\geq 0: J_{n}=j\\right\\}, \\quad N_{k}^{j}:=\\inf \\left\\{n>N_{k-1}^{j}: J_{n}=j\\right\\}\n$$\n\nfor $k \\geq 1$. Denote the set $\\left\\{N_{k-1}^{j}, N_{k-1}^{j}+1, \\ldots, N_{k}^{j}-2, N_{k}^{j}-1\\right\\}$ (which is a successive array of integers) by $A_{k}^{j}$ (the $k$-th recursion from state $j$ to itself by the process $J$ ) for each $k \\geq 1$. Positive recurrence of $J$ suggests that $E\\left|A_{k}^{j}\\right|=E\\left[N_{k}^{j}-N_{k-1}^{j}\\right]<\\infty$. By $(i, j)$ we denote a successive transition from state $i$ to $j$ (or $i \\rightarrow j$ ) for the $J$ chain if $P_{i j}>0$. Set of all possible transitions can be described as $\\left\\{(i, j) \\in S \\times S: P_{i j}>0\\right\\}$.\nThe recursion path $A_{k}^{j}$ can be alternatively represented as the set $A_{k}^{j}=\\left\\{j, i_{1}, i_{2}, \\ldots, i_{l_{1}}\\right\\}$ where $l_{1}=$ $\\left[N_{k}^{j}-N_{k-1}^{j}\\right]-1$, representing the sequence of transitions $j \\rightarrow i_{1} \\rightarrow i_{2} \\rightarrow \\ldots \\rightarrow i_{l_{1}} \\rightarrow j$. By $\\widetilde{A}_{k}^{j}$ we denote the set of tuples denoting the successive state transitions of $A_{k}^{j}$ expressed as\n\n$$\n\\widetilde{A}_{k}^{j}=\\left\\{\\left(j, i_{1}\\right),\\left(i_{1}, i_{2}\\right),\\left(i_{2}, i_{3}\\right), \\ldots,\\left(i_{\\left|A_{k}^{j}\\right|-1}, j\\right): i_{l} \\in S, \\& i_{l} \\neq j \\forall l=1, \\ldots,\\left|A_{k}^{j}\\right|-1\\right\\}\n$$\n\nObserve that $\\widetilde{A}_{k}^{j}$ has a one to one correspondence with $A_{k}^{j}$ as both represent the $k$-th recursion cycle from state $j$ to itself.\n\nNote that $P\\left[T_{0}=0\\right]=1$ and for any arbitrary $u_{1}, \\ldots, u_{n}>0$ and any arbitrary $i_{1}, \\ldots, i_{n+1} \\in S$ one has the following identity for any $n \\in \\mathbb{N}$\n\n$$\n\\begin{aligned}\nP\\left[T_{1} \\leq\\right. & \\left.u_{1}, \\ldots, T_{n} \\leq u_{n} \\mid J_{0}=i_{1}, J_{1}=i_{2}, \\ldots, J_{n}=i_{n+1}\\right] \\\\\n\\stackrel{(a)}{=} & \\frac{\\prod_{k=1}^{n} Q_{i_{k} i_{k+1}}\\left(u_{k}\\right)}{\\prod_{k=1}^{n} P_{i_{k} i_{k+1}}} \\\\\n& \\stackrel{(b)}{=} \\prod_{k=1}^{n} F_{i_{k} i_{k+1}}\\left(u_{k}\\right)\n\\end{aligned}\n$$\n\nwhere $(a)$ and $(b)$ in above equalities hold due to (2.1) and (2.4) (as a result of Assumption 1 (c)) respectively. Display (2.6) suggests that conditioned on path $\\left\\{J_{0}=i_{1}, J_{1}=i_{2}, \\ldots, J_{n}=i_{n+1}\\right\\}$ the sojourn times $\\left\\{T_{1}, \\ldots T_{n}\\right\\}$ in corresponding states are independent, which also prompts us to consider the regenerating renewal intervals for $Y$ as well. We define the hitting times of $Y$ at state $j \\in S$, denoted by $\\left\\{\\tau_{k}^{j}: k \\geq 0\\right\\}$ as\n\n$$\n\\tau_{0}^{j}:=\\sum_{i=0}^{N_{0}^{j}} T_{i}, \\quad \\tau_{k}^{j}:=\\sum_{i=0}^{N_{k}^{j}} T_{i} \\quad \\forall k \\geq 1\n$$\n\nand denote the last hitting time to state $j$ before $t$ by\n\n$$\ng_{t}^{j}:=\\max \\left(\\sup \\left\\{n: \\tau_{n}^{j} \\leq t\\right\\}, 0\\right), \\quad \\sup \\emptyset=-\\infty\n$$\n\nIt is clear that any functionals of Y in $\\left\\{\\left[\\tau_{i}^{j}, \\tau_{i+1}^{j}\\right): i \\geq 0\\right\\}$ behave identically and independently as $\\left\\{\\sum_{i=N_{k-1}^{j}+1}^{N_{k}^{j}} T_{i}: k \\geq 1\\right\\}$ are iid due to the fact that $\\mathcal{G}$ is a fixed set and $\\left\\{A_{k}^{j}\\right\\}_{k \\geq 1}$ are regenerating sets for $J$ at state $j \\in S$.\n\nFor $Y$ denote the $k$-th recursion interval at state $j \\in S$ by $\\mathfrak{I}_{k}^{j}:=\\left[\\tau_{k-1}^{j}, \\tau_{k}^{j}\\right)$. From Assumption 1(b) it follows that\n\n$$\n\\begin{aligned}\nE\\left|\\mathfrak{I}_{k}^{j}\\right| & =E \\sum_{n=1}^{\\infty} T_{n} 1_{\\left\\{\\left(J_{n-1}, J_{n}\\right) \\in \\widetilde{A}_{k}^{j}\\right\\}} \\\\\n& =E\\left[\\sum_{n=1}^{\\infty} E\\left[T_{n} \\mid J_{n}=i_{n}, J_{n-1}=i_{n-1}\\right] 1_{\\left\\{\\left(J_{n-1}, J_{n}\\right) \\in \\widetilde{A}_{k}^{j}\\right\\}}\\right] \\\\\n& \\leq\\left(\\sup _{i, j \\in S} m_{i j}\\right) E\\left|\\widetilde{A}_{k}^{j}\\right|<\\infty, \\quad \\forall j \\in S, \\quad \\forall k \\in \\mathbb{N}\n\\end{aligned}\n$$\n\nas a consequence of $E\\left[T_{n} \\mid J_{n}=i_{n}, J_{n-1}=i_{n-1}\\right]=m_{i_{n-1}, i_{n}} \\leq \\sup _{i, j \\in S} m_{i j}$, uniformly for all $\\left(i_{n-1}, i_{n}\\right) \\in$ $S^{2}$.\n\nFor each tuple $\\left(i_{k}, i_{k+1}\\right)$, the sojourn time of the semi-Markov process $Y$ during the transition from state $i_{k}$ to state $i_{k+1}$ is denoted by $\\widetilde{F}_{i_{k} i_{k+1}}$ and follows the distribution $F_{i_{k} i_{k+1}}$. It is possible for two tuples, say $\\left(i_{k}, i_{k+1}\\right)$ and $\\left(i_{l}, i_{l+1}\\right)$, representing different transitions in $\\widetilde{A}_{k}^{j}$, to be identical; that is, for $k \\neq l$, we may have $i_{k}=i_{l}$ and $i_{k+1}=i_{l+1}$. Even in this case, we treat the two tuples $\\left(i_{k}, i_{k+1}\\right)$ and $\\left(i_{l}, i_{l+1}\\right)$ as distinct elements of $\\widetilde{A}_{k}^{j}$. Correspondingly, the sojourn times $\\widetilde{F}_{i_{k} i_{k+1}}$ and $\\widetilde{F}_{i_{l} i_{l+1}}$ are considered independent random variables, each distributed according to $F_{i_{k} i_{k+1}}$.\n\nFor any event $A$ by $P_{i}[A]$ we denote $P\\left[A \\mid Y_{0}=i\\right]$.\nRemark 2.1. Assumption 1(c) is essential for applying the regenerating-renewal argument to the process $Y$. As a result, any functionals of $Y$ within the intervals $\\left\\{\\left[\\tau_{i}^{j}, \\tau_{i+1}^{j}\\right): i \\geq 0\\right\\}$ behave identically and independently for each $j \\in S$. If Assumption 1(c) does not hold, the process $Y$ would fail to regenerate independently after reaching state $j$, as the sojourn time at state $j$ would be influenced by the time spent in the previous state before transitioning to $j$. This would break the independence required for the regeneration of $Y$ in the intervals $\\left\\{\\left[\\tau_{i}^{j}, \\tau_{i+1}^{j}\\right): i \\geq 0\\right\\}$.\n\nTheorem 7.14 of [20] (Page 160) suggests that if $Y$ is an irreducible, recurrent (The term 'Persistent' is used in [20] for recurrent), aperiodic semi-Markov process along with $m_{i}:=\\sum_{j \\in S} P_{i j} m_{i j}<\\infty$, then\n\n$$\n\\lim _{t \\rightarrow \\infty} P_{i}\\left[Y_{t}=j\\right]=\\frac{\\mu_{j} m_{j}}{\\sum_{k \\in S} \\mu_{k} m_{k}}, \\quad \\forall i \\in S\n$$\n\nwhich follows from conditions of Assumption 1. By $\\pi$ denote the probability vector $\\left(\\pi_{i}: i \\in S\\right)$ such that\n\n$$\n\\pi_{j}:=\\frac{\\mu_{j} m_{j}}{\\sum_{k \\in S} \\mu_{k} m_{k}} \\forall j \\in S\n$$\n\nFrom Assumption 1 it follows that $\\pi_{j}>0, \\forall j \\in S$. We loosely describe a process to be ergodic when it converges to a limiting distribution that does not depend on the initial distribution and hence a semiMarkov process $Y$ having all properties above (irreducible, recurrent, aperiodic, $m_{k}<\\infty, \\forall k \\in S$ ) is ergodic.\n\nRegenerative property of $Y$ suggests that any specific functional of $Y$ in $\\left\\{\\left[\\tau_{i-1}^{j}, \\tau_{i}^{j}\\right): i \\geq 1\\right\\}$ behave identically independent random variables. Denote the sigma algebra $\\sigma\\left\\{Y_{t}: t \\in\\left[\\tau_{i-1}^{j}, \\tau_{i}^{j}\\right)\\right\\}$ by $\\mathcal{H}_{i}$ for each $i \\geq 1$. In this setting we have the following result. For any time $t>0$, denote $t-\\tau_{g_{i}^{j}}^{j}, \\tau_{g_{i}^{j}+1}^{j}-t$ by $A_{j}(t), B_{j}(t)$ as respectively backward residual time and forward residual times at state $j \\in S$. Clearly $A_{j}(t)+B_{j}(t)=\\tau_{g_{i}^{j}+1}^{j}-\\tau_{g_{i}^{j}}^{j}$, length of the regenerating interval containing $t$. Results from [20],[5] suggest if $E\\left[\\tau_{g}^{j}-\\tau_{1}^{j}\\right]<\\infty$, (which follows from $E\\left[\\mathfrak{I}_{1}^{j}\\right]<\\infty$, ensured under Assumption 1) then both $A_{j}(t), B_{j}(t)$ are $O_{\\rho}(1)$ as both quantities\n\n$$\nP\\left[A_{j}(t)>x\\right] \\rightarrow \\frac{\\int_{x}^{\\infty} P\\left[\\left|\\mathfrak{I}_{k}^{j}\\right|>y\\right] d y}{E\\left[\\mathfrak{I}_{k}^{j}\\right]}, \\quad P\\left[B_{j}(t)>x\\right] \\rightarrow \\frac{\\int_{x}^{\\infty} P\\left[\\left|\\mathfrak{I}_{k}^{j}\\right|>y\\right] d y}{E\\left|\\mathfrak{I}_{k}^{j}\\right|}\n$$\n\nas $t \\rightarrow \\infty$.\nThe following proposition is a consequence of $Y$ exhibiting renewal regenerative property.\nProposition 2.2. Under Assumption 1, for any $t>\\tau_{0}^{j}$,\n(i) the distribution of $\\tau_{g_{i}^{j}+2}^{j}-\\tau_{g_{i}^{j}+1}^{j}$ is identical as $\\tau_{1}^{j}-\\tau_{0}^{j}$.\n(ii) any functional of $Y$ in $\\left\\{s: s \\geq \\tau_{g_{i}^{j}+1}^{j}\\right\\}$ is independent of $g_{i}^{j}$ and identically distrubuted as the same functional of $Y$ on $\\left\\{s: s \\geq \\tau_{0}^{j}\\right\\}$.\n(iii) Let $Y^{(1)}:=\\left(Y_{t}^{(1)}: t \\geq 0\\right), Y^{(2)}:=\\left(Y_{t}^{(2)}: t \\geq 0\\right)$ be two arbitrary stochastic processes. Conditioned on any event $K_{t}$, suppose marginals of $Y_{t}^{(1)}, Y_{t}^{(2)}$ are respectively $\\sigma\\left\\{\\mathcal{H}_{i}: i \\leq g_{i}^{j}\\right\\}$ and $\\sigma\\left\\{\\mathcal{H}_{i}: i \\geq g_{i}^{j}+2\\right\\}$ measurable for any $j \\in S$. Then following holds conditioned on $\\left\\{Y_{t}=j^{\\prime}\\right\\}$\n\n$$\nP\\left[Y_{t}^{(1)} \\in A, Y_{t}^{(2)} \\in B \\mid K_{t}, Y_{t}=j^{\\prime}\\right]=P\\left[Y_{t}^{(1)} \\in A \\mid K_{t}, Y_{t}=j^{\\prime}\\right] P\\left[Y_{t}^{(2)} \\in B \\mid K_{t}\\right]\n$$\n\nfor arbitrary events $A, B$ for any $j^{\\prime} \\in S$.\nConsider a probability measure $\\pi$ on a countable set $S$ such that $\\pi(A)=\\sum_{i \\in A} \\pi_{i}$ for any $A \\in \\mathcal{B}(S)$ and a set of probability measures $\\left\\{\\mu_{j}: j \\in S\\right\\}$. Then\n\n$$\n\\sum_{j \\in S} \\delta_{U}(\\{j\\}) Z_{j}, \\quad \\text { where } \\quad U \\perp\\left(Z_{j}\\right)_{j \\in S}, \\quad U \\sim \\pi, \\quad Z_{j} \\sim \\mu_{j}\n$$\n\nis a random variable whose distribution is the mixture distribution $\\sum_{j \\in S} \\pi_{j} \\mu_{j}$.\nLet $\\left\\{R_{n}\\right\\}_{n \\geq 1}$ be an arbitrary sequence of random variables and $N_{t}^{*}$ is a $\\mathbb{N}$ valued stopped random time. Suppose there exists a random variable $R_{\\infty}$, such that $R_{n} \\xrightarrow{d} R_{\\infty}$ as $n \\rightarrow \\infty$. Let $N_{t}^{*}$ be any \"stopped random time\" (defined in the common probability space where $\\left\\{R_{n}\\right\\}_{n \\geq 1}$ is defined) such that there exists an increasing function $c(\\cdot)$ such that $c(t) \\rightarrow \\infty$ and $\\frac{N_{t}^{*}}{c(t)} \\xrightarrow{P} 1$ as $t \\rightarrow \\infty$. In this context Anscombe's contiguity condition (Gut [34], p. 16) is useful for establishing weak convergence of the process $\\left(R_{N_{t}^{*}}: t \\geq 0\\right)$ as $t \\rightarrow \\infty$ which is following:\nGiven $\\epsilon>0$ and $\\eta>0$ there exists $\\delta>0$ and $n_{0}$, such that\n\n$$\nP\\left(\\max _{\\{m:|m-n|<n \\delta\\}}\\left|R_{m}-R_{n}\\right|>\\epsilon\\right)<\\eta, \\quad \\forall \\quad n>n_{0}\n$$\n\nIf (2.11) is satisfied by $\\left\\{R_{n}\\right\\}_{n \\geq 1}$, then it is sufficient to conclude\n\n$$\nR_{N_{t}^{*}} \\xrightarrow{d} R_{\\infty} \\quad \\text { as } \\quad t \\rightarrow \\infty\n$$\n\nThe notion of \"stopped random time\" is not same as the \"stopping time\" in the literature.\nFor a given bivariate random variable $(A, B)$, the following time series is referred to as a stochastic recurrence equation (in short SRE, also referred to as random coefficient $\\mathrm{AR}(1)$ )\n\n$$\nZ_{n+1}=A_{n+1} Z_{n}+B_{n+1} \\quad \\text { with } \\quad\\left(A_{i}, B_{i}\\right) \\xrightarrow{\\text { i.i.d }} \\mathcal{L}(A, B), \\quad Z_{n} \\Perp\\left(A_{n+1}, B_{n+1}\\right)\n$$\n\nfor an arbitrary initial $Z_{0}=z_{0} \\in \\mathbb{R}$. Let $\\log ^{+}|a|:=\\log (\\max (|a|, 1))$. If\n\n$$\nP[A=0]=0, \\quad E \\log |A|<0, \\quad \\text { and } \\quad E \\log ^{+}|B|<\\infty\n$$\n\nthen $\\left(Z_{n}\\right)$ has a unique causal ergodic strictly stationary solution solving the following fixed-point equation in law:\n\n$$\nZ \\stackrel{d}{=} A Z+B \\quad \\text { with } \\quad Z \\nmid(A, B)\n$$\n\nThe condition $P[A x+B=x]<1$, for all $x \\in \\mathbb{R}$, rules out degenerate solutions $Z=x$ a.s. We refer to Corollary 2.1.2 and Theorem 2.1.3 in Buraczewski et al. [17] for further details. For multivariate $d$-dimensional case the existence and uniqueness [27] of the distributional solution (2.13) holds if\n\n$$\n\\prod_{i=1}^{n} A_{i} \\stackrel{a, s}{\\rightarrow} 0, \\quad \\& \\quad\\left(\\prod_{i=1}^{n} A_{i}\\right) B_{n+1} \\stackrel{a, s}{\\rightarrow} 0\n$$\n\nFor any two functions $f, g$ the notation $f \\sim g$, implies that $\\lim _{x \\rightarrow \\infty} \\frac{f(x)}{g(x)} \\rightarrow 1$. Furthermore the notation $f \\sim o(g)$, will imply $\\lim _{x \\rightarrow \\infty} \\frac{f(x)}{g(x)} \\rightarrow 0$. A random variable $X$ will be called regularly varying at $\\infty$ with index $\\alpha>0$, if $P[X>x] \\sim x^{-\\alpha} L(x)$ holds where $L(\\cdot)$ is any slowly varying function at $\\infty$, i.e $\\lim _{t \\rightarrow \\infty} \\frac{L^{\\prime}(t)}{L(t)}=1, \\forall x \\in \\mathbb{R}_{+}$. If $X$ is a random variable regularly varying at $\\infty$ with index $\\alpha>0$, then we have $E|X|^{\\beta}<\\infty$ for all $\\beta<\\alpha$, and $E|X|^{\\beta}=\\infty$ for all $\\beta \\geq \\alpha$, for which we alternatively describe $X$ as heavy tailed with index $\\alpha \\geq 0^{\\circ}$ (Proposition 1.4.6 of [43]).\n\nLet $\\widetilde{X}$ be a non-negative regularly varying random variable with index $\\alpha>0$. For each $\\epsilon>0$ there exists a finite constant $c_{\\epsilon}$ such that for any $y \\geq 0$ one has the following upper bound\n\n$$\n\\frac{P[y \\widetilde{X}>x]}{P[\\widetilde{X}>x]} \\leq c_{\\epsilon}(1 \\vee y)^{\\alpha}\n$$\n\nholds that follows directly from Potter's bound (see Proposition 1.4.2 of [43]).\nDefine $\\mathcal{S}_{\\alpha}(\\sigma, \\beta, \\mu)$ as the Stable random variable with $(\\alpha, \\sigma, \\beta, \\mu) \\in(0,2] \\times \\mathbb{R}^{+} \\times[-1,1] \\times \\mathbb{R}$ respectively denoting the index, scale, skewness and the shift parameter whose characteristic function is\n\n$$\n\\begin{aligned}\n\\log E e^{i \\theta \\mathcal{S}_{\\alpha}(\\sigma, \\beta, \\mu)} & =-\\sigma^{\\alpha}|\\theta|^{\\alpha}\\left(1-i \\beta(\\operatorname{sign}(\\theta)) \\tan \\frac{\\pi \\alpha}{2}\\right)+i \\mu \\theta, \\quad \\alpha \\neq 1 \\\\\n& =-\\sigma|\\theta|\\left(1+i \\beta(\\operatorname{sign}(\\theta)) \\frac{2}{\\pi} \\log |\\theta|\\right)+i \\mu \\theta, \\quad \\alpha=1\n\\end{aligned}\n$$\n\nwhere $\\operatorname{sign}(\\theta)=1_{\\{\\theta>0\\}}-1_{\\{\\theta<0\\}}$. In our work we are only concerned for $\\alpha \\in(1,2)$. Under above definition given $C_{\\alpha}:=\\left(\\int_{0}^{\\infty} x^{-\\alpha} \\sin x d x\\right)^{-1}$, significance of $\\beta \\in(-1,1)$ can be represented through the following limits\n\n$$\nx^{\\alpha} P\\left[\\mathcal{S}_{\\alpha}(\\sigma, \\beta, \\mu)>x\\right] \\rightarrow C_{\\alpha} \\frac{1+\\beta}{2} \\sigma^{\\alpha}, \\quad x^{\\alpha} P\\left[\\mathcal{S}_{\\alpha}(\\sigma, \\beta, \\mu)<-x\\right] \\rightarrow C_{\\alpha} \\frac{1-\\beta}{2} \\sigma^{\\alpha}\n$$\n\nas $x \\rightarrow \\infty$. If $\\alpha \\in(1,2)$, it follows that $\\frac{1}{\\sigma} \\mathcal{S}_{\\alpha}(\\sigma, \\beta, \\mu) \\stackrel{d}{=} \\mathcal{S}_{\\alpha}\\left(1, \\beta, \\frac{\\mu}{\\sigma}\\right)$. We recall Theorem 4.5.1 of [62] for a version of stable central limit theorem for a sequence of iid random variables $\\left\\{X_{i}: i \\geq 1\\right\\}$ with each of them is regularly varying $\\mathrm{RV}^{-\\alpha}$, i.e there exists a slowly varying function $L(\\cdot)$ (at $\\infty$ ) such that\n\n$$\nP[|X|>x] \\sim x^{-\\alpha} L(x) \\quad \\text { with } \\quad \\lim _{x \\rightarrow \\infty} \\frac{P[X>x]}{P[|X|>x]} \\rightarrow \\frac{1+\\beta}{2}\n$$\n\nfor some $-1<\\beta<1$. Given this set up, define a scaling function $c_{n}$ such that\n\n$$\n\\lim _{n \\rightarrow \\infty} \\frac{n L\\left(c_{n}\\right)}{c_{n}^{\\alpha}}=C_{\\alpha}, \\quad \\text { which implies that } \\quad c_{n}=n^{\\frac{1}{\\alpha}} L_{0}(n) \\text { (Thm 4.5.1 [62]), }\n$$\n\nfor some slowly varying function $L_{0}(\\cdot)$ different from $L(\\cdot)$ but it depends on $L$ through (2.15). By $\\mathbf{S}_{\\alpha, \\beta}$ denote the $\\alpha$-stable Levy process $\\mathbf{S}_{\\alpha, \\beta}:=\\left(\\mathbf{S}_{\\alpha, \\beta}(t): t \\geq 0\\right)$ such that the increments follow Stable law (see display (5.30) of [62]) as\n\n$$\n\\mathbf{S}_{\\alpha, \\beta}(t+s)-\\mathbf{S}_{\\alpha, \\beta}(s) \\stackrel{d}{=} \\mathcal{S}_{\\alpha}\\left(t^{\\frac{1}{\\alpha}}, \\beta, 0\\right) \\stackrel{d}{=} t^{\\frac{1}{\\alpha}} \\mathcal{S}_{\\alpha}(1, \\beta, 0) \\quad \\forall s, t \\geq 0\n$$",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 3,
      "text": "# 3 Main results on stable domain \n\nIn this section we study long-time behavior of the joint process $\\left(\\Phi^{(a)}, I^{(a, b)}, Y\\right):=\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}, Y_{t}\\right)_{t \\geq 0}$ ensuring convergence in distribution as $t \\rightarrow \\infty$. Following assumption will ensure the existence of a limiting distribution for $\\left(\\Phi^{(a)}, I^{(a, b)}, Y\\right)$ :\nAssumption 2. The $S$-valued process $Y$ and the functions $a, b: S \\rightarrow \\mathbb{R}$ satisfy\n(a) $a(\\cdot)$ is integrable with respect to $\\pi$, and $E_{\\pi} a(\\cdot)>0$.\n(b) For every $j \\in S, E\\left[\\log ^{+} \\mid \\int_{\\tau_{0}^{j}}^{\\tau_{j}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{\\pi}^{\\tau_{j}^{j}} a\\left(Y_{r}\\right) d r} d s\\right]<\\infty$.\n\nFor each $j \\in S$, let $\\pi_{j}^{*}$ be the distribution on $\\mathbb{R}^{+}$such that for any $x>0$,\n\n$$\n\\pi_{j}^{*}[x, \\infty):=\\frac{\\sum_{k \\in S} P_{j k} \\int_{x}^{\\infty}\\left(1-F_{j k}(y)\\right) d y}{m_{j}}\n$$\n\nRemark 3.1. (i) Assumption 2 corresponds to the general condition (2.12) for existence of a stationary solution to the stochastic recurrence equation\n\n$$\nZ_{j, n+1}=e^{-\\int_{\\tau_{0}^{j}}^{\\tau_{0}^{j}}+1} a\\left(Y_{s}\\right) d s} Z_{j, n}+\\int_{\\tau_{0}^{j}}^{\\tau_{n+1}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{\\pi}^{\\tau_{n+1}^{j}} a\\left(Y_{r}\\right) d r} d s\n$$\n\nwith affine solution of the form\n\n$$\nZ_{j} \\stackrel{d}{=} e^{-\\int_{\\tau_{0}^{j}}^{\\tau_{0}^{j}} a\\left(Y_{s}\\right) d s} Z_{j}+\\int_{\\tau_{0}^{j}}^{\\tau_{j}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{\\pi}^{\\tau_{0}^{j}} a\\left(Y_{r}\\right) d r} d s\n$$\n\nAssumption 2(b) defines integrability criteria for $b(\\cdot)$. Observe that if $\\sup _{j \\in S}|a(j)|<\\infty$ and $E_{\\pi}|b(\\cdot)|<$ $\\infty$, then Assumption 2(b) follows immediately from Assumption 1 as a consequence of the inequalities $\\log ^{+}|a b| \\leq \\log ^{+}|a|+\\log ^{+}|b|$ and $\\log ^{+}|a| \\leq|a|$ for any $a, b$.\n(ii) $\\pi_{j}^{*}$ in (3.1) is a size-biased distribution of averaged sojourn time at state $j \\in S$. Note that if $F_{j k}(x)=1-e^{-\\lambda_{j} x} \\forall k$, (corresponds to the case of CTMC) then $\\pi_{j}^{*}[x, \\infty)=e^{-\\lambda_{j} x}$ for $x>0$, as a consequence of the fact that Exponential distribution is the unique distributional fixed point of the size-biased transformation. If we consider a variation, such that $F_{j k}(x):=1-e^{-\\lambda_{j k} x}$, for some $\\lambda_{j k} \\in(0, \\infty) \\forall j, k \\in S$, then\n\n$$\n\\pi_{j}^{*}[x, \\infty):=\\frac{\\sum_{k \\in S} \\frac{P_{j k}}{\\lambda_{j k}} e^{-\\lambda_{j k} x}}{\\sum_{k \\in S} \\frac{P_{j k}}{\\lambda_{j k}}} \\quad \\forall x>0\n$$\n\ni.e, $\\pi_{j}^{*}$ will be a mixture of Exponentials of aforementioned form.\n\nAn explicit expression for the limiting distribution of the joint process $(\\Phi, I, Y)$ is given in following theorem.\n\nTheorem 1. Under Assumptions 1 and 2 the limiting distribution of the joint process $\\left(\\Phi^{(a)}, I^{(a, b)}, Y\\right)$ can be expressed as :\n\n$$\n\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}, Y_{t}\\right) \\xrightarrow{d} \\quad\\left(0, \\sum_{j \\in S} \\delta_{U}(\\{j\\}) Z_{j}, U\\right) \\quad \\text { as } t \\rightarrow \\infty\n$$\n\nwhere $U \\Perp\\left(Z_{j}\\right)_{j \\in S}, U \\sim \\pi$, and\n\n$$\nZ_{j} \\stackrel{d}{=} b(j) \\int_{0}^{T^{j}} e^{-a(j)\\left(T^{j}-s\\right)} d s+e^{-a(j) T^{j}} V_{j}^{*}\n$$\n\nwhere $T^{j} \\sim \\pi_{j}^{*}$ is independent of $V_{j}^{*}$, and $\\mathcal{L}\\left(V_{j}^{*}\\right)$ is the unique solution to (2.13) with $(A, B)$ having the distribution of\n\n$$\n\\left(e^{-\\int_{\\tau_{0}^{j}}^{\\tau_{0}^{j}} a\\left(Y_{s}\\right) d s}, \\int_{\\tau_{0}^{j}}^{\\tau_{j}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{\\pi}^{\\tau_{j}^{j}} a\\left(Y_{r}\\right) d r} d s\\right)\n$$\n\nA remark on moments of $I$ is made (similar to Remark 3.3 in [46]) below.\nRemark 3.2. Moments for the stationary distribution of $I$ in (3.2) can be computed recursively using the representation for $\\left(A_{j}, B_{j}\\right)$ in (3.4). From $V_{j}^{*} \\stackrel{d}{=} A_{j} V_{j}^{*}+B_{j}$ follows that, for $m \\in \\mathbb{N}$,\n\n$$\n\\left(V_{j}^{*}\\right)^{m}\\left(1-A_{j}^{m}\\right)=\\sum_{k=0}^{m-1}\\binom{m}{k} A_{j}^{k} B_{j}^{m-k}\\left(V_{j}^{*}\\right)^{k}\n$$\n\nIf there exists $n \\in \\mathbb{N}$ such that $E A_{j}^{m}<\\infty$ and $E\\left[A_{j}^{k} B_{j}^{m-k}\\right]<\\infty$ for $0 \\leq k \\leq m \\leq n$, then $E\\left|V_{j}^{*}\\right|^{n}<\\infty$ and independence between $V_{j}^{*}$ and $\\left(A_{j}, B_{j}\\right)$ gives following recursive relation of moments\n\n$$\nE\\left[\\left(V_{j}^{*}\\right)^{m}\\right]=\\frac{1}{1-E A_{j}^{m}} \\sum_{k=0}^{m-1}\\binom{m}{k} E\\left[A_{j}^{k} B_{j}^{m-k}\\right] E\\left[\\left(V_{j}^{*}\\right)^{k}\\right]\n$$\n\nFrom the above representations moments of the limit distribution\n\n$$\nE\\left[\\left(I_{\\infty}^{(a, b)}\\right)^{m}\\right]=\\sum_{j \\in S} \\pi_{j} E\\left[\\left(b(j) \\int_{0}^{T^{j}} e^{-a(j)\\left(T^{j}-s\\right)} d s+e^{-a(j) T^{j}} V_{j}^{*}\\right)^{m}\\right]\n$$\n\ncan be computed using the independence of $T^{j}, V_{j}^{*}$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 4,
      "text": "# 4 Divergence and critical domains \n\nThis section is devoted to the exploration of the long-term behavior of the process $\\left(\\Phi^{(a)}, I^{(a, b)}\\right)$ under conditions that are different from Assumption 2. In particular, it will be assumed that the stability condition $E_{\\pi} a(\\cdot)>0$ in Assumption 2(a) does not hold. We will see that the conditions $E_{\\pi} a(\\cdot)=0$ and $E_{\\pi} a(\\cdot)<0$ correspond to critical case and divergent (or transient) case respectively which will be further subdivided into cases when\n\n$$\n\\sigma_{j}^{2}:=\\operatorname{Var}\\left(\\int_{\\tau_{0}^{j}}^{\\tau_{t}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s\\right)\n$$\n\nis $\\in(0, \\infty)$, or $=\\infty$, or $=0$ for each $j \\in S$ as below\n\n- Case A: $E_{\\pi} a(\\cdot) \\leq 0$, and $\\sigma_{j}^{2} \\in(0, \\infty)$ for all $j \\in S$,\n- Case B: $E_{\\pi} a(\\cdot) \\leq 0$, and $\\int_{\\tau_{0}^{j}}^{\\tau_{t}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s$ is regularly varying with index $\\alpha \\in(1,2)$, for all $j \\in S$,\n- Case C: $E_{\\pi} a(\\cdot) \\leq 0$, and $\\sigma_{j}^{2}=0$ for all $j \\in S$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 5,
      "text": "### 4.1 Case A: $\\quad E_{\\pi} a(\\cdot) \\leq 0$, and $\\sigma_{j}^{2} \\in(0, \\infty)$\n\nObserve that $I_{t}^{(a, b)}=\\Phi_{t}^{(a)} \\widetilde{I}_{t}^{(a, b)}$ where $\\widetilde{I}_{t}^{(a, b)}=\\int_{0}^{t} b\\left(Y_{s}\\right) e^{\\int_{0}^{s} a\\left(Y_{r}\\right) d r} d s$. When $E_{\\pi} a(\\cdot)<0$, then $\\widetilde{I}_{t}^{(a, b)}$ behaves similar to $I_{t}^{(a, b)}$ as $t \\rightarrow \\infty$ distributional limit in Theorem 1, implies that as $t \\rightarrow \\infty$,\n\n$$\n\\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{t} \\xrightarrow{a s}-E_{\\pi} a(\\cdot)\n$$\n\nas a consequence of ergodic renewal theory. To be precise we restate the assumptions under which a scaled fluctuation of $\\left(\\Phi^{(a)}, I^{(a, b)}\\right)$ will obtain the following limit theorem.\nAssumption 3. The $S$-valued process $Y$ and the functions $a, b: S \\rightarrow \\mathbb{R}$ satisfy\n(a) $a$ is integrable with respect to $\\pi$, and $E_{\\pi} a(\\cdot) \\leq 0$.\n\n(b) For every $j \\in S, \\sigma_{j}^{2}:=\\operatorname{Var}\\left(\\int_{\\tau_{0}^{j}}^{\\tau_{j}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s\\right) \\in(0, \\infty)$.\n(c) Assumption 2(b) holds.\n\nLet $(B, M)$ be a Brownian motion and its supremum jointly defined in the same space, i.e\n\n$$\n\\left(\\left(B_{s}, M_{s}\\right): B \\text { is a standard Brownian motion, } M_{s}:=\\sup _{0 \\leq t \\leq s} B_{t}, s \\geq 0\\right)\n$$\n\nTheorem 2. Suppose Assumptions 1 and 3 hold. Let $U \\sim \\pi$, and $N \\sim \\mathrm{~N}(0,1)$ are all mutually independent.\n(a) If $E_{\\pi} a(\\cdot)<0$, as $t \\rightarrow \\infty$\n\n$$\n\\left(\\frac{\\log \\Phi_{t}^{(a)}+t E_{\\pi} a(\\cdot)}{\\sqrt{t}}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|+t E_{\\pi} a(\\cdot)}{\\sqrt{t}}\\right) \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\frac{\\sigma_{j}}{\\sqrt{E\\left|\\mathcal{H}_{1}^{t}\\right|}}(N, N)\n$$\n\n(b) Suppose $E_{\\pi} a(\\cdot)=0, b \\neq 0$ and Assumption 3(c) is replaced by\n\n$$\n\\begin{gathered}\nE\\left[\\left(\\log \\left|\\int_{\\tau_{0}^{j}}^{\\tau_{j}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{\\tau_{0}^{j}}^{\\tau_{j}^{j}} a\\left(Y_{\\tau}\\right) d \\tau} d s\\right]\\right)^{2}\\right]<\\infty \\quad \\text { for every } j \\in S \\\\\n\\left(\\frac{\\log \\Phi_{t}^{(a)}}{\\sqrt{t}}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{\\sqrt{t}}\\right) \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\frac{\\sigma_{j}}{\\sqrt{E\\left|\\mathcal{H}_{1}^{t}\\right|}}\\left(F_{1}, F_{2}\\right) \\quad \\text { as } t \\rightarrow \\infty\n\\end{gathered}\n$$\n\nwhere $U$ is independent of random variables $\\left(F_{1}, F_{2}\\right)$ having joint density\n\n$$\nP\\left[F_{1} \\in d x, F_{2} \\in d \\xi\\right]=\\sqrt{\\frac{2}{\\pi}}(2 \\xi-x) e^{-\\frac{(2 \\xi-x)^{2}}{2}} 1_{[0, \\infty) \\times(-\\infty, \\xi)}(\\xi, x) d \\xi d x\n$$\n\nRemark 4.1. $\\left(F_{1}, F_{2}\\right)$ is identical with $\\left(B_{1}, M_{1}\\right)$ in distribution (using notation from (4.1)). The difference between \" $E_{\\pi} a(\\cdot)<0$ \" and \" $E_{\\pi} a(\\cdot)=0$ \" is reflected in the distributional part of RHS weak limit of $\\left(\\frac{\\log \\Phi_{t}^{(a)}+t E_{\\pi} a(\\cdot)}{\\sqrt{t}}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|+t E_{\\pi} a(\\cdot)}{\\sqrt{t}}\\right)$, as it weakly transits from $\\left(B_{1}, B_{1}\\right) \\stackrel{d}{=}(N, N)$ to $\\left(B_{1}, M_{1}\\right)$. Marginally $M_{1} \\stackrel{d}{=}\\left|B_{1}\\right| \\stackrel{d}{=}|N| \\stackrel{d}{=} F_{2}$, (a consequence of the reflection principle) which is also celebrated as a consequence of the Erdos-Kac theorem [26].",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 6,
      "text": "# 4.2 Case B: $\\left(E_{\\pi} a(\\cdot) \\leq 0\\right.$, and a case of $\\sigma_{j}^{2}=\\infty$ for all $\\left.j \\in S\\right)$ \n\nBy $\\widehat{a}(\\cdot)$, denote the function $a(\\cdot)-E_{\\pi} a(\\cdot)$. We consider a special case of $\\sigma_{j}^{2}=\\infty$, such that the condition\n\n$$\n\\int_{\\tau_{0}^{j}}^{\\tau_{j}^{j}} \\widehat{a}\\left(Y_{s}\\right) d s\n$$\n\nis regularly varying with index $\\alpha \\in(1,2)$ holds for all $j \\in S$. Under additional model assumptions, a limit result in this context will be established. Recall the definition of $\\widehat{A}_{k}^{j}$ from display (2.5), which represents the set of tuples corresponding to successive transitions during the $k$-th recursion at state $j$ by the underlying process $J$. If we allow some elements of $\\mathcal{G}$ to be regularly varying heavy-tailed, under the assumption of divergence (i.e $E_{\\pi} a(\\cdot) \\leq 0$ ), it is intuitive that the long time limit results will be influenced by the behavior of the process during sojourn times, that have the heaviest tails. As noted in the Remark 4.3, even if all sojourn times have an Exponentially light tail, it is still possible for $\\int_{\\tau_{0}^{j}}^{\\tau_{j}^{j}} \\widehat{a}\\left(Y_{s}\\right) d s$ to exhibit a regularly varying heavy tail, driven purely by the state-interaction dynamics of $J$. Here, we examine a scenario where the heaviest tail of the sojourn times dominates the effect of the $J$ chain (via controlling the moments of $\\left|\\widehat{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}\\right|$ in (4.7)), in explaining the regular variation of $\\int_{\\tau_{0}^{j}}^{\\tau_{j}^{j}} \\widehat{a}\\left(Y_{s}\\right) d s$. Following assumption, particularly Assumption 4(b), formalizes this notion which is why it is somewhat lengthy.\n\nAssumption 4. The $S$-valued process $Y$ and the functions $a, b: S \\rightarrow \\mathbb{R}$ satisfy\n(a) $a$ is integrable with respect to $\\pi$, and $E_{\\pi} a(\\cdot) \\leq 0$.\n(b) Suppose the set $\\mathcal{G}$ contains at least one element that is regularly varying at $\\infty$. Let the heaviest tail index of the sojourn times (which are elements of $\\mathcal{G}$ ) be $\\alpha \\in(1,2)$, and let $L(\\cdot)$ represent the largest slowly varying function among them (the function that diverges to $\\infty$ the fastest as the argument tends to $\\infty$ ). Define the set\n\n$$\n\\begin{gathered}\n\\mathbb{S}_{\\alpha}:=\\left\\{(i, j) \\in S^{2}: P_{i j}>0, F_{i j} \\in \\mathcal{G}, \\widehat{a}(i) \\neq 0, \\text { and } \\bar{F}_{i j}(x)=c_{i j} L(x) x^{-\\alpha}\\right. \\\\\n\\text { such that } \\left.\\forall\\left(i_{k}, i_{k+1}\\right) \\notin \\mathbb{S}_{\\alpha}, \\bar{F}_{i_{k} i_{k+1}}(x)=o\\left(\\bar{F}_{i j}(x)\\right)\\right\\}\n\\end{gathered}\n$$\n\nThis set $\\mathbb{S}_{\\alpha}$ consists of all pairs $(i, j)$ (representing transitions of the $J$-chain) whose corresponding sojourn time distributions have the same heaviest regularly varying tails (upto multiplicative constants), characterized by the smallest index $\\alpha$ and the largest slowly varying function $L(\\cdot)$ ) at $+\\infty$. We assume $\\mathbb{S}_{\\alpha}$ is non-empty.\nIn line with (2.14), we assume the existence of $\\epsilon>0$, and a universal constant $\\widetilde{c}_{\\epsilon}<\\infty$ such that for all $y \\geq 0$,\n\n$$\n\\begin{gathered}\n\\sup _{\\left(i_{k}, i_{k+1}\\right) \\in \\mathbb{S}_{\\alpha}} \\frac{P\\left[y \\widetilde{F}_{i_{k} i_{k+1}}>x\\right]}{P\\left[\\widetilde{F}_{i_{k} i_{k+1}}>x\\right]} \\leq \\widetilde{c}_{\\epsilon}(1 \\vee y)^{\\alpha+\\epsilon}, \\quad \\text { and } \\\\\nE\\left[\\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\widetilde{A}\\left[\\cap \\mathbb{S}_{\\alpha}\\right.} c_{i_{l} i_{l+1}}\\left(\\left|a\\left(i_{l}\\right)\\right|\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}\\right|\\right)^{\\alpha+\\epsilon}\\right]<\\infty, \\forall j \\in S\n\\end{gathered}\n$$\n\nwhere $\\widetilde{F}_{i_{k} i_{k+1}}$ is a random variable distributed as $F_{i_{k} i_{k+1}}$.\nFurthermore, there exist constants $x^{*}, a^{*}<\\infty$, such that following hold:\n\n$$\n\\begin{gathered}\n\\sup _{x \\geq x^{*}}\\sup _{\\left(j_{k}, j_{k+1}\\right) \\notin \\mathbb{S}_{\\alpha}} \\frac{\\bar{F}_{j_{k} j_{k+1}}(x)}{x^{-\\alpha} L(x)} \\leq 1 \\\\\n\\sup _{\\left(j_{k}, j_{k+1}\\right) \\notin \\mathbb{S}_{\\alpha}} a\\left(j_{k}\\right)=a^{*}, \\&\\left.E\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c}\\right|^{1+\\alpha}<\\infty\\right.\n\\end{gathered}\n$$\n\nwhere $\\mathbb{S}_{\\alpha}^{c}=\\mathbb{S}_{\\alpha}^{c,+} \\cup \\mathbb{S}_{\\alpha}^{c,-}$, with\n\n$$\n\\begin{aligned}\n\\mathbb{S}_{\\alpha}^{c,+}: & =\\left\\{\\left(i_{k}, i_{k+1}\\right) \\notin \\mathbb{S}_{\\alpha}: P_{i_{k} i_{k+1}}>0, \\widehat{a}\\left(i_{k}\\right)>0\\right\\}, \\quad \\text { and } \\\\\n\\mathbb{S}_{\\alpha}^{c,-} & :=\\left\\{\\left(i_{k}, i_{k+1}\\right) \\notin \\mathbb{S}_{\\alpha}: P_{i_{k} i_{k+1}}>0, \\widehat{a}\\left(i_{k}\\right)<0\\right\\}\n\\end{aligned}\n$$\n\n(c) Assumption 2(b) holds.\n(d) Define $\\mathbb{S}_{\\alpha}^{+}:=\\left\\{(i, j) \\in \\mathbb{S}_{\\alpha}: \\widehat{a}(i)>0\\right\\}, \\quad \\mathbb{S}_{\\alpha}^{-}:=\\left\\{(i, j) \\in \\mathbb{S}_{\\alpha}: \\widehat{a}(i)<0\\right\\}$. For any $j \\in S$, define further\n\n$$\n\\begin{aligned}\n\\widetilde{\\alpha}_{j}^{(+)} & :=E\\left[\\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\widetilde{A}\\left[\\cap \\mathbb{S}_{\\alpha}^{+}\\right.} c_{i_{l} i_{l+1}}\\left[a\\left(i_{l}\\right)-E_{\\pi} a(\\cdot)\\right]^{\\alpha}\\right] \\\\\n\\widetilde{\\alpha}_{j}^{(-)} & :=E\\left[\\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\widetilde{A}\\left[\\cap \\mathbb{S}_{\\alpha}^{-}\\right.} c_{i_{l} i_{l+1}}\\left|a\\left(i_{l}\\right)-E_{\\pi} a(\\cdot)\\right|^{\\alpha}\\right] \\\\\n\\sigma_{(j, \\alpha)} & :=\\left(\\widetilde{\\alpha}_{j}^{(+)}+\\widetilde{\\alpha}_{j}^{(-)}\\right)^{1 / \\alpha}, \\quad \\beta_{j}:=\\frac{\\widetilde{\\alpha}_{j}^{(-)}-\\widetilde{\\alpha}_{j}^{(+)}}{\\widetilde{\\alpha}_{j}^{(+)}+\\widetilde{\\alpha}_{j}^{(-)}} \\in[-1,1]\n\\end{aligned}\n$$\n\ngiven that the RHS of (4.10),(4.11) and (4.12) are all finite, specified by the marginal dynamics of $J$ chain and $a(\\cdot)$.\nRemark 4.2. (a) Under Assumptions 1 and 4 the quantities $\\widetilde{\\alpha}_{j}^{(+)}, \\widetilde{\\alpha}_{j}^{(-)}$can be simplified in closed form, given the information on the marginal Markovian dynamics J. For all $j \\in S$,\n\n$$\n\\widetilde{\\alpha}_{j}^{(+)}=E\\left|A_{k}^{j}\\right| \\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\mathbb{S}_{\\alpha}^{+}} \\mu_{i_{l}} P_{i_{l} i_{l+1}} c_{i_{l} i_{l+1}}\\left[\\widehat{a}(\\cdot)\\left(i_{l}\\right)\\right]^{\\alpha}\n$$\n\n$$\n\\widetilde{\\alpha}_{j}^{(-)}=E\\left|A_{k}^{j}\\right| \\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\mathbb{S}_{\\alpha}^{-}} \\mu_{i_{l}} P_{i_{l} i_{l+1}} c_{i_{l} i_{l+1}}|\\widehat{a}(\\cdot)\\left(i_{l}\\right)|^{\\alpha}\n$$\n\nwhere $\\mu$ is the stationary distribution of the marginal $S$-valued Markovian dynamics $J$.\n(b) In line of (2.14), (4.6) holds trivially by setting $\\widetilde{c}_{e}=\\sup _{\\left(i_{k}, i_{k+1}\\right) \\in \\mathbb{S}_{\\alpha}} c_{i_{k} i_{k+1}}<\\infty$.\n(c) Display (4.7) indicates that the tail of the heaviest sojourn time distribution will dominate the effect of the interaction dynamics of the $J$ chain, and it holds if we have $\\sup _{x \\in S}|a(x)|<\\infty$, and $E\\left[\\left|A_{1}^{j}\\right|^{1+\\alpha+\\epsilon}\\right]<$ $\\infty$.\n(d) Since for any $\\left(j_{k}, j_{k+1}\\right) \\notin \\mathbb{S}_{\\alpha}, \\frac{\\bar{F}_{j_{k} j_{k+1}}(x)}{x^{-\\alpha} L(x)} \\rightarrow 0$ as $x \\rightarrow \\infty$, so does $\\sup _{\\left(j_{k}, j_{k+1}\\right) \\notin \\mathbb{S}_{\\alpha}} \\frac{\\bar{F}_{j_{k} j_{k+1}}(x)}{x^{-\\alpha} L(x)}$ and (4.8) holds trivially.\nTheorem 3. Suppose Assumptions 1 and 4 hold for some $\\alpha \\in(1,2)$ and slowly varying function $L(\\cdot)$. Let $U \\sim \\pi$, and $\\alpha$-Stable processes $\\left(\\mathbf{S}_{\\alpha, \\beta_{j}}: j \\in S\\right)$ are all mutually independent.\n(a) If $E_{\\pi} a(\\cdot)<0$, there exists a slowly varying function $L_{0}(\\cdot)$ such that as $t \\rightarrow \\infty$,\n\n$$\n\\begin{aligned}\n& \\left(\\frac{\\log \\Phi_{t}^{(a)}+t E_{\\pi} a(\\cdot)}{t^{\\frac{1}{\\alpha}} L_{0}(t)}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|+t E_{\\pi} a(\\cdot)}{t^{\\frac{1}{\\alpha}} L_{0}(t)}\\right) \\\\\n& \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left(\\frac{1}{E\\left|\\mathfrak{I}_{1}^{j}\\right|}\\right)^{\\frac{1}{\\alpha}} \\sigma_{(j, \\alpha)}\\left(\\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right), \\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right)\\right)\n\\end{aligned}\n$$\n\n(b) Suppose $E_{\\pi} a(\\cdot)=0, b \\neq 0$ and Assumption 4(c) is replaced by the following condition that there exists $\\epsilon>0$, such that following holds for all $j \\in S$,\n\n$$\nE\\left[\\left(\\log \\left|\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{\\epsilon}^{\\tau_{1}^{j}} a\\left(Y_{r}\\right) d r} d s\\right|\\right)^{\\alpha+\\epsilon}\\right]<\\infty\n$$\n\nThen there exists a slowly varying function $L_{0}(\\cdot)$ such that as $t \\rightarrow \\infty$,\n\n$$\n\\left(\\frac{\\log \\Phi_{t}^{(a)}}{t^{\\frac{1}{\\alpha}} L_{0}(t)}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{t^{\\frac{1}{\\alpha}} L_{0}(t)}\\right) \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left(\\frac{1}{E\\left|\\mathfrak{I}_{1}^{j}\\right|}\\right)^{\\frac{1}{\\alpha}} \\sigma_{(j, \\alpha)}\\left(\\mathbf{S}_{\\alpha, \\beta_{j}}(1), \\sup _{0 \\leq u \\leq 1} \\mathbf{S}_{\\alpha, \\beta_{j}}(u)\\right)\n$$\n\nRemark 4.3. A major component of Theorem 3 is Lemma 10.1, which states that under Assumption 1, Assumption 4(b) implies that the quantity $\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} \\widehat{a}\\left(Y_{s}\\right) d s$ is regularly varying with index $\\alpha \\in(1,2)$. We conjecture that in a finite state space $(|S|<\\infty)$, the reverse also holds, i.e under Assumption 1, if the quantity $\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} \\widehat{a}\\left(Y_{s}\\right) d s$ is regularly varying with index $\\alpha \\in(1,2)$, then at least one element of $\\mathcal{G}$ must be regularly varying at infinity with tail index $\\alpha \\in(1,2)$. However, in the case of an infinite state space $(|S|=\\infty)$, this implication may not hold. For instance, it is possible to construct a continuous-time Markov chain (i.e, all sojourn times are Exponentially distributed) where $\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} \\widehat{a}\\left(Y_{s}\\right) d s$ exhibits heavy-tailed behavior with index $\\alpha \\in(1,2)$ purely due to the dynamics of $J$ in the infinite state space $S$. In such pathological cases, results analogous to Theorem 3(a) and (b) will still hold, even in the absence of Assumption 4(b) (or a modification), a scenario we plan to explore further in future.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 7,
      "text": "# 4.3 Case C: $\\left(E_{\\pi} a(\\cdot) \\leq 0\\right.$, and $\\left.\\sigma_{j}^{2}=0\\right$, for all $\\left.j \\in S\\right)$ \n\nWe begin by stating the following proposition.\nProposition 4.4. If $S$ is finite, then the Assumption $\\sigma_{j}^{2}=0$ implies that $a(\\cdot)=a$ constant with probability 1 .\n\nWe assume that the $a(\\cdot)$ remains constant throughout Case $\\mathbf{C}$ and let that constant be $a(\\cdot)=a$ and as a consequence $\\Phi^{(a)}(t)=e^{a t}$. The following results show how under different conditions $I_{t}^{(a, b)}$ grow differently, from exponential with a random multiplicative coefficient to an asymptotically linear function of $t$ with different exponents.\n\nTheorem 4. Suppose Assumptions 1 holds with $a(\\cdot)=a$. Let $U \\sim \\pi$, and $N \\sim N(0,1)$ are independent of each other. As $t \\rightarrow \\infty$, for any $s>0$\n(a) if $a<0$, and suppose $E \\log ^{+}\\left|\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b\\left(Y_{s}\\right) e^{a\\left(s-\\tau_{0}^{j}\\right)} d s\\right|<\\infty$ holds. Then as $t \\rightarrow \\infty$,\n\n$$\ne^{a t} I_{t}^{(a, b)} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left[\\int_{0}^{\\tau_{0}^{j}} b\\left(Y_{s}\\right) e^{a s} d s+e^{a \\tau_{0}^{j}} V_{j}^{*}\\right]\n$$\n\nwhere $V_{j}^{*}$ satisfies (2.13) with $(A, B)$ respectively are\n\n$$\n(A, B) \\stackrel{d}{=}\\left(e^{a\\left(\\tau_{1}^{j}-\\tau_{0}^{j}\\right)}, \\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b\\left(Y_{s}\\right) e^{a\\left(s-\\tau_{0}^{j}\\right)} d s\\right)\n$$\n\n(b) Suppose $a=0, b \\neq 0$ and $b(\\cdot)$ is integrable with respect to $\\pi$. As $t \\rightarrow \\infty$,\n\n$$\n\\frac{I_{t}^{(0, b)}}{t} \\xrightarrow{p} E_{\\pi} b(\\cdot)\n$$\n\nThis result can be further tri-furcated based on whether\n\n$$\n\\sigma_{j,(b)}^{2}:=\\operatorname{Var}\\left(\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}}\\left(b\\left(Y_{s}\\right)-E_{\\pi} b(\\cdot)\\right) d s\\right)\n$$\n\nis finite, $=\\infty$, or $=0$; and they are following:\n(i) If $\\sigma_{j,(b)}^{2}<\\infty$, as $t \\rightarrow \\infty$, then $\\frac{I_{t}^{(0, b)}}{\\sqrt{t}}-\\sqrt{t} E_{\\pi} b(\\cdot) \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\frac{\\sigma_{j,(b)}}{\\sqrt{E\\left|\\Im_{1}^{j}\\right|}} N$.\n(ii) Suppose Assumption 4(a)(b) $\\mathcal{O}$ (d) hold replacing a by $b$ and $\\alpha$ by $\\alpha_{b}$ (a special case of $\\sigma_{j,(b)}^{2}=$ $\\infty$ ). The quartet $\\left(\\widetilde{\\alpha}_{j,(b)}^{(\\dagger)}, \\widetilde{\\alpha}_{j,(b)}^{(-)}, \\widetilde{\\beta}_{j,(b)}, \\sigma_{\\left(j, \\alpha_{b},(b)\\right)}\\right)$ is defined similarly as $\\left(\\widetilde{\\alpha}_{j}^{(\\dagger)}, \\widetilde{\\alpha}_{j}^{(-)}, \\widetilde{\\beta}_{j}, \\sigma_{(j, \\alpha)}\\right)$ in (4.10),(4.11), (4.12) replacing a by $b$. Then as $t \\rightarrow \\infty$,\n\n$$\n\\frac{I_{t}^{(0, b)}-t E_{\\pi} b(\\cdot)}{t^{\\frac{1}{1}} L_{1}(t)} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left(\\frac{1}{E\\left|\\Im_{1}^{j}\\right|}\\right)^{\\frac{1}{m}} \\sigma_{\\left(j, \\alpha_{b},(b)\\right)} \\mathcal{S}_{\\alpha_{b}}\\left(1,-\\widetilde{\\beta}_{j,(b)}, 0\\right)\n$$\n\nfor some slowly varying function $L_{1}(\\cdot)$.\n(iii) If $b$ is a constant (case corresponding to $\\sigma_{j,(b)}^{2}=0$ ), and then $I_{t}^{(0, b)}=b t$ is a deterministic quantity.\n\nFollowing result indicates that the asymptotic behavior of $\\log \\left|I_{t}^{(a, b)}\\right|$ from Theorems 2 and 3 also applies to the logarithm of any process that can be expressed as an arbitrary linear combination of $\\left\\{\\Phi_{t}^{(a)}, I_{t}^{(a, b)}\\right\\}$ or $\\left\\{\\Phi_{t}^{(a)},\\left|I_{t}^{(m a, b)}\\right|^{\\frac{1}{m}}\\right\\}$. However, the result for Theorem 4 will differ from those in Theorems 2 and 3, which will be relevant for various applications. For brevity, we denote the weak limits of $\\log \\left|I_{t}^{(a, b)}\\right|$ as $t \\rightarrow \\infty$ (after appropriate scaling and shifts) by $\\mathcal{W}_{2(a)}, \\mathcal{W}_{2(b)}, \\mathcal{W}_{3(a)}$, and $\\mathcal{W}_{3(b)}$, corresponding to Theorems 2(a), $2(\\mathrm{~b}), 3(\\mathrm{a})$, and $3(\\mathrm{~b})$, respectively, under the corresponding assumptions.\n\nCorollary 4.5. Suppose two arbitrary stochastic processes $\\left(\\widetilde{Z}_{t}^{(1)}: t \\geq 0\\right),\\left(\\widetilde{Z}_{t}^{(2)}: t \\geq 0\\right)$ are marginally defined as a random linear combination of both $\\Phi_{t}^{(a)}$ and $I_{t}^{(a, b)}$ weakly (for any given $a, b$ that are $S$ valued functions); i.e, for any $t>0$, marginally\n\n$$\n\\widetilde{Z}_{t}^{(1)}: \\stackrel{d}{=} a_{1} \\Phi_{t}^{(a)}+b_{1} I_{t}^{(a, b)}, \\quad \\widetilde{Z}_{t}^{(2)}: \\stackrel{d}{=} a_{2} \\Phi_{t}^{(a)}+b_{2}\\left|I_{t}^{(m a, b)}\\right|^{\\frac{1}{m}}\n$$\n\nfor some $m \\geq 0$, and any arbitrary real valued random variables $\\left(a_{1}, b_{1}\\right),\\left(a_{2}, b_{2}\\right)$ that are independent with $\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}\\right)$ and $\\left(\\Phi_{t}^{(a)}, I_{t}^{(m a, b)}\\right)$ respectively.\n\n(a) (1) Time asymptotic behaviors of both $\\log \\left|\\widetilde{Z}_{t}^{(1)}\\right|$ and $\\log \\left|I_{t}^{(a, b)}\\right|$ will be identical in distribution under the same scaling and shifts, in all possible cases of Theorem 2, Theorem 3 irrespective of any $\\left(a_{1}, b_{1}\\right)$.\n(2) For $\\log \\left|\\widetilde{Z}_{t}^{(2)}\\right|$ we will use identical scaling and shifts as used for $\\log \\left|\\widetilde{Z}_{t}^{(1)}\\right|$.\n(i) Under assumptions of Theorem 2(a) with $(a, b)$ replaced by $(m a, b)$ in Assumption 3(c), as $t \\rightarrow \\infty$, the quantity\n\n$$\n\\frac{\\log \\left|\\widetilde{Z}_{t}^{(2)}\\right|}{\\sqrt{t}}+\\sqrt{t} E_{\\pi} a(\\cdot) \\xrightarrow{d} \\mathcal{W}_{2(a)}\n$$\n\nirrespective of any $\\left(a_{2}, b_{2}\\right)$.\nUnder assumptions of Theorem 2(b) with $(a, b)$ replaced by $(m a, b)$ in (4.3) as $t \\rightarrow \\infty$, the quantity\n\n$$\n\\frac{\\log \\left|\\widetilde{Z}_{t}^{(2)}\\right|}{\\sqrt{t}} \\xrightarrow{d} \\mathcal{W}_{2(b)}\n$$\n\nirrespective of any $\\left(a_{2}, b_{2}\\right)$.\n(ii) Under assumptions of Theorem 3(a) with $(a, b)$ replaced by $(m a, b)$ in Assumption 4(c), as $t \\rightarrow \\infty$, the quantity\n\n$$\n\\frac{\\log \\left|\\widetilde{Z}_{t}^{(2)}\\right|+t E_{\\pi} a(\\cdot)}{t^{1 / \\alpha} L_{0}(t)} \\xrightarrow{d} \\mathcal{W}_{3(a)}\n$$\n\nirrespective of any $\\left(a_{2}, b_{2}\\right)$.\nUnder assumptions of Theorem 3(b) with $(a, b)$ replaced by $(m a, b)$ in (4.14) as $t \\rightarrow \\infty$, the quantity\n\n$$\n\\frac{\\log \\left|\\widetilde{Z}_{t}^{(2)}\\right|}{t^{1 / \\alpha} L_{0}(t)} \\xrightarrow{d} \\mathcal{W}_{3(b)}\n$$\n\nirrespective of any $\\left(a_{2}, b_{2}\\right)$.\n(b) Suppose assumptions of Theorem 4 holds.\n(i) If $a<0$, and $E \\log ^{+}\\left|\\int_{\\tau_{0}^{j}}^{\\tau_{j}^{j}} b\\left(Y_{s}\\right) e^{a\\left(s-\\tau_{0}^{j}\\right)} d s\\right|<\\infty$, as $t \\rightarrow \\infty$,\n\n$$\ne^{a t} \\widetilde{Z}_{t}^{(1)} \\xrightarrow{d} a_{1}+b_{1}\\left(\\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left[\\int_{0}^{\\tau_{0}^{j}} b\\left(Y_{s}\\right) e^{a s} d s+e^{a \\tau_{0}^{j}} V_{j}^{*}\\right]\\right)\n$$\n\nwhere $V_{j}^{*}$ is same as in Theorem 4(a).\nSuppose $a<0, \\& E \\log ^{+}\\left|\\int_{\\tau_{0}^{j}}^{\\tau_{j}^{j}} b\\left(Y_{s}\\right) e^{m a\\left(s-\\tau_{0}^{j}\\right)} d s\\right|<\\infty$ holds then as $t \\rightarrow \\infty$,\n\n$$\ne^{a t} \\widetilde{Z}_{t}^{(2)} \\xrightarrow{d} a_{2}+b_{2}\\left(\\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left|\\int_{0}^{\\tau_{0}^{j}} b\\left(Y_{s}\\right) e^{m a s} d s+e^{m a \\tau_{0}^{j}} V_{j, m}^{*}\\right| \\stackrel{\\Delta}{=}\\right)\n$$\n\nwhere $V_{j, m}^{*}$ is defined similar to $V_{j}^{*}$ in (2.13) with $(A, B)$ respectively defined as\n\n$$\n(A, B) \\stackrel{\\Delta}{\\rightarrow}\\left(e^{m a\\left(\\tau_{1}^{j}-\\tau_{0}^{j}\\right)} \\cdot \\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b\\left(Y_{s}\\right) e^{m a\\left(s-\\tau_{0}^{j}\\right)} d s\\right)\n$$\n\n(ii) If $a=0$ and conditions of Theorem 4(b) hold, then $\\frac{\\widetilde{Z}_{t}^{(1)}}{t} \\xrightarrow{d}\\left[E_{\\pi} b(\\cdot)\\right] b_{1} \\quad \\Leftrightarrow \\quad \\frac{\\widetilde{Z}_{t}^{(2)}}{t^{\\frac{d}{m}}} \\xrightarrow{d}\\left|E_{\\pi} b(\\cdot)\\right|^{\\frac{1}{m}} b_{2}$ as $t \\rightarrow \\infty$.\n\nRemark 4.6. (i) Results of Corollary 4.5 can be further extended in finding long-time limit results of any non-linear functions, such as polynomials of three quantities $\\Phi_{t}^{(a)},\\left|I_{t}^{(a, b)}\\right|,\\left|I_{t}^{(m a, b)}\\right|^{1 / m}$ of any order as $t \\rightarrow \\infty$ in the divergent cases (i.e under $E_{\\pi} a(\\cdot) \\leq 0$ ).\n\n(ii) The random coefficients $\\left(a_{1}, b_{1}, a_{2}, b_{2}\\right)$ in (4.16)) can be time-dependent (or stochastic) as well. All results of Corollary 4.5(a) will still identically hold if $\\left(a_{1}, b_{1}, a_{2}, b_{2}\\right)$ satisfies either\n\n$$\n\\frac{\\log \\max \\left\\{\\left|a_{1}\\right|+\\left|b_{1}\\right|,\\left|a_{2}\\right|+\\left|b_{2}\\right|\\right\\}}{\\sqrt{t}} \\xrightarrow{P} 0, \\quad \\text { as } \\quad t \\rightarrow \\infty\n$$\n\nin Corollary 4.5(a) part (i) under conditions of Theorem 2; or\n\n$$\n\\frac{\\log \\max \\left\\{\\left|a_{1}\\right|+\\left|b_{1}\\right|,\\left|a_{2}\\right|+\\left|b_{2}\\right|\\right\\}}{t^{1 / \\alpha} L_{0}(t)} \\xrightarrow{P} 0, \\quad \\text { as } \\quad t \\rightarrow \\infty\n$$\n\nin Corollary 4.5(a) part (ii) under conditions of Theorem 3. Corollary 4.5(b) also holds identically if $\\left(a_{1}, b_{1}, a_{2}, b_{2}\\right)$ represents the $t \\rightarrow \\infty$ weak limits of their time-dependent/stochastic versions of the respective quantities (given that their weak limits exist uniquely).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 8,
      "text": "# 5 Applications\n### 5.1 Pitchfork Bifurcation\n\nIn certain deterministic dynamical systems, a notable phenomenon called the 'phase transition' takes place in the steady state behavior, depending on a critical parameter as its value shifts from one regime to another. While shifting, the previously stable steady state of the system becomes unstable and gives way to the emergence of more locally stable steady states. In computational terms, this transition corresponds to what is known as Hopf bifurcation. It occurs when one of the \"linearized\" eigenvalues of the Jacobian matrix becomes purely imaginary. Importantly, the real part of this eigenvalue exhibits a disparity on either side of the bifurcation point, marking a critical change in the system's behavior.\n\nWe begin with the most common example in 2-dimension which is known as the Hopf-Andronov's model (Pg. 57, [44]). A general form of it can be expressed in the polar coordinate $\\left(\\rho_{t}, \\phi_{t}\\right)$ form as\n\n$$\n\\frac{d \\rho_{t}}{d t}=\\rho_{t}\\left(a-b \\rho_{t}^{2}\\right), \\quad \\frac{d \\phi_{t}}{d t}=1\n$$\n\nSolving above system for $b=1$ (for simplicity) yields a closed-form solution for $\\rho:=\\left(\\rho_{t}: t>0\\right)$.\n\n$$\n\\rho_{t}^{2}=\\left[\\frac{1}{a}+\\left[\\frac{1}{\\rho_{0}^{2}}-\\frac{1}{a}\\right] e^{-2 a t}\\right]^{-1} 1_{\\{a \\neq 0\\}}+\\left(t+\\frac{1}{\\rho_{0}^{2}}\\right)^{-1} 1_{\\{a=0\\}}, \\quad \\phi_{t}=\\phi_{0}+t\n$$\n\nThis leads to conclusions that\n\n- if $a \\leq 0$, then 0 is a globally stable steady state.\n- If $a>0$, then $\\rho^{2}=a$ is a stable steady state (globally stable respectively in $(0, \\infty)$ ) and 0 is an unstable steady state. For $a>0$, for initial value $\\rho_{0}^{2}$, any arbitrary path of $\\rho_{t}^{2}$ will exponentially converges to $a$.\n\nThis is an example of Pitchfork bifurcation [44] where $a=0$ is the bifurcation parameter value. For this problem, we give an exact structure of limit results when the bifurcation parameters are time-dependent and modulated by an $S$-valued semi-Markov process $Y$.\n\nConsider the model described in (1.2). Unlike the deterministic part in (5.1), we see that sign of $E_{\\pi} a(\\cdot)$ will determine the long time behaviour of the process $\\rho:=\\left(\\rho_{t}: t>0\\right)$ in (1.2). In [39] authors found a closed form of the stationary distribution of (1.2) under Markov-switching with $|S|=2$. Two states made the computation a lot easier, however, for $|S|>2$ their technique does not yield a closed-form solution. Below for more general $S$-valued semi-Markov process $Y$, we account for explicit long-time results for $\\rho^{2}$ in different cases determined by the sign of $E_{\\pi} a(\\cdot)$, and tail properties of the sojourn times of $Y$. These results will help construct the confidence intervals for $\\rho^{2}$ that can be time-dependent, and asymptotically exact (in time).\n\nTheorem 5. Consider the model in (1.2). Suppose Assumptions 1 holds for the underlying semi-Markovian environment $Y$ with the limiting distribution $\\pi$ and $U$ is a random variable such that $U \\sim \\pi$.\n(A) Suppose Assumption 2 holds with $(a, b)$ replaced by $(2 a, b)$. Weak limit of $\\left(\\rho_{t}^{2}, t \\geq 0\\right)$ will satisfy\n\n$$\n\\rho_{t}^{2} \\xrightarrow{d} \\rho_{\\infty}^{2}:=\\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\frac{1}{2 W_{j}^{(2 a, b)}} \\quad \\text { as } \\quad t \\rightarrow \\infty\n$$\n\nwhere $U \\perp\\left(W_{j}^{(2 a, b)}\\right)_{j \\in S}$, and $W_{j}^{(2 a, b)}$ is defined in (3.3) identically as $Z_{j}$ where $(a, b)$ is replaced by $(2 a, b)$.\n(B) Suppose Assumptions $1 \\varnothing 3$ hold with with $(a, b)$ replaced by $(2 a, b)$ and\n\n$$\n\\widetilde{\\sigma}_{j}^{2}:=4 \\operatorname{Var}\\left(\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s\\right)<\\infty\n$$\n\n(i) If $E_{\\pi} a(\\cdot)<0$, then as $t \\rightarrow \\infty$\n\n$$\n\\frac{-2 \\log \\left|\\rho_{t}\\right|+2 t E_{\\pi} a(\\cdot)}{\\sqrt{t}} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\frac{\\widetilde{\\sigma}_{j}}{\\sqrt{E\\left|\\mathcal{H}_{1}^{j}\\right|}} N\n$$\n\n(ii) Suppose $E_{\\pi} a(\\cdot)=0, b \\neq 0$ and Assumption 3(c) is replaced by\n\n$$\nE\\left[\\left(\\log \\left|\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{\\tau}^{\\tau_{1}^{j}} 2 a\\left(Y_{\\tau}\\right) d r} d s\\right|\\right)^{2}\\right]<\\infty\n$$\n\nthen as $t \\rightarrow \\infty$,\n\n$$\n\\frac{-2 \\log \\left|\\rho_{t}\\right|}{\\sqrt{t}} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\frac{\\widetilde{\\sigma}_{j}}{\\sqrt{E\\left|\\mathcal{H}_{1}^{j}\\right|}}|N|\n$$\n\n(C) Suppose Assumption 1 ( 4 hold for some $\\alpha \\in(1,2)$ and slowly varying function $L(\\cdot)$, and $\\left(\\widetilde{\\alpha}_{j}^{(+)}, \\widetilde{\\alpha}_{j}^{(-)}, \\beta_{j}, \\sigma_{(j, \\alpha)}\\right)$ are re-defined with $(a, b)$ replaced by $(2 a, b)$. Let $U \\sim \\pi$, and Stable- $\\alpha$ process $\\mathbf{S}_{\\alpha, \\beta_{j}}$ be all mutually independent for each $j \\in S$.\n(i) If $E_{\\pi} a(\\cdot)<0$, then as $t \\rightarrow \\infty$,\n\n$$\n\\frac{-2 \\log \\left|\\rho_{t}\\right|+2 t E_{\\pi} a(\\cdot)}{t^{\\frac{1}{n}} L_{0}(t)} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left(\\frac{1}{E\\left|\\mathcal{H}_{1}^{j}\\right|}\\right)^{\\frac{1}{n}} \\sigma_{(j, \\alpha)} \\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right)\n$$\n\n(ii) If $E_{\\pi} a(\\cdot)=0, b \\neq 0$ and Assumption 4(c) is replaced by\n\n$$\nE\\left[\\left(\\log \\left|\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{\\tau}^{\\tau_{1}^{j}} 2 a\\left(Y_{\\tau}\\right) d r} d s\\right|\\right)^{\\alpha+\\epsilon}\\right]<\\infty \\quad \\text { for some } \\epsilon>0\n$$\n\nThen for a slowly varying function $L_{0}(\\cdot)$ as $t \\rightarrow \\infty$,\n\n$$\n\\frac{-2 \\log \\left|\\rho_{t}\\right|}{t^{\\frac{1}{n}} L_{0}(t)} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left(\\frac{1}{E\\left|\\mathcal{H}_{1}^{j}\\right|}\\right)^{\\frac{1}{n}} \\sigma_{(j, \\alpha)} \\sup _{0 \\leq u \\leq 1} \\mathbf{S}_{\\alpha, \\beta_{j}}(u)\n$$\n\n(D) Suppose Assumption 1 holds and $a(\\cdot)=$ constant denoted by $a$, and $U \\sim \\pi$. As $t \\rightarrow \\infty$, if\n(i) $a<0$, and $E \\log ^{+}\\left|\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b\\left(Y_{s}\\right) e^{2 a\\left(s-\\tau_{0}^{j}\\right)} d s\\right|<\\infty$, then\n\n$$\ne^{2 a t} \\rho_{t}^{-2} \\xrightarrow{d} \\rho_{0}^{-2}+2\\left(\\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left[\\int_{0}^{\\tau_{0}^{j}} b\\left(Y_{s}\\right) e^{2 a s} d s+e^{2 a \\tau_{0}^{j}} V_{j}^{*}\\right]\\right)\n$$\n\nwhere $V_{j}^{*}$ satisfies (2.13) with\n\n$$\n(A, B) \\stackrel{d}{=}\\left(e^{2 a\\left(\\tau_{1}^{j}-\\tau_{0}^{j}\\right)} \\cdot \\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b\\left(Y_{s}\\right) e^{2 a\\left(s-\\tau_{0}^{j}\\right)} d s\\right)\n$$\n\n(ii) $a=0, \\& \\quad E_{\\pi}|b|<\\infty$. Then as $t \\rightarrow \\infty$,\n\n$$\n\\frac{\\rho_{t}^{-2}}{t} \\xrightarrow{d} E_{\\pi} b(\\cdot)\n$$\n\nRemark 5.1. The Goldie-Kesten theorem (Theorem 2.4.4 in Buraczewski et al. [17]) characterizes the heavy-tailed behavior of the solution to the fixed-point equation (2.13). If $A \\geq 0$ a.s. and $\\mathcal{L}(\\log A \\mid A \\geq 0)$ is non-arithmetic, $P[A x+B=x]<1$ for all $x \\in \\mathbb{R}$, and there exists $\\alpha_{1}>0$ such that\n\n$$\nE A^{\\alpha_{1}}=1, \\quad E|B|^{\\alpha_{1}}<\\infty, \\quad E A^{\\alpha_{1}} \\log^{+} A<\\infty\n$$\n\nthen there exist constants $c_{+}, c_{-} \\geq 0$ with $c_{+}+c_{-}>0$ such that as $x \\rightarrow \\infty$\n\n$$\nP[X>x] \\sim c_{+} x^{-\\alpha_{1}}, \\quad P[X<-x] \\sim c_{-} x^{-\\alpha_{1}}\n$$\n\nUnder $E_{\\pi} a(\\cdot)>0$ (the stable regime), irrespective of $\\rho_{0}$, the trajectory $\\left(\\rho_{t}^{2}: t \\geq 0\\right)$ will converge to the weak limit (5.2). Under this case, it can be shown that $P\\left[\\sup _{t \\geq 0} \\rho_{t}^{-2}<\\infty\\right]=1$ and hence $P\\left[\\inf \\left|\\rho_{t}\\right|>0\\right]=1$. The aversion from 0 in the weak limit of $\\rho_{t}^{2}$ can be shown quantitatively, as a consequence of the GoldieKesten theorem result. Under Assumption 1 \\& Assumption 2, if $\\inf _{j \\in S} a(j)<0$ holds, then there exists $\\nu^{*}>0$, such that\n\n$$\n\\nu^{*}:=\\inf _{j \\in S} \\alpha_{j}>0, \\quad \\text { where } \\alpha_{j}:=\\sup \\left\\{\\alpha>0: E e^{-\\alpha \\int_{c_{0}^{2}}^{c_{1}^{2}} 2 a\\left(Y_{s}\\right) d s}=1\\right\\}\n$$\n\nUnder regularity conditions of Goldie-Kesten theorem following holds,\n\n$$\n\\lim _{x \\rightarrow \\infty} x^{\\nu^{*}} P\\left[\\rho_{\\infty}^{2}<\\frac{1}{x}\\right]=\\lim _{x \\rightarrow \\infty} \\sum_{j \\in S} \\pi_{j}\\left[x^{\\nu^{*}} P\\left[W_{j}^{(2 a, b)}>\\frac{x}{2}\\right]\\right] \\rightarrow c\n$$\n\nfor some explicit constant $c$. This implies that if there exists at least one regime $x_{*} \\in S$ where $a\\left(x_{*}\\right)<0$ then $P\\left[\\rho_{\\infty}^{2} \\leq \\epsilon\\right]$ will scale as $c \\epsilon^{\\nu^{*}}$ as $\\epsilon \\rightarrow 0^{+}$, which is quite surprising.\n\nIn epidemic model contexts, results on the deterministic SIS model under Markov switching are derived in Proposition 5.2 of [46]. When the infection and the susceptibility rates are modulated by a semimarkovian $Y$, similar results can be established in line with Theorem 5. Also in a jump-type process context under Markovian regime-switching, multivariate version of the fixed-point equation (2.13) appears that is explored in [19] with applications in stochastic mono-molecular biochemical reaction networks. Similar semi-Markovian extension can be established there as well.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 9,
      "text": "# 5.2 Applications to regime-switching generalized O.U process \n\nThis framework can be used to establish long-term behaviors of a class of diffusions beyond just the Ornstein-Uhlenback type. Let $a(\\cdot), b(\\cdot): S \\rightarrow \\mathbb{R}$ be two arbitrary $S$-valued functions. Consider the following descriptions of two semi-Markov modulated stochastic processes $X_{1}:=\\left(X_{1, t}: t \\geq 0\\right), X_{2}:=$ $\\left(X_{2, t}: t \\geq 0\\right)$ satisfying stochastic differential equations (SDE) that do not immediately look like the Ornstein-Uhlenbeck processes:\n\n$$\n\\begin{aligned}\nd X_{1, t} & =\\left(X_{1, t}^{2}+1\\right)\\left[-a\\left(Y_{t}\\right) \\tan ^{-1}\\left(X_{1, t}\\right)+b^{2}\\left(Y_{t}\\right) X_{1, t}\\right] d t+b\\left(Y_{t}\\right)\\left(X_{1, t}^{2}+1\\right) d W_{t} \\\\\nd X_{2, t} & =-\\left[a\\left(Y_{t}\\right)+\\frac{b^{2}\\left(Y_{t}\\right)}{2} e^{-2 X_{2, t}}\\right] d t+b\\left(Y_{t}\\right) e^{-X_{2, t}} d W_{t}\n\\end{aligned}\n$$\n\nWe generalize above examples in the following manner. Given any continuous and differentiable function $\\beta(\\cdot): \\mathbb{R} \\rightarrow \\mathbb{R}_{\\geq 0}$, that does not vanish in $\\mathbb{R}$, the function $h$ is defined as\n\n$$\nh(x):=\\int_{c}^{x} \\frac{1}{\\beta(y)} d y\n$$\n\nfor some constant $c$. The general structure $X:=\\left(X_{t}: t \\geq 0\\right)$ with initial condition $X_{0}=x_{0}$ can be illustrated as the solution of the following SDE\n\n$$\nd X_{t}=\\left[-a\\left(Y_{t}\\right) h\\left(X_{t}\\right) \\beta\\left(X_{t}\\right)+\\frac{b^{2}\\left(Y_{t}\\right)}{2} \\beta\\left(X_{t}\\right) \\beta^{\\prime}\\left(X_{t}\\right)\\right] d t+b\\left(Y_{t}\\right) \\beta\\left(X_{t}\\right) d W_{t}\n$$\n\nthat is modulated by an $S$-valued semi-Markovian environment $Y$. Clearly $h$ is a monotone-increasing function, so the inverse exists. One can see that $X_{1}, X_{2}$ are special cases of (5.9) when $(\\beta(x), c)$ is $\\left(x^{2}+1,0\\right)$ and $\\left(e^{-x},-\\infty\\right)$ respectively $\\forall x \\geq 0$. Observe that the simple Ornstein-Uhlenbeck process is a trivial case when $(h(x), \\beta(x), c)$ is $(x, 1,0) \\quad \\forall x \\geq 0$. Following result displays the explicit long-time behavior of $X$ (in (5.9)) given the semi-Markov process $Y$ :\n\nTheorem 6. Suppose Assumptions 1 holds for underlying semi-Markovian environment $Y$ with the limiting distribution $\\pi$ and $U$ is a random variable such that $U \\sim \\pi$. For any $h, \\beta, c$ the long time vehaviour of the weak solution of $X:=\\left(X_{t}: t \\geq 0\\right)$ defined in (5.9) will depend on different signs of $E_{\\pi} a(\\cdot)$ and some integrability conditions involving with $b(\\cdot)$, and they are following:\n(A) Suppose Assumptions 1 and 2 hold with $(a, b)$ replaced by $\\left(2 a, b^{2}\\right)$. Weak limit of $\\left(X_{t}, Y_{t}\\right)$ will satisfy\n\n$$\n\\left(X_{t}, Y_{t}\\right) \\xrightarrow{d}\\left(\\sum_{j \\in S} \\delta_{U}(\\{j\\}) h^{-1}\\left(\\sqrt{Z_{j}} N\\right), U\\right) \\quad \\text { as } t \\rightarrow \\infty\n$$\n\nwhere $U \\perp\\left(Z_{j}\\right)_{j \\in S}, U \\sim \\pi$, and $Z_{j}$ is defined in (3.3) with $(a, b)$ replaced by $\\left(2 a, b^{2}\\right)$, and $N \\sim N(0,1)$ is independent of everything.\n(B) Suppose Assumptions 1 \\& 3 hold with $(a, b)$ replaced by $\\left(2 a, b^{2}\\right)$ in Assumption 3(c). Let $U \\sim \\pi$, and $N$ be a standard normal random variable that are mutually independent with each other.\n(i) If $E_{\\pi} a(\\cdot)<0$, then as $t \\rightarrow \\infty$\n\n$$\n\\frac{\\log \\left|h\\left(X_{t}\\right)\\right|+t E_{\\pi} a(\\cdot)}{\\sqrt{t}} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\frac{\\sigma_{j}}{\\sqrt{E\\left|\\mathfrak{I}_{1}^{j}\\right|}} N\n$$\n\n(ii) Suppose $E_{\\pi} a(\\cdot)=0, b \\neq 0$ and Assumption 3(c) is replaced by\n\n$$\nE\\left[\\left(\\log \\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b^{2}\\left(Y_{s}\\right) e^{-\\int_{s}^{\\tau_{1}^{j}} 2 a\\left(Y_{r}\\right) d r} d s\\right)^{2}\\right]<\\infty\n$$\n\nthen as $t \\rightarrow \\infty$,\n\n$$\n\\frac{\\log \\left|h\\left(X_{t}\\right)\\right|}{\\sqrt{t}} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\frac{\\sigma_{j}}{\\sqrt{E\\left|\\mathfrak{I}_{1}^{j}\\right|}}|N|\n$$\n\n(C) Suppose Assumptions 1 \\& 4 hold for some $\\alpha \\in(1,2)$ and slowly varying function $L(\\cdot)$, with $(a, b)$ replaced by $\\left(2 a, b^{2}\\right)$ in Assumption 4(c). Let $U \\sim \\pi$, and Stable- $\\alpha$ process $\\mathbf{S}_{\\alpha, \\beta_{j}}$ be all mutually independent for each $j \\in S$. As $t \\rightarrow \\infty$,\n(i) if $E_{\\pi} a(\\cdot)<0$,\n\n$$\n\\frac{\\log \\left|h\\left(X_{t}\\right)\\right|+t E_{\\pi} a(\\cdot)}{t^{\\frac{1}{\\alpha}} L_{0}(t)} \\quad \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left(\\frac{1}{E\\left|\\mathfrak{I}_{1}^{j}\\right|}\\right)^{\\frac{1}{\\alpha}} \\sigma_{(j, \\alpha)} \\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right)\n$$\n\n(ii) if $E_{\\pi} a(\\cdot)=0, b \\neq 0$ and Assumption 4(c) is replaced by\n\n$$\nE\\left[\\left(\\log \\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b^{2}\\left(Y_{s}\\right) e^{-\\int_{s}^{\\tau_{1}^{j}} 2 a\\left(Y_{r}\\right) d r} d s\\right)^{\\alpha+\\epsilon}\\right]<\\infty \\quad \\text { for some } \\epsilon>0\n$$\n\nThen for a slowly varying function $L_{0}(\\cdot)$ as $t \\rightarrow \\infty$,\n\n$$\n\\frac{\\log \\left|h\\left(X_{t}\\right)\\right|}{t^{\\frac{1}{\\alpha}} L_{0}(t)} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left(\\frac{1}{E\\left|\\mathfrak{I}_{1}^{j}\\right|}\\right)^{\\frac{1}{\\alpha}} \\sigma_{(j, \\alpha)} \\sup _{0 \\leq u \\leq 1} \\mathbf{S}_{\\alpha, \\beta_{j}}(u)\n$$\n\n(D) Suppose Assumption 1 holds and $a(\\cdot)=a$ constant denoted by $a . U \\sim \\pi$, and $N \\sim N(0,1)$ are independent. As $t \\rightarrow \\infty$, if\n(i) $a<0$ and $E \\log ^{+}\\left[\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b^{2}\\left(Y_{s}\\right) e^{2 a\\left(s-\\tau_{0}^{j}\\right)} d s\\right]<\\infty$, then\n\n$$\ne^{a t} h\\left(X_{t}\\right) \\xrightarrow{d} h\\left(X_{0}\\right)+\\left(\\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\sqrt{\\int_{0}^{\\tau_{0}^{j}} b^{2}\\left(Y_{s}\\right) e^{2 a s} d s+e^{2 a \\tau_{0}^{j}} V_{j}^{*}}\\right) N\n$$\n\nwhere $V_{j}^{*}$ satisfies (2.13) with\n\n$$\n(A, B) \\stackrel{d}{=}\\left(e^{2 a\\left(\\tau_{1}^{j}-\\tau_{0}^{j}\\right)} \\cdot \\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b^{2}\\left(Y_{s}\\right) e^{2 a\\left(s-\\tau_{0}^{j}\\right)} d s\\right)\n$$\n\n(ii) $a=0, \\& \\quad E_{\\pi} b^{2}(\\cdot)<\\infty$, then $\\quad \\frac{h\\left(X_{t}\\right)}{\\sqrt{t}} \\xrightarrow{d} \\sqrt{E_{\\pi} b^{2}(\\cdot)} N$.\n\nWe will see a little variations in the distributional weak limits in parts (A),(D) if we have a symmetric $\\alpha$-stable noise process; but parts (B),(C) remain the same (except the integrability assumptions).\n\nCorollary 5.2. We consider a case where $(h(x), \\beta(x), c)$ is $(x, 1,0) \\quad \\forall x \\geq 0$, in (5.9), but the noise process is a symmetric stable- $\\alpha^{*}$ process $\\mathbf{S}_{\\alpha^{*}, 0}$ instead of a Wiener process for some $1<\\alpha^{*}<2$. Hence the process $X$ satisfies\n\n$$\nd X_{t}=-a\\left(Y_{t}\\right) X_{t} d t+b\\left(Y_{t}\\right) d \\mathbf{S}_{\\alpha^{*}, 0}(t)\n$$\n\n(A) Suppose Assumptions 1 and 2 hold with $(a, b)$ replaced by $\\left(\\alpha^{*} a, b^{* *}\\right)$. Weak limit of $\\left(X_{t}, Y_{t}\\right)$ will satisfy\n\n$$\n\\left(X_{t}, Y_{t}\\right) \\xrightarrow{d}\\left(\\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\mid Z_{j}^{*}\\right|^{1 / \\alpha^{*}} \\mathcal{S}_{\\alpha^{*}}(1,0,0), U \\quad \\text { as } t \\rightarrow \\infty\n$$\n\nwhere $U \\Perp\\left(Z_{j}^{*}\\right)_{j \\in S}, U \\sim \\pi$, and $Z_{j}^{*}$ is defined in (3.3) with $(a, b)$ replaced by $\\left(\\alpha^{*} a, b^{* *}\\right)$, and $\\mathcal{S}_{\\alpha^{*}}(1,0,0)$ is a symmetric- $\\alpha^{*}$ stable random variable with scale $=1$ and it is independent of everything.\n(B) Suppose Assumptions 1 \\& 3 hold with $(a, b)$ replaced by $\\left(\\alpha^{*} a, b^{* *}\\right)$ in Assumption 3(c). Let $U \\sim \\pi$, and $N$ be a standard normal random variable that are mutually independent with each other.\n(i) If $E_{\\pi} a(\\cdot)<0$, then as $t \\rightarrow \\infty$\n\n$$\n\\frac{\\log \\left|X_{t}\\right|+t E_{\\pi} a(\\cdot)}{\\sqrt{t}} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\frac{\\sigma_{j}}{\\sqrt{E\\left|\\mathcal{H}_{1}^{j}\\right|}} N\n$$\n\n(ii) Suppose $E_{\\pi} a(\\cdot)=0, b \\neq 0$ and Assumption 3(c) is replaced by\n\n$$\nE\\left[\\left(\\log \\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} b^{* *}\\left(Y_{s}\\right) e^{-\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} \\alpha^{*} a\\left(Y_{\\tau}\\right) d \\tau} d s\\right)^{2}\\right]<\\infty\n$$\n\nthen as $t \\rightarrow \\infty$,\n\n$$\n\\frac{\\log \\left|X_{t}\\right|}{\\sqrt{t}} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\frac{\\sigma_{j}}{\\sqrt{E\\left|\\mathcal{H}_{1}^{j}\\right|}}|N|\n$$\n\n(C) Suppose Assumptions 1 \\& 4 hold for some $\\alpha \\in(1,2)$ and slowly varying function $L(\\cdot)$, with $(a, b)$ replaced by $\\left(\\alpha^{*} a, b^{* *}\\right)$ in Assumption 4(c). Let $U \\sim \\pi$, and Stable- $\\alpha$ process $\\mathbf{S}_{\\alpha, \\beta_{j}}$ be all mutually independent for each $j \\in S$. As $t \\rightarrow \\infty$,\n\n(i) if $E_{\\pi} a(\\cdot)<0$\n\n$$\n\\frac{\\log \\left|X_{t}\\right|+t E_{\\pi} a(\\cdot)}{t^{\\frac{1}{n}} L_{0}(t)} \\quad \\xrightarrow{d} \\quad \\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left(\\frac{1}{E\\left|\\mathfrak{I}_{1}^{j}\\right|}\\right)^{\\frac{1}{n}} \\sigma_{(j, \\alpha)} \\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right)\n$$\n\n(ii) if $E_{\\pi} a(\\cdot)=0, b \\neq 0$ and Assumption 4(c) is replaced by\n\n$$\nE\\left[\\left(\\log \\int_{\\tau_{0}^{j}}^{\\tau_{t}^{j}} b^{\\alpha^{*}}\\left(Y_{s}\\right) e^{-\\int_{s}^{\\tau_{t}^{j}} \\alpha^{*} a\\left(Y_{v}\\right) d r} d s\\right)^{\\alpha+\\epsilon}\\right]<\\infty \\quad \\text { for some } \\epsilon>0\n$$\n\nThen for a slowly varying function $L_{0}(\\cdot)$ as $t \\rightarrow \\infty$,\n\n$$\n\\frac{\\log \\left|X_{t}\\right|}{t^{\\frac{1}{n}} L_{0}(t)} \\xrightarrow{d} \\sum_{j \\in S} \\delta_{U}(\\{j\\})\\left(\\frac{1}{E\\left|\\mathfrak{I}_{1}^{j}\\right|}\\right)^{\\frac{1}{n}} \\sigma_{(j, \\alpha)} \\sup _{0 \\leq u \\leq 1} \\mathbf{S}_{\\alpha, \\beta_{j}}(u)\n$$\n\n(D) Suppose Assumption 1 holds and $a(\\cdot)=a$ (constant). Let $U \\sim \\pi$, and $\\mathcal{S}_{\\alpha^{*}}(1,0,0)$ be a symmetric- $\\alpha$ stable random variable with scale $=1$, and they are independent. As $t \\rightarrow \\infty$, if\n(i) $a<0$ and $E \\log ^{+}\\left[\\int_{\\tau_{0}^{j}}^{\\tau_{t}^{j}} b^{\\alpha^{*}}\\left(Y_{s}\\right) e^{\\alpha^{*} a\\left(s-\\tau_{0}^{j}\\right)} d s\\right]<\\infty$, then\n\n$$\ne^{\\alpha t} X_{t} \\xrightarrow{d} X_{0}+\\left(\\sum_{j \\in S} \\delta_{U}(\\{j\\})\\right| \\int_{0}^{\\tau_{0}^{j}} b^{\\alpha^{*}}\\left(Y_{s}\\right) e^{\\alpha^{*} a s} d s+e^{\\alpha^{*} a \\tau_{0}^{j}}\\left.V_{j, \\alpha^{*}}^{*}\\right|^{\\frac{1}{\\alpha^{*}}}\n$$\n\nwhere $V_{j, \\alpha^{*}}^{*}$ satisfies (2.13) with\n\n$$\n(A, B) \\stackrel{d}{=}\\left(e^{\\alpha^{*} a\\left(\\tau_{1}^{j}-\\tau_{0}^{j}\\right)}, \\int_{\\tau_{0}^{j}}^{\\tau_{t}^{j}} b^{\\alpha^{*}}\\left(Y_{s}\\right) e^{\\alpha^{*} a\\left(s-\\tau_{0}^{j}\\right)} d s\\right)\n$$\n\n(ii) $a=0, \\& \\quad E_{\\pi} b^{\\alpha^{*}}(\\cdot)<\\infty$, then $\\quad \\frac{X_{t}}{t^{\\frac{1}{n}}} \\xrightarrow{d}\\left|E_{\\pi} b^{\\alpha^{*}}(\\cdot)\\right|^{\\frac{1}{\\alpha^{*}}} \\mathcal{S}_{\\alpha^{*}}(1,0,0)$.\n\nRemark 5.3. (i) Both Theorem 5.9 and Corollary 5.2 show that weak limits depend on the noise process only in the stable domain (i.e., when $E_{\\pi} a(\\cdot)>0$ ) and in the divergence domain when $\\sigma_{j}^{2}=0$ for all $j \\in S$. However, in other divergent cases (B) $\\mathscr{E}(C)$ (where $\\sigma_{j}^{2}$ is finite or infinite for all $j \\in S$ ) the weak limits do not depend on the volatility term $b(\\cdot)$. Consequently, the limit results in cases (B) and (C) are universal and remain unchanged regardless of choice of noise processes, provided the relevant integrability conditions (Assumptions 3(c), 4(c), or conditions (5.19), (5.22), with exponent 2 replaced by $\\alpha^{*}$ in all stable $\\alpha^{*}$ cases) hold. This phenomenon arising from the logarithmic transformation and associated scaling used in the divergent cases is quite surprising.\n(ii) The stable case of Corollary 5.2(A) provides an explicit form of the limiting measure, clearly showing how its heavy tail structure arises from the stable distribution of noise process and the stochastic environments through the mixing measure. This explicit form can be used for parametric statistical inference to estimate $\\alpha^{*}$ when partial information about the latent dynamics is available.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 10,
      "text": "# 6 An important Lemma \n\nBy notation $\\mathcal{F}_{\\tau_{0}^{j}}^{Y}$, define the sigma field generated by the class of sets $\\left\\{A: A \\cap\\left\\{g_{t}^{j}=n\\right\\} \\in \\mathcal{F}_{\\tau_{0}^{j}}^{Y}\\right\\}$. Crucial elements of main proofs rely on the following lemma on asymptotic conditional independence of $t-\\tau_{g_{t}^{j}}^{j}$ and a $\\left\\{\\mathcal{F}_{\\tau_{0}^{j}}^{Y}\\right\\}_{t \\geq 0}$ measurable $\\mathbb{R}^{d}$ valued process $\\left(H_{t}: t \\geq 0\\right)$ conditioned on $\\left\\{Y_{t}=j\\right\\}$. We present Lemma 6.1 separately, It is useful in eliminating $Y_{t}=j$ in the $t \\rightarrow \\infty$ limit from the conditioning part of a probability, particularly when the main event is regarding some functional of $Y$, that exhibits a marginal weak limit with some properties (see (6.1)). By $\\mathbf{0}_{d}, I_{d}$ we respectively denote a $d$-dimensional vector of zeros and a diagonal matrix of order $d$.\n\nLemma 6.1. Fix $j \\in S$. Suppose $\\left(H_{t}: t \\geq 0\\right)$ is a $\\left\\{\\mathcal{F}_{r_{j}^{\\prime}}^{Y}\\right\\}_{t \\geq 0}$ measurable $\\mathbb{R}^{d}$ valued process such that there exists a random variable $H_{\\infty}$, and an increasing deterministic function $\\epsilon(\\cdot): \\mathbb{R}_{\\geq 0} \\rightarrow \\mathbb{R}_{\\geq 0}$ such that as $t \\rightarrow \\infty$\n\n$$\nH_{t} \\xrightarrow{d} H_{\\infty}, \\quad \\frac{\\epsilon(t)}{t} \\rightarrow 0, \\quad \\epsilon(t) \\rightarrow \\infty, \\text { as } t \\rightarrow \\infty, \\quad \\text { and } \\quad H_{t}-H_{t-\\epsilon(t)} \\xrightarrow{P} \\mathbf{0}_{d}\n$$\n\nand $Y$ is a semi-Markov process with Assumption 1. Suppose further that $\\left(L_{t}^{(1)}, L_{t}^{(2)}\\right)_{t \\geq 0}$ are arbitrary $d$-dimensional vector and matrix valued processes satisfying $\\left(L_{t}^{(1)}, L_{t}^{(2)}\\right) \\xrightarrow{P}\\left(\\mathbf{0}_{d}, I_{d}\\right)$ as $t \\rightarrow \\infty$. Then, $L_{t}^{(1)}+L_{t}^{(2)} H_{t}$ and $\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)$ are asymptotically independent conditioned on $\\left\\{Y_{t}=j\\right\\}$; i.e, for any $A \\in \\mathcal{B}\\left(\\mathbb{R}^{d}\\right)$ such that $P\\left[H_{\\infty} \\in \\partial A\\right]=0$,\n\n$$\n\\lim _{t \\rightarrow \\infty} P\\left[L_{t}^{(1)}+L_{t}^{(2)} H_{t} \\in A, t-\\tau_{g_{t}^{j}}^{j}>x \\mid Y_{t}=j\\right]=P\\left[H_{\\infty} \\in A\\right] \\frac{\\sum_{k \\in S} P_{j k} \\int_{s}^{\\infty}\\left(1-F_{j k}(y)\\right) d y}{m_{j}}\n$$\n\nfor any $x \\in \\mathbb{R}_{\\geq 0}$.\nRemark 6.1. Both the process $\\left(H_{t}: t \\geq 0\\right)$ and the random variable $H_{\\infty}$ depend on $j \\in S$, but for notational simplicity the subscript $j$ is omitted.\n\nProof. Since under necessary assumptions $\\lim _{t \\rightarrow \\infty} P\\left[Y_{t}=j\\right]=\\pi_{j}=\\frac{\\mu_{j} m_{j}}{\\sum_{k \\in S} \\mu_{k} m_{k}}$, the main assertion will follow if we prove that, for any $A \\in \\mathcal{B}\\left(\\mathbb{R}^{d}\\right)$ with $P\\left[H_{\\infty} \\in \\partial A\\right]=0$, as $t \\rightarrow \\infty$,\n\n$$\nP\\left[H_{t} \\in A, t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right] \\rightarrow P\\left[H_{\\infty} \\in A\\right] \\frac{\\mu_{j} \\sum_{k \\in S} P_{j k} \\int_{s}^{\\infty}\\left(1-F_{j k}(y)\\right) d y}{\\sum_{k \\in S} \\mu_{k} m_{k}}\n$$\n\nthen, by Slutsky's theorem, the assertion will hold as\n\n$$\n\\lim _{t \\rightarrow \\infty} P\\left[L_{t}^{(1)}+L_{t}^{(2)} H_{t} \\in A, t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right]=\\lim _{t \\rightarrow \\infty} P\\left[H_{t} \\in A, t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right]\n$$\n\nWe prove (6.2) in following steps sequentially.\n\n- Step 1: $\\lim _{t \\rightarrow \\infty} P_{i}\\left[t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right]=\\frac{\\mu_{j} \\sum_{k \\in S} P_{j k} \\int_{s}^{\\infty}\\left(1-F_{j k}(y)\\right) d y}{\\sum_{k \\in S} \\mu_{k} m_{k}}$.\n- Step 2: $\\lim _{t \\rightarrow \\infty} P\\left[H_{t-\\epsilon(t)} \\in A \\mid t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right]=P\\left[H_{\\infty} \\in A\\right]$.\n- Step 3: $\\lim _{t \\rightarrow \\infty} P\\left[H_{t} \\in A \\mid t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right]=\\lim _{t \\rightarrow \\infty} P\\left[H_{t-\\epsilon(t)} \\in A \\mid t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right]$ for any $A$ such that $P\\left[H_{\\infty} \\in \\partial A\\right]=0$.\n\nStep 1 follows by similar arguments used in proving asymptotic time limit of forward residual time $\\lim _{t \\rightarrow \\infty} P\\left[\\tau_{g_{t}^{j}+1}^{j}-t>x, Y_{t}=j\\right]$ at display (8.5) in [20]. For completeness we give a proof in the appendix as Lemma 12.1.\n\nStep 2: Denote the event $\\left\\{Y_{t}=j, t-\\tau_{g_{t}^{j}}^{j}>x\\right\\}$ by $\\widetilde{C}_{t, x}^{(j)}$. Observe that for any set $A \\in \\mathcal{B}\\left(\\mathbb{R}^{d}\\right)$,\n\n$$\n\\begin{aligned}\nP\\left[H_{t-\\epsilon(t)} \\in A \\mid \\widetilde{C}_{t, x}^{(j)}\\right]=\\sum_{j^{\\prime} \\in S} & P\\left[H_{t-\\epsilon(t)} \\in A \\mid Y_{t-\\epsilon(t)}=j^{\\prime}, \\widetilde{C}_{t, x}^{(j)}\\right] P\\left[Y_{t-\\epsilon(t)}=j^{\\prime} \\mid \\widetilde{C}_{t, x}^{(j)}\\right] \\\\\n= & \\sum_{j^{\\prime} \\in S} \\frac{P\\left[\\widetilde{C}_{t, x}^{(j)} \\mid Y_{t-\\epsilon(t)}=j^{\\prime}, H_{t-\\epsilon(t)} \\in A\\right]}{P\\left[\\widetilde{C}_{t, x}^{(j)}\\right]} P\\left[H_{t-\\epsilon(t)} \\in A, Y_{t-\\epsilon(t)}=j^{\\prime}\\right] \\\\\n= & P\\left[H_{t-\\epsilon(t)} \\in A\\right]+\\sum_{j^{\\prime} \\in S} P\\left[H_{t-\\epsilon(t)} \\in A, Y_{t-\\epsilon(t)}=j^{\\prime}\\right] \\\\\n& \\quad \\times\\left(\\frac{P\\left[\\widetilde{C}_{t, x}^{(j)} \\mid H_{t-\\epsilon(t)} \\in A, Y_{t-\\epsilon(t)}=j^{\\prime}\\right]}{P\\left[\\widetilde{C}_{t, x}^{(j)}\\right]}-1\\right)\n\\end{aligned}\n$$\n\nDenote the second term in RHS of (6.3) by $\\mathcal{D}_{t}$ and the quantity in first bracket by\n\n$$\nM_{t}:=\\frac{P\\left[t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j \\mid H_{t-\\epsilon(t)} \\in A, Y_{t-\\epsilon(t)}=j^{\\prime}\\right]}{P\\left[t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right]}\n$$\n\nIn order to show $\\mathcal{D}_{t} \\rightarrow 0$, we first prove that $\\lim _{t \\rightarrow \\infty} M_{t} \\rightarrow 1$.\nDenote the set $\\left\\{\\tau_{g_{t-\\epsilon(t)}^{j}+2}^{j} \\leq \\tau_{g_{t}^{j}}^{j}\\right\\}$ by $K_{t}$. Observe that\n\n$$\nK_{t}=\\left\\{B_{j}(t-\\epsilon(t))+\\left(\\tau_{g_{t-\\epsilon(t)}^{j}+2}^{j}-\\tau_{g_{t-\\epsilon(t)}^{j}+1}^{j}\\right)+A_{j}(t) \\leq \\epsilon(t)\\right\\}\n$$\n\nClearly $P\\left[K_{t}\\right] \\rightarrow 1$, as $t \\rightarrow \\infty$ (since all quantities $B_{j}(t-\\epsilon(t)), \\tau_{g_{t-\\epsilon(t)}^{j}+2}^{j}-\\tau_{g_{t-\\epsilon(t)}^{j}+1}^{j}$ and $A_{j}(t)$ are $O_{\\rho}$ (1) (using (2.10) and Proposition 2.2(i)) and $t-\\epsilon(t) \\rightarrow \\infty, \\epsilon(t) \\rightarrow \\infty$ as $t \\rightarrow \\infty$ ).\n\nDefine $\\widetilde{a}_{t}, \\widetilde{b}_{t}$ as\n\n$$\n\\begin{aligned}\n& \\widetilde{a}_{t}:=P\\left[K_{t} \\mid Y_{t-\\epsilon(t)}=j^{\\prime}, H_{t-\\epsilon(t)} \\in A\\right] \\\\\n& \\widetilde{b}_{t}:=P\\left[K_{t}^{c},\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)>x, Y_{t}=j \\mid H_{t-\\epsilon(t)} \\in A, Y_{t-\\epsilon(t)}=j^{\\prime}\\right]\n\\end{aligned}\n$$\n\nand it is easy to see that as $t \\rightarrow \\infty$,\n\n$$\n\\left(\\widetilde{a}_{t}, \\widetilde{b}_{t}\\right) \\rightarrow(1,0)\n$$\n\nObserve that the numerator of $M_{t}$\n\n$$\n\\begin{aligned}\n& P\\left[t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j \\mid H_{t-\\epsilon(t)} \\in A, Y_{t-\\epsilon(t)}=j^{\\prime}\\right] \\\\\n& \\quad=\\widetilde{a}_{t} P\\left[t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j \\mid K_{t}, H_{t-\\epsilon(t)} \\in A, Y_{t-\\epsilon(t)}=j^{\\prime}\\right]+\\widetilde{b}_{t} \\\\\n& \\quad \\stackrel{(a)}{=} \\quad \\widetilde{a}_{t} P\\left[t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j \\mid K_{t}\\right]+\\widetilde{b}_{t}\n\\end{aligned}\n$$\n\nwhere equality in (a) follows by observing that conditioned on $K_{t},\\left\\{Y_{t-\\epsilon(t)}=j^{\\prime}\\right\\}$ the event $\\left\\{t-\\tau_{g_{t}^{j}}^{j}>\\right.$ $\\left.x, Y_{t}=j\\right\\}$ is $\\sigma\\left\\{\\mathcal{H}_{i}: i \\geq g_{t-\\epsilon(t)}^{j}+2\\right\\}$ measurable where $H_{t-\\epsilon(t)}$ is $\\sigma\\left\\{\\mathcal{H}_{i}: i \\leq g_{t-\\epsilon(t)}^{j}\\right\\}$ measurable so using Proposition 2.2(iii) one can remove $\\left\\{H_{t \\rightarrow(t)} \\in A\\right\\}$ from the conditioning event. Furthermore, $\\left\\{Y_{t \\rightarrow(t)}=j^{\\prime}\\right\\}$ can be removed from the conditional part as well, since it is $\\mathcal{F}_{g_{t-\\epsilon(t)}^{j}}^{j+1}$ measurable which is independent of $\\sigma\\left\\{\\mathcal{H}_{i}: i \\geq g_{t-\\epsilon(t)}^{j}+2\\right\\}$ under which $\\left\\{t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right\\}$ is measurable conditioned on $K_{t}$.\n\nSince $\\left(\\widetilde{a}_{t}, \\widetilde{b}_{t}\\right) \\rightarrow(1,0)$, both the numerator and denominator of $M_{t}$ will have identical time limit, it follows that $\\lim _{t \\rightarrow \\infty} M_{t} \\rightarrow 1$. Now we prove $D_{t} \\rightarrow 0$ as $t \\rightarrow \\infty$.\n\nDenote $\\frac{\\mu_{j} \\sum_{k \\in S} P_{j k} \\int_{S}^{\\infty}\\left(1-F_{j k}(y)\\right) d y}{\\sum_{k \\in S} \\mu_{k} m_{k}}$ by $\\pi_{j, x}$. For a fixed $j \\in S, x \\geq 0$, and any $\\delta_{x} \\in\\left(0, \\pi_{j, x}\\right)$ there exists $t_{\\delta_{x}}>0$ such that\n\n$$\n\\left|P\\left[t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right]-\\pi_{j, x}\\right| \\leq \\delta_{x}\n$$\n\nfor $t \\geq t_{\\delta_{x}}$.\nObserve that each summand in the second term of the RHS of (6.3) converges to 0 as $t \\rightarrow \\infty$. Also note that, for any $x>0, t \\geq t_{\\delta_{x}}$, the $j^{\\prime}$-th term has the following upper bound\n\n$$\n\\begin{aligned}\n& P\\left[H_{t-\\varepsilon(t)} \\in A, Y_{t-\\varepsilon(t)}=j^{\\prime}\\right]\\left|M_{t}-1\\right| \\\\\n& \\quad \\leq P\\left[Y_{t-\\varepsilon(t)}=j^{\\prime}\\right] \\frac{2}{P\\left[t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right]} \\\\\n& \\quad \\leq P\\left[Y_{t-\\varepsilon(t)}=j^{\\prime}\\right] \\frac{2}{\\pi_{j, x}-\\delta_{x}}\n\\end{aligned}\n$$\n\nand the upper bound is summable over $j^{\\prime} \\in S$ and has a limit as $t \\rightarrow \\infty$ which is also summable over $j^{\\prime} \\in S$. Hence, by Pratt's lemma (p. 101 in Schilling [54]), the sum in the RHS of (6.3) converges to $D_{t} \\rightarrow 0$ as $t \\rightarrow \\infty$.\n\nFrom assumption $\\left(\\frac{\\tau(t)}{t} \\rightarrow 0\\right)$ the assertion $H_{t-\\epsilon(t)} \\xrightarrow{d} H_{\\infty}$ follows, showing the first term in (6.3) converging to $P\\left[H_{\\infty} \\in A\\right]$ as asserted.\nStep 3: Take any $\\delta>0$ and define $A^{\\delta}:=\\{x: d(x, A)<\\delta\\}, A^{-\\delta}:=\\left\\{x \\in A: d\\left(x, A^{c}\\right)>\\delta\\right\\}$ and note that $A^{-\\delta} \\subseteq A \\subseteq A^{\\delta}$. Denoting $B_{t}:=H_{t}-H_{t-\\epsilon(t)}$ one has\n\n$$\nP\\left[H_{t} \\in A \\mid t-\\tau_{g_{t}^{t}}^{j}>x, Y_{t}=j\\right]=P\\left[H_{t-\\epsilon(t)}+B_{t} \\in A,\\left|B_{t}\\right| \\leq \\delta \\mid t-\\tau_{g_{t}^{t}}^{j}>x, Y_{t}=j\\right]+C_{t}\n$$\n\nwhere\n\n$$\n\\limsup _{t \\rightarrow \\infty} C_{t} \\leq \\limsup _{t \\rightarrow \\infty} \\frac{P\\left[\\left|B_{t}\\right|>\\delta\\right]}{P\\left[t-\\tau_{g_{t}^{t}}^{j}>x, Y_{t}=j\\right]}=0\n$$\n\nObserve that\n\n$$\n\\begin{aligned}\nP\\left[H_{t-\\epsilon(t)} \\in A^{-\\delta} \\mid t-\\tau_{g_{t}^{t}}^{j}>x, Y_{t}=j\\right] & \\leq P\\left[H_{t-\\epsilon(t)}+B_{t} \\in A,\\left|B_{t}\\right| \\leq \\delta \\mid t-\\tau_{g_{t}^{t}}^{j}>x, Y_{t}=j\\right] \\\\\n& \\leq P\\left[H_{t-\\epsilon(t)} \\in A^{\\delta} \\mid t-\\tau_{g_{t}^{t}}^{j}>x, Y_{t}=j\\right]\n\\end{aligned}\n$$\n\nStep 3 follows by letting $\\delta \\rightarrow 0$ after taking $t \\rightarrow \\infty$ to both sides of aforementioned step and applying result obtained from Step 2 (using continuity set assumption of $A$ i.e $P\\left[H_{\\infty} \\in \\partial A\\right]=0$ ).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 11,
      "text": "# 7 Conclusion and future directions \n\n(i) The regime-switching framework of CTMC in [46] is extended to a semi-Markovian regime switching while preserving the renewal regenerative structure. This extension is crucial for the modeling point of view as well as for making long-term prediction of observed stochastic processes via finding the scaled limits. Exact long-time behaviors of several classes of stochastic models, admitting a function of a specific integral $\\int_{0}^{t} b\\left(Y_{s}\\right) e^{-\\int_{s}^{\\tau} a\\left(Y_{r}\\right) d r} d s$, become explicit in terms of the parameters that determine the dynamics of the underlying regime process. We applied it further in two examples (Pitchfork bifurcation and regime switching diffusions) and got explicit long-time behaviors in different cases with several interesting observations (Remark 5.1 and Remark 5.3). We are curious whether, for regime-switching diffusions that are more general than (5.9) and (5.16), phenomena similar to those in Remark 5.3 still occur or not. Specifically, we wonder if the universal weak limit results emerge in the divergent cases, that do not depend on the noise process (as in cases (B) and (C)) in the right hand side weak limit, while strong dependence on the noise process is observed in the stable case (A) and the special divergent case (D) in both Theorem 6 and Corollary 5.2.\nCan this framework be extended to more general regime processes while maintaining the renewal regenerative structure? To address this partially, several works on long-memory (see [11]) and infinitememory processes (see [33]) suggest that under certain restrictive conditions, the regenerative renewal property may still hold. However, integrating such formulation with our technique requires the distributional estimate of the asymptotic residual time\n\n$$\n\\mathcal{L}\\left(t-\\tau_{g_{t}^{t}}^{j} \\mid Y_{t}=j\\right)\n$$\n\nas well as developing an analogous version of Lemma 6.1. Such derivations may not be as explicit as those for the semi-Markov regime process that we have here, which will be addressed later.\nAs mentioned in Remark 2.1 the renewal regenerative structure of $Y$ will be absent if Assumption 1(c) does not hold. Can we have any alternative methodology to circumvent this or at least have some closed-form limit results in such non-regular cases? We conjecture that in the divergent cases, one may still get similar limit theorems for $\\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{a^{\\prime}(t)}-b^{\\prime}(t)$ for suitable choices of $a^{\\prime}(\\cdot), b^{\\prime}(\\cdot)$ depending on different cases. Such results for non-regenerative $Y$, will be explored further in future.\n\n(ii) In contrast to [46], the varying tail structures of sojourn time distributions play a crucial role in shaping the different behaviors of the scaling limits. In the stable region that change is not abrupt as it only affects the common law of $\\left\\{\\left(L_{i}^{j}, Q_{i}^{j}\\right): i \\geq 1\\right\\}$ as well as the law of the residual time $\\left(t-\\tau_{g_{i}^{j}}^{j}\\right)$, but in the transient region it changes the scaling factor of $\\log \\left|I_{t}\\right|$ as it controls the rate on how it will diverge in a long time. In a way, this work illustrates universal results on long-time behaviour of some semi-markovian regime-switching stochastic processes with different tail structures of the sojourn times.\n\nAs hinted in Remark 4.3, tails of $\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c}\\right|$ and $\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}\\right|$ are governed by the underlying chain $J$, and the assumptions in (4.7) and $E\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c}\\right|^{1+\\alpha}<\\infty$ are quite restrictive in a sense that they force $\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c}\\right|,\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}\\right|$ to have tails lighter than $\\alpha$, which is the heaviest tails of the sojourn times. In pathological cases when the tail index of $\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}\\right|$ is equal to $\\alpha$ or less than that, it will drive the aggregate tail index of $\\int_{\\tau_{g}^{j}}^{\\tau_{t}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s$ in line of Lemma 3.7 (part (2) and other parts) of [41] and that will change the statement of Theorem 3 as well (which will be explored with details in future).\n(iii) As a standing condition Assumption 1(b) ensures that all elements of $\\mathcal{G}$ should have finite first moment. If that is violated, several problems will arise such as $\\int_{\\tau_{g}^{j}}^{\\tau_{t}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s$ can be regularly varying with some $\\alpha \\in(0,1)$, and as a consequence almost surely/ in probability convergence of $\\frac{g_{i}^{j}}{t}$ will not hold anymore, instead for an increasing function $\\alpha(\\cdot)$ one has $\\frac{g_{i}^{j}}{\\alpha(t)} \\xrightarrow{d} X$ for some strictly positive random variable $X$. As a consequence, Anscome's law via verifying the contiguity condition (2.11) will not be useful as it requires in probability convergence of the stopped random time to a constant, such as $\\frac{g_{i}^{j}}{\\alpha(t)} \\xrightarrow{p} a$ for some $a>0$. There should be a way to circumvent this issue, and it will be addressed in the future.\n(iv) Lemma 6.1 can be seen as a conditional version of the Anscombe's law when the stopped random time (here the renewal time $g_{i}^{j}$ ) appears from the semi-Markovian contexts and it can be used in more general directions such as in finding the weak limit of $H_{t}:=\\sup _{t \\geq 0} I_{t}$. It would be interesting to use similar methods in the context of extremal processes under general regime-switching structures as well.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 12,
      "text": "# Acknowledgements \n\nThe author thanks Prof. Filip Lindskog and Prof. Jochen Broecker for their valuable comments on the first draft, and Prof. Jeffrey Collamore for suggesting the article [11] during his visit to Stockholm University.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 13,
      "text": "## 8 Set-up of proof-ideas \\& notations\n\nWe proceed with the convention $\\sum_{i=j}^{k} a_{i}=0$ and $\\prod_{i=j}^{k} a_{i}=1$ if $j>k$ for any $a_{i}$. For any functions $c, d: S \\rightarrow \\mathbb{R}$ and $j \\in S$, define\n\n$$\nG_{j}^{c, d}(x):=\\int_{0}^{x} d(j) e^{-c(j)(x-s)} d s=x d(j) 1_{\\{c(j)=0\\}}+\\frac{d(j)}{c(j)}\\left(1-e^{-x c(j)}\\right) 1_{\\{c(j) \\neq 0\\}}\n$$\n\nLet $e^{-\\int_{c}^{t} a\\left(Y_{r}\\right) d r}$ be denoted by $\\Phi(s, t)$ and by this notation $\\Phi_{t}=\\Phi(0, t)$. Given two functions $a(\\cdot), b(\\cdot)$ : $S \\rightarrow \\mathbb{R}$, we define some random variables $\\left\\{\\left(L_{i}^{j}, Q_{i}^{j}\\right): i \\geq 1\\right\\},\\left(L_{0}^{j}, Q_{0}^{j}\\right)$ as\n\n$$\n\\begin{aligned}\n\\left(L_{i}^{j}, Q_{i}^{j}\\right) & :=\\left(e^{-\\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}} a\\left(Y_{s}\\right) d s}, \\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{s}^{\\tau_{i}^{j}} a\\left(Y_{r}\\right) d r} d s\\right) \\quad \\forall i \\geq 1, \\quad \\text { and } \\\\\n\\left(L_{0}^{j}, Q_{0}^{j}\\right) & :=\\left(e^{-\\int_{0}^{\\tau_{0}^{j}} a\\left(Y_{s}\\right) d s}, \\int_{0}^{\\tau_{0}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{s}^{\\tau_{0}^{j}} a\\left(Y_{r}\\right) d r} d s\\right)\n\\end{aligned}\n$$\n\nObserve that if $Y_{0}=j$, then $\\tau_{0}^{j}=0$ and $\\left(L_{0}^{j}, Q_{0}^{j}\\right)=(1,0)$. The sequence of intervals $\\left(\\mathfrak{I}_{k}^{j}\\right)_{k \\geq 1}$ of renewal cycles (recall $\\mathfrak{I}_{k}^{j}:=\\left[\\tau_{k-1}^{j}, \\tau_{k}^{j}\\right)$ ) is an i.i.d. sequence and therefore also $\\left(L_{i}^{j}, Q_{i}^{j}\\right)_{i=1}^{\\infty}$ is an i.i.d. sequence under Assumption 1. However, for fixed $t>0,\\left(L_{i}^{j}, Q_{i}^{j}\\right)_{i=1}^{g_{t}^{j}}$ is not an i.i.d. sequence since $g_{t}^{j}$, defined in (2.7), is a renewal time which depends on the sum of all renewal cycle lengths before time $t$.\n\nGiven an arbitrary sequence of iid random variables $\\left\\{\\left(A_{i}, B_{i}\\right): i \\geq 1\\right\\}$ having common law $\\mathcal{L}(A, B)$, define the random variables $\\left\\{\\left(P_{n}(A, B), \\widetilde{P}_{n}(A, B)\\right): n \\geq 1\\right\\}$ as following\n\n$$\nP_{n}(A, B):=\\sum_{k=1}^{n}\\left(\\prod_{i=1}^{k-1} A_{i}\\right) B_{k}, \\quad \\widetilde{P}_{n}(A, B):=\\sum_{k=1}^{n}\\left(\\prod_{i=k+1}^{n} A_{i}\\right) B_{k}\n$$\n\nFurther note that in general $\\left\\{\\widetilde{P}_{n}(A, B): n \\geq 1\\right\\}$ is Markovian and have a random coefficient autoregressive process type evolution\n\n$$\n\\widetilde{P}_{n+1}(A, B)=A_{n+1} \\widetilde{P}_{n}(A, B)+B_{n+1}, \\quad \\text { with } \\widetilde{P}_{n}(A, B) \\Perp\\left(A_{n+1}, B_{n+1}\\right)\n$$\n\nwhile the sequence $\\left\\{P_{n}(A, B): n \\geq 1\\right\\}$ is not Markovian but admits the following representation\n\n$$\nP_{n+1}(A, B)=P_{n}(A, B)+\\left(\\prod_{i=1}^{n} A_{i}\\right) B_{n+1}\n$$\n\nObserve that $\\left\\{\\left(L_{i}^{j}, Q_{i}^{j}\\right): i \\geq 1\\right\\}$ are iid under Assumption 1. For notational simplicity, by $P_{g_{t}^{j}}^{j}, \\widetilde{P}_{g_{t}^{j}}^{j}$ we denote $P_{g_{t}^{j}}\\left(L_{i}^{j}, Q_{i}^{j}\\right), \\widetilde{P}_{g_{t}^{j}}\\left(L_{i}^{j}, Q_{i}^{j}\\right)$ respectively. Define\n\n$$\nR_{t}:=\\left(R_{t}^{(1)}, R_{t}^{(2)}\\right):=\\left(\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) L_{0}^{j}, \\quad\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) Q_{0}^{j}+P_{g_{t}^{j}}^{j}\\right)\n$$\n\nFrom the aforementioned definitions, $R_{t}$ depends on $j \\in S$ but for notational simplicity $j$ is omitted.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 14,
      "text": "# 9 Proof of Theorem 1 \n\nWe use the following two lemmas to prove the theorem.\nLemma 9.1. Under Assumption 1, for any $t>0$ and $A=\\left(A_{1}, A_{2}\\right) \\in \\mathcal{B}\\left(\\mathbb{R}^{2}\\right)$,\n\n$$\nP\\left[\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}\\right) \\in A \\mid Y_{0}=i, Y_{t}=j\\right]=P\\left[\\left(Q_{t}^{(1)}, Q_{t}^{(2)}\\right) \\in\\left(A_{1}, A_{2}\\right) \\mid Y_{0}=i, Y_{t}=j\\right]\n$$\n\nwhere $\\left(Q_{t}^{(1)}, Q_{t}^{(2)}\\right)_{t \\geq 0}$ is an $\\left(\\mathcal{F}_{t}^{\\mathrm{Y}}\\right)_{t \\geq 0}$-adapted process defined as\n\n$$\n\\begin{aligned}\n\\left(Q_{t}^{(1)}, Q_{t}^{(2)}\\right):= & \\left(e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) L_{0}^{j}\\right. \\\\\n& \\left.G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)+e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left[\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) Q_{0}^{j}+P_{g_{t}^{j}}^{j}\\right]\\right)\n\\end{aligned}\n$$\n\nLemma 9.2. Suppose Assumptions 1 and 2 hold.\n(a) For each $j \\in S$, as $t \\rightarrow \\infty$, the process $R:=\\left(R_{t}: t \\geq 0\\right)$ defined in (8.5) marginally satisfies\n\n$$\nR_{t}=\\left(R_{t}^{(1)}, R_{t}^{(2)}\\right) \\xrightarrow{d}\\left(0, V_{j}^{*}\\right)\n$$\n\nwhere the random variable $V_{j}^{*}$ is distributed identically as in (3.3).\n(b) The process $\\left(R_{t}^{(2)}: t \\geq 0\\right)$ satisfies all properties of $\\left(H_{t}\\right)_{t \\geq 0}$ in (6.1) of Lemma 6.1.\n\nWe sketch how aforementioned lemmas will help us proving the assertion in (3.2). For any $A_{3} \\in \\mathcal{B}\\left(\\mathbb{R}_{\\geq 0} \\times\\right.$ $\\mathbb{R} \\times S$ ) taking $t \\rightarrow \\infty$ limit on both sides of\n\n$$\nP_{i}\\left[\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}, Y_{t}\\right) \\in A_{3}\\right]=\\sum_{j \\in S} P\\left[Y_{t}=j \\mid Y_{0}=i\\right] P\\left[\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}, j\\right) \\in A_{3} \\mid Y_{0}=i, Y_{t}=j\\right]\n$$\n\nand using $P\\left[Y_{t}=j \\mid Y_{0}=i\\right] \\rightarrow \\pi_{j}$ (which holds under Assumption 1), main assertion will be a consequence of Dominated Convergence Theorem if we show that as $t \\rightarrow \\infty$,\n\n$$\nP\\left[\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}, Y_{t}\\right) \\in A_{3} \\mid Y_{0}=i, Y_{t}=j\\right] \\rightarrow P\\left[\\left(0, Z_{j}, j\\right) \\in A_{3}\\right]\n$$\n\nwhere for each $j \\in S$, the random variable $Z_{j}$ is defined in (3.2). Since on conditioning with respect to $\\left\\{Y_{t}=j\\right\\}$ last co-ordinate of $\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}, Y_{t}\\right)$ becomes deterministic, we proceed with $P\\left[\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}\\right) \\in A\\right.$ $\\mid$ $\\left.Y_{0}=i, Y_{t}=j\\right]$ which has a distributional characterization from Lemma 9.1 through $\\left(Q_{t}^{(1)}, Q_{t}^{(2)}\\right)$. The assertion holds if we show that as $t \\rightarrow \\infty$,\n\n$$\nP\\left[\\left(Q_{t}^{(1)}, Q_{t}^{(2)}\\right) \\in A \\mid Y_{0}=i, Y_{t}=j\\right] \\rightarrow P\\left[\\left(0, Z_{j}\\right) \\in A\\right] \\quad A \\in \\mathcal{B}\\left(\\mathbb{R}_{\\geq 0} \\times \\mathbb{R}\\right)\n$$\n\nObserve that\n\n$$\n\\left(Q_{t}^{(1)}, Q_{t}^{(2)}\\right)=\\left(e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)} R_{t}^{(1)}, G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)+e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)} R_{t}^{(2)}\\right)\n$$\n\nThe limit in (9.2) holds if one can find $t \\rightarrow \\infty$ limit of $\\mathcal{L}\\left(\\left(t-\\tau_{g_{t}^{j}}^{j}\\right), R_{t} \\mid Y_{0}=i, Y_{t}=j\\right)$. From Lemma 9.2(a) one has the unconditional $t \\rightarrow \\infty$ weak limit for $R_{t}$. As $R_{t}$ is a $\\mathcal{F}_{\\tau_{g_{t}^{j}}}^{Y_{t}}$ measurable process with $R_{t}^{(1)} \\xrightarrow{d} 0$ established in Lemma 9.2(a), It suffices to find the limit of $\\mathcal{L}\\left(\\left(t-\\tau_{g_{t}^{j}}^{j}\\right), R_{t}^{(2)} \\mid Y_{0}=i, Y_{t}=j\\right)$.\n\nWith the help of Lemma 9.2(b), Lemma 6.1 is applied by setting $H_{t}:=R_{t}^{(2)},\\left(L_{t}^{(1)}, L_{t}^{(2)}\\right)=(0,1)$, and we yield for any $A_{1} \\in \\mathcal{B}(\\mathbb{R}), A_{2} \\in \\mathcal{B}\\left(\\mathbb{R}_{\\geq 0}\\right)$ as $t \\rightarrow \\infty$\n\n$$\nP_{i}\\left[\\left(R_{t}^{(2)},\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right) \\in A_{1} \\times A_{2} \\mid Y_{t}=j\\right] \\rightarrow P\\left[V_{j}^{*} \\in A_{1}\\right] \\pi_{j}^{*}\\left(A_{2}\\right)\n$$\n\nwhere $V_{j}^{*}$ is defined as the unconditional limit of $R_{t}^{(2)}$ in Lemma 9.2(a) and the measure $\\pi_{j}^{*}(\\cdot)$ is defined in (3.1). This way (9.2) is established by setting the random variable $T^{j}$ (that is independent of rest of the random variables) such that $\\mathcal{L}\\left(T^{j}\\right)=\\pi_{j}^{*}$, and observing\n\n$$\n\\begin{aligned}\n\\mathcal{L}\\left(e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)} R_{t}^{(1)}, G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)+e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)} R_{t}^{(2)} \\mid Y_{0} & =i, Y_{t}=j\\right) \\\\\n& \\xrightarrow{a} \\mathcal{L}\\left(0, G_{j}^{a, b}\\left(T^{j}\\right)+e^{-a(j) T^{j}} V_{j}^{*}\\right) \\\\\n& =\\mathcal{L}\\left(0, Z_{j}\\right)\n\\end{aligned}\n$$\n\nas $t \\rightarrow \\infty$ (where $Z_{j}$ is defined in (3.3)) proving the assertion in (9.2).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 15,
      "text": "# 9.1 Proof of Lemma 9.1 \n\nProof. Define $\\Phi(s, t)$ as $e^{-\\int_{s}^{t} a\\left(Y_{r}\\right) d r}$ for any $0<s<t$. On set $\\left\\{Y_{0}=i, Y_{t}=j\\right\\}=\\left\\{\\omega \\in \\Omega: Y_{0}(\\omega)=\\right.$ $\\left.i, Y_{t}(\\omega)=j\\right\\}$ we decompose the integral type expressions of $\\left(\\Phi_{t}^{(a)}, I_{t}^{(a, b)}\\right)$ through partitioning the interval\n\n$[0, t)$ into disjoint intervals as $[0, t)=\\left[0, \\tau_{0}^{j}\\right) \\cup_{k=1}^{g_{t}^{j}}\\left[\\tau_{k-1}^{j}, \\tau_{k}^{j}\\right) \\cup\\left[\\tau_{g_{t}^{j}}^{j}, t\\right)$. One has the following representation using the notations in (8.2),(8.3) and (8.5)\n\n$$\n\\begin{aligned}\n& \\binom{\\Phi_{t}^{(a)}}{I_{t}^{(a, b)}}={ }^{\\left(\\Phi\\left(0, \\tau_{0}^{j}\\right)\\left(\\prod_{i=1}^{g_{t}^{j}} \\Phi\\left(\\tau_{i-1}^{j}, \\tau_{i}^{j}\\right)\\right) \\Phi\\left(\\tau_{g_{t}^{j}}^{j}, t\\right)\\right.} \\\\\n& \\int_{0}^{\\tau_{0}^{j}} b\\left(Y_{s}\\right) \\Phi(s, t) d s+\\sum_{k=1}^{g_{t}^{j}} \\int_{\\tau_{k-1}^{j}}^{\\tau_{k}^{j}} b\\left(Y_{s}\\right) \\Phi(s, t) d s+\\int_{g_{t}^{j}}^{t} b\\left(Y_{s}\\right) \\Phi(s, t) d s \\\\\n& =\\binom{L_{0}^{j}\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) \\Phi\\left(\\tau_{g_{t}^{j}}^{j}, t\\right)}{\\Phi\\left(\\tau_{g_{t}^{j}}^{j}, t\\right)\\left[Q_{0}^{j} \\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}+\\sum_{k=1}^{g_{t}^{j}}\\left(\\prod_{i=k}^{g_{t}^{j}-1} L_{i+1}^{j}\\right) Q_{k}^{j}\\right]+\\int_{\\tau_{g_{t}^{j}}^{j}}^{t} b\\left(Y_{s}\\right) \\Phi(s, t) d s} \\\\\n& \\stackrel{\\left\\{Y_{0}=i, Y_{t}=j\\right\\}}{\\equiv}\\binom{L_{0}^{j}\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}}{e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left[\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) Q_{0}^{j}+\\widetilde{P}_{g_{t}^{j}}^{j}\\right]+G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\n\\end{aligned}\n$$\n\nwhere the last equality is a consequence of the fact that on $\\left\\{Y_{0}=i, Y_{t}=j\\right\\}$ the latent process $Y$ will always be at state $j$ in interval $\\left[\\tau_{g_{t}^{j}}^{j}, t\\right)$ and that implies\n\n$$\n\\int_{\\tau_{g_{t}^{j}}^{j}}^{t} b\\left(Y_{s}\\right) \\Phi(s, t) d s=\\int_{\\tau_{g_{t}^{j}}^{j}}^{t} b(j) e^{-a(j)(t-s)} d s=\\int_{0}^{t-\\tau_{g_{t}^{j}}^{j}} b(j) e^{-a(j)(t-r)} d r=G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\n$$\n\nNote that in (9.1) we have $P_{g_{t}^{j}}^{j}$ which is not same as $\\widetilde{P}_{g_{t}^{j}}^{j}$ in (9.4). Observe that\n\n$$\n\\begin{aligned}\n& \\mathcal{L}\\left(\\left(L_{0}^{j}, Q_{0}^{j}\\right),\\left(L_{1}^{j}, Q_{1}^{j}\\right),\\left(L_{2}^{j}, Q_{2}^{j}\\right), \\ldots,\\left(L_{g_{t}^{j}}^{j}, Q_{g_{t}^{j}}^{j}\\right),\\left(t-\\tau_{g_{t}^{j}}^{j}\\right) \\mid Y_{0}=i, Y_{t}=j\\right) \\\\\n= & \\mathcal{L}\\left(\\left(L_{0}^{j}, Q_{0}^{j}\\right),\\left(L_{g_{t}^{j}}^{j}, Q_{g_{t}^{j}}^{j}\\right),\\left(L_{g_{t}^{j}-1}^{j}, Q_{g_{t}^{j}-1}^{j}\\right), \\ldots,\\left(L_{1}^{j}, Q_{1}^{j}\\right),\\left(t-\\tau_{g_{t}^{j}}^{j}\\right) \\mid Y_{0}=i, Y_{t}=j\\right)\n\\end{aligned}\n$$\n\nThis follows from the fact that $g_{t}^{j}$ represents the renewal time, which depends solely on the total sum of the interval lengths $\\left[0, \\tau_{0}^{j}\\right) \\cup_{k=1}^{g_{t}^{j}}\\left[\\tau_{k-1}^{j}, \\tau_{k}^{j}\\right.$. This sum remains unchanged if we reverse the order of the regenerating renewal intervals in $\\cup_{k=1}^{g_{t}^{j}}\\left[\\tau_{k-1}^{j}, \\tau_{k}^{j}\\right.$ by replacing each $k$ with $g_{t}^{j}-k+1$ for $k=1, \\ldots, g_{t}^{j}$. As a result, the equality in distribution holds for both sides of (9.5).\n\nSince $P_{g_{t}^{j}}^{j}$ and $\\widetilde{P}_{g_{t}^{j}}^{j}$ are outputs of identical function of the random variables in LHS and RHS of (9.5). This implies that\n\n$$\n\\left(\\left(L_{0}^{j}, Q_{0}^{j}\\right), P_{g_{t}^{j}}^{j},\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right) \\stackrel{\\mathcal{L}\\left(\\cdot \\mid Y_{0}=i, Y_{t}=j\\right.}{\\equiv}\\left(\\left(L_{0}^{j}, Q_{0}^{j}\\right), \\widetilde{P}_{g_{t}^{j}}^{j},\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right)\n$$\n\nare weakly identical. Hence,\n\n$$\n\\begin{aligned}\n\\mathcal{L}\\left(L_{0}^{j}\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}, \\quad\\right. & \\left.e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left[\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) Q_{0}^{j}+\\widetilde{P}_{g_{t}^{j}}^{j}\\right] \\\\\n& +G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right) \\mid Y_{0}=i, Y_{t}=j\\right) \\\\\n= & \\mathcal{L}\\left(Q_{t}^{(1)}, Q_{t}^{(2)} \\mid Y_{0}=i, Y_{t}=j\\right)\n\\end{aligned}\n$$\n\nholds, proving the assertion of Lemma 9.1.\n\nProof of Lemma 9.2 is given in the Supplementary Material. Since the proof of Theorem 2 closely follows the approach of Theorem 3 (and Theorem 2 of [46]), it is added in the Supplementary material.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 16,
      "text": "# 10 Proof of Theorem 3 \n\nDenote $t^{1 / \\alpha} L_{0}(t), n^{1 / \\alpha} L_{0}(n)$ by $c_{t}, c_{n}$ respectively. We begin by stating the following Lemma and prove the theorem in the following subsections.\n\nLemma 10.1. Suppose Assumptions 1 and $4(a, b)$ hold. Then for each $j \\in S$, there exist $\\alpha \\in(1,2)$ and a slowly varying function $L(\\cdot)$ (specified in Assumption 4(b)) such that\n\n$$\n\\begin{aligned}\n\\lim _{x \\rightarrow \\infty} \\frac{P\\left[\\int_{\\tau_{0}^{j}}^{r_{t}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s>x\\right]}{x^{-\\alpha} L(x)} & =\\widetilde{\\alpha}_{j}^{(+)}=\\frac{1-\\beta_{j}}{2} \\sigma_{(\\dot{j}, \\alpha)}^{j s} \\\\\n\\lim _{x \\rightarrow \\infty} \\frac{P\\left[\\int_{\\tau_{0}^{j}}^{r_{t}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s<-x\\right]}{x^{-\\alpha} L(x)} & =\\widetilde{\\alpha}_{j}^{(-)}=\\frac{1+\\beta_{j}}{2} \\sigma_{(\\dot{j}, \\alpha)}^{j s}\n\\end{aligned}\n$$",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 17,
      "text": "### 10.1 Proof of Theorem 3(a)\n\nProof. We begin with $I_{t}^{(a, b)}=\\Phi_{t}^{(a)} \\widetilde{I}_{t}^{(a, b)}$, where $\\widetilde{I}_{t}^{(a, b)}=\\int_{0}^{t} b\\left(Y_{s}\\right) e^{\\int_{0}^{\\tau} a\\left(Y_{r}\\right) d r} d s$. Fix arbitrary $i, j \\in S$. Observe that on $\\left\\{Y_{0}=i, Y_{t}=j\\right\\}$ using renewal regenerative structure of $Y$ (as a consequence of Assumption 1)\n\n$$\n\\Phi_{t}^{(a)}=L_{0}^{j}\\left(\\prod_{i=1}^{g_{t}^{j}} L_{i}^{j}\\right) e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}, \\widetilde{I}_{t}^{(a, b)}=\\left[\\frac{Q_{0}^{j}+S_{g_{t}^{j}}^{* *}}{L_{0}^{j}}+\\frac{G_{j}^{(a, b)}\\left(t-\\tau_{g_{t}^{j}}\\right)}{\\Phi_{t}^{(a)}}\\right]\n$$\n\nwhere for any integer $n \\geq 1, \\quad S_{n}^{* *}:=P_{n}\\left(\\frac{1}{L_{1}^{j}}, \\frac{Q_{t}^{j}}{L_{1}^{j}}\\right)=\\sum_{i=1}^{n} \\frac{Q_{i}^{j}}{L_{i}^{j}} \\prod_{k=1}^{i-1}\\left(\\frac{1}{L_{k}^{j}}\\right)$.\nIt follows that\n\n$$\n\\begin{aligned}\n\\mathcal{L} & {\\left[\\left(\\frac{\\log \\Phi_{t}^{(a)}+t E_{\\pi} a(\\cdot)}{t^{\\frac{1}{a}} L_{0}(t)}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|+t E_{\\pi} a(\\cdot)}{t^{\\frac{1}{a}} L_{0}(t)}\\right)\\left|Y_{0}=i, Y_{t}=j\\right] } \\\\\n& =\\mathcal{L}\\left[\\left(\\widetilde{G}_{t}^{*(1)}+\\widetilde{G}_{t}^{(2)}, \\widetilde{G}_{t}^{*(1)}+\\widetilde{G}_{t}^{(2)}+\\widetilde{G}_{t}^{(3)}\\right)\\left|Y_{0}=i, Y_{t}=j\\right]\\right.\n\\end{aligned}\n$$\n\nwhere\n\n$$\n\\begin{aligned}\n& \\widetilde{G}_{t}^{*(1)}=\\frac{\\sum_{i=1}^{g_{t}^{j}} \\log L_{i}^{j}+t E_{\\pi} a(\\cdot)}{t^{\\frac{1}{a}} L_{0}(t)}, \\quad \\widetilde{G}_{t}^{(2)}=\\frac{\\int_{0}^{\\tau_{0}^{j}} a\\left(Y_{s}\\right) d s+a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}{t^{\\frac{1}{a}} L_{0}(t)} \\\\\n& \\widetilde{G}_{t}^{(3)}=\\frac{\\log \\left|\\frac{Q_{0}^{j}+S_{g_{t}^{j}}^{* *}}{L_{0}^{j}}+\\frac{G_{t}^{(a, b)}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}{\\Phi_{t}^{(a)}}\\right|}{t^{\\frac{1}{a}} L_{0}(t)}\n\\end{aligned}\n$$\n\nHence for any $A_{1}, A_{2} \\in \\mathcal{B}\\left(\\mathbb{R}_{\\geq 0}\\right)$,\n\n$$\n\\begin{aligned}\n& P\\left[\\left(\\frac{\\log \\Phi_{t}^{(a)}+t E_{\\pi} a(\\cdot)}{t^{\\frac{1}{a}} L_{0}(t)}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|+t E_{\\pi} a(\\cdot)}{t^{\\frac{1}{a}} L_{0}(t)}\\right) \\in \\mid Y_{0}=i\\right] \\\\\n& \\quad=\\sum_{j \\in S} P\\left[Y_{t}=j \\mid Y_{0}=i\\right] P\\left[\\left(\\widetilde{G}_{t}^{*(1)}+\\widetilde{G}_{t}^{(2)}, \\widetilde{G}_{t}^{*(1)}+\\widetilde{G}_{t}^{(2)}+\\widetilde{G}_{t}^{(3)}\\right) \\in \\mid Y_{t}=j, Y_{0}=i\\right]\n\\end{aligned}\n$$\n\nObserve that\n\n$$\n\\begin{aligned}\n\\widetilde{G}_{t}^{*(1)} & =\\frac{\\sum_{i=1}^{g_{t}^{j}}\\left(\\log L_{i}^{j}+E_{\\pi} a(\\cdot)\\right) \\mathfrak{I}_{i}^{j} \\mid)}{t^{\\frac{1}{a}} L_{0}(t)}+\\frac{\\left[\\tau_{0}^{j}+\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right] E_{\\pi} a(\\cdot)}{t^{\\frac{1}{a}} L_{0}(t)} \\\\\n& =-\\frac{c_{g_{t}^{j}}}{c_{t}} \\frac{\\sum_{i=1}^{g_{t}^{j}} \\int_{\\tau_{i}^{j}}^{\\tau_{i}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s}{\\left(g_{t}^{j}\\right)^{\\frac{1}{a}} L_{0}\\left(g_{t}^{j}\\right)}+\\frac{\\left[\\tau_{0}^{j}+\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right] E_{\\pi} a(\\cdot)}{t^{\\frac{1}{a}} L_{0}(t)}\n\\end{aligned}\n$$\n\nNow clearly $\\left\\{-\\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s: i \\geq 1\\right\\}$ are iid regularly varying with $1<\\alpha<2$, mean $=0$, with right asymptotic tail-index $\\widetilde{\\alpha}_{j}^{(-)}=\\frac{1+\\beta_{j}}{2} \\sigma_{(j, \\alpha)}^{\\alpha}$, left asymptotic tail-index $\\widetilde{\\alpha}_{j}^{(+)}=\\frac{1-\\beta_{j}}{2} \\sigma_{(j, \\alpha)}^{\\alpha}$, after scaling by $x^{-\\alpha} L(x)$ (from Lemma 10.1). Furthermore, $\\lim _{t \\rightarrow \\infty} \\frac{c_{s j}}{c_{i}}=\\left(\\frac{1}{E\\left|\\mathfrak{H}_{1}^{j}\\right|}\\right)^{\\frac{1}{\\alpha}}$ (see Lemma 12.3(a)).\n\nUsing for each $j \\in S$ the quantity $\\beta_{j}$ in (4.12), applying the stable central limit Theorem 4.5.1 of [62], as sample size $n \\rightarrow \\infty$\n\n$$\n-c_{n}^{-1}\\left(\\sum_{i=1}^{n} \\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s\\right) \\xrightarrow{d} \\sigma_{(j, \\alpha)} \\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right)\n$$\n\nUsing (10.5) and Theorem 3.2 of [34] for the stopped random time $g_{t}^{j}$ as $t \\rightarrow \\infty$,\n\n$$\n-\\frac{\\sum_{i=1}^{g_{t}^{j}} \\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s}{\\left(g_{t}^{j}\\right)^{\\frac{1}{\\alpha}} L_{0}\\left(g_{t}^{j}\\right)} \\xrightarrow{d} \\sigma_{(j, \\alpha)} \\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right)\n$$\n\nFurthermore since $\\tau_{0}^{j}+\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)$ is $O_{p}(1)$ and hence\n\n$$\n\\mathcal{L}\\left(\\widetilde{G}_{t}^{*(1)} \\mid Y_{0}=i\\right) \\xrightarrow{w} \\mathcal{L}\\left(\\left(E\\left|\\mathfrak{H}_{1}^{j}\\right|\\right)^{-\\frac{1}{\\alpha}} \\sigma_{(j, \\alpha)} \\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right)\\right)\n$$\n\nSince both $\\log L_{0}^{j},\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)$ are $O_{P}(1)$, hence\n\n$$\n\\mathcal{L}\\left(\\widetilde{G}_{t}^{(2)} \\mid Y_{0}=i\\right) \\xrightarrow{w} \\delta_{\\{0\\}}\n$$\n\nLastly using similar arguments used in proof of Theorem 2(a), as $t \\rightarrow \\infty$, one has $S_{g_{t}^{j}}^{*} \\xrightarrow{d} S^{* *}$ where $S^{* *}$ satisfies the stochastic recurrence equation\n\n$$\nS^{* *} \\stackrel{d}{=} \\frac{1}{L_{i}^{j}} S^{* *}+\\frac{Q_{t}^{j}}{L_{i}^{j}}, \\quad S^{* *} \\perp\\left(\\frac{1}{L_{i}^{j}}, \\frac{Q_{t}^{j}}{L_{i}^{j}}\\right)\n$$\n\nAlso $\\Phi_{t}^{(a)} \\rightarrow \\infty$ as $t \\rightarrow \\infty$, we have $\\log \\left|\\frac{Q_{0}^{j}+S_{g_{t}^{j}}^{* *}}{L_{0}^{j}}+\\frac{G_{j}^{(a, b)}\\left(t-\\tau_{g_{t}^{j}}\\right)}{\\Phi_{t}^{(a)}}\\right|$ is $O_{P}(1)$.\n\n$$\n\\mathcal{L}\\left(\\widetilde{G}_{t}^{(3)} \\mid Y_{0}=i\\right) \\xrightarrow{w} \\delta_{\\{0\\}}\n$$\n\nCombining (10.6),(10.7),(10.9) and taking\n\n$$\nL_{t}^{(1)}=\\left(\\widetilde{G}_{t}^{(2)}, \\widetilde{G}_{t}^{(2)}+\\widetilde{G}_{t}^{(3)}\\right)^{\\prime}, \\quad L_{t}^{(2)}=\\left(\\begin{array}{ll}\n1 & 0 \\\\\n0 & 1\n\\end{array}\\right), \\quad H_{t}=\\left(\\widetilde{G}_{t}^{*(1)}\\right. \\\\\n\\left.\\widetilde{G}_{t}^{*(1)}\\right)\n$$\n\nin Lemma 6.1 as $t \\rightarrow \\infty$\n\n$$\n\\begin{gathered}\n\\mathcal{L}\\left(\\left(\\widetilde{G}_{t}^{*(1)}+\\widetilde{G}_{t}^{(2)}, \\widetilde{G}_{t}^{*(1)}+\\widetilde{G}_{t}^{(2)}+\\widetilde{G}_{t}^{(3)}\\right) \\mid Y_{t}=j, Y_{0}=i\\right) \\\\\n\\xrightarrow{w}\\left(E\\left|\\mathfrak{H}_{1}^{j}\\right|\\right)^{-\\frac{1}{\\alpha}} \\sigma_{(j, \\alpha)}\\left(\\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right), \\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right)\\right)\n\\end{gathered}\n$$\n\nwhere $\\widetilde{G}_{t}^{*(1)}$ satisfies (6.1), i.e,\n\n$$\n\\widetilde{G}_{t}^{*(1)}-\\widetilde{G}_{t-\\varepsilon(t)}^{*(1)} \\rightarrow 0, \\quad \\text { as } \\quad t \\rightarrow \\infty\n$$\n\nfor some $\\varepsilon(t) \\rightarrow \\infty, \\& \\frac{\\varepsilon(t)}{t} \\rightarrow 0$, which follows from Lemma 10.2. Using (10.10) and $P\\left[Y_{t}=j \\mid Y_{0}=i\\right] \\rightarrow \\pi_{j}$ in (10.4) as $t \\rightarrow \\infty$ the assertion will follow.\n\nLemma 10.2. There exists an increasing function $t \\rightarrow \\varepsilon(t)$ such that $\\varepsilon(t) \\rightarrow \\infty$ and $\\frac{\\varepsilon(t)}{t} \\rightarrow 0$ as $t \\rightarrow \\infty$ for which (10.11) holds.\n\nProofs of Lemma 10.1 and Lemma 10.2 are given in the supplementary material.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 18,
      "text": "# 10.2 Proof of Theorem 3(b) \n\nProof. We will expand $I_{t}^{(a, b)}$ in a different manner than in Theorem 3(a). Fix $i, j \\in S$. Given $E_{\\pi} a(\\cdot)=0$, the random walk generated by the process $\\left(\\sum_{k=1}^{n} \\log L_{k}^{j}: n \\geq 1\\right)$ has zero drift as the $k$-th increment $\\log L_{k}^{j}=-\\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}} a\\left(Y_{s}\\right) d s$ has mean 0 , but $\\operatorname{Var}\\left(\\log L_{k}^{j}\\right)$ doesn't exist unlike Theorem 2(b). Let\n\n$$\nS_{n}^{\\otimes j}:=\\sum_{i=1}^{n} \\log L_{i}^{j}, \\quad M_{n}^{\\otimes j}:=\\max _{1 \\leq k \\leq n}\\left\\{\\sum_{i=1}^{k} \\log L_{i}^{j}\\right\\}, \\quad \\text { and } \\quad Z_{n}^{\\otimes j}:=\\max _{1 \\leq k \\leq n}\\left\\{\\left(\\prod_{i=1}^{k-1} L_{i}^{j}\\right)\\left|Q_{k}^{j}\\right|\\right\\}\n$$\n\nObserve that on $\\left\\{Y_{0}=i, Y_{t}=j\\right\\}$, using (9.1)\n\n$$\n\\begin{aligned}\n& \\left(\\log \\Phi_{t}^{(a)}, \\log \\left|I_{t}^{(a, b)}\\right|\\right) \\stackrel{\\mathcal{L}\\left(\\cdot \\mid Y_{0}=i, Y_{t}=j\\right)}{=}\\left(\\log L_{0}^{j}+\\log \\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right)+\\log \\left(e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\right)\\right. \\\\\n& \\log \\left|e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left[\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) Q_{0}^{j}+\\widetilde{P}_{g_{t}^{j}}^{j}\\right]+G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right| \\right) \\\\\n& \\stackrel{d}{=} \\quad\\left(S_{g_{t}^{j}}^{\\otimes j}+\\left[\\log L_{0}^{j}-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right]\\right. \\\\\n& \\left.\\quad \\log Z_{g_{t}^{j}}^{\\otimes j}+\\log \\left|B_{t}^{(1)}+\\frac{B_{t}^{(2)}}{Z_{g_{t}^{j}}^{\\otimes j}} P_{g_{t}^{j}}^{j}\\right|\\right)\n\\end{aligned}\n$$\n\nwhere\n\n$$\nB_{t}^{(1)}=\\frac{e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) Q_{0}^{j}+G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}{Z_{g_{t}^{j}}^{\\otimes j}}, \\quad B_{t}^{(2)}=e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\n$$\n\nand denote $\\left(B_{t}^{(1)}+\\frac{B_{t}^{(2)}}{Z_{g_{t}^{j}}^{\\otimes j}} P_{g_{t}^{j}}^{j}\\right)$ by $B_{t}^{(3)}$. Consider the probability\n\n$$\n\\begin{aligned}\n& P\\left[\\left(\\frac{\\log \\Phi_{t}^{(a)}}{t^{\\frac{1}{n}} L_{0}(t)}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{t^{\\frac{1}{n}} L_{0}(t)}\\right)^{\\prime} \\in \\mid Y_{0}=i\\right] \\\\\n& \\quad=\\sum_{j \\in S} P\\left[Y_{t}=j \\mid Y_{0}=i\\right] P\\left[\\left(\\frac{\\log \\Phi_{t}^{(a)}}{t^{\\frac{1}{n}} L_{0}(t)}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{t^{\\frac{1}{n}} L_{0}(t)}\\right)^{\\prime} \\in \\mid Y_{0}=i, Y_{t}=j\\right] \\\\\n& \\quad=\\sum_{j \\in S} P\\left[Y_{t}=j \\mid Y_{0}=i\\right] P\\left[\\widetilde{L}_{t}^{(1)}+L_{t}^{(2)} \\widetilde{H}_{t} \\in \\mid Y_{0}=i, Y_{t}=j\\right]\n\\end{aligned}\n$$\n\nwhere the identity (17.2) is used in (10.13) and\n\n$$\n\\widetilde{L}_{t}^{(1)}=\\left(\\frac{\\log L_{0}^{j}-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}{t^{\\frac{1}{n}} L_{0}(t)}, \\frac{\\log \\left|B_{t}^{(3)}\\right|}{t^{\\frac{1}{n}} L_{0}(t)}\\right)^{\\prime}, L_{t}^{(2)}=\\left(\\begin{array}{cc}1 & 0 \\\\ 0 & 1\\end{array}\\right), \\widetilde{H}_{t}=\\left(\\frac{S_{g_{t}^{j}}^{\\otimes}}{t^{\\frac{1}{n}} L_{0}(t)}, \\frac{\\log Z_{g_{t}^{j}}^{\\otimes}}{t^{\\frac{1}{n}} L_{0}(t)}\\right)^{\\prime}\n$$\n\nWe will apply Lemma 6.1 with the above specifications. Observe that both $B_{t}^{(1)}$ and $B_{t}^{(2)}$ are $O_{p}(1)$. For each $1 \\leq k \\leq n$, we have\n\n$$\n-Z_{n}^{\\otimes j} \\leq Q_{k}^{j}\\left(\\prod_{i=1}^{k-1} L_{i}^{j}\\right) \\leq Z_{n}^{\\otimes j}\n$$\n\nThis implies that $-n Z_{n}^{\\otimes j} \\leq P_{n}^{j} \\leq n Z_{n}^{\\otimes j}$ for all $n \\geq 1$, which further implies that $\\left|\\frac{P_{g_{t}^{j}}^{j}}{Z_{g_{t}^{j}}^{\\otimes j}}\\right| \\leq g_{t}^{j}$. Hence, $\\left|B_{t}^{(3)}\\right|=O_{p}(t)$ and is strictly positive.\n\nSince $L_{0}^{j},\\left(t-\\tau_{g_{l}^{j}}^{j}\\right)$ are both $O_{P}(1)$, hence $\\widetilde{L}_{t}^{(1)} \\xrightarrow{P}(0,0)^{\\prime}$ and by Lemma 10.3(c) $\\widetilde{H}_{t}^{\\prime}$ verifies the condition $\\widetilde{H}_{t}^{\\prime}-\\widetilde{H}_{t-\\varepsilon(t)}^{\\prime} \\xrightarrow{P}(0,0)$ as $t \\rightarrow \\infty$. The proof will be done if we show as $t \\rightarrow \\infty$\n\n$$\n\\widetilde{H}_{t} \\stackrel{d}{\\rightarrow}\\left(\\frac{1}{E\\left|\\mathfrak{I}_{1}^{j}\\right|}\\right)^{\\frac{1}{\\alpha}} \\sigma_{(j, \\alpha)}\\left(\\mathbf{S}_{\\alpha, \\beta_{j}}(1), \\sup _{0 \\leq u \\leq 1} \\mathbf{S}_{\\alpha, \\beta_{j}}(u)\\right)\n$$\n\nsince then using $P\\left[Y_{t}=j \\mid Y_{0}=i\\right] \\rightarrow \\pi_{j}$, after applying the Lemma 6.1 the LHS of (10.13) will lead to\n\n$$\n\\begin{aligned}\n& \\lim _{t \\rightarrow \\infty} P\\left[\\left(\\frac{\\log \\Phi_{t}^{(a)}}{t^{\\frac{1}{\\alpha}} L_{0}(t)}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{t^{\\frac{1}{\\alpha}} L_{0}(t)}\\right) \\in \\cdot \\mid Y_{0}=i\\right] \\\\\n& \\quad=\\sum_{j \\in S} \\pi_{j} \\lim _{t \\rightarrow \\infty} P\\left[\\left(\\frac{S_{g_{l}^{\\circ}}^{\\otimes j}}{t^{\\frac{1}{\\alpha}} L_{0}(t)}, \\frac{\\log Z_{g_{l}^{\\circ}}^{\\otimes j}}{t^{\\frac{1}{\\alpha}} L_{0}(t)}\\right) \\in \\cdot \\mid Y_{0}=i\\right]\n\\end{aligned}\n$$\n\nwhere we got rid of $\\left\\{Y_{t}=j\\right\\}$ in the conditioning part of RHS of (10.13) by virtue of the Lemma 6.1. From the definitions of $M_{n}^{\\otimes j}, Z_{n}^{\\otimes j}$, it follows that\n\n$$\nM_{g_{l}^{\\prime}}^{\\otimes j}-\\max _{1 \\leq k \\leq g_{l}^{\\prime}} \\log \\left|Q_{k}^{j}\\right| \\leq \\log Z_{g_{l}^{\\prime}}^{\\otimes j} \\leq M_{g_{l}^{\\prime}}^{\\otimes j}+\\max _{1 \\leq k \\leq g_{l}^{\\prime}} \\log \\left|Q_{k}^{j}\\right|\n$$\n\n(see also (4.4) of [37]). Now under the condition (4.14) Lemma 10.3(a) holds and Lemma 10.3(b) below verifies the weak convergence result as $t \\rightarrow \\infty$. Combining these in (10.14) the assertion follows in $t \\rightarrow \\infty$ limit.\n\nLemma 10.3. Under assumptions of Theorem 3(b) as $t \\rightarrow \\infty$,\n\n$$\n\\begin{aligned}\n& \\text { (a) } \\quad \\text { under (4.14) } \\frac{\\max _{1 \\leq k \\leq g_{l}^{\\prime}} \\log \\left|Q_{k}^{j}\\right|}{t^{\\frac{1}{\\alpha}} L_{0}(t)} \\stackrel{\\text { a.e. }}{=} 0 \\text {, } \\\\\n& \\text { (b) } \\quad\\left(\\frac{S_{g_{l}^{\\prime}}^{\\otimes j}}{t^{\\frac{1}{\\alpha}} L_{0}(t)}, \\frac{M_{g_{l}^{\\prime}}^{\\otimes j}}{t^{\\frac{1}{\\alpha}} L_{0}(t)}\\right) \\stackrel{d}{\\rightarrow}\\left(\\frac{1}{E\\left|\\mathfrak{I}_{1}^{j}\\right|}\\right)^{\\frac{1}{\\alpha}} \\sigma_{(j, \\alpha)}\\left(\\mathbf{S}_{\\alpha, \\beta_{j}}(1), \\sup _{0 \\leq u \\leq 1} \\mathbf{S}_{\\alpha, \\beta_{j}}(u)\\right) \\\\\n& \\text { (c) } \\quad \\widetilde{H}_{t}^{\\prime}=\\left(\\frac{S_{g_{l}^{\\prime}}^{\\otimes j}}{t^{\\frac{1}{\\alpha}} L_{0}(t)}, \\frac{\\log Z_{g_{l}^{\\prime}}^{\\otimes j}}{t^{\\frac{1}{\\alpha}} L_{0}(t)}\\right) \\quad \\text { satisfies the condition in (6.1), i.e } \\\\\n& \\quad \\widetilde{H}_{t}-\\widetilde{H}_{t-\\varepsilon(t)} \\xrightarrow{P}(0,0)^{\\prime} \\quad \\text { for some } \\quad \\varepsilon(\\cdot) \\quad \\text { as specified in (6.1). }\n\\end{aligned}\n$$\n\nProof of Lemma 10.3, along with proofs of results in Remark 4.2, Proposition 4.4, Theorem 4 are all given in the supplementary material.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 19,
      "text": "# 11 Corollary 4.5\n### 11.1 Proof of Corollary 4.5\n\nFor some time-dependent deterministic functions $a_{2}(\\cdot), b_{2}(\\cdot)$ (such that $a_{2}(t) \\rightarrow \\infty$ as $t \\rightarrow \\infty$ ) limit results of $\\log \\left|I_{t}^{(a, b)}\\right|$ in Theorem $2 \\&$ Theorem 3 can be summarized as\n\n$$\n\\mathcal{L}\\left(\\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{a_{2}(t)}-b_{2}(t)\\right) \\xrightarrow{w} \\text { some mixture type law }\n$$\n\nwhere the functions $a_{2}(\\cdot)$ and $b_{2}(\\cdot)$ can be figured out separately from the results of Theorems 2 and 3. Notably, $a_{2}(t)$ grows polynomially in $t$, specifically as $t^{\\frac{1}{\\alpha}}$ in Theorem 2, and as $t^{\\frac{1}{\\alpha}} L_{0}(t)$ for some slowly varying function $L_{0}(\\cdot)$ in Theorem 3. The term $b_{2}(\\cdot)$ takes the form $\\left(-\\sqrt{t} E_{\\pi} a(\\cdot) \\& 0\\right)$ (respectively $\\left.\\left(t^{1-\\frac{1}{\\alpha}} L_{0}^{-1}(t) \\& 0\\right)\\right)$ in Theorem 2(a) and 2(b) (respectively in Theorem 3(a) and 3(b)).\n\nWe first prove part (a) for $\\left|\\widetilde{Z}_{t}^{(1)}\\right|$ in a general setting, while the proof for $\\left|\\widetilde{Z}_{t}^{(2)}\\right|$ requires additional work. Under the assumptions of Theorems 2(a) and 2(b), we establish the results, with analogous conclusions for Theorems 3(a) and 3(b), which we omit here. The proof of part (b) follows similar steps as in Theorem 4 , completing the assertion.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 20,
      "text": "# 11.1.1 Proof of part (a) \n\nProof. For simplicity of notation, we denote the scaling and shifting functions as $a_{2}(\\cdot), b_{2}(\\cdot)$. We use the fact that for any two non-negative random variables $X, Y$ one has $\\log \\max \\{X, Y\\} \\stackrel{d}{=} \\max \\{\\log X, \\log Y\\}$ (See Lemma 12.4).\n\nObserve that $\\widetilde{Z}_{t}^{(1)}=\\widetilde{Z}_{t}^{*} c_{t}$ where $\\widetilde{Z}_{t}^{*}:=\\max \\left\\{\\Phi_{t}^{(a)},\\left|I_{t}^{(a, b)}\\right|\\right\\}$ and $c_{t}:=a_{1} \\frac{\\Phi_{t}^{(a)}}{\\widetilde{Z}_{t}^{*}}+b_{1} \\frac{\\left|I_{t}^{(a, b)}\\right|}{\\widetilde{Z}_{t}^{*}}$. Note that for all $t \\geq 0$, almost surely\n\n$$\n0 \\leq\\left|c_{t}\\right| \\leq\\left|a_{1}\\right|+\\left|b_{1}\\right|\n$$\n\nshowing that $c_{t}$ is $O_{p}(1)$.\n\n$$\n\\begin{aligned}\n\\frac{\\log \\left|\\widetilde{Z}_{t}^{(1)}\\right|}{a_{2}(t)}-b_{2}(t) & =\\frac{\\log \\left|\\widetilde{Z}_{t}^{*} c_{t}\\right|}{a_{2}(t)}-b_{2}(t) \\\\\n& =\\left(\\frac{\\log \\left|\\widetilde{Z}_{t}^{*}\\right|}{a_{2}(t)}-b_{2}(t)\\right)+\\frac{\\log \\left|c_{t}\\right|}{a_{2}(t)}\n\\end{aligned}\n$$\n\nSince $\\frac{\\log \\left|c_{t}\\right|}{a_{2}(t)} \\xrightarrow{P} 0$, it is enough to show that $t \\rightarrow \\infty$ weak limit of $\\frac{\\log \\left|\\widetilde{Z}_{t}^{*}\\right|}{a_{2}(t)}-b_{2}(t)$ matches with $t \\rightarrow \\infty$ weak limit of $\\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{a_{2}(t)}-b_{2}(t)$. Using Lemma 12.4 we observe that\n\n$$\n\\begin{aligned}\n\\frac{\\log \\left|\\widetilde{Z}_{t}^{*}\\right|}{a_{2}(t)}-b_{2}(t) & =\\frac{\\log \\max \\left\\{\\Phi_{t}^{(a)},\\left|I_{t}^{(a, b)}\\right|\\right\\}}{a_{2}(t)}-b_{2}(t) \\\\\n& \\stackrel{d}{=} \\max \\left\\{\\frac{\\log \\Phi_{t}^{(a)}}{a_{2}(t)}-b_{2}(t), \\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{a_{2}(t)}-b_{2}(t)\\right\\}\n\\end{aligned}\n$$\n\nNote that any two variables $x, y$; the function $\\max \\{x, y\\}=\\frac{(x+y)}{2}+\\frac{|x-y|}{2}$, is a continuous function in its arguments. Using the continuous mapping theorem it is easy to verify that the weak limit of $\\max \\left\\{\\frac{\\log \\Phi_{t}^{(a)}}{a_{2}(t)}-\\right.$ $\\left.b_{2}(t), \\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{a_{2}(t)}-b_{2}(t)\\right\\}$ matches with the $t \\rightarrow \\infty$ marginal weak limit of $\\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{a_{2}(t)}-b_{2}(t)$ in all cases of Theorem 2 and Theorem 3, proving the assertion (1) of part (a).\n\nFor simplicity, let the bivariate $t \\rightarrow \\infty$ weak limit of $\\left(\\frac{\\left(\\log \\Phi_{t}^{(a)}, \\log \\left|I_{t}^{(a, b)}\\right|\\right)}{a_{2}(t)}-b_{2}(t)\\right)$ be represented by the laws $\\mathcal{W}_{2(a)}^{*}, \\mathcal{W}_{2(b)}^{*}, \\mathcal{W}_{3(a)}^{*}, \\mathcal{W}_{3(b)}^{*}$ under the assumptions of Theorem 2(a),2(b),3(a) and Theorem 3(b) respectively, whose second marginals are laws $\\mathcal{W}_{2(a)}, \\mathcal{W}_{2(b)}, \\mathcal{W}_{3(a)}$ and $\\mathcal{W}_{3(b)}$ respectively as defined before Corollary 4.5 .\n\nTo prove the result (2) of part (a) for $\\widetilde{Z}_{t}^{(2)}$, we show that the time asymptotic behaviour of $\\left(\\log \\Phi_{t}^{(a)}, \\frac{\\log \\left|I_{t}^{(m a, b)}\\right|}{m}\\right)$ and $\\left(\\log \\Phi_{t}^{(a)}, \\log \\left|I_{t}^{(a, b)}\\right|\\right)$ will be identical in distribution under same scaling and shifts, under conditions of Theorem 2(a) and 2(b) (with some modifications). We show that under conditions of Theorem 2(a) with $(a, b)$ replaced by $(m a, b)$ in Assumption $3(c)$\n\n$$\n\\lim _{t \\rightarrow \\infty} \\mathcal{L}\\left(\\frac{\\left(\\log \\Phi_{t}^{(a)}, \\log \\left|I_{t}^{(m a, b)}\\right| \\frac{1}{m}\\right)}{a_{2}(t)}-b_{2}(t)\\right)=\\mathcal{W}_{2(a)}^{*}\n$$\n\nand under conditions of Theorem 2(b) with $(a, b)$ replaced by $(m a, b)$ in (4.3)\n\n$$\n\\lim _{t \\rightarrow \\infty} \\mathcal{L}\\left(\\frac{\\left(\\log \\Phi_{t}^{(a)}, \\log \\left|I_{t}^{(m a, b)}\\right| \\frac{1}{m}\\right)}{a_{2}(t)}\\right)=\\mathcal{W}_{2(b)}^{*}\n$$\n\nThe verifications of (11.1) and (11.2) will be done in Lemma 11.1. Now we finish the proof by proceeding similar to the proof of $\\left|\\widetilde{Z}_{t}^{(1)}\\right|$ and using (11.1) \\& (11.2). Replacing $\\left|I_{t}^{(a, b)}\\right|$ by $\\left|I_{t}^{(m a, b)}\\right| \\frac{1}{m}$, we define\n\n$$\n\\widetilde{Z}_{t}^{(2)}:=\\widetilde{Z}_{m, t}^{*} c_{m, t}\n$$\n\nwhere $\\widetilde{Z}_{m, t}^{*}:=\\max \\left\\{\\Phi_{t}^{(a)},\\left|I_{t}^{(m a, b)}\\right| \\stackrel{\\mathrm{t}}{=}\\right\\}$ and $c_{m, t}:=a_{2} \\frac{\\Phi_{t}^{(a)}}{\\widetilde{Z}_{m, t}^{*}}+b_{2} \\frac{\\left|I_{t}^{(m a, b)}\\right|^{\\mathrm{t} / m}}{\\widetilde{Z}_{m, t}^{*}}$. Since $c_{m, t}$ is asymptotically $O_{p}(1)$, hence $\\lim _{t \\rightarrow \\infty} \\frac{\\left|c_{m, t}\\right|}{a_{2}(t)} \\xrightarrow{P} 0$. Following along the lines of proof of $\\left|\\widetilde{Z}_{t}^{(1)}\\right|$,\n\n$$\n\\begin{aligned}\n\\lim _{t \\rightarrow \\infty} \\mathcal{L}\\left(\\frac{\\log \\left|\\widetilde{Z}_{t}^{(2)}\\right|}{a_{2}(t)}-b_{2}(t)\\right) & =\\lim _{t \\rightarrow \\infty} \\mathcal{L}\\left(\\frac{\\log \\left|\\widetilde{Z}_{m, t}^{*}\\right|}{a_{2}(t)}-b_{2}(t)\\right) \\\\\n& =\\lim _{t \\rightarrow \\infty} \\mathcal{L}\\left(\\frac{\\log \\max \\left\\{\\Phi_{t}^{(a)},\\left|I_{t}^{(m a, b)}\\right| \\stackrel{t}{=}\\right\\}}{a_{2}(t)}-b_{2}(t)\\right) \\\\\n& \\stackrel{d}{=} \\lim _{t \\rightarrow \\infty} \\mathcal{L}\\left(\\max \\left\\{\\frac{\\log \\Phi_{t}^{(a)}}{a_{2}(t)}-b_{2}(t), \\frac{\\log \\left|I_{t}^{(m a, b)}\\right| \\stackrel{t}{=}}{a_{2}(t)}-b_{2}(t)\\right\\}\\right)\n\\end{aligned}\n$$\n\nUsing Lemma 11.1(a) \\& (b), the result for $\\left|\\widetilde{Z}_{t}^{(2)}\\right|$ will follow.\nAnalog versions (i.e the second part of part (a)(2)) under conditions of Theorem 3(a) and 3(b) (with (a,b) replaced by $(m a, b)$ in Assumption 4(c) and in (4.14) respectively) will be similar and we omit their proofs.\nLemma 11.1. (a) (11.1) holds under assumptions of Theorem 2(a) with $(a, b)$ replaced by $(m a, b)$ in Assumption 3(c).\n(b) (11.2) holds under assumptions of Theorem 2(b) with $(a, b)$ replaced by $(m a, b)$ in (4.3).\n\nAssertions of part (b) of the Corollary 4.5 follow similarly by proceeding like proofs of Theorem 4 (hence omitted).\n\nProofs of Lemma 11.1 (a),(b) are given in the supplementary material.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 21,
      "text": "# 11.2 Proof of Theorem 5 \n\nProof. We begin with the equation at display (1.2) with initial value $\\rho_{0}$. Dividing both sides by $\\rho_{t}^{3}$ will yield\n\n$$\n\\begin{aligned}\n\\frac{1}{\\rho_{t}^{3}} \\frac{d \\rho_{t}}{d t} & =\\rho_{t}^{-2} a\\left(Y_{t}\\right)-b\\left(Y_{t}\\right) \\\\\n-\\frac{1}{2} \\frac{d\\left(\\rho_{t}^{-2}\\right)}{d t} & =\\left(\\rho_{t}^{-2}\\right) a\\left(Y_{t}\\right)-b\\left(Y_{t}\\right)\n\\end{aligned}\n$$\n\nDenoting $X_{t}:=\\rho_{t}^{-2}$, we get a linear ODE for with semi-Markov $Y$ modulated coefficients $a\\left(Y_{t}\\right), b\\left(Y_{t}\\right)$ as\n\n$$\n\\begin{aligned}\n\\frac{d X_{t}}{d t} & =2 b\\left(Y_{t}\\right)-2 a\\left(Y_{t}\\right) X_{t} \\\\\n\\frac{d\\left[e^{\\int_{0}^{t} 2 a\\left(Y_{s}\\right) d s} X_{t}\\right]}{d t} & =2 b\\left(Y_{t}\\right) e^{\\int_{0}^{t} 2 a\\left(Y_{s}\\right) d s} \\\\\nX_{t} \\Phi_{t}^{(-2 a)}-X_{0} \\Phi_{0}^{(-2 a)} & =\\int_{0}^{t} 2 b\\left(Y_{s}\\right) \\Phi_{s}^{(-2 a)} d s \\\\\n& =2 I_{t}^{(-2 a, b)}\n\\end{aligned}\n$$\n\nwhere $\\Phi_{0}^{(-2 a)}=1$, and (11.4) is obtained by multiplying (11.3) by $\\Phi_{t}^{(-2 a)}$ in both sides and integrating in $[0, t]$, using the notations of integrals in (1.1). After simplifying we get that conditioned on $\\mathcal{F}_{t}^{Y}$,\n\n$$\n\\begin{aligned}\nX_{t} & =X_{0} \\Phi_{t}^{(2 a)}+2 I_{t}^{(2 a, b)} \\\\\n\\rho_{t}^{-2} & =\\rho_{0}^{-2} \\Phi_{t}^{(2 a)}+2 I_{t}^{(2 a, b)} \\\\\n\\rho_{t}^{2} & =\\frac{1}{\\rho_{0}^{-2} \\Phi_{t}^{(2 a)}+2 I_{t}^{(2 a, b)}}\n\\end{aligned}\n$$\n\nWe finish the proof of part (a) when $E_{\\pi} a(\\cdot)>0$. Observe that unconditionally under assumptions of Theorem 5(a) the result of Theorem 1 translates to\n\n$$\n\\left(\\Phi_{t}^{(2 a)}, I_{t}^{(2 a, b)}, Y_{t}\\right) \\xrightarrow{d}\\left(0, \\sum_{j \\in S} \\delta_{U}(\\{j\\}) W_{j}^{(2 a, b)}, U\\right) \\quad \\text { as } \\quad t \\rightarrow \\infty\n$$\n\nwhere $W_{j}^{(2 a, b)}$ is defined in (3.3) identically as $Z_{j}$ where $(a, b)$ is replaced by $(2 a, b)$.\nHence using the continuous mapping theorem, one gets\n\n$$\n\\begin{aligned}\n\\lim _{t \\rightarrow \\infty} \\mathcal{L}\\left(\\rho_{t}^{2}, Y_{t}\\right) & =\\lim _{t \\rightarrow \\infty} \\mathcal{L}\\left(\\frac{1}{\\rho_{0}^{-2} \\Phi_{t}^{(2 a)}+2 I_{t}^{(2 a, b)}}, Y_{t}\\right) \\\\\n& =\\left(\\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\frac{1}{2 W_{j}^{(2 a, b)}}, U\\right)\n\\end{aligned}\n$$\n\nproving the assertion in (5.2) of the theorem.\nClearly in divergent cases (i.e, $E_{\\pi} a(\\cdot) \\leq 0$ ) the state-space representation of the process $\\left(\\rho_{t}^{-2}: t \\geq 0\\right)$ in (11.5) marginally evolves like $\\left(\\widetilde{Z}_{t}^{(1)}: t \\geq 0\\right)$ in Corollary 4.5 with $a_{1}=\\rho_{0}^{-2}, b_{1}=2$, and $(a, b)$ is replaced by $(2 a, b)$. Hence the results for $\\log \\rho_{t}^{-2}=-2 \\log \\left|\\rho_{t}\\right|$ will be identical with the results for $\\log \\left|\\widetilde{Z}_{t}^{(1)}\\right|$ under the assumptions of Theorem 2, Theorem 3, and Theorem 4 with $a(\\cdot)$ replaced by $2 a(\\cdot)$ as the only change. As a result in part (B), the quantity $\\widetilde{\\sigma}_{j}^{2}$ will be identical with the term $\\sigma_{j}^{2}$ in Theorem 2. Using Corollary 4.5 the rest parts of Theorem 5 will follow.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 22,
      "text": "# 11.3 Proof of Theorem 6 \n\nProof. Beginning with the set-up at (5.9) using differentiability of $\\beta(\\cdot)$ we observe that $h^{\\prime}(x)=\\frac{1}{\\beta(x)}, h^{\\prime \\prime}(x)=$ $-\\frac{\\beta^{\\prime}(x)}{\\beta^{2}(x)}$. Given the trajectory of $Y$ in $[0, \\mathrm{t}]$, the SDE of $X$ is defined by\n\n$$\nd X_{s}=\\left[-a\\left(Y_{s}\\right) h\\left(X_{s}\\right) \\beta\\left(X_{s}\\right)+\\frac{b^{2}\\left(Y_{s}\\right)}{2} \\beta\\left(X_{s}\\right) \\beta^{\\prime}\\left(X_{s}\\right)\\right] d t+b\\left(Y_{s}\\right) \\beta\\left(X_{s}\\right) d W_{s}, \\quad X_{0}=x_{0}\n$$\n\nApplying Ito's lemma with the transformation $h(\\cdot)$ on $X$ above yields\n\n$$\n\\begin{aligned}\nd h\\left(X_{s}\\right)= & {\\left[0+h^{\\prime}\\left(X_{s}\\right)\\left(-a\\left(Y_{s}\\right) h\\left(X_{s}\\right) \\beta\\left(X_{s}\\right)+\\frac{b^{2}\\left(Y_{s}\\right)}{2} \\beta\\left(X_{s}\\right) \\beta^{\\prime}\\left(X_{s}\\right)\\right)\\right.} \\\\\n& \\left.+\\frac{b^{2}\\left(Y_{s}\\right)}{2} h^{\\prime \\prime}\\left(X_{s}\\right) \\beta^{2}\\left(X_{s}\\right)\\right] d s+\\left(h^{\\prime}\\left(X_{s}\\right) b\\left(Y_{s}\\right) \\beta\\left(X_{s}\\right)\\right) d W_{s} \\\\\n= & -a\\left(Y_{s}\\right) h\\left(X_{s}\\right) d s+b\\left(Y_{s}\\right) d W_{s}\n\\end{aligned}\n$$\n\nNow integrating both sides with $s$ in the range $[0, t]$ yields,\n\n$$\n\\begin{aligned}\nh\\left(X_{t}\\right) & =h\\left(x_{0}\\right) e^{-\\int_{0}^{t} a\\left(Y_{s}\\right) d s}+\\int_{0}^{t} b\\left(Y_{s}\\right) e^{-\\int_{s}^{t} a\\left(Y_{r}\\right) d r} d W_{s} \\\\\n& \\stackrel{d}{=} h\\left(x_{0}\\right) \\Phi_{t}^{(a)}+\\sqrt{\\int_{0}^{t} b^{2}\\left(Y_{s}\\right) e^{-\\int_{s}^{t} 2 a\\left(Y_{r}\\right) d r} d s N} \\\\\n& =h\\left(x_{0}\\right) \\Phi_{t}^{(a)}+\\sqrt{I_{t}^{(2 a, b^{2})}} N\n\\end{aligned}\n$$\n\nfor some $N \\sim N(0,1)$ independent of $Y$, hence independent of $\\left(\\Phi_{t}^{(a)}, I_{t}^{\\left(2 a, b^{2}\\right)}\\right)$. Since $h$ does not vanish in $\\mathbb{R}$, and it is monotone, hence the inverse $h^{-1}(\\cdot)$ exists. Using representation (11.7), under Assumptions 1 and 2 using the result of Theorem 1 and continuous mapping theorem following holds:\n\n$$\n\\left(h\\left(X_{t}\\right), Y_{t}\\right) \\xrightarrow{d}\\left(\\sum_{j \\in S} \\delta_{U}(\\{j\\}) \\sqrt{Z_{j}} N, U\\right)\n$$\n\nwhere $U \\sim \\pi$ independent of $Z_{j}$ and $N \\sim N(0,1)$, where $Z_{j}$ satisfies weak solution of (3.3) with $(a, b)$ replaced by $\\left(2 a, b^{2}\\right)$. Now using the continuity of $h^{-1}(\\cdot)$ and continuous mapping theorem the result in part (A) follows.\n\nFor the rest of part (B), (C), (D) we observe that marginal evolution of the process\n\n$$\nh\\left(X_{t}\\right) \\stackrel{d}{=} h\\left(x_{0}\\right) \\Phi_{t}^{(a)}+\\sqrt{I_{t}^{\\left(2 a, b^{2}\\right)}} N\n$$\n\nresembles with $Z_{t}^{(2)}$ in Corollary 4.5 with $a_{2}=h\\left(x_{0}\\right), b_{2}=N, m=2$; hence all the results will follow by replacing $(a, b)$ by $\\left(a, b^{2}\\right)$ in Corollary 4.5 for $\\left|Z_{t}^{(2)}\\right|$.\n\nProof of Corollary 5.2 is given in the supplementary material.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 23,
      "text": "# 12 Appendix \n\nLemma 12.1. Under Assumption 1,\n\n$$\n\\lim _{t \\rightarrow \\infty} P,\\left[t-\\tau_{g_{t}^{i}}^{j}>x, Y_{t}=j\\right]=\\frac{\\mu_{j} \\sum_{k \\in S} P_{j k} \\int_{x}^{\\infty}\\left(1-F_{j k}(y)\\right) d y}{\\sum_{k \\in S} \\mu_{k} m_{k}}\n$$\n\nLemma 12.2. Under Assumptions 1 and 2 the quantities $\\log L_{0}^{j}$ and $\\left|Q_{0}^{j}\\right|$ are $O_{P}(1)$.\nLemma 12.3. (a) Suppose Assumption 1 holds and $c$. is a function defined on $\\mathbb{N}$ as (2.15) and its definition is extended to the whole $\\mathbb{R}_{\\geq 0}$ for any arbitrary slowly varying function $L(\\cdot)$. Let $g_{t}^{j}$ be defined as the number of total renewals to the state $j$, before time $t$. Then for any fixed $s>0$,\n\n$$\n\\lim _{t \\rightarrow \\infty} c_{g_{s t}^{j}}^{-1} / c_{t}^{-1} \\stackrel{a, s}{\\rightarrow}\\left(\\frac{s}{E\\left|\\mathcal{H}_{1}\\right|}\\right)^{-\\frac{1}{a}}\n$$\n\n(b) For any function $L(\\cdot)$ slowly varying at $+\\infty$, and any two functions $a_{1}(\\cdot), b_{1}(\\cdot): \\mathbb{R}_{\\geq 0} \\rightarrow \\mathbb{R}_{\\geq 0}$ such that both $a_{1}(t), b_{1}(t) \\rightarrow \\infty$ as $t \\rightarrow \\infty$ and $a_{1} \\leq b_{1}$; for any $\\epsilon>0$ there exists $t_{0, \\epsilon} \\geq 0$, such that for all $t \\geq t_{0, \\epsilon}$,\n\n$$\n(1-\\epsilon)\\left(\\frac{b_{1}(t)}{a_{1}(t)}\\right)^{-\\epsilon} \\leq \\frac{L\\left(b_{1}(t)\\right)}{L\\left(a_{1}(t)\\right)} \\leq(1+\\epsilon)\\left(\\frac{b_{1}(t)}{a_{1}(t)}\\right)^{\\epsilon}\n$$\n\n(c) For any function $L(\\cdot)$ slowly varying at $t \\rightarrow \\infty, \\lim _{t \\rightarrow \\infty} \\frac{\\log L(t)}{\\log t} \\rightarrow 0$.\n\nLemma 12.4. For any two non-negative random variables $X, Y$ one has\n\n$$\n\\log \\max \\{X, Y\\} \\stackrel{d}{=} \\max \\{\\log X, \\log Y\\}\n$$\n\nProofs of these lemmas are given in the Supplementary material.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 24,
      "text": "## References\n\n[1] Abourashchi, N. and Clacher, I. and Freeman, M.C. and Hillier, D. and Kemp, M. and Zhang, Q.(2016). Pension plan solvency and extreme market movements: A regime switching approach. The European Journal of Finance, 22 1292-1319.\n[2] Alsmeyer, G. and Buckmann, F. (2017) Stability of perpetuities in Markovian environment. Journal of Difference Equations and Applications.23(4) 699-740.\n[3] Ang, A. and Timmermann, A. (2012). Regime changes and financial markets. Annu. Rev. Financ. Econ. 4(1) 313-337.\n\n[4] Apergis, N. Gozgor, G. Lau, C. and Wang, S. (2019). Decoding the Australian electricity market: new evidence from three-regime hidden semi-Markov model. Energy Economics 78 129-142.\n[5] Asmussen, S. (2008). Applied probability and queues, 2nd ed. Springer Science \\& Business Media (Volume 51).\n[6] Behme, A. and Sideris, A. (2020) Markov-modulated generalized Ornstein-Uhlenbeck processes and an application in risk theory.arXiv preprint arXiv:2012.10712\n[7] Behme, A. and Sideris, A. (2020) Exponential functionals of Markov additive processes. Electronic Journal of Probability. 25 1-25. https://doi.org/10.1214/20-EJP441\n[8] Behme, A. and Lindner, A. (2015). On exponential functionals of L\u00e9vy processes. Journal of Theoretical Probability 28 681-720.\n[9] Benaim, M. and Lobry, C. (2016). Lotka Volterra with randomly fluctuating environments or \"how switching between beneficial environments can make survival harder.\" Annals of Applied Probability 26 3574-3785.\n[10] BenSaida, A. (2015). The frequency of regime switching in financial market volatility. Journal of empirical finance 32(C) 63-79.\n[11] Berbee, H.(1987) Chains with infinite connections: Uniqueness and Markov representation. Probability theory and related fields. 76(2) 243-253.\n[12] Bertail, P. and Ciolek, G. (2019). New Bernstein and Hoeffding type inequalities for regenerative Markov chains. ALEA, Lat. Am. J. Probab. Math. Stat. 16 259-277.\n[13] Bertoin, J. and Yor, M. (2005). Exponential functionals of L\u00e9vy processes. Probability Surveys 2 $191-212$.\n[14] Bishop, A N. Del Moral, P. Kamatani, K. and Remillard, B. (2017). On one-dimensional Riccati diffusions. arXiv preprint,arXiv:1711.10065.\n[15] Bulla, J. Bulla, Ingo. and Nenadi\u0107, O. (2010). hsmm-An R package for analyzing hidden semi-Markov models. Computational Statistics \\& Data Analysis, 54(3) 611-619.\n[16] Buraczewski, D., Damek, E., \\& Zienkiewicz, J. (2016). On the Kesten-Goldie constant. Journal of Difference Equations and Applications, 22(11) 1646-1662.\n[17] Buraczewski, D., Damek, E., and Mikosch, T. (2016). Stochastic Models with Power-Law Tails. Springer.\n[18] Callaway, M. Doan, T S. Lamb, J S. and Rasmussen, M. (2017). The dichotomy spectrum for random dynamical systems and pitchfork bifurcations with additive noise. Annales de l'Institut Henri Poincar\u00e9, Probabilit\u00e9s et Statistiques, 53(4) 1548-1574. Institut Henri Poincar\u00e9.\n[19] Cappelletti, D. and Majumder, A.P. and Wiuf, C. (2021). The dynamics of stochastic monomolecular reaction systems in stochastic environments. Stochastic Processes and their Applications, $137106-148$.\n[20] Ciniar, E. (1969). Markov renewal theory. Advances in Applied Probability. 1(2) 123-187.\n[21] Ciniar, E. (1967). Queues with semi-Markovian arrivals. Journal of Applied Probability. 365 - 379.\n[22] Ciniar, E. (1969). On semi-Markov processes on arbitrary spaces. Mathematical Proceedings of the Cambridge Philosophical Society. 66(2) 381-392.\n[23] Cloez, B. and Hairer, M. (2015). Exponential ergodicity for Markov processes with random switching. Bernoulli. 21(1) 505-536.\n[24] Djehiche, B. and L\u00f6fdahl, B. (2018). A hidden Markov approach to disability insurance. North American Actuarial Journal, 22 119-136.\n\n[25] D\u2019Amico, G. Manca, R. and Salvi, G. (2013). A semi-Markov modulated interest rate model. Statistics \\& Probability Letters 83(9) 2094-2102.\n[26] Erd\u00f6s, P. and Kac, M. (1946). On certain limit theorems of the theory of probability. Bull. Amer. Math. Society 52:292-302.\n[27] Erhardsson, T. (2014). Conditions for convergence of random coefficient AR(1) processes and perpetuities in higher dimensions. Bernoulli, 20(2) 990-1005.\n[28] Feng, R., Kuznetsov, A., and Yang, F. (2019). Exponential functionals of L\u00e9vy processes and variable annuity guaranteed benefits. Stochastic Processes and their Applications 129 604-625.\n[29] Fink, H. and Klimova, Y. and Czado, C. and St\u00f6ber, J. (2017). Regime switching vine copula models for global equity and volatility indices. Econometrics, 5 3-17.\n[30] Gao, H. and Mamon, R. and Liu, X. and Tenyakov, A. (2015). Mortality modelling with regimeswitching for the valuation of a guaranteed annuity option. Insurance: Mathematics and Economics, $63108-120$.\n[31] Genon-Catalot, V. and Jeantheau, T. and Lar\u00e9do, C. (2000). Stochastic volatility models as hidden Markov models and statistical applications. Bernoulli, 6 1051-1079.\n[32] Gjessing, H.K. and Paulsen, J. (1997). Present value distributions with applications to ruin theory and stochastic equations. Stochastic processes and their applications 71 123-144.\n[33] Graham, C.(2021). Regenerative properties of the linear Hawkes process with unbounded memory. The Annals of Applied Probability, 31(6) 2844-2863.\n[34] Gut, A. (2009). Stopped random walks. Springer.\n[35] Hairer, M. (2010). Convergence of Markov processes. Lecture notes.\n[36] Hardy, M.R.(2001). A regime-switching model of long-term stock returns. North American Actuarial Journal, 5 41-53.\n[37] Hitczenko, P. and Wesolowski, J. (2011). Renorming divergent perpetuities. Bernoulli. 17(3) $880-894$.\n[38] Hopf Bifurcation. Lecture notes, Link: https://www.mscs.dal.ca/ iron/math3260/hopf.pdf.\n[39] Hurth, T. and Kuehny, C. (2020). Random Switching near Bifurcations. Stochastics and Dynamics, 20(2) 2050008.\n[40] Iksanov, A.(2016). Renewal theory for perturbed random walks and similar processes. Springer.\n[41] Jessen, A.H. and Mikosch, T. (2006). Regularly varying functions. Publications de L'institut Mathematique, 80(94) 171-192.\n[42] Korolyuk, Vo S. Brodi, SM. and Turbin, AF. (1975). Semi-Markov processes and their applications. Journal of Soviet Mathematics. 4(3) 244-280.\n[43] Kulik, R. and Soulier, P.(2020). Heavy-tailed time series. Springer.\n[44] Kuznetsov, Y A.(2013). Elements of applied bifurcation theory. Springer Science \\& Business Media (Volume 112).\n[45] Lin, X.S. and Tan, K.S. and Yang, H. (2009). Pricing annuity guarantees under a regime-switching model. North American Actuarial Journal, 13 316-338.\n[46] Lindskog, F. and Majumder, A.P. (2020). Exact long time behavior of some regime switching stochastic processes. Bernoulli, 26(4)2572-2604.\n[47] Mao, X. and Yuan, C.(2006). Stochastic differential equations with Markovian switching. Imperial college press.\n\n[48] Maulik, K. and Zwart, B. (2006). Tail asymptotics for exponential functionals of L\u00e9vy processes. Stochastic Processes and their Applications 116 156-177.\n[49] Mikosch, T. (1999). Regular variation, subexponentiality and their applications in probability theory. 99 Eindhoven, The Netherlands: Eindhoven University of Technology.\n[50] O'Connell, J. and H\u00f8jsgaard, S.(2011). Hidden semi markov models for multiple observation sequences: The mhsmm package for R. Journal of Statistical Software, 39 1-22.\n[51] Qin, S. Tan, Z. and Wu, Y. (2024). On robust estimation of hidden semi-Markov regime-switching models. Annals of Operations Research 2024 1-33.\n[52] Resnick, S I. (1992). Adventures in stochastic processes. Springer Science \\& Business Media.\n[53] Salhi, K. Deaconu, M. Lejay, A. Champagnat, N. and Navet, N. (2016). Regime switching model for financial data: Empirical risk analysis. Physica A: Statistical Mechanics and its Applications $461148-157$.\n[54] Schilling, R L. (2005). Measures, Integrals and Martingales. Cambridge University Press.\n[55] Serfozo, R. (2009). Basics of Applied Stochastic Processes. Springer Science \\& Business Media.\n[56] Shao, J (2015) Ergodicity of regime-switching diffusions in Wasserstein distances. Stochastic Processes and their Applications, 125(2): 739-758.\nDOI: $10.1016 /$ j.spa.2014.10.007\n[57] Shen, Y. and Siu, T.K.(2013). Longevity bond pricing under stochastic interest rate and mortality with regime-switching. Insurance: Mathematics and Economics, 52 114-123.\n[58] Stenberg, F. Manca, R. and Silvestrov, D. (2007). An algorithmic approach to discrete time non-homogeneous backward semi-Markov reward processes with an application to disability insurance. Methodology and Computing in Applied Probability 9(4) 497-519.\n[59] Tijms, H C. (2003). A first course in stochastic models. John Wiley and sons\n[60] Vervaat, W. (1979). On a stochastic difference equation and a representation of non-negative infinitely divisible random variables. Advances in Applied Probability 11(4) 750-783.\n[61] Wang, S. Gupta, R. and Zhang, Y J. (2021). Bear, bull, sidewalk, and crash: the evolution of the US stock market using over a century of daily data. Finance Research Letters 43101998.\n[62] Whitt, W. (2002). Stochastic-process limits: an introduction to stochastic-process limits and their application to queues. Springer Science \\& Business Media.\n[63] Yin, G. and Zhu, C. (2010) Hybrid Switching Diffusions: Properties and Applications. Springer. DOI: 10.1007/978-1-4419-1105-6\n[64] Zhang, Z. and Tong, J. and Hu, L. (2016) Long-term behavior of stochastic interest rate models with Markov switching. Insurance: Mathematics and Economics, 70: 320-326. DOI: 10.1016/j.insmatheco.2016.06.017\n[65] Zhang, Z. and Wang, W. (2017). The stationary distribution of Ornstein-Uhlenbeck process with a two-state Markov switching. Communications in Statistics-Simulation and Computation 46 47834794 .",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 25,
      "text": "# 13 Supplementary materials of \"Long time behavior of semiMarkov modulated perpetuity and some related processes\" \n\nThe supplementary section contains the proofs of\n\n- Lemma 9.2 (a)(b) of Theorem 1;\n- Theorem 2;\n- Lemma 10.1, Lemma 10.3 and Lemma 10.2 of Theorem 3;\n- proofs of results in Remark 4.2, Proposition 4.4;\n- Theorem 4;\n- Lemma 11.1(a)(b) of Corollary 4.5; Corollary 5.2, and the results in the Appendix appearing in the main article.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 26,
      "text": "## 14 Proof of supplementary results of Theorem 1\n\nWe prove Lemma 9.2 here.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 27,
      "text": "### 14.1 Proof of Lemma 9.2(a)\n\nWe prove this lemma by showing\n\n- Step 1: $R_{t}^{(1)}$ and absolute value of first term of $R_{t}^{(2)}$ both will converge to 0 in probability as $t \\rightarrow \\infty$,\n- Step 2: $P_{g_{t}^{j}}^{j} \\xrightarrow{d} V_{j}^{*}$ where $V_{j}^{*}$ is defined in (3.3), (3.4) (i.e second term of $R_{t}^{(2)}$ will converge to the solution of SRE),\nand as a consequence of Slutsky's theorem, the assertion of this lemma holds.\nTo show Step 1, observe that $R_{t}^{(1)}$ and first term of $R_{t}^{(2)}$ are respectively\n\n$$\n\\left(\\exp \\left\\{t\\left(\\frac{\\sum_{t=1}^{g_{t}} \\log L_{t}^{j}}{g_{t}}+\\frac{\\log L_{0}^{j}}{g_{t}}\\right) \\frac{g_{t}}{t}\\right\\}, \\exp \\left\\{t\\left(\\frac{\\sum_{t=1}^{g_{t}} \\log L_{t}^{j}}{g_{t}}+\\frac{\\log \\left|Q_{0}^{j}\\right|}{g_{t}}\\right) \\frac{g_{t}}{t}\\right\\}\\right)\n$$\n\nA consequence of renewal theorem, law of large number (validated under Assumption 1) will give that\n\n$$\n\\frac{\\sum_{t=1}^{g_{t}} \\log L_{t}^{j}}{g_{t}} \\xrightarrow{p} E_{\\pi} \\log L_{t}^{j}=-E\\left|\\mathcal{F}_{1}^{j}\\right| E_{\\pi} a(\\cdot)<0 \\quad \\text { and } \\quad \\frac{g_{t}}{t} \\xrightarrow{a . g} \\frac{1}{E\\left|\\mathcal{F}_{1}^{j}\\right|}\n$$\n\nSince $\\log L_{0}^{j},\\left|Q_{0}^{j}\\right|$ are both $O_{\\nu}(1)$ a consequence of Lemma 12.2, both of $\\frac{\\log L_{0}^{j}}{g_{t}}, \\frac{\\log \\left|Q_{0}^{j}\\right|}{g_{t}}$ will go to 0 in probability. This implies as $t \\rightarrow \\infty$,\n\n$$\n\\left(\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) L_{0}^{j},\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right)\\left|Q_{0}^{j}\\right|\\right) \\xrightarrow{P}(0,0)\n$$\n\nLemma 14.1. Step 2 holds under assumptions of Theorem 1, i.e under Assumptions 1 and 2, $P_{g_{t}^{j}}^{j} \\xrightarrow{d} V_{j}^{*}$ as $t \\rightarrow \\infty$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 28,
      "text": "# 14.1.1 Proof of Lemma 14.1 \n\nProof. Define $P_{\\infty}^{j}:=\\sum_{k=1}^{\\infty}\\left(\\prod_{i=1}^{k-1} L_{i}^{j}\\right) Q_{k}^{j}$, and we show that $P_{g_{l}^{j}}^{j} \\xrightarrow{P} P_{\\infty}^{j}$ and $P_{\\infty}^{j}$ satisfies unique solution of SRE that is identical as $\\mathcal{L}\\left(V_{j}^{*}\\right)$ (defined in (3.3), (3.4)). Note that\n\n$$\nP_{\\infty}^{j}=\\sum_{k=1}^{\\infty}\\left(\\prod_{i=1}^{k-1} L_{i}^{j}\\right) Q_{k}^{j}=Q_{1}^{j}+L_{1}^{j}\\left(\\sum_{k=2}^{\\infty}\\left(\\prod_{i=2}^{k-1} L_{i}^{j}\\right) Q_{k}^{j}\\right)\n$$\n\nNow since $\\left(L_{1}^{j}, Q_{1}^{j}\\right) \\perp\\left\\{\\left(L_{i}^{j}, Q_{i}^{j}\\right): i \\geq 2\\right\\}$, it follows that the second term inside first bracket of RHS $\\sum_{k=2}^{\\infty}\\left(\\prod_{i=2}^{k-1} L_{i}^{j}\\right) Q_{k}^{j} \\stackrel{d}{=} P_{\\infty}^{j}$ and also $\\left(L_{1}^{j}, Q_{1}^{j}\\right) \\perp \\sum_{k=2}^{\\infty}\\left(\\prod_{i=2}^{k-1} L_{i}^{j}\\right) Q_{k}^{j}$, it follows that $P_{\\infty}^{j}$ satisfies the SRE at (3.3). Now since under Assumption 2\n\n$$\nE \\log \\left|L_{1}^{j}\\right|=-E\\left|\\mathfrak{I}_{1}^{j}\\right| E_{\\pi} a(\\cdot)<0, \\quad \\text { and } \\quad E \\log ^{+}\\left|Q_{1}^{j}\\right|<\\infty\n$$\n\nit follows that the solution to the $\\operatorname{SRE} X \\stackrel{d}{=} Q_{1}^{j}+L_{1}^{j} X$ is unique in distribution (Lemma 1.4(a) and Vervaat's Theorem 1.5 in [60]). So it follows that $\\mathcal{L}\\left(P_{\\infty}^{j}\\right)=\\mathcal{L}\\left(V_{j}^{*}\\right)$ in (3.3), (3.4).\nObserve that for any $t>0$,\n\n$$\n\\begin{aligned}\nP_{\\infty}^{j}-P_{g_{l}^{j}}^{j} & =\\left(\\prod_{i=1}^{g_{l}^{j}} L_{i}^{j}\\right)\\left[\\sum_{k=g_{l}^{j}+1}^{\\infty}\\left(\\prod_{i=g_{l}^{j}+1}^{k-1} L_{i}^{j}\\right) Q_{k}^{j}\\right] \\\\\n& =\\exp \\left\\{t\\left(\\frac{\\sum_{i=1}^{g_{t}} \\log L_{i}^{j}}{g_{t}}\\right) \\frac{g_{t}^{j}}{t}\\right\\}\\left[\\sum_{k=g_{l}^{j}+1}^{\\infty}\\left(\\prod_{i=g_{l}^{j}+1}^{k-1} L_{i}^{j}\\right) Q_{k}^{j}\\right]\n\\end{aligned}\n$$\n\nAs $t \\rightarrow \\infty$, using (14.1) the first term $\\prod_{i=1}^{g_{l}^{j}} L_{i}^{j} \\xrightarrow{P} 0$. To prove the assertion, we prove that the second term (in the RHS above) is $O_{P}(1)$. Observe that for any $t \\geq 0$,\n\n$$\n\\left(\\left(L_{g_{l}^{j}+1}^{j}, Q_{g_{l}^{j}+1}^{j}\\right),\\left(L_{g_{l}^{j}+2}^{j}, Q_{g_{l}^{j}+2}^{j}\\right), \\ldots\\right) \\stackrel{d}{=}\\left(\\left(L_{1}^{j}, Q_{1}^{j}\\right),\\left(L_{2}^{j}, Q_{2}^{j}\\right), \\ldots\\right)\n$$\n\nwhich follows by conditioning w.r.t $g_{t}^{j}$ and using argument similar to Proposition 2.2 (ii). A consequence of (14.2) gives\n\n$$\nP_{\\infty}^{j} \\stackrel{d}{=} \\sum_{k=g_{l}^{j}+1}^{\\infty}\\left(\\prod_{i=g_{l}^{j}+1}^{k-1} L_{i}^{j}\\right) Q_{k}^{j}=Q_{g_{t}+1}^{j}+L_{g_{t}+1}^{j}\\left(Q_{g_{t}+2}^{j}+L_{g_{t}+2}^{j}(\\ldots)\\right)\n$$\n\nand since distribution of $P_{\\infty}^{j}$ uniquely exists under Assumption 2, the random quantity $\\sum_{k=g_{l}^{j}+1}^{\\infty}\\left(\\prod_{i=g_{l}^{j}+1}^{k-1} L_{i}^{j}\\right) Q_{k}^{j}$ is $O_{\\rho}(1)$, proving our assertion.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 29,
      "text": "### 14.2 Proof of Lemma 9.2(b)\n\nSince first term of $R_{t}^{(2)}$ i.e $\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) Q_{0}^{j} \\xrightarrow{P} 0$ as $t \\rightarrow \\infty$. The assertion holds if we show (6.1) of Lemma 6.1 with $P_{g_{l}^{j}}^{j}$ as $H_{t}$. Note that from Lemma 9.2(a) it follows that unconditionally $P_{g_{l}^{j}}^{j} \\xrightarrow{d} V_{j}^{*}$, so we can take $V_{j}^{*}$ as $H_{\\infty}$ in (6.1). We are only left to prove $P_{g_{l}^{j}}^{j}-P_{g_{l-\\epsilon(t)}}^{j} \\xrightarrow{P} 0$ for some function $\\epsilon(\\cdot)$ such that $\\epsilon(t) \\rightarrow \\infty$ and $\\frac{\\epsilon(t)}{t} \\rightarrow 0$ as $t \\rightarrow \\infty$.\n\n$$\n\\begin{aligned}\nP_{g_{t}^{j}}^{j}-P_{g_{t-\\epsilon(t)}^{j}}^{j} & =\\sum_{k=1}^{g_{t}^{j}}\\left(\\prod_{i=1}^{k-1} L_{i}^{j}\\right) Q_{k}^{j}-\\sum_{k=1}^{g_{t-\\epsilon(t)}^{j}}\\left(\\prod_{i=1}^{k-1} L_{i}^{j}\\right) Q_{k}^{j} \\\\\n& =\\left(\\prod_{i=1}^{g_{t-\\epsilon(t)}^{j}} L_{i}^{j}\\right)\\left[\\sum_{k=g_{t-\\epsilon(t)}^{j+1}}^{g_{t}^{j}}\\left(\\prod_{i=g_{t-\\epsilon(t)}^{j+1}}^{k-1} L_{i}^{j}\\right) Q_{k}^{j}\\right]\n\\end{aligned}\n$$\n\nObserve that absolute value of second term of the product in (14.4) can be bounded by\n\n$$\n\\begin{aligned}\n\\left|\\sum_{k=g_{t-\\epsilon(t)}^{j}+1}^{g_{t}^{j}}\\left(\\prod_{i=g_{t-\\epsilon(t)}^{j+1}+1}^{k-1} L_{i}^{j}\\right) Q_{k}^{j}\\right| & \\leq \\sum_{k=g_{t-\\epsilon(t)}^{j+1}+1}^{g_{t}^{j}}\\left(\\prod_{i=g_{t-\\epsilon(t)}^{j+1}+1}^{k-1} L_{i}^{j}\\right)\\left|Q_{k}^{j}\\right| \\\\\n& \\leq \\sum_{k=g_{t-\\epsilon(t)}^{j+1}+1}^{\\infty}\\left(\\prod_{i=g_{t-\\epsilon(t)}^{j+1}+1}^{k-1} L_{i}^{j}\\right)\\left|Q_{k}^{j}\\right|\n\\end{aligned}\n$$\n\nNote that $\\sum_{k=g_{t-\\epsilon(t)}^{j}+1}^{\\infty}\\left(\\prod_{i=g_{t-\\epsilon(t)}^{j+1}+1}^{k-1} L_{i}^{j}\\right)\\left|Q_{k}^{j}\\right| \\stackrel{d}{=} \\sum_{k=1}^{\\infty}\\left(\\prod_{i=1}^{k-1} L_{i}^{j}\\right)\\left|Q_{k}^{j}\\right|$ (using ideas similar to (14.2) and (14.3)) which satisfies the unique solution of the SRE\n\n$$\nX=L_{1}^{j} X+\\left|Q_{1}^{j}\\right|, \\quad X \\perp\\left(L_{1}^{j}, Q_{1}^{j}\\right)\n$$\n\nunder conditions $E \\log L_{k}^{j}=-E\\left|\\mathfrak{I}_{1}^{j}\\right| E_{\\pi} a(\\cdot)<0, E \\log ^{+}\\left|Q_{k}^{j}\\right|<\\infty$ ensured by Assumption 2. This implies that second term of the product in (14.4) is $O_{P}(1)$.\n\nObserve that first term in the product of (14.4) is\n\n$$\n\\left(\\prod_{i=1}^{g_{t-\\epsilon(t)}^{j}} L_{i}^{j}\\right)=\\exp \\left\\{(t-\\epsilon(t))\\left(\\frac{\\sum_{i=1}^{g_{t-\\epsilon(t)}} \\log L_{i}^{j}}{g_{t-\\epsilon(t)}}\\right) \\frac{g_{t-\\epsilon(t)}^{j}}{t-\\epsilon(t)}\\right\\}\n$$\n\nA consequence of Renewal Theorem and Law of large number leads to (14.1) with $t$ replaced by $t-\\epsilon(t)$ and as $t-\\epsilon(t) \\rightarrow \\infty$, one has $\\prod_{i=1}^{g_{t-\\epsilon(t)}^{j}} L_{i}^{j} \\xrightarrow{P} 0$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 30,
      "text": "# 15 Proof of Theorem 2\n### 15.1 Proof of Theorem 2(a)\n\nWe begin with $I_{t}^{(a, b)}=\\Phi_{t}^{(a)} \\widetilde{I}_{t}^{(a, b)}$ where $\\widetilde{I}_{t}^{(a, b)}=\\int_{0}^{t} b\\left(Y_{s}\\right) e^{\\int_{0}^{\\tau} u\\left(Y_{r}\\right) d r} d s$. Fix arbitrary $i, j \\in S$. Observe that on $\\left\\{Y_{0}=i, Y_{t}=j\\right\\}$ using renewal regenerative structure of $Y$ (as a consequence of Assumption 1)\n\n$$\n\\Phi_{t}^{(a)}=L_{0}^{j}\\left(\\prod_{i=1}^{g_{t}^{j}} L_{i}^{j}\\right) e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}\\right)}, \\quad \\widetilde{I}_{t}^{(a, b)}=\\left[\\frac{Q_{0}^{j}+S_{g_{t}^{j}}^{* *}}{L_{0}^{j}}+\\frac{G_{j}^{(a, b)}\\left(t-\\tau_{g_{t}^{j}}\\right)}{\\Phi_{t}^{(a)}}\\right]\n$$\n\nwhere for any integer $n \\geq 1, \\quad S_{n}^{* *}:=P_{n}\\left(\\frac{1}{L_{1}^{j}}, \\frac{Q_{1}^{j}}{L_{1}^{j}}\\right)=\\sum_{i=1}^{n} \\frac{Q_{i}^{j}}{L_{i}^{j}} \\prod_{k=1}^{i-1}\\left(\\frac{1}{L_{k}^{j}}\\right)$.\n\nLet $G_{t}^{(1)}, G_{t}^{(2)}, G_{t}^{(3)}$ be defined as\n\n$$\n\\begin{aligned}\n& G_{t}^{(1)}=\\frac{\\left(\\prod_{i=1}^{g_{t}^{j}} L_{i}^{j}\\right)^{\\frac{1}{\\sqrt{t}}}}{e^{-\\sqrt{t} E_{\\pi} a(\\cdot)}}, \\quad G_{t}^{(2)}=\\left[L_{0}^{j} e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right.}\\right]^{\\frac{1}{\\sqrt{t}}} \\\\\n& G_{t}^{(3)}=\\left[\\frac{Q_{0}^{j}+S_{g_{t}^{j}}^{* *}}{L_{0}^{j}}+\\frac{G_{j}^{(a, b)}\\left(t-\\tau_{g_{t}^{j}}\\right)}{\\Phi_{t}^{(a)}}\\right]^{\\frac{1}{\\sqrt{t}}}\n\\end{aligned}\n$$\n\nObserve that\n\n$$\n\\mathcal{L}\\left(\\left|\\widetilde{I}_{t}^{(a, b)}\\right|^{\\frac{1}{\\sqrt{t}}}\\left|Y_{0}=i, Y_{t}=j\\right)=\\mathcal{L}\\left(G_{t}^{(3)} \\mid Y_{0}=i, Y_{t}=j\\right)\\right.\n$$\n\nand\n\n$$\n\\begin{aligned}\n\\mathcal{L} & \\left(\\left(\\frac{\\left[\\Phi_{t}^{(a)}\\right]^{\\frac{1}{\\sqrt{t}}}}{e^{-\\sqrt{t} E_{\\pi} a(\\cdot)}}, \\frac{\\left|I_{t}^{(a, b)}\\right|^{\\frac{1}{\\sqrt{t}}}}{e^{-\\sqrt{t} E_{\\pi} a(\\cdot)}}\\right)\\left|Y_{0}=i, Y_{t}=j\\right)\\right. \\\\\n& =\\mathcal{L}\\left(\\left(G_{t}^{(1)} G_{t}^{(2)}, G_{t}^{(1)} G_{t}^{(2)} G_{t}^{(3)}\\right) \\mid Y_{0}=i, Y_{t}=j\\right)\n\\end{aligned}\n$$\n\nFor any $A_{1}, A_{2} \\in \\mathcal{B}\\left(\\mathbb{R}_{\\geq 0}\\right)$,\n\n$$\n\\begin{aligned}\n& P\\left[\\left(\\frac{\\left[\\Phi_{t}^{(a)}\\right]^{\\frac{1}{\\sqrt{t}}}}{e^{-\\sqrt{t} E_{\\pi} a(\\cdot)}}, \\frac{\\left|I_{t}^{(a, b)}\\right|^{\\frac{1}{\\sqrt{t}}}}{\\left.e^{-\\sqrt{t} E_{\\pi} a(\\cdot)}\\right)} \\in A_{1} \\times A_{2} \\mid Y_{0}=i\\right]\\right. \\\\\n& =\\sum_{j \\in S} P\\left[\\left(\\frac{\\left[\\Phi_{t}^{(a)}\\right]^{\\frac{1}{\\sqrt{t}}}}{e^{-\\sqrt{t} E_{\\pi} a(\\cdot)}}, \\frac{\\left|I_{t}^{(a, b)}\\right|^{\\frac{1}{\\sqrt{t}}}}{e^{-\\sqrt{t} E_{\\pi} a(\\cdot)}}\\right) \\in A_{1} \\times A_{2}, Y_{t}=j \\mid Y_{0}=i\\right] \\\\\n& =\\sum_{j \\in S} P\\left[Y_{t}=j \\mid Y_{0}=i\\right] P\\left[\\left(G_{t}^{(1)} G_{t}^{(2)}, G_{t}^{(1)} G_{t}^{(2)} G_{t}^{(3)}\\right) \\in A_{1} \\times A_{2} \\mid Y_{0}=i, Y_{t}=j\\right] .\n\\end{aligned}\n$$\n\nAs a consequence of the Ergodic theorem and Renewal theorem,\n\n$$\nE \\log L_{1}^{j}=-E\\left|\\mathfrak{I}_{1}^{j}\\right| E_{\\pi} a(\\cdot), \\quad \\& \\quad \\frac{g_{t}^{j}}{t} \\stackrel{a, \\sigma}{\\rightarrow} \\frac{1}{E\\left|\\mathfrak{I}_{1}^{j}\\right|} \\text { as } t \\rightarrow \\infty\n$$\n\nApplying Central Limit Theorem for the renewal reward process $\\left(\\sum_{k=1}^{g_{t}^{j}} \\log L_{k}^{j}: t \\geq 0\\right)$, with the reward $\\log L_{k}^{j}$ for the $k$-th interval $\\mathfrak{I}_{k}^{j}$ (see Theorem 2.2.5 of [59]), with the continuous mappling theorem using the map $x \\rightarrow e^{x}$, with $N \\sim N(0,1)$,\n\n$$\n\\mathcal{L}\\left(G_{t}^{(1)} \\mid Y_{0}=i\\right) \\xrightarrow{w} \\mathcal{L}\\left(\\operatorname{exp}\\left\\{\\frac{\\sigma_{j}}{\\sqrt{E\\left|\\mathfrak{I}_{k}^{j}\\right|}} N\\right\\}\\right)\n$$\n\nUsing arguments similar to step 2 of Lemma 9.2(a) in Theorem 1, with the conditions (i.e, $E_{\\pi} a(\\cdot)<0 \\&$ Assumption 3(c))\n\n$$\nE\\left[\\frac{1}{L_{i}^{j}}\\right]<0, \\quad E \\log ^{+}\\left(\\frac{Q_{i}^{j}}{L_{i}^{j}}\\right)<\\infty\n$$\n\none finds that $S_{g_{t}^{j}}^{* *} \\rightarrow S^{* *}$ as $t \\rightarrow \\infty$, where\n\n$$\nS^{* *} \\stackrel{d}{=} \\frac{1}{L_{i}^{j}} S^{* *}+\\frac{Q_{i}^{j}}{L_{i}^{j}}, \\quad S^{* *} \\perp\\left(\\frac{1}{L_{i}^{j}}, \\frac{Q_{i}^{j}}{L_{i}^{j}}\\right)\n$$\n\nObserve further, that in the transient regime, as $t \\rightarrow \\infty$,\n\n$$\n\\frac{\\log \\Phi_{t}^{(a)}}{t} \\rightarrow-E_{\\pi} a(\\cdot)\n$$\n\nshowing that $\\Phi_{t}^{(a)}$ diverges exponentially fast as $t \\rightarrow \\infty$. Also, under Assumption $1 G_{j}^{(a, b)}\\left(t-\\tau_{g_{t}^{j}}\\right)$ is $O_{p}(1)$ and using $S_{g_{t}^{i}}^{* *} \\rightarrow S^{* *}$, as $t \\rightarrow \\infty$\n\n$$\n\\mathcal{L}\\left(\\left(G_{t}^{(3)}\\right)^{\\sqrt{t}} \\mid Y_{0}=i\\right) \\xrightarrow{w} \\mathcal{L}\\left(\\frac{Q_{0}^{j}+S^{* *}}{L_{0}^{j}}\\right)\n$$\n\nand this further implies that\n\n$$\n\\mathcal{L}\\left(G_{t}^{(3)} \\mid Y_{0}=i\\right) \\xrightarrow{w} \\delta_{\\{1\\}} \\quad \\text { as } \\quad t \\rightarrow \\infty\n$$\n\nSince $G_{t}^{(2)}=e^{\\frac{\\log L_{0}^{j}}{\\sqrt{t}}-a(j) \\frac{\\left(t-\\tau_{g_{t}^{j}}\\right)}{\\sqrt{t}}}$, and both $L_{0}^{j},\\left(t-\\tau_{g_{t}^{j}}\\right)$ are $O_{p}(1)$, as $t \\rightarrow \\infty$\n\n$$\n\\mathcal{L}\\left(G_{t}^{(2)} \\mid Y_{0}=i\\right) \\xrightarrow{w} \\delta_{\\{1\\}}\n$$\n\nCombining (15.3), (15.6), (15.7) and taking\n\n$$\nL_{t}^{(1)}=(0,0)^{\\prime}, \\quad L_{t}^{(2)}=\\left(\\begin{array}{cc}\nG_{t}^{(2)} & 0 \\\\\n0 & G_{t}^{(2)} G_{t}^{(3)}\n\\end{array}\\right), \\quad H_{t}=\\binom{G_{t}^{(1)}}{G_{t}^{(1)}}\n$$\n\nin Lemma 6.1 as $t \\rightarrow \\infty$,\n\n$$\n\\begin{aligned}\n& \\mathcal{L}\\left(G_{t}^{(1)} G_{t}^{(2)}, G_{t}^{(1)} G_{t}^{(2)} G_{t}^{(3)} \\mid Y_{0}=i, Y_{t}=j\\right) \\\\\n& \\quad \\xrightarrow{w} \\mathcal{L}\\left(\\exp \\left(\\frac{\\sigma_{j}}{\\sqrt{E\\left|\\mathfrak{I}_{k}^{j}\\right|}} N\\right), \\exp \\left\\{\\frac{\\sigma_{j}}{\\sqrt{E\\left|\\mathfrak{I}_{k}^{j}\\right|}} N\\right\\}\\right)\n\\end{aligned}\n$$\n\ngiven $H_{t}$ satisfies the condition (6.1), which holds if $G_{t}^{(1)}$ satisfies (6.1). This holds if $\\log G_{t}^{(1)}$ satisfies $(6.1)$,\n\n$$\n\\log G_{t}^{(1)}-\\log G_{t-\\epsilon(t)}^{(1)} \\xrightarrow{P} 0, \\quad \\text { as } \\quad t \\rightarrow \\infty\n$$\n\nfor some $\\epsilon(\\cdot)$ such that $\\frac{\\epsilon(t)}{t} \\rightarrow 0$ which follows from Lemma 15.1.\nIt follows that, using $\\log (\\cdot)$ transformation on both sides of (15.2)\n\n$$\n\\begin{aligned}\nP[ & \\left(\\frac{\\log \\Phi_{t}^{(a)}+t E_{\\pi} a(\\cdot)}{\\sqrt{t}}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|+t E_{\\pi} a(\\cdot)}{\\sqrt{t}}\\right) \\in A_{1} \\times A_{2} \\mid Y_{0}=i] \\\\\n= & \\sum_{j \\in S} P\\left[\\left(\\log \\left(G_{t}^{(1)} G_{t}^{(2)}\\right), \\log \\left(G_{t}^{(1)} G_{t}^{(2)} G_{t}^{(3)}\\right)\\right) \\in A_{1} \\times A_{2} \\mid Y_{0}=i, Y_{t}=j\\right] \\\\\n& \\times P\\left[Y_{t}=j \\mid Y_{0}=i\\right]\n\\end{aligned}\n$$\n\nObserve that $P\\left[Y_{t}=j \\mid Y_{0}=i\\right] \\rightarrow \\pi_{j}$, and taking $\\log (\\cdot)$ transformation in both co-ordinates of (15.8) desired limit of each term inside the sum will be obtained. Applying the dominated convergence theorem using the trivial upper bound 1 , for the first term in the above sum completes the proof. Finally taking the $t \\rightarrow \\infty$ limit, the assertion will follow.\nLemma 15.1. There exists an increasing function $t \\rightarrow \\epsilon(t)$ such that $\\epsilon(t) \\rightarrow \\infty$ and $\\frac{\\epsilon(t)}{t} \\rightarrow 0$ as $t \\rightarrow \\infty$, such that (15.9) holds for $\\log G_{t}^{(1)}$.\n\nProof. Take $\\varepsilon(t):=\\sqrt{t}$. Define $\\widetilde{G}_{t}^{(1)}:=\\sum_{i=1}^{g_{t}^{j}}\\left(Y_{i}^{*}-Z_{i}^{*}\\right) / \\sqrt{t}$, where\n\n$$\nY_{k}^{*}:=\\log L_{k}^{j}-E \\log L_{k}^{j}, \\quad Z_{k}^{*}:=\\left(\\left|\\mathfrak{I}_{k}^{j}\\right|-E\\left|\\mathfrak{I}_{k}^{j}\\right|\\right) E_{\\pi} a(\\cdot)\n$$\n\nfor $k=1, \\ldots, g_{t}^{j}$ are two sequences of random variables with zero means. Note that it is sufficient to prove condition (15.9) for $\\widetilde{G}_{t}^{(1)}$ since\n\n$$\n\\begin{aligned}\n\\log G_{t}^{(1)} & =\\frac{\\sum_{i=1}^{g_{t}^{j}} \\log L_{i}^{j}-t E_{\\pi} a(\\cdot)}{\\sqrt{t}} \\\\\n& =\\widetilde{G}_{t}^{(1)}-\\frac{\\left[\\tau_{0}+\\left(t-\\tau_{g_{t}^{j}}\\right)\\right] E_{\\pi} a(\\cdot)}{\\sqrt{t}}\n\\end{aligned}\n$$\n\nand the second term in the right-hand side above is $o_{P}(1)$. Now observe\n\n$$\n\\begin{aligned}\n\\widetilde{G}_{t}^{(1)}-\\widetilde{G}_{t-\\sqrt{t}}^{(1)}= & \\frac{\\sum_{i=1}^{g_{t-\\sqrt{t}}^{j}} Y_{i}^{*}}{\\sqrt{t}}\\left[1-\\left(1-\\frac{1}{\\sqrt{t}}\\right)^{-1 / 2}\\right]+\\frac{\\sum_{i=g_{t-\\sqrt{t}}^{j}}^{g_{t}^{j}} Y_{i}^{*}}{\\sqrt{t}} \\\\\n& -\\frac{\\sum_{i=1}^{g_{t-\\sqrt{t}}^{j}} Z_{i}^{*}}{\\sqrt{t}}\\left[1-\\left(1-\\frac{1}{\\sqrt{t}}\\right)^{-1 / 2}\\right]-\\frac{\\sum_{i=g_{t-\\sqrt{t}}^{j}}^{g_{t}^{j}} Z_{i}^{*}}{\\sqrt{t}}\n\\end{aligned}\n$$\n\nUsing the asymptotic approximation\n\n$$\n\\left(1-\\frac{1}{\\sqrt{t}}\\right)^{-1 / 2}=1+\\frac{1}{2 \\sqrt{t}}+O\\left(t^{-1}\\right)\n$$\n\nshows that\n\n$$\n\\frac{\\sum_{i=1}^{g_{t-\\sqrt{t}}^{j}} Y_{i}^{*}}{\\sqrt{t}}\\left[1-\\left(1-\\frac{1}{\\sqrt{t}}\\right)^{-1 / 2}\\right]=-\\frac{\\sum_{i=1}^{g_{t-\\sqrt{t}}^{j}} Y_{i}^{*}}{2 t}+o_{\\rho}\\left(t^{-1 / 2}\\right) \\xrightarrow{P}-\\frac{E Y_{k}^{*}}{2 E\\left|\\mathfrak{I}_{1}^{j}\\right|}=0\n$$\n\nby the renewal version of the law of large numbers. Also $\\frac{\\sum_{i=1}^{g_{t-\\sqrt{t}}^{j}} Z_{i}^{*}}{\\sqrt{t}}\\left[1-\\left(1-\\frac{1}{\\sqrt{t}}\\right)^{-1 / 2}\\right] \\xrightarrow{P} 0$ holds similarly. By a similar argument as $t \\rightarrow \\infty$,\n\n$$\n\\begin{aligned}\n& \\frac{\\sum_{i=g_{t-\\sqrt{t}}^{j}}^{g_{t}^{j}} Y_{i}^{*}}{\\sqrt{t}}=\\frac{\\sum_{i=g_{t-\\sqrt{t}}^{j}}^{g_{t}^{j}} Y_{i}^{*}}{g_{t}^{j}-g_{t-\\sqrt{t}}^{j}} \\frac{g_{t}^{j}-g_{t-\\sqrt{t}}^{j}}{\\sqrt{t}} \\xrightarrow{\\text { a.s. }} \\frac{1}{E\\left|\\mathfrak{I}_{1}^{j}\\right|} E Y_{k}^{*}=0, \\quad \\text { and } \\\\\n& \\frac{\\sum_{i=g_{t-\\sqrt{t}}^{j}}^{g_{t}^{j}} Z_{i}^{*}}{\\sqrt{t}} \\quad \\xrightarrow{\\text { a.s. }} \\frac{E Z_{k}^{*}}{E\\left|\\mathfrak{I}_{1}^{j}\\right|}=0 .\n\\end{aligned}\n$$\n\nThe verification is complete.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 31,
      "text": "# 15.2 Proof of Theorem 2(b) \n\nProof. We will expand $I_{t}^{(a, b)}$ in a different manner than in Theorem 2(a), but before that we set few ideas and notations regarding random walk with zero drift. Fix $i, j \\in S$. Given $E_{\\pi} a(\\cdot)=0$, the random walk generated by the process $\\left(\\sum_{k=1}^{n} \\log L_{k}^{j}: n \\geq 1\\right)$ has zero drift as the $k$-th increment $\\log L_{k}^{j}=$ $-\\int_{\\tau_{i-1}^{j}}^{T_{s}^{j}} a\\left(Y_{s}\\right) d s$ has mean 0 and following variance\n\n$$\n\\operatorname{Var}\\left(\\log L_{k}^{j}\\right)=\\operatorname{Var}\\left(-\\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}} a\\left(Y_{s}\\right) d s\\right)=\\sigma_{j}^{2} \\quad\\left(\\text { since } E_{\\pi} a(\\cdot)=0\\right)\n$$\n\nLet\n\n$$\nS_{n}^{\\otimes j}:=\\sum_{i=1}^{n} \\log L_{i}^{j}, \\quad M_{n}^{\\otimes j}:=\\max _{1 \\leq k \\leq n}\\left\\{\\sum_{i=1}^{k} \\log L_{i}^{j}\\right\\}, \\quad \\text { and } \\quad Z_{n}^{\\otimes j}:=\\max _{1 \\leq k \\leq n}\\left\\{\\left(\\prod_{i=1}^{k-1} L_{i}^{j}\\right)\\left|Q_{k}^{j}\\right|\\right\\}\n$$\n\nObserve that on $\\left\\{Y_{0}=i, Y_{t}=j\\right\\}$, using (9.1)\n\n$$\n\\begin{aligned}\n& \\left(\\log \\Phi_{t}^{(a)}, \\log \\left|I_{t}^{(a, b)}\\right|\\right) \\stackrel{\\mathcal{L}\\left(\\cdot \\mid Y_{0}=i, Y_{t}=j\\right)}{=}\\left(\\log L_{0}^{j}+\\log \\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right)+\\log \\left(e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\right)\\right. \\\\\n& \\log \\left|e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left[\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) Q_{0}^{j}+\\widetilde{P}_{g_{t}^{j}}^{j}\\right]+G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right| \\right) \\\\\n& \\stackrel{d}{=}\\left(S_{g_{t}^{\\otimes j}}^{\\otimes j}+\\left[\\log L_{0}^{j}-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right]\\right. \\\\\n& \\left.\\log Z_{g_{t}^{j}}^{\\otimes j}+\\log \\left|B_{t}^{(1)}+\\frac{B_{t}^{(2)}}{Z_{g_{t}^{j}}^{\\otimes j}} P_{g_{t}^{j}}^{j}\\right|\\right)\n\\end{aligned}\n$$\n\nwhere\n\n$$\n\\begin{aligned}\n& B_{t}^{(1)}=\\frac{e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) Q_{0}^{j}+G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}{Z_{g_{t}^{j}}^{\\otimes j}} \\\\\n& B_{t}^{(2)}=e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\n\\end{aligned}\n$$\n\nand denote $\\left(B_{t}^{(1)}+\\frac{B_{t}^{(2)}}{Z_{g_{t}^{j}}^{\\otimes j}} P_{g_{t}^{j}}^{j}\\right)$ by $B_{t}^{(3)}$. We now consider the scaled limit of $\\left(\\frac{\\log \\Phi_{t}^{(a)}}{\\sqrt{t}}\\right), \\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{\\sqrt{t}}$ ) as $t \\rightarrow \\infty$.\nObserve that both $B_{t}^{(1)}, B_{t}^{(2)}$ are $O_{p}(1)$, and for each $1 \\leq k \\leq n$,\n\n$$\n-Z_{n}^{\\otimes j} \\leq Q_{k}^{j}\\left(\\prod_{i=1}^{k-1} L_{i}^{j}\\right) \\leq Z_{n}^{\\otimes j}\n$$\n\nThis implies that $-n Z_{n}^{\\otimes j} \\leq P_{n}^{j} \\leq n Z_{n}^{\\otimes j}$, for all $n \\geq 1$, which further implies that $\\left|\\frac{P_{n}^{j}}{Z_{g_{t}^{j}}^{\\otimes j}}\\right| \\leq g_{t}^{j}$; hence $\\left|B_{t}^{(3)}\\right|=O_{p}(t)$ and strictly positive. Hence as $t \\rightarrow \\infty$,\n\n$$\n\\frac{\\log \\left|B_{t}^{(3)}\\right|}{\\sqrt{t}}=\\frac{\\log \\left|B_{t}^{(1)}+\\frac{B_{t}^{(2)}}{Z_{g_{t}^{\\otimes j}}^{\\otimes j}} P_{g_{t}^{j}}^{j}\\right|}{\\sqrt{t}} \\xrightarrow{P_{n}} 0\n$$\n\nConsider the probability,\n\n$$\n\\begin{aligned}\n& P\\left[\\left(\\frac{\\log \\Phi_{t}^{(a)}}{\\sqrt{t}}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{\\sqrt{t}}\\right) \\in \\cdot \\mid Y_{0}=i\\right] \\\\\n& =\\sum_{j \\in S} P\\left[Y_{t}=j \\mid Y_{0}=i\\right] P\\left[\\left(\\frac{\\log \\Phi_{t}^{(a)}}{\\sqrt{t}}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{\\sqrt{t}}\\right) \\in \\cdot \\mid Y_{0}=i, Y_{t}=j\\right]\n\\end{aligned}\n$$\n\nLet $t \\rightarrow \\infty$, in both sides of (15.14), and to get rid of $\\left\\{Y_{t}=j\\right\\}$ in the conditioning part of the RHS in the limit, we apply the Lemma 6.1 with\n\n$$\nL_{t}^{(1)}=\\left(\\frac{\\left[\\log L_{0}^{j}-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right]}{\\sqrt{t}}, \\frac{\\log \\left|B_{t}^{(3)}\\right|}{\\sqrt{t}}\\right)^{\\prime}, \\quad L_{t}^{(2)}=\\left(\\begin{array}{ll}\n1 & 0 \\\\\n0 & 1\n\\end{array}\\right), \\quad H_{t}=\\left(\\begin{array}{c}\n\\frac{S_{t}^{\\otimes j}}{\\sqrt{t}} \\\\\n\\log \\frac{Z_{t}^{\\otimes j}}{\\sqrt{t}}\n\\end{array}\\right)\n$$\n\nSince both $\\log L_{0}^{j}$ and $a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)$ are $O_{P}(1)$, hence $L_{t}^{(1)} \\xrightarrow{P} 0$, and by Lemma 15.2(c) $H_{t}$ verifies the condition in (6.1). We will be done if we prove that $H_{t}^{\\prime} \\xrightarrow{d} \\frac{\\sigma_{t}}{\\sqrt{E\\left|S_{1}^{1}\\right|}}\\left(F_{1}, F_{2}\\right)$ as $t \\rightarrow \\infty$. This is because using\n\n$P\\left[Y_{t}=j \\mid Y_{0}=i\\right] \\rightarrow \\pi_{j}$, LHS of (15.14) would lead to\n\n$$\n\\begin{aligned}\n& \\lim _{t \\rightarrow \\infty} P\\left[\\left(\\frac{\\log \\Phi_{t}^{(a)}}{\\sqrt{t}}, \\frac{\\log \\left|I_{t}^{(a, b)}\\right|}{\\sqrt{t}}\\right) \\in \\mid Y_{0}=i\\right] \\\\\n& =\\sum_{j \\in S} \\pi_{j} \\lim _{t \\rightarrow \\infty} P\\left[\\left(\\frac{S_{g_{t}^{j}}^{\\otimes j}}{\\sqrt{t}}, \\frac{\\log Z_{g_{t}^{j}}^{\\otimes j}}{\\sqrt{t}}\\right) \\in \\mid Y_{0}=i\\right]\n\\end{aligned}\n$$\n\nproving the result. From the definitions of $M_{n}^{\\otimes j}, Z_{n}^{\\otimes j}$, it follows that\n\n$$\nM_{g_{t}^{j}}^{\\otimes j}-\\max _{1 \\leq k \\leq g_{t}^{j}} \\log \\left|Q_{k}^{j}\\right| \\leq \\log Z_{g_{t}^{\\otimes j}}^{\\otimes j} \\leq M_{g_{t}^{\\otimes j}}^{\\otimes j}+\\max _{1 \\leq k \\leq g_{t}^{j}} \\log \\left|Q_{k}^{j}\\right|\n$$\n\n(see also (4.4) of [37]). Now under the condition (4.3) Lemma 15.2(a) holds and Lemma 15.2(b) below verifies the weak convergence result as $t \\rightarrow \\infty$. Combining these in (15.15) the assertion follows by taking $t \\rightarrow \\infty$ limit.\nLemma 15.2. Under assumptions of Theorem 2(b) as $t \\rightarrow \\infty$,\n\n$$\n\\begin{aligned}\n& \\text { (a) } \\frac{\\max _{1 \\leq k \\leq g_{t}^{j}} \\log \\left|Q_{k}^{j}\\right|}{\\sqrt{t}} \\stackrel{a, q}{\\rightarrow} 0, \\quad \\text { (b) } \\quad\\left(\\frac{S_{g_{t}^{j}}^{\\otimes j}}{\\sqrt{t}}, \\frac{M_{g_{t}^{j}}^{\\otimes j}}{\\sqrt{t}}\\right) \\xrightarrow{d} \\frac{\\sigma_{j}}{\\sqrt{E\\left|\\mathfrak{I}_{1}^{j}\\right|}}\\left(F_{1}, F_{2}\\right) \\\\\n& \\text { (c) } H_{t}^{\\prime}=\\left(\\frac{S_{g_{t}^{j}}^{\\otimes j}}{\\sqrt{t}}, \\frac{\\log Z_{g_{t}^{j}}^{\\otimes j}}{\\sqrt{t}}\\right) \\quad \\text { satisfies the condition in (6.1), i.e } \\\\\n& H_{t}-H_{t-\\varepsilon(t)} \\xrightarrow{P}(0,0)^{\\prime} \\quad \\text { for some } \\quad \\varepsilon(\\cdot) \\quad \\text { specified in (6.1). }\n\\end{aligned}\n$$",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 32,
      "text": "# 15.2.1 Proof of Lemma 15.2 (a) \\& (b) \n\nProof. For ease of notations, write $\\mu_{j}:=1 / E\\left|\\mathfrak{I}_{1}^{j}\\right|$. Since $\\frac{g_{t}^{j}}{t} \\rightarrow \\mu_{j}$ as $t \\rightarrow \\infty$.\nPart (a) will be proved if we show $\\frac{\\max _{1 \\leq k \\leq g_{t}^{j}} \\log \\left|Q_{k}^{j}\\right|}{\\sqrt{g_{t}^{j}}} \\stackrel{a, q}{\\rightarrow} 0$. As $\\left(\\log \\left|Q_{i}^{j}\\right|\\right)_{i \\geq 1}$ is an i.i.d. sequence and (4.3) implies that $E\\left[\\log \\left|Q_{1}^{j}\\right|\\right]^{2}<\\infty$. By the Borel-Cantelli lemma, we will show that\n\n$$\n\\frac{\\max _{1 \\leq k \\leq n} \\log \\left|Q_{k}^{j}\\right|}{\\sqrt{n}} \\stackrel{a, q}{\\rightarrow} 0 \\quad \\text { as } n \\rightarrow \\infty\n$$\n\nWe first show $\\log \\left|Q_{n}^{j}\\right| / \\sqrt{n} \\xrightarrow{a, q} 0$ as a consequence of Borel-Cantelli Lemma and $E\\left[\\log \\left|Q_{1}^{j}\\right|\\right]^{2}<\\infty$. This is evident as $E\\left[\\log \\left|Q_{1}^{j}\\right|\\right]^{2}=E\\left[\\log \\left|Q_{n}^{j}\\right|\\right]^{2}<\\infty$ implies\n\n$$\n\\begin{aligned}\n& \\sum_{n=1}^{\\infty} P\\left[\\left(\\log \\left|Q_{n}^{j}\\right|\\right)^{2}>\\varepsilon^{2} n\\right]<\\infty \\quad \\text { for every } \\varepsilon>0 \\\\\n& \\quad \\Leftrightarrow P\\left[\\log \\left|Q_{n}^{j}\\right|>\\varepsilon \\sqrt{n} \\text { i.o. }\\right]=0 \\quad \\text { for every } \\varepsilon>0\n\\end{aligned}\n$$\n\nSince only finitely many of $\\left\\{\\log \\left|Q_{k}^{j}\\right| / \\sqrt{k}, 1 \\leq k \\leq n\\right\\}$ can exceed $\\varepsilon$ for any arbitrarily small $\\varepsilon>0$, (15.17) holds. Then from this and $g_{t} \\xrightarrow{a, q} \\infty$; part (a) will follow by observing\n\n$$\n\\left\\{\\frac{\\max _{1 \\leq k \\leq g_{t}^{j}} \\log \\left|Q_{k}^{j}\\right|}{\\sqrt{g_{t}^{j}}} \\stackrel{\\rightharpoonup}{r} 0\\right\\}=\\left\\{\\frac{\\max _{1 \\leq k \\leq n} \\log \\left|Q_{k}^{j}\\right|}{\\sqrt{n}} \\stackrel{\\rightharpoonup}{r} 0\\right\\} \\cup\\left\\{g_{t} \\stackrel{\\rightharpoonup}{\\rightharpoonup} \\infty\\right\\}\n$$\n\nand using Theorem 2.1 in Gut [34] by replacing $n$ by $g_{t}^{j}$ (as $g_{t}^{j} \\stackrel{a, q}{\\rightarrow} \\infty$ ) in (15.17).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 33,
      "text": "# 15.2.2 Proof of part (b) \n\nSince $\\left(\\frac{S_{n}^{\\otimes j}}{\\sqrt{t}}, \\frac{M_{n}^{\\otimes j}}{\\sqrt{t}}\\right)=\\left(\\frac{S_{n}^{\\otimes j}}{\\sqrt{g_{t}^{j}}}, \\frac{M_{n}^{\\otimes j}}{\\sqrt{g_{t}^{j}}}\\right) \\sqrt{\\frac{g_{t}^{j}}{t}}$, and under Assumption 1, $g_{t}^{j} / t \\xrightarrow{a . s} \\mu_{j}$, part (b) will follow if we prove following two steps,\n\n- Step 1 : $\\left(\\frac{S_{n}^{\\otimes j}}{\\sqrt{n}}, \\frac{M_{n}^{\\otimes j}}{\\sqrt{n}}\\right) \\xrightarrow{d} \\sigma_{j}\\left(F_{1}, F_{2}\\right)$ as $n \\rightarrow \\infty$;\n- Step 2 : $\\left(\\frac{S_{n}^{\\otimes j}}{\\sqrt{n}}, \\frac{M_{n}^{\\otimes j}}{\\sqrt{n}}\\right)$ satisfy Anscombe's contiguity condition for $R_{n}$ in (2.11);\nthen by replacing $n$ by $g_{t}^{j}$ (as $g_{t}^{j} \\xrightarrow{a . s} \\infty$ ) the result will follow.\n(A) (Proof of Step 1) Let $W:=\\left(W_{t}: 0 \\leq t \\leq 1\\right)$ be a Wiener process in $[0,1]$. Let the random curve $x_{(n)}:=\\left(x_{(n)}(t): 0 \\leq t \\leq 1\\right)$ in $[0,1]$ be defined in the following manner\n\n$$\nx_{(n)}(t):=n^{-\\frac{1}{2}} S_{[n t]}^{\\otimes j}+(n t-[n t]) \\frac{\\log L_{[n t]+1}^{j}}{\\sqrt{n}}, \\quad 0 \\leq t \\leq 1\n$$\n\nwhere it represents the continuous time interpolated version of the discrete partial sum process $\\left\\{S_{n}^{\\otimes j}\\right.$ : $n \\in \\mathbb{N}\\}$. By $(\\mathcal{C}[0,1], \\mathcal{C})$ denote the space of continuous functions in $[0,1]$ with topology induced under supremum norm. Under conditions of Theorem 2(b) the weak convergence of $x_{(n)}$ in $\\mathcal{C}[0,1]$ holds (a.k.a the functional central limit theorem (FCLT)),\n\n$$\nx_{(n)} \\stackrel{w}{\\Longrightarrow} \\sigma_{j} W \\quad \\text { in } \\quad \\mathcal{C}[0,1]\n$$\n\nas $n \\rightarrow \\infty$. We will use the traditional invariance principle. Note that for any element $x \\in \\mathcal{C}[0,1]$, the functional $f: \\mathcal{C}[0,1] \\rightarrow(\\mathcal{C}[0,1] \\times \\mathcal{C}[0,1])$ defined as\n\n$$\nf(x):=\\left((x(t), \\sup _{0 \\leq s \\leq t} x(s)): t \\in[0,1]\\right)\n$$\n\nis a continuous under supremum norm. Using continuous mapping theorem as $n \\rightarrow \\infty$, one has $f\\left(x_{(n)}\\right) \\xrightarrow{w} f\\left(\\sigma_{j} W\\right)$ in $\\mathcal{C}[0,1]$, and as a consequence\n\n$$\nf\\left(x_{(n)}\\right)(1) \\xrightarrow{d} f\\left(\\sigma_{j} W\\right)(1)=\\sigma_{j}\\left(W_{1}, \\sup _{0 \\leq s \\leq 1} W_{s}\\right)\n$$\n\nObserve that $f\\left(x_{(n)}\\right)(1)=n^{-\\frac{1}{2}}\\left(S_{n}^{\\otimes j}, M_{n}^{\\otimes j}\\right)$. Hence (15.21) implies that\n\n$$\nn^{-\\frac{1}{2}}\\left(S_{n}^{\\otimes j}, M_{n}^{\\otimes j}\\right) \\xrightarrow{d} \\sigma_{j}\\left(W_{1}, \\sup _{0 \\leq s \\leq 1} W_{s}\\right), \\quad \\text { as } \\quad n \\rightarrow \\infty\n$$\n\nCorollary 6.5.5 of [52] gives an explicit form of density of $\\left(W_{1}, \\sup _{0 \\leq s \\leq 1} W_{s}\\right)$ that is identical to the joint density of $\\left(F_{1}, F_{2}\\right)$ in (4.5).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 34,
      "text": "## (B) (Proof of Step 2)\n\nWe prove Step 2 by showing Anscombe's condition (uniform continuity in probability, condition (A) on page 16 in [34]) which in our context requires showing the following: Given $\\gamma>0, \\eta>0$, there exist $\\delta>0, n_{0}>0$ such that\n\n$$\nP\\left[\\max _{\\{k:|k-n|<n \\delta\\}}\\left|\\left(\\frac{S_{k}^{\\otimes j}}{\\sqrt{k}}, \\frac{M_{k}^{\\otimes j}}{\\sqrt{k}}\\right)-\\left(\\frac{S_{n}^{\\otimes j}}{\\sqrt{n}}, \\frac{M_{n}^{\\otimes j}}{\\sqrt{n}}\\right)\\right|>\\gamma\\right]<\\eta \\quad \\text { for } n \\geq n_{0}\n$$\n\nFor any two $a=\\left(a_{1}, a_{2}\\right), b=\\left(b_{1}, b_{2}\\right)$, we use the $L_{1}$ norm $|a-b|=\\left|a_{1}-a_{2}\\right|+\\left|b_{1}-b_{2}\\right|$ without loss of generality. (15.22) holds if we show that given $\\gamma>0, \\eta>0$, there exist $\\delta>0, n_{1}, n_{2}>0$ such that\n\n$$\n\\begin{gathered}\nP\\left[\\max _{\\{k:|k-n|<n \\delta\\}}\\left|\\frac{S_{k}^{\\otimes j}}{\\sqrt{k}}-\\frac{S_{n}^{\\otimes j}}{\\sqrt{n}}\\right|>\\frac{\\gamma}{2}\\right]<\\frac{\\eta}{2} \\quad \\text { for } n \\geq n_{1} \\\\\nP\\left[\\max _{\\{k:|k-n|<n \\delta\\}}\\left|\\frac{M_{k}^{\\otimes j}}{\\sqrt{k}}-\\frac{M_{n}^{\\otimes j}}{\\sqrt{n}}\\right|>\\frac{\\gamma}{2}\\right]<\\frac{\\eta}{2} \\quad \\text { for } n \\geq n_{2}\n\\end{gathered}\n$$\n\nby setting $n_{0}=n_{1} \\vee n_{2}$.\nSince $\\{k:|k-n|<n \\delta\\}=\\{n \\leq k \\leq n(1+\\delta)\\} \\cup\\{n(1-\\delta) \\leq k \\leq n\\}$ an upper bound for the probability in (15.24) is\n\n$$\n\\begin{aligned}\n& P\\left[\\max _{\\{k: n \\leq k \\leq n+n \\delta\\}}\\left|\\frac{M_{k}^{\\otimes j}}{\\sqrt{k}}-\\frac{M_{n}^{\\otimes j}}{\\sqrt{n}}\\right|>\\frac{\\gamma}{2}\\right] \\\\\n& \\quad+P\\left[\\max _{\\{k: n(1-\\delta) \\leq k \\leq n\\}}\\left|\\frac{M_{k}^{\\otimes j}}{\\sqrt{k}}-\\frac{M_{n}^{\\otimes j}}{\\sqrt{n}}\\right|>\\frac{\\gamma}{2}\\right]\n\\end{aligned}\n$$\n\nWe prove that the first term is smaller than $\\eta / 4$. Similar arguments show that second term is smaller than $\\eta / 4$ from which (15.24) follows. For notational simplicity we assume $n \\delta$ to be an integer (even if it's not then abuse the notation $n \\delta$ to denote $[n \\delta]$ ). Observe that\n\n$$\n\\begin{aligned}\n& P\\left[\\max _{\\{k: n \\leq k \\leq n(1+\\delta)\\}}\\left|\\frac{M_{k}^{\\otimes j}}{\\sqrt{k}}-\\frac{M_{n}^{\\otimes j}}{\\sqrt{n}}\\right|>\\frac{\\gamma}{2}\\right] \\\\\n& \\quad \\leq P\\left[\\max _{\\{k: n \\leq k \\leq n(1+\\delta)\\}}\\left(\\left|\\frac{M_{k}^{\\otimes j}}{\\sqrt{k}}-\\frac{M_{k}^{\\otimes j}}{\\sqrt{n}}\\right|+\\left|\\frac{M_{k}^{\\otimes j}}{\\sqrt{n}}-\\frac{M_{n}^{\\otimes j}}{\\sqrt{n}}\\right|\\right)>\\frac{\\gamma}{2}\\right] \\\\\n& \\quad \\leq P\\left[\\frac{\\left|M_{n(1+\\delta)}^{\\otimes j}\\right|}{\\sqrt{n(1+\\delta)}}\\left[(1+\\delta)^{\\frac{1}{2}}-1\\right]>\\frac{\\gamma}{4}\\right]+P\\left[\\frac{M_{n(1+\\delta)}^{\\otimes j}-M_{n}^{\\otimes j}}{\\sqrt{n}}>\\frac{\\gamma}{4}\\right]\n\\end{aligned}\n$$\n\nFor all $\\delta \\geq 0,(1+\\delta)^{\\frac{1}{2}} \\leq\\left(1+\\frac{\\delta}{2}\\right)$. Consequently, for all $\\delta \\geq 0$,\n\n$$\nP\\left[\\frac{\\left|M_{n(1+\\delta)}^{\\otimes j}\\right|}{\\sqrt{n(1+\\delta)}}\\left[(1+\\delta)^{\\frac{1}{2}}-1\\right]>\\frac{\\gamma}{4}\\right] \\leq P\\left[\\frac{\\delta}{2} \\frac{\\left|M_{n(1+\\delta)}^{\\otimes j}\\right|}{\\sqrt{n(1+\\delta)}}>\\frac{\\gamma}{4}\\right]\n$$\n\nNote that the marginal density of $F_{2}$ will be identical as of a $|N|$ where $N$ is a Normal $(0,1)$ distributed random variable and this can be derived from the joint density of $\\left(F_{1}, F_{2}\\right)$ in step 2 . This implies that, as $n \\rightarrow \\infty$\n\n$$\n\\frac{M_{n}^{\\otimes j}}{\\sqrt{n}} \\xrightarrow{d} \\sigma_{j}|N|\n$$\n\nwhich is also celebrated as the Erdos-Kac theorem (see Theorem I in Erd\u00f6s and Kac [26]). As a consequence of (15.27), for given $\\gamma>0, \\eta>0$ one can choose a small $\\delta_{\\eta}>0$ and a large $n_{2}^{(1)}$ such that for all $\\delta \\leq \\delta_{\\eta}^{(1)}$,\n\n$$\nP\\left[\\frac{\\delta}{2} \\frac{\\left|M_{n(1+\\delta)}^{\\otimes j}\\right|}{\\sqrt{n(1+\\delta)}}>\\frac{\\gamma}{4}\\right]<\\frac{\\eta}{8}, \\quad \\text { for } n \\geq n_{2}^{(1)}\n$$\n\nSecond term in (15.26) can be shown to be smaller than $\\eta / 8$ as well. This can be shown by first writing, with $A_{1}:=\\{(x, y): 0 \\leq y<\\infty,-\\infty<x<y\\}$,\n\n$$\n\\begin{aligned}\n& P\\left[M_{n(1+\\delta)}^{\\otimes j}-M_{n}^{\\otimes j}>\\frac{\\gamma}{4} \\sqrt{n}\\right] \\\\\n& \\quad=\\int_{A_{1}} P\\left[M_{n(1+\\delta)}^{\\otimes j}-M_{n}^{\\otimes j}>\\frac{\\gamma}{4} \\sqrt{n} \\mid\\left(S_{n}^{\\otimes j}, M_{n}^{\\otimes j}\\right)=(s, t)\\right] f_{\\left(S_{n}^{\\otimes j}, M_{n}^{\\otimes j}\\right)}(s, t) d s d t \\\\\n& \\quad=\\int_{A_{1}} P\\left[\\frac{M_{n \\delta}^{\\otimes j}}{\\sqrt{n \\delta}}>\\frac{t-s}{\\sqrt{n \\delta}}+\\frac{\\gamma \\sqrt{n}}{4 \\sqrt{n \\delta}}\\right] f_{\\left(S_{n}^{\\otimes j}, M_{n}^{\\otimes j}\\right)}(s, t) d s d t\n\\end{aligned}\n$$\n\nwhere (15.28) follows from the independent increment property of the mean 0 , random walk $\\left(S_{n}^{\\otimes j}\\right)_{n \\geq 1}$. For $(s, t) \\in A_{1}$, one has $t-s>0$, and as a consequence\n\n$$\nP\\left[\\frac{M_{n \\delta}^{\\otimes j}}{\\sqrt{n \\delta}}>\\frac{t-s}{\\sqrt{n \\delta}}+\\frac{\\gamma}{4 \\sqrt{\\delta}}\\right] \\leq P\\left[\\frac{M_{n \\delta}^{\\otimes j}}{\\sqrt{n \\delta}}>\\frac{\\gamma}{4 \\sqrt{\\delta}}\\right]\n$$\n\nBy choosing $\\delta_{\\eta, \\gamma}^{(2)}>0$ and $\\delta<\\delta_{\\eta, \\gamma}^{(2)}$ such that $\\gamma /(4 \\sqrt{\\delta})$ is sufficiently large and choosing $n_{\\eta, \\gamma}^{(2)}$ large, as a consequence of (15.27),\n\n$$\nP\\left[\\frac{M_{n \\delta}^{\\otimes j}}{\\sqrt{n \\delta}}>\\frac{\\gamma}{4 \\sqrt{\\delta}}\\right]<\\frac{\\eta}{8}, \\quad \\text { for } n \\geq n_{\\eta, \\gamma}^{(2)}\n$$\n\nPutting this upper bound in (15.28), the first probability term in (15.25) can be shown to be less than $\\eta / 4$, which follows by taking $n \\geq n_{0}^{(1)} \\vee n_{\\eta, \\gamma}^{(2)}$ and $\\delta \\leq \\delta_{\\eta}^{(1)} \\wedge \\delta_{\\eta, \\gamma}^{(2)}$. Hence (15.24) holds by setting $n_{2}=n_{0}^{(1)} \\vee n_{\\eta, \\gamma}^{(2)}$.\nTo show (15.23), we can decompose its upper-bound like (15.25) and then show that given $\\gamma, \\eta>0$ there exists $\\delta, n_{1}$ such that\n\n$$\nP\\left[\\max _{\\{n \\leq k \\leq n(1+\\delta)\\}}\\left|\\frac{S_{k}^{\\otimes j}}{\\sqrt{k}}-\\frac{S_{n}^{\\otimes j}}{\\sqrt{n}}\\right|>\\frac{\\gamma}{2}\\right]<\\frac{\\eta}{4} \\quad \\text { for } n \\geq n_{1}\n$$\n\nThe LHS of (15.29) can be shown to be less than\n\n$$\n\\begin{aligned}\n& P\\left[\\frac{\\left|S_{n}^{\\otimes j}\\right|}{\\sqrt{n(1+\\delta)}}\\left[(1+\\delta)^{\\frac{1}{2}}-1\\right]>\\frac{\\gamma}{4}\\right]+P\\left[\\frac{\\max _{\\{n \\leq k \\leq n(1+\\delta)\\}}\\left|S_{k}^{\\otimes j}-S_{n}^{\\otimes j}\\right|}{\\sqrt{n}}>\\frac{\\gamma}{4}\\right] \\\\\n& \\quad \\leq P\\left[\\frac{\\delta}{2} \\frac{\\left|S_{n}^{\\otimes j}\\right|}{\\sqrt{n}}>\\frac{\\gamma}{4}\\right]+P\\left[\\frac{\\max _{0 \\leq k \\leq n \\delta}\\left|S_{k}^{\\otimes j}\\right|}{\\sqrt{n}}>\\frac{\\gamma}{4}\\right] \\\\\n& \\quad=P\\left[\\frac{\\left|S_{n}^{\\otimes j}\\right|}{\\sqrt{n}}>\\frac{\\gamma}{2 \\delta}\\right]+P\\left[\\frac{\\max _{0 \\leq k \\leq n \\delta}\\left|S_{k}^{\\otimes j}\\right|}{\\sqrt{n}}>\\frac{\\gamma}{4}\\right]\n\\end{aligned}\n$$\n\nSince marginally $\\frac{S_{n}^{\\otimes j}}{\\sqrt{n}} \\xrightarrow{d} \\sigma_{j} N$, as $n \\rightarrow \\infty$ (follows from step 1), given $\\gamma, \\eta>0$ we can always find $\\delta_{0}>0$ small enough and $n_{1}$ large enough such that for $n \\geq n_{1}$, the first term in RHS of (15.30) is less than $\\eta / 8$. Regarding the second term Choose $\\delta \\leq \\frac{\\eta \\gamma^{2}}{128 \\sup _{j \\in S} \\sigma_{j}^{2}}$, using Kolmogorov's maximal inequality it follows that\n\n$$\nP\\left[\\frac{\\max _{0 \\leq k \\leq n \\delta}\\left|S_{k}^{\\otimes j}\\right|}{\\sqrt{n}}>\\frac{\\gamma}{4}\\right] \\leq \\frac{16 \\sum_{i=1}^{n \\delta} \\operatorname{Var}\\left(\\log L_{i}^{j}\\right)}{(\\gamma \\sqrt{n})^{2}} \\leq \\frac{16 \\delta \\sup _{j \\in S} \\sigma_{j}^{2}}{\\gamma^{2}} \\leq \\frac{\\eta}{8}\n$$\n\nCombining both terms (15.29) is proved. (15.23) and (15.24) together show (15.22), and the verification of step 2 is complete.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 35,
      "text": "# 15.2.3 Proof of Lemma 15.2 (c) \n\nProof. Part (c) follows if both $S_{g_{l}^{j}}^{\\otimes j} / \\sqrt{t}$ and $M_{g_{l}^{\\prime}}^{\\otimes j} / \\sqrt{t}$ verify (15.9) separately as $\\log G_{t}^{(1)}$ (since $M_{g_{l}^{\\prime}}^{\\otimes j} / \\sqrt{t}$ and $\\log Z_{g_{l}^{\\prime}}^{\\otimes j} / \\sqrt{t}$ are equivalent in probability using part (a)). Take $t \\mapsto \\varepsilon(t)$ to be an increasing function satisfying $\\lim _{t \\rightarrow \\infty} \\varepsilon(t)=\\infty$ and $\\lim _{t \\rightarrow \\infty} \\varepsilon(t) / t=0$. Observe that\n\n$$\n\\begin{aligned}\n& \\frac{M_{g_{l}^{\\prime}}^{\\otimes j}}{\\sqrt{t}}-\\frac{M_{g_{l-\\varepsilon(t)}^{\\otimes j}}^{\\otimes j}}{\\sqrt{t-\\varepsilon(t)}}=-\\frac{M_{g_{l}^{\\prime}}^{\\otimes j}-M_{\\left[\\mu_{j} t\\right]}^{\\otimes j}}{\\sqrt{t}} \\\\\n& +\\frac{M_{\\left[\\mu_{j} t\\right]}^{\\otimes j}}{\\sqrt{t}}-\\frac{M_{\\left[\\mu_{j}(t-\\varepsilon(t))\\right]}^{\\otimes j}}{\\sqrt{t-\\varepsilon(t)}}+\\frac{M_{\\left[\\mu_{j}(t-\\varepsilon(t))\\right]}^{\\otimes j}-M_{g_{l-\\varepsilon(t)}^{\\otimes j}}^{\\otimes j}}{\\sqrt{t-\\varepsilon(t)}}\n\\end{aligned}\n$$\n\nFor $\\delta>0$, set $A_{(\\delta, j)}:=\\left\\{n \\in \\mathbb{N}:\\left|n / t-\\mu_{j}\\right| \\leq \\delta\\right\\}$ and observe that $\\lim _{t \\rightarrow \\infty} P\\left[g_{t}^{j} \\in A_{(\\delta, j)}\\right]=1$. For the first term on the right-hand side in (15.32),\n\n$$\n\\begin{aligned}\n& P\\left[\\frac{\\left|M_{g_{l}^{\\prime}}^{\\otimes j}-M_{\\left[\\mu_{j} t\\right]}^{\\otimes j}\\right|}{\\sqrt{t}}>\\gamma\\right] \\\\\n& \\quad \\leq P\\left[\\frac{\\left|M_{g_{l}^{\\prime}}^{\\otimes j}-M_{\\left[\\mu_{j} t\\right]}^{\\otimes j}\\right|}{\\sqrt{t}}>\\gamma, g_{t}^{j} \\in A_{(\\delta, j)}\\right]+P\\left[\\frac{\\left|M_{g_{l}^{\\prime}}^{\\otimes j}-M_{\\left[\\mu_{j} t\\right]}^{\\otimes j}\\right|}{\\sqrt{t}}>\\gamma, g_{t}^{j} \\in A_{(\\delta, j)}^{c}\\right] \\\\\n& \\quad \\leq P\\left[\\frac{M_{\\left[\\left[\\mu_{j}+\\delta\\right) t\\right]}^{\\otimes j}-M_{\\left[\\mu_{j} t\\right]}^{\\otimes j}}{\\sqrt{t}}>\\gamma\\right]+P\\left[\\frac{M_{\\left[\\mu_{j} t\\right]}^{\\otimes j}-M_{\\left[\\left[\\mu_{j}-\\delta\\right) t\\right]}^{\\otimes j}}{\\sqrt{t}}>\\gamma\\right]+P\\left[g_{t}^{j} \\notin A_{(\\delta, j)}^{c}\\right]\n\\end{aligned}\n$$\n\nThe arguments used to prove part (b) can be applied to prove that the first two terms on the right-hand side above goes to 0 , by making $\\delta$ arbitrarily small, and taking $t \\rightarrow \\infty$. The third term goes to 0 as $t \\rightarrow \\infty$ since $g_{i}^{j} / t \\stackrel{\\text { a.s. }}{\\rightarrow} \\mu_{j}$ as $t \\rightarrow \\infty$. Consequently, the first term on the right-hand side in (15.32) goes to 0 in probability as $t \\rightarrow \\infty$. Similarly, the third term on the right-hand side in (15.32) goes to 0 in probability as $t \\rightarrow \\infty$ since $t-\\varepsilon(t) \\rightarrow \\infty$ as $t \\rightarrow \\infty$. The second term on the right-hand side in (15.32) goes to 0 in probability as $t \\rightarrow \\infty$ by using an argument similar to (15.26) with $\\varepsilon(t) / t \\rightarrow 0$ as $t \\rightarrow \\infty$.\n\nRegarding verification for the $S_{g_{i}^{j}}^{\\otimes j} / \\sqrt{t}$, observe that\n\n$$\n\\frac{S_{g_{i}^{j}}^{\\otimes j}}{\\sqrt{t}}-\\frac{S_{g_{i-\\varepsilon(t)}^{\\otimes j}}^{\\otimes j}}{\\sqrt{t-\\varepsilon(t)}}=\\frac{S_{g_{i-\\varepsilon(t)}^{\\otimes j}}^{\\otimes j}}{\\sqrt{t-\\varepsilon(t)}}\\left[\\left(1-\\frac{\\varepsilon(t)}{t}\\right)^{\\frac{1}{2}}-1\\right]+\\frac{\\sum_{i=g_{i-\\varepsilon(t)}^{j}+1}^{\\beta_{i}^{j}} \\log L_{i}^{j}}{\\sqrt{t}}\n$$\n\nWithout loss of generality assume that $t$ is large enough so that $\\varepsilon(t) \\leq t$, for some $t \\geq t_{0}$. Observe that $\\left(1-\\delta_{1}\\right)^{\\frac{1}{2}} \\leq 1-\\frac{d_{1}}{d}$ for all $0 \\leq \\delta_{1} \\leq 1$. Hence, the upper bound can be expressed as\n\n$$\n\\left|\\frac{S_{g_{i}^{j}}^{\\otimes j}}{\\sqrt{t}}-\\frac{S_{g_{i-\\varepsilon(t)}^{\\otimes j}}^{\\otimes j}}{\\sqrt{t-\\varepsilon(t)}}\\right| \\leq \\frac{\\varepsilon(t)}{2 t} \\frac{\\left|S_{g_{i-\\varepsilon(t)}^{\\otimes j}}^{\\otimes j}\\right|}{\\sqrt{t-\\varepsilon(t)}}+\\sqrt{\\frac{\\varepsilon(t)}{t}} \\frac{\\sum_{i=g_{i-\\varepsilon(t)}^{j}+1}^{\\beta_{i}^{j}} \\log L_{i}^{j}}{\\sqrt{\\varepsilon(t)}}\n$$\n\nfor $t \\geq t_{0}$. Since $\\frac{\\varepsilon(t)}{t} \\rightarrow 0$ as $t \\rightarrow \\infty$ and both quantities $\\frac{\\left|S_{g_{i-\\varepsilon(t)}^{\\otimes j}}^{\\otimes j}\\right|}{\\sqrt{t-\\varepsilon(t)}}, \\frac{\\left|\\sum_{i=g_{i-\\varepsilon(t)}^{j}+1}^{\\beta_{i}^{j}} \\log L_{i}^{j}\\right|}{\\sqrt{\\varepsilon(t)}}$ are $O_{P}(1)$ which follows from part (b) as $(t-\\varepsilon(t))$ is large. Hence by Slutsky's theorem the LHS of (15.33) $\\xrightarrow{P} 0$ as $t \\rightarrow \\infty$, and this concludes the proof of part (c).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 36,
      "text": "# 16 Proof of supplementary results of Theorem 3\n### 16.1 Proof of Lemma 10.1\n\nProof. Denote $\\widetilde{a}(\\cdot)=a(\\cdot)-E_{\\pi} a(\\cdot)$. Conditioned on $\\widetilde{A}_{1}^{j}$, observe that\n\n$$\n\\int_{\\widetilde{\\pi}_{0}^{j}}^{\\tau_{1}^{j}} \\widetilde{a}\\left(Y_{s}\\right) d s=\\sum_{i \\in A_{1}^{j}} \\widetilde{a}\\left(J_{i}\\right) T_{i+1} \\stackrel{d}{=} \\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j}} \\widetilde{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}\n$$\n\nSince for $\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{-}$, the quantity $\\widetilde{a}\\left(i_{k}\\right)<0$, hence conditioned on $\\widetilde{A}_{1}^{j}$, we have\n\n$$\n\\begin{aligned}\n\\int_{\\widetilde{\\pi}_{0}^{j}}^{\\tau_{1}^{j}} \\widetilde{a}\\left(Y_{s}\\right) d s & \\stackrel{d}{=} \\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j}} \\widetilde{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}} \\\\\n& =\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+} \\widetilde{a}}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}-\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{-}}\\left|\\widetilde{a}\\left(i_{k}\\right)\\right| \\widetilde{F}_{i_{k} i_{k+1}} \\\\\n& +\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+}} \\widetilde{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}\n\\end{aligned}\n$$\n\nFor any event $D$\n\n$$\n\\begin{aligned}\n& P\\left[\\int_{\\tau_{0}^{j}}^{t_{1}^{j}} \\widehat{a}\\left(Y_{s}\\right) d s \\in D\\right]=E P\\left[\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j}} \\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}} \\in D \\mid \\widetilde{A}_{1}^{j}\\right] \\\\\n& =E P\\left[\\left(\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{+}} \\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}+\\sum_{\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{v,+}} \\widehat{a}\\left(j_{k}\\right) \\widetilde{F}_{j_{k} j_{k+1}}\\right)\\right. \\\\\n& \\left.-\\left(\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{-}} \\widehat{a}\\left(i_{k}\\right) \\mid \\widetilde{F}_{i_{k} i_{k+1}}+\\sum_{\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{v,-}} \\widehat{a}\\left(j_{k}\\right) \\mid \\widetilde{F}_{j_{k} j_{k+1}}\\right) \\in D \\mid \\widetilde{A}_{1}^{j}\\right] \\\\\n& =: E P\\left[\\widetilde{X}_{1}^{(1)}-\\widetilde{X}_{1}^{(2)} \\in D \\mid \\widetilde{A}_{1}^{j}\\right]\n\\end{aligned}\n$$\n\nwhere\n\n$$\n\\begin{aligned}\n& \\widetilde{X}_{1}^{(1)}:=\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{+}} \\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}+\\sum_{\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{v,+}} \\widehat{a}\\left(j_{k}\\right) \\widetilde{F}_{j_{k} j_{k+1}} \\\\\n& \\widetilde{X}_{1}^{(2)}:=\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{-}} \\widehat{a}\\left(i_{k}\\right)\\left|\\widetilde{F}_{i_{k} i_{k+1}}+\\sum_{\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{v,-}}\\right| \\widehat{a}\\left(j_{k}\\right) \\mid \\widetilde{F}_{j_{k} j_{k+1}}\n\\end{aligned}\n$$\n\nWe use the following Lemma 16.1 few times in this proof.\nLemma 16.1. For any arbitrary class of non-negative independent regularly varying random variables $\\left\\{\\widetilde{X}_{i}: i=1, \\ldots, n\\right\\}$ with index $\\alpha \\geq 0$, one has the following asymptotic results as $x \\rightarrow \\infty$\n(i) $P\\left[\\widetilde{X}_{1}-\\widetilde{X}_{2}>x\\right] \\sim P\\left[\\widetilde{X}_{1}>x\\right], \\quad$ and $\\quad P\\left[\\widetilde{X}_{1}-\\widetilde{X}_{2}<-x\\right] \\sim P\\left[\\widetilde{X}_{2}>x\\right]$.\n(ii) $P\\left[\\sum_{i=1}^{n} \\widetilde{X}_{i}>x\\right] \\sim \\sum_{i=1}^{n} P\\left[\\widetilde{X}_{i}>x\\right]$.\n(iii) If $P\\left[\\widetilde{X}_{2}>x\\right] \\sim o\\left(P\\left[\\widetilde{X}_{1}>x\\right]\\right)$, then $P\\left[\\widetilde{X}_{1}+\\widetilde{X}_{2}>x\\right] \\sim P\\left[\\widetilde{X}_{1}>x\\right]$.\n\nSuppose both sets $\\mathbb{S}_{\\alpha}^{+}, \\mathbb{S}_{\\alpha}^{-}$are non-empty. Choose $\\widetilde{A}_{1}^{j}$ such that $\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+} \\neq \\emptyset$ and $\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{-} \\neq \\emptyset$ (since if one of them doesn't hold then later we will see that the corresponding one of (10.1) or (10.2) will vacuously hold true in limit, as both sides will be 0 ).\n\nConditioned on $\\widetilde{A}_{1}^{j}$ observe that $\\left\\{\\widetilde{F}_{i_{k} i_{k+1}}:\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+}\\right\\}$are all independent and regularly varying at $+\\infty$ with rate $x^{-\\alpha} L(x)$. As a result of Lemma 16.1(ii) the following holds\n\n$$\n\\begin{aligned}\nP\\left[\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+}} \\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}>x \\mid \\widetilde{A}_{1}^{j}\\right] & \\sim \\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+}} P\\left[\\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}>x\\right] \\\\\n& \\sim\\left(\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{+}} c_{i_{k}, i_{k+1}} \\widehat{a}^{\\alpha}\\left(i_{k}\\right)\\right) x^{-\\alpha} L(x)\n\\end{aligned}\n$$\n\nFor any $\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{v,+}$, the quantity $P\\left[\\widehat{a}\\left(j_{k}\\right) \\widetilde{F}_{j_{k} j_{k+1}}>x \\mid \\widetilde{A}_{1}^{j}\\right]=o\\left(x^{-\\alpha} L(x)\\right)$, and as a result it follows that\n\n$$\nP\\left[\\widehat{a}\\left(j_{k}\\right) \\widetilde{F}_{j_{k} j_{k+1}}>x \\mid \\widetilde{A}_{1}^{j}\\right]=o\\left(P\\left[\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+}} \\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}>x \\mid \\widetilde{A}_{1}^{j}\\right]\\right)\n$$\n\nsince for any $\\left(j_{k}, j_{k+1}\\right) \\in \\mathbb{S}_{\\alpha}^{v,+}$ the sojourn time will have tails lighter than any sojourn time corresponding to the element $\\left(i_{k}, i_{k+1}\\right) \\in \\mathbb{S}_{\\alpha}^{+}$. Hence as a consequence of Lemma 16.1(iii) we have as $x \\rightarrow \\infty$\n\n$$\n\\begin{aligned}\n& P\\left[\\widetilde{X}_{1}^{(1)}>x \\mid \\widetilde{A}_{1}^{j}\\right] \\sim P\\left[\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+}} \\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}>x \\mid \\widetilde{A}_{1}^{j}\\right] \\\\\n& \\text { \\& similarly } \\quad P\\left[\\widetilde{X}_{1}^{(2)}>x \\mid \\widetilde{A}_{1}^{j}\\right] \\sim P\\left[\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{-}} \\widehat{a}\\left(i_{k}\\right) \\mid \\widetilde{F}_{i_{k} i_{k+1}}>x \\mid \\widetilde{A}_{1}^{j}\\right]\n\\end{aligned}\n$$\n\nClearly conditioned on $\\widetilde{A}_{1}^{j}$ both $\\widetilde{X}_{1}^{(1)}, \\widetilde{X}_{1}^{(2)}$ are independent and regularly varying at $+\\infty$ with rate $x^{-\\alpha} L(x)$. By virtue of Lemma 16.1(i) it follows that almost surely\n\n$$\n\\begin{aligned}\nP\\left[\\widetilde{X}_{1}^{(1)}-\\widetilde{X}_{1}^{(2)}>x \\mid \\widetilde{A}_{1}^{j}\\right] & \\sim P\\left[\\widetilde{X}_{1}^{(1)}>x \\mid \\widetilde{A}_{1}^{j}\\right] \\\\\n& \\sim P\\left[\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+} }\\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}>x \\mid \\widetilde{A}_{1}^{j}\\right] \\\\\n& \\sim\\left(\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+}} c_{i_{k}, i_{k+1}} \\widehat{a}^{\\alpha}\\left(i_{k}\\right)\\right) x^{-\\alpha} L(x)\n\\end{aligned}\n$$\n\nWe will need an upper bound of $\\frac{P\\left[\\widetilde{X}_{1}^{(1)}-\\widetilde{X}_{1}^{(2)}>x \\mid \\widetilde{A}_{1}^{j}\\right]}{x^{-\\alpha} L(x)}$ with finite expectation for large $x$, in order to use the Dominated Convergence Theorem. Observe that\n\n$$\n\\begin{aligned}\n& P\\left[\\widetilde{X}_{1}^{(1)}-\\widetilde{X}_{1}^{(2)}>x \\mid \\widetilde{A}_{1}^{j}\\right] \\leq P\\left[\\widetilde{X}_{1}^{(1)}>x \\mid \\widetilde{A}_{1}^{j}\\right] \\\\\n\\leq & P\\left[\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{+}} \\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}>\\frac{x}{2} \\mid \\widetilde{A}_{1}^{j}\\right]+P\\left[\\sum_{\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{c,+}} \\widehat{a}\\left(j_{k}\\right) \\widetilde{F}_{j_{k} j_{k+1}}>\\frac{x}{2} \\mid \\widetilde{A}_{1}^{j}\\right]\n\\end{aligned}\n$$\n\nWorking with the first-term yields\n\n$$\nP\\left[\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+}} \\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}>x \\mid \\widetilde{A}_{1}^{j}\\right] \\leq \\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+}} P\\left[\\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}>\\frac{x}{\\left|\\widetilde{A}_{1}^{j} \\cap S_{\\alpha}^{+}\\right|} \\widetilde{A}_{1}^{j}\\right]\n$$\n\nand after scaling by $x^{-\\alpha} L(x)$ we get\n\n$$\n\\begin{aligned}\n& \\frac{P\\left[\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}} \\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}>x \\mid \\widetilde{A}_{1}^{j}\\right]}{x^{-\\alpha} L(x)} \\leq \\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c}} \\frac{P\\left[\\widehat{a}\\left(i_{k}\\right) \\widetilde{F}_{i_{k} i_{k+1}}>\\frac{x}{\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c}\\right|} \\widetilde{A}_{1}^{j}\\right]}{x^{-\\alpha} L(x)} \\\\\n& \\stackrel{(a)}{\\leq} \\widetilde{c}_{\\varepsilon} \\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}} c_{i_{k} i_{k+1}}\\left(1 \\vee \\widehat{a}\\left(i_{k}\\right)\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+}\\right|\\right)^{\\alpha+\\epsilon}\n\\end{aligned}\n$$\n\nwhere (a) holds due to (4.6) and the expectation of the final upper bound in the above RHS is finite due to (4.7).\n\nThe second term after scaled by $p(x):=x^{-\\alpha} L(x)$ will give the upper bound for any $x \\geq 2 a^{*} \\mid \\widetilde{A}_{1}^{j} \\mid x^{*}, \\& \\epsilon_{1} \\in$ $(0, \\alpha)$\n\n$$\n\\begin{aligned}\n& \\frac{P\\left[\\sum_{\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}} \\widehat{a}\\left(j_{k}\\right) \\widetilde{F}_{j_{k} j_{k+1}}>\\frac{x}{2} \\mid \\widetilde{A}_{1}^{j}\\right]}{x^{-\\alpha} L(x)} \\\\\n& \\leq \\sum_{\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}} \\frac{P\\left[\\widehat{a}\\left(j_{k}\\right) \\widetilde{F}_{j_{k} j_{k+1}}>\\frac{x}{2\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}\\right|} \\widetilde{A}_{1}^{j}\\right]}{x^{-\\alpha} L(x)} \\\\\n& =\\sum_{\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}} \\frac{\\widetilde{F}_{j_{k} j_{k+1}}\\left(\\frac{x}{2 \\widehat{a}\\left(j_{k}\\right)\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}\\right|}\\right)}{p\\left(\\frac{x}{2 \\widehat{a}\\left(j_{k}\\right)\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}\\right|}\\right)} \\frac{p\\left(\\frac{x}{2 \\widehat{a}\\left(j_{k}\\right)\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}\\right|}\\right)}{p(x)} \\\\\n& \\stackrel{(a)}{\\leq} \\sum_{\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}} \\frac{p\\left(\\frac{x}{2 \\widehat{a}\\left(j_{k}\\right)\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}\\right|}\\right)}{p(x)} \\\\\n& \\stackrel{(b)}{\\leq} \\sum_{\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}}\\left(1+\\epsilon_{1}\\right)\\left(2 \\widehat{a}\\left(j_{k}\\right)\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}\\right|\\right)^{\\alpha-\\epsilon_{1}} \\\\\n& \\stackrel{(c)}{\\leq}\\left(1+\\epsilon_{1}\\right)\\left(4 a^{*}\\right)^{\\alpha-\\epsilon_{1}} \\sum_{\\left(j_{k}, j_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}}\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c,+}\\right|^{\\alpha} \\\\\n& \\stackrel{(d)}{=}\\left(1+\\epsilon_{1}\\right)\\left(4 a^{*}\\right)^{\\alpha-\\epsilon_{1}}\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{c}\\right|^{1+\\alpha}\n\\end{aligned}\n$$\n\nwhere (a) follows by using the first condition of (4.8) with $x \\geq 2 a^{*} \\mid \\widetilde{\\mathcal{A}}_{1}^{j} \\mid x^{*}$, (b) follows by using the Potter's bound using any arbitrary $\\epsilon_{1} \\in(0, \\alpha)$. The inequality at (c) holds by taking supremum of $\\widehat{a}(\\cdot)$ over the summand, and taking it outside of the sum and having the upper bound by ignoring $\\epsilon_{1}$; and finally, the result follows by observing that the final upper bound in the RHS of (d) has finite expectation due to the third condition of (4.8).\n\nHence from (16.4) the assertion holds for the right tail (10.1) as a consequence of Dominated Convergence Theorem, i.e, as $x \\rightarrow \\infty$,\n\n$$\n\\begin{aligned}\n\\frac{P\\left[\\widetilde{X}_{1}^{(1)}-\\widetilde{X}_{1}^{(2)}>x\\right]}{x^{-\\alpha} L(x)} & =\\frac{E P\\left[\\widetilde{X}_{1}^{(1)}-\\widetilde{X}_{1}^{(2)}>x \\mid \\widetilde{A}_{1}^{j}\\right]}{x^{-\\alpha} L(x)} \\\\\n& \\rightarrow E\\left[\\sum_{\\left(i_{k}, i_{k+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+} \\alpha} c_{i_{k}, i_{k+1}} \\widehat{a}^{\\alpha}\\left(i_{k}\\right)\\right] \\\\\n& =\\widehat{\\alpha}_{j}^{(+)}==\\frac{1+\\beta_{j}}{2} \\sigma_{(j, \\alpha)}^{\\alpha}\n\\end{aligned}\n$$\n\nSimilarly (10.2) holds working with the $\\left\\{\\widetilde{X}_{1}^{(1)}-\\widetilde{X}_{1}^{(2)}<-x\\right\\}$ type of events.\nIf $\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{+}$is empty then (10.1) holds vacuously true as both sides are 0 in limit, and the same holds for (10.2) corresponding to the case $\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{-}=\\emptyset$ as well.\n\nHence the assertion is proved for the case when both $\\mathbb{S}_{\\alpha}^{+} \\mathbb{S}_{\\alpha}^{-}$non-empty. If one of $\\mathbb{S}_{\\alpha}^{+} \\mathbb{S}_{\\alpha}^{-}$is empty, then the RHS of one of (10.1) and (10.2) will be trivially 0 , that can be easily verified after scaling the probability in the corresponding LHS by $x^{-\\alpha} L(x)$ (using similar arguments as above).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 37,
      "text": "# 16.1.1 Proof of Lemma 10.2 \n\nProof. Observe that\n\n$$\n\\widetilde{G}_{t}^{*(1)}=\\frac{\\sum_{i=1}^{g_{t}^{j}} Y_{i}^{* *}}{t^{\\frac{1}{n}} L_{0}(t)}+\\frac{\\left[\\tau_{0}^{j}+\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right] E_{\\pi} a(\\cdot)}{t^{\\frac{1}{n}} L_{0}(t)}\n$$\n\nwhere $Y_{i}^{* *}=-\\int_{\\tau_{t-1}^{j}}^{\\tau_{t}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s$. Since the quantity $\\tau_{0}^{j}+\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)$ is $O_{P}(1)$, the second term of $\\widetilde{G}_{t}^{*(1)}$ is $o_{P}(1)$. Denoting $t^{\\frac{1}{n}} L_{0}(t),\\left(g_{t}^{j}\\right)^{1 / \\alpha} L_{0}\\left(g_{t}^{j}\\right)$ by $c_{t}, c_{g_{t}^{j}}$ respectively, it is enough to show that as $t \\rightarrow \\infty$,\n\n$$\n\\frac{\\sum_{i=1}^{g_{t}^{j}} Y_{i}^{* *}}{c_{t}}-\\frac{\\sum_{i=1}^{g_{t-s(t)}^{j}} Y_{i}^{* *}}{c_{t-\\varepsilon(t)}} \\xrightarrow{p} 0\n$$\n\nfor some increasing $t \\rightarrow \\varepsilon(t)$, such that $\\varepsilon(t) \\rightarrow \\infty$ and $\\frac{\\varepsilon(t)}{t} \\rightarrow 0$ as $t \\rightarrow \\infty$.\nObserve that\n\n$$\n\\begin{aligned}\n& \\frac{\\sum_{i=1}^{g_{t}^{j}} Y_{i}^{* *}}{c_{t}}-\\frac{\\sum_{i=1}^{g_{t-s(t)}^{j}} Y_{i}^{* *}}{c_{t-\\varepsilon(t)}} \\\\\n& =\\frac{\\sum_{i=g_{t-s(t)}^{j}+1}^{g_{t}^{j}} Y_{i}^{* *}}{c_{t}}+\\sum_{i=1}^{g_{t-s(t)}^{j}} Y_{i}^{* *}\\left[\\frac{1}{c_{t}}-\\frac{1}{c_{t-\\varepsilon(t)}}\\right] \\\\\n& =\\frac{c_{\\varepsilon(t)}}{c_{t}} \\frac{c_{g_{t}^{j}-g_{t-s(t)}^{j}}}{c_{\\varepsilon(t)}} \\frac{\\sum_{i=g_{t-s(t)}^{j}+1}^{g_{t}^{j}} Y_{i}^{* *}}{c_{g_{t}^{j}-g_{t-s(t)}^{j}}}+\\frac{c_{g_{t-s(t)}^{j}}}{c_{t-\\varepsilon(t)}} \\frac{\\sum_{i=1}^{g_{t-s(t)}^{j}} Y_{i}^{* *}}{c_{g_{t-s(t)}^{j}}}\\left[\\frac{c_{t-\\varepsilon(t)}}{c_{t}}-1\\right] .\n\\end{aligned}\n$$\n\nUsing ideas of Lemma 12.3(a) it follows that both $\\frac{c_{g_{t}^{j}-g_{t-s(t)}^{j}}}{c_{\\varepsilon(t)}}$ and $\\frac{c_{g_{t-s(t)}^{j}}}{c_{t-\\varepsilon(t)}}$ converges almost surely to $\\left(E\\left[\\mathfrak{I}_{1}^{j}\\right]\\right)^{-1 / \\alpha}$, as $t \\rightarrow \\infty$. Since $\\left\\{Y_{i}^{* *}: i \\geq 1\\right\\}$ are a sequence of regularly varying random variables with mean 0 , and hence a version of stable central limit theorem can be obtained in line of $c_{n}^{-1} \\sum_{i=1}^{n} Y_{i}^{* *} \\stackrel{d}{\\rightarrow}$\n\n$\\sigma_{(j, \\alpha)} \\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right)$ for $n \\rightarrow \\infty$. Hence by Theorem 3.2 of [34], using $g_{t-\\varepsilon(t)}^{j}$ and $g_{t}^{j}-g_{t-\\varepsilon(t)}^{j}$ as the stopped random times it follows that as $t \\rightarrow \\infty$\n\n$$\n\\begin{aligned}\n\\frac{\\sum_{i=1}^{g_{t-\\varepsilon(t)}^{j}} Y_{i}^{* *}}{c_{g_{t-\\varepsilon(t)}^{j}}} & \\xrightarrow{d} \\quad \\sigma_{(j, \\alpha)} \\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right) \\\\\n\\frac{\\sum_{i=g_{t-s(t)}^{j}}^{g_{t-s(t)}^{j}}+1 Y_{i}^{* *}}{c_{g_{t-s(t)}^{j}-g_{t-s(t)}^{j}} \\stackrel{d}{=} & \\stackrel{d}{\\underset{i=1}{\\sum_{t=1}^{g_{t-s(t)}^{j}}}-1} Y_{i}^{* *} \\\\\n& \\stackrel{d}{\\rightarrow} \\sigma_{(j, \\alpha)} \\mathcal{S}_{\\alpha}\\left(1, \\beta_{j}, 0\\right)\n\\end{aligned}\n$$\n\nHence by Slutsky's theorem our assertion will follow in (16.6) if we prove that both $\\frac{c_{\\varepsilon(t)}}{c_{t}},\\left[\\frac{c_{t-\\varepsilon(t)}}{c_{t}}-1\\right]$ go to 0 as $t \\rightarrow \\infty$.\n\nObserve that $\\frac{c_{\\varepsilon(t)}}{c_{t}}=\\left(\\frac{\\varepsilon(t)}{t}\\right)^{1 / \\alpha} \\frac{L_{0}(\\varepsilon(t))}{L_{0}(t)}$, and using Lemma12.3(b) (Potter's bound) it follows that for any $0<\\epsilon<\\frac{1}{\\alpha}$, there exists $t_{0, \\epsilon}$ such that for all $t \\geq t_{0, \\epsilon}$,\n\n$$\n\\frac{1}{1+\\epsilon}\\left(\\frac{\\varepsilon(t)}{t}\\right)^{\\frac{1}{\\alpha}+\\epsilon} \\leq \\frac{c_{\\varepsilon(t)}}{c_{t}} \\leq \\frac{1}{1-\\epsilon}\\left(\\frac{\\varepsilon(t)}{t}\\right)^{\\frac{1}{\\alpha}-\\epsilon}\n$$\n\nand similarly using $\\frac{c_{t-\\varepsilon(t)}}{c_{t}}=\\left(1-\\frac{\\varepsilon(t)}{t}\\right)^{\\frac{1}{\\alpha}} \\frac{L_{0}(t-\\varepsilon(t))}{L_{0}(t)}$ one can get the following\n\n$$\n(1-\\epsilon)\\left(1-\\frac{\\varepsilon(t)}{t}\\right)^{\\frac{1}{\\alpha}+\\epsilon}-1 \\leq \\frac{c_{t-\\varepsilon(t)}}{c_{t}}-1 \\leq(1+\\epsilon)\\left(1-\\frac{\\varepsilon(t)}{t}\\right)^{\\frac{1}{\\alpha}-\\epsilon}-1\n$$\n\nfor any $0<\\epsilon<\\frac{1}{\\alpha}$, and $t \\geq t_{0, \\epsilon}$. Now taking $t \\rightarrow \\infty, \\frac{\\varepsilon(t)}{t} \\rightarrow 0$, and taking $\\epsilon$ arbitrarily small\n\n$$\n\\left(\\frac{c_{\\varepsilon(t)}}{c_{t}},\\left[\\frac{c_{t-\\varepsilon(t)}}{c_{t}}-1\\right]\\right) \\rightarrow(0,0)\n$$\n\nis proved as $t \\rightarrow \\infty$, showing the assertion.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 38,
      "text": "# 16.2 Proof of Lemma 10.3 (a) \\& (b) \n\nProof. The proof follows similar ideas (and notations) used in proving Lemma 15.2 with some differences as this is a case when variance of the increments (that is $\\operatorname{Var}\\left(\\log L_{i}^{j}\\right)$ ) does not exist.\n\nPart (a) will follow if we show that $\\frac{\\max _{1 \\leq k \\leq n} \\log \\left|Q_{k}^{j}\\right|}{c_{n}} a_{k} b_{n}$ as $n \\rightarrow \\infty$. Condition (4.14) suggests that $E\\left[\\left(\\log \\left|Q_{1}^{j}\\right|\\right)^{\\alpha+\\epsilon}\\right]=E\\left[\\left(\\log \\left|Q_{n}^{j}\\right|\\right)^{\\alpha+\\epsilon}\\right]<\\infty$, it follows that\n\n$$\n\\begin{aligned}\n& \\sum_{n=1}^{\\infty} P\\left[\\left(\\log \\left|Q_{n}^{j}\\right|\\right)^{\\alpha+\\epsilon}>n \\epsilon_{1}^{\\alpha+\\epsilon}\\right]<\\infty, \\quad \\forall \\epsilon_{1}>0 \\\\\n& \\Longleftrightarrow P\\left[\\log \\left|Q_{n}^{j}\\right|>\\epsilon_{1} n^{\\frac{1}{\\alpha+\\epsilon}} \\text { infinitely often }\\right]=0, \\quad \\forall \\epsilon_{1}>0\n\\end{aligned}\n$$\n\nHence for the set $\\left\\{\\frac{\\log \\left|Q_{k}^{j}\\right|}{k^{\\frac{1}{n+\\epsilon}}}, 1 \\leq k \\leq \\infty\\right\\}$ only finitely many exceed $\\epsilon_{1}>0$, for any arbitrarily small $\\epsilon_{1}>0$. Hence we have $\\frac{\\max _{1 \\leq k \\leq n} \\log \\left|Q_{k}^{j}\\right|}{n^{\\frac{1}{n+\\epsilon}}} a_{k} b_{n} a_{k} 0$ as $n \\rightarrow \\infty$. Since $\\epsilon>0$, and\n\n$$\n\\frac{\\max _{1 \\leq k \\leq n} \\log \\left|Q_{k}^{j}\\right|}{c_{n}}=\\frac{\\max _{1 \\leq k \\leq n} \\log \\left|Q_{k}^{j}\\right|}{n^{\\frac{1}{n+\\epsilon}}} \\frac{1}{n^{\\frac{1}{\\alpha}-\\frac{1}{\\alpha+\\epsilon}} L_{0}(n)}\n$$\n\nusing $n^{\\frac{1}{\\alpha}-\\frac{1}{\\alpha+\\epsilon}} L_{0}(n)=n^{\\left[\\left(\\frac{1}{\\alpha}-\\frac{1}{\\alpha+\\epsilon}\\right)+\\frac{\\log L_{0}(n)}{\\log n}\\right]}$, and Lemma 12.3(c) suggests that $\\frac{\\log L_{0}(n)}{\\log n} \\xrightarrow{P} 0$. Hence $\\frac{\\max _{1 \\leq k \\leq n} \\log \\left|Q_{k}^{j}\\right|}{c_{n}} a_{k} b_{n}$ as $n \\rightarrow \\infty$. Using argument similar to (15.18) the assertion of part (a) follows.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 39,
      "text": "# 16.2.1 Proof of part (b) \n\nSince $\\left(\\frac{S_{s_{t}^{j}}^{\\oplus j}}{c_{t}}, \\frac{M_{s_{t}^{j}}^{\\oplus j}}{c_{t}}\\right)=\\left(\\frac{S_{t}^{\\oplus j}}{c_{s_{t}^{j}}}, \\frac{M_{t}^{\\oplus j}}{c_{s_{t}^{j}}}\\right) \\frac{c_{s_{t}^{j}}}{c_{t}}$, and under Assumption 1 and Lemma 12.3(a), $c_{y_{t}^{j}} / c_{t} \\xrightarrow{a_{*}}\\left(\\frac{1}{E[\\mathcal{I}]}\\right)^{\\frac{1}{n}}$, part (b) will follow if we prove the following two steps,\n\n- Step 1 : $\\left(\\frac{S_{n}^{\\oplus j}}{c_{n}}, \\frac{M_{n}^{\\oplus j}}{c_{n}}\\right) \\xrightarrow{d} \\sigma_{(j, \\alpha)}\\left(\\mathbf{S}_{\\alpha, \\beta_{j}}(1), \\sup _{0 \\leq u \\leq 1} \\mathbf{S}_{\\alpha, \\beta_{j}}(u)\\right)$ as $n \\rightarrow \\infty$;\n- Step 2 : $\\left(\\frac{S_{n}^{\\oplus j}}{c_{n}}, \\frac{M_{n}^{\\oplus j}}{c_{n}}\\right)$ satisfies the Anscombe's contiguity condition for $R_{n}$ in (2.11);\nthen by replacing $n$ by $g_{t}^{j}$ (as $g_{t}^{j} \\xrightarrow{a_{*}} \\infty$ ) the result will follow.\n(A) (Proof of Step 1) Let $\\mathbf{S}_{\\alpha, \\beta}$ denote the $\\alpha$-stable Levy process $\\mathbf{S}_{\\alpha, \\beta}:=\\left(\\mathcal{S}_{\\alpha, \\beta}(t): t \\geq 0\\right)$ in $[0, \\infty)$. Recall that $S_{n}^{\\oplus j}:=\\sum_{i=1}^{n} \\log L_{i}^{j}, \\quad M_{n}^{\\oplus j}:=\\max _{1 \\leq k \\leq n}\\left\\{\\sum_{i=1}^{k} \\log L_{i}^{j}\\right\\}$ where under condition of Theorem 3(b), $E \\log L_{i}^{j}=0$ and $\\left\\{\\log L_{i}^{j}: i \\geq 1\\right\\}$ is a sequence of regularly varying random variables with index $\\alpha>0$ along with (10.1) and (10.2). Let the random curve $y_{(n)}:=\\left(y_{(n)}(t): t \\geq 0\\right)$ be defined in the following manner\n\n$$\ny_{(n)}(t):=c_{n}^{-1} S_{[n t]}^{\\oplus j}, \\quad t \\geq 0\n$$\n\nwhere it represents a stepwise functions having jumps at integers in $\\{n t: t \\geq 0\\}$, which is also the continuous time analogue of the discrete partial sum process $\\left\\{S_{n}^{\\oplus j}: n \\in \\mathbb{N}\\right\\}$. We express a FCLT motivated by Stable CLT in Theorem 4.5.3 in [62]. Under conditions of Theorem 3(b) one has\n\n$$\n\\left(c_{n}^{-1} S_{[n t]}^{\\oplus j}: t \\geq 0\\right) \\stackrel{w}{\\Longrightarrow} \\sigma_{(j, \\alpha)} \\mathbf{S}_{\\alpha, \\beta_{j}} \\quad \\text { in } \\quad\\left(D, J_{1}\\right)\n$$\n\nas $n \\rightarrow \\infty$, where $\\left(D, J_{1}\\right)$ denotes the Skorohod space under $J_{1}$ topology. Note that for any element $y \\in D$, define the functional $f: D \\rightarrow(D \\times D)$ such that\n\n$$\nf(y):=\\left((y(t), \\sup _{0 \\leq s \\leq t} y(s)): t \\geq 0\\right)\n$$\n\nand it can be shown that, $f$ is a continuous functional that is continuous almost surely at every continuity point of the Levy process $\\mathbf{S}_{\\alpha, \\beta_{j}}$. When $E \\log L_{1}^{j}=0$, using continuous mapping theorem one has as $n \\rightarrow \\infty, f\\left(y_{(n)}\\right) \\xrightarrow{w} f\\left(\\mathbf{S}_{\\alpha, \\beta_{j}}\\right)$ in $\\left(D \\times D, J_{1}\\right)$, and as a consequence one has\n\n$$\nf\\left(y_{(n)}\\right)(1) \\xrightarrow{d} f\\left(\\mathbf{S}_{\\alpha, \\beta_{j}}\\right)(1)=\\sigma_{(j, \\alpha)}\\left(\\mathbf{S}_{\\alpha, \\beta_{j}}(1), \\sup _{0 \\leq u \\leq 1} \\mathbf{S}_{\\alpha, \\beta_{j}}(u)\\right)\n$$\n\nObserve that $f\\left(y_{(n)}\\right)(1)=c_{n}^{-1}\\left(S_{n}^{\\oplus j}, M_{n}^{\\oplus j}\\right)$. Hence (16.11) implies that\n\n$$\nc_{n}^{-1}\\left(S_{n}^{\\oplus j}, M_{n}^{\\oplus j}\\right) \\xrightarrow{d} \\sigma_{(j, \\alpha)}\\left(\\mathbf{S}_{\\alpha, \\beta_{j}}(1), \\sup _{0 \\leq u \\leq 1} \\mathbf{S}_{\\alpha, \\beta_{j}}(u)\\right), \\quad \\text { as } \\quad n \\rightarrow \\infty\n$$\n\nwhich proves the assertion.\n(B) (Proof of Step 2) We proceed similar to Step 2 of (15.2). In order to show - \"Given $\\gamma>0, \\eta>0$, there exist $\\delta>0, n_{0}>0$ such that\n\n$$\nP\\left[\\max _{\\{k:|k-n|<n \\delta\\}}\\left|\\left(\\frac{S_{k}^{\\oplus j}}{c_{k}}, \\frac{M_{k}^{\\oplus j}}{c_{k}}\\right)-\\left(\\frac{S_{n}^{\\oplus j}}{c_{n}}, \\frac{M_{n}^{\\oplus j}}{c_{n}}\\right)\\right|>\\gamma\\right]<\\eta \\quad \\text { for } n \\geq n_{0} . \"\n$$\n\nit is enough if we show that given $\\gamma>0, \\eta>0$, there exist $\\delta>0, n_{1}, n_{2}>0$ such that\n\n$$\n\\begin{gathered}\nP\\left[\\max _{\\{k:|k-n|<n \\delta\\}}\\left|\\frac{S_{k}^{\\oplus j}}{c_{k}}-\\frac{S_{n}^{\\oplus j}}{c_{n}}\\right|>\\frac{\\gamma}{2}\\right]<\\frac{\\eta}{2} \\quad \\text { for } n \\geq n_{1} \\\\\nP\\left[\\max _{\\{k:|k-n|<n \\delta\\}}\\left|\\frac{M_{k}^{\\oplus j}}{c_{k}}-\\frac{M_{n}^{\\oplus j}}{c_{n}}\\right|>\\frac{\\gamma}{2}\\right]<\\frac{\\eta}{2} \\quad \\text { for } n \\geq n_{2}\n\\end{gathered}\n$$\n\nby setting $n_{0}=n_{1} \\vee n_{2}$.\nTo prove (16.14) it is enough to show that there exists $\\eta, \\gamma>0$, and large $n_{2}$ such that\n\n$$\na_{n}:=P\\left[\\max _{k: n \\leq k \\leq n(1+\\delta)}\\left|\\frac{M_{k}^{\\otimes j}}{c_{k}}-\\frac{M_{n}^{\\otimes j}}{c_{n}}\\right|>\\frac{\\gamma}{2}\\right]<\\frac{\\eta}{4} \\quad \\text { for } n \\geq n_{2}\n$$\n\nthen using similar argument the other quantity $P\\left[\\max _{\\{k: n(1-\\delta) \\leq k \\leq n\\}} \\mid \\cdot \\mid>\\frac{\\gamma}{2}\\right]$ can be shown to be less than $\\frac{\\eta}{4}$ proving (16.14). It is important to note that $c_{n}$ is increasing in $n \\geq 0$. Observe that\n\n$$\n\\begin{aligned}\na_{n} & =P\\left[\\max _{k: n \\leq k \\leq n(1+\\delta)}\\left|\\frac{M_{k}^{\\otimes j}}{c_{k}}-\\frac{M_{n}^{\\otimes j}}{c_{n}}\\right|>\\frac{\\gamma}{2}\\right] \\\\\n& \\leq P\\left[\\max _{k: n \\leq k \\leq n(1+\\delta)}\\left(\\left|\\frac{M_{k}^{\\otimes j}}{c_{k}}-\\frac{M_{k}^{\\otimes j}}{c_{n}}\\right|+\\left|\\frac{M_{k}^{\\otimes j}}{c_{n}}-\\frac{M_{n}^{\\otimes j}}{c_{n}}\\right|\\right)>\\frac{\\gamma}{2}\\right] \\\\\n& \\leq P\\left[\\max _{k: n \\leq k \\leq n(1+\\delta)}\\left|\\frac{M_{k}^{\\otimes j}}{c_{k}}-\\frac{M_{k}^{\\otimes j}}{c_{n}}\\right|>\\frac{\\gamma}{4}\\right]+P\\left[\\frac{M_{n(1+\\delta)}^{\\otimes j}-M_{n}^{\\otimes j}}{c_{n}}>\\frac{\\gamma}{4}\\right] \\\\\n& \\leq P\\left[\\frac{\\left|M_{n(1+\\delta)}^{\\otimes j}\\right|}{c_{n(1+\\delta)}}\\left(\\frac{c_{n(1+\\delta)}}{c_{n}}-1\\right)>\\frac{\\gamma}{4}\\right]+P\\left[\\frac{M_{n(1+\\delta)}^{\\otimes j}-M_{n}^{\\otimes j}}{c_{n}}>\\frac{\\gamma}{4}\\right]\n\\end{aligned}\n$$\n\nand denote the two probabilities in (16.16) respectively by $a_{n}^{(1)}$ and $a_{n}^{(2)}$. Using the Potter's bound, for any $\\epsilon_{1} \\in\\left(0,1-\\frac{1}{\\alpha}\\right)$, there exists $n_{\\epsilon_{1}}$ such that for all $n \\geq n_{\\epsilon_{1}},\\left(1-\\epsilon_{1}\\right)(1+\\delta)^{-\\epsilon_{1}} \\leq \\frac{L_{0}(n(1+\\delta))}{L_{0}(n)} \\leq$ $\\left(1+\\epsilon_{1}\\right)(1+\\delta)^{\\epsilon_{1}}$, and as a consequence\n\n$$\n\\frac{c_{n(1+\\delta)}}{c_{n}}=(1+\\delta)^{\\frac{1}{\\alpha}} \\frac{L_{0}(n(1+\\delta))}{L_{0}(n)} \\leq\\left(1+\\epsilon_{1}\\right)(1+\\delta)^{\\frac{1}{\\alpha}+\\epsilon_{1}}\n$$\n\nHence the first term $a_{n}^{(1)} \\leq P\\left[\\frac{\\left|M_{n(1+\\delta)}^{\\otimes j}\\right|}{c_{n(1+\\delta)}}\\left(\\left(1+\\epsilon_{1}\\right)(1+\\delta)^{\\frac{1}{\\alpha}+\\epsilon_{1}}-1\\right)>\\frac{\\gamma}{4}\\right]$. Since $\\frac{1}{2}<\\frac{1}{\\alpha}<1$, and the chosen $\\epsilon_{1} \\in\\left(0,1-\\frac{1}{\\alpha}\\right)$, hence $\\epsilon_{1}+\\frac{1}{\\alpha}<1$. As a consequence of that for any $\\delta>0$, we have $(1+\\delta)^{\\frac{1}{\\alpha}+\\epsilon_{1}} \\leq 1+\\frac{\\delta}{\\alpha}+\\delta \\epsilon_{1}$ and\n\n$$\n\\left(1+\\epsilon_{1}\\right)(1+\\delta)^{\\frac{1}{\\alpha}+\\epsilon_{1}} \\leq\\left(1+\\epsilon_{1}\\right)\\left(1+\\frac{\\delta}{\\alpha}+\\delta \\epsilon_{1}\\right)=: 1+g\\left(\\epsilon_{1}, \\delta\\right)\n$$\n\nwhere $g\\left(\\epsilon_{1}, \\delta\\right):=\\frac{\\delta}{\\alpha}+(1+\\delta) \\epsilon_{1}+\\epsilon_{1}\\left(\\frac{\\delta}{\\alpha}+\\delta \\epsilon_{1}\\right)$. Observe that $g\\left(\\epsilon_{1}, \\delta\\right)$ can be made arbitrarily small if we take both $\\epsilon_{1}, \\delta$ small towards 0 . It follows that for the first term\n\n$$\na_{n}^{(1)} \\leq P\\left[\\frac{\\left|M_{n(1+\\delta)}^{\\otimes j}\\right|}{c_{n(1+\\delta)}}>\\frac{\\gamma}{4 g\\left(\\epsilon_{1}, \\delta\\right)}\\right]\n$$\n\nNow given $\\gamma>0, \\eta>0$, we can choose $\\epsilon_{1}, \\delta$ arbitrarily small, such that $\\frac{\\gamma}{4 g\\left(\\epsilon_{1}, \\delta\\right)}$ will be large. Since $\\frac{M_{n}^{\\otimes j}}{c_{n}} \\xrightarrow{d} \\sigma_{(j, \\alpha)} \\sup _{0 \\leq u \\leq 1} \\mathbf{S}_{\\alpha, \\beta_{j}}(u)$ as $n \\rightarrow \\infty$, there exists $n\\left(\\epsilon_{1}, \\delta\\right)>0$ such that for all $n \\geq n\\left(\\epsilon_{1}, \\delta\\right) \\vee n_{\\epsilon_{1}}$\n\n$$\na_{n}^{(1)} \\leq P\\left[\\frac{\\left|M_{n(1+\\delta)}^{\\otimes j}\\right|}{c_{n(1+\\delta)}}>\\frac{\\gamma}{4 g\\left(\\epsilon_{1}, \\delta\\right)}\\right] \\leq \\frac{\\eta}{8}\n$$\n\nFor the second term $a_{n}^{(2)}$, with the notation $A_{1}:=\\{(x, y): 0 \\leq y<\\infty,-\\infty<x<y\\}$, it follows that\n\n$$\n\\begin{aligned}\na_{n}^{(2)} & =P\\left[M_{n(1+\\delta)}^{\\otimes j}-M_{n}^{\\otimes j}>\\frac{\\gamma}{4} c_{n}\\right] \\\\\n& =\\int_{A_{1}} P\\left[M_{n(1+\\delta)}^{\\otimes j}-M_{n}^{\\otimes j}>\\frac{\\gamma}{4} c_{n} \\mid\\left(S_{n}^{\\otimes j}, M_{n}^{\\otimes j}\\right)=(s, t)\\right] f_{\\left(S_{n}^{\\otimes j}, M_{n}^{\\otimes j}\\right)}(s, t) d s d t \\\\\n& \\stackrel{(a)}{\\leq} \\int_{A_{1}} P\\left[\\frac{M_{n \\delta}^{\\otimes j}}{c_{n \\delta}}>\\frac{t-s}{c_{n \\delta}}+\\frac{\\gamma c_{n}}{4 c_{n \\delta}}\\right] f_{\\left(S_{n}^{\\otimes j}, M_{n}^{\\otimes j}\\right)}(s, t) d s d t \\\\\n& \\stackrel{(b)}{\\leq} P\\left[\\frac{M_{n \\delta}^{\\otimes j}}{c_{n \\delta}}>\\frac{\\gamma c_{n}}{4 c_{n \\delta}}\\right]\n\\end{aligned}\n$$\n\nwhere $(a)$ follows from the independent increment property of the mean 0 , random walk $\\left(S_{n}^{\\otimes j}\\right)_{n \\geq 1}$, and the inequality $(b)$ follows by observing that for any $(s, t) \\in A_{1}$, one has $t-s>0$.\nUsing Potter's bound again for any $\\epsilon_{2}>0$, there exists $n_{\\epsilon_{2}}>0$, such that for all $n \\geq n_{\\epsilon_{2}}$, one has\n\n$$\n\\frac{c_{n}}{c_{n \\delta}}=\\left(\\frac{1}{\\delta}\\right)^{\\frac{1}{\\alpha}} \\frac{L_{0}(n)}{L_{0}(n \\delta)} \\geq\\left(1-\\epsilon_{2}\\right)\\left(\\frac{1}{\\delta}\\right)^{\\frac{1}{\\alpha}-\\epsilon_{2}}\n$$\n\nwhich implies that $a_{n}^{(2)} \\leq P\\left[\\frac{M_{n \\delta}^{\\otimes j}}{c_{n \\delta}}>\\left(1-\\epsilon_{2}\\right) \\frac{\\gamma}{4}\\left(\\frac{1}{\\delta}\\right)^{\\frac{1}{\\alpha}-\\epsilon_{2}}\\right]$ for all $n \\geq n_{\\epsilon_{2}}$.\nSelect $\\epsilon_{2} \\in\\left(0, \\frac{1}{\\alpha}\\right)$ and fix any $\\eta, \\gamma>0$. There exists $\\delta_{a, \\gamma}^{(2)}>0$, small enough so that for $\\delta<\\delta_{a, \\gamma}^{(2)}$, the quantity $\\frac{\\gamma}{4}\\left(\\frac{1}{\\delta}\\right)^{\\frac{1}{\\alpha}-\\epsilon_{2}}$ is sufficiently large and choosing $n_{\\eta, \\gamma, \\epsilon_{2}}^{(2)}$ large, so that for all $n \\geq n_{\\eta, \\gamma, \\epsilon_{2}}^{(2)}$, we will have\n\n$$\na_{n}^{(2)} \\leq P\\left[\\frac{M_{n \\delta}^{\\otimes j}}{c_{n \\delta}}>\\left(1-\\epsilon_{2}\\right) \\frac{\\gamma}{4}\\left(\\frac{1}{\\delta}\\right)^{\\frac{1}{\\alpha}-\\epsilon_{2}}\\right]<\\frac{\\eta}{8}\n$$\n\nHence putting all bounds together, combining (16.19), (16.21) it follows that $a_{n} \\leq \\frac{\\eta}{4}$, for all $n \\geq n_{2}:=$ $\\left(n\\left(\\epsilon_{1}, \\delta\\right) \\vee n_{\\epsilon_{1}}\\right) \\vee\\left(n_{\\epsilon_{2}} \\vee n_{\\eta, \\gamma, \\epsilon_{2}}^{(2)}\\right)$ proving (16.15).\nIn order to show (16.13) it is enough to show that there exists $\\eta, \\gamma>0$ and some large $n_{1}$ such that\n\n$$\nb_{n}:=P\\left[\\max _{k: n \\leq k \\leq n(1+\\delta)}\\left|\\frac{S_{k}^{\\otimes j}}{c_{k}}-\\frac{S_{n}^{\\otimes j}}{c_{n}}\\right|>\\frac{\\gamma}{2}\\right]<\\frac{\\eta}{4} \\text { for } n \\geq n_{1}\n$$\n\nUsing the following inequalities,\n\n$$\n\\begin{aligned}\nb_{n} & \\leq P\\left[\\max _{k: n \\leq k \\leq n(1+\\delta)}\\left(\\left|\\frac{S_{n}^{\\otimes j}}{c_{k}}-\\frac{S_{n}^{\\otimes j}}{c_{n}}\\right|+\\left|\\frac{S_{k}^{\\otimes j}}{c_{k}}-\\frac{S_{n}^{\\otimes j}}{c_{k}}\\right|\\right)>\\frac{\\gamma}{2}\\right] \\\\\n& \\leq P\\left[\\max _{k: n \\leq k \\leq n(1+\\delta)} \\frac{\\left|S_{n}^{\\otimes j}\\right|}{c_{n}}\\left|\\frac{c_{n}}{c_{k}}-1\\right|>\\frac{\\gamma}{4}\\right]+P\\left[\\max _{k: n \\leq k \\leq n(1+\\delta)} \\frac{\\left|S_{k}^{\\otimes j}-S_{n}^{\\otimes j}\\right|}{c_{n}}>\\frac{\\gamma}{4}\\right] \\\\\n& \\leq P\\left[\\left.\\frac{\\left|S_{n}^{\\otimes j}\\right|}{c_{n}} \\right\\rvert\\, \\frac{c_{n}}{c_{n(1+\\delta)}}-1 \\right\\rvert\\,>\\frac{\\gamma}{4}\\right]+P\\left[\\frac{\\max _{\\{k: 0 \\leq k \\leq n \\delta\\}}\\left|S_{k}^{\\otimes j}\\right|}{c_{n}}>\\frac{\\gamma}{4}\\right]\n\\end{aligned}\n$$\n\nand denote the above two terms in the RHS by $b_{n}^{(1)}, b_{n}^{(2)}$ respectively. Using (16.17) and (16.18) the first term $b_{n}^{(1)}$ can be upper bounded by $P\\left[\\frac{\\left|S_{n}^{\\otimes j}\\right|}{c_{n}}>\\frac{\\gamma}{4 g\\left(\\epsilon_{1}, \\delta\\right)}\\right]$ for any $\\epsilon_{1} \\in\\left(0,1-\\frac{1}{\\alpha}\\right)$. Since $\\frac{S_{n}^{\\otimes j}}{c_{n}} \\xrightarrow{d} \\sigma_{(j, \\alpha)} \\mathbf{S}_{\\alpha, \\beta_{j}}(1)$, for a fixed $\\gamma, \\eta>0$ we can always find a small $\\epsilon_{1}^{*}$ and $\\delta^{*}$, such that for $\\left(\\epsilon_{1}, \\delta\\right) \\in\\left(0, \\epsilon_{1}^{*}\\right) \\times\\left(0, \\delta^{*}\\right)$, the quantity $\\frac{\\gamma}{4 g\\left(\\epsilon_{1}, \\delta\\right)}$ is large and there exists $n_{2}\\left(\\epsilon_{1}, \\delta\\right)>0$ such that for all $n \\geq n_{2}\\left(\\epsilon_{1}, \\delta\\right) \\vee n_{\\epsilon_{1}}$\n\n$$\nb_{n}^{(1)} \\leq P\\left[\\frac{\\left|S_{n}^{\\otimes j}\\right|}{c_{n}}>\\frac{\\gamma}{4 g\\left(\\epsilon_{1}, \\delta\\right)}\\right] \\leq \\frac{\\eta}{8}\n$$\n\nFor bounding the second term $b_{n}^{(2)}$, we cannot use the same Kolmogorov-Maximal-inequality based technique since the random walk $\\left(S_{n}^{\\otimes j}\\right)_{n \\geq 1}$ has regularly varying increment with $1<\\alpha<2$, for non-existence of the variance of its increments. Instead we use Montgomery-Smith inequality (see Theorem 3.2 (Page 263 of [12]) also) that we state here.\n\nTheorem 7. (Montgomery-Smith's inequality) If $\\left\\{\\widetilde{X}_{i}: i \\in \\mathbb{N}\\right\\}$ are independent and identically distributed random variables, then for $1 \\leq k \\leq n<\\infty$ and all $t>0$ we have\n\n$$\nP\\left(\\max _{1 \\leq k \\leq n}\\left\\|\\sum_{i=1}^{k} \\widetilde{X}_{i}\\right\\|>t\\right) \\leq 9 P\\left(\\left\\|\\sum_{i=1}^{n} \\widetilde{X}_{i}\\right\\|>t / 30\\right)\n$$\n\nSince $\\left\\{\\log L_{i}^{j}: i \\geq 1\\right\\}$ are regularly varying with $1<\\alpha<2$, using Jensen's inequality there exists $\\alpha^{\\prime} \\in(1, \\alpha)$ such that $\\sup _{j \\in S} E\\left|\\log L_{i}^{j}\\right|^{\\alpha^{\\prime}}<\\infty$ and for any $\\delta$\n\n$$\n\\left(\\frac{\\left|S_{n \\delta}^{\\otimes j}\\right|}{n \\delta}\\right)^{\\alpha^{\\prime}} \\leq \\frac{\\sum_{i=1}^{n \\delta}\\left|\\log L_{i}^{j}\\right|^{\\alpha^{\\prime}}}{n \\delta} \\quad \\Longrightarrow \\quad E\\left[\\left|S_{n \\delta}^{\\otimes j}\\right|^{\\alpha^{\\prime}}\\right] \\leq(n \\delta)^{\\alpha^{\\prime}} E\\left|\\log L_{i}^{j}\\right|^{\\alpha^{\\prime}}\n$$\n\nIt follows that\n\n$$\n\\begin{aligned}\nP\\left[\\frac{\\max _{0 \\leq k \\leq n \\delta}\\left|S_{k}^{\\otimes j}\\right|}{c_{n}}>\\frac{\\gamma}{4}\\right] & \\stackrel{(a)}{\\leq} 9 P\\left[\\left|S_{n \\delta}^{\\otimes j}\\right|>\\frac{\\gamma c_{n}}{120}\\right] \\\\\n& \\stackrel{(b)}{\\leq} 9 \\times 120^{\\alpha^{\\prime}} \\frac{E\\left[\\left|S_{n \\delta}^{\\otimes j}\\right|^{\\alpha^{\\prime}}\\right]}{\\gamma^{\\alpha^{\\prime}} c_{n}^{\\alpha^{\\prime}}} \\\\\n& \\stackrel{(c)}{\\leq} 9 \\times 120^{\\alpha^{\\prime}}\\left(\\frac{n \\delta}{\\gamma c_{n}}\\right)^{\\alpha^{\\prime}} E\\left|\\log L_{i}^{j}\\right|^{\\alpha^{\\prime}} \\\\\n& =9 \\times 120^{\\alpha^{\\prime}}\\left(\\frac{n^{1-\\frac{1}{\\alpha}} \\delta}{\\gamma L_{0}(n)}\\right)^{\\alpha^{\\prime}} E\\left|\\log L_{i}^{j}\\right|^{\\alpha^{\\prime}}\n\\end{aligned}\n$$\n\nwhere $(a),(b),(c)$ follow respectively by using Montgomery-Smith's inequality, Chebyshev and Jensen's inequality. Now given $\\gamma, \\eta$ we can choose $\\delta_{0}$ such that\n$\\delta_{0}=\\frac{\\gamma}{120}\\left[\\frac{\\eta}{36 \\sup _{j \\in S} E\\left|\\log L_{i}^{j}\\right|^{\\alpha^{\\prime}}}\\right]^{1 / \\alpha^{\\prime}} \\frac{L_{0}(n)}{n^{1-\\frac{1}{\\alpha^{\\prime}}}}$, and then for any $\\delta<\\min \\left\\{\\delta_{0}, \\delta^{*}\\right\\}$,\n\n$$\nP\\left[\\frac{\\max _{0 \\leq k \\leq n \\delta}\\left|S_{k}^{\\otimes j}\\right|}{c_{n}}>\\frac{\\gamma}{4}\\right] \\leq 9 \\times 120^{\\alpha^{\\prime}}\\left(\\frac{n^{1-\\frac{1}{\\alpha}} \\delta}{\\gamma L_{0}(n)}\\right)^{\\alpha^{\\prime}} E\\left|\\log L_{i}^{j}\\right|^{\\alpha^{\\prime}} \\leq \\frac{\\eta}{8}\n$$\n\nPutting all bounds together, combining the lower limit for $\\delta$, it follows that $b_{n} \\leq \\frac{\\eta}{4}$, for all $n \\geq n_{1}:=$ $n_{2}\\left(\\epsilon_{1}, \\delta\\right) \\vee n_{\\epsilon_{1}}$ proving (16.22).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 40,
      "text": "# 16.3 Proof of Lemma 10.3(c) \n\nProof. This follows if both $S_{g_{t}^{j}}^{\\otimes j} / c_{t}$ and $M_{g_{t}^{\\otimes j}}^{\\otimes j} / c_{t}$ verify (6.1) separately as $H_{t}$ (since $M_{g_{t}^{\\otimes j}}^{\\otimes j} / c_{t}$ and $\\log Z_{g_{t}^{\\otimes j}}^{\\otimes j} / c_{t}$ are equivalent in probability using part (a)). For $\\delta>0$, use the same notation $A_{(\\delta, j)}:=\\{n \\in \\mathbb{N}$ : $\\left.\\left|n / t-\\mu_{j}\\right| \\leq \\delta\\right\\}$ as in Lemma 15.2(c) and observe that $\\lim _{t \\rightarrow \\infty} P\\left[g_{t}^{j} \\in A_{(\\delta, j)}\\right]=1$. Use the equality\n\n$$\n\\begin{aligned}\n& \\frac{M_{g_{t}^{\\otimes j}}^{\\otimes j}}{c_{t}}-\\frac{M_{g_{t-\\varepsilon(t)}^{\\otimes j}}^{\\otimes j}}{c_{t-\\varepsilon(t)}}=-\\frac{M_{g_{t}^{\\otimes j}}^{\\otimes j}-M_{[\\mu_{j} t]}^{\\otimes j}}{c_{t}} \\\\\n& +\\frac{M_{[\\mu_{j} t]}^{\\otimes j}}{c_{t}}-\\frac{M_{[\\mu_{j}(t-\\varepsilon(t))]}^{\\otimes j}}{c_{t-\\varepsilon(t)}}+\\frac{M_{[\\mu_{j}(t-\\varepsilon(t))]}^{\\otimes j}-M_{g_{t-\\varepsilon(t)}^{\\otimes j}}^{\\otimes j}}{c_{t-\\varepsilon(t)}}\n\\end{aligned}\n$$\n\nFor the first term in the right-hand side of (16.25),\n\n$$\n\\begin{aligned}\n& P\\left[\\frac{\\left|M_{g_{t}^{\\otimes j}}^{\\otimes j}-M_{[\\mu_{j} t]}^{\\otimes j}\\right|}{c_{t}}>\\gamma\\right] \\\\\n& \\quad \\leq P\\left[\\frac{\\left|M_{g_{t}^{\\otimes j}}^{\\otimes j}-M_{[\\mu_{j} t]}^{\\otimes j}\\right|}{c_{t}}>\\gamma, g_{t}^{j} \\in A_{(\\delta, j)}\\right]+P\\left[\\frac{\\left|M_{g_{t}^{\\otimes j}}^{\\otimes j}-M_{[\\mu_{j} t]}^{\\otimes j}\\right|}{c_{t}}>\\gamma, g_{t}^{j} \\in A_{(\\delta, j)}^{c}\\right] \\\\\n& \\quad \\leq P\\left[\\frac{M_{[\\left[\\mu_{j}+\\delta\\right) t]}^{\\otimes j}-M_{[\\mu_{j} t]}^{\\otimes j}}{c_{t}}>\\gamma\\right]+P\\left[\\frac{M_{[\\mu_{j} t]}^{\\otimes j}-M_{[\\left[\\mu_{j}-\\delta\\right) t]}^{\\otimes j}}{c_{t}}>\\gamma\\right]+P\\left[g_{t}^{j} \\notin A_{(\\delta, j)}^{c}\\right]\n\\end{aligned}\n$$\n\nThe arguments used to prove part (b) can be applied to prove that the first two terms on the right-hand side above goes to 0 , by making $\\delta$ arbitrarily small, and taking $t \\rightarrow \\infty$. The third term goes to 0 as $t \\rightarrow \\infty$ since $g_{t}^{j} / t \\xrightarrow{\\text { a.s. }} \\mu_{j}$ as $t \\rightarrow \\infty$. Consequently, the first term on the right-hand side in (16.25) goes to 0 in probability as $t \\rightarrow \\infty$. Similarly, the third term on the right-hand side in (16.25) goes to 0 in probability as $t \\rightarrow \\infty$ since $t-\\varepsilon(t) \\rightarrow \\infty$ as $t \\rightarrow \\infty$.\n\nRegarding verification for the $S_{g_{t}^{\\otimes j}}^{\\otimes j} / c_{t}$, observe that\n\n$$\n\\frac{S_{g_{t}^{\\otimes j}}^{\\otimes j}}{c_{t}}-\\frac{S_{g_{t-\\varepsilon(t)}^{\\otimes j}}^{\\otimes j}}{c_{t-\\varepsilon(t)}}=\\frac{S_{g_{t-\\varepsilon(t)}^{\\otimes j}}^{\\otimes j}}{c_{t-\\varepsilon(t)}}\\left[\\frac{c_{t-\\varepsilon(t)}}{c_{t}}-1\\right]+\\frac{\\sum_{i=g_{t-\\varepsilon(t)}+1}^{g_{t}^{\\prime}} \\log L_{i}^{j}}{c_{t}}\n$$\n\nThe upper bound can be expressed as\n\n$$\n\\left|\\frac{S_{g_{t}^{\\circ}}^{g_{j}^{\\prime}}^{\\otimes j}}{c_{t}}-\\frac{S_{g_{t-s(t)}^{\\prime}}^{\\otimes j}}{c_{t-\\varepsilon(t)}}\\right| \\leq\\left|\\frac{S_{g_{t-s(t)}^{\\prime}}^{\\otimes j}}{c_{t-\\varepsilon(t)}}\\right|\\left|\\frac{c_{t-\\varepsilon(t)}}{c_{t}}-1\\right|+\\frac{c_{\\varepsilon(t)}}{c_{t}} \\frac{\\sum_{i=g_{t-s(t)}^{\\prime}+1}^{g_{t}^{\\prime}}}{\\log L_{i}^{j}}\n$$\n\nfor $t \\geq t_{0}$. Since $\\frac{\\varepsilon(t)}{t} \\rightarrow 0$ as $t \\rightarrow \\infty$ and both quantities $\\frac{\\left|S_{g_{t-s(t)}^{\\prime}}^{\\otimes j}\\right|}{c_{t-\\varepsilon(t)}}, \\frac{\\sum_{i=g_{t-s(t)}^{\\prime}+1}^{g_{t}^{\\prime}} c_{\\varepsilon(t)}}{\\log L_{i}^{j}}$ are $O_{P}(1)$ which follows from part (b) as $(t-\\varepsilon(t)), \\varepsilon(t)$ are large. As a consequence of (16.7) $\\left(\\frac{c_{\\varepsilon(t)}}{c_{t}},\\left[\\frac{c_{t-\\varepsilon(t)}}{c_{t}}-1\\right]\\right) \\rightarrow(0,0)$, and by using Slutsky's theorem the LHS of (16.26) $\\xrightarrow{P} 0$ as $t \\rightarrow \\infty$, and this concludes the proof of part (c).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 41,
      "text": "# 16.4 Proof of results in Remark 4.2 \n\nProof. Under Assumption 1(a) the $S$-valued Markov chain $J$ is irreducible, aperiodic, and positive recurrent. Hence using that for any $f: S \\times S \\rightarrow \\mathbb{R}$, for any subset $A \\subset S \\times S$, using Proposition 2.12 .2 of [52] we have\n\n$$\n\\frac{E_{j}\\left[\\sum_{\\left(i_{1}, i_{2}\\right) \\in A} \\sum_{n=0}^{|\\widetilde{A}_{1}^{j}|-1} 1_{\\left\\{J_{n}=i_{1}, J_{n+1}=i_{2}\\right\\}} f\\left(J_{n}, J_{n+1}\\right)\\right]}{E_{j}|\\widetilde{A}_{1}^{j}|}=\\sum_{\\left(i_{1}, i_{2}\\right) \\in A} \\mu_{i_{1}} P_{i_{1} i_{2}} f\\left(i_{1} \\cdot i_{2}\\right)\n$$\n\nas under stationarity $P_{\\mu}\\left[J_{n}=i_{1}, J_{n+1}=i_{2}\\right]=\\mu_{i_{1}} P_{i_{1} i_{2}}$. The right tail-index expression can be simplified under Assumptions 1 and 4. It follows from Lemma 10.1 that\n\n$$\n\\begin{aligned}\n\\widetilde{\\alpha}_{j}^{(+)} & :=E\\left[\\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{n}} c_{i_{l} i_{l+1}}\\left[a\\left(i_{l}\\right)-E_{\\pi} a(\\cdot)\\right]^{\\alpha}\\right] \\\\\n& =E\\left|\\widetilde{A}_{1}^{j}\\right| \\frac{E\\left[\\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}^{n}} c_{i_{l} i_{l+1}} \\widetilde{a}^{\\alpha}\\left(i_{l}\\right)\\right]}{E\\left|\\widetilde{A}_{1}^{j}\\right|} \\\\\n(a) & E\\left|A_{1}^{j}\\right| \\frac{E \\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\mathbb{S}_{\\alpha}^{n}}\\left[\\sum_{n=0}^{|\\widetilde{A}_{1}^{j}|-1} 1_{\\left\\{J_{n}=i_{1}, J_{n+1}=i_{2}\\right\\}} c_{J_{n} J_{n+1}} \\widetilde{a}^{\\alpha}\\left(J_{n}\\right)\\right]}{E\\left|\\widetilde{A}_{1}^{j}\\right|} \\\\\n= & E\\left|A_{1}^{j}\\right| \\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\mathbb{S}_{\\alpha}^{n}} \\mu_{i_{1}} P_{i_{1} i_{2}} c_{i_{1} i_{2}} \\widetilde{a}^{\\alpha}\\left(i_{1}\\right)\n\\end{aligned}\n$$\n\nwhere (a) follows by observing $\\left|A_{1}^{j}\\right|=\\left|\\widetilde{A}_{1}^{j}\\right|$ and the last equality follows by using (16.27). The left tail-index expression and $\\sigma_{(j, \\alpha)}$ can be derived similarly.\n\nSecond part of the remark holds as\n\n$$\n\\begin{aligned}\nE\\left[\\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}} \\widetilde{c}_{\\varepsilon}\\left(\\left|a\\left(i_{l}\\right)\\right|\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}\\right|\\right)^{\\alpha+\\epsilon}\\right] & \\leq \\widetilde{c}_{\\varepsilon} \\sup _{x \\in S}|a(x)| E\\left[\\left|\\widetilde{A}_{1}^{j} \\cap \\mathbb{S}_{\\alpha}\\right|^{1+\\alpha+\\epsilon}\\right] \\\\\n& \\leq \\widetilde{c}_{\\varepsilon} \\sup _{x \\in S}|a(x)| E\\left[\\left|\\widetilde{A}_{1}^{j}\\right|^{1+\\alpha+\\epsilon}\\right] \\\\\n& =\\widetilde{c}_{\\varepsilon} \\sup _{x \\in S}|a(x)| E\\left[\\left|A_{1}^{j}\\right|^{1+\\alpha+\\epsilon}\\right]<\\infty\n\\end{aligned}\n$$",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 42,
      "text": "# 16.5 Proof of Proposition 4.4 \n\nProof. Note that $\\sigma_{j}^{2}=\\operatorname{Var}\\left(\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s\\right)$, and\n\n$$\n\\sigma_{j}^{2}=0 \\Longleftrightarrow P\\left[\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s=c\\right]=1\n$$\n\nfor some constant $c$. Taking expectation of $\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}}\\left(a\\left(Y_{s}\\right)-E_{\\pi} a(\\cdot)\\right) d s$ observe that $c=0$, which implies that\n\n$$\nP\\left[\\frac{\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} a\\left(Y_{s}\\right) d s}{\\tau_{1}^{j}-\\tau_{0}^{j}}=E_{\\pi} a(\\cdot)\\right]=1\n$$\n\nwhere recall that $E_{\\pi} a(\\cdot)=\\frac{E\\left[\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} a\\left(Y_{s}\\right) d s\\right]}{E\\left[\\tau_{1}^{j}-\\tau_{0}^{j}\\right]}$. Denote the set $\\left\\{\\omega \\in \\Omega: \\frac{\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} a\\left(Y_{s}\\right) d s}{\\tau_{1}^{j}-\\tau_{0}^{j}}=E_{\\pi} a(\\cdot)\\right\\}$ by $A$.\nFor each $i \\in S$, and for each $\\omega \\in A$ with $P[A]=1$, define\n\n$$\n\\tilde{T}_{i}(\\omega)=\\text { total time spent at state } i \\text { in }\\left[\\tau_{0}^{j}, \\tau_{1}^{j}\\right)\n$$\n\nNote that $\\int_{\\tau_{0}^{j}}^{\\tau_{1}^{j}} a\\left(Y_{s}\\right) d s=\\sum_{i \\in S} a(i) \\tilde{T}_{i}(\\omega)$ by definition and for each $i \\in S$ define $\\widehat{a}(i):=a(i)-E_{\\pi} a(\\cdot)$, and for each $\\omega \\in A, \\tilde{T}_{i}(\\omega)>0$ with probability 1 (since under Assumption 1 sojourn time laws do not have atom at 0 ). (16.28) can be rewritten as\n\n$$\nP\\left[\\frac{\\sum_{i \\in S} a(i) \\tilde{T}_{i}}{\\tau_{1}^{j}-\\tau_{0}^{j}}=E_{\\pi} a(\\cdot)\\right]=1 \\quad \\Longleftrightarrow \\quad \\forall \\omega \\in A, \\quad \\sum_{i \\in S} \\widehat{a}_{i} \\tilde{T}_{i}(\\omega)=0\n$$\n\nSince there are uncountably infinitely many $\\omega \\in A$, and $S$ can be only at most countably finite. Then one can always choose a finite collection $B=\\left\\{\\omega_{j}: j \\in S\\right\\}$, such that the matrix $\\left\\{\\tilde{T}_{i}\\left(\\omega_{j}\\right): i \\in S, \\omega_{j} \\in B\\right\\}$ will be almost surely non-singular. (16.29) implies that\n\n$$\n\\text { for all } \\omega_{j} \\in B, \\quad \\sum_{i \\in S} \\widehat{a}(i) \\tilde{T}_{i}\\left(\\omega_{j}\\right)=0\n$$\n\nHence the only solution for $\\{\\widehat{a}(i): i \\in S\\}$ holds iff $\\widehat{a}(i)=0 \\forall i \\in S$, proving the assertion.\nRemark 16.1. We conjecture that Proposition 4.4 holds even if $S$ is countably infinite. This can be shown if we can prove that one can always choose a countably infinite collection $B=\\left\\{\\omega_{j}: j \\in S\\right\\}$, such that the matrix $\\left\\{\\tilde{T}_{i}\\left(\\omega_{j}\\right): i \\in S, \\omega_{j} \\in B\\right\\}$ will be almost surely non-singular.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 43,
      "text": "### 16.6 Proof of Theorem 4\n\nProof. For part (a) with $a<0$, we use following notations\n\n$$\n\\begin{aligned}\n& \\left(L_{k}^{j}, Q_{k}^{j}\\right):=\\left(e^{-a\\left(\\tau_{k}^{j}-\\tau_{k-1}^{j}\\right)}, \\int_{\\tau_{k-1}^{j}}^{\\tau_{k}^{j}} b\\left(Y_{s}\\right) e^{-a\\left(\\tau_{k}^{j}-s\\right)} d s\\right), \\quad k \\geq 1 \\\\\n& \\left(L_{0}^{j}, Q_{0}^{j}\\right):=\\left(e^{-a \\tau_{0}^{j}}, \\int_{0}^{\\tau_{0}^{j}} b\\left(Y_{s}\\right) e^{-a\\left(\\tau_{0}^{j}-s\\right)} d s\\right)\n\\end{aligned}\n$$\n\nRecalling (8.4), denote the following $S_{n}^{n *}:=P_{n}\\left(\\frac{1}{L_{1}^{j}}, \\frac{Q_{1}^{j}}{L_{1}^{j}}\\right)=\\sum_{k=1}^{n}\\left(\\prod_{l=1}^{k-1} \\frac{1}{L_{l}^{j}}\\right) \\frac{Q_{k}^{j}}{L_{k}^{j}}, n \\geq 1$.\nWe begin with for any function $f(\\cdot, \\cdot): \\mathbb{R}_{\\geq 0} \\times \\mathbb{R} \\rightarrow \\mathbb{R}$\n\n$$\nP\\left[f\\left(t, I_{t}^{(a, b)}\\right) \\in A \\mid Y_{0}=i\\right]=\\sum_{j \\in S} P\\left[Y_{t}=j \\mid Y_{0}=i\\right] P\\left[f\\left(t, I_{t}^{(a, b)}\\right) \\in A \\mid Y_{0}=i, Y_{t}=j\\right]\n$$\n\nObserve that on the event $\\left\\{Y_{0}=i, Y_{t}=j\\right\\}$ for $f\\left(t_{1}, x\\right)=e^{a t_{1}} x$ one has\n\n$$\n\\begin{aligned}\n& e^{a t} I_{t}^{(a, b)} \\stackrel{d}{=} \\frac{\\int_{0}^{t} b\\left(Y_{s}\\right) e^{a(s-t)} d s}{e^{-a t}} \\\\\n& =\\frac{G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)+e^{-a\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left[\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) Q_{0}^{j}+\\sum_{k=1}^{g_{t}^{j}}\\left(\\prod_{l=k+1}^{g_{t}^{j}} L_{l}^{j}\\right) Q_{k}^{j}\\right]}{e^{-a\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right) e^{-a \\tau_{0}^{j}}} \\\\\n& =\\frac{G_{j}^{a, b}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}{e^{-a t}}+\\frac{Q_{0}^{j}+S_{g_{t}^{j}}^{* *}}{L_{0}^{j}} \\\\\n& \\stackrel{P}{\\rightarrow} \\frac{Q_{0}^{j}+S_{\\infty}^{* *}}{L_{0}^{j}}\n\\end{aligned}\n$$\n\nas $t \\rightarrow \\infty$. Last step follows by using $a<0$ and proceeding similarly to the derivation done in the display (15.5). Notice that using similar steps of Lemma 6.2 with relevant assumptions $S_{\\infty}^{* *}$ satisfies the unique solution of the SRE\n\n$$\nS_{\\infty}^{* *} \\stackrel{d}{=} \\frac{1}{L_{1}^{j}} S_{\\infty}^{* *}+\\frac{Q_{1}^{j}}{L_{1}^{j}}, \\quad S_{\\infty}^{* *} \\perp\\left(\\frac{1}{L_{1}^{j}}, \\frac{Q_{1}^{j}}{L_{1}^{j}}\\right)\n$$\n\nUsing (16.31), proceeding similar to the way we proved Theorem 2(a) from (15.2), the assertion of part (a) follows by taking limit $t \\rightarrow \\infty$ in (16.30), denoting $S_{\\infty}^{* *}$ by $\\widetilde{V}_{j}$.\n\nUnder the conditions of part (b) (that is when $a=0$ ) observe that\n\n$$\nI_{t}^{(0, b)}=\\int_{0}^{t} b\\left(Y_{s}\\right) d s\n$$\n\nand then applying the law of large number for renewal process (under condition $E_{\\pi}|b(\\cdot)|<\\infty$ ) yields\n\n$$\n\\frac{I_{t}^{(0, b)}}{t}=\\frac{\\int_{0}^{t} b\\left(Y_{s}\\right) d s}{t} \\stackrel{a, x}{\\rightarrow} E_{\\pi} b(\\cdot)\n$$\n\nas $t \\rightarrow \\infty$ as required.\n\nFor the rest parts, we sketch the proofs omitting the details, as they are very similar to steps of Theorem 2(a) and Theorem 3(a) and follow finally by using (16.30) by taking $f(t, x)=x$. Observe that on the set $\\left\\{Y_{0}=i, Y_{t}=j\\right\\}$ one has\n\n$$\n\\int_{0}^{t} b\\left(Y_{s}\\right) d s=\\sum_{i=1}^{g_{t}^{j}} \\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}} b\\left(Y_{s}\\right) d s+\\int_{0}^{\\tau_{0}^{j}} b\\left(Y_{s}\\right) d s+b(j)\\left(t-\\tau_{g_{t}^{j}}\\right)\n$$\n\nwhere $\\sum_{i=1}^{g_{t}^{j}} \\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}} b\\left(Y_{s}\\right) d s$ is the key term determining the asymptotics result while $\\int_{0}^{\\tau_{0}^{j}} b\\left(Y_{s}\\right) d s+b(j)\\left(t-\\tau_{g_{t}^{j}}\\right)$ is just a $O_{p}(1)$ which goes to 0 asymptotically after division with any exponent of $t$. Since $\\left(\\sum_{i=1}^{g_{t}^{j}} \\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}} b\\left(Y_{s}\\right) d s:\\right.$ $t \\geq 0$ ) can be seen as a renewal reward process with $i$-th reward being $\\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}} b\\left(Y_{s}\\right) d s$, using results derived in (15.3) of Theorem 2(a) and Theorem 3(a), one can the subsequently derive results based on conditions if $\\sigma_{j,(b)}^{2}$ is finite, or $=\\infty$ or $=0$.\n\nWe prove the result for (ii). Observe that if $\\widetilde{b}(\\cdot):=b(\\cdot)-E_{\\pi} b(\\cdot)$, then on $\\left\\{Y_{0}=i, Y_{t}=j\\right\\}$\n\n$$\nI_{t}^{(0, b)}-t E_{\\pi} b(\\cdot)=\\sum_{i=1}^{g_{t}^{j}} \\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}} \\widetilde{b}\\left(Y_{s}\\right) d s+\\int_{0}^{\\tau_{0}^{j}} \\widetilde{b}\\left(Y_{s}\\right) d s+\\widetilde{b}(j)\\left(t-\\tau_{g_{t}^{j}}\\right)\n$$\n\nUnder Assumptions 4(a),(b) with $a(\\cdot)$ replaced by $b(\\cdot)$, Lemma 10.1 suggests that $\\int_{\\tau_{0}^{j}}^{\\tau_{i}^{j}} \\widetilde{b}\\left(Y_{s}\\right) d s=\\int_{\\tau_{0}^{j}}^{\\tau_{i}^{j}}\\left(b\\left(Y_{s}\\right)-\\right.$ $E_{\\pi} b(\\cdot)) d s$ is regularly varying with index $\\alpha_{b}$, along with the slowly varying function $L_{1}(\\cdot)$, with following\n\nright and left tail asymptotic limits\n\n$$\n\\begin{aligned}\n\\widetilde{\\alpha}_{j,(b)}^{(+)} & =E\\left[\\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\widetilde{A}_{l}^{1} \\cap \\widetilde{\\widetilde{\\omega}_{a_{b}}}^{+}} c_{i_{l} i_{l+1}}\\left[b\\left(i_{l}\\right)-E_{\\pi} b(\\cdot)\\right]^{\\alpha_{b}}\\right] \\\\\n\\widetilde{\\alpha}_{j,(b)}^{(-)} & =E\\left[\\sum_{\\left(i_{l}, i_{l+1}\\right) \\in \\widetilde{A}_{l}^{1} \\cap \\widetilde{\\widetilde{\\omega}_{a_{b}}}^{-}} c_{i_{l} i_{l+1}}\\left|b\\left(i_{l}\\right)-E_{\\pi} b(\\cdot)\\right|^{\\alpha_{b}}\\right] \\\\\n\\widetilde{\\beta}_{j,(b)} & =\\frac{\\widetilde{\\alpha}_{j,(b)}^{(-)}-\\widetilde{\\alpha}_{j,(b)}^{(+)}}{\\widetilde{\\alpha}_{j,(b)}^{(+)}+\\widetilde{\\alpha}_{j,(b)}^{(-)}}\n\\end{aligned}\n$$\n\nOnly for this part denote $t^{1 / \\alpha_{b}} L_{1}(t), n^{1 / \\alpha_{b}} L_{1}(n)$ by $\\tilde{c}_{t}, \\tilde{c}_{n}$ respectively. For each $j \\in S$ using the quantity $\\widetilde{\\beta}_{j,(b)}$ above, applying the stable central limit Theorem 4.5.1 of [62], as sample size $n \\rightarrow \\infty$ one has\n\n$$\n\\widetilde{c}_{n}^{-1}\\left(\\sum_{i=1}^{n} \\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}} \\widehat{b}\\left(Y_{s}\\right) d s\\right) \\xrightarrow{d} \\sigma_{\\left(j, \\alpha_{b},(b)\\right)} \\mathcal{S}_{\\alpha_{b}}\\left(1,-\\beta_{j,(b)}, 0\\right)\n$$\n\nUsing (16.32) and Theorem 3.2 of [34] for the stopped random time $g_{t}^{j}$ as $t \\rightarrow \\infty$,\n\n$$\n\\frac{\\sum_{i=1}^{g_{t}^{j}} \\int_{\\tau_{i-1}^{j}}^{\\tau_{i}^{j}} \\widehat{b}\\left(Y_{s}\\right) d s}{\\left(g_{t}^{j}\\right)^{\\frac{1}{a_{b}}} L_{1}\\left(g_{t}^{j}\\right)} \\xrightarrow{d} \\sigma_{\\left(j, \\alpha_{b},(b)\\right)} \\mathcal{S}_{\\alpha_{b}}\\left(1,-\\beta_{j,(b)}, 0\\right)\n$$\n\nFurthermore observe $\\tau_{0}^{j}+\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)$ is $O_{p}(1)$ and $\\lim _{t \\rightarrow \\infty} \\frac{\\tilde{c}_{n j}}{\\tilde{c}_{t}}=\\left(\\frac{1}{E\\left|\\mathcal{H}_{1}^{j}\\right|}\\right)^{\\frac{1}{\\alpha_{b}}}$ (see Lemma 12.3(a)). Hence as $t \\rightarrow \\infty$ we have\n\n$$\n\\mathcal{L}\\left(\\widetilde{c}_{t}^{-1}\\left[I_{t}^{(0, b)}-t E_{\\pi} b(\\cdot)\\right]\\left|Y_{0}=i, Y_{t}=j\\right\\rangle \\stackrel{\\infty}{\\rightarrow} \\mathcal{L}\\left(\\left(E\\left|\\mathcal{H}_{1}^{j}\\right|\\right)^{-\\frac{1}{\\alpha_{b}}} \\sigma_{\\left(j, \\alpha_{b},(b)\\right)} \\mathcal{S}_{\\alpha_{b}}\\left(1,-\\beta_{j,(b)}, 0\\right)\\right)\\right.\n$$\n\nPutting this estimate in (16.30) using $f(t, x)=x$, and taking $t \\rightarrow \\infty$, the second part of Theorem 4(b) will follow. Third part is trivial and the proof is omitted.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 44,
      "text": "# 17 Proof of Supplementary parts of Corollary 4.5\n### 17.0.1 Proof of Lemma 11.1(a)\n\nProof. Proceeding similar to the proof of Theorem 2(a) (and using same notation) observe that,\n\n$$\n\\begin{aligned}\n\\left|I_{t}^{(m a, b)}\\right|^{\\frac{1}{m}} & =\\left|\\int_{0}^{t} b\\left(Y_{s}\\right) e^{-\\int_{s}^{t} m a\\left(Y_{r}\\right) d r} d s\\right|^{\\frac{1}{m}} \\\\\n& =\\Phi_{t}^{(a)}\\left|\\widehat{I}_{t}^{(m a, b)}\\right|^{\\frac{1}{m}}\n\\end{aligned}\n$$\n\nSuppose $\\left\\{\\left(L_{i, m}^{j}, Q_{i, m}^{j}\\right): i \\geq 1\\right\\},\\left(L_{0, m}^{j}, Q_{0, m}^{j}\\right)$ are defined similarly as $\\left\\{\\left(L_{i}^{j}, Q_{i}^{j}\\right): i \\geq 1\\right\\}$ and $\\left(L_{0}^{j}, Q_{0}^{j}\\right)$ by replacing $a(\\cdot)$ by $m a(\\cdot)$ respectively. $\\left\\{S_{n, m}^{*}: n \\geq 1\\right\\}$ are defined as\n\n$$\nS_{n, m}^{* *}:=P_{n}\\left(\\frac{1}{L_{1, m}^{j}}, \\frac{Q_{1, m}^{j}}{L_{1, m}^{j}}\\right)=\\sum_{i=1}^{n} \\frac{Q_{i, m}^{j}}{L_{i, m}^{j}} \\prod_{k=1}^{i-1}\\left(\\frac{1}{L_{k, m}^{j}}\\right)\n$$\n\nObserve that on $\\left\\{Y_{0}=i, Y_{t}=j\\right\\}$,\n\n$$\n\\widehat{I}_{t}^{(m a, b)}=\\left[\\frac{Q_{0, m}^{j}+S_{g_{t}^{j}, m}^{* *}}{L_{0, m}^{j}}+\\frac{O_{j}^{(m a, b)}\\left(t-\\tau_{g_{t}^{j}}\\right)}{\\Phi_{t}^{(m a)}}\\right]\n$$\n\nUsing same notations as in the proof of Theorem 2(a), let $\\widetilde{G}_{t}^{(3, m)}$ be defined as\n\n$$\n\\widetilde{G}_{t}^{(3, m)}:=\\left[\\frac{Q_{0, m}^{j}+S_{g_{t}^{j}, m}^{**}}{L_{0, m}^{j}}+\\frac{G_{j}^{(m a, b)}\\left(t-\\tau_{g_{t}^{j}}\\right)}{\\Phi_{t}^{(m a)}}\\right]^{\\frac{1}{m \\sqrt{t}}}\n$$\n\nObserve that\n\n$$\n\\mathcal{L}\\left(\\left|\\widetilde{I}_{t}^{(m a, b)}\\right|^{\\frac{1}{m \\sqrt{t}}}\\left|Y_{0}=i, Y_{t}=j\\right)=\\mathcal{L}\\left(\\widetilde{G}_{t}^{(3, m)} \\mid Y_{0}=i, Y_{t}=j\\right)\\right.\n$$\n\nand furthermore\n\n$$\n\\begin{aligned}\n\\mathcal{L} & \\left(\\left(\\frac{\\left.\\left.[\\Phi_{t}^{(a)}\\right]^{\\frac{1}{\\sqrt{t}}}}{e^{-\\sqrt{t} E_{*} a(\\cdot)}}, \\frac{\\left|I_{t}^{(m a, b)}\\right|^{\\frac{1}{m \\sqrt{t}}}}{e^{-\\sqrt{t} E_{*} a(\\cdot)}}\\right) \\mid Y_{0}=i, Y_{t}=j\\right) \\\\\n& =\\mathcal{L}\\left(\\left(G_{t}^{(1)} G_{t}^{(2)}, G_{t}^{(1)} G_{t}^{(2)} \\widetilde{G}_{t}^{(3, m)}\\right) \\mid Y_{0}=i, Y_{t}=j\\right)\n\\end{aligned}\n$$\n\nSince $S_{g_{t}^{j}, m}^{**} \\xrightarrow{d} S_{m}^{**}$ where $S_{m}^{**}$ satisfies\n\n$$\nS_{m}^{**} \\stackrel{d}{=} \\frac{1}{L_{1, m}^{j}} S_{m}^{**}+\\frac{Q_{1, m}^{j}}{L_{1, m}^{j}}, \\text { with } E \\log \\left[\\frac{1}{L_{1, m}^{j}}\\right]<0, E \\log ^{+}\\left|\\frac{Q_{1, m}^{j}}{L_{1, m}^{j}}\\right|<\\infty\n$$\n\nunder Assumption 3(c) with $(a, b)$ replaced by $(m a, b)$.\nHence $S_{g_{t}^{j}, m}^{**}$ is $O_{p}(1)$, along with $\\left(L_{0, m}^{j}, Q_{0, m}^{j}, t-\\tau_{g_{t}^{j}}\\right)$. Since $\\Phi_{t}^{(m a)} \\rightarrow \\infty$, as $t \\rightarrow \\infty$\n\n$$\n\\mathcal{L}\\left(\\widetilde{G}_{t}^{(3, m)} \\mid Y_{0}=i, Y_{t}=j\\right)=\\exp \\left[\\frac{\\log \\left|\\frac{Q_{0, m}^{j}+S_{g_{t}^{j}, m}^{**}}{L_{0, m}^{j}}+\\frac{G_{j}^{(m a, b)}\\left(t-\\tau_{g_{t}^{j}}\\right)}{\\Phi_{t}^{(m a)}}\\right]}{m \\sqrt{t}}\\right] \\frac{n}{t} \\delta_{\\{1\\}}\n$$\n\nUsing similar analysis on the asymptotic results of $G_{t}^{(1)}, G_{t}^{(2)}$, proceeding as the rest of the proof of Theorem 2(a), the assertion of Lemma 11.1(a) will follow.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 45,
      "text": "# 17.0.2 Proof of Lemma 11.1(b) \n\nLet $\\left\\{\\left(L_{i, m}^{j}, Q_{i, m}^{j}\\right): i \\geq 0\\right\\}$ be defined as in Lemma 11.1(a) and for any $n \\geq 1$, denote $Z_{n, m}^{\\otimes j}:=\\max _{1 \\leq k \\leq n}\\left\\{\\left(\\prod_{i=1}^{k-1} L_{i, m}^{j}\\right)\\left|Q_{k, m}^{j}\\right|\\right\\}$ and\n\n$$\nP_{n, m}^{(j)}:=\\sum_{k=1}^{n}\\left(\\prod_{i=1}^{k-1} L_{i, m}^{j}\\right) Q_{k, m}^{j}, \\quad \\widetilde{P}_{n, m}^{(j)}:=\\sum_{k=1}^{n}\\left(\\prod_{i=k+1}^{n} L_{i, m}^{j}\\right) Q_{k, m}^{j}\n$$\n\nProof. Using a similar approach and notations of the proof of Theorem 2(b), we observe that\n\n$$\n\\begin{aligned}\n\\left(\\log \\Phi_{t}^{(a)}, \\frac{\\log \\left|I_{t}^{(m a, b)}\\right|}{m}\\right) \\stackrel{\\mathcal{L}\\left(\\cdot \\mid Y_{0}=i, Y_{t}=j\\right)}{=} & \\left(\\log L_{0}^{j}+\\log \\left(\\prod_{k=1}^{g_{t}^{j}} L_{k}^{j}\\right)+\\log \\left(e^{-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\right)\\right. \\\\\n& \\left.\\frac{1}{m} \\log \\left|e^{-m a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left[\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k, m}^{j}\\right) Q_{0, m}^{j}+\\widetilde{P}_{g_{t}^{j}, m}^{(j)}\\right]+G_{j}^{(m a, b)}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right]\\right) \\\\\n& \\stackrel{d}{=}\\left(S_{g_{t}^{j}}^{\\otimes j}+\\left[\\log L_{0}^{j}-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right], \\frac{\\log Z_{g_{t}^{j}, m}^{\\otimes j}}{m}+\\frac{1}{m} \\log \\left|B_{i, m}^{(1)}+\\frac{B_{t, m}^{(2)}}{Z_{g_{t}^{j}, m}^{\\otimes j}} P_{g_{t}^{j}, m}^{(j)}\\right|\\right)\n\\end{aligned}\n$$\n\nwhere\n\n$$\n\\begin{aligned}\n& B_{t, m}^{(1)}=\\frac{e^{-m a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k, m}^{j}\\right) Q_{0, m}^{j}+G_{j}^{(m a, b)}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}{Z_{g_{t}^{j}, m}^{\\otimes j}} \\\\\n& B_{t, m}^{(2)}=e^{-m a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}\n\\end{aligned}\n$$\n\nand denote $\\left(B_{t, m}^{(1)}+B_{t, m}^{(2)} \\frac{P_{g_{t}^{j}, m}^{(j)}}{Z_{g_{t}^{j}, m}^{(j)}}\\right)$ by $B_{t, m}^{(3)}$. We now consider the scaled limit of $\\left(\\frac{\\log \\Phi_{t}^{(a)}}{\\sqrt{t}}, \\frac{\\log \\left|I_{t}^{(m a, b)}\\right|}{m \\sqrt{t}}\\right)$ as $t \\rightarrow \\infty$. Observe that\n\n$$\nB_{t, m}^{(1)}=\\frac{e^{-m a(j)\\left(t-r_{g_{t}^{j}}^{j}\\right)}\\left(\\prod_{k=1}^{g_{t}^{j}} L_{k, m}^{j}\\right) Q_{0, m}^{j}+G_{j}^{(m a, b)}\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)}{\\max _{1 \\leq k \\leq g_{t}^{j}}\\left(\\prod_{i=1}^{k-1} L_{i, m}^{j}\\right)\\left|Q_{k, m}^{j}\\right|}\n$$\n\nand $B_{t, m}^{(2)}$ are both $O_{p}(1)$ by construction, and for each $1 \\leq k \\leq n$,\n\n$$\n-\\max _{1 \\leq k \\leq g_{t}^{j}}\\left(\\prod_{i=1}^{k-1} L_{i, m}^{j}\\right)\\left|Q_{k, m}^{j}\\right| \\leq Q_{k, m}^{j}\\left(\\prod_{i=1}^{k-1} L_{i, m}^{j}\\right) \\leq \\max _{1 \\leq k \\leq g_{t}^{j}}\\left(\\prod_{i=1}^{k-1} L_{i, m}^{j}\\right)\\left|Q_{k, m}^{j}\\right|\n$$\n\nHence for all $1 \\leq k \\leq n, Q_{k, m}^{j}\\left(\\prod_{i=1}^{k-1} L_{i, m}^{j}\\right) \\in\\left(-Z_{n, m}^{\\otimes j}, Z_{n, m}^{\\otimes j}\\right)$. This implies that for all $n \\geq 1$,\n\n$$\n-n Z_{n, m}^{\\otimes j} \\leq P_{n, m}^{(j)} \\leq n Z_{n, m}^{\\otimes j}\n$$\n\nwhich further implies that $\\left|\\frac{P_{g_{t}^{j}, m}^{(j)}}{Z_{g_{t}^{j}, m}^{(j)}}\\right| \\leq g_{t}^{j}$; hence $\\left|B_{t, m}^{(3)}\\right|=O_{p}(t)$ and strictly positive. As $t \\rightarrow \\infty$,\n\n$$\n\\frac{\\log \\left|B_{t, m}^{(3)}\\right|}{m \\sqrt{t}}=\\frac{\\log \\left|B_{t, m}^{(1)}+B_{t, m}^{(2)} \\frac{P_{g_{t}^{j}, m}^{(j)}}{Z_{g_{t}^{j}, m}^{(j)}}\\right|}{m \\sqrt{t}} \\xrightarrow{P} 0\n$$\n\nNow we proceed identically as done in Theorem 2(b) and observe that\n\n$$\n\\begin{aligned}\n& P\\left[\\left(\\frac{\\log \\Phi_{t}^{(a)}}{\\sqrt{t}}, \\frac{\\log \\left|I_{t}^{(m a, b)}\\right|}{m \\sqrt{t}}\\right) \\in \\cdot \\quad \\mid Y_{0}=i\\right] \\\\\n& =\\sum_{j \\in S} P\\left[Y_{t}=j \\mid Y_{0}=i\\right] P\\left[\\left(\\frac{\\log \\Phi_{t}^{(a)}}{\\sqrt{t}}, \\frac{\\log \\left|I_{t}^{(m a, b)}\\right|}{m \\sqrt{t}}\\right) \\in \\cdot \\quad \\mid Y_{0}=i, Y_{t}=j\\right] \\\\\n& =\\sum_{j \\in S} \\pi_{j} \\lim _{t \\rightarrow \\infty} P\\left[\\left(\\frac{Z_{g_{t}^{j}, m}^{(j)}}{\\sqrt{t}}, \\frac{\\log Z_{g_{t}^{j}, m}^{(j)}}{m \\sqrt{t}}\\right) \\in \\cdot \\quad \\mid Y_{0}=i\\right]\n\\end{aligned}\n$$\n\nby applying Lemma 6.1, with\n\n$$\nL_{t}^{(1)}:=\\left(\\frac{\\left|\\log L_{0}^{j}-a(j)\\left(t-\\tau_{g_{t}^{j}}^{j}\\right)\\right|}{\\sqrt{t}}, \\frac{\\log \\left|B_{t, m}^{(3)}\\right|}{m \\sqrt{t}}\\right)^{\\prime}, H_{t}:=\\left(\\frac{Z_{g_{t}^{j}}^{j}}{\\sqrt{t}}, \\frac{\\log Z_{g_{t}^{j}, m}^{\\otimes j}}{m \\sqrt{t}}\\right)^{\\prime}\n$$\n\nand $L_{t}^{(2)}$ defined as in Theorem 2(b) (with the verification lemma that $H_{t}$ satisfies (6.1), using ideas similar to Lemma 15.2(c)).\n\nFor any two sequences $\\left\\{u_{k}\\right\\}_{k \\geq 1},\\left\\{v_{k}\\right\\}_{k \\geq 1}$, one has\n\n$$\n\\max \\left\\{u_{k}\\right\\}-\\max \\left\\{v_{k}\\right\\} \\leq \\max \\left\\{u_{k}+v_{k}\\right\\} \\leq \\max \\left\\{u_{k}\\right\\}+\\max \\left\\{v_{k}\\right\\}\n$$\n\nAs a result we can bound\n\n$$\n\\begin{aligned}\n\\log Z_{g_{t}^{j}, m}^{\\otimes j} & =\\max _{1 \\leq k \\leq g_{t}^{j}}\\left\\{\\log \\left(\\prod_{i=1}^{K-1} L_{i, m}^{j}\\right)\\left|Q_{k, m}^{j}\\right|\\right\\} \\\\\n& =\\max _{1 \\leq k \\leq g_{t}^{j}}\\left(\\sum_{i=1}^{k-1} \\log L_{i, m}^{j}+\\log \\left|Q_{k, m}^{j}\\right|\\right\\} \\\\\n& =\\max _{1 \\leq k \\leq g_{t}^{j}}\\left\\{m \\sum_{i=1}^{k-1} \\log L_{i}^{j}+\\log \\left|Q_{k, m}^{j}\\right|\\right\\}\n\\end{aligned}\n$$\n\nin the following manner\n\n$$\n\\frac{M_{g_{l}^{\\circ}}^{\\otimes j}}{\\sqrt{t}}-\\frac{\\max _{1 \\leq k \\leq g_{l}^{j}} \\log \\left|Q_{k, m}^{j}\\right|}{m \\sqrt{t}} \\leq \\frac{\\log Z_{g_{l}^{\\circ}, m}^{\\otimes j}}{m \\sqrt{t}} \\leq \\frac{M_{g_{l}^{\\circ}}^{\\otimes j}}{\\sqrt{t}}+\\frac{\\max _{1 \\leq k \\leq g_{l}^{j}} \\log \\left|Q_{k, m}^{j}\\right|}{m \\sqrt{t}}\n$$\n\nSince (4.3) holds with $(a, b)$ replaced by $(m a, b)$, it follows that $\\frac{\\max _{1 \\leq k \\leq g_{l}^{j}} \\log \\left|Q_{k, m}^{j}\\right|}{m \\sqrt{t}} \\stackrel{a, b}{\\rightarrow} 0$ (following arguments similar to Lemma 15.2(a)). We get the final result by applying the weak limit of $\\left(\\frac{S_{l}^{\\otimes j}}{\\sqrt{t}}, \\frac{M_{g_{l}^{\\circ}}^{\\otimes j}}{\\sqrt{t}}\\right)$ by using Lemma 15.2(b).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 46,
      "text": "# 17.1 Proof of Corollary 5.2 \n\nProof. Proceeding similar to the proof of Theorem 5.9, integrating in the range $[0, t]$ yields,\n\n$$\n\\begin{aligned}\nX_{t} & =X_{0} e^{-\\int_{0}^{t} a\\left(Y_{s}\\right) d s}+\\int_{0}^{t} b\\left(Y_{s}\\right) e^{-\\int_{s}^{t} a\\left(Y_{r}\\right) d r} d \\mathbf{S}_{\\alpha^{*}, 0}(s) \\\\\n& \\stackrel{d}{=} X_{0} \\Phi_{t}^{(a)}+\\left|I_{t}^{\\left(\\alpha^{*} a, b^{\\alpha^{*}}\\right.}\\right|^{1 / \\alpha^{*}} \\mathcal{S}_{\\alpha^{*}}(1,0,0)\n\\end{aligned}\n$$\n\nUsing the continuous mapping theorem on Theorem 1, part (A) will follow.\nFor the rest of part (B), (C), (D) we observe that marginal evolution of the process at (17.4) resembles with $Z_{t}^{(2)}$ in Corollary 4.5 of [?] with $a_{2}=X_{0}, b_{2}=\\mathcal{S}_{\\alpha^{*}}(1,0,0), m=\\alpha^{*}$; hence all the results will follow by replacing $(a, b)$ by $\\left(a, b^{\\alpha^{*}}\\right)$ in Corollary 4.5 for $\\left|Z_{t}^{(2)}\\right|$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 47,
      "text": "## 18 Proofs of the lemmas in the Appendix with some additional results\n\nProofs of Lemma 12.1, Proposition 2.2, Lemma 12.2, Lemma 12.3(a),(b),(c), and one supplementary result are given here.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 48,
      "text": "### 18.1 Proof of Lemma 12.1\n\nProof. We use the notations similar to section 8 of [20]. Define the matrix of functions $A(t):=\\left(A_{i j}(t)\\right.$ : $i, j \\in S)$ such that $A_{i j}(t):=Q_{i j}(t)=P\\left[J_{1}=j, T_{1} \\leq t \\mid J_{0}=j\\right]=P_{i j} F_{i j}(t) . A$ represents the semi-Markov matrix. For any two matrix valued functions $B(t):=\\left(B_{i j}(t): i, j \\in S\\right), C(t):=\\left(C_{i j}(t): i, j \\in S\\right)$, by the convolution $B \\star C$ we denote the matrix valued functions where for each $i, j \\in S, \\quad(B \\star C)_{i j}(t):=$ $\\int_{0}^{t} \\sum_{k \\in S} B_{i k}(d u) C_{k j}(t-u)=\\int_{0}^{t} \\sum_{k \\in S} B_{i k}(t-u) C_{k j}(d u)$. This manner recursively for $n \\geq 1$, we have $A^{(n)}=A \\star A^{(n-1)}$ and the interpretation of $A_{i j}^{(n)}(t)=P\\left[Y_{n}=j, T_{n} \\leq t \\mid Y_{0}=i\\right]$. Define the renewal function at state $j$ starting from $i$ as $R_{i j}(t):=E\\left[\\left(g_{t}^{j}+1\\right) 1_{\\left\\{t \\geq \\tau_{t}^{j}\\right\\}} \\mid Y_{0}=i\\right]=\\sum_{n \\geq 0} A_{i j}^{(n)}(t)$ as the expected number of hitting at state $j$ before time $t$. Using similar notations of [20] by $V^{-}(t)$ we denote $t-S_{N_{t}}$. Note that on $\\left\\{Y_{t}=j\\right\\}, \\tau_{g_{t}^{j}}=S_{N_{t}}$, hence we can safely write $P_{.}\\left[t-\\tau_{g_{t}^{j}}^{j}>x, Y_{t}=j\\right]=P_{.}\\left[t-S_{N_{t}}>x, Y_{t}=\\right.$ $\\left.j]=P_{.}\\left[V^{-}(t)>x, Y_{t}=j\\right]$.\n\nObserve that\n\n$$\n\\begin{aligned}\n& P_{.}\\left[V^{-}(t)>x, Y_{t}=j\\right]=P_{.}\\left[V^{-}(t)>x, Y_{t}=j, T_{1}>t\\right]+P_{.}\\left[V^{-}(t)>x, Y_{t}=j, T_{1}<t\\right] \\\\\n& \\quad=\\delta_{\\{i=j\\}} 1_{\\{t>x\\}} P\\left[T_{1}>t \\mid Y_{0}=j\\right]+\\sum_{k \\in S} \\int_{0}^{t} P_{i k} F_{i k}(d u) P_{k}\\left[V^{-}(t-u)>x, Y_{t-u}=j\\right] \\\\\n& \\quad=\\delta_{\\{i=j\\}} 1_{\\{t>x\\}} \\sum_{k \\in S} P_{j k} \\bar{F}_{j k}(t)+\\sum_{k \\in S} \\int_{0}^{t} A_{i k}(d u) P_{k}\\left[V^{-}(t-u)>x, Y_{t-u}=j\\right]\n\\end{aligned}\n$$\n\nNow for fixed $i, x$, writing $U_{j}(t):=P_{i}\\left[V^{-}(t)>x, Y_{t}=j\\right]$, and\n\n$$\nG_{j}(t):=\\delta_{\\{i=j\\}} 1_{\\{t>x\\}} \\sum_{k \\in S} P_{j k} \\bar{F}_{j k}(t)\n$$\n\nfrom aforementioned relation we have the renewal equation\n\n$$\nU=G+A \\star U\n$$\n\nObserve that $G_{j}(t)=\\delta_{\\{i=j\\}} 1_{\\{t>x\\}} \\sum_{k \\in S} P_{j k} \\bar{F}_{j k}(t)=\\delta_{\\{i=j\\}} 1_{\\{t>x\\}}\\left(1-F_{j}(t)\\right) \\leq\\left(1-F_{j}(t)\\right)=1-A_{j}(t) 1$, which implies that $G \\leq 1-A .1$ co-ordinate wise, and as a consequence of Theorem 3.17 of [20] there exists a solution of the equation (18.1), and from Theorem 3.11 and display 4.9 of [20] the solution is unique if all states are conservative (which is granted under Assumption 1). The minimal solution satisfies\n\n$$\n\\begin{aligned}\nP_{i}\\left[V^{-}(t)>x, Y_{t}=j\\right] & =\\int_{0}^{t} R_{i j}(d u) 1_{\\{t-u>x\\}}\\left(1-F_{j}(t-u)\\right) \\\\\n& =\\int_{0}^{t} R_{i j}(d u) 1_{\\{t-u>x\\}} \\sum_{k \\in S} P_{j k} \\bar{F}_{j k}(t-u)\n\\end{aligned}\n$$\n\nNow using analog of Key-Renewal Theorem 6.3 of [20] gives\n\n$$\n\\begin{aligned}\n\\lim _{t \\rightarrow \\infty} P_{i}\\left[V^{-}(t)>x, Y_{t}=j\\right] & =\\lim _{t \\rightarrow \\infty} \\int_{0}^{t} R_{i j}(d u) 1_{\\{t-u>x\\}}\\left(1-F_{j}(t-u)\\right) \\\\\n& =\\frac{\\mu_{j} \\int_{S}^{\\infty}\\left(1-F_{j}(y)\\right) d y}{\\sum_{k \\in S} \\mu_{k} m_{k}}\n\\end{aligned}\n$$\n\ngiven the fact that state $j$ is recurrent (follows from Assumption 1) and the function $t \\rightarrow 1_{\\{t>x\\}}\\left(1-F_{j}(t)\\right)$ is directly Riemann integrable (in short d.r.i). Definition and the necessary-sufficient conditions of 'd.r.i functions' can be found in Section 4 (Page 153 of chapter V (Renewal theory) of [5]) and Proposition 4.1 of [5] respectively. Since the distribution function $F_{j}(t)=\\sum_{k \\in S} P_{j k} F_{j k}(t)$ has at most countable number of jumps so it is continuous almost everywhere w.r.t Lebesgue measure and the function $1_{\\{t>x\\}}\\left(1-F_{j}(t)\\right)$ is bounded as well. So using Proposition 4.1(i) of [5] the function $1_{\\{t>x\\}}\\left(1-F_{j}(t)\\right)$ is d.r.i hence the above assertion (18.2) holds.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 49,
      "text": "# 18.2 Proof of Proposition 2.2 \n\nProof. Note that the distribution of $\\tau_{g_{t}^{j}+2}^{j}-\\tau_{g_{t}^{j}+1}^{j}$ is identical as $\\tau_{2}^{j}-\\tau_{1}^{j}$, since\n\n$$\n\\begin{aligned}\nP\\left[\\tau_{g_{t}^{j}+2}^{j}-\\tau_{g_{t}^{j}+1}^{j}>x\\right] & =\\sum_{n=0}^{\\infty} P\\left[\\tau_{g_{t}^{j}+2}^{j}-\\tau_{g_{t}^{j}+1}^{j}>x \\mid g_{t}^{n}=n\\right] P\\left[g_{t}^{n}=n\\right] \\\\\n& =\\sum_{n=0}^{\\infty} P\\left[\\tau_{n+2}^{j}-\\tau_{n+1}^{j}>x \\mid g_{t}^{j}=n\\right] P\\left[g_{t}^{j}=n\\right] \\\\\n& \\stackrel{(a)}{=} \\sum_{n=0}^{\\infty} P\\left[\\tau_{1}^{j}-\\tau_{0}^{j}>x\\right] P\\left[g_{t}^{j}=n\\right]=P\\left[\\tau_{1}^{j}-\\tau_{0}^{j}>x\\right]\n\\end{aligned}\n$$\n\nwhere (a) holds from the fact that the event $\\left\\{g_{t}^{j}=n\\right\\}=\\left\\{\\tau_{n}^{j} \\leq t<\\tau_{n+1}^{j}\\right\\}$ is independent with the event $\\left\\{\\tau_{n+2}^{j}-\\tau_{n+1}^{j}>x\\right\\}$ due to the regeneration property, and the latter is identical in probability with $\\left\\{\\tau_{1}^{j}-\\tau_{0}^{j}>x\\right\\}$, proving the assertion of part (i).\nSimilar to the steps done in (18.3) one can show that any functional of $Y$ in $\\left\\{s: s \\geq \\tau_{g_{t}^{j}+1}^{j}\\right\\}$ is independent of $g_{t}^{j}$ and identically distributed as that functional on $\\left\\{s: s \\geq \\tau_{0}^{j}\\right\\}$ for any $t \\geq \\tau_{0}^{j}$ for part (ii).\n\nFor part (iii), observe that $\\left\\{g_{t}^{j}=n, Y_{t}=j^{\\prime}\\right\\}=\\left\\{\\tau_{n}^{j} \\leq t<\\tau_{n+1}^{j}, Y_{t}=j^{\\prime}\\right\\}$. For any two sets $A, B$\n\n$$\n\\begin{aligned}\n& P\\left[Y_{t}^{(1)} \\in A, Y_{t}^{(2)} \\in B \\mid K_{t}, Y_{t}=j^{\\prime}\\right] \\\\\n= & \\sum_{n=0}^{\\infty} P\\left[Y_{t}^{(1)} \\in A, Y_{t}^{(2)} \\in B \\mid K_{t}, Y_{t}=j^{\\prime}, g_{t}^{j}=n\\right] P\\left[g_{t}^{j}=n \\mid K_{t}, Y_{t}=j^{\\prime}\\right] \\\\\n\\stackrel{(a)}{=} & \\sum_{n=0}^{\\infty} P\\left[Y_{t}^{(1)} \\in A \\mid K_{t}, g_{t}^{j}=n, Y_{t}=j^{\\prime}\\right] P\\left[Y_{t}^{(2)} \\in B \\mid K_{t}, g_{t}^{j}=n, Y_{t}=j^{\\prime}\\right] \\\\\n& \\times P\\left[g_{t}^{j}=n \\mid K_{t}, Y_{t}=j^{\\prime}\\right] \\\\\n\\stackrel{(b)}{=} & \\sum_{n=0}^{\\infty} P\\left[Y_{t}^{(1)} \\in A \\mid K_{t}, g_{t}^{j}=n, Y_{t}=j^{\\prime}\\right] P\\left[Y_{t}^{(2)} \\in B \\mid K_{t}\\right] P\\left[g_{t}^{j}=n \\mid K_{t}, Y_{t}=j^{\\prime}\\right] \\\\\n= & P\\left[Y_{t}^{(1)} \\in A \\mid K_{t}, Y_{t}=j^{\\prime}\\right] P\\left[Y_{t}^{(2)} \\in B \\mid K_{t}\\right]\n\\end{aligned}\n$$\n\nEquality in (a) follows from the fact that conditioned on $\\left\\{K_{t}, g_{t}^{j}=n, Y_{t}=j^{\\prime}\\right\\}$ the processes $Y_{t}^{(1)}, Y_{t}^{(2)}$ are respectively $\\sigma\\left\\{\\mathcal{H}_{i}: i \\leq n\\right\\}$ and $\\sigma\\left\\{\\mathcal{H}_{i}: i \\geq n+2\\right\\}$ measurable which are independent sigma fields. Equality in $(b)$ follows as conditioned on $\\left\\{K_{t}\\right\\}$ and $\\left\\{g_{t}^{j}=n, Y_{t}=j^{\\prime}\\right\\} Y_{t}^{(2)}$ is $\\sigma\\left\\{\\mathcal{H}_{i}: i \\geq n+2\\right\\}$ measurable and independent with $\\left\\{g_{t}^{j}=n, Y_{t}=j^{\\prime}\\right\\}=\\left\\{\\tau_{n}^{j} \\leq t<\\tau_{n+1}^{j}, Y_{t}=j^{\\prime}\\right\\}$ as the latter is $\\sigma\\left\\{\\mathcal{H}_{i}: i \\leq n+1\\right\\}$ measurable.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 50,
      "text": "# 18.3 Proof of Lemma 12.2 \n\nProof. We prove that $\\log \\left|L_{0}^{j}\\right|=O_{P}(1)$ and $\\left|Q_{0}^{j}\\right|=O_{P}(1)$. Let, for arbitrary $i, j \\in S, A_{i j}^{(k)}$ denote the event that $Y$ visits the state $j$ in $k$-th excursion from state $i$ to itself (i.e in time interval $\\left.\\left[\\tau_{k-1}^{j}, \\tau_{k}^{j}\\right)\\right)$. Clearly $0<P\\left(A_{i j}^{(k)}\\right)<1$ for any $k \\in \\mathbb{N}$ since $Y$ is irreducible in $S$. Observe that on $\\left\\{Y_{0}=i\\right\\}$ for any arbitrary $i \\in S$,\n\n$$\n\\log \\left|L_{0}^{j}\\right|=-\\int_{0}^{\\tau_{0}^{j}} a\\left(Y_{s}\\right) d s \\leq \\sum_{l=1}^{k^{*}-1} \\log L_{k}^{i}+\\int_{\\tau_{k *-1}^{j}}^{\\tau_{k *}^{j}}\\left|a\\left(Y_{s}\\right)\\right| d s, \\quad k^{*}=\\inf \\left\\{k \\geq 1: 1_{A_{i j}^{(k)}}=1\\right\\}\n$$\n\nObserve that above upper bound is a geometric sum of random variables having finite expectation which proves the first assertion that $\\log \\left|L_{0}^{j}\\right|=O_{P}(1)$. Similarly, on $\\left\\{Y_{0}=i\\right\\}$,\n\n$$\n\\begin{aligned}\nQ_{0}^{j} & =\\int_{0}^{\\tau_{0}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{\\tau_{0}^{\\tau_{0}^{j}}^{j}} a\\left(Y_{r}\\right) d r} d s \\\\\n& =e^{\\left(\\tau_{0}^{j}-\\tau_{k^{*}}^{j}\\right)} \\sum_{l=1}^{k^{*}-1}\\left(\\prod_{n=l+1}^{k^{*}} L_{n}^{i}\\right) Q_{l}^{i}+\\int_{\\tau_{k *-1}^{j}}^{\\tau_{0}^{j}} b\\left(Y_{s}\\right) e^{-\\int_{\\tau_{k *-1}^{j}}^{\\tau_{0}^{j}} a\\left(Y_{r}\\right) d r} d s\n\\end{aligned}\n$$\n\nNote that $\\left[\\tau_{k *-1}^{j}, \\tau_{0}^{j}\\right) \\subset\\left[\\tau_{k *-1}^{i}, \\tau_{k *}^{i}\\right)$ and that\n\n$$\n\\sum_{l=1}^{\\infty}\\left(\\prod_{n=l+1}^{\\infty} L_{n}^{i}\\right) Q_{l}^{i}\n$$\n\nis absolutely convergent due to Assumption 2. Hence, $\\left|Q_{0}^{j}\\right|=O_{P}(1)$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 51,
      "text": "### 18.4 Statement of Lemma 12.3\n\n(a) Suppose Assumption 1 holds and $c$. is a function defined on $\\mathbb{N}$ as (2.15) and its definition is extended to the whole $\\mathbb{R}_{\\geq 0}$ for any arbitrary slowly varying function $L(\\cdot)$. Let $g_{t}^{j}$ be defined as the number of total renewals to the state $j$, before time $t$. Then for any fixed $s>0$,\n\n$$\n\\lim _{t \\rightarrow \\infty} c_{g_{t j}^{j}}^{-1} / c_{t}^{-1} \\stackrel{a, s}{\\rightarrow}\\left(\\frac{s}{E\\left|\\mathcal\u042d}_{1}^{j}\\right|}\\right)^{-\\frac{1}{n}}\n$$\n\n(b) For any function $L(\\cdot)$ slowly varying at $+\\infty$, and any two functions $a_{1}(\\cdot), b_{1}(\\cdot): \\mathbb{R}_{\\geq 0} \\rightarrow \\mathbb{R}_{\\geq 0}$ such that both $a_{1}(t), b_{1}(t) \\rightarrow \\infty$ as $t \\rightarrow \\infty$ and $a_{1} \\leq b_{1}$; for any $\\epsilon>0$ there exists $t_{0, \\epsilon} \\geq 0$, such that for all $t \\geq t_{0, \\epsilon}$,\n\n$$\n(1-\\epsilon)\\left(\\frac{b_{1}(t)}{a_{1}(t)}\\right)^{-\\epsilon} \\leq \\frac{L\\left(b_{1}(t)\\right)}{L\\left(a_{1}(t)\\right)} \\leq(1+\\epsilon)\\left(\\frac{b_{1}(t)}{a_{1}(t)}\\right)^{\\epsilon}\n$$\n\n(c) For any function $L(\\cdot)$ slowly varying at $t \\rightarrow \\infty, \\lim _{t \\rightarrow \\infty} \\frac{\\log L(t)}{\\log t} \\rightarrow 0$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 52,
      "text": "# 18.4.1 Proof of Lemma 12.3(a) \n\nProof. Observe that,\n\n$$\nc_{g_{s t}^{j}}^{-1} / c_{t}^{-1}=\\frac{\\left(g_{s t}^{j}\\right)^{-\\frac{1}{n}} L_{0}^{-1}\\left(g_{s t}\\right)}{t^{-\\frac{1}{n}} L_{0}^{-1}(t)}\n$$\n\nwhere $L_{0}(\\cdot)$ depends on $L(\\cdot)$ through (2.15) as it is defined as $c_{n} \\sim n^{-1 / n} L_{0}(n)$.\nThe result follows from the fact $\\lim _{t \\rightarrow \\infty} \\frac{g_{s t}}{\\frac{c_{n}}{E\\left[\\beta_{1}^{t}\\right]}} \\frac{a_{s t}^{s}}{t} 1$, and $\\lim _{t \\rightarrow \\infty} \\frac{L_{0}(t)}{L_{0}\\left(g_{s t}^{j}\\right)} \\frac{a_{s t}^{s}}{t} 1$ as an application of Potter's bound. To see the second result observe that given a small $\\epsilon_{1} \\in\\left(0, \\frac{s}{E\\left[\\beta_{1}^{t}\\right]}\\right)$, for each $\\omega \\in A$ with $P[A]=1$ there exists $t_{1}\\left(\\omega, \\epsilon_{1}\\right)$ such that $\\frac{g_{s t}}{\\frac{c_{n}}{E\\left[\\beta_{1}^{t}\\right]}} \\geq 1-\\frac{\\epsilon_{1}}{\\frac{s}{E\\left[\\beta_{1}^{t}\\right]}}$, for all $t \\geq t_{1}\\left(\\omega, \\epsilon_{1}\\right)$. Since\n\n$$\n\\frac{L_{0}(t)}{L_{0}\\left(g_{s t}\\right)}=\\frac{L_{0}(t)}{L_{0}\\left(t\\left(\\frac{s}{E\\left[\\beta_{1}^{t}\\right]}-\\epsilon_{1}\\right)\\right)} \\frac{L_{0}\\left(t\\left(\\frac{s}{E\\left[\\beta_{1}^{t}\\right]}-\\epsilon_{1}\\right)\\right)}{L_{0}\\left(g_{s t}\\right)}\n$$\n\nthe first term goes to 1 as $t \\rightarrow \\infty$ by definition. The second term can be bounded by using Potter's bound for any slowly varying function $L_{0}(\\cdot)$ which suggests that for all $\\epsilon>0$, there exists $t_{0}>0$, such that\n\n$$\n(1-\\epsilon)\\left(\\frac{\\frac{g_{s t}^{j}}{t}}{\\frac{s}{E\\left[\\beta_{1}^{t}\\right]}-\\epsilon_{1}}\\right)^{-\\epsilon} \\leq \\frac{L_{0}\\left(g_{s t}^{j}\\right)}{L_{0}\\left(t\\left(\\frac{s}{E\\left[\\beta_{1}^{t}\\right]}-\\epsilon_{1}\\right)\\right)} \\leq(1+\\epsilon)\\left(\\frac{\\frac{g_{s t}^{j}}{E\\left[\\beta_{1}^{t}\\right]}}{1-\\frac{\\epsilon_{1}}{\\frac{s}{E\\left[\\beta_{1}^{t}\\right]}}}\\right)^{\\epsilon}\n$$\n\nfor all $t \\geq t_{0} \\vee t_{1}\\left(\\omega, \\epsilon_{1}\\right)$. As both $\\epsilon_{1}, \\epsilon$ can be chosen arbitrarily small, both sides have an almost sure limit to 1 , for large $t$ proving the part (b) of the Lemma.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 53,
      "text": "### 18.4.2 Proof of Lemma 12.3(b)\n\nProof. Using Karamata's representation theorem for a slowly varying function $L(\\cdot)$ at $\\infty$, there exist $x_{0} \\geq 0$, functions $c_{1}(\\cdot), \\eta(\\cdot)$ such that there exists a constant $c_{0}$, for which $\\lim _{x \\rightarrow \\infty} c_{1}(x)=c_{0}, \\lim _{x \\rightarrow \\infty} \\eta(x)=0$, and $L(\\cdot)$ can be represented as $L(x)=c_{1}(x) e^{\\int_{x_{0}}^{x} \\frac{\\eta(x)}{c} d s}$.\nUsing this representation for any $t \\geq 0$,\n\n$$\n\\frac{L\\left(b_{1}(t)\\right)}{L\\left(a_{1}(t)\\right)}=\\frac{c_{1}\\left(b_{1}(t)\\right)}{c_{1}\\left(a_{1}(t)\\right)} \\frac{e^{\\int_{x_{0}}^{b_{1}(t)} \\frac{\\eta(x)}{c} d s}}{e^{\\int_{x_{0}}^{b_{1}(t)} \\frac{\\eta(x)}{c} d s}}=\\frac{c_{1}\\left(b_{1}(t)\\right)}{c_{1}\\left(a_{1}(t)\\right)} e^{\\int_{x_{1}}^{b_{1}(t)} \\frac{\\eta\\left(a_{1}(t) x\\right)}{c} d s} d s\n$$\n\nSince both $\\left(a_{1}(t), b_{1}(t)\\right) \\rightarrow(\\infty, \\infty)$ as $t \\rightarrow \\infty$, for any $\\epsilon>0$, there exists $t_{0, \\epsilon} \\geq 0$ such that\n\n$$\n\\left|\\frac{c_{1}\\left(b_{1}(t)\\right)}{c_{1}\\left(a_{1}(t)\\right)}-1\\right|<\\epsilon \\quad \\& \\quad\\left|\\eta\\left(a_{1}(t) s\\right)\\right| \\leq \\epsilon \\quad \\forall t \\geq t_{0, \\epsilon}\n$$\n\nIf $\\left|\\eta\\left(a_{1}(t) s\\right)\\right| \\leq \\epsilon$, it implies that\n\n$$\n-\\epsilon \\log \\left(\\frac{b_{1}(t)}{a_{1}(t)}\\right) \\leq \\int_{1}^{\\frac{b_{1}(t)}{a_{1}(t)}} \\frac{\\eta\\left(a_{1}(t) s\\right)}{s} d s \\leq \\epsilon \\log \\left(\\frac{b_{1}(t)}{a_{1}(t)}\\right)\n$$\n\nwhich together with $\\left|\\frac{c_{1}\\left(b_{1}(t)\\right)}{c_{1}\\left(a_{1}(t)\\right)}-1\\right|<\\epsilon$, prove the assertion in (18.4).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 54,
      "text": "# 18.4.3 Proof of Lemma 12.3(c) \n\nProof. For any $L(t)$ slowly varying at $t \\rightarrow \\infty$, we show that $\\lim _{t \\rightarrow \\infty} \\frac{\\log L(t)}{\\log t} \\rightarrow 0$. Suppose given any small $\\delta>0$, there exists $t_{\\delta}$ such that for all $t \\geq t_{\\delta},|\\eta(t)| \\leq \\delta$ and $\\left|c_{1}(t)-c_{0}\\right| \\leq \\delta$.\n\nUsing Karamata's presentation\n\n$$\n\\frac{\\log L(t)}{\\log t}=\\frac{\\log c_{1}(t)}{\\log (t)}+\\frac{1}{\\log (t)}\\left[\\int_{x_{0}}^{t_{\\delta}} \\frac{\\eta(s)}{s} d s+\\int_{t_{\\delta}}^{t} \\frac{\\eta(s)}{s} d s\\right]\n$$\n\nIt follows that for large $t$, the first and second term in the RHS go to 0 , and the third term\n\n$$\n\\frac{1}{\\log (t)} \\int_{t_{\\delta}}^{t} \\frac{\\eta(s)}{s} d s \\leq \\delta \\frac{\\log (t)-\\log \\left(t_{\\delta}\\right)}{\\log (t)} \\leq \\delta\n$$\n\nfor any arbitrary $\\delta>0$. Hence the assertion follows as $t \\rightarrow \\infty$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 55,
      "text": "### 18.5 Proof of Lemma 16.1\n\nProof. To prove first assertion observe that for any $\\delta>0$,\n\n$$\n\\left\\{\\widetilde{X}_{1}>(1+\\delta) x, \\widetilde{X}_{2}<\\delta x\\right\\} \\subset\\left\\{\\widetilde{X}_{1}-\\widetilde{X}_{2}>x\\right\\} \\subset\\left\\{\\widetilde{X}_{1}>x\\right\\}\n$$\n\nThese inequalities together imply that\n\n$$\n\\begin{aligned}\n1 & \\geq \\frac{P\\left[\\widetilde{X}_{1}-\\widetilde{X}_{2}>x\\right]}{P\\left[\\widetilde{X}_{1}>x\\right]} \\\\\n& \\geq \\frac{P\\left[\\widetilde{X}_{1}>(1+\\delta) x, \\widetilde{X}_{2}<\\delta x\\right]}{P\\left[\\widetilde{X}_{1}>x\\right]} \\\\\n& =\\frac{P\\left[\\widetilde{X}_{1}>(1+\\delta) x\\right]}{P\\left[\\widetilde{X}_{1}>x\\right]}[1-P\\left[\\widetilde{X}_{2} \\geq \\delta x\\right]]=(1+\\delta)^{-\\alpha}\\left[1-\\delta^{-\\alpha} O\\left(x^{-\\alpha}\\right)\\right]+o(1)\n\\end{aligned}\n$$\n\nwhere equality in (18.5) follows from the independence of $\\left\\{\\widetilde{X}_{i}: i=1, \\ldots, n\\right\\}$. Taking limit as $x \\rightarrow \\infty$ and having $\\delta>0$ arbitrarily small proves the first assertion\n\n$$\nP\\left[\\widetilde{X}_{1}-\\widetilde{X}_{2}>x\\right] \\sim P\\left[\\widetilde{X}_{1}>x\\right]\n$$\n\nThe assertion $P\\left[\\widetilde{X}_{1}-\\widetilde{X}_{2}<-x\\right] \\sim P\\left[\\widetilde{X}_{2}>x\\right]$ follows similarly by changing signs. Second and third assertion follow as a corollary of Lemma 1.3.4 and Remark 1.3.5 of [49] respectively.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 56,
      "text": "### 18.6 Proof of Lemma 12.4\n\nProof. Define two functions $G_{1}, G_{2}: \\mathbb{R}_{\\geq 0}^{2} \\rightarrow \\mathbb{R}$, such that\n\n$$\nG_{1}(x, y)=\\max \\{\\log x, \\log y\\}, G_{2}(x, y)=\\log \\max \\{x, y\\}\n$$\n\nIt is easy to see that\n\n$$\n\\begin{aligned}\n& P\\left[G_{1}(X, Y)=G_{2}(X, Y)\\right]=P\\left[G_{1}(X, Y)=G_{2}(X, Y), X>Y\\right] \\\\\n& \\quad+P\\left[G_{1}(X, Y)=G_{2}(X, Y), X=Y\\right]+P\\left[G_{1}(X, Y)=G_{2}(X, Y), X<Y\\right]\n\\end{aligned}\n$$\n\nand each of these probabilities in the RHS are\n\n$$\n\\begin{aligned}\n& P\\left[G_{1}(X, Y)=G_{2}(X, Y), X>Y\\right]=P[X>Y] \\\\\n& P\\left[G_{1}(X, Y)=G_{2}(X, Y), X<Y\\right]=P[X<Y] \\\\\n& P\\left[G_{1}(X, Y)=G_{2}(X, Y), X=Y\\right]=P[X=Y]\n\\end{aligned}\n$$\n\nand after summing one can see that $P\\left[G_{1}(X, Y)=G_{2}(X, Y)\\right]=1$.",
      "tables": {},
      "images": {}
    }
  ],
  "id": "2410.15824v2",
  "authors": [
    "Abhishek Pal Majumder"
  ],
  "categories": [
    "math.PR",
    "math.DS",
    "q-fin.MF",
    "stat.CO"
  ],
  "abstract": "Examples of stochastic processes whose state space representations involve\nfunctions of an integral type structure\n$$I_{t}^{(a,b)}:=\\int_{0}^{t}b(Y_{s})e^{-\\int_{s}^{t}a(Y_{r})dr}ds, \\quad t\\ge\n0$$ are studied under an ergodic semi-Markovian environment described by an $S$\nvalued jump type process $Y:=(Y_{s}:s\\in\\mathbb{R}^{+})$ that is ergodic with a\nlimiting distribution $\\pi\\in\\mathcal{P}(S)$. Under different assumptions on\nsigns of $E_{\\pi}a(\\cdot):=\\sum_{j\\in S}\\pi_{j}a(j)$ and tail properties of the\nsojourn times of $Y$ we obtain different long time limit results for\n$I^{(a,b)}_{}:=(I^{(a,b)}_{t}:t\\ge 0).$ In all cases mixture type of laws\nemerge which are naturally represented through an affine stochastic recurrence\nequation (SRE) $X\\stackrel{d}{=}AX+B,\\,\\, X\\perp\\!\\!\\!\\perp (A, B)$. Examples\ninclude explicit long-time representations of pitchfork bifurcation, and\nregime-switching diffusions under semi-Markov modulated environments, etc.",
  "updated": "2025-02-22T15:32:08Z",
  "published": "2024-10-21T09:41:59Z"
}