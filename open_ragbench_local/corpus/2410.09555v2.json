{
  "title": "Parallel Execution Fee Mechanisms",
  "sections": [
    {
      "section_id": 0,
      "text": "#### Abstract\n\nThis paper investigates how pricing schemes can achieve efficient allocations in blockchain systems featuring multiple transaction queues under a global capacity constraint. I model a capacity-constrained blockchain where users submit transactions to different queues - each representing a submarket with unique demand characteristics-and decide to participate based on posted prices and expected delays. I find that revenue maximization tends to allocate capacity to the highestpaying queue, whereas welfare maximization generally serves all queues. Optimal relative pricing of different queues depends on factors such as market size, demand elasticity, and the balance between local and global congestion. My results have implications for the implementation of local congestion pricing for evolving blockchain architectures, including parallel transaction execution, directed acyclic graph (DAG)-based systems, and multiple concurrent proposers.\n\n\nKeywords: Blockchain, Fintech, Transactions, Parallel Execution, Fee Markets, Consensus",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 1,
      "text": "# 1 Introduction \n\nBlockchain technology is rapidly reshaping the global financial landscape. In the United States, a notable milestone occurred in January 2024 when the Securities and Exchange Commission approved the trading of Bitcoin ETFs on public exchanges [17]. Cryptocurrencies such as Bitcoin and Ethereum have gained widespread adoption, enabling peer-to-peer transactions without the need for traditional intermediaries like banks. On platforms like Ethereum, smart contracts-self-executing agreements with conditions encoded in software-facilitate various financial services, from loans and insurance to decentralized exchanges.\nBlockchain technology operates by executing transactions in a decentralized manner, ensuring that transactions are ultimately executed (liveness) and that a decentralized network of computers-referred to as miners in proof-of-work systems or validators in proof-of-stake systems-can agree on the state of the blockchain after execution (safety). Despite the growing importance of blockchain technology, there are still significant limitations in their scalability, particularly in the efficient execution of transactions in the presence of congestion. As blockchain applications expand beyond cryptocurrencies into decentralized finance (DeFi), supply chain management, and digital identity, the efficient allocation of blockchain resources has become increasingly critical.\nTraditional blockchain protocols often rely on simple fee-based models where users attach fees to their transactions, and miners or validators prioritize transactions based on these fees. While straightforward, such Transaction Fee Mechanisms (TFMs) can lead to inefficiencies, including congestion of parts of the blockchain state, high transaction fees during peak demand, and suboptimal resource allocation. ${ }^{1}$ Moreover, as blockchains evolve to allow for parallel transaction settlement and support complex decentralized applications, the need for more sophisticated mechanisms that can handle heterogeneous transaction types becomes apparent.\nWhile TFMs that guarantee the inclusion of a transaction in the next block are well-studied [5], [15], [18], [14], [13], [9], little is known about the design of Execution Fee Mechanisms (EFMs). EFMs refer to the protocols and systems that determine the order and manner in which transactions are processed and finalized on a blockchain network. In any decentralized system like blockchain, transactions are submitted by multiple users, often simultaneously. The mechanism by which these transactions are sequenced and confirmed is crucial for maintaining the network's integrity, security, and performance.\nParallel EFMs are at the heart of several emerging blockchain systems, including parallel execution blockchains, Directed Acyclic Graph (DAG)based blockchains, and blockchains with multiple concurrent proposers. For instance, parallel execution blockchains ${ }^{2}$ divide the state represented by the blockchain into multiple, non-overlapping partitions or local fee\n\n[^0]\n[^0]:    ${ }^{1}$ For three hours on April 30, 2022, it cost at least $\\$ 6500$ to send any transaction on the Ethereum blockchain because of a single anticipated NFT collection release; see https://www.coindesk.com/business/2022/05/01/bayc-team-raises-285m-with-otherside-nfts-clogs-ethereum/.\n    ${ }^{2}$ Such as Solana, Avalanche, or the planned upgrade to the Ethereum blockchain.\n\nmarkets, each of which can handle transactions independently. ${ }^{3}$ Optimal pricing of these local markets can allow for a EFM where fees are determined by the demand within each partition rather than the entire network. In DAG-based blockchains ${ }^{4}$, transactions are included in a graph of blocks without requiring them to be ordered in a single chain. However, their EFM is crucial for organizing the unordered transactions into a logical sequence for execution and achieving consensus on the final state across the entire network. ${ }^{5}$ Lastly, in blockchains with multiple concurrent proposers ${ }^{6}$ a key challenge is to ensure that concurrent proposals do not lead to conflicts or forks that compromise the network's safety. A EFM is, therefore, needed to aggregate proposals from multiple validators or proposers.\nIn this paper, I embed a general queuing model into the standard price theory framework and study optimal posted-price EFMs for blockchains that can execute independent transactions in parallel. I model a capacityconstrained blockchain execution system as an $N$-queue system that serves delay-sensitive customers. Each queue represents a submarket or a specific resource requested by transactions. ${ }^{7}$ Users submit transactions to these queues and decide upon arrival whether to proceed based on the posted price and expected delays that decrease their utility. A global capacity constraint arises from the need for consensus mechanisms to consider all transactions across queues. A larger volume of transactions leads to propagation delay on consensus security; [3].\nIn the context of this model, I ask the following research questions: how does revenue maximization affect the allocation of capacity across queues, and under what conditions does it lead to the exclusion of lowerpaying queues? What are the welfare implications of different pricing strategies, and how can we design prices that maximize social welfare while accounting for the global capacity constraint? How do market characteristics such as demand elasticity and market size affect the optimal relative pricing across queues?\nTo address these questions, I first examine the case where the protocol or miners/validators aim to maximize revenue. Formally, such a protocol maximizes the sum of fees collected from all served queues, subject to the local equilibrium conditions in each queue and the global capacity constraint. The local equilibrium condition ensures that, in each queue, the marginal user's expected utility is her outside option-users join a queue if their valuation exceeds the price plus expected delay costs. I find that there exists a threshold capacity level below which allocating all capacity\n\n[^0]\n[^0]:    ${ }^{3}$ Note that one may argue that parallel execution is already the case in Ethereum, given the proliferation of Ethereum Layer 2s, or the co-existence of regular transactions and blobs.\n    ${ }^{4}$ Such as Aptos, Sui, and IOTA.\n    ${ }^{5}$ See [8] for this process of \"flattening the DAG needed for global consensus on transactions.\n    ${ }^{6}$ Such as in current proposals for the Ethereum blockchain, see https://ethresear.ch/t/concurrent-block-proposers-in-ethereum/18777.\n    ${ }^{7}$ Such as a smart contract, a high-level resource that transactions try to access, or a shared object in object-centric blockchains.\n\nto the highest-paying queue maximizes revenue. This result highlights a potential inefficiency in revenue maximization: the system may exclude transactions from other queues that could contribute positively to social welfare.\nNext, I consider the objective of maximizing social welfare. The analysis shows that, in contrast to revenue maximization, the welfare-maximizing allocation generally involves serving all queues. By distributing capacity across all queues, the system ensures that users in different submarkets can access the resources they require. Then I derive the socially optimal relative prices for each queue that implement the welfare-maximizing allocation. These prices are designed as Pigouvian taxes that internalize both the local and global congestion externalities imposed by each executed transaction.\nTo provide further insights, I specialize the model to a setting where the time between arrivals is exponentially distributed, and execution times are also exponentially distributed. Each market has an isoelastic demand function characterized by a specific elasticity parameter. I derive explicit formulas for the socially optimal prices as a function of market characteristics such as demand elasticity, market size, and congestion levels.\nWhen the degree of parallelization is high (i.e., the system can process many transactions concurrently), and local congestion dominates global congestion, the ratio of socially optimal prices between any two queues approximates the ratio of their demand intensities normalized by market sizes. In particular, when demand is highly elastic and local congestion effects are strong, the optimal relative price in a queue is approximately proportional to the ratio of demand relative to market size. This implies that setting prices based on the relative demand intensity in each queue approximates the welfare-maximizing solution.\nThese findings have important implications for the design of Parallel Execution Fee Mechanisms in evolving blockchain architectures. On the one hand, a revenue-maximizing validator favors uniform pricing and serving only the highest-paying user category. On the other hand, by implementing local fee markets - where transactions are assigned to queues with different relative prices based on the resources they access - protocol designers can steer the blockchain closer to efficiency and scalability in transaction execution. In practice, this means that blockchains can define local prices for each state, contract, or program object and employ adaptive base fee mechanisms that adjust prices based on local demand conditions. ${ }^{8}$ By doing so, the blockchain can prevent high-demand areas from congesting the entire network and ensure that capacity is allocated efficiently across all resources.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 2,
      "text": "# 1.1 Related Work \n\nThis paper contributes to the broader economics literature on the market design of blockchain technology [4], [10], [7]. [5], and [14], [13] study the question of pricing blockspace-that is, determining optimal\n\n[^0]\n[^0]:    ${ }^{8}$ Such as Ethereum's EIP-1559 fee mechanism studied in [16] and [13].\n\nfee mechanisms for including transactions in blockchain blocks under capacity constraints. [18], [16], [15], [6], and [2] provide foundational analysis of transaction fee mechanisms, focusing on blockchains with linear transaction ordering. This work opens the analysis of transaction execution by modeling complexities introduced by parallel execution in multi-queue blockchain systems. In doing so, I build on the literature on the pricing of queues [12], [11], [1] and emphasize the balance between global and local congestion. Beyond the theoretical contributions, my results have practical implications for blockchain system design and can help improve the efficiency and scalability of both new and existing blockchain technologies. My framework is applicable to other settings where multi-queue systems are present, and there is potential for congestion, such as supply chain management, cloud computing, and online service platforms.\nThe remainder of the paper is organized as follows. Section 2 highlights the limits of traditional blockchain fee models with a two-queue example. Section 3 presents the model setup, including users, local equilibrium conditions, and global inclusion constraints. In Section 4.1, I analyze the revenue maximization problem and derive the conditions under which capacity allocation favors the highest-paying queue. Sections 4.2 and 4.3 focus on welfare maximization, characterizing the socially optimal pricing strategies and their implications. Finally, Section 5 concludes the paper and suggests avenues for future research.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 3,
      "text": "# 2 The Problem of Execution in Standard TFMs: An Example \n\nIn this section, I illustrate the challenges associated with executing transactions in standard Transaction Fee Mechanisms (TFMs) through a simple example. Consider a blockchain system with two separate queues, Queue A and Queue B, each holding three transactions awaiting inclusion and execution in the blockchain. The expected values of the transactions in Queues A and B are $\\mathbb{E}\\left[v_{a}\\right]=10$ and $\\mathbb{E}\\left[v_{b}\\right]=6$, respectively.\nFigure 1 depicts the state of the two queues. In each period, two new transactions arrive in each queue. However, due to the necessity for global consensus, the blockchain can collect and process up to five transactions at a time.\nIn Queue A, there are three transactions denoted as $a_{1}, a_{2}$, and $a_{3}$, with individual values of 15,10 , and 5 , respectively. Similarly, Queue B contains transactions $b_{1}, b_{2}$, and $b_{3}$, with values of 8,6 , and 4 . The higher expected value in Queue A indicates that, on average, transactions in this queue are more valuable to the network or its users compared to those in Queue B.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 4,
      "text": "### 2.1 The Problem with Global Ordering and a Uniform Price\n\nUnder a standard TFM, the selection of transactions for inclusion is typically based on the fees attached to them. With a uniform price for\n\nQueue A: $\\mathbb{E}\\left[v_{a}\\right]=10$\n![img-0.jpeg](img-0.jpeg)\n\nQueue B: $\\mathbb{E}\\left[v_{b}\\right]=6$\n\n![table_0](table_0)\n\nFig. 1: Example Transaction Queues\ninclusion and a global ordering for all transactions, the global capacity constraint can lead to an imbalance in how transactions from different queues are executed. Specifically, more transactions from Queue A are processed than those from Queue B, even though transactions from both queues could be executed in parallel without interference. This results in Queue B becoming underserved, causing its backlog to grow over time. Figure 2 illustrates this scenario.\nThe top portion of the figure represents the global execution order, where transactions from both Queue A and Queue B are interleaved based on their arrival times and values. Transactions $a_{1}, a_{2}$, and $b_{1}$ are included in the execution queue. Additionally, new higher-value transactions $a_{4}^{*}$ and $a_{5}^{*}$ (highlighted in red and starred) arrive in Queue A with values of 12 and 7 , respectively. Due to their higher values, these transactions are immediately prioritized in the global ordering.\nThe middle section shows Queue A's state. Transaction $a_{3}$ remains in the queue with a value of 5 . While some transactions from Queue A are being executed, new higher-value transactions continue to arrive, maintaining its dominance in the execution queue.\nThe bottom section illustrates Queue B's state. Transactions $b_{2}$ to $b_{5}$ accumulate in the queue with values ranging from 4 to 7 . Despite the continuous arrival of transactions, Queue B's transactions are not prioritized in the global execution order due to their lower values compared to those in Queue A.\nBecause of the global capacity constraint-only five transactions can be executed at a time-the mechanism tends to favor transactions with higher values to maximize immediate throughput or revenue. Transactions from Queue B could be processed in parallel with those from Queue A without any conflicts or interference. However, the global ordering does not account for this possibility, resulting in suboptimal use of the system's parallel processing capabilities.\n\nGlobal Ordering for Execution:\n\n![table_1](table_1)\n\nQueue A: | $a_{3}$ |\n| :-- |\n| $b_{5}$ | $\\cdots$ |\n\n\n![table_2](table_2)\n\nQueue B: | $b_{5}$ | $b_{2}$ | $b_{4}$ | $b_{3}$ |\n| :-- | :-- | :-- | :-- | :-- |\n| 7 | 6 | 5 | 4 | $\\cdots$ |\n\nFig. 2: Global Ordering under Uniform Price. Newly arrived and executed transactions are highlighted in red and starred.",
      "tables": {
        "table_0": "| $b_{1}$ | $b_{2}$ | $b_{3}$ |\n| :--: | :--: | :--: |\n| 8 | 6 | 4 |",
        "table_1": "| $a_{1}$ | $a_{4}^{*}$ | $a_{2}$ | $b_{1}$ | $a_{5}^{*}$ |\n| :--: | :--: | :--: | :--: | :--: |\n| 15 | 12 | 10 | 8 | 7 |",
        "table_2": "| $b_{5}$ | $b_{2}$ | $b_{4}$ | $b_{3}$ |\n| :--: | :--: | :--: | :--: |\n| 7 | 6 | 5 | 4 |"
      },
      "images": {
        "img-0.jpeg": "data:image/jpeg;base64,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"
      }
    },
    {
      "section_id": 5,
      "text": "# 2.2 A Potential Solution: Market Value-Weighted Ordering \n\nTo address the issues above, we study a potential solution we will call Market Value-Weighted Ordering. Suppose that the expected values of transactions in Queues A and B, denoted by $\\mathbb{E}\\left[v_{a}\\right]$ and $\\mathbb{E}\\left[v_{b}\\right]$ respectively, are known or can be reliably estimated. This information could be derived from historical data, statistical analysis, or real-time monitoring of transaction patterns.\nThe key idea is to adjust or normalize the bids of transactions in each queue according to the expected value of that queue. Specifically, we treat each transaction as if its bid is scaled by the inverse of the expected value of its queue. For transactions in Queue A and Queue B, we adjust their bids as follows:\n\n$$\na_{i}^{\\prime}=\\frac{a_{i}}{\\mathbb{E}\\left[v_{a}\\right]}, \\quad b_{i}^{\\prime}=\\frac{b_{i}}{\\mathbb{E}\\left[v_{b}\\right]}\n$$\n\nBy scaling the bids in this manner, we standardize the bids across queues, allowing for a comparison of transactions based on their relative value within their respective queues. Figure 3 illustrates these adjusted bids. Under this Market Value-Weighted Ordering, the system evaluates transactions based on their adjusted bids, resulting in a more balanced execution of transactions from both queues. Figure 4 illustrates how transactions are selected for execution under this mechanism.\nTransactions $a_{1}^{\\prime}, b_{1}^{*}, a_{4}^{\\prime}, b_{5}^{*}$, and $a_{2}^{\\prime}$ are selected for execution. Transactions from Queue B' that are executed are highlighted in blue. The\n\n$$\n\\text { Queue } \\mathrm{A}^{\\prime}: \\mathbb{E}\\left[v_{a^{\\prime}}\\right]=1\n$$\n\n![table_3](table_3)\n\nQueue B': $\\mathbb{E}\\left[v_{b^{\\prime}}\\right]=1$\n\n![table_4](table_4)\n\nFig. 3: Market Value-Weighted Ordering. Each transaction is treated as if its bid is $a_{i} / \\mathbb{E}\\left[v_{a}\\right]$ or $b_{i} / \\mathbb{E}\\left[v_{b}\\right]$\nlower-value transactions remain in their respective queues, awaiting future execution based on their adjusted bids and arrival times.\nThis example demonstrates the potential social value of relative pricing and suggests that value-weighted relative pricing of different queues can be approximately welfare-maximizing. In the remainder of this article, I will generalize this idea in a model of a blockchain with parallel execution and a global capacity constraint due to consensus.",
      "tables": {
        "table_3": "| $a_{1}^{\\prime}$ | $a_{2}^{\\prime}$ | $a_{3}^{\\prime}$ |\n| :--: | :--: | :--: |\n| 1.5 | 1 | 0.5 |",
        "table_4": "| $b_{1}^{\\prime}$ | $b_{2}^{\\prime}$ | $b_{3}^{\\prime}$ |\n| :--: | :--: | :--: |\n| $\\frac{4}{3}$ | 1 | $\\frac{2}{3}$ |"
      },
      "images": {}
    },
    {
      "section_id": 6,
      "text": "# 3 Model \n\nIn this section, I present a formal model of a capacity-constrained blockchain execution system. The system is modeled as an $N$-queue system that serves delay-sensitive customers. These queues can be associated with each smart contract, each high-level resource that transactions try to access, or each shared object in the case of object-centric blockchains.\n\nSetup. I assume that execution times are independently and identically distributed (i.i.d.) with unit mean. ${ }^{9}$ Each user submits a transaction that arrives in one of the queues $i \\in\\{1, \\ldots, N\\}$, following an exogenous Poisson process with rate (or market size) $\\Lambda_{i}$. Since the consensus mechanism takes into account transactions in all queues, there is a global capacity constraint for inclusion, meaning that the total number of transactions that can be included across all queues is limited. For simplicity, we consider mechanisms with posted prices $p_{i}$ for each submarket or queue $i$.\n\n[^0]\n[^0]:    ${ }^{9}$ For transactions with different execution times, we can interpret the derived prices below as gross prices rather than per-unit prices. This simplification allows us to focus on the core dynamics without loss of generality.\n\nMarket Value-Weighted Ordering for Execution:\n\n![table_5](table_5)\n\nQueue A': | $a_{5}^{\\prime}$ | $a_{3}^{\\prime}$ |\n| :--: | :--: |\n|  |  |\n| 0.7 | 0.5 | $\\cdots$ |\n\nQueue B': | $b_{2}^{\\prime}$ | $b_{4}^{\\prime}$ | $b_{3}^{\\prime}$ |\n| :--: | :--: | :--: | :--: |\n|  | 1 | $\\frac{5}{6}$ | $\\frac{2}{3}$ | $\\cdots$ |\n\nFig. 4: Execution under Market Value-Weighted Ordering. Executed transactions from queue B' are highlighted in blue and starred.\n\nUpon arrival and observing the posted prices, users decide whether or not to submit their transaction at the posted price $p_{i}$, taking into account potential delays and their own valuations.\n\nUser Valuations. Users are considered to be atomistic relative to the market size, meaning that each individual user's actions have a negligible impact on the overall system. They differ in their valuations $v$, representing their willingness to pay for immediate execution without delay. For each submarket $i$, valuations are independently and identically distributed (i.i.d.) draws from a continuous distribution $\\Phi_{i}$ (independent of arrival and execution times) with probability density function $\\phi_{i}$. I assume that $\\phi_{i}$ is strictly positive and continuous on the positive interval $[\\underline{v}, \\bar{v}]$. Let $\\bar{\\Phi}_{i}(v)=1-\\Phi_{i}(v)$ denote the complementary cumulative distribution function, representing the probability that a user's valuation exceeds $v$. If all transactions with values greater than $v$ join queue $i$, the arrival (or demand) rate in market $i$ will be $\\lambda_{i}=\\Lambda_{i} \\bar{\\Phi}_{i}(v)$. Conversely, when the arrival rate is $\\lambda_{i}$, the marginal value $v$ is equal to $\\bar{\\Phi}_{i}^{-1}\\left(\\lambda_{i} / \\Lambda_{i}\\right)$, where $\\bar{\\Phi}_{i}^{-1}$ is the inverse of $\\bar{\\Phi}_{i}$.\nFollowing [1], let $V_{i}\\left(\\lambda_{i}\\right)$ denote the expected aggregate (gross) value in submarket $i$ per unit of time without delay. Then, the downwardsloping marginal value (or inverse gross demand) function $V_{i}^{\\prime}\\left(\\lambda_{i}\\right) \\equiv$ $\\bar{\\Phi}_{i}^{-1}\\left(\\lambda_{i} / \\Lambda_{i}\\right)$ defines a one-to-one mapping between the demand rate $\\lambda_{i}$ and the marginal value $V_{i}^{\\prime}\\left(\\lambda_{i}\\right)$. Each $V_{i}$ is increasing and is assumed to be strictly concave, $V_{i}^{\\prime}\\left(\\lambda_{i}\\right)>0, V_{i}^{\\prime \\prime}\\left(\\lambda_{i}\\right)<0$ for $\\lambda_{i}<\\Lambda_{i}$.\n\nDelay Costs. Users are sensitive to delays in transaction execution. I consider the following utility function for a user with valuation $v$ who pays a price $p$ and experiences a delay of $t$ units of time:\n\n$$\nu(v, t, p, i)=v \\cdot D_{i}(t)-C_{i}(t)-p\n$$\n\nIn this expression, $p$ is the price paid by the user to submit the transaction. The term $D_{i}(t)$ is a multiplicative delay discount function for queue $i$, capturing how the user's valuation decreases with delay. For example, $D_{i}(t)$ could be a discount factor like $e^{-d_{i} t}$, where $d_{i}$ is the discount rate. The term $C_{i}(t)$ is an additive delay cost function for queue $i$, representing additional costs incurred due to delay, such as opportunity costs or penalties. These costs capture a variety of losses that can occur due to the deterioration of execution performance with delay 10\nLet $\\boldsymbol{\\lambda} \\equiv\\left(\\lambda_{1}, \\ldots, \\lambda_{N}\\right)$ denote a vector of demand rates in each submarket. Each user in queue $i$ maximizes her own expected utility, which she forecasts using the distribution of the steady-state delay $\\hat{W}\\left(\\lambda_{i}\\right)$. The delay depends on the set of paying users only through the resulting demand rate $\\lambda_{i}$ and is not affected by the actions of an individual atomistic user. In addition, we allowed the individual delay costs $D_{i}(t)$ and $C_{i}(t)$ to depend directly on $i$, which can reflect the selection of different types of users in queues. Let $\\bar{D}_{i}\\left(\\lambda_{i}\\right) \\equiv \\mathbb{E}\\left[D_{i}\\left(\\hat{W}\\left(\\lambda_{i}\\right)\\right)\\right]$ and $\\bar{C}_{i}\\left(\\lambda_{i}\\right) \\equiv \\mathbb{E}\\left[C_{i}\\left(\\hat{W}\\left(\\lambda_{i}\\right)\\right)\\right]$ be the expected delay discount and delay cost functions, respectively. Given $\\lambda_{i}$, a user with value $v_{i}$ for submarket $i$ who pays $p_{i}$ has expected utility\n\n$$\nu\\left(v_{i} \\mid p_{i}, \\lambda_{i}\\right) \\equiv v_{i} \\cdot \\bar{D}_{i}\\left(\\lambda_{i}\\right)-\\bar{C}_{i}\\left(\\lambda_{i}\\right)-p_{i}\n$$\n\nLocal Equilibrium Demand. I now consider the equilibrium behavior of users in each queue. Let $i \\in\\{1, \\ldots, N\\}$ and $p_{i}$ the price in submarket $i$. Suppose $V_{i}$ is continuously differentiable in $\\mathbb{R}^{+}$and that the net value to the highest value user of being served immediately in each queue is positive, that is $V_{i}^{\\prime}(0) \\bar{D}_{i}(0)-\\bar{C}_{i}(0)>0$. This condition ensures that there is a positive net benefit to participating in the market for at least some users. Without loss of generality, I index the queues in decreasing order (without ties) of their net value of being served immediately: $V_{1}^{\\prime}(0) \\bar{D}_{1}(0)-\\bar{C}_{1}(0)>V_{2}^{\\prime}(0) \\bar{D}_{2}(0)-\\bar{C}_{2}(0)>\\cdots>V_{N}^{\\prime}(0) \\bar{D}_{N}(0)-\\bar{C}_{N}(0)$. Given a price $p_{i}$, queue $i$ is active (i.e., has positive demand) if the highest-value user obtains positive expected utility when served immediately: $V_{i}^{\\prime}(0) \\cdot \\bar{D}_{i}(0)-\\bar{C}_{i}(0)>p_{i}$. The marginal user has valuation $V_{i}^{\\prime}\\left(\\lambda_{i}\\left(p_{i}\\right)\\right)$ and zero expected utility in equilibrium. That is, in any Nash equilibrium, users join if, and only if demand in market $i, \\lambda_{i}\\left(p_{i}\\right)$, satisfies\n\n$$\nu\\left(V_{i}^{\\prime}\\left(\\lambda_{i}\\left(p_{i}\\right)\\right) \\mid p_{i}, \\lambda_{i}\\right)=V_{i}^{\\prime}\\left(\\lambda_{i}\\left(p_{i}\\right)\\right) \\cdot \\bar{D}_{i}\\left(\\lambda_{i}\\right)-\\bar{C}_{i}\\left(\\lambda_{i}\\right)-p_{i}=0\n$$\n\nThis equilibrium condition can be interpreted in at least two ways. If users can choose which queue to join, entry and exit occur across queues in equilibrium until the expected utility from joining any queue equals\n\n[^0]\n[^0]:    ${ }^{10}$ Typical costs due to slow execution can be the failure to purchase a good, loss of an arbitrage opportunity, sandwich-attacked transactions, and other MEV attacks.\n\ntheir outside option (which is normalized to zero). ${ }^{11}$ Second, if the protocol dictates which queue transactions are assigned to (e.g., based on transaction type or resource accessed), entry and exit occur within each queue, and the expected utility for the marginal user in each queue equals zero. Users decide whether to participate based on the conditions in their assigned queue. Thus, the equilibrium condition maps the demand rate $\\lambda_{i}$ to the price in queue $i$ and vice-versa for queues that are active. Henceforth, we will write such expression as $p_{i}\\left(\\lambda_{i}\\right)$.\n\nGlobal Inclusion Constraint. Because all transactions need to be considered for consensus before the execution phase, there is a global capacity constraint on the total number of transactions that can be included. Let $\\kappa$ denote the global capacity of transactions that can be served per unit of time. The capacity constraint is then\n\n$$\n\\sum_{i=1}^{N} \\lambda_{i} \\leq \\kappa:\n$$\n\n. This constraint implies that the sum of the demand rates across all queues cannot exceed the global capacity $\\kappa$. It reflects limitations such as block size, network bandwidth, and the need for synchronization across the network.\nIn this analysis, I focus on instances where the global capacity constraint is binding, meaning that the total demand equals the capacity. This situation is common in blockchain systems during periods of high demand. The problem of variable global capacity would deliver similar results.",
      "tables": {
        "table_5": "|  | $a_{1}^{\\prime}$ | $b_{1}^{\\prime \\prime}$ | $a_{4}^{\\prime}$ | $b_{3}^{\\prime \\prime}$ | $a_{2}^{\\prime}$ |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n|  | 1.5 | $\\frac{4}{3}$ | 1.2 | $\\frac{7}{5}$ | 1 |"
      },
      "images": {}
    },
    {
      "section_id": 7,
      "text": "# 4 Results \n\nIn this section, I analyze the implications of the model for revenue maximization and welfare maximization.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 8,
      "text": "### 4.1 Revenue Maximization\n\nWe begin by examining how a protocol or miners/validators aiming to maximize revenue would set prices and allocate capacity across the different queues.\n\nRevenue. Let $\\mathcal{S}$ denote the set of served queues, i.e., the queues that are active and receive a positive capacity allocation. The protocol's revenue is the total fees collected from all served queues, which can be expressed as $\\sum_{i \\in \\mathcal{S}} \\lambda_{i} p_{i}\\left(\\lambda_{i}\\right)$, where $\\lambda_{i}$ is the demand rate in queue $i$, and $p_{i}\\left(\\lambda_{i}\\right)$ is the price charged in queue $i$ as a function of the demand rate. Using the equilibrium condition from equation (3), the revenue maximization\n\n[^0]\n[^0]:    ${ }^{11}$ This would be, for instance, the case of multi-proposer consensus, or DAG-based blockchains where users choose to which part of the graph they send their transactions.\n\nproblem can be expressed in terms of demand rates. For simplicity of notation, we assume here that all queues are served. ${ }^{12}$\n\n$$\n\\Pi=\\max _{\\left(p_{1}, \\ldots, p_{N}\\right)} \\sum_{i=1}^{N} \\lambda_{i} V_{i}^{\\prime}\\left(\\lambda_{i}\\right) \\cdot \\bar{D}_{i}\\left(\\lambda_{i}\\right)-\\lambda_{i} \\cdot \\bar{C}_{i}\\left(\\lambda_{i}\\right)\n$$\n\nOur objective is to find the set of prices $\\left(p_{1}, p_{2}, \\ldots, p_{N}\\right)$ and served queues $\\mathcal{S}$ that maximize revenue $\\Pi$, subject to the local equilibrium condition (3) for all served queues and the global capacity constraint (4). I consider uniform pricing where $p_{1}=\\cdots=p_{N}=p \\in \\mathbb{R}_{+}$and optimal relative prices $\\left(p_{1}, \\ldots, p_{N}\\right) \\in \\mathbb{R}_{+}^{N}$. The following proposition characterizes the revenue-maximizing allocation under both pricing strategies.\n\nProposition 1. There exists a threshold capacity $\\underline{\\kappa} \\in(0,+\\infty)$ such that for all total capacities $\\kappa \\leq \\underline{\\kappa}$, the revenue-maximizing uniform price and the revenue-maximizing relative prices allocate all capacity to the highest price queue, i.e., $\\mathcal{S}=\\{1\\}$.\n\nProof. The idea of the proof is to construct a small capacity (or equivalently, a large enough level of congestion and price for queue 1) so that no customers will be willing to join queues $2, \\ldots, N$ and net revenue from queue one is increasing in its allocated capacity. In these conditions, allocating all capacity to queue one is revenue maximizing. Since $V_{1}^{\\prime}(0) \\bar{D}_{1}(0)-\\bar{C}_{1}(0)>V_{2}^{\\prime}(0) \\bar{D}_{2}(0)-\\bar{C}_{2}(0)>\\cdots>V_{N}^{\\prime}(0) \\bar{D}_{N}(0)-\\bar{C}_{N}(0)$ without loss of generality, and $V_{i}^{\\prime}(\\lambda) \\bar{D}_{i}(\\lambda)-\\bar{C}_{i}(\\lambda)$ is continuously decreasing in $\\lambda$ for all $i$, there exists $\\kappa_{1} \\in(0,+\\infty)$ such that $V_{1}^{\\prime}\\left(\\kappa_{1}\\right) \\bar{D}_{1}\\left(\\kappa_{1}\\right)-$ $\\bar{C}_{1}\\left(\\kappa_{1}\\right)>V_{2}^{\\prime}(0) \\bar{D}_{2}(0)-\\bar{C}_{2}(0)>\\cdots>V_{N}^{\\prime}(0) \\bar{D}_{N}(0)-\\bar{C}_{N}(0)$. Denote gross revenue from queue 1 absent any delays as $R_{1}\\left(\\lambda_{1}\\right)=\\lambda_{1} V_{1}^{\\prime}\\left(\\lambda_{1}\\right)$, the marginal net revenue from this queue is $R_{1}^{\\prime}\\left(\\lambda_{1}\\right) \\bar{D}_{1}\\left(\\lambda_{1}\\right)-\\bar{C}_{1}\\left(\\lambda_{1}\\right)+$ $\\lambda_{1} V_{1}^{\\prime}\\left(\\lambda_{1}\\right) \\bar{D}_{1}\\left(\\lambda_{1}\\right)-\\lambda_{1} \\bar{C}_{1}\\left(\\lambda_{1}\\right)$. Evaluated at $\\lambda_{1}=0$ yields $R_{1}^{\\prime}(0) \\bar{D}_{1}(0)-$ $\\bar{C}_{1}(0)=V_{1}^{\\prime}(0) \\bar{D}_{1}(0)-\\bar{C}_{1}(0)>0$, therefore, by continuity, the marginal net revenue from queue 1 is increasing in a neighborhood of 0 . That is, $\\exists 0<\\underline{\\kappa} \\leq \\kappa_{1}$ such that $V_{1}^{\\prime}(\\underline{\\kappa}) \\bar{D}_{1}(\\underline{\\kappa})-\\bar{C}_{1}(\\underline{\\kappa})>V_{2}^{\\prime}(0) \\bar{D}_{2}(0)-$ $\\bar{C}_{2}(0)>\\cdots>V_{N}^{\\prime}(0) \\bar{D}_{N}(0)-\\bar{C}_{N}(0)$ and the net revenue function $\\kappa \\mapsto \\kappa\\left[V_{1}^{\\prime}(\\kappa) \\bar{D}_{1}(\\kappa)-\\bar{C}_{1}(\\kappa)\\right]$ is increasing in $[0, \\underline{\\kappa}]$. In both the relative price and uniform price case, for capacity below $\\underline{\\kappa}$ it is revenue maximizing to allocate all capacity to queue 1 , since at those capacities and prices, no customers will be willing to join queues $2, \\ldots, N$ and the total capacity is used since net revenue from queue one is increasing in this segment.\n\nThis proposition highlights a potential inefficiency in revenue maximization: when capacity is limited, the system tends to favor the queue with the highest-paying users, potentially excluding transactions from other queues that could contribute positively to social welfare.\n${ }^{12}$ The general expression is\n\n$$\n\\Pi=\\max _{\\mathcal{S},\\left(p_{i} ; i \\in \\mathcal{S}\\right)} \\sum_{i \\in \\mathcal{S}} \\lambda_{i} V_{i}^{\\prime}\\left(\\lambda_{i}\\right) \\cdot \\bar{D}_{i}\\left(\\lambda_{i}\\right)-\\lambda_{i} \\cdot \\bar{C}_{i}\\left(\\lambda_{i}\\right)\n$$",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 9,
      "text": "# 4.2 Welfare Maximization \n\nNext, I consider the objective of maximizing social welfare, which takes into account the total net benefit to all users across all queues rather than focusing solely on revenue. The protocol's social welfare over all queues ${ }^{13}$\n\n$$\nS W=\\max _{\\lambda_{i} \\in\\left[0, \\Lambda_{i}\\right)^{N}} \\sum_{i=1}^{N} V_{i}\\left(\\lambda_{i}\\right) \\cdot \\bar{D}_{i}\\left(\\lambda_{i}\\right)-\\lambda_{i} \\cdot \\bar{C}_{i}\\left(\\lambda_{i}\\right)\n$$\n\nSubject to the local equilibrium condition (3) and the global inclusion constraint (4). The protocol's social welfare is defined as the sum of the expected net values to all users across all queues, accounting for delay costs. Under welfare maximization, setting optimal relative prices $\\left(p_{1}, \\ldots, p_{N}\\right) \\in \\mathbb{R}_{+}^{N}$ is equivalent to a planner choosing the demand rates $\\lambda_{i} \\in\\left[0, \\Lambda_{i}\\right)^{N}, i \\in \\mathcal{S}$ directly subject to local equilibrium conditions (3) in all served queues and the global capacity constraint(4). The following proposition shows that the relative price social optimum generically serves all queues.\n\nProposition 2. Suppose that the discount rate and linear delay cost functions are so that the net utility function from queue $i$, that is $W_{i} \\equiv$ $\\lambda_{i} \\mapsto V_{i}\\left(\\lambda_{i}\\right) \\cdot \\bar{D}_{i}\\left(\\lambda_{i}\\right)-\\lambda_{i} \\cdot \\bar{C}_{i}\\left(\\lambda_{i}\\right)$ is strictly concave, and $\\exists \\nu>0$ such that $W_{i}^{\\prime}(0)>\\nu$ for all $i$, and $\\sum_{i=1}^{N}\\left(W_{i}^{\\prime}\\right)^{-1}(\\nu)=\\kappa$ then in the relative price social optimum, capacity is allocated in all queues, $\\mathcal{S}=\\{1, \\ldots, N\\}$.\n\nProof. Since each $W_{i}$ is strictly concave, their sum is strictly concave. Let $\\lambda^{*}$ be an optimal solution to the problem. By the Karush-Kuhn-Tucker conditions, $\\exists \\mu \\geq 0$ such that $W_{i}^{\\prime}\\left(\\lambda_{i}^{*}\\right)=\\mu$ if $\\lambda_{i}^{*}>0$ and $W_{i}^{\\prime \\prime}\\left(\\lambda_{i}^{*}\\right) \\leq$ $\\mu$ if $\\lambda_{i}^{*}=0$ Suppose, for contradiction, that $\\exists j$ such that $\\lambda_{j}^{*}=0$. Then, $W_{j}^{\\prime}(0) \\leq \\mu$. But we know that $W_{j}^{\\prime}(0)>\\nu$, therefore, $\\mu>\\nu$. There exists at least one index $i$ so that $\\lambda_{i}^{*}>0$, otherwise total capacity would be zero. For all $i$ where $\\lambda_{i}^{*}>0$, we have $W_{i}^{\\prime}\\left(\\lambda_{i}^{*}\\right)=\\mu>\\nu$. Since $W_{i}$ is strictly concave, $W_{i}^{\\prime}$ is strictly decreasing. Therefore, $\\lambda_{i}^{*}<$ $\\left(W_{i}^{\\prime}\\right)^{-1}(\\nu)$ for all $i$ where $\\lambda_{i}^{*}>0$. This implies that $\\sum_{i=1}^{N} \\lambda_{i}^{*}<\\sum_{i=1}^{N}\\left(W_{i}^{\\prime}\\right)^{-1}(\\nu)=$ $\\kappa$. But this contradicts the optimality of $\\lambda^{*}$ because we can increase the objective function by increasing $\\lambda_{j}^{*}$ slightly while still satisfying the constraint. Therefore, our assumption of the existence of $j$ is a contradiction, and we conclude that $\\lambda_{i}^{*}>0$ for all $i$. That is, all queues are allocated non-zero capacity.\n\nThis proposition indicates that, under welfare maximization, it is optimal to serve all queues, distributing capacity across them in a way that balances the marginal social welfare contributions. This contrasts with the revenue-maximizing allocation, which may exclude some queues to maximize revenue.\n\n[^0]\n[^0]:    ${ }^{13}$ The general problem is\n\n    $$\n    S W=\\max _{\\mathcal{S}, \\lambda_{i} \\in\\left[0, \\Lambda_{i}\\right)^{N}, i \\in \\mathcal{S}} \\sum_{i \\in \\mathcal{S}} V_{i}\\left(\\lambda_{i}\\right) \\cdot \\bar{D}_{i}\\left(\\lambda_{i}\\right)-\\lambda_{i} \\cdot \\bar{C}_{i}\\left(\\lambda_{i}\\right)\n    $$",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 10,
      "text": "# 4.3 Welfare Maximizing Relative Pricing \n\nHaving established that welfare maximization leads to capacity allocation across all queues, we now derive the welfare-maximizing relative prices that support this allocation under the conditions of Proposition 2 Let $\\mu$ denote the Lagrange multiplier associated with the global capacity constraint (4). Economically, $\\mu$ represents the shadow price of including an additional transaction in the system; it reflects the marginal social cost of capacity constraints. The following propositions link the socially optimal prices in each queue to this shadow price and demand characteristics.\n\nProposition 3. The socially optimal relative prices are given by\n\n$$\np_{i}=-V_{i}\\left(\\lambda_{i}\\right) \\bar{D}_{i}\\left(\\lambda_{i}\\right)+\\lambda_{i} \\bar{C}_{i}\\left(\\lambda_{i}\\right)+\\mu\n$$\n\nThis proposition emerges from the first order condition for $\\lambda_{i}$ and replacing $p_{i}$ from (3). This expression shows that the socially optimal price in queue $i$ includes three components. First, the local delay externality $-V_{i}\\left(\\lambda_{i}\\right) \\cdot \\bar{D}_{i}\\left(\\lambda_{i}\\right)$ captures the negative impact of increased demand on the expected delay discount. As $\\lambda_{i}$ increases, the expected delay increases (since the system becomes more congested), reducing the net value for all users in queue $i$. Second, the local additive delay cost $\\lambda_{i} \\cdot \\bar{C}_{i}^{t}\\left(\\lambda_{i}\\right)$ represents the additional additive delay costs incurred due to increased demand. Third, the global capacity externality $\\mu$ reflects the marginal cost of consuming limited capacity that could have been used by other queues.\nAt the socially optimal prices, the marginal user's expected net value is equal to the total externality they impose on the system. This ensures that users internalize the full social cost of their participation, leading to an efficient allocation of resources.\nTo gain further insights, I specialize the model to a setting where the time between arrivals is exponentially distributed, and the execution times for each user also follow an exponential distribution. Each market has size $\\Lambda_{i}$ each with a different isoelastic marginal value function $V_{i}^{\\prime}\\left(\\lambda_{i}\\right)=\\left(\\lambda_{i} / \\Lambda_{i}\\right)^{-1 / \\varepsilon_{i}}$ where $\\varepsilon_{i}>1$ represents demand elasticity for queue/resource $i$. In this setting, $V_{i}\\left(\\lambda_{i}\\right)=\\frac{\\left(\\lambda_{i} / \\Lambda_{i}\\right)^{1-1 / \\varepsilon_{i}}}{1-1 / \\varepsilon_{i}}$.\nAssuming that the delay discount function is exponential, $D(t)=e^{-d t}$ and the additive delay cost is linear $C(t)=c \\times t$ where $c, d>0$, we have (see Appendix A for detailed derivations)\n\n$$\n\\begin{aligned}\n\\bar{C}_{i}\\left(\\lambda_{i}\\right) & =\\frac{c}{1-\\lambda_{i}} \\\\\n\\bar{D}_{i}\\left(\\lambda_{i}\\right) & =\\frac{1-\\lambda_{i}}{1+d-\\lambda_{i}}\n\\end{aligned}\n$$\n\nApproximation under High Parallelization. Suppose that the demand rates $\\lambda_{i}$ and $\\lambda_{j}$ are small relative to 1 and the discount rate $d$, reflecting a high degree of parallelization (i.e., the system can process many transactions concurrently). Under this assumption, we can approximate the socially optimal relative prices.\n\nCorollary 1. Under the above assumptions, the ratio of the socially optimal prices in queues $i$ and $j$ is approximately\n\n$$\n\\frac{p_{i}}{p_{j}} \\approx \\frac{\\frac{\\left(\\lambda_{i} / \\Lambda_{i}\\right)^{1-1 / \\varepsilon_{i}}}{1-1 / \\varepsilon_{i}} \\cdot \\frac{d}{(1+d)^{2}}+c \\lambda_{i}+\\mu}{\\frac{\\left(\\lambda_{i} / \\Lambda_{j}\\right)^{1-1 / \\varepsilon_{j}}}{1-1 / \\varepsilon_{j}} \\cdot \\frac{d}{(1+d)^{2}}+c \\lambda_{j}+\\mu}\n$$\n\nProof. First, we compute the derivatives: $V_{i}^{\\prime}\\left(\\lambda_{i}\\right)=\\Lambda_{i} \\lambda_{i}^{-1 / \\varepsilon_{i}}, \\overline{D^{\\prime}}\\left(\\lambda_{i}\\right)=$ $-\\frac{d}{(1+d-\\lambda_{i})^{2}}, \\overline{C^{\\prime}}\\left(\\lambda_{i}\\right)=\\frac{c}{(1-\\lambda_{i})^{2}}$. Substitute into the equation for $p_{i}, p_{i}=$ $\\frac{\\left(\\lambda_{i} / \\Lambda_{i}\\right)^{1-1 / \\varepsilon_{i}}}{1-1 / \\varepsilon_{i}} \\cdot\\left(\\frac{d}{(1+d-\\lambda_{i})^{2}}\\right)+\\lambda_{i} \\cdot \\frac{c}{(1-\\lambda_{i})^{2}}+\\mu$. Consider the ratio $p_{i} / p_{j}$. Assuming $\\lambda_{i}$ and $\\lambda_{j}$ are small compared to 1 and $d$ we have $(1+d-\\lambda_{i})^{2} \\approx$ $(1+d)^{2},\\left(1-\\lambda_{i}\\right)^{2} \\approx 1$, replacing in the expression for relative prices yields $\\frac{p_{i}}{p_{j}} \\approx \\frac{\\frac{\\left(\\lambda_{i} / \\Lambda_{i}\\right)^{1-1 / \\varepsilon_{i}}}{1-1 / \\varepsilon_{i}} \\cdot \\frac{d}{(1+d)^{2}}+c \\lambda_{i}+\\mu}{\\frac{\\left(\\lambda_{i} / \\Lambda_{i}\\right)^{1-1 / \\varepsilon_{j}}}{1-1 / \\varepsilon_{j}} \\cdot \\frac{d}{(1+d)^{2}}+c \\lambda_{j}+\\mu}$.\n\nThe approximate price ratio reveals how the optimal prices depend on queue-specific characteristics such as market size $\\Lambda_{i}$, demand elasticity $\\varepsilon_{i}$, and demand rates $\\lambda_{i}$. When $\\mu$ is small relative to the other terms (i.e., when local congestion effects dominate global capacity constraints), the price ratio is primarily determined by these queue-specific factors. As $\\mu$ increases (i.e., when global congestion becomes more significant), its effect is to push the price ratio closer to 1 , reducing price differentiation across queues.\n\nCorollary 2. Suppose, in addition to the assumptions of Corollary 1, that local congestion dominates global congestion ( $\\mu$ is negligible compared to $p_{i}$ and $p_{j}$ ), and demand is perfectly elastic $\\left(\\varepsilon_{i}, \\varepsilon_{j} \\rightarrow \\infty\\right)$. Then, the price ratio is simplified to\n\n$$\n\\frac{p_{i}}{p_{j}} \\approx \\frac{\\lambda_{i}}{\\lambda_{j}} \\cdot \\frac{\\Lambda_{i}}{\\Lambda_{i}}\n$$\n\nThis limit expression offers several insights. First, in the case of perfectly elastic demand, the optimal prices are proportional to the ratio of demand rates normalized by market sizes $\\left(\\lambda_{i} / \\Lambda_{i}\\right)$. This suggests that setting prices based on the relative demand intensity in each queue approximates the welfare-maximizing solution. Second, as the market size $\\Lambda_{i}$ for a congested queue decreases, the optimal price for that queue diverges from a uniform price, reflecting the higher marginal value of capacity in smaller markets.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 11,
      "text": "# 5 Conclusion \n\nIn this paper, I investigated posted-price Parallel Execution Fee Mechanisms within a capacity-constrained blockchain system characterized by multiple queues or local fee markets. My model captures the essential features of parallel execution in blockchain networks, where transactions may access different resources or contracts and can be processed concurrently. A key aspect of our analysis was the global inclusion constraint\n\nimposed by the consensus mechanism. This constraint necessitates that all transactions, regardless of their queue, must be considered collectively for inclusion.\nThe analysis reveals several key insights. When the objective is to maximize revenue, especially under limited capacity, the system tends to allocate all capacity to the queue with users willing to pay the highest fees. In contrast, when the objective is to maximize social welfare, the optimal allocation generally involves serving all queues. I found that the optimal relative pricing across different queues depends on several factors, including market size, demand elasticity, and the balance between local and global congestion. In settings where demand elasticity is high, and local congestion effects dominate, pricing individual queues proportional to demand relative to market size is approximately welfare-maximizing. The findings suggest that implementing local fee markets within such blockchains can improve overall system efficiency. By defining local values for each state, contract, or object and employing an adaptive base fee mechanism for inclusion, transactions can be assigned to queues with different relative prices. As blockchain technologies evolve towards more complex architectures, such as parallel execution, Directed Acyclic Graph (DAG)-based systems, and multiple concurrent proposers, this paper provides valuable insights for protocol designers.\nWhile this study provides a foundational model for efficient parallel execution fee mechanisms, I have abstracted from several aspects of transaction execution on blockchains.\nOne important extension is the study of optimal local priority auctions. In such a setting, customers could participate in a two-stage bidding process for entering queues in a system with multiple service points. Initially, users might bid for priority in a global queue, reflecting the capacity constraints of the consensus mechanism. Subsequently, they could bid for specific services in parallel queues, corresponding to different resources or contracts. Studying how to design such auctions to optimize for social welfare or revenue maximization would be a promising area for further research.\nAnother area for future research is the development of dynamic pricing mechanisms that adapt to changing network conditions, user behaviors, and congestion levels in real time. While a comprehensive examination of these complex issues lies beyond the scope of this paper, they offer promising opportunities for future research and further refinement of my analysis.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 12,
      "text": "# References \n\n1. Afeche, P., Mendelson, H.: Pricing and priority auctions in queueing systems with a generalized delay cost structure. Management science $\\mathbf{5 0}(7), 869-882(2004)$\n2. Bahrani, M., Garimidi, P., Roughgarden, T.: Transaction Fee Mechanism Design in a Post-MEV World. In: B\u00f6hme, R., Kiffer, L. (eds.) 6th Conference on Advances in Financial Technologies (AFT 2024). Leibniz International Proceedings\n\nin Informatics (LIPIcs), vol. 316, pp. 29:1-29:24. Schloss Dagstuhl - Leibniz-Zentrum f\u00fcr Informatik, Dagstuhl, Germany (2024). https://doi.org/10.4230/LIPIcs.AFT.2024.29, https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.AFT.2024.29\n3. Bonneau, J., Felten, E., Miller, A., Goldfeder, S.: Bitcoin and cryptocurrency technologies arvind narayanan. Network Security 2016(8), 4 (2016)\n4. Budish, E.: Trust at Scale: The Economic Limits of Cryptocurrencies and Blockchains* $\\dagger$. The Quarterly Journal of Economics p. qjae033 (10 2024). https://doi.org/10.1093/qje/qjae033, https://doi.org/10.1093/qje/qjae033\n5. Buterin, V.: Blockchain resource pricing. URL: https://ethresear. ch/uploads/default/original X 2 (2018)\n6. Chung, H., Shi, E.: Foundations of transaction fee mechanism design. In: Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA). pp. 3856-3899. SIAM (2023)\n7. Halaburda, H., Haeringer, G., Gans, J., Gandal, N.: The microeconomics of cryptocurrencies. Journal of Economic Literature 60(3), 971-1013 (September 2022). https://doi.org/10.1257/jel.20201593, https://www.aeaweb.org/articles?id=10.1257/jel. 20201593\n8. Keidar, I., Kokoris-Kogias, E., Naor, O., Spiegelman, A.: All you need is dag. In: Proceedings of the 2021 ACM Symposium on Principles of Distributed Computing. pp. 165-175 (2021)\n9. Kiayias, A., Koutsoupias, E., Lazos, P., Panagiotakos, G.: Tiered mechanisms for blockchain transaction fees (2023), https://arxiv.org/abs/2304.06014\n10. Leshno, J.D., Strack, P.: Bitcoin: An axiomatic approach and an impossibility theorem. American Economic Review: Insights 2(3), 269-86 (September 2020). https://doi.org/10.1257/aeri.20190494, https://www.aeaweb.org/articles?id=10.1257/aeri. 20190494\n11. Mendelson, H.: Pricing computer services: queueing effects. Communications of the ACM 28(3), 312321 (Mar 1985). https://doi.org/10.1145/3166.3171, https://dl.acm.org/doi/10.1145/3166.3171\n12. Naor, P.: The regulation of queue size by levying tolls. Econometrica: journal of the Econometric Society pp. 15-24 (1969)\n13. Ndiaye, A.: Why bitcoin and ethereum differ in transaction fees: A theory of blockchain fee policies. CEPR Discussion Paper No. 18890 (2024), https://cepr.org/publications/dp18890\n14. Ndiaye, A.: Blockchain price vs. quantity controls. Working Paper (2023)\n15. Roughgarden, T.: Transaction fee mechanism design for the ethereum blockchain: An economic analysis of eip-1559. arXiv preprint arXiv:2012.00854 (2020)\n16. Roughgarden, T.: Transaction fee mechanism design. ACM SIGecom Exchanges 19(1), 52-55 (2021)\n17. SEC: Statement on the approval of spot bitcoin exchange-traded products. https://www.sec.gov/newsroom/speeches-statements/gensler-statement-spot-bitcoin-011023 (2024), accessed: 2024-10-22\n\n18. Shi, E., Chung, H., Wu, K.: What Can Cryptography Do for Decentralized Mechanism Design? In: Tauman Kalai, Y. (ed.) 14th Innovations in Theoretical Computer Science Conference (ITCS 2023). Leibniz International Proceedings in Informatics (LIPIcs), vol. 251, pp. 97:1-97:22. Schloss Dagstuhl - Leibniz-Zentrum f\u00fcr Informatik, Dagstuhl, Germany (2023). https://doi.org/10.4230/LIPIcs.ITCS.2023.97, https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ITCS.2023.97",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 13,
      "text": "# A Appendix\n## A. 1 Expression of delay costs\n\nProof. We begin by considering the definitions of $\\bar{C}_{i}\\left(\\lambda_{i}\\right)$ and $\\bar{D}_{i}\\left(\\lambda_{i}\\right)$ :\n\n$$\n\\begin{aligned}\n& \\bar{C}_{i}\\left(\\lambda_{i}\\right)=\\mathbb{E}\\left[C\\left(T_{i}\\right)\\right]=\\int_{0}^{\\infty} C(t) f_{T_{i}}(t) d t \\\\\n& \\bar{D}_{i}\\left(\\lambda_{i}\\right)=\\mathbb{E}\\left[D\\left(T_{i}\\right)\\right]=\\int_{0}^{\\infty} D(t) f_{T_{i}}(t) d t\n\\end{aligned}\n$$\n\nwhere $f_{T_{i}}(t)$ is the probability density function of the exponential distribution with rate parameter $\\lambda_{i}$ :\n\n$$\nf_{T_{i}}(t)=\\lambda_{i} e^{-\\lambda_{i} t}\n$$\n\nFor $\\bar{C}_{i}\\left(\\lambda_{i}\\right)$, we substitute $C(t)=c t$ and solve:\n\n$$\n\\begin{aligned}\n\\bar{C}_{i}\\left(\\lambda_{i}\\right) & =\\int_{0}^{\\infty} c t \\lambda_{i} e^{-\\lambda_{i} t} d t \\\\\n& =c \\lambda_{i} \\int_{0}^{\\infty} t e^{-\\lambda_{i} t} d t \\\\\n& =c \\lambda_{i}\\left[-\\left.\\frac{t}{\\lambda_{i}} e^{-\\lambda_{i} t}\\right|_{0} ^{\\infty}-\\int_{0}^{\\infty}-\\frac{1}{\\lambda_{i}} e^{-\\lambda_{i} t} d t\\right] \\\\\n& =c \\lambda_{i}\\left[0+\\frac{1}{\\lambda_{i}^{2}}\\right] \\\\\n& =\\frac{c}{\\lambda_{i}}=\\frac{c}{1-\\lambda_{i}}\n\\end{aligned}\n$$\n\nFor $\\bar{D}_{i}\\left(\\lambda_{i}\\right)$, we substitute $D(t)=e^{-d t}$ and solve:\n\n$$\n\\begin{aligned}\n\\bar{D}_{i}\\left(\\lambda_{i}\\right) & =\\int_{0}^{\\infty} e^{-d t} \\lambda_{i} e^{-\\lambda_{i} t} d t \\\\\n& =\\lambda_{i} \\int_{0}^{\\infty} e^{-\\left(d+\\lambda_{i}\\right) t} d t \\\\\n& =\\lambda_{i}\\left[-\\left.\\frac{1}{d+\\lambda_{i}} e^{-\\left(d+\\lambda_{i}\\right) t}\\right|_{0} ^{\\infty}\\right] \\\\\n& =\\lambda_{i}\\left[0+\\frac{1}{d+\\lambda_{i}}\\right] \\\\\n& =\\frac{\\lambda_{i}}{d+\\lambda_{i}}=\\frac{1-\\lambda_{i}}{1+d-\\lambda_{i}}\n\\end{aligned}\n$$\n\nThus, when the delay discount function is exponential $D(t)=e^{-d t}$ and the additive delay cost is linear $C(t)=c \\times t$ where $c, d>0$, the following equations hold:\n\n$$\n\\begin{aligned}\n& \\bar{C}_{i}\\left(\\lambda_{i}\\right)=\\frac{c}{1-\\lambda_{i}} \\\\\n& \\bar{D}_{i}\\left(\\lambda_{i}\\right)=\\frac{1-\\lambda_{i}}{1+d-\\lambda_{i}}\n\\end{aligned}\n$$",
      "tables": {},
      "images": {}
    }
  ],
  "id": "2410.09555v2",
  "authors": [
    "Abdoulaye Ndiaye"
  ],
  "categories": [
    "econ.GN",
    "math.OC",
    "q-fin.EC"
  ],
  "abstract": "This paper investigates how pricing schemes can achieve efficient allocations\nin blockchain systems featuring multiple transaction queues under a global\ncapacity constraint. I model a capacity-constrained blockchain where users\nsubmit transactions to different queues -- each representing a submarket with\nunique demand characteristics -- and decide to participate based on posted\nprices and expected delays. I find that revenue maximization tends to allocate\ncapacity to the highest-paying queue, whereas welfare maximization generally\nserves all queues. Optimal relative pricing of different queues depends on\nfactors such as market size, demand elasticity, and the balance between local\nand global congestion. My results have implications for the implementation of\nlocal congestion pricing for evolving blockchain architectures, including\nparallel transaction execution, directed acyclic graph (DAG)-based systems, and\nmultiple concurrent proposers.",
  "updated": "2025-02-24T20:56:14Z",
  "published": "2024-10-12T15:03:26Z"
}