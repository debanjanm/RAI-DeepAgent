{"title": "Macroscopic Market Making Games via Multidimensional Decoupling Field", "sections": [{"section_id": 0, "text": "#### Abstract\n\nBuilding on the macroscopic market making framework as a control problem, this paper investigates its extension to stochastic games. In the context of price competition, each agent is benchmarked against the best quote offered by the others. We begin with the linear case. While constructing the solution directly, the ordering property and the dimension reduction in the equilibrium are revealed. For the non-linear case, we extend the decoupling approach by introducing a multidimensional characteristic equation to analyse the well-posedness of the forward-backward stochastic differential equations. Properties of the coefficients in this characteristic equation are derived using tools from non-smooth analysis. Several new well-posedness results are presented.\n\n\nKeywords: Market making, Stochastic differential game, Forward-backward stochastic differential equation, Riccati equation, Price impact", "tables": {}, "images": {}}, {"section_id": 1, "text": "## CONTENTS\n\n1. Introduction 1\n2. Linear Market Making Game 4\n3. General Market Making Game: Lipschitz Formulations 12\n4. General Game: $Z$-matrix and $M$-matrix 18\n5. General Game: Ordering Property and Decoupling Field 27\n6. General Game: Well-posedness and Properties 33\n7. Heterogeneous Risk Coefficients 40\nReferences 44\n8. Appendix: Stochastic Maximum Principle 46\n9. Appendix: Non-smooth Analysis and Implicit Function 50", "tables": {}, "images": {}}, {"section_id": 2, "text": "## 1. InTRODUCTION\n\nThis paper is mainly devoted to the strategic interactions between market makers, who act as liquidity providers in the financial market. Market makers offer bid and ask prices for one or multiple assets, generating profits from the bid-ask spread (the price difference between buying and selling orders). Market making as a stochastic control problem has been extensively explored in market microstructure literature, introduced by [25] and further developed by [4]. Recently, a\n\n[^0]\n[^0]:    Ivan Guo, Email: ivan.guo@monash.edu, Address: Centre for Quantitative Finance and Investment Strategies, School of Mathematics, Monash University, Wellington Rd, Clayton VIC 3800, Australia.\n\n    Corresponding author: Shijia Jin, Email: shijia.jin@monash.edu, Address: School of Mathematics, Monash University, Wellington Rd, Clayton VIC 3800, Australia.\n\nmacroscopic model \u00e0 la Avellaneda-Stoikov [4] has been proposed by [24], while still following the single-player optimization setting. Therefore, we extend the investigation to stochastic games within this macroscopic framework, with two main motivations in mind. Our model mainly focuses on quote-driven markets and order-driven markets where the ratio of bid-ask spread to tick size is large. We refer readers to the introduction of [24] for further details on the macroscopic model and a comparison with the Avellaneda-Stoikov model.\n\nThe study of market making games \u00e0 la Avellaneda-Stoikov is relatively rare, while two recent notable exceptions are [29] and [15]. As mentioned by [29], literatures on the market making as a stochastic control problem and trading via limit orders (e.g., [23], [22], [20], [6], [8]) share a common assumption. In detail, the probability that a limit order is executed at the quoted price is only a function of the price gap between the order and a reference price. While this approach offers tractability, it neglects the influences of prices offered by other market makers. In our setting, this 'probability' depends on the difference between the agent's price and the best price offered by the others. The consideration of price competition is a key distinction in our paper compared to these stochastic control models. In comparison to [29] and [15], we provide a distinct modelling of competition, which delivers several explicit mathematical results.\n\nThe macroscopic market making model seeks to bridge several gaps between market making and optimal execution problems. For comprehensive treatments of these two topics, we refer the reader to [21] and [11]. One key contribution of the macroscopic model is its alignment with optimal execution problems in representing market orders through trading rates. On the other hand, price impact functions-introduced by [1] and [7]-were designed to capture the effect of large orders on asset prices. These functions are typically pre-specified in an execution problem to accommodate stochastic control techniques. For instance, non-linear impact functions were studied in [2], while [34] considered stochastic coefficients. However, such impact functions serve primarily as approximations of actual price dynamics. In contrast, our approach models price impact as a consequence of the quoting strategies of market makers. Considering the number market participants, explaining price changes can be better achieved through the interactions of multiple market makers.\n\nContribution: This paper proposes novel game models for market makers. Mathematically, the contributions lie in the global well-posedness of Nash equilibria and the development of associated tools to achieve these results. From an economic perspective, along with novel models for price competitions, we aim to establish connections between the market making problem, price impact, and the optimal execution problem. The outline of each section is given as follows:\n\n- Section 2 studies the game in a linear setting, of which the well-posedness result is presented in Theorem 2.7. After introducing the general non-linear setting, Section 3 characterizes the Nash equilibrium as the solution of a forward-backward system (21). The local well-posedness is well-known, due to the Lipschitz property obtained by a novel version of the implicit function theorem.\n- To achieve the global well-posedness of (21), the generalized derivatives of the coefficient functions are analysed in Section 4. The finding is summarized in Theorem 4.7, using a novel non-smooth analysis method. Based on the generalized derivative, Section 5 explores a key property in the equilibrium, described in Theorem 5.6. Additionally, by an extension of the decoupling approach, Theorem 5.12 bridges the global well-posedness between (21) and a Riccati equation.\n\n- With above tools, several global well-posedness results (e.g., Theorem 6.5) are presented in Section 6, along with a price impact decomposition (58) in a simple example. Concerning heterogenous coefficients, Section 7 studies a two-player game; see Theorem 7.1.\n\nWe then provide a more detailed introduction. The paper starts with the linear case in Section 2 for analytic tractability. In the game setting, we let the portion be a linear decreasing function with respect to $\\delta-\\bar{\\delta}$, where $\\delta$ is the price gap of the agent and $\\bar{\\delta}$ is the smallest gap provided by the other market makers. In other words, each player is compared with the best quote from the others. The concavity of the objective functional helps characterize the Nash equilibrium as the solution of a forward-backward stochastic differential equation (FBSDE). Thanks to the linear structure, we can explicitly derive the solution of the equation. The ordering property in the stochastic control setting (Theorem 3.8 in [24])-agent with higher inventory tends to place ask orders at a lower price-persists in the equilibrium. This, in turn, effectively reduces the $N$-player game into a 4 -player game.\n\nNext, in Section 3 we delve into the case where the portion becomes a general decreasing function, as introduced in [20], with respect to $\\delta-\\bar{\\delta}$. After verifying the Isaac's condition, we introduce a non-smooth implicit function theorem to ensure the Lipschitz continuity of the implicit function. A version of the stochastic maximum principle then characterizes the equilibrium as an FBSDE, the local well-posedness of which is well-known due to the Lipschitz condition.\n\nTo achieve the global well-posedness result, in Section 4, we look at the 'derivative' of the coefficient functions. Since the functions are Lipschitz, we utilize the (Clarke) generalized derivatives and the corresponding non-smooth analysis. While the derivative of the implicit function in the smooth implicit function theorem is well-known, the generalized derivative of the implicit function in the non-smooth scenario is not as well established. A novel analysis reveals that the generalized derivative of the coefficient functions consists of $M$-matrices.\n\nBased on the derivative information, in Section 5, we show the ordering property remains in the non-linear setting. With respect to the FBSDE system, we adopt the method of decoupling fields introduced by [30] for the one-dimensional equation. A multi-dimensional extension of the characteristic BSDE is then presented. Consequently, the well-posedness of the FBSDE can then be guaranteed by the existence of a unique bounded solution to some backward stochastic Riccati equation (BSRE).\n\nThe majority of literature on Riccati equations deals with either symmetric or positive definite coefficient matrices, let alone literature on BSREs. Section 6 establishes several new wellposedness results, particularly providing a complete study of the 2 -dimensional equation. In companion with this 2-dimensional result, additional conditions are presented so that the 4 player game can be further reduced to a 2 -player game. As an example, we study the case when all players are identical. In this scenario, the permanent price impact can be further decomposed into two components: an ex post impact indicates the effect of past order imbalances, and an ex ante impact specifies the influences of expected imbalances in the future.\n\nWhile most prior discussions focus on agents with homogeneous risk parameters, Section 7 examines a stochastic game consisting of two heterogeneous agents. Despite the heterogeneity, the concavity of the objective functional remains unaffected, allowing the equilibrium to be characterized as the solution of an FBSDE. The well-posedness of the equation is derived based on [32]. Additionally, we provide an example demonstrating that the ordering property can fail in the heterogeneous case.\n\nNotation: Throughout the present work, we fix $T>0$ to represent our finite trading horizon. We denote by $\\left(\\Omega, \\mathcal{F}, \\mathbb{F}=\\left(\\mathcal{F}_{t}\\right)_{0 \\leq t \\leq T}, \\mathbb{P}\\right)$ a complete filtered probability space, with $\\mathcal{F}_{T}=\\mathcal{F}$.\n\nAn $m$-dimensional Brownian motion $W=\\left(W^{1}, \\ldots, W^{m}\\right)$ is defined on such space, for a fixed positive integer $m$, and the filtration $\\mathbb{F}$ is generated by $W$ and augmented. Let $\\mathcal{G}$ represents an arbitrary $\\sigma$-algebra contained in $\\mathcal{F}$ and consider the following spaces:\n\n$$\n\\begin{gathered}\nL^{p}(\\Omega, \\mathcal{G}):=\\left\\{X: X \\text { is } \\mathcal{G} \\text {-measurable and } \\mathbb{E}|X|^{p}<\\infty\\right\\} \\\\\n\\mathbb{H}^{p}:=\\left\\{X: X \\text { is } \\mathbb{F} \\text {-progressively measurable and } \\mathbb{E}\\left[\\left(\\int_{0}^{T}\\left|X_{t}\\right|^{2} d t\\right)^{p / 2}\\right]<\\infty\\right\\} \\\\\n\\mathbb{S}^{p}:=\\left\\{X \\in \\mathbb{H}^{p}: \\mathbb{E}\\left[\\sup _{0 \\leq t \\leq T}\\left|X_{t}\\right|^{p}\\right]<\\infty\\right\\}\n\\end{gathered}\n$$\n\n$\\mathbb{M}:=\\left\\{M: M_{t} \\in L^{2}\\left(\\Omega, \\mathcal{F}_{t}\\right)\\right.$ for a.e. $\\left.t \\in[0, T]\\right.$ and $\\left\\{M_{t}, \\mathcal{F}_{t}\\right\\}_{0 \\leq t \\leq T}$ is a continuous martingale $\\}$.\nWe use superscripts for enumerating purposes. For example, superscripts in $Q^{1}, Q^{2}$ are to mark objects which are associated with player 1 and player 2 respectively. In particular, $Q^{2}$ is not to be confused with quadratic powers, which will be explicitly denoted with brackets like $(Q)^{2}$.", "tables": {}, "images": {}}, {"section_id": 3, "text": "# 2. Linear Market Making Game \n\nIn [24], macroscopic marketing making was studied as a control problem for a market maker. Here we explore its extension as a stochastic game between several market makers. We start with the case of the linear intensity function and subsequently extend our analysis to general intensity functions. The linear structure of the model offers extra analytic tractability, allowing us to construct the solution explicitly. Moreover, we can see more directly how the $N$-player game can be reduced to the four-player framework.\n\nWe consider a scenario involving multiple liquidity takers engaged in trading a single asset within the market. The collective trading rates of market orders on the ask and bid side are represented by the processes $a:=\\left(a_{t}\\right)_{t \\in[0, T]} \\in \\mathbb{H}^{2}$ and $b:=\\left(b_{t}\\right)_{t \\in[0, T]} \\in \\mathbb{H}^{2}$, respectively, where $a_{t} \\in(0, \\bar{a}]$ and $b_{t} \\in(0, \\bar{b}]$ for some constants $\\bar{a}, \\bar{b}>0$. These trading rates reflect the liquidity demands of liquidity takers. To meet this demand, a group of $N \\in \\mathbb{N}$ homogeneous market makers provides the liquidity. Each market maker, identified by $i \\in\\{1, \\ldots, N\\}$, dynamically places buy limit orders at the price level $S_{t}-\\delta_{t}^{i, b}$ and sell limit orders at $S_{t}+\\delta_{t}^{i, a}$. Here, vector $\\boldsymbol{\\delta}^{i}:=\\left(\\delta^{i, a}, \\delta^{i, b}\\right) \\in \\mathbb{H}^{2} \\times \\mathbb{H}^{2}$ represents the control strategy employed by agent $i$, and $\\left\\{S_{t}, \\mathcal{F}_{t}\\right\\}_{t \\in[0, T]}$-the fundamental price-is a square-integrable martingale. Recalling that the linear intensity function is defined by $\\Lambda(\\delta)=\\zeta-\\gamma \\delta$, we introduce its game extension as follows:\n\nAssumption 2.1 (Linear intensity). The quantity of order flow executed by agent $i$ depends linearly on the difference between her offered price and the best price offered by the others. On the ask side, the executed flow is determined by the difference $\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}$, and on the bid side, it is determined by $\\delta_{t}^{i, b}-\\bar{\\delta}_{t}^{i, b}$, where\n\n$$\n\\bar{\\delta}_{t}^{i, a}:=\\min _{j \\neq i} \\delta_{t}^{j, a} \\quad \\text { and } \\quad \\bar{\\delta}_{t}^{i, b}:=\\min _{j \\neq i} \\delta_{t}^{j, b}\n$$\n\nSpecifically, if we write $v_{t}^{i, a}$ and $v_{t}^{i, b}$ as the (passive) selling and buying rates of the agent at time $t$, the linear dependence can be represented by\n\n$$\nv_{t}^{i, a}=a_{t} \\cdot\\left(\\zeta-\\gamma\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right)\\right) \\quad \\text { and } \\quad v_{t}^{i, b}=b_{t} \\cdot\\left(\\zeta-\\gamma\\left(\\delta_{t}^{i, b}-\\bar{\\delta}_{t}^{i, b}\\right)\\right)\n$$\n\nfor some constants $\\zeta, \\gamma>0$. We have also assumed the bid-ask symmetry for notational convenience.\n\nRemark 2.2. The proposed model serves as an approximation for the price competition. While the model does not guarantee the market clearing condition, it retains a crucial element from the Avellaneda-Stoikov model: the gap between the offered price and the 'best' price. Both the stochastic control problems in [24] and [4] can then be viewed as special cases where the 'best' price is assumed to be the fundamental price. On the other hand, it is possible in (1) that $v_{t}^{i, a}>a_{t}$. To address this, one can further propose a bounded action space for all agents and introduce an additional drift term in (1):\n\n$$\nv_{t}^{i, a}=a_{t}\\left(\\zeta-\\xi_{3}-\\gamma\\left(\\delta_{t}^{i, a} \\vee\\left(-\\xi_{1}\\right) \\wedge \\xi_{2}-\\bar{\\delta}_{t}^{i, a} \\vee\\left(-\\xi_{1}\\right) \\wedge \\xi_{2}\\right)\\right)\n$$\n\nwhere $\\xi_{1}, \\xi_{2}, \\xi_{3}>0$ are additional coefficients. We choose to not follow this approach, due to considerations of notation convenience and its little impact on the mathematical difficulty of the latter general case.\n\nThe inventory and cash of the agent $i$ are modelled by $X_{t}^{i}$ and $Q_{t}^{i}$ accordingly:\n\n$$\n\\begin{gathered}\nX_{t}^{i}=\\int_{0}^{t}\\left(S_{u}+\\delta_{u}^{i, a}\\right) a_{u}\\left(\\zeta-\\gamma\\left(\\delta_{u}^{i, a}-\\bar{\\delta}_{u}^{i, a}\\right)\\right) d u-\\int_{0}^{t}\\left(S_{u}-\\delta_{u}^{i, b}\\right) b_{u}\\left(\\zeta-\\gamma\\left(\\delta_{u}^{i, b}-\\bar{\\delta}_{u}^{i, b}\\right)\\right) d u \\\\\nQ_{t}^{i}=q_{0}^{i}-\\int_{0}^{t} a_{u}\\left(\\zeta-\\gamma\\left(\\delta_{u}^{i, a}-\\bar{\\delta}_{u}^{i, a}\\right)\\right) d u+\\int_{0}^{t} b_{u}\\left(\\zeta-\\gamma\\left(\\delta_{u}^{i, b}-\\bar{\\delta}_{u}^{i, b}\\right)\\right) d u\n\\end{gathered}\n$$\n\nwhere $q_{0}^{i} \\in \\mathbb{R}$ denotes the initial inventory level. The player $i$ aims at maximizing the objective functional\n\n$$\n\\begin{aligned}\nJ\\left(\\boldsymbol{\\delta}^{i} ; \\boldsymbol{\\delta}^{-i}\\right):= & \\mathbb{E}\\left[X_{T}^{i}+S_{T} Q_{T}^{i}-\\int_{0}^{T} \\phi_{t}\\left(Q_{t}^{i}\\right)^{2} d t-A\\left(Q_{T}^{i}\\right)^{2}\\right] \\\\\n= & \\mathbb{E}\\left[\\int_{0}^{T} \\delta_{t}^{i, a} a_{t}\\left(\\zeta-\\gamma\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right)\\right) d t+\\int_{0}^{T} \\delta_{t}^{i, b} b_{t}\\left(\\zeta-\\gamma\\left(\\delta_{t}^{i, b}-\\bar{\\delta}_{t}^{i, b}\\right)\\right) d t\\right. \\\\\n& \\left.\\quad-\\int_{0}^{T} \\phi_{t}\\left(Q_{t}^{i}\\right)^{2} d t-A\\left(Q_{T}^{i}\\right)^{2}\\right]\n\\end{aligned}\n$$\n\nHere, penalty coefficients $\\phi:=\\left(\\phi_{t}\\right)_{t \\in[0, T]} \\in \\mathbb{H}^{2}, A \\in L^{2}\\left(\\Omega, \\mathcal{F}_{T}\\right)$ are non-negative and (uniformly) bounded by constants $\\bar{\\phi}, \\bar{A}>0$ respectively. The simplification is deduced by the martingale property of $S$ and It\u00f4's formula; see the [24] for the interpretation and the simplification step of (2). The goal is to find a Nash equilibrium in which all agents solve their maximization problems simultaneously in the following sense:\n\nDefinition 2.3. A strategy profile $\\left(\\hat{\\boldsymbol{\\delta}}^{j}\\right)_{j=1}^{N} \\in\\left(\\mathbb{H}^{2} \\times \\mathbb{H}^{2}\\right)^{N}$ is called a Nash equilibrium if, for all $1 \\leq i \\leq N$ and any admissible strategies $\\boldsymbol{\\delta}^{i} \\in \\mathbb{H}^{2} \\times \\mathbb{H}^{2}$, it holds that\n\n$$\nJ\\left(\\boldsymbol{\\delta}^{i} ; \\hat{\\boldsymbol{\\delta}}^{-i}\\right) \\leq J\\left(\\hat{\\boldsymbol{\\delta}}^{i} ; \\hat{\\boldsymbol{\\delta}}^{-i}\\right)\n$$\n\nThanks to the linear-quadratic structure, we utilize the convex-analytic method, introduced in [5], to characterize the Nash equilibrium as a system of FBSDEs.\n\nTheorem 2.4. A strategy profile $\\left(\\boldsymbol{\\delta}^{j}\\right)_{j=1}^{N} \\in\\left(\\mathbb{H}^{2} \\times \\mathbb{H}^{2}\\right)^{N}$ forms a Nash equilibrium if and only if it solves the following system of FBSDEs:\n\n$$\n\\left\\{\\begin{array}{l}\nd Q_{t}^{i}=-a_{t}\\left(\\zeta+\\gamma \\bar{\\delta}_{t}^{i, a}-\\gamma \\delta_{t}^{i, a}\\right) d t+b_{t}\\left(\\zeta+\\gamma \\bar{\\delta}_{t}^{i, b}-\\gamma \\delta_{t}^{i, b}\\right) d t \\\\\nd \\delta_{t}^{i, a}=d \\bar{\\delta}_{t}^{i, a} / 2+\\phi_{t} Q_{t}^{i} d t-d M_{t}^{i} \\\\\nd \\delta_{t}^{i, b}=d \\bar{\\delta}_{t}^{i, b} / 2-\\phi_{t} Q_{t}^{i} d t+d M_{t}^{i} \\\\\nQ_{0}^{i}=q_{0}^{i}, \\quad \\delta_{T}^{i, a}=\\zeta /(2 \\gamma)+\\bar{\\delta}_{T}^{i, a} / 2-A Q_{T}^{i}, \\quad \\delta_{T}^{i, b}=\\zeta /(2 \\gamma)+\\bar{\\delta}_{T}^{i, b} / 2+A Q_{T}^{i}\n\\end{array}\\right.\n$$\n\nwhere $M_{t}^{i} \\in \\mathbb{M}$, for all $i \\in\\{1, \\ldots, N\\}$.\nProof. Consider an agent $i$ with $i \\in\\{1, \\ldots, N\\}$. If the profile $\\left(\\boldsymbol{\\delta}^{j}\\right)_{1 \\leq j \\leq N}$ represents a Nash equilibrium, agent $i$ can be seen as solving a stochastic control problem with a fixed $\\boldsymbol{\\delta}^{-i}$. In comparison to the problem studied in the [24], the only necessary modifications are replacing the 'old' constant $\\zeta$ with the processes $\\zeta+\\gamma \\delta_{t}^{i, b}$ and $\\zeta+\\gamma \\delta_{t}^{i, a}$. However, these modifications do not alter the concave nature of the functional (2) with respect to the control $\\boldsymbol{\\delta}^{i}$. The proof in Theorem 2.6 in [24] demonstrates that the concavity relies solely on the linear impact of $\\boldsymbol{\\delta}^{i}$ on $Q^{i}$, and the non-negative property of $\\gamma$. Thanks to the concavity, the necessary and sufficient condition for the optimality of $\\boldsymbol{\\delta}^{i}$ can be characterized by the first-order condition: for any $\\boldsymbol{w} \\in \\mathbb{H}^{2} \\times \\mathbb{H}^{2}$ that is also uniformly bounded, the G\u00e2teaux derivative of the functional (2) with respect to the direction $\\boldsymbol{w}$ should vanish, i.e.,\n\n$$\n\\begin{aligned}\n0=\\left\\langle\\nabla J\\left(\\boldsymbol{\\delta}^{i} ; \\boldsymbol{\\delta}^{-i}\\right), \\boldsymbol{w}\\right\\rangle=\\mathbb{E}[ & \\int_{0}^{T} a_{t} w_{t}^{a}\\left(\\zeta+\\gamma \\bar{\\delta}_{t}^{i, a}-2 \\gamma \\delta_{t}^{i, a}-2 \\gamma A Q_{T}^{i}-2 \\gamma \\int_{t}^{T} \\phi_{s} Q_{s}^{i} d s\\right) d t \\\\\n& \\left.+\\int_{0}^{T} b_{t} w_{t}^{b}\\left(\\zeta+\\gamma \\bar{\\delta}_{t}^{i, b}-2 \\gamma \\delta_{t}^{i, b}+2 \\gamma A Q_{T}^{i}+2 \\gamma \\int_{t}^{T} \\phi_{s} Q_{s}^{i} d s\\right) d t\\right]\n\\end{aligned}\n$$\n\nDue to the arbitrariness of $\\boldsymbol{w}$, the law of total expectation yields\n\n$$\n\\begin{aligned}\n& \\delta_{t}^{i, a}=\\frac{\\zeta}{2 \\gamma}+\\frac{1}{2} \\bar{\\delta}_{t}^{i, a}-\\mathbb{E}_{t}\\left[A Q_{T}^{i}\\right]-\\mathbb{E}_{t} \\int_{t}^{T} \\phi_{s} Q_{s}^{i} d s \\\\\n& \\delta_{t}^{i, b}=\\frac{\\zeta}{2 \\gamma}+\\frac{1}{2} \\bar{\\delta}_{t}^{i, b}+\\mathbb{E}_{t}\\left[A Q_{T}^{i}\\right]+\\mathbb{E}_{t} \\int_{t}^{T} \\phi_{s} Q_{s}^{i} d s\n\\end{aligned}\n$$\n\nthat holds $d \\mathbb{P} \\times d t$ almost everywhere. Since the above relation holds for all agents, we obtain the system (4).\n\nThe remainder of this section focuses on the well-posedness of the system (4). We first introduce a crucial lemma named as the ordering property, which provides notable simplifications to the system. Especially, based on Theorem 3.8 in [24], it has been established that the optimal strategy in the control problem is monotonic with respect to the initial inventory. In the equilibrium of the game setting, we will demonstrate that this property still holds true.\n\nLemma 2.5 (Ordering property). Every equilibrium possesses the ordering property. Specifically, for each pair $i, j \\in\\{1, \\ldots, N\\}$ with $q_{0}^{i} \\geq q_{0}^{j}$, the equilibrium strategies $\\boldsymbol{\\delta}^{i}$ and $\\boldsymbol{\\delta}^{j}$ satisfy that\n\n$$\n\\delta_{t}^{i, a} \\leq \\delta_{t}^{j, a} \\quad \\text { and } \\quad \\delta_{t}^{i, b} \\geq \\delta_{t}^{j, b}\n$$\n\n$\\mathbb{P}$-a.s. for all $t \\in[0, T]$.\n\nProof. Let $\\left(\\boldsymbol{\\delta}^{j}\\right)_{1 \\leq j \\leq N} \\in\\left(\\mathbb{R}^{2} \\times \\mathbb{R}^{2}\\right)^{N}$ be an equilibrium strategy profile. As a necessary condition, for any player $i$ the following holds $d \\mathbb{P} \\times d t$ a.e. that:\n\n$$\n\\begin{aligned}\n& \\delta_{t}^{i, a}=\\frac{\\zeta}{2 \\gamma}+\\frac{1}{2} \\bar{\\delta}_{t}^{i, a}-\\mathbb{E}_{t}\\left[A Q_{T}^{i}\\right]-\\mathbb{E}_{t} \\int_{t}^{T} \\phi_{s} Q_{s}^{i} d s \\\\\n& \\delta_{t}^{i, b}=\\frac{\\zeta}{2 \\gamma}+\\frac{1}{2} \\bar{\\delta}_{t}^{i, b}+\\mathbb{E}_{t}\\left[A Q_{T}^{i}\\right]+\\mathbb{E}_{t} \\int_{t}^{T} \\phi_{s} Q_{s}^{i} d s\n\\end{aligned}\n$$\n\nConsider another player $j$ and the same procedure yields $d \\mathbb{P} \\times d t$ a.e. that:\n\n$$\n\\begin{aligned}\n\\delta_{t}^{i, a}-\\delta_{t}^{j, a} & =\\frac{1}{2}\\left(\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}\\right)-\\mathbb{E}_{t}\\left[A\\left(Q_{T}^{i}-Q_{T}^{j}\\right)\\right]-\\mathbb{E}_{t} \\int_{t}^{T} \\phi_{s}\\left(Q_{s}^{i}-Q_{s}^{j}\\right) d s \\\\\n\\delta_{t}^{i, b}-\\delta_{t}^{j, b} & =\\frac{1}{2}\\left(\\bar{\\delta}_{t}^{i, b}-\\bar{\\delta}_{t}^{j, b}\\right)+\\mathbb{E}_{t}\\left[A\\left(Q_{T}^{i}-Q_{T}^{j}\\right)\\right]+\\mathbb{E}_{t} \\int_{t}^{T} \\phi_{s}\\left(Q_{s}^{i}-Q_{s}^{j}\\right) d s \\\\\n\\delta_{t}^{i, a}-\\delta_{t}^{j, a}-\\frac{1}{2}\\left(\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}\\right) & =(-1)\\left[\\delta_{t}^{i, b}-\\delta_{t}^{j, b}-\\frac{1}{2}\\left(\\bar{\\delta}_{t}^{i, b}-\\bar{\\delta}_{t}^{j, b}\\right)\\right]\n\\end{aligned}\n$$\n\nDue to the equilibrium characterization, the profile $\\left(\\boldsymbol{\\delta}^{i}\\right)_{1 \\leq i \\leq N}$ solves the system (4). By taking the difference of equations for players $i$ and $j$, one can obtain the FBSDE\n\n$$\n\\left\\{\\begin{array}{l}\nd\\left(Q_{t}^{i}-Q_{t}^{j}\\right)=-\\gamma a_{t}\\left(\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}-\\left(\\delta_{t}^{i, a}-\\delta_{t}^{j, a}\\right)\\right) d t+\\gamma b_{t}\\left(\\bar{\\delta}_{t}^{i, b}-\\bar{\\delta}_{t}^{j, b}-\\left(\\delta_{t}^{i, b}-\\delta_{t}^{j, b}\\right)\\right) d t \\\\\nd\\left(\\delta_{t}^{i, a}-\\delta_{t}^{j, a}\\right)=d\\left(\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}\\right) / 2+\\phi_{t}\\left(Q_{t}^{i}-Q_{t}^{j}\\right) d t-d\\left(M_{t}^{i}-M_{t}^{j}\\right) \\\\\nd\\left(\\delta_{t}^{i, b}-\\delta_{t}^{j, b}\\right)=d\\left(\\bar{\\delta}_{t}^{i, b}-\\bar{\\delta}_{t}^{j, b}\\right) / 2-\\phi_{t}\\left(Q_{t}^{i}-Q_{t}^{j}\\right) d t+d\\left(M_{t}^{i}-M_{t}^{j}\\right) \\\\\nQ_{0}^{i}-Q_{0}^{j}=q_{0}^{i}-q_{0}^{j}, \\quad \\delta_{T}^{i, a}-\\delta_{T}^{j, a}=\\left(\\bar{\\delta}_{T}^{i, a}-\\bar{\\delta}_{T}^{j, a}\\right) / 2-A\\left(Q_{T}^{i}-Q_{T}^{j}\\right) \\\\\n\\delta_{T}^{i, b}-\\delta_{T}^{j, b}=\\left(\\bar{\\delta}_{T}^{i, b}-\\bar{\\delta}_{T}^{j, b}\\right) / 2+A\\left(Q_{T}^{i}-Q_{T}^{j}\\right)\n\\end{array}\\right.\n$$\n\nDefine $\\mathcal{X}_{t}:=Q_{t}^{i}-Q_{t}^{j}, \\mathcal{Y}_{t}:=\\delta_{t}^{i, a}-\\delta_{t}^{j, a}-\\left(\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}\\right) / 2$ and $\\mathcal{M}_{t}:=M_{t}^{i}-M_{t}^{j}$ for any $t \\in[0, T]$. In view of (5), the above FBSDE can be rewritten as\n\n$$\n\\left\\{\\begin{array}{l}\nd \\mathcal{X}_{t}=-\\gamma a_{t}\\left(\\left(\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}\\right) / 2-\\mathcal{Y}_{t}\\right) d t+\\gamma b_{t}\\left(\\left(\\bar{\\delta}_{t}^{i, b}-\\bar{\\delta}_{t}^{j, b}\\right) / 2+\\mathcal{Y}_{t}\\right) d t \\\\\nd \\mathcal{Y}_{t}=\\phi_{t} \\mathcal{X}_{t} d t-d \\mathcal{M}_{t} \\\\\n\\mathcal{X}_{0}=q_{0}^{i}-q_{0}^{j}, \\quad \\mathcal{Y}_{T}=-A \\mathcal{X}_{T}\n\\end{array}\\right.\n$$\n\nWhen $\\mathcal{Y}_{t} \\neq 0$, note that\n\n$$\n\\begin{aligned}\n\\left|\\frac{\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}}{\\mathcal{Y}_{t}}\\right| & =\\left|\\frac{\\delta_{t}^{j, a} \\wedge \\min _{k \\neq i, j} \\delta_{t}^{k, a}-\\delta_{t}^{i, a} \\wedge \\min _{k \\neq i, j} \\delta_{t}^{k, a}}{\\delta_{t}^{i, a}-\\delta_{t}^{j, a}-\\left(\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}\\right) / 2}\\right| \\leq \\frac{\\left|\\delta_{t}^{j, a}-\\delta_{t}^{i, a}\\right|}{\\left|\\delta_{t}^{i, a}-\\delta_{t}^{j, a}\\right|}=1 \\\\\n\\left|\\frac{\\bar{\\delta}_{t}^{i, b}-\\bar{\\delta}_{t}^{j, b}}{\\mathcal{Y}_{t}}\\right| & =\\left|\\frac{\\delta_{t}^{j, b} \\wedge \\min _{k \\neq i, j} \\delta_{t}^{k, b}-\\delta_{t}^{i, b} \\wedge \\min _{k \\neq i, j} \\delta_{t}^{k, b}}{\\delta_{t}^{i, a}-\\delta_{t}^{j, a}-\\left(\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}\\right) / 2}\\right| \\\\\n& =\\left|\\frac{\\delta_{t}^{j, b} \\wedge \\min _{k \\neq i, j} \\delta_{t}^{k, b}-\\delta_{t}^{i, b} \\wedge \\min _{k \\neq i, j} \\delta_{t}^{k, b}}{\\delta_{t}^{i, b}-\\delta_{t}^{j, b}-\\left(\\bar{\\delta}_{t}^{i, b}-\\bar{\\delta}_{t}^{j, b}\\right) / 2}\\right| \\leq 1\n\\end{aligned}\n$$\n\nwhere we have applied the property that $\\delta_{t}^{i, a}-\\delta_{t}^{j, a}$ and $-\\left(\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}\\right)$ can not have different signs. While one can observe that $\\bar{\\delta}_{t}^{j, a}-\\bar{\\delta}_{t}^{i, a}=0$ if $\\mathcal{Y}_{t}=0$, by introducing the process $\\mathcal{U}$ as\n\n$$\n\\mathcal{U}_{t}=\\left\\{\\begin{array}{l}\n-\\gamma a_{t}\\left(\\frac{\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}}{2 \\mathcal{Y}_{t}}-1\\right)+\\gamma b_{t}\\left(\\frac{\\bar{\\delta}_{t}^{i, b}-\\bar{\\delta}_{t}^{j, b}}{2 \\mathcal{Y}_{t}}+1\\right), \\quad \\text { when } \\mathcal{Y}_{t} \\neq 0 \\\\\n0, \\quad \\text { when } \\mathcal{Y}_{t}=0\n\\end{array}\\right.\n$$\n\nequation (6) can then be further simplified as\n\n$$\n\\left\\{\\begin{array}{l}\nd \\mathcal{X}_{t}=\\mathcal{U}_{t} \\mathcal{Y}_{t} d t \\\\\nd \\mathcal{Y}_{t}=\\phi_{t} \\mathcal{X}_{t} d t-d \\mathcal{M}_{t} \\\\\n\\mathcal{X}_{0}=q_{0}^{i}-q_{0}^{j}, \\quad \\mathcal{Y}_{T}=-A \\mathcal{X}_{T}\n\\end{array}\\right.\n$$\n\nNotice that $\\mathcal{U}$ is bounded and also non-negative because\n\n$$\n\\frac{\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}}{2 \\mathcal{Y}_{t}}-1 \\leq-\\frac{1}{2} \\quad \\text { and } \\quad \\frac{\\bar{\\delta}_{t}^{i, b}-\\bar{\\delta}_{t}^{j, b}}{2 \\mathcal{Y}_{t}}+1 \\geq \\frac{1}{2}\n$$\n\nConsequently, the above FBSDE is studied in Lemma 3.6 from [24]. We know it has a unique solution and the sign of $\\mathcal{Y}$ differs from the initial condition of $\\mathcal{X}$. Given $\\mathcal{X}_{0}=q_{0}^{i}-q_{0}^{j} \\geq 0$, for $t \\in[0, T]$ one has $\\mathcal{X}_{t} \\geq 0$ and\n\n$$\n0 \\geq \\mathcal{Y}_{t}=\\delta_{t}^{i, a}-\\delta_{t}^{j, a}-\\left(\\bar{\\delta}_{t}^{i, a}-\\bar{\\delta}_{t}^{j, a}\\right) / 2\n$$\n\nwhich finally implies $\\delta_{t}^{i, a}-\\delta_{t}^{j, a} \\leq 0$ and simultaneously $\\delta_{t}^{i, b}-\\delta_{t}^{j, b} \\geq 0$.\nFollowing the ordering property, the next lemma looks carefully at a particular four-player game that serves as a fundamental building block for the interaction of the general $N$-player game.\n\nLemma 2.6 (Four-player framework). Assume $N=4$ and $q_{0}^{1} \\geq q_{0}^{2} \\geq q_{0}^{3} \\geq q_{0}^{4}$. Then, there exists a unique Nash equilibrium for this four-player game and the equilibrium strategy profile $\\left(\\boldsymbol{\\delta}^{i}\\right)_{1 \\leq i \\leq 4}$ exhibits the following ordering property:\n\n$$\n\\begin{aligned}\n& \\delta_{t}^{1, a} \\leq \\delta_{t}^{2, a} \\leq \\delta_{t}^{3, a} \\leq \\delta_{t}^{4, a} \\\\\n& \\delta_{t}^{4, b} \\leq \\delta_{t}^{3, b} \\leq \\delta_{t}^{2, b} \\leq \\delta_{t}^{1, b}\n\\end{aligned}\n$$\n\n$\\mathbb{P}$-a.s. for all $t \\in[0, T]$.\nProof. Given Lemma 2.5 and that $q_{0}^{1} \\geq q_{0}^{2} \\geq q_{0}^{3} \\geq q_{0}^{4}$, we know as a necessary condition that\n\n$$\n\\begin{aligned}\n& \\delta_{t}^{1, a} \\leq \\delta_{t}^{2, a} \\leq \\delta_{t}^{3, a} \\leq \\delta_{t}^{4, a} \\\\\n& \\delta_{t}^{4, b} \\leq \\delta_{t}^{3, b} \\leq \\delta_{t}^{2, b} \\leq \\delta_{t}^{1, b}\n\\end{aligned}\n$$\n\nHence, instead of (4), it is equivalent to look at the following system :\n\n$$\n\\left\\{\\begin{array}{l}\nd Q_{t}^{1}=-a_{t}\\left(\\zeta+\\gamma \\delta_{t}^{2, a}-\\gamma \\delta_{t}^{1, a}\\right) d t+b_{t}\\left(\\zeta+\\gamma \\delta_{t}^{4, b}-\\gamma \\delta_{t}^{1, b}\\right) d t \\\\\nd \\delta_{t}^{1, a}=d \\delta_{t}^{2, a} / 2+\\phi_{t} Q_{t}^{1} d t-d M_{t}^{1} \\\\\nd \\delta_{t}^{1, b}=d \\delta_{t}^{4, b} / 2-\\phi_{t} Q_{t}^{1} d t+d M_{t}^{1} \\\\\nQ_{0}^{1}=q_{0}^{1}, \\quad \\delta_{T}^{1, a}=\\zeta /(2 \\gamma)+\\delta_{T}^{2, a} / 2-A Q_{T}^{1}, \\quad \\delta_{T}^{1, b}=\\zeta /(2 \\gamma)+\\delta_{T}^{4, b} / 2+A Q_{T}^{1}\n\\end{array}\\right.\n$$\n\n$$\n\\begin{aligned}\n& \\left\\{\\begin{array}{l}\nd Q_{t}^{2}=-a_{t}\\left(\\zeta+\\gamma \\delta_{t}^{1, a}-\\gamma \\delta_{t}^{2, a}\\right) d t+b_{t}\\left(\\zeta+\\gamma \\delta_{t}^{4, b}-\\gamma \\delta_{t}^{2, b}\\right) d t \\\\\nd \\delta_{t}^{2, a}=d \\delta_{t}^{1, a} / 2+\\phi_{t} Q_{t}^{2} d t-d M_{t}^{2} \\\\\nd \\delta_{t}^{2, b}=d \\delta_{t}^{4, b} / 2-\\phi_{t} Q_{t}^{2} d t+d M_{t}^{2} \\\\\nQ_{0}^{2}=q_{0}^{2}, \\quad \\delta_{T}^{2, a}=\\zeta /(2 \\gamma)+\\delta_{T}^{1, a} / 2-A Q_{T}^{2}, \\quad \\delta_{T}^{2, b}=\\zeta /(2 \\gamma)+\\delta_{T}^{4, b} / 2+A Q_{T}^{2}\n\\end{array}\\right. \\\\\n& \\left\\{\\begin{array}{l}\nd Q_{t}^{3}=-a_{t}\\left(\\zeta+\\gamma \\delta_{t}^{1, a}-\\gamma \\delta_{t}^{3, a}\\right) d t+b_{t}\\left(\\zeta+\\gamma \\delta_{t}^{4, b}-\\gamma \\delta_{t}^{3, b}\\right) d t \\\\\nd \\delta_{t}^{3, a}=d \\delta_{t}^{1, a} / 2+\\phi_{t} Q_{t}^{3} d t-d M_{t}^{3} \\\\\nd \\delta_{t}^{3, b}=d \\delta_{t}^{4, b} / 2-\\phi_{t} Q_{t}^{3} d t+d M_{t}^{3} \\\\\nQ_{0}^{3}=q_{0}^{3}, \\quad \\delta_{T}^{3, a}=\\zeta /(2 \\gamma)+\\delta_{T}^{1, a} / 2-A Q_{T}^{3}, \\quad \\delta_{T}^{3, b}=\\zeta /(2 \\gamma)+\\delta_{T}^{4, b} / 2+A Q_{T}^{3}\n\\end{array}\\right. \\\\\n& \\left\\{\\begin{array}{l}\nd Q_{t}^{4}=-a_{t}\\left(\\zeta+\\gamma \\delta_{t}^{1, a}-\\gamma \\delta_{t}^{4, a}\\right) d t+b_{t}\\left(\\zeta+\\gamma \\delta_{t}^{3, b}-\\gamma \\delta_{t}^{4, b}\\right) d t \\\\\nd \\delta_{t}^{4, a}=d \\delta_{t}^{1, a} / 2+\\phi_{t} Q_{t}^{4} d t-d M_{t}^{4} \\\\\nd \\delta_{t}^{4, b}=d \\delta_{t}^{3, b} / 2-\\phi_{t} Q_{t}^{4} d t+d M_{t}^{4} \\\\\nQ_{0}^{4}=q_{0}^{4}, \\quad \\delta_{T}^{4, a}=\\zeta /(2 \\gamma)+\\delta_{T}^{1, a} / 2-A Q_{T}^{4}, \\quad \\delta_{T}^{4, b}=\\zeta /(2 \\gamma)+\\delta_{T}^{3, b} / 2+A Q_{T}^{4}\n\\end{array}\\right.\n\\end{aligned}\n$$\n\nOur goal is to construct a solution to the affine system (9) - (12) and then show that the ordering property holds. To solve the affine system, first let us take the difference of (10) and (11) to obtain\n\n$$\n\\left\\{\\begin{array}{l}\nd\\left(Q_{t}^{2}-Q_{t}^{3}\\right)=-\\gamma a_{t}\\left(\\delta_{t}^{3, a}-\\delta_{t}^{2, a}\\right) d t+\\gamma b_{t}\\left(\\delta_{t}^{3, b}-\\delta_{t}^{2, b}\\right) d t \\\\\nd\\left(\\delta_{t}^{2, a}-\\delta_{t}^{3, a}\\right)=\\phi_{t}\\left(Q_{t}^{2}-Q_{t}^{3}\\right) d t-d\\left(M_{t}^{2}-M_{t}^{3}\\right) \\\\\nd\\left(\\delta_{t}^{2, b}-\\delta_{t}^{3, b}\\right)=-\\phi_{t}\\left(Q_{t}^{2}-Q_{t}^{3}\\right) d t+d\\left(M_{t}^{2}-M_{t}^{3}\\right) \\\\\nQ_{0}^{2}-Q_{0}^{3}=q_{0}^{2}-q_{0}^{3}, \\quad \\delta_{T}^{2, a}-\\delta_{T}^{3, a}=-A\\left(Q_{T}^{2}-Q_{T}^{3}\\right), \\quad \\delta_{T}^{2, b}-\\delta_{T}^{3, b}=A\\left(Q_{T}^{2}-Q_{T}^{3}\\right)\n\\end{array}\\right.\n$$\n\nWhile it is clear that $\\delta_{t}^{2, a}-\\delta_{t}^{3, a}=\\delta_{t}^{3, b}-\\delta_{t}^{2, b}$, one can then observes that $\\left(Q^{2}-Q^{3}, \\delta^{2, a}-\\delta^{3, a}, M^{2}-\\right.$ $\\left.M^{3}\\right)$ is of the same type as (7). Based on Lemma 3.6 of [24], there exists a non-positive bounded process $\\left(P_{2,3}(t)\\right)_{0 \\leq t \\leq T} \\in \\mathbb{R}^{2}$ such that\n\n$$\n\\delta_{t}^{2, a}-\\delta_{t}^{3, a}=P_{2,3}(t) \\cdot\\left(Q_{t}^{2}-Q_{t}^{3}\\right) \\quad \\text { and } \\quad Q_{t}^{2}-Q_{t}^{3}=\\left(q_{0}^{2}-q_{0}^{3}\\right) \\cdot e^{\\int_{0}^{t} \\gamma\\left(a_{u}+b_{u}\\right) P_{2,3}(u) d u}\n$$\n\nIn the same fashion, one can also take the difference of (9) and (10) to have\n\n$$\n\\left\\{\\begin{aligned}\nd\\left(Q_{t}^{1}-Q_{t}^{2}\\right) & =-2 \\gamma a_{t}\\left(\\delta_{t}^{2, a}-\\delta_{t}^{1, a}\\right) d t+\\gamma b_{t}\\left(\\delta_{t}^{2, b}-\\delta_{t}^{1, b}\\right) d t \\\\\n(3 / 2) d\\left(\\delta_{t}^{1, a}-\\delta_{t}^{2, a}\\right) & =\\phi_{t}\\left(Q_{t}^{1}-Q_{t}^{2}\\right) d t-d\\left(M_{t}^{1}-M_{t}^{2}\\right) \\\\\nd\\left(\\delta_{t}^{1, b}-\\delta_{t}^{2, b}\\right) & =-\\phi_{t}\\left(Q_{t}^{1}-Q_{t}^{2}\\right) d t+d\\left(M_{t}^{1}-M_{t}^{2}\\right) \\\\\nQ_{0}^{1}-Q_{0}^{2}=q_{0}^{1}-q_{0}^{2}, \\quad(3 / 2)\\left(\\delta_{T}^{1, a}-\\delta_{T}^{2, a}\\right) & =-A\\left(Q_{T}^{1}-Q_{T}^{2}\\right), \\quad \\delta_{T}^{1, b}-\\delta_{T}^{2, b}=A\\left(Q_{T}^{1}-Q_{T}^{2}\\right)\n\\end{aligned}\\right.\n$$\n\nSetting $(3 / 2)\\left(\\delta_{t}^{1, a}-\\delta_{t}^{2, a}\\right)=\\delta_{t}^{2, b}-\\delta_{t}^{1, b}$, it turns out that $\\left(Q^{1}-Q^{2}, \\delta^{1, a}-\\delta^{2, a}\\right)$ accepts the representation:\n\n$$\n\\delta_{t}^{1, a}-\\delta_{t}^{2, a}=P_{1,2}(t) \\cdot\\left(Q_{t}^{1}-Q_{t}^{2}\\right) \\quad \\text { and } \\quad Q_{t}^{1}-Q_{t}^{2}=\\left(q_{0}^{1}-q_{0}^{2}\\right) \\cdot e^{\\int_{0}^{t} \\gamma\\left(2 a_{u}+3 b_{u} / 2\\right) P_{1,2}(u) d u}\n$$\n\nfor a non-positive bounded process $\\left(P_{1,2}(t)\\right)_{0 \\leq t \\leq T} \\in \\mathbb{H}^{2}$. Symmetrically, the difference of (11) and (12) yields\n\n$$\n\\left\\{\\begin{array}{c}\nd\\left(Q_{t}^{3}-Q_{t}^{4}\\right)=-\\gamma a_{t}\\left(\\delta_{t}^{4, a}-\\delta_{t}^{3, a}\\right) d t+2 \\gamma b_{t}\\left(\\delta_{t}^{4, b}-\\delta_{t}^{3, b}\\right) d t \\\\\nd\\left(\\delta_{t}^{3, a}-\\delta_{t}^{4, a}\\right)=\\phi_{t}\\left(Q_{t}^{3}-Q_{t}^{4}\\right) d t-d\\left(M_{t}^{3}-M_{t}^{4}\\right) \\\\\n(3 / 2) d\\left(\\delta_{t}^{3, b}-\\delta_{t}^{4, b}\\right)=-\\phi_{t}\\left(Q_{t}^{3}-Q_{t}^{4}\\right) d t+d\\left(M_{t}^{3}-M_{t}^{4}\\right) \\\\\nQ_{0}^{3}-Q_{0}^{4}=q_{0}^{3}-q_{0}^{4}, \\quad \\delta_{T}^{3, a}-\\delta_{T}^{4, a}=-A\\left(Q_{T}^{3}-Q_{T}^{4}\\right), \\quad(3 / 2)\\left(\\delta_{T}^{3, b}-\\delta_{T}^{4, b}\\right)=A\\left(Q_{T}^{3}-Q_{T}^{4}\\right)\n\\end{array}\\right.\n$$\n\nSetting $(3 / 2)\\left(\\delta_{t}^{3, b}-\\delta_{t}^{4, b}\\right)=\\delta_{t}^{4, a}-\\delta_{t}^{3, a}$, we can represent $\\left(Q_{t}^{3}-Q_{t}^{4}, \\delta_{t}^{3, a}-\\delta_{t}^{4, a}\\right)$ by:\n\n$$\n\\delta_{t}^{3, a}-\\delta_{t}^{4, a}=P_{3,4}(t) \\cdot\\left(Q_{t}^{3}-Q_{t}^{4}\\right) \\quad \\text { and } \\quad Q_{t}^{3}-Q_{t}^{4}=\\left(q_{0}^{3}-q_{0}^{4}\\right) \\cdot e^{\\int_{0}^{t} \\gamma\\left(a_{u}+4 b_{u} / 3\\right) P_{3,4}(u) d u}\n$$\n\nfor a non-positive bounded process $\\left(P_{3,4}(t)\\right)_{0 \\leq t \\leq T} \\in \\mathbb{H}^{2}$. Finally, since we have computed $\\delta^{j, a}-$ $\\delta^{j+1, a}$ (and hence $\\left.\\delta^{j, b}-\\delta^{j+1, b}\\right)$ for $j \\in\\{1,2,3\\}$, the right hand side of $d Q_{t}^{1}$ are known and $Q^{1}$ can be computed. Consequently, the equation (9) is reduced to a simple BSDE\n\n$$\n\\left\\{\\begin{array}{l}\n\\frac{1}{2} d \\delta_{t}^{1, a}=\\frac{1}{2} d\\left(\\delta_{t}^{2, a}-\\delta_{t}^{1, a}\\right)+\\phi_{t} Q_{t}^{1} d t-d M_{t}^{1} \\\\\n\\frac{1}{2} d \\delta_{t}^{1, b}=\\frac{1}{2} d\\left(\\delta_{t}^{4, b}-\\delta_{t}^{1, b}\\right)-\\phi_{t} Q_{t}^{1} d t+d M_{t}^{1} \\\\\nQ_{0}^{1}=q_{0}^{1}, \\quad \\frac{1}{2} \\delta_{T}^{1, a}=\\frac{\\zeta}{2 \\gamma}+\\frac{1}{2}\\left(\\delta_{T}^{2, a}-\\delta_{T}^{1, a}\\right)-A Q_{T}^{1}, \\quad \\frac{1}{2} \\delta_{T}^{1, b}=\\frac{\\zeta}{2 \\gamma}+\\frac{1}{2}\\left(\\delta_{T}^{4, b}-\\delta_{T}^{1, b}\\right)+A Q_{T}^{1}\n\\end{array}\\right.\n$$\n\nIts solution is given by\n\n$$\n\\begin{aligned}\n& \\frac{1}{2} \\delta_{t}^{1, a}=\\frac{\\zeta}{2 \\gamma}+\\frac{1}{2}\\left(\\delta_{t}^{2, a}-\\delta_{t}^{1, a}\\right)+\\int_{0}^{t} \\phi_{u} Q_{u}^{1} d u-\\mathbb{E}_{t}\\left[\\int_{0}^{T} \\phi_{u} Q_{u}^{1} d u+A Q_{T}^{1}\\right] \\\\\n& \\frac{1}{2} \\delta_{t}^{1, b}=\\frac{\\zeta}{2 \\gamma}+\\frac{1}{2}\\left(\\delta_{t}^{4, b}-\\delta_{t}^{1, b}\\right)-\\int_{0}^{t} \\phi_{u} Q_{u}^{1} d u+\\mathbb{E}_{t}\\left[\\int_{0}^{T} \\phi_{u} Q_{u}^{1} d u+A Q_{T}^{1}\\right]\n\\end{aligned}\n$$\n\nwhere all terms on the right hand side are known, and the expression inside of the conditional expectation is almost surely bounded. In conclusion, we have computed $\\left(\\boldsymbol{\\delta}^{1}, \\boldsymbol{\\delta}^{1}-\\boldsymbol{\\delta}^{2}, \\boldsymbol{\\delta}^{2}-\\boldsymbol{\\delta}^{3}, \\boldsymbol{\\delta}^{3}-\\right.$ $\\boldsymbol{\\delta}^{4}$ ), which is an invertible linear transformation of $\\left(\\boldsymbol{\\delta}^{1}, \\boldsymbol{\\delta}^{2}, \\boldsymbol{\\delta}^{3}, \\boldsymbol{\\delta}^{4}\\right)$. This guarantees the existence of solutions. Moreover, the uniqueness of the solution can be established by noting that each of the three FBSDEs associated with $\\boldsymbol{\\delta}^{1}-\\boldsymbol{\\delta}^{2}, \\boldsymbol{\\delta}^{2}-\\boldsymbol{\\delta}^{3}$, and $\\boldsymbol{\\delta}^{3}-\\boldsymbol{\\delta}^{4}$ has a unique solution in $\\mathbb{S}^{2} \\times \\mathbb{S}^{2} \\times \\mathbb{M}$, ensuring the uniqueness of $\\boldsymbol{\\delta}^{1}$ finally.\n\nFinally, in order to derive the ordering property, we would like to summarize the above discussion as follows:\n\n$$\n\\begin{aligned}\n\\delta_{t}^{1, a}-\\delta_{t}^{2, a}=P_{1,2}(t) \\cdot\\left(q_{0}^{1}-q_{0}^{2}\\right) \\cdot e^{\\int_{0}^{t} \\gamma\\left(2 a_{u}+3 b_{u} / 2\\right) P_{1,2}(u) d u} \\quad \\text { and } \\quad \\delta_{t}^{2, b}-\\delta_{t}^{1, b} & =\\frac{3}{2}\\left(\\delta_{t}^{1, a}-\\delta_{t}^{2, a}\\right) \\\\\n\\delta_{t}^{2, a}-\\delta_{t}^{3, a}=P_{2,3}(t) \\cdot\\left(q_{0}^{2}-q_{0}^{3}\\right) \\cdot e^{\\int_{0}^{t} \\gamma\\left(a_{u}+b_{u}\\right) P_{2,3}(u) d u} \\quad \\text { and } \\quad \\delta_{t}^{2, a}-\\delta_{t}^{3, a} & =\\delta_{t}^{3, b}-\\delta_{t}^{2, b} \\\\\n\\delta_{t}^{3, a}-\\delta_{t}^{4, a}=P_{3,4}(t) \\cdot\\left(q_{0}^{3}-q_{0}^{4}\\right) \\cdot e^{\\int_{0}^{t} \\gamma\\left(a_{u}+4 b_{u} / 3\\right) P_{3,4}(u) d u} \\quad \\text { and } \\quad \\delta_{t}^{4, a}-\\delta_{t}^{3, a} & =\\frac{3}{2}\\left(\\delta_{t}^{3, b}-\\delta_{t}^{4, b}\\right)\n\\end{aligned}\n$$\n\nfor all $t \\in[0, T]$. The ordering follows from the non-positiveness of $P_{j, j+1}(t)$ and non-negativeness of $\\left(q_{0}^{j}-q_{0}^{j+1}\\right)$ for $j \\in\\{1,2,3\\}$.\n\nWe are now prepared to present the main result of the $N$-player game. Firstly, we solve the four-player game involving the 'top' two players and the 'bottom' two players. Once the\n\nequilibrium of this four-player game is determined, it becomes evident that the remaining players are simply solving an equivalent stochastic control problem.\n\nTheorem 2.7. Let the index of a player be the rank of her initial inventory level, i.e.,\n\n$$\nq_{0}^{1} \\geq q_{0}^{2} \\geq q_{0}^{3} \\geq \\cdots \\geq q_{0}^{N-1} \\geq q_{0}^{N}\n$$\n\nThen, there exists a unique Nash equilibrium. Moreover, the equilibrium strategy profile $\\left(\\boldsymbol{\\delta}^{j}\\right)_{1 \\leq j \\leq N}$ satisfies\n\n$$\n\\begin{aligned}\n& \\delta_{t}^{1, a} \\leq \\delta_{t}^{2, a} \\leq \\cdots \\leq \\delta_{t}^{N-1, a} \\leq \\delta_{t}^{N, a} \\\\\n& \\delta_{t}^{1, b} \\geq \\delta_{t}^{2, b} \\geq \\cdots \\geq \\delta_{t}^{N-1, b} \\geq \\delta_{t}^{N, b}\n\\end{aligned}\n$$\n\n$\\mathbb{P}$-a.s. for all $t \\in[0, T]$.\nProof. Based on the ordering property, through a finite number of iterations of the method in the proof of Lemma 2.6, one can construct a solution $\\left(Q^{i}, \\boldsymbol{\\delta}^{i}, M^{i}\\right)_{i \\in\\{1, \\ldots, N\\}}$ to the FBSDE system (4). Consequently, strategy profile $\\left(\\boldsymbol{\\delta}^{i}\\right)_{i \\in\\{1, \\ldots, N\\}}$ forms a Nash equilibrium with the prescribed ordering. We then turn to the uniqueness. The ordering property again infers that the best ask and bid prices are determined by the four-dimensional FBSDE in Lemma 2.6, which admits a unique solution. Denoting by $\\delta^{1, a}$ (resp. $\\delta^{N, b}$ ) the obtained best ask (resp. bid) quoting strategy, the agent $i$, with $i \\in\\{3, \\ldots, N-2\\}$, solves the FBSDE\n\n$$\n\\left\\{\\begin{array}{l}\nd Q_{t}^{i}=-a_{t}\\left(\\zeta+\\gamma \\delta_{t}^{1, a}-\\gamma \\delta_{t}^{i, a}\\right) d t+b_{t}\\left(\\zeta+\\gamma \\delta_{t}^{N, b}-\\gamma \\delta_{t}^{i, b}\\right) d t \\\\\nd \\delta_{t}^{i, a}=d \\delta_{t}^{1, a} / 2+\\phi_{t} Q_{t}^{i} d t-d M_{t}^{i} \\\\\nd \\delta_{t}^{i, b}=d \\delta_{t}^{N, b} / 2-\\phi_{t} Q_{t}^{i} d t+d M_{t}^{i} \\\\\nQ_{0}^{i}=q_{0}^{i}, \\quad \\delta_{T}^{i, a}=\\zeta /(2 \\gamma)+\\delta_{T}^{1, a} / 2-A Q_{T}^{i}, \\quad \\delta_{T}^{i, b}=\\zeta /(2 \\gamma)+\\delta_{T}^{N, b} / 2+A Q_{T}^{i}\n\\end{array}\\right.\n$$\n\nIt suffices to derive its uniqueness. Let $\\left(Q^{i}, \\boldsymbol{\\delta}^{i}, M^{i}\\right),\\left(\\tilde{Q}^{i}, \\tilde{\\boldsymbol{\\delta}}^{i}, \\tilde{M}^{i}\\right)$ be two solutions and define $(\\Delta Q, \\Delta \\boldsymbol{\\delta}, \\Delta M):=\\left(\\tilde{Q}^{i}-Q^{i}, \\tilde{\\boldsymbol{\\delta}}^{i}-\\boldsymbol{\\delta}^{i}, \\tilde{M}^{i}-M^{i}\\right)$. It follows $(\\Delta Q, \\Delta \\boldsymbol{\\delta}, \\Delta M)$ solves\n\n$$\n\\left\\{\\begin{array}{l}\nd \\Delta Q_{t}=\\gamma a_{t} \\Delta \\delta_{t}^{a} d t-\\gamma b_{t} \\Delta \\delta_{t}^{b} d t \\\\\nd \\Delta \\delta_{t}^{a}=\\phi_{t} \\Delta Q_{t} d t-d \\Delta M_{t} \\\\\nd \\Delta \\delta_{t}^{b}=-\\phi_{t} \\Delta Q_{t} d t+d \\Delta M_{t} \\\\\n\\Delta Q_{0}=0, \\quad \\Delta \\delta_{T}^{a}=-A \\Delta Q_{T}, \\quad \\Delta \\delta_{T}^{b}=A \\Delta Q_{T}\n\\end{array}\\right.\n$$\n\nWhile it is straightforward to see $\\Delta \\delta^{a}=-\\Delta \\delta^{b}$, the FBSDE (13) reduces to\n\n$$\n\\left\\{\\begin{array}{l}\nd \\Delta Q_{t}=\\gamma\\left(a_{t}+b_{t}\\right) \\Delta \\delta_{t}^{a} d t \\\\\nd \\Delta \\delta_{t}^{a}=\\phi_{t} \\Delta Q_{t} d t-d \\Delta M_{t} \\\\\n\\Delta Q_{0}=0, \\quad \\Delta \\delta_{T}^{a}=-A \\Delta Q_{T}\n\\end{array}\\right.\n$$\n\nthe well-posedness of which is derived in [24]. The proof is completed by noting that the unique solution to this system is $(0,0,0)$.\n\nRemark 2.8. (1) The equilibrium profile bears a similar economic interpretation to the optimal strategy in the control problem: players with higher inventory aim to sell more, consequently offering more favorable ask prices but less attractive bid prices. Some other economic interpretations are left to the general case later.\n\n(2) For illustration, here we let $b \\equiv 0$ and define multi-dimensional processes $\\boldsymbol{Q}:=\\left(Q^{1}, Q^{2}, \\ldots\\right)$ and $\\boldsymbol{Y}:=\\left(\\delta^{1, a}, \\delta^{2, a}, \\ldots\\right)$. Then, it turns out later that the forward equations of both (4) and (9)-(12) can be written neatly by\n\n$$\nd \\boldsymbol{Q}_{t}=\\boldsymbol{H}_{t} \\boldsymbol{Y}_{t} d t\n$$\n\nwhere $\\boldsymbol{H}_{t}$ is a random $M$-matrix for all $t$. We will later introduce and examine this type of matrices in a more general context, along with investigating the associated FBSDE system.", "tables": {}, "images": {}}, {"section_id": 4, "text": "# 3. General Market Making Game: Lipschitz Formulations \n\nSince the Assumption 2.1 is proposed based on the linear intensity function, we extend such assumption to the case of general intensity functions. Moreover, agents are allows to be heterogeneous in their penalty parameters. The first goal of this section is to characterize the equilibrium of the stochastic game as the solution of Lipschitz FBSDEs. We adopt the following notations, definitions, and associated results from [20] regarding general intensity functions, with a slight modification.\n\nAssumption 3.1. A function $\\Lambda: \\mathbb{R} \\rightarrow \\mathbb{R}_{+}$belongs to the class of intensity functions $\\boldsymbol{\\Lambda}$ if:\n\n1. $\\Lambda$ is twice continuously differentiable;\n2. $\\Lambda$ is strictly decreasing and hence $\\Lambda^{\\prime}(x)<0$ for any $x \\in \\mathbb{R}$;\n3. $\\lim _{x \\rightarrow \\infty} \\Lambda(x)=0$ and $-\\infty<\\inf _{x \\in \\mathbb{R}} \\frac{\\Lambda(x) \\Lambda^{\\prime \\prime}(x)}{\\left(\\Lambda^{\\prime}(x)\\right)^{2}} \\leq \\sup _{x \\in \\mathbb{R}} \\frac{\\Lambda(x) \\Lambda^{\\prime \\prime}(x)}{\\left(\\Lambda^{\\prime}(x)\\right)^{2}} \\leq 1$.\n\nLemma 3.2 ([20]). For any $\\Lambda \\in \\Lambda$, define the function $\\mathcal{W}: \\mathbb{R} \\rightarrow \\mathbb{R}$ as $\\mathcal{W}(p)=\\sup _{\\delta \\in \\mathbb{R}} \\Lambda(\\delta)(\\delta-$ p). Then, the following holds:\n\n1. $\\mathcal{W}$ is a decreasing function of class $C^{2}$;\n2. The supremum in the definition of $\\mathcal{W}$ is attained at a unique $\\delta^{*}(p)$ characterized by\n\n$$\n\\delta^{*}(p)=\\Lambda^{-1}\\left(-\\mathcal{W}^{\\prime}(p)\\right)\n$$\n\nwhere $\\Lambda^{-1}$ denotes the inverse function of $\\Lambda$;\n3. The function $p \\mapsto \\delta^{*}(p)$ belongs to $C^{1}$ and is increasing. Its derivative reads\n\n$$\n\\left(\\delta^{*}\\right)^{\\prime}(p)=\\left[2-\\frac{\\Lambda\\left(\\delta^{*}(p)\\right) \\Lambda^{\\prime \\prime}\\left(\\delta^{*}(p)\\right)}{\\Lambda^{\\prime}\\left(\\delta^{*}(p)\\right)^{2}}\\right]^{-1}>0\n$$\n\nRemark 3.3. The definition remains the same as in [20], with the only modification being the replacement of the original inequality $\\sup _{x \\in \\mathbb{R}} \\frac{\\Lambda(x) \\Lambda^{\\prime \\prime}(x)}{\\left(\\Lambda^{\\prime}(x)\\right)^{2}}<2$ with $\\sup _{x \\in \\mathbb{R}} \\frac{\\Lambda(x) \\Lambda^{\\prime \\prime}(x)}{\\left(\\Lambda^{\\prime}(x)\\right)^{2}} \\leq 1$, and the addition of $-\\infty<\\inf _{x \\in \\mathbb{R}} \\frac{\\Lambda(x) \\Lambda^{\\prime \\prime}(x)}{\\left(\\Lambda^{\\prime}(x)\\right)^{2}}$. This adjustment is made for technical reasons. Note that $\\Lambda(x)=u^{-x}$ is eligible for any $u>1$.\n\nSimilar to the role played by the linear intensity function in Assumption 2.1, we now introduce the nonlinear context characterized by the usage of general intensity functions.\n\nAssumption 3.4 (General intensity). The quantity of order flow executed by agent $i$ depends on the difference between her offered price and the best price offered by the others in a nonlinear way. Specifically, if we write $v_{t}^{i, a}$ and $v_{t}^{i, b}$ as the (passive) selling and buying rates of the agent at time $t$, we can express this nonlinear dependence as\n\n$$\nv_{t}^{i, a}=a_{t} \\Lambda\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right) \\quad \\text { and } \\quad v_{t}^{i, b}=b_{t} \\Lambda\\left(\\delta_{t}^{i, b}-\\bar{\\delta}_{t}^{i, b}\\right)\n$$\n\nfor some $\\Lambda \\in \\Lambda$. We have also assumed the bid-ask symmetry for notational convenience.\nGiven any admissible strategy $\\boldsymbol{\\delta}^{i} \\in \\mathbb{A} \\times \\mathbb{A}$ with\n\n$$\n\\mathbb{A}:=\\left\\{\\delta \\in \\mathbb{H}^{2}:\\left|\\delta_{t}\\right| \\leq \\xi \\text { for all } t \\in[0, T]\\right\\} \\text { for some constant } \\xi>0\n$$\n\nthe inventory and cash of the agent $i$ are given by\n\n$$\n\\begin{gathered}\nX_{t}^{i}=\\int_{0}^{t}\\left(S_{u}+\\delta_{u}^{i, a}\\right) a_{u} \\Lambda\\left(\\delta_{u}^{i, a}-\\bar{\\delta}_{u}^{i, a}\\right) d u-\\int_{0}^{t}\\left(S_{u}-\\delta_{u}^{i, b}\\right) b_{u} \\Lambda\\left(\\delta_{u}^{i, b}-\\bar{\\delta}_{u}^{i, b}\\right) d u \\\\\nQ_{t}^{i}=q_{0}^{i}-\\int_{0}^{t} a_{u} \\Lambda\\left(\\delta_{u}^{i, a}-\\bar{\\delta}_{u}^{i, a}\\right) d u+\\int_{0}^{t} b_{u} \\Lambda\\left(\\delta_{u}^{i, b}-\\bar{\\delta}_{u}^{i, b}\\right) d u\n\\end{gathered}\n$$\n\nwith $q_{0}^{i} \\in \\mathbb{R}$ representing the initial inventory. The player $i$ aims at maximizing the objective functional\n\n$$\n\\begin{aligned}\n& J^{i}\\left(\\boldsymbol{\\delta}^{i} ; \\boldsymbol{\\delta}^{-i}\\right):=\\mathbb{E}\\left[X_{T}^{i}+S_{T} Q_{T}^{i}-\\int_{0}^{T} \\phi_{t}^{i}\\left(Q_{t}^{i}\\right)^{2} d t-A^{i}\\left(Q_{T}^{i}\\right)^{2}\\right] \\\\\n& =\\mathbb{E}\\left[\\int_{0}^{T} \\delta_{t}^{i, a} a_{t} \\Lambda\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right) d t+\\int_{0}^{T} \\delta_{t}^{i, b} b_{t} \\Lambda\\left(\\delta_{t}^{i, b}-\\bar{\\delta}_{t}^{i, b}\\right) d t-\\int_{0}^{T} \\phi_{t}^{i}\\left(Q_{t}^{i}\\right)^{2} d t-A^{i}\\left(Q_{T}^{i}\\right)^{2}\\right]\n\\end{aligned}\n$$\n\nHere, for all $i \\in\\{1, \\ldots, N\\}$, penalties $\\phi^{i}:=\\left(\\phi_{t}^{i}\\right)_{t \\in[0, T]} \\in \\mathbb{H}^{2}$ and $A^{i} \\in L^{2}\\left(\\Omega, \\mathcal{F}_{T}\\right)$ are nonnegative, satisfying $\\phi_{t}^{i} \\leq \\bar{\\phi}$ and $A^{i} \\leq \\bar{A}$ for some constants $\\bar{\\phi}, \\bar{A}>0$. The goal is to find a Nash equilibrium in the same sense as (3).\n\nDefinition 3.5. An admissible strategy profile $\\left(\\tilde{\\boldsymbol{\\delta}}^{j}\\right)_{1 \\leq j \\leq N} \\in(\\mathbb{A} \\times \\mathbb{A})^{N}$ is called a Nash equilibrium if, for all $1 \\leq i \\leq N$ and any admissible strategies $\\boldsymbol{\\delta}^{i} \\in \\mathbb{A} \\times \\mathbb{A}$, it holds that\n\n$$\nJ^{i}\\left(\\boldsymbol{\\delta}^{i} ; \\tilde{\\boldsymbol{\\delta}}^{-i}\\right) \\leq J^{i}\\left(\\dot{\\tilde{\\boldsymbol{\\delta}}}^{i} ; \\tilde{\\boldsymbol{\\delta}}^{-i}\\right)\n$$\n\nRemark 3.6. The constant $\\xi$ in the definition of $\\mathbb{A}$ serves as a regularization parameter, allowing us to formulate some Lipschitz mappings. In the homogeneous case, we will explore how this constant can be eliminated.\n\nIn view of the Pontryagin stochastic maximum principle, the Hamiltonian of agent $i$ reads\n\n$$\n\\begin{aligned}\nH^{i}\\left(t, q^{i}, y^{i}, \\boldsymbol{\\delta}^{i} ; \\boldsymbol{\\delta}^{-i}\\right)=\\left[b_{t} \\Lambda\\left(\\delta^{i, b}\\right.\\right. & \\left.-\\bar{\\delta}^{i, b}\\right)-a_{t} \\Lambda\\left(\\delta^{i, a}-\\bar{\\delta}^{i, a}\\right)\\right] y^{i} \\\\\n& +b_{t} \\delta^{i, b} \\Lambda\\left(\\delta^{i, b}-\\bar{\\delta}^{i, b}\\right)+a_{t} \\delta^{i, a} \\Lambda\\left(\\delta^{i, a}-\\bar{\\delta}^{i, a}\\right)-\\phi_{t}^{i}\\left(q^{i}\\right)^{2}\n\\end{aligned}\n$$\n\nWhile $H^{i}$ exhibits concavity in the state variable $Q^{i}$, its concavity with respect to the control $\\boldsymbol{\\delta}^{i}$ is not assured. This lack of concavity violates the typical stochastic maximum principle, outlined in works such as [9] and [10]. However, due to the separation between the state variable and control, we can still apply the stochastic maximum principle.\n\nDefinition 3.7. Given an admissible strategy profile $\\left(\\boldsymbol{\\beta}^{i}\\right)_{i \\in\\{1, \\ldots, N\\}} \\in(\\mathbb{A} \\times \\mathbb{A})^{N}$ and the corresponding controlled inventories $\\left(Q^{1}, \\ldots, Q^{N}\\right)$, a set of $N$ pairs $\\left(Y^{i}, M^{i}\\right)=\\left(Y_{t}^{i}, M_{t}^{i}\\right)_{t \\in[0, T]}$ of processes in $\\mathbb{S}^{2}$ and $\\mathbb{M}$, respectively, for $i=1, \\ldots, N$, is said to be a set of adjoint processes associated with $\\left(\\boldsymbol{\\beta}^{i}\\right)_{i \\in\\{1, \\ldots, N\\}}$ if they satisfy the BSDEs\n\n$$\n\\left\\{\\begin{array}{l}\nd Y_{t}^{i}=2 \\phi_{t}^{i} Q_{t}^{i} d t+d M_{t}^{i} \\\\\nY_{T}^{i}=-2 A^{i} Q_{T}^{i}\n\\end{array}\\right.\n$$\n\nfor all $i \\in\\{1, \\ldots, N\\}$.\n\nProposition 3.8. Consider an admissible strategy profile $\\left(\\tilde{\\boldsymbol{\\delta}}^{i}\\right)_{i=1}^{N} \\in(\\mathbb{A} \\times \\mathbb{A})^{N}$. Let $\\left(Q^{i}\\right)_{i=1}^{N}$ denote the corresponding controlled inventories and $\\left(Y^{i}, M^{i}\\right)_{i=1}^{N}$ represent the adjoint processes. Then $\\left(\\tilde{\\boldsymbol{\\delta}}^{i}\\right)_{i=1}^{N}$ forms a Nash equilibrium if and only if the generalized min-max Isaacs condition holds along the optimal paths in the following sense:\n\n$$\nH^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\tilde{\\boldsymbol{\\delta}}_{t}^{i} ; \\tilde{\\boldsymbol{\\delta}}_{t}^{-i}\\right)=\\max _{\\boldsymbol{\\beta}^{i} \\in[-\\xi, \\xi]^{2}} H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\beta}^{i} ; \\tilde{\\boldsymbol{\\delta}}_{t}^{-i}\\right)\n$$\n\n$d t \\times d \\mathbb{P}$-a.s. for each $i \\in\\{1, \\ldots, N\\}$.\nPROOF. See the appendix.\nTo maximize the Hamiltonian simultaneously for all agents, it must hold for all $i$ that\n\n$$\n\\begin{aligned}\n& \\delta^{i, b}=\\left[\\bar{\\delta}^{i, b}+\\delta^{*}\\left(-y^{i}-\\bar{\\delta}^{i, b}\\right)\\right] \\vee(-\\xi) \\wedge \\xi \\\\\n& \\delta^{i, a}=\\left[\\bar{\\delta}^{i, a}+\\delta^{*}\\left(y^{i}-\\bar{\\delta}^{i, a}\\right)\\right] \\vee(-\\xi) \\wedge \\xi\n\\end{aligned}\n$$\n\nsee [24] for the derivation based on Lemma 3.2. We claim that, for any $\\boldsymbol{y}:=\\left(y^{1}, \\ldots, y^{N}\\right) \\in$ $\\mathbb{R}^{N}$, there exist $\\boldsymbol{\\delta}^{b}:=\\left(\\delta^{1, b}, \\ldots, \\delta^{N, b}\\right) \\in \\mathbb{R}^{N}$ and $\\boldsymbol{\\delta}^{a} \\in \\mathbb{R}^{N}$ such that (18) holds. Indeed, the compactness brought by the truncation $\\xi$ enables us to find such $\\boldsymbol{\\delta}^{a}$ and $\\boldsymbol{\\delta}^{b}$ through the Schauder fixed-point theorem. Define functions $\\Psi^{a}, \\Psi^{b}: \\mathbb{R}^{N} \\times \\mathbb{R}^{N} \\rightarrow \\mathbb{R}^{N}$ as\n\n$$\n\\begin{aligned}\n& \\Psi^{i, b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)=\\delta^{i, b}-\\left[\\bar{\\delta}^{i, b}+\\delta^{*}\\left(-y^{i}-\\bar{\\delta}^{i, b}\\right)\\right] \\vee(-\\xi) \\wedge \\xi \\\\\n& \\Psi^{i, a}\\left(\\boldsymbol{\\delta}^{a}, \\boldsymbol{y}\\right)=\\delta^{i, a}-\\left[\\bar{\\delta}^{i, a}+\\delta^{*}\\left(y^{i}-\\bar{\\delta}^{i, a}\\right)\\right] \\vee(-\\xi) \\wedge \\xi\n\\end{aligned}\n$$\n\nfor all $i \\in\\{1, \\ldots, N\\}$. Here, the additional superscript $i$ represents the $i$-th entry of the vector. Consequently, the Issacs condition can be represented as\n\n$$\n\\Psi^{i, b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)=0 \\quad \\text { and } \\quad \\Psi^{i, a}\\left(\\boldsymbol{\\delta}^{a}, \\boldsymbol{y}\\right)=0\n$$\n\nWe intend to find Lipschitz functions $\\psi^{a}, \\psi^{b}: \\mathbb{R}^{N} \\rightarrow \\mathbb{R}^{N}$ such that\n\n$$\n\\Psi^{b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)=0 \\quad \\text { and } \\quad \\Psi^{a}\\left(\\psi^{a}(\\boldsymbol{y}), \\boldsymbol{y}\\right)=0\n$$\n\nFunctions $\\psi^{a}$ and $\\psi^{b}$ are known as implicit functions, and their existence, uniqueness, and regularity are the main focus of the (global) implicit function theorem. While the original theorem primarily dealt with the case when $\\Psi^{a}$ and $\\Psi^{b}$ are smooth, a local implicit function theorem was first introduced in [13] to handle locally Lipschitz non-smooth mappings. Subsequently, [19] investigated a global implicit function theorem for the same type of mappings, where the resulting implicit function was locally Lipschitz. Building upon these works, we propose a global implicit function theorem for non-smooth mappings with Lipschitz implicit functions.\n\nProposition 3.9. Assume that $F: \\mathbb{R}^{n} \\times \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$ is a locally Lipschitz mapping such that:\n\n1. For every $y \\in \\mathbb{R}^{m}$, the functional $\\varphi_{y}: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ given by the formula\n\n$$\n\\varphi_{y}(x):=\\frac{1}{2}|F(x, y)|^{2}\n$$\n\nis coercive, i.e., $\\lim _{|x| \\rightarrow \\infty} \\varphi_{y}(x)=\\infty$;\n2. The set $\\partial_{x} F(x, y)$ is of maximal rank for all $(x, y) \\in \\mathbb{R}^{n} \\times \\mathbb{R}^{m}$;\n3. Define the function $\\tilde{F}: \\mathbb{R}^{m+n} \\rightarrow \\mathbb{R}^{m+n}$ by\n\n$$\n\\tilde{F}(x, y)=(y, F(x, y))\n$$\n\nand let $\\tilde{S}$ denote the unit sphere in $\\mathbb{R}^{m+n}$. There exists a constant $v>0$ such that the distance between $\\partial \\tilde{F}(x, y) \\tilde{S}$ and 0 is at least $v$, for all $(x, y) \\in \\mathbb{R}^{n} \\times \\mathbb{R}^{m}$. Here, set $\\partial \\tilde{F}(x, y) \\tilde{S}$ is defined by\n\n$$\n\\partial \\tilde{F}(x, y) \\tilde{S}:=\\{U v: U \\in \\tilde{F}(x, y) \\text { and } v \\in \\tilde{S}\\}\n$$\n\nand the distance refers to $\\inf \\{|U v|: U \\in \\tilde{F}(x, y)$ and $v \\in \\tilde{S}\\}$.\nThen, there exists a unique Lipschitz function $f: \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$ such that $F(x, y)=0$ and $x=f(y)$ are equivalent in the set $\\mathbb{R}^{n} \\times \\mathbb{R}^{m}$.\n\nProof. See the appendix.\nWe intend to use Proposition 3.9 to solve the Issacs condition with Lipschitz mappings. The following result in [35] turns out to be helpful.\n\nTheorem 3.10 ([35]). Assume $\\boldsymbol{A} \\in \\mathbb{R}^{n \\times n}$ is strictly diagonally dominant (by rows) matrix and set the 'gap' $\\alpha=\\min _{1 \\leq k \\leq n}\\left\\{\\boldsymbol{A}_{k k}-\\sum_{j \\neq k}\\left|\\boldsymbol{A}_{k j}\\right|\\right\\}$. Then, $\\left\\|\\boldsymbol{A}^{-1}\\right\\|_{\\infty} \\leq 1 / \\alpha$, where $\\|\\cdot\\|_{\\infty}$ is the matrix norm induced by vector $\\infty$-norm.\n\nTheorem 3.11. (1) There exist unique Lipschitz functions $\\psi^{a}, \\psi^{b}: \\mathbb{R}^{N} \\rightarrow \\mathbb{R}^{N}$ such that $\\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)=0$ and $\\boldsymbol{\\delta}^{b}=\\psi^{b}(\\boldsymbol{y})$ are equivalent in the set $\\mathbb{R}^{N} \\times \\mathbb{R}^{N}$. The same is true for $\\Psi^{a}\\left(\\boldsymbol{\\delta}^{a}, \\boldsymbol{y}\\right)=0$ and $\\boldsymbol{\\delta}^{a}=\\psi^{a}(\\boldsymbol{y})$.\n(2) An admissible strategy profile $\\left(\\overline{\\boldsymbol{\\delta}}^{i}\\right)_{i \\in 1, \\ldots, N} \\in(\\mathbb{A} \\times \\mathbb{A})^{N}$ forms a Nash equilibrium if and only if the profile, together with the adjoint processes $\\left(Y^{i}, M^{i}\\right)_{i \\in 1, \\ldots, N}$, satisfies the system of FBSDEs\n\n$$\n\\left\\{\\begin{array}{l}\nd Q_{t}^{i}=b_{t} \\Lambda\\left(\\psi^{i, b}\\left(\\boldsymbol{Y}_{t}\\right)-\\bar{\\psi}^{i, b}\\left(\\boldsymbol{Y}_{t}\\right)\\right) d t-a_{t} \\Lambda\\left(\\psi^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)-\\bar{\\psi}^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)\\right) d t \\\\\nd Y_{t}^{i}=2 \\phi_{t}^{i} Q_{t}^{i} d t+d M_{t}^{i} \\\\\nQ_{0}^{i}=q_{0}^{i}, \\quad Y_{T}^{i}=-2 A^{i} Q_{T}^{i}\n\\end{array}\\right.\n$$\n\nfor all $i$. Here, the additional superscript $i$ of $\\psi^{b}$ indicates the $i$-th entry of the vector and $\\bar{\\psi}^{i, b}(\\boldsymbol{y}):=\\min _{j \\neq i} \\psi^{j, b}(\\boldsymbol{y})$.\nProof. (1) We look at the bid side, where Proposition 3.9 is applied for this proof. First, let us show the Lipschitz property of $\\Psi^{b}$ and verify the first two conditions stated in Proposition 3.9. To show that $\\Psi^{b}$ is Lipschitz, it suffices to prove the Lipschitz property of $\\overline{\\delta}^{i, b}$ for all $i$, since $\\delta^{*}$ has a bounded derivative. Indeed, the third condition of Assumption 3.1 along with\n\nLemma 3.2 infers such boundedness. Given any $\\boldsymbol{\\alpha}^{b}, \\boldsymbol{\\beta}^{b} \\in \\mathbb{R}^{N}$, let us set $j:=\\arg \\min _{l \\neq i} \\alpha^{l, b}$, $k:=\\arg \\min _{l \\neq i} \\beta^{l, b}$ and then observe the following:\n\n$$\n\\begin{aligned}\n& \\text { if } \\alpha^{j, b} \\geq \\beta^{k, b}, \\text { then } 0 \\leq \\alpha^{j, b}-\\beta^{k, b} \\leq \\alpha^{k, b}-\\beta^{k, b} \\\\\n& \\text { if } \\alpha^{j, b} \\leq \\beta^{k, b}, \\text { then } 0 \\geq \\alpha^{j, b}-\\beta^{k, b} \\geq \\alpha^{j, b}-\\beta^{j, b}\n\\end{aligned}\n$$\n\nThis observation helps us deduce that\n\n$$\n\\left|\\tilde{\\alpha}^{i, b}-\\tilde{\\beta}^{i, b}\\right|=\\left|\\alpha^{j, b}-\\beta^{k, b}\\right| \\leq \\max \\left(\\left|\\alpha^{j, b}-\\beta^{j, b}\\right|,\\left|\\alpha^{k, b}-\\beta^{k, b}\\right|\\right) \\leq\\left|\\alpha^{j, b}-\\beta^{j, b}\\right|+\\left|\\alpha^{k, b}-\\beta^{k, b}\\right|\n$$\n\nand hence function $\\Psi^{b}$ is Lipschitz. The coercive property is clear because the second term of\n\n$$\n\\Psi_{i}^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)=\\delta^{i, b}-\\left[\\tilde{\\delta}^{i, b}+\\delta^{*}\\left(-y^{i}-\\tilde{\\delta}^{i, b}\\right)\\right] \\vee(-\\xi) \\wedge \\xi\n$$\n\nis bounded by $\\xi$ for all $\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$. Finally, cases when $\\Psi_{i}^{b}$ is differentiable consist of\n\n$$\n\\begin{aligned}\n\\Psi_{i}^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right) & =\\delta^{i, b}-\\xi \\\\\n\\Psi_{i}^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right) & =\\delta^{i, b}-\\left[\\delta^{j, b}+\\delta^{*}\\left(-y^{i}-\\delta^{j, b}\\right)\\right] \\\\\n\\Psi_{i}^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right) & =\\delta^{i, b}+\\xi\n\\end{aligned}\n$$\n\nfor a unique index $j \\neq i$. Consequently, whenever $\\Psi^{b}$ is differentiable with respect to $\\boldsymbol{\\delta}^{b}$, the $i$-th row of the Jacobian matrix $\\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}$ is a vector with 1 in the $i$-th coordinate, and 0 or $-1+\\left(\\delta^{*}\\right)^{\\prime}\\left(-y^{i}-\\delta^{j, b}\\right)$ in the $j$-th coordinate. Since\n\n$$\n0<\\inf _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x) \\leq \\sup _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x) \\leq 1\n$$\n\ndue to Lemma 3.2, it follows $\\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}$ is always strictly row diagonally dominant and thus is of maximal rank. Defined as the convex hull of selected limits in $\\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}$, each matrix in $\\partial_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}$ is also strictly diagonally dominant, hence has a maximal rank.\n\nDefine the function $\\tilde{F}: \\mathbb{R}^{2 N} \\rightarrow \\mathbb{R}^{2 N}$ by $\\tilde{F}\\left(\\boldsymbol{y}, \\boldsymbol{\\delta}^{b}\\right)=\\left(\\boldsymbol{y}, \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)\\right)$. Whenever $\\tilde{F}$ is differentiable, the Jacobian matrix $\\nabla \\tilde{F}$ has the block form\n\n$$\n\\nabla \\tilde{F}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)=\\left(\\begin{array}{cc}\nI & 0 \\\\\n\\nabla_{\\boldsymbol{y}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right) & \\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)\n\\end{array}\\right)\n$$\n\nwhere $I \\in \\mathbb{R}^{N \\times N}$ is the identity matrix and $\\nabla_{\\boldsymbol{y}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$ is a diagonal matrix with\n\n$$\n\\left[\\nabla_{\\boldsymbol{y}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)\\right]_{i i} \\text { being } 0 \\text { or }\\left(\\delta^{*}\\right)^{\\prime}\\left(-y^{i}-\\delta^{j, b}\\right)\n$$\n\nfor all $i$ and some $j \\neq i$. Taking the advantage of the singular value decomposition (SVD), we now show the smallest singular value of $\\nabla \\tilde{F}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$ is bounded away from 0 , in order to meet the last condition of Proposition 3.9. First, recall that the smallest singular value of a matrix is the reciprocal of the 2 -norm of its inverse, i.e.,\n\n$$\n\\underline{\\sigma}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)=\\frac{1}{\\left\\|\\nabla \\tilde{F}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1}\\right\\|_{2}}\n$$\n\nHere, we denote by $\\underline{\\sigma}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$ the smallest singular value of $\\nabla \\tilde{F}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$ and use $\\|\\cdot\\|_{p}$ to indicate the matrix norm induced by the vector $p$-norm. Since\n\n$$\n\\nabla \\tilde{F}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1}=\\left(\\begin{array}{cc}\nI & 0 \\\\\n-\\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1} \\nabla_{\\boldsymbol{y}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right) & \\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1}\n\\end{array}\\right)\n$$\n\nan application of the triangle inequality and the matrix norm inequality $\\|\\cdot\\|_{2} \\leq \\sqrt{N}\\|\\cdot\\|_{\\infty}$ implies\n\n$$\n\\begin{aligned}\n\\left\\|\\nabla \\tilde{F}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1}\\right\\|_{2} & \\leq\\|I\\|_{2}+\\left\\|\\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1} \\nabla_{\\boldsymbol{y}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)\\right\\|_{2}+\\left\\|\\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1}\\right\\|_{2} \\\\\n& \\leq 1+\\left\\|\\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1}\\right\\|_{2}\\left\\|\\nabla_{\\boldsymbol{y}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)\\right\\|_{2}+\\left\\|\\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1}\\right\\|_{2} \\\\\n& \\leq 1+\\left(1+\\sup _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x)\\right)\\left\\|\\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1}\\right\\|_{2} \\\\\n& \\leq 1+\\sqrt{N}\\left(1+\\sup _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x)\\right)\\left\\|\\nabla_{\\boldsymbol{\\delta}^{b}} \\Psi^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1}\\right\\|_{\\infty}\n\\end{aligned}\n$$\n\nIn view of Theorem 3.10, one can obtain a uniform lower bounded of the singular value\n\n$$\n\\begin{aligned}\n\\underline{\\sigma}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right) & =\\frac{1}{\\left\\|\\nabla \\tilde{F}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)^{-1}\\right\\|_{2}} \\\\\n& \\geq\\left\\{1+\\sqrt{N}\\left[1+\\sup _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x)\\right] \\frac{1}{\\inf _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x)}\\right\\}^{-1}\n\\end{aligned}\n$$\n\nwhere we remark that the right hand side is independent of $\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$. According to the SVD, matrix $\\nabla \\tilde{F}$ can be represented as\n\n$$\n\\nabla \\tilde{F}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)=\\mathscr{U}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right) \\Sigma\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right) \\mathscr{V}^{*}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)\n$$\n\nwhere $\\mathscr{U}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$ is a square orthogonal matrix, $\\Sigma\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$ is square diagonal matrix with nonnegative singular values on the diagonal, $\\mathscr{V}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$ is a square orthogonal matrix, and $\\mathscr{V}^{*}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$ is its transpose, for every $\\boldsymbol{\\delta}^{b}$ and $\\boldsymbol{y}$. Because any orthogonal matrix is also an isometry, the only matrix in (24) that will change the norm of a vector is $\\Sigma\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$. While the smallest singular value of $\\nabla \\tilde{F}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$ is uniformly bounded away from 0 , the third condition of Proposition 3.9 now holds whenever differentiable. Finally, it suffices to notice that every matrix $D \\in \\partial \\tilde{F}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$ has the same partitioned structure as in (22):\n\n$$\nD=\\left(\\begin{array}{cc}\nI & 0 \\\\\nD_{1} & D_{2}\n\\end{array}\\right)\n$$\n\nwhere $D_{1} \\in \\mathbb{R}^{N \\times N}$ is some diagonal matrix with entries being non-negative and bounded by $\\sup _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x)$, and $D_{2} \\in \\mathbb{R}^{N \\times N}$ is a $Z$-matrix (see Definition 4.2) with 1 on the diagonal and positive row sums. The diagonal dominance 'gap' of the $D_{2}$ is still $\\inf _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x)$. Notice that\n\n$$\nD^{-1}=\\left(\\begin{array}{cc}\nI & 0 \\\\\n\\left(D_{2}\\right)^{-1} & D_{1}\n\\end{array}\\right)\n$$\n\nand a similar computation gives\n\n$$\n\\begin{aligned}\n\\left\\|D^{-1}\\right\\|_{2} & \\leq 1+\\left\\|\\left(D_{2}\\right)^{-1}\\right\\|_{2}\\left\\|D_{1}\\right\\|_{2}+\\left\\|\\left(D_{2}\\right)^{-1}\\right\\|_{2} \\\\\n& \\leq 1+\\sqrt{N}\\left(1+\\sup _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x)\\right)\\left\\|\\left(D_{2}\\right)^{-1}\\right\\|_{\\infty}\n\\end{aligned}\n$$\n\nIts smallest singular value $\\underline{\\sigma}_{D}$ is bounded away from 0 by the same constant as in (23):\n\n$$\n\\underline{\\sigma}_{D}=\\frac{1}{\\left\\|D^{-1}\\right\\|_{2}} \\geq\\left\\{1+\\sqrt{N}\\left[1+\\sup _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x)\\right] \\frac{1}{\\inf _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x)}\\right\\}^{-1}\n$$\n\nAs all conditions of Proposition 3.9 have been checked, the first part of the proof is complete.\n\n(2) By the stochastic maximum principle 3.8, an admissible strategy profile $\\left(\\delta^{i}\\right)_{i \\in 1, \\ldots, N}$ forms a Nash equilibrium if and only if the profile, together with the adjoint processes $\\left(Y^{i}, M^{i}\\right)_{i \\in 1, \\ldots, N}$, satisfies the Issacs condition (20). Subsequently, to fulfil the Issacs condition, the implicit function theorem 3.9 infers that $\\boldsymbol{\\delta}_{t}^{a}=\\psi^{a}\\left(\\boldsymbol{Y}_{t}\\right)$ and $\\boldsymbol{\\delta}_{t}^{b}=\\psi^{b}\\left(\\boldsymbol{Y}_{t}\\right)$, where $\\psi^{a}, \\psi^{b}$ are Lipschitz functions defined in the previous part of this theorem. The FBSDE system is thus the outcome of these two procedures.\n\nExample 3.12. Let $\\Lambda(\\delta)=\\exp (-\\gamma \\delta)$ for some $\\gamma>0$. By maximizing the Hamiltonian (16), the optimal control in feedback form reads\n\n$$\n\\delta^{i, b}=\\left(\\frac{1}{\\gamma}-y^{i}\\right) \\vee(-\\xi) \\wedge \\xi \\quad \\text { and } \\quad \\delta^{i, a}=\\left(\\frac{1}{\\gamma}+y^{i}\\right) \\vee(-\\xi) \\wedge \\xi\n$$\n\nIf we assume here the adjoint processes $\\left(Y^{i}\\right)_{i \\in\\{1, \\ldots, N\\}}$ are all bounded so that the truncation does not influence if large enough, the FBSDE suggested by the stochastic maximum principle can be neatly written as\n\n$$\n\\left\\{\\begin{aligned}\nd Q_{t}^{i} & =b_{t} \\exp \\left(-\\gamma\\left(\\max _{j \\neq i} Y_{t}^{j}-Y_{t}^{i}\\right)\\right) d t-a_{t} \\exp \\left(-\\gamma\\left(Y_{t}^{i}-\\min _{j \\neq i} Y_{t}^{j}\\right)\\right) d t \\\\\nd Y_{t}^{i} & =2 \\phi_{t}^{i} Q_{t}^{i} d t+d M_{t}^{i} \\\\\nQ_{0}^{i} & =q_{0}^{i}, \\quad Y_{T}^{i}=-2 A^{i} Q_{T}^{i}\n\\end{aligned}\\right.\n$$\n\nfor all $i$. Although the absence of the truncation leads to a non-Lipschitz FBSDE, we will find a unique bounded solution.", "tables": {}, "images": {}}, {"section_id": 5, "text": "# 4. General Game: $Z$-matrix and $M$-matrix \n\nThanks to the Lipschitz property of $\\psi^{a}, \\psi^{b}$ and the uniform boundedness of admissible strategy $\\mathbb{A}$, the FBSDE system (21) is therefore Lipschitz and a local well-posedness result is well-known; see [10]. To expand the analysis to global well-posedness, we need more information on the generalized derivative of the forward equations\n\n$$\n\\begin{aligned}\n\\rho\\left(t, \\boldsymbol{Y}_{t}\\right) & :=\\rho^{b}\\left(t, \\boldsymbol{Y}_{t}\\right)+\\rho^{a}\\left(t, \\boldsymbol{Y}_{t}\\right) \\\\\n\\rho^{b}\\left(t, \\boldsymbol{Y}_{t}\\right) & :=\\left\\{b_{t} \\Lambda\\left(\\psi^{i, b}\\left(\\boldsymbol{Y}_{t}\\right)-\\widetilde{\\psi}^{i, b}\\left(\\boldsymbol{Y}_{t}\\right)\\right)\\right\\}_{i \\in\\{1, \\cdots, N\\}} \\\\\n\\rho^{a}\\left(t, \\boldsymbol{Y}_{t}\\right) & :=\\left\\{-a_{t} \\Lambda\\left(\\psi^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)-\\widetilde{\\psi}^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)\\right)\\right\\}_{i \\in\\{1, \\cdots, N\\}}\n\\end{aligned}\n$$\n\nwith respect to $\\boldsymbol{Y}$, where function $\\rho:[0, T] \\times \\Omega \\times \\mathbb{R}^{N} \\rightarrow \\mathbb{R}^{N}$ is Lipschitz in the space variable. In this section, we will see its Jacobian matrix is a $Z_{+}$-matrix. Moreover, the forward equation of the corresponding variational FBSDE system will take the form of (14). We first introduce essential concepts in matrix algebra that are crucial for our subsequent analysis.\n\nDefinition 4.1 ([26]). A square matrix $\\mathbf{A}$ is (strictly) row diagonally dominant if $\\left|\\mathbf{A}_{i i}\\right|>$ $\\sum_{j \\neq i}\\left|\\mathbf{A}_{i j}\\right|$ for all $i$. The column diagonal dominance is similarly defined. A square matrix $\\mathbf{A}$ is (strictly) diagonally dominant of row entries if $\\left|\\mathbf{A}_{i i}\\right|>\\left|\\mathbf{A}_{i j}\\right|$ for any $i, j$. The diagonal dominance of column entries is similarly defined. A matrix $\\mathbf{A}$ is said non-negative if $\\mathbf{A}_{i j} \\geq 0$ for all $i, j$. We remark the difference between non-negativeness and positive semi-definiteness.\n\nDefinition 4.2. The class of $Z$-matrices are those matrices whose off-diagonal entries are less than or equal to zero. Denote by $Z_{+}$-matrices the class of $Z$-matrices with non-negative diagonal entries. A matrix is called non-negative stable if all its eigenvalues have non-negative real parts. Finally, an $M$-matrix is a $Z$-matrix that is also non-negative stable.\n\nRemark 4.3. It is worth noting that in some literature, such as [26], an $M$-matrix is defined as a $Z$-matrix with eigenvalues whose real parts are strictly positive. In our definition, we include both the $M$-matrix and the singular $M$-matrix with respect to their terminology.\n$M$-matrices play a crucial role in various areas of mathematics, including matrix theory, numerical analysis, and optimization. We conclude this paragraph with a simple result as follows:\n\nLemma 4.4. A $Z$-matrix with non-negative row sums is an $M$-matrix. Especially, a $Z$-matrix with zero row sums, defined as a $M_{0}$-matrix, is an $M$-matrix. The same is true for the case of column sums.\n\nProof. According to Theorem 2.5.3 of [26], a $Z$-matrix $\\boldsymbol{A}$ is a non-singular $M$-matrix if and only if $\\boldsymbol{A}+t I$ is non-singular for all $t \\geq 0$. Let $\\boldsymbol{B}$ be a $Z$-matrix with non-negative row sums. From that theorem, we know that $\\boldsymbol{B}+\\epsilon I$ is an $M$-matrix for any $\\epsilon>0$ due to strict row dominance, and thus eigenvalues of $\\boldsymbol{B}+\\epsilon I$ have positive real parts. Finally, eigenvalues of $\\boldsymbol{B}$ have non-negative real parts due to the continuity.\n\nRecall that implicit functions $\\psi^{a}$ and $\\psi^{b}$ satisfy\n\n$$\n\\Psi^{b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)=0 \\quad \\text { and } \\quad \\Psi^{a}\\left(\\psi^{a}(\\boldsymbol{y}), \\boldsymbol{y}\\right)=0\n$$\n\nWe take the total derivative with respect to $\\boldsymbol{y}$ on both sides to see\n\n$$\n\\nabla \\Psi^{b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)=\\mathbf{0} \\quad \\text { and } \\quad \\nabla \\Psi^{a}\\left(\\psi^{a}(\\boldsymbol{y}), \\boldsymbol{y}\\right)=\\mathbf{0}\n$$\n\nwhere $\\mathbf{0}$ here is an zero matrix. Although both the implicit functions $\\psi^{a}, \\psi^{b}$, and mappings $\\Psi^{a}, \\Psi^{b}$ are Lipschitz, in general we can not further write\n\n$$\n\\begin{aligned}\n& \\partial \\psi^{b}(\\boldsymbol{y})=-\\left[\\partial_{\\delta} \\Psi^{b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)\\right]^{-1} \\partial_{\\boldsymbol{y}}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right) \\\\\n& \\partial \\psi^{a}(\\boldsymbol{y})=-\\left[\\partial_{\\delta} \\Psi^{a}\\left(\\psi^{a}(\\boldsymbol{y}), \\boldsymbol{y}\\right)\\right]^{-1} \\partial_{\\boldsymbol{y}}\\left(\\psi^{a}(\\boldsymbol{y}), \\boldsymbol{y}\\right)\n\\end{aligned}\n$$\n\nwhich is true in the smooth case; see Theorem 4.5. Regarding the calculus of the generalized derivative (see [12] and [14] for references), while several results on the sum rule and chain rule are discussed, the subset relations presented are insufficient for our analysis of the derivative of the implicit function. Since additional regularity is required to obtain the equality relation, we can not use them directly but instead introduce a 'region-by-region' method. According to the definition and the Lipschitz property, functions $\\Psi^{a}$ and $\\Psi^{b}$ are non-differentiable in some closed zero-measure sets $\\mathscr{D}^{a}$ and $\\mathscr{D}^{b} \\subset \\mathbb{R}^{N} \\times \\mathbb{R}^{N}$ accordingly. On the other hand, the graph $\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)$ resides in the same space $\\mathbb{R}^{N} \\times \\mathbb{R}^{N}$. To analyze the gradient, the subsequent result divides the examination into two scenarios: when $\\Psi^{b}$ is differentiable at $\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)$ and when it is not at that point. The following smooth version of the implicit function theorem turns out to be helpful. Although we only state the global result, one should note that it also holds locally.\n\nTheorem 4.5 ([28], [19]). Assume that $F: \\mathbb{R}^{n} \\times \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$ is a $C^{1}$ mapping such that:\n\n1. For every $y \\in \\mathbb{R}^{m}$, the functional $\\varphi_{y}: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ given by the formula\n\n$$\n\\varphi_{y}(x):=\\frac{1}{2}|F(x, y)|^{2}\n$$\n\nis coercive, i.e., $\\lim _{|x| \\rightarrow \\infty} \\varphi_{y}(x)=\\infty$;\n2. The Jacobian matrix $\\nabla_{x} F(x, y)$ is of maximal rank for all $(x, y) \\in \\mathbb{R}^{n} \\times \\mathbb{R}^{m}$.\n\nThen, there exists a unique function $f: \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$ such that equations $F(x, y)=0$ and $x=f(y)$ are equivalent in the set $\\mathbb{R}^{n} \\times \\mathbb{R}^{m}$. Moreover, function $f$ is also continuously differentiable with\n\n$$\n\\nabla f(y)=-\\left[\\nabla_{x} F(f(y), y)\\right]^{-1} \\nabla_{y} F(f(y), y)\n$$\n\nThe following lemma analyzes the derivative of $\\rho$ in the differentiable region, utilizing the smooth implicit function theorem provided.\n\nLemma 4.6. For any $\\boldsymbol{y}$ such that $\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right) \\notin \\mathscr{D}^{b}$ and $\\left(\\psi^{a}(\\boldsymbol{y}), \\boldsymbol{y}\\right) \\notin \\mathscr{D}^{a}$, the following statements hold:\n(i) matrix $\\nabla_{y} \\psi^{b}$ is element-wise uniformly bounded by some constant independent of $\\xi$. It has non-positive entries and is diagonally dominant of column entries;\n(ii) matrix $\\nabla_{y} \\psi^{a}$ is element-wise uniformly bounded by some constant independent of $\\xi$. It has non-negative entries and is diagonally dominant of column entries;\n(iii) the Jacobian $\\nabla_{y} \\rho(t, \\boldsymbol{y})$ is an $M$-matrix. Notably, it is an $M_{0}$-matrix in the absence of $\\xi$.\n\nProof. We start with the bid side and $\\rho^{b}$. Since $\\mathscr{D}^{b}$ is closed, if $\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right) \\notin \\mathscr{D}^{b}$, then there exists a neighbourhood $\\mathscr{B}_{\\boldsymbol{y}}$ of $\\boldsymbol{y}$ such that $\\left(\\psi^{b}(\\boldsymbol{x}), \\boldsymbol{x}\\right) \\notin \\mathscr{D}^{b}$ for any $\\boldsymbol{x} \\in \\mathscr{B}_{\\boldsymbol{y}}$. Recalling the definition (19) of $\\Psi^{b}$, the non-smoothness is caused by the min function and the truncation by $\\pm \\xi$. Let us first look at the case when the truncation has no effect and consider the possible ordering:\n\n$$\n\\psi^{1, b}(\\boldsymbol{y})<\\psi^{2, b}(\\boldsymbol{y})<\\cdots<\\psi^{N, b}(\\boldsymbol{y})\n$$\n\nGiven above relation, in the neighbourhood $\\mathscr{B}_{\\boldsymbol{y}}$, function $\\Psi^{b}$ is equal to $\\tilde{\\Psi}^{b}$ defined as\n\n$$\n\\begin{aligned}\n& \\tilde{\\Psi}^{1, b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)=\\delta^{1, b}-\\left[\\delta^{2, b}+\\delta^{*}\\left(-y^{1}-\\delta^{2, b}\\right)\\right] \\\\\n& \\tilde{\\Psi}^{i, b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)=\\delta^{i, b}-\\left[\\delta^{1, b}+\\delta^{*}\\left(-y^{i}-\\delta^{1, b}\\right)\\right]\n\\end{aligned}\n$$\n\nfor $i \\in\\{2, \\ldots, N\\}$. Noting that $\\tilde{\\Psi}^{b}$ is differentiable, we then check the conditions in Theorem 4.5. The property of maximal rank can be verified similarly as in Theorem 3.11. Fixing any $\\boldsymbol{y} \\in \\mathbb{R}^{N}$, the triangle inequality yields\n\n$$\n\\left|\\tilde{\\Psi}^{1, b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)\\right|+\\left|\\tilde{\\Psi}^{2, b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)\\right| \\geq\\left|\\tilde{\\Psi}^{1, b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)+\\tilde{\\Psi}^{2, b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)\\right|=\\left|\\delta^{*}\\left(-y^{2}-\\delta^{1, b}\\right)+\\delta^{*}\\left(-y^{1}-\\delta^{2, b}\\right)\\right|\n$$\n\nIf the right hand side of above equation does not explode when $\\left|\\boldsymbol{\\delta}^{b}\\right| \\rightarrow \\infty$, only the following three cases can happen because the derivative of $\\delta^{*}$ is non-negative and bounded away from 0 :\n(i) both $\\delta^{1, b}$ and $\\delta^{2, b}$ are bounded;\n(ii) $\\delta^{1, b} \\rightarrow-\\infty$ and $\\delta^{2, b} \\rightarrow \\infty$;\n(iii) $\\delta^{1, b} \\rightarrow \\infty$ and $\\delta^{2, b} \\rightarrow-\\infty$.\n\nIf case (i) is true, since $\\left|\\boldsymbol{\\delta}^{b}\\right| \\rightarrow \\infty$, there exists an index $j \\notin\\{1,2\\}$ such that $\\left|\\delta^{j, b}\\right| \\rightarrow \\infty$ and thus $\\left|\\tilde{\\Psi}^{j, b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)\\right|=\\left|\\delta^{j, b}-\\left[\\delta^{1, b}+\\delta^{*}\\left(-y^{j}-\\delta^{1, b}\\right)\\right]\\right| \\rightarrow \\infty$. Turning to case (ii), in view of $\\left(\\delta^{*}\\right)^{\\prime} \\in(0,1)$, one can see $\\delta^{2, b}+\\delta^{*}\\left(-y^{1}-\\delta^{2, b}\\right)$ is increasing with respect to $\\delta^{2, b}$. This gives\n\n$$\n\\tilde{\\Psi}^{1, b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)=\\delta^{1, b}-\\left[\\delta^{2, b}+\\delta^{*}\\left(-y^{1}-\\delta^{2, b}\\right)\\right] \\rightarrow-\\infty\n$$\n\nFinally, since case (iii) is symmetric to case (ii), we see the $\\ell_{1}$-norm of $\\tilde{\\Psi}^{b}\\left(\\boldsymbol{\\delta}^{b}, \\boldsymbol{y}\\right)$ will always explode when $\\left|\\boldsymbol{\\delta}^{b}\\right| \\rightarrow \\infty$. The coercive property follows from the equivalence of norms in the finite-dimensional space. Therefore, the local version of Theorem 4.5 guarantees an implicit function $\\tilde{\\psi}^{b}$ and the uniqueness further implies $\\tilde{\\psi}^{b}=\\psi^{b}$ in the neighborhood $\\mathscr{B}_{\\boldsymbol{y}}$. We then learn that $\\psi^{b}$ is differentiable in $\\mathscr{B}_{\\boldsymbol{y}}$ with\n\n$$\n\\nabla \\psi^{b}(\\boldsymbol{y})=-\\left[\\nabla_{\\delta} \\tilde{\\Psi}^{b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)\\right]^{-1} \\nabla_{\\boldsymbol{y}} \\tilde{\\Psi}^{b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)\n$$\n\nfor any $\\boldsymbol{y} \\in \\mathscr{B}_{\\boldsymbol{y}}$. Note that $\\rho^{b}$ is thus also differentiable at such $\\boldsymbol{y}$.\nThe Jacobian matrix $\\nabla_{\\delta} \\tilde{\\Psi}^{b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)$ reads\n\n$$\n\\left[\\begin{array}{cccc}\n1 & (-1)\\left[1-\\left(\\delta^{*}\\right)^{\\prime}\\left(-\\psi^{2, b}(\\boldsymbol{y})-y^{1}\\right)\\right] & 0 & \\cdots & 0 \\\\\n(-1)\\left[1-\\left(\\delta^{*}\\right)^{\\prime}\\left(-\\psi^{1, b}(\\boldsymbol{y})-y^{2}\\right)\\right] & 1 & 0 & \\cdots & 0 \\\\\n(-1)\\left[1-\\left(\\delta^{*}\\right)^{\\prime}\\left(-\\psi^{1, b}(\\boldsymbol{y})-y^{3}\\right)\\right] & 0 & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n(-1)\\left[1-\\left(\\delta^{*}\\right)^{\\prime}\\left(-\\psi^{1, b}(\\boldsymbol{y})-y^{N}\\right)\\right] & 0 & 0 & \\cdots & 1\n\\end{array}\\right]\n$$\n\nDefine\n\n$$\n\\mathrm{a}_{1}=(-1)\\left[1-\\left(\\delta^{*}\\right)^{\\prime}\\left(-\\psi^{2, b}(\\boldsymbol{y})-y^{1}\\right)\\right] \\text { and } \\mathrm{a}_{i}=(-1)\\left[1-\\left(\\delta^{*}\\right)^{\\prime}\\left(-\\psi^{1, b}(\\boldsymbol{y})-y^{i}\\right)\\right]\n$$\n\nfor $i \\in\\{2, \\ldots, N\\}$ and observe that each $a_{i} \\in(-1,0]$. Direct calculations yield\n\n$$\n\\left[\\nabla_{\\delta} \\tilde{\\Psi}^{b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)\\right]^{-1}=\\frac{1}{1-\\mathrm{a}_{1} \\mathrm{a}_{2}}\\left[\\begin{array}{cccccc}\n1 & -\\mathrm{a}_{1} & 0 & \\cdots & 0 \\\\\n-\\mathrm{a}_{2} & 1 & 0 & \\cdots & 0 \\\\\n-\\mathrm{a}_{3} & \\mathrm{a}_{1} \\mathrm{a}_{3} & 1-\\mathrm{a}_{1} \\mathrm{a}_{2} & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n-\\mathrm{a}_{N} & \\mathrm{a}_{1} \\mathrm{a}_{N} & 0 & \\cdots & 1-\\mathrm{a}_{1} \\mathrm{a}_{2}\n\\end{array}\\right]\n$$\n\nSince the Jacobian matrix $\\nabla_{\\boldsymbol{y}} \\tilde{\\Psi}^{b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)$ reads\n\n$$\n\\nabla_{\\boldsymbol{y}} \\tilde{\\Psi}^{b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)=\\left[\\begin{array}{cccc}\n\\mathrm{a}_{1}+1 & 0 & \\cdots & 0 \\\\\n0 & \\mathrm{a}_{2}+1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\mathrm{a}_{N}+1\n\\end{array}\\right]\n$$\n\nwe can compute the Jacobian matrix $\\nabla \\psi^{b}(\\boldsymbol{y})$ via\n\n$$\n\\begin{aligned}\n\\nabla \\psi^{b}(\\boldsymbol{y}) & =\\frac{1}{1-\\mathrm{a}_{1} \\mathrm{a}_{2}} . & & \\\\\n& {\\left[\\begin{array}{cccc}\n-\\mathrm{a}_{1}-1 & \\mathrm{a}_{1}\\left(\\mathrm{a}_{2}+1\\right) & 0 & \\cdots & 0 \\\\\n\\mathrm{a}_{2}\\left(\\mathrm{a}_{1}+1\\right) & -\\mathrm{a}_{2}-1 & 0 & \\cdots & 0 \\\\\n\\mathrm{a}_{3}\\left(\\mathrm{a}_{1}+1\\right) & -\\mathrm{a}_{1} \\mathrm{a}_{3}\\left(\\mathrm{a}_{2}+1\\right) & \\left(\\mathrm{a}_{1} \\mathrm{a}_{2}-1\\right)\\left(\\mathrm{a}_{3}+1\\right) & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\mathrm{a}_{N}\\left(\\mathrm{a}_{1}+1\\right) & -\\mathrm{a}_{1} \\mathrm{a}_{N}\\left(\\mathrm{a}_{2}+1\\right) & 0 & \\cdots & \\left(\\mathrm{a}_{1} \\mathrm{a}_{2}-1\\right)\\left(\\mathrm{a}_{N}+1\\right)\n\\end{array}\\right] .}\n\\end{aligned}\n$$\n\nIt is evident that $\\nabla \\psi^{b}(\\boldsymbol{y})$ has non-positive entries and is diagonally dominant of column entries, for which an element-wise bound can be\n\n$$\n\\frac{2}{1-\\left[1-\\inf _{x \\in \\mathbb{R}}\\left(\\delta^{*}\\right)^{\\prime}(x)\\right]^{2}}\n$$\n\nBecause we are considering the scenario (26), each agent is affected by the best offer (or equivalently the smallest gap $\\delta$ ) from the others. The interaction between agents now is\n\n$$\n\\Xi^{b}(\\boldsymbol{y}):=\\left(\\psi^{1, b}(\\boldsymbol{y})-\\psi^{2, b}(\\boldsymbol{y}), \\psi^{2, b}(\\boldsymbol{y})-\\psi^{1, b}(\\boldsymbol{y}), \\psi^{3, b}(\\boldsymbol{y})-\\psi^{1, b}(\\boldsymbol{y}), \\ldots, \\psi^{N, b}(\\boldsymbol{y})-\\psi^{1, b}(\\boldsymbol{y})\\right)\n$$\n\nand the Jacobian $\\nabla \\Xi^{b}(\\boldsymbol{y})$ is given by\n\n$$\n\\begin{aligned}\n& \\nabla \\Xi^{b}(\\boldsymbol{y})=\\frac{1}{1-\\mathfrak{a}_{1} \\mathfrak{a}_{2}} \\cdot \\\\\n& {\\left[\\begin{array}{cccc}\n-\\left(\\mathfrak{a}_{1}+1\\right)\\left(\\mathfrak{a}_{2}+1\\right) & \\left(\\mathfrak{a}_{1}+1\\right)\\left(\\mathfrak{a}_{2}+1\\right) & 0 & \\cdots & 0 \\\\\n\\left(\\mathfrak{a}_{1}+1\\right)\\left(\\mathfrak{a}_{2}+1\\right) & -\\left(\\mathfrak{a}_{1}+1\\right)\\left(\\mathfrak{a}_{2}+1\\right) & 0 & \\cdots & 0 \\\\\n\\left(\\mathfrak{a}_{1}+1\\right)\\left(\\mathfrak{a}_{3}+1\\right) & -\\mathfrak{a}_{1}\\left(\\mathfrak{a}_{2}+1\\right)\\left(\\mathfrak{a}_{3}+1\\right) & \\left(\\mathfrak{a}_{1} \\mathfrak{a}_{2}-1\\right)\\left(\\mathfrak{a}_{3}+1\\right) & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\left(\\mathfrak{a}_{1}+1\\right)\\left(\\mathfrak{a}_{N}+1\\right) & -\\mathfrak{a}_{1}\\left(\\mathfrak{a}_{2}+1\\right)\\left(\\mathfrak{a}_{N}+1\\right) & 0 & \\cdots & \\left(\\mathfrak{a}_{1} \\mathfrak{a}_{2}-1\\right)\\left(\\mathfrak{a}_{N}+1\\right)\n\\end{array}\\right] .}\n\\end{aligned}\n$$\n\nIt is straightforward to observe that the matrix (28) has a zero row sum. Recalling $\\mathfrak{a}_{k} \\in(-1,0]$ for all $k \\in\\{1, \\ldots, N\\}$, we can further determine\n\n$$\n\\left(\\mathfrak{a}_{1}+1\\right)\\left(\\mathfrak{a}_{i}+1\\right) \\geq 0, \\quad-\\mathfrak{a}_{1}\\left(\\mathfrak{a}_{1}+1\\right)\\left(\\mathfrak{a}_{i}+1\\right) \\geq 0, \\quad \\mathfrak{a}_{1} \\mathfrak{a}_{2}-1 \\leq 0\n$$\n\nConsequently, the matrix (28) has non-positive diagonal entries and non-negative off-diagonal entries, with zero row sums. Because $\\Lambda$ is a decreasing function, the Jacobian $\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ equals to the multiplication of a non-positive diagonal matrix with $\\nabla \\Xi^{b}(\\boldsymbol{y})$. Therefore, the matrix $\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ exhibits non-negative diagonal entries and non-positive off-diagonal entries, with zero row sums. By Lemma 4.4, it is an $M_{0}$-matrix and thus an $M$-matrix. Since $\\Psi^{b}$ is symmetric with respect to the index, any permutation of the ordering (26) will result in a matrix with the same property as above.\n\nThen, let us turn to the case when the truncation by $\\xi$ is in effect. That is to say, given $\\boldsymbol{y}$, there exists some $k$ such that\n\n$$\n\\Psi^{k, b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)=\\psi^{k, b}(\\boldsymbol{y})-\\left[\\bar{\\psi}^{k, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{k}-\\bar{\\psi}^{k, b}(\\boldsymbol{y})\\right)\\right] \\vee(-\\xi) \\wedge \\xi=\\psi^{k, b}(\\boldsymbol{y})-\\xi\n$$\n\nSuppose this is true for all $k$, condition (20) yields $\\psi^{k, b}(\\boldsymbol{y})=\\xi$ for any $k$ and hence $\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ is a zero matrix, which is an $M$-matrix. Next, suppose there exists only one index, denoted by 1 , such that the truncation has no influence:\n\n$$\n\\begin{aligned}\n\\Psi^{1, b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right) & =\\psi^{1, b}(\\boldsymbol{y})-\\left[\\bar{\\psi}^{1, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{1}-\\bar{\\psi}^{1, b}(\\boldsymbol{y})\\right)\\right] \\vee(-\\xi) \\wedge \\xi \\\\\n& =\\psi^{1, b}(\\boldsymbol{y})-\\left[\\xi+\\delta^{*}\\left(-y^{1}-\\xi\\right)\\right]\n\\end{aligned}\n$$\n\nOne can observe that $\\psi^{1, b}(\\boldsymbol{y})=\\psi^{1, b}\\left(y^{1}\\right)$ is decreasing with respect to $y^{1}$. The interaction between agents is\n\n$$\n\\Xi^{b}(\\boldsymbol{y}):=\\left(\\psi^{1, b}(\\boldsymbol{y})-\\xi, \\xi-\\psi^{1, b}(\\boldsymbol{y}), \\xi-\\psi^{1, b}(\\boldsymbol{y}), \\ldots, \\xi-\\psi^{1, b}(\\boldsymbol{y})\\right)\n$$\n\nBecause $\\Lambda$ is decreasing, for constants $C_{i} \\geq 0$, it can be deduced that\n\n$$\n\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})=\\left[\\begin{array}{cccc}\nC_{1} & 0 & \\cdots & 0 \\\\\n-C_{2} & 0 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n-C_{N} & 0 & \\cdots & 0\n\\end{array}\\right]\n$$\n\nwhich is an $M$-matrix by the method in the proof of Lemma 4.4. Finally, if there exist more than one index such that the truncation has no influence. In this case, let us suppose that truncation is only applied to index 1 but not the others, that is,\n\n$$\n\\begin{aligned}\n\\Psi^{1, b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right) & =\\psi^{1, b}(\\boldsymbol{y})-\\left[\\ddot{\\psi}^{1, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{1}-\\ddot{\\psi}^{1, b}(\\boldsymbol{y})\\right)\\right] \\vee(-\\xi) \\wedge \\xi=\\psi^{1, b}(\\boldsymbol{y})-\\xi \\\\\n\\Psi^{k, b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right) & =\\psi^{k, b}(\\boldsymbol{y})-\\left[\\ddot{\\psi}^{k, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{k}-\\ddot{\\psi}^{k, b}(\\boldsymbol{y})\\right)\\right] \\vee(-\\xi) \\wedge \\xi \\\\\n& =\\psi^{k, b}(\\boldsymbol{y})-\\left[\\ddot{\\psi}^{k, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{k}-\\ddot{\\psi}^{k, b}(\\boldsymbol{y})\\right)\\right]\n\\end{aligned}\n$$\n\nfor $k \\neq 1$. Note that index 1 has no impact on the remaining $N-1$ indices. If we further assume the ordering $\\psi^{2, b}(\\boldsymbol{y})<\\psi^{3, b}(\\boldsymbol{y})<\\cdots<\\psi^{N, b}(\\boldsymbol{y})$, the result from the previous discussion yields\n\n$$\n\\nabla \\psi^{b}(\\boldsymbol{y})=\\frac{1}{1-c_{2} c_{3}}\\left[\\begin{array}{ccccc}\n0 & 0 & 0 & \\cdots & 0 \\\\\n0 & -c_{2}-1 & c_{2}\\left(c_{3}+1\\right) & \\cdots & 0 \\\\\n0 & c_{3}\\left(c_{2}+1\\right) & -c_{3}-1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & c_{N}\\left(c_{2}+1\\right) & -c_{2} c_{N}\\left(c_{3}+1\\right) & \\cdots & \\left(c_{2} c_{3}-1\\right)\\left(c_{N}+1\\right)\n\\end{array}\\right]\n$$\n\nwhere\n\n$$\nc_{2}=(-1)\\left[1-\\left(\\delta^{*}\\right)^{\\prime}\\left(-\\psi^{3, b}(\\boldsymbol{y})-y^{2}\\right)\\right] \\in(-1,0], c_{i}=(-1)\\left[1-\\left(\\delta^{*}\\right)^{\\prime}\\left(-\\psi^{2, b}(\\boldsymbol{y})-y^{i}\\right)\\right] \\in(-1,0]\n$$\n\nfor $i \\in\\{3, \\cdots, N\\}$. Since the interaction between agents now is\n\n$$\n\\left(\\psi^{1, b}(\\boldsymbol{y})-\\psi^{2, b}(\\boldsymbol{y}), \\psi^{2, b}(\\boldsymbol{y})-\\psi^{3, b}(\\boldsymbol{y}), \\psi^{3, b}(\\boldsymbol{y})-\\psi^{2, b}(\\boldsymbol{y}), \\ldots, \\psi^{N, b}(\\boldsymbol{y})-\\psi^{2, b}(\\boldsymbol{y})\\right)\n$$\n\nthe Jacobian of $\\rho^{b}$ admits the representation as the following block matrix:\n\n$$\n\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})=\\left[\\begin{array}{cc}\n0 & -\\vec{C} \\\\\n\\overrightarrow{0} & D\n\\end{array}\\right]\n$$\n\nwhere $\\overrightarrow{0} \\in \\mathbb{R}^{N-1}$ is the zero vector, $\\vec{C} \\in \\mathbb{R}^{N-1}$ is a vector with non-negative entries, and $D \\in \\mathbb{R}^{(N-1) \\times(N-1)}$ is an $M_{0}$-matrix. Through an application of the Laplace expansion, one can see $\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ is an $M$-matrix. Since $\\Psi^{b}$ is symmetric with respect to the index, above situations with different indices will not change the desired property of the Jacobian matrix.\n\nFinally, we examine the case when the truncation by $-\\xi$ happens. Especially, given $\\boldsymbol{y}$, there exists some $k$ such that\n\n$$\n\\Psi^{k, b}\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)=\\psi^{k, b}(\\boldsymbol{y})-\\left[\\ddot{\\psi}^{k, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{k}-\\ddot{\\psi}^{k, b}(\\boldsymbol{y})\\right)\\right] \\vee(-\\xi) \\wedge \\xi=\\psi^{k, b}(\\boldsymbol{y})+\\xi\n$$\n\nSuppose this is true for multiple indices; for example 1 and 2 . Since $-\\xi$ is the smallest value admissible, the smallest and second smallest value of the vector $\\psi^{b}(\\boldsymbol{y})$ are then both $-\\xi$. As a result, for $j \\notin\\{1,2\\}$ it holds that\n\n$$\n\\psi^{j, b}(\\boldsymbol{y})=\\ddot{\\psi}^{j, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{j}-\\ddot{\\psi}^{j, b}(\\boldsymbol{y})\\right)=-\\xi+\\delta^{*}\\left(-y^{j}+\\xi\\right)\n$$\n\nwhich infers $\\psi^{j, b}(\\boldsymbol{y})=\\psi^{j, b}\\left(y^{j}\\right)$ is decreasing in $y^{j}$. Because the interaction between agents now reads\n\n$$\n\\left(\\psi^{1, b}(\\boldsymbol{y})-\\psi^{2, b}(\\boldsymbol{y})=0, \\psi^{2, b}(\\boldsymbol{y})-\\psi^{1, b}(\\boldsymbol{y})=0, \\psi^{3, b}(\\boldsymbol{y})+\\xi, \\ldots, \\psi^{N, b}(\\boldsymbol{y})+\\xi\\right)\n$$\n\nthe Jacobian of $\\rho^{b}$ admits the following block representation:\n\n$$\n\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})=\\left[\\begin{array}{ll}\nO & O \\\\\nO & D\n\\end{array}\\right]\n$$\n\nwhere $O \\in \\mathbb{R}^{2 \\times 2}$ is the zero matrix and $D \\in \\mathbb{R}^{2 \\times 2}$ is a diagonal matrix with non-negative entries. It is now straightforward to see that $\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ is an $M$-matrix. Next, suppose there is only index 1 with truncation being applied. The definition of implicit function then yields\n\n$$\n\\psi^{1, b}(\\boldsymbol{y})=-\\xi \\quad \\text { and } \\quad \\psi^{j, b}(\\boldsymbol{y})=-\\xi+\\delta^{*}\\left(-y^{j}+\\xi\\right)\n$$\n\nfor $j \\neq 1$. Let $m=\\arg \\min _{j \\neq 1} \\psi^{j, b}(\\boldsymbol{y})$. With the interaction being\n\n$$\n\\left(\\psi^{1, b}(\\boldsymbol{y})-\\psi^{m, b}(\\boldsymbol{y}), \\psi^{2, b}(\\boldsymbol{y})+\\xi, \\psi^{3, b}(\\boldsymbol{y})+\\xi, \\ldots, \\psi^{N, b}(\\boldsymbol{y})+\\xi\\right)\n$$\n\nthe Jacobian of $\\rho^{b}$ admits the representation as the following block matrix:\n\n$$\n\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})=\\left[\\begin{array}{cc}\n0 & -\\vec{C} \\\\\n\\overrightarrow{0} & D\n\\end{array}\\right]\n$$\n\nHere, again $\\vec{C}$ is a non-negative vector, $D$ is non-negative diagonal matrix, and thus $\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ is an $M$-matrix. We remark again that change of index will not alter the targeted property of the matrix, and also the composition of different truncation can be discussed likewise.\n\nThe ask side can be verified in like manner, while we briefly summarize the calculation results when all truncation is of no effect. Consider the possible ordering\n\n$$\n\\psi_{1}^{a}(\\boldsymbol{y})>\\psi_{2}^{a}(\\boldsymbol{y})>\\cdots>\\psi_{N}^{a}(\\boldsymbol{y})\n$$\n\nThe interaction between agents now is\n\n$$\n\\Xi^{a}(\\boldsymbol{y}):=\\left(\\psi_{1}^{a}(\\boldsymbol{y})-\\psi_{N}^{a}(\\boldsymbol{y}), \\psi_{2}^{a}(\\boldsymbol{y})-\\psi_{N}^{a}(\\boldsymbol{y}), \\ldots, \\psi_{N-1}^{a}(\\boldsymbol{y})-\\psi_{N}^{a}(\\boldsymbol{y}), \\psi_{N}^{a}(\\boldsymbol{y})-\\psi_{N-1}^{a}(\\boldsymbol{y})\\right)\n$$\n\nLet us define\n\n$$\n\\mathrm{b}_{N}=(-1)\\left[1-\\left(\\delta^{*}\\right)^{\\prime}\\left(y^{N}-\\psi^{N-1, a}(\\boldsymbol{y})\\right)\\right] \\text { and } \\mathrm{b}_{i}=(-1)\\left[1-\\left(\\delta^{*}\\right)^{\\prime}\\left(y^{i}-\\psi^{N, a}(\\boldsymbol{y})\\right)\\right]\n$$\n\nfor $i \\in\\{2, \\ldots, N\\}$ and notice that $\\mathrm{b}_{k} \\in(-1,0]$ for all $k \\in\\{1, \\ldots, N\\}$. The Jacobian of the control $\\psi^{a}(\\boldsymbol{y})$ is given by\n\n$$\n\\nabla \\psi^{a}(\\boldsymbol{y})=\\frac{1}{1-\\mathrm{b}_{N-1} \\mathrm{~b}_{N}}\n$$\n\n$$\n\\left[\\begin{array}{ccccc}\n\\left(1-\\mathrm{b}_{N-1} \\mathrm{~b}_{N}\\right)\\left(\\mathrm{b}_{1}+1\\right) & 0 & \\cdots & \\mathrm{b}_{1} \\mathrm{~b}_{N}\\left(\\mathrm{~b}_{N-1}+1\\right) & -\\mathrm{b}_{1}\\left(\\mathrm{~b}_{N}+1\\right) \\\\\n0 & \\left(1-\\mathrm{b}_{N-1} \\mathrm{~b}_{N}\\right)\\left(\\mathrm{b}_{2}+1\\right) & \\cdots & \\mathrm{b}_{2} \\mathrm{~b}_{N}\\left(\\mathrm{~b}_{N-1}+1\\right) & -\\mathrm{b}_{2}\\left(\\mathrm{~b}_{N}+1\\right) \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & \\cdots & \\mathrm{~b}_{N-1}+1 & -\\mathrm{b}_{N-1}\\left(\\mathrm{~b}_{N}+1\\right) \\\\\n0 & 0 & \\cdots & -\\left(\\mathrm{b}_{N-1}+1\\right) \\mathrm{b}_{N} & \\mathrm{~b}_{N}+1\n\\end{array}\\right] .\n$$\n\nand resulting $\\nabla \\Xi^{a}(\\boldsymbol{y})$ reads\n$\\nabla \\Xi^{a}(\\boldsymbol{y})=\\frac{1}{1-b_{N-1} \\mathfrak{b}_{N}}$.\n$\\left[\\begin{array}{ccccc}\\left(1-b_{N-1} \\mathfrak{b}_{N}\\right)\\left(\\mathfrak{b}_{1}+1\\right) & 0 & \\cdots & \\mathfrak{b}_{N}\\left(\\mathfrak{b}_{1}+1\\right)\\left(\\mathfrak{b}_{N-1}+1\\right) & -\\left(\\mathfrak{b}_{1}+1\\right)\\left(\\mathfrak{b}_{N}+1\\right) \\\\ 0 & \\left(1-b_{N-1} \\mathfrak{b}_{N}\\right)\\left(\\mathfrak{b}_{2}+1\\right) & \\cdots & \\mathfrak{b}_{N}\\left(\\mathfrak{b}_{2}+1\\right)\\left(\\mathfrak{b}_{N-1}+1\\right) & -\\left(\\mathfrak{b}_{2}+1\\right)\\left(\\mathfrak{b}_{N}+1\\right) \\\\ \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\ 0 & 0 & \\cdots & \\left(\\mathfrak{b}_{N-1}+1\\right)\\left(\\mathfrak{b}_{N}+1\\right) & -\\left(\\mathfrak{b}_{N-1}+1\\right)\\left(\\mathfrak{b}_{N}+1\\right) \\\\ 0 & 0 & \\cdots & -\\left(\\mathfrak{b}_{N-1}+1\\right)\\left(\\mathfrak{b}_{N}+1\\right) & \\left(\\mathfrak{b}_{N-1}+1\\right)\\left(\\mathfrak{b}_{N}+1\\right)\\end{array}\\right]$.\nSince $-\\Lambda$ is increasing, the Jacobian $\\nabla_{\\boldsymbol{y}} \\rho^{a}(t, \\boldsymbol{y})$ is the multiplication of a non-negative diagonal matrix with $\\nabla \\Xi^{a}(\\boldsymbol{y})$. Therefore, the matrix $\\nabla_{\\boldsymbol{y}} \\rho^{a}(t, \\boldsymbol{y})$ exhibits non-negative diagonal entries and non-positive off-diagonal entries, with zero row sums. By Lemma 4.4, it is an $M_{0}$-matrix and thus an $M$-matrix.\n\nWe then seek the generalization of the above result to the whole space.\nTheorem 4.7. For all $\\boldsymbol{y} \\in \\mathbb{R}^{N}$, the following statements hold:\n(i) any matrix in $\\partial_{\\boldsymbol{y}} \\psi^{b}(\\boldsymbol{y})$ is element-wise uniformly bounded by some constant independent of $\\xi$. The matrix is non-positive and is diagonally dominant of column entries;\n(ii) any matrix in $\\partial_{\\boldsymbol{y}} \\psi^{a}(\\boldsymbol{y})$ is element-wise uniformly bounded by some constant independent of $\\xi$. The matrix is non-negative and is diagonally dominant of column entries;\n(iii) any matrix in $\\partial_{\\boldsymbol{y}} \\rho(t, \\boldsymbol{y})$ is an $Z_{+}$-matrix, and notably an $M_{0}$-matrix in the absence of $\\xi$.\n\nProof. We begin with the bid side. Fix any $\\boldsymbol{y} \\in \\mathbb{R}^{N}$. Since $\\rho^{b}$ is Lipschitz with respect to $\\boldsymbol{y}$, the set $\\partial_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ is the convex hull generated by matrices of the kind $\\lim _{\\boldsymbol{y}_{n} \\rightarrow \\boldsymbol{y}} \\nabla_{\\boldsymbol{y}} \\rho^{b}\\left(t, \\boldsymbol{y}_{n}\\right)$, where $\\rho^{b}$ is differentiable at $\\boldsymbol{y}_{n}$ for each $n$. Considering that Lemma 4.6 has studied $\\boldsymbol{y}$ such that $\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right) \\notin \\mathscr{D}^{b}$, it suffices to explore $\\boldsymbol{y}$ such that $\\Psi^{b}$ is not differentiable at $\\left(\\psi^{b}(\\boldsymbol{y}), \\boldsymbol{y}\\right)$. Scenarios in $\\mathscr{D}^{b}$ can be categorized into three regions:\n(i) there are multiple indices achieving the minimum, i.e., for some indices $j$ and $k$, it holds\n\n$$\n\\psi^{j, b}(\\boldsymbol{y})=\\psi^{k, b}(\\boldsymbol{y})=\\min _{l} \\psi^{l, b}(\\boldsymbol{y})\n$$\n\n(ii) there are multiple indices achieving the second minimum, i.e., for some indices $j$ and $k$, we set $l:=\\arg \\min _{i} \\psi^{i, b}(\\boldsymbol{y})$ and then the following holds\n\n$$\n\\min _{i \\neq j, k, l} \\psi^{i, b}(\\boldsymbol{y}) \\geq \\psi^{j, b}(\\boldsymbol{y})=\\psi^{k, b}(\\boldsymbol{y})>\\psi^{l, b}(\\boldsymbol{y})\n$$\n\n(iii) there exists some index $k$ such that it touches the truncation level:\n\n$$\n\\bar{\\psi}^{k, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{k}-\\bar{\\psi}^{k, b}(\\boldsymbol{y})\\right)= \\pm \\xi\n$$\n\nRegion (i) refers to the area where $\\Psi^{b}$ is not differentiable for the 'non-minimizing' indices. Given any indices $j, k$ with property (33), first we can observe that\n\n$$\n\\rho^{j, b}(t, \\boldsymbol{y})=\\rho^{k, b}(t, \\boldsymbol{y})=b_{t} \\Lambda(0)\n$$\n\nTherefore, the $j$-th and $k$-th rows in the (generalized) Jacobian matrix are $N$-dimensional zero vectors. Since $\\psi^{j, b}, \\psi^{k, b}$ are implicit functions, it further implies\n\n$$\n\\begin{aligned}\n& \\psi^{j, b}(\\boldsymbol{y})=\\psi^{k, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{j}-\\psi^{k, b}(\\boldsymbol{y})\\right) \\\\\n& \\psi^{k, b}(\\boldsymbol{y})=\\psi^{j, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{k}-\\psi^{j, b}(\\boldsymbol{y})\\right)\n\\end{aligned}\n$$\n\nfor any $\\boldsymbol{y}$ in region (i). Due to the fact that $\\left(\\delta^{*}\\right)^{\\prime} \\in(\\epsilon, 1)$ for some $\\epsilon>0$, we can deduce from (35) that\n\n$$\ny^{j}=y^{k} \\quad \\text { and } \\quad \\psi^{j, b}(\\boldsymbol{y})=-y^{j}-\\tilde{\\delta}^{*}(0)=-y^{k}-\\tilde{\\delta}^{*}(0)=\\psi^{k, b}(\\boldsymbol{y})\n$$\n\nfor any $\\boldsymbol{y}$ in region (i), where $\\tilde{\\delta}^{*}$ is the inverse function of $\\delta^{*}$. Based on (36), the implicit functions of the others now possess explicit formulae as\n\n$$\n\\begin{aligned}\n\\psi^{l, b}(\\boldsymbol{y}) & =\\psi^{j, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{l}-\\psi^{j, b}(\\boldsymbol{y})\\right) \\\\\n& =-y^{j}-\\tilde{\\delta}^{*}(0)+\\delta^{*}\\left(-y^{l}+y^{j}+\\tilde{\\delta}^{*}(0)\\right)=-y^{k}-\\tilde{\\delta}^{*}(0)+\\delta^{*}\\left(-y^{l}+y^{k}+\\tilde{\\delta}^{*}(0)\\right)\n\\end{aligned}\n$$\n\nfor $l \\neq j, k$. It suffices to consider $y^{j}$ only. We infer that $\\psi^{l, b}$ is decreasing in both $y^{l}$ and $y^{k}$. The partial derivative with respect to $y^{k}$ is no smaller than -1 , together with (36) implying the diagonal dominance of column entries. Bearing in mind that $j$ achieves the minimum, we then calculate the gradient of interactions\n\n$$\n\\nabla\\left(\\psi^{l, b}-\\psi^{j, b}\\right)(\\boldsymbol{y})=(\\cdots, \\underbrace{\\left(\\delta^{*}\\right)^{\\prime}\\left(-y^{l}+y^{j}+\\tilde{\\delta}^{*}(0)\\right)}_{j \\text {-th entry }}, \\cdots, \\underbrace{-\\left(\\delta^{*}\\right)^{\\prime}\\left(-y^{l}+y^{j}+\\tilde{\\delta}^{*}(0)\\right)}_{l \\text {-th entry }}, \\cdots)\n$$\n\nThe $l$-th entry of $\\nabla\\left(\\psi^{l, b}-\\psi^{j, b}\\right)$ is negative and its 'off-diagonal' entries are non-negative. Because $\\Lambda$ is decreasing, we conclude that $\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ is an $M_{0}$-matrix in region (i). The case that more than two indices satisfy property (33) can be discussed in an analogous manner.\n\nRegion (ii) refers to the area where $\\Psi^{b}$ is not differentiable for the 'minimizing' indices. Since the overlapping at the minimum value has been discussed, we now assume that $l$ is the unique minimizing index and consider the property\n\n$$\n\\min _{i \\neq j, k, l} \\psi^{i, b}(\\boldsymbol{y})>\\psi^{j, b}(\\boldsymbol{y})=\\psi^{k, b}(\\boldsymbol{y})>\\psi^{l, b}(\\boldsymbol{y})\n$$\n\nSince $\\psi^{j, b}, \\psi^{k, b}$ are implicit functions, we similarly have\n\n$$\n\\begin{aligned}\n\\psi^{j, b}(\\boldsymbol{y}) & =\\psi^{l, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{j}-\\psi^{l, b}(\\boldsymbol{y})\\right) \\\\\n\\psi^{k, b}(\\boldsymbol{y}) & =\\psi^{l, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{k}-\\psi^{l, b}(\\boldsymbol{y})\\right)\n\\end{aligned}\n$$\n\nand subsequently $y^{j}=y^{k}$, for any $\\boldsymbol{y}$ in region (ii). Let $\\mathcal{I}$ be the index set defined as $\\mathcal{I}=$ $\\{1, \\ldots, N\\} \\backslash k$. According to (38) and the continuity of implicit functions, there exists a neighborhood $\\mathscr{B} \\subseteq \\mathbb{R}^{N-1}$ of $\\left(y^{i}\\right)_{i \\in \\mathcal{I}}$ such that\n\n$$\n\\min _{i \\in \\mathcal{I}, i \\neq j, l} \\psi^{i, b}(\\boldsymbol{y})>\\psi^{j, b}(\\boldsymbol{y})>\\psi^{l, b}(\\boldsymbol{y})\n$$\n\nfor any $\\left(y^{i}\\right)_{i \\in \\mathcal{I}} \\in \\mathscr{B}$. Notice that $\\left(\\Psi^{i, b}\\right)_{i \\in \\mathcal{I}}$ is differentiable in $\\mathscr{B}$. While $\\left(\\psi^{i, b}\\right)_{i \\in \\mathcal{I}}$ is the implicit functions for $\\left(\\Psi^{i, b}\\right)_{i \\in \\mathcal{I}}$ in $\\mathscr{B}$, the uniqueness implies that $\\left(\\psi^{i, b}\\right)_{i \\in \\mathcal{I}}$ satisfies the property stated in Lemma 4.6. After applying the same argument for $k$, we can deduce in region (ii) that functions $\\psi^{j, b}$ and $\\psi^{k, b}$ are equivalent. Consequently, the resulting Jacobian $\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ is still an $M_{0}$-matrix. The case that more than two indices satisfy property (38) can be again discussed analogously.\n\nThe analysis of region (iii) is already included in the proof of Lemma 4.6. We can then conclude that $\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ is an $M$-matrix whenever it is well-defined. Recall that\n\n$$\n\\partial_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})=\\operatorname{co}\\left\\{\\lim _{n \\rightarrow \\infty} \\nabla_{\\boldsymbol{y}} \\rho^{b}\\left(t, \\boldsymbol{y}_{n}\\right): \\boldsymbol{y}_{n} \\rightarrow \\boldsymbol{y}, \\nabla_{\\boldsymbol{y}} \\rho^{b}\\left(t, \\boldsymbol{y}_{n}\\right) \\text { is well-defined }\\right\\}\n$$\n\nAlthough the convex combination of $M$-matrices may lead to a non- $M$-matrix, any matrix in $\\partial_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ must be a $Z_{+}$-matrix, considering any $M$-matrix has non-negative diagonal elements and non-positive off-diagonal elements. A similar discussion infers that any matrix in $\\partial_{\\boldsymbol{y}} \\rho^{a}(t, \\boldsymbol{y})$ is a $Z_{+}$-matrix. The statement that any matrix in $\\partial_{\\boldsymbol{y}} \\rho(t, \\boldsymbol{y})$ is an $Z_{+}$-matrix then follows from the sum rule in Theorem 9.4.", "tables": {}, "images": {}}, {"section_id": 6, "text": "# 5. General Game: Ordering Property and Decoupling Field \n\nWe will consider the homogeneous case for the global well-posedness. Similar to the linear scenario, the ordering property will be derived first, with an immediate application in removing the constraint $\\xi$. Moreover, the property simplifies the analysis from $Z_{+}$-matrices to $M_{0}$-matrices. Afterward, we will present the connection between the FBSDE and the characteristic BSDE. Let us begin with the following assumption:\n\nAssumption 5.1. (1) The agents are homogeneous in penalty coefficients. Specifically, there are bounded $\\phi:=\\left(\\phi_{t}\\right)_{t \\in[0, T]} \\in \\mathbb{H}^{2}$ and $A \\in L^{2}\\left(\\Omega, \\mathcal{F}_{T}\\right)$, such that $\\phi^{i}=\\phi$ and $A^{i}=A$ for all $i$.\n(2) The index of the agent indicates the rank of her initial inventory as follows:\n\n$$\nq_{0}^{1} \\leq q_{0}^{2} \\leq \\cdots \\leq q_{0}^{N-1} \\leq q_{0}^{N}\n$$\n\nIn analogy to the linear case, the ordering property under the general intensity function is presented in the following lemma, utilizing matrix properties in Theorem 4.7.\n\nLemma 5.2. Suppose the FBSDE (21) has a solution on $[0, T]$, then the corresponding equilibrium satisfies\n\n$$\n\\begin{gathered}\n\\psi^{1, b}\\left(\\boldsymbol{Y}_{t}\\right) \\leq \\psi^{2, b}\\left(\\boldsymbol{Y}_{t}\\right) \\leq \\cdots \\leq \\psi^{N-1, b}\\left(\\boldsymbol{Y}_{t}\\right) \\leq \\psi^{N, b}\\left(\\boldsymbol{Y}_{t}\\right) \\\\\n\\psi^{1, a}\\left(\\boldsymbol{Y}_{t}\\right) \\geq \\psi^{2, a}\\left(\\boldsymbol{Y}_{t}\\right) \\geq \\cdots \\geq \\psi^{N-1, a}\\left(\\boldsymbol{Y}_{t}\\right) \\geq \\psi^{N, a}\\left(\\boldsymbol{Y}_{t}\\right)\n\\end{gathered}\n$$\n\nalmost surely for all $t \\in[0, T]$.\nProof. Denote by $(\\boldsymbol{Q}, \\boldsymbol{Y}, \\boldsymbol{M})$ the solution of the FBSDE (21). For any $i \\in\\{1, \\ldots, N\\}$, we first define the function $\\varrho^{i}$ as\n\n$$\n\\begin{aligned}\n& b_{t} \\Lambda\\left(\\psi^{i, b}(\\boldsymbol{y})-\\bar{\\psi}^{i, b}(\\boldsymbol{y})\\right)-a_{t} \\Lambda\\left(\\psi^{i, a}(\\boldsymbol{y})-\\bar{\\psi}^{i, a}(\\boldsymbol{y})\\right) \\\\\n& \\quad=b_{t} \\Lambda\\left(\\psi^{i, b}(\\ldots, \\underbrace{y^{i}-y^{j}+y^{j}}_{\\text {i-th entry }}, \\ldots)-\\bar{\\psi}^{i, b}\\left(\\ldots, y^{i}-y^{j}+y^{j}, \\ldots\\right)\\right) \\\\\n& \\quad-a_{t} \\Lambda\\left(\\psi^{i, a}\\left(\\ldots, y^{i}-y^{j}+y^{j}, \\ldots\\right)-\\bar{\\psi}^{i, a}\\left(\\ldots, y^{i}-y^{j}+y^{j}, \\ldots\\right)\\right) \\\\\n& \\quad=\\varrho^{i}\\left(t, y^{i}-y^{j}\\right)\n\\end{aligned}\n$$\n\nwhere function $\\varrho^{i}$ is defined as\n\n$$\n\\begin{aligned}\n& \\varrho^{i}(t, x)=b_{t} \\Lambda\\left(\\psi^{i, b}(\\ldots, \\underbrace{x+y^{j}}_{\\text {i-th entry }}, \\ldots)-\\bar{\\psi}^{i, b}\\left(\\ldots, x+y^{j}, \\ldots\\right)\\right) \\\\\n& \\quad-a_{t} \\Lambda\\left(\\psi^{i, a}\\left(\\ldots, x+y^{j}, \\ldots\\right)-\\bar{\\psi}^{i, a}\\left(\\ldots, x+y^{j}, \\ldots\\right)\\right)\n\\end{aligned}\n$$\n\nfor a given vector $\\boldsymbol{y}$. According to Theorem 4.7, function $\\varrho^{i}$ is non-decreasing with respect to the second variable. We pick $j \\geq i$ as some other index and define function $\\varrho^{j}$ through the same trick on the $j$-th entry. Note that $\\varrho^{j}$ is also non-decreasing in the space variable. If one further set $(\\Delta Q, \\Delta Y, \\Delta M):=\\left(Q^{i}-Q^{j}, Y^{i}-Y^{j}, M^{i}-M^{j}\\right)$, the following can then be obtained:\n\n$$\nd \\Delta Q_{t}=\\left(\\varrho^{i}\\left(t, Y_{t}^{i}-Y_{t}^{j}\\right)-\\varrho^{i}\\left(t,-Y_{t}^{i}+Y_{t}^{j}\\right)\\right) d t=\\varrho\\left(t, Y_{t}^{i}-Y_{t}^{j}\\right) d t\n$$\n\nHere, function $\\varrho$ is defined as $\\varrho(t, x)=\\varrho^{i}(t, x)-\\varrho^{j}(t,-x)$ and it is non-decreasing with respect to $x$. Think of the case when $\\Delta Y_{t}=Y_{t}^{i}-Y_{t}^{j}=0$. Since $\\psi^{i, b}, \\psi^{j, b}$ are implicit functions, it holds that\n\n$$\n\\begin{aligned}\n& \\psi^{i, b}(\\boldsymbol{y})=\\left[\\bar{\\psi}^{i, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{i}-\\bar{\\psi}^{i, b}(\\boldsymbol{y})\\right)\\right] \\vee(-\\xi) \\wedge \\xi \\\\\n& \\psi^{j, b}(\\boldsymbol{y})=\\left[\\bar{\\psi}^{j, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{j}-\\bar{\\psi}^{j, b}(\\boldsymbol{y})\\right)\\right] \\vee(-\\xi) \\wedge \\xi\n\\end{aligned}\n$$\n\nGiven $y^{i}=y^{j}$, let us assume that $\\psi^{i, b}(\\boldsymbol{y})>\\psi^{j, b}(\\boldsymbol{y})$. The definition first yields\n\n$$\n\\bar{\\psi}^{i, b}(\\boldsymbol{y})=\\psi^{j, b}(\\boldsymbol{y}) \\wedge \\min _{k \\neq i, j} \\psi^{k, b}(\\boldsymbol{y}) \\leq \\psi^{i, b}(\\boldsymbol{y}) \\wedge \\min _{k \\neq i, j} \\psi^{k, b}(\\boldsymbol{y})=\\bar{\\psi}^{j, b}(\\boldsymbol{y})\n$$\n\nSince $\\left(\\delta^{*}\\right)^{\\prime} \\in(0,1)$, the function defined by\n\n$$\nz \\mapsto z+\\delta^{*}\\left(-y^{i}-z\\right)\n$$\n\nis increasing. Consequently, this leads to a contradiction that\n\n$$\n\\bar{\\psi}^{i, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{i}-\\bar{\\psi}^{i, b}(\\boldsymbol{y})\\right) \\leq \\bar{\\psi}^{j, b}(\\boldsymbol{y})+\\delta^{*}\\left(-y^{j}-\\bar{\\psi}^{j, b}(\\boldsymbol{y})\\right)\n$$\n\nThe contradiction when $\\psi^{i, b}(\\boldsymbol{y})<\\psi^{j, b}(\\boldsymbol{y})$ can be found symmetrically. Since the relation for $\\psi^{i, a}$ and $\\psi^{j, a}$ can be analyzed similarly, it is now evident that $\\Delta Y_{t}=Y_{t}^{i}-Y_{t}^{j}=0$ yields $\\psi^{i, b}\\left(\\boldsymbol{Y}_{t}\\right)=\\psi^{j, b}\\left(\\boldsymbol{Y}_{t}\\right), \\psi^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)=\\psi^{j, a}\\left(\\boldsymbol{Y}_{t}\\right)$, and thus $\\varrho(t, 0)=0$. Literally, agent $i$ and $j$ execute the same control. Consequently, we can write\n\n$$\nd \\Delta Q_{t}=\\varrho\\left(t, \\Delta Y_{t}\\right) d t=\\left(\\varrho\\left(t, \\Delta Y_{t}\\right)-\\varrho(t, 0)\\right) d t=\\iota_{t} \\Delta Y_{t} d t\n$$\n\nwhere $\\iota \\in \\mathbb{H}^{2}$ is non-negative and bounded because of the Lipschitz property of $\\varrho$. One can now see $(\\Delta Q, \\Delta Y, \\Delta M)$ solves the FBSDE\n\n$$\n\\left\\{\\begin{aligned}\nd \\Delta Q_{t} & =\\iota_{t} \\Delta Y_{t} d t \\\\\nd \\Delta Y_{t} & =2 \\phi_{t} \\Delta Q_{t} d t+d \\Delta M_{t} \\\\\n\\Delta Q_{0} & =q_{0}^{i}-q_{0}^{j}, \\quad \\Delta Y_{T}=-2 A \\Delta Q_{T}\n\\end{aligned}\\right.\n$$\n\nIn accordance with [24], not only the above FBSDE is well-posed, but also we know $\\Delta Q$ always has the same sign with $q_{0}^{i}-q_{0}^{j}$ and $\\Delta Y$ has a different sign with $\\Delta Q$. Hence, when $q_{0}^{i}-q_{0}^{j} \\leq 0$, it follows that $\\Delta Q_{t} \\leq 0$ and $\\Delta Y_{t} \\geq 0$.\n\nIt suffices to study how $\\Delta y$ affects the controls of agent $i$ and $j$. For convenience, here we write $\\psi^{b}\\left(y^{i}, y^{j}\\right)=\\psi^{b}\\left(\\ldots, y^{i}, \\ldots, y^{j}, \\ldots\\right)$. By the mean value theorem 5.11 , we can have\n\n$$\n\\binom{\\psi^{i, b}\\left(y^{i}, y^{j}\\right)}{\\psi^{j, b}\\left(y^{i}, y^{j}\\right)}-\\binom{\\psi^{i, b}\\left(y^{i}, y^{i}\\right)}{\\psi^{j, b}\\left(y^{i}, y^{i}\\right)}=\\boldsymbol{K}\\binom{0}{-\\Delta y}=\\left(\\begin{array}{cc}\nk_{11} & k_{12} \\\\\nk_{21} & k_{22}\n\\end{array}\\right)\\binom{0}{-\\Delta y}\n$$\n\nwhere $\\boldsymbol{K} \\in \\mathbb{R}^{2 \\times 2}$ is the convex combination of matrices with properties described in Theorem 4.7. Therefore, matrix $\\boldsymbol{K}$ has non-positive entries and is diagonally dominant of column entries. We can further deduce\n\n$$\n\\begin{gathered}\n\\psi^{i, b}\\left(y^{i}, y^{j}\\right)-\\psi^{i, b}\\left(y^{i}, y^{i}\\right)-\\psi^{j, b}\\left(y^{i}, y^{j}\\right)+\\psi^{j, b}\\left(y^{i}, y^{i}\\right)=-k_{12} \\Delta y+k_{22} \\Delta y \\\\\n\\psi^{i, b}\\left(y^{i}, y^{j}\\right)-\\psi^{j, b}\\left(y^{i}, y^{j}\\right)=\\left(k_{22}-k_{12}\\right) \\Delta y\n\\end{gathered}\n$$\n\nGiven $\\Delta y \\geq 0$, the fact that $k_{22} \\leq k_{12} \\leq 0$ yields $\\psi^{i, b}\\left(y^{i}, y^{j}\\right)-\\psi^{j, b}\\left(y^{i}, y^{j}\\right) \\leq 0$. The ask side can be discussed similarly.\n\nAs the first application of the ordering property, we use it in the following result to remove the regularization term $\\xi$ in the $\\mathbb{A}$. This is achieved by establishing a bound for the solution that is independent of $\\xi$.\n\nProposition 5.3. Suppose that the FBSDE (21) has a solution $(\\boldsymbol{Q}, \\boldsymbol{Y}, \\boldsymbol{M})$ on $[0, T]$ and $\\xi \\geq$ $\\left|\\delta^{*}(0)\\right|$, then it holds almost surely that $\\left|\\boldsymbol{Y}_{t}^{i}\\right| \\leq C$ for any $i$ and $t$, where $C>0$ is some constant independent of $\\xi$.\n\nProof. Given the ordering property in Lemma 5.2, the forward equations for $i \\in\\{2, \\ldots, N-1\\}$ now becomes\n\n$$\n\\begin{aligned}\nd Q_{t}^{i} & =b_{t} \\Lambda\\left(\\psi^{i, b}\\left(\\boldsymbol{Y}_{t}\\right)-\\bar{\\psi}^{i, b}\\left(\\boldsymbol{Y}_{t}\\right)\\right) d t-a_{t} \\Lambda\\left(\\psi^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)-\\bar{\\psi}^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)\\right) d t \\\\\n& =b_{t} \\Lambda\\left(\\psi^{i, b}\\left(\\boldsymbol{Y}_{t}\\right)-\\psi^{1, b}\\left(\\boldsymbol{Y}_{t}\\right)\\right) d t-a_{t} \\Lambda\\left(\\psi^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)-\\psi^{N, a}\\left(\\boldsymbol{Y}_{t}\\right)\\right) d t\n\\end{aligned}\n$$\n\nSince $\\psi^{i, b}\\left(\\boldsymbol{Y}_{t}\\right) \\geq \\psi^{1, b}\\left(\\boldsymbol{Y}_{t}\\right)$ and $\\psi^{i, a}\\left(\\boldsymbol{Y}_{t}\\right) \\geq \\psi^{N, a}\\left(\\boldsymbol{Y}_{t}\\right)$, it infers $\\left|Q_{t}^{i}\\right| \\leq\\left|q_{0}^{i}\\right|+(\\bar{a}+\\bar{b}) \\Lambda(0) T$ for all $t \\in[0, T]$. Due to the fact that\n\n$$\nY_{t}^{i}=\\mathbb{E}_{t}\\left[-2 A Q_{T}^{i}-2 \\int_{t}^{T} \\phi_{s} Q_{s}^{i} d s\\right]\n$$\n\nwe can then conclude $\\left(Y^{i}\\right)_{i \\in\\{2, \\ldots, N-1\\}}$ are uniformly bounded by some constant independent of the constraint $\\xi$. For agent 1 , we first observe\n\n$$\nQ_{t}^{1} \\geq q_{0}^{1}-\\int_{0}^{t} a_{s} \\Lambda\\left(\\psi^{1, a}\\left(\\boldsymbol{Y}_{s}\\right)-\\psi^{N, a}\\left(\\boldsymbol{Y}_{s}\\right)\\right) d s \\geq q_{0}^{1}-\\bar{a} \\Lambda(0) T\n$$\n\nBy the expression in (40), a lower bound of $Q^{1}$ provides an upper bound for $Y^{1}$ that is also independent of $\\xi$. One can obtain a uniform lower bound for $Y^{N}$ from a symmetric argument. Via the $\\mathbb{Z}_{+}$-matrix property in Theorem 4.7, the function\n\n$$\n\\psi^{1, b}\\left(Y_{t}^{1}, Y_{t}^{2}, \\ldots, Y_{t}^{N-1}, Y_{t}^{N}\\right)-\\psi^{2, b}\\left(Y_{t}^{1}, Y_{t}^{2}, \\ldots, Y_{t}^{N-1}, Y_{t}^{N}\\right)\n$$\n\nis non-increasing with respect to $Y_{t}^{1}$ and non-decreasing in $\\left\\{Y_{t}^{2}, \\ldots, Y_{t}^{N}\\right\\}$, the generalized derivatives of which are all bounded element-wise by some constant independent of $\\xi$. In addition, considering the following facts:\n(1) $Y^{1}$ is upper bounded and $Y^{N}$ is lower bounded;\n(2) $\\left(Y^{j}\\right)_{j \\in\\{2, \\ldots, N-1\\}}$ are bounded;\n(3) all above bounds are independent of $\\xi$;\n(4) $\\psi^{1, b}(0,0, \\ldots, 0)-\\psi^{2, b}(0,0, \\ldots, 0)=0$,\nwe can derive a lower bound for expression (41) and it leads to an upper bound for $Q^{1}$, both of which are again independent of $\\xi$. It follows $Y^{1}$ are bounded by some constant independent of $\\xi$; the same is true for $Y^{N}$ through a similar argument. On the other hand, it can be directly checked that $\\psi^{b}(\\mathbf{0})=\\mathbf{0}$ provided $\\xi \\geq\\left|\\delta^{*}(0)\\right|$. Together with the boundedness of $\\boldsymbol{Y}$, the Lipschitz continuity of $\\psi^{b}$ yields $\\psi^{i, b}\\left(\\boldsymbol{Y}_{t}\\right) \\leq C$ for all $i$ and $t$, where $C$ is a constant independent of $\\xi$.\n\nHence, we force $\\xi$ to be large enough.\n\nAssumption 5.4. The constraint $\\xi$ is chosen to be larger than the constant specified in Theorem 5.3. As a result, the truncation has no effect.\n\nRemark 5.5. The absence of the truncation $\\xi$ renders the FBSDE (21) non-Lipschitz. We will still regard (21) as a Lipschitz FBSDE due to the boundedness of its solution. From the perspective of the non-Lipschitz FBSDE, what we will find is the unique bounded solution.\n\nThe following statement is then an immediate consequence of Theorem 4.7.\nTheorem 5.6. For any $\\boldsymbol{y} \\in \\mathbb{R}^{N}$, any matrix in $\\partial_{y} \\rho(t, \\boldsymbol{y})$ is an $M_{0}$-matrix.\nProof. When $\\xi$ has no effect, matrices $\\nabla_{\\boldsymbol{y}} \\rho^{b}(t, \\boldsymbol{y})$ and $\\nabla_{\\boldsymbol{y}} \\rho^{a}(t, \\boldsymbol{y})$ are always $M_{0}$-matrix whenever differentiable, according to the proof of Theorem 4.7. It suffices to observe that $M_{0}$-matrices are stable under convex combinations.\n\nThanks to the Lipschitz property of the FBSDE (21), it is well-known that there exists $\\Delta>0$ being small enough, such that (21) is well-posed on the horizon $[T-\\Delta, T]$ via the contraction mapping principle; i.e., the original initial time 0 is replaced by $T-\\Delta$. Given any $t \\in[T-\\Delta, T]$ and $\\boldsymbol{q} \\in \\mathbb{R}^{N}$ as the initial time and condition, there exists a unique solution $\\left(\\boldsymbol{Q}^{t, \\boldsymbol{q}}, \\boldsymbol{Y}^{t, \\boldsymbol{q}}, \\boldsymbol{M}^{t, \\boldsymbol{q}}\\right)$ to (21), where the superscript denotes the dependence on the initial data. We can then define a function $u:[T-\\Delta, T] \\times \\Omega \\times \\mathbb{R}^{N} \\rightarrow \\mathbb{R}^{N}$ through\n\n$$\nu(t, \\boldsymbol{q}):=\\boldsymbol{Y}^{t, \\boldsymbol{q}}\n$$\n\nwhich is known as the decoupling field.\nDefinition 5.7. Let $t \\in[0, T]$. A function $u:[t, T] \\times \\Omega \\times \\mathbb{R}^{N} \\rightarrow \\mathbb{R}^{N}$, with $u(T, \\boldsymbol{q})=-2 A \\boldsymbol{q}$ a.e., is called a decoupling field for the FBSDE on $[t, T]$ if, for all $t_{1}, t_{2} \\in[t, T]$ with $t_{1}<t_{2}$ and any $\\mathcal{F}_{t_{1}}$-measurable $\\boldsymbol{\\eta}: \\Omega \\rightarrow \\mathbb{R}^{N}$, there exist progressively measurable processes $(\\boldsymbol{Q}, \\boldsymbol{Y}, \\boldsymbol{Z})$ on $\\left[t_{1}, t_{2}\\right]$ such that\n\n$$\n\\begin{aligned}\n& \\boldsymbol{Q}_{s}=\\boldsymbol{\\eta}+\\int_{t_{1}}^{s} \\rho\\left(r, \\boldsymbol{Y}_{r}\\right) d r \\\\\n& \\boldsymbol{Y}_{s}=\\boldsymbol{Y}_{t_{2}}-\\int_{s}^{t_{2}} 2 \\phi_{r} \\boldsymbol{Q}_{r} d r-\\int_{s}^{t_{2}} \\boldsymbol{Z}_{r} d W_{r} \\\\\n& \\boldsymbol{Y}_{s}=u\\left(s, \\boldsymbol{Q}_{s}\\right)\n\\end{aligned}\n$$\n\nfor all $s \\in\\left[t_{1}, t_{2}\\right]$. In particular, we want all integrals to be well defined.\nThe theory of decoupling fields, originally introduced by [30] for one-dimensional equations, has been extended to multi-dimensional equations through subsequent works such as [18], [17], and [3]. The fundamental idea is that, if the decoupling field can be regularly extended over the whole prescribed time horizon, it then ensures the well-posedness of the FBSDE on that horizon. Some essential results are provided below, but we refer the reader to [3] for an excellent short summary.\n\nDefinition 5.8 ([3]). Denote by $\\mathscr{L}_{u\\left(s, \\cdot\\right)}$ the Lipschitz coefficient of $u$ with respect to the space variable at time $s$ :\n\n$$\n\\mathscr{L}_{u\\left(s, \\cdot\\right)}:=\\inf \\left\\{L>0:\\left|u\\left(s, \\boldsymbol{q}^{\\prime}\\right)-u(s, \\boldsymbol{q})\\right| \\leq L \\mid \\boldsymbol{q}^{\\prime}-\\boldsymbol{q}\\right\\} \\text { almost surely for all } \\boldsymbol{q}^{\\prime}, \\boldsymbol{q} \\in \\mathbb{R}^{N}\\right\\}\n$$\n\nA decoupling field $u:[t, T] \\times \\Omega \\times \\mathbb{R}^{N} \\rightarrow \\mathbb{R}^{N}$ is called (weakly) regular if\n\n$$\n\\sup _{s \\in[t, T]} \\mathscr{L}_{u\\left(s, \\cdot\\right)}<\\infty \\quad \\text { and } \\quad \\sup _{s \\in[t, T]}\\|u(s, \\cdot, 0)\\|_{\\infty}<\\infty\n$$\n\nwhere $\\|\\cdot\\|_{\\infty}$ denotes the $L^{\\infty}$-norm of random variables.\nThe decoupling field (42) constructed by the contraction mapping principle is indeed regular. Therefore, one can apply the fixed point method again, extending the definition of the decoupling field to a longer horizon. The first part of the following theorem provides a generalized result of this constructive procedure, while the second part reveals the connection between the decoupling field and the well-posedness of FBSDEs.\n\nTheorem 5.9 ([3]). (1) There exists a time $t \\in[0, T]$ such that the FBSDE has a unique (up to modification) decoupling field $u$ on $[t, T]$ that is also regular.\n(2) If there exists a regular decoupling field $u$ of the corresponding FBSDE on some interval $[t, T]$, then for any initial condition $\\boldsymbol{Q}_{t}=\\eta \\in \\mathbb{R}^{N}$ there is a unique solution $(\\boldsymbol{Q}, \\boldsymbol{Y}, \\boldsymbol{Z})$ of the FBSDE on $[t, T]$ satisfying\n\n$$\n\\sup _{s \\in[t, T]} \\mathbb{E}\\left[\\left|\\boldsymbol{Q}_{s}\\right|^{2}\\right]+\\sup _{s \\in[t, T]} \\mathbb{E}\\left[\\left|\\boldsymbol{Y}_{s}\\right|^{2}\\right]+\\mathbb{E}\\left[\\int_{t}^{T}\\left|\\boldsymbol{Z}_{s}\\right|^{2} d s\\right]<\\infty\n$$\n\nSince the extension of the decoupling field is a key consideration, several important questions arise: (1) How far can the decoupling field be extended? (2) What are the implications if it cannot be extended further? Here are some answers to these questions:\n\nTheorem 5.10 ([3]). Define the maximal interval $I_{\\max } \\subseteq[0, T]$ of the FBSDE as the union of all intervals $[t, T] \\subseteq[0, T]$, such that there exists a regular decoupling field $u$ on $[t, T]$. Then, there exists a unique regular decoupling field $u$ on $I_{\\max }$. Furthermore, either $I_{\\max }=[0, T]$ or $I_{\\max }=\\left(t_{\\min }, T\\right]$ with $t_{\\min } \\in[0, T)$. In the latter case, we have $\\lim _{t \\searrow t_{\\min }} \\mathscr{L}_{u\\left(t,\\cdot\\right)}=\\infty$.\nThe regularity of the decoupling field, which ensures the well-posedness of FBSDEs, is studied in the latter theorem through the analysis of the corresponding characteristic BSDE. The ideas of variational FBSDEs and characteristic BSDEs are initially introduced for one-dimensional FBSDEs in [30]. While [27] presents a one-dimensional characteristic BSDE for multi-dimensional equations, the construction method suffers from the loss of critical information from the original FBSDE. The resulting BSDE is hence difficult to analyze. To overcome this challenge, we introduce a multi-dimensional characteristic BSDE that preserves more information from the original FBSDE, albeit at the expense of increased dimension. A mean value theorem in non-smooth analysis is presented below.\n\nTheorem 5.11 ([13]). Let $F$ be Lipschitz on an open convex set $U$ in $\\mathbb{R}^{n}$, and let $x$ and $y$ be two points in $U$. Then, it holds that\n\n$$\nF(y)-F(x) \\in \\operatorname{co}\\{k \\cdot(y-x) \\mid k \\in \\partial F(z) \\text { and } z \\text { is in the line segment between } x \\text { and } y\\}\n$$\n\nSuch mean value theorem is utilized in the proof of the following theorem, which establishes a connection between the well-posedness of the FBSDE and that of the backward stochastic Riccati equation (BSRE).\n\nTheorem 5.12. Consider the BSRE of the following type:\n\n$$\nd \\mathcal{X}_{t}=\\left(2 \\phi_{t} I-\\mathcal{X}_{t} \\mathcal{B}_{t} \\mathcal{X}_{t}\\right) d t+\\mathcal{Z}_{t} d W_{t}, \\quad \\mathcal{X}_{T}=-2 A I\n$$\n\nNote that $\\mathcal{X}_{t}$ and $\\mathcal{B}_{t}$ are $N \\times N$ matrices, and $I$ represents the identity matrix. Additionally, the process $\\mathcal{B}$ satisfies the following: (1) each entry is a bounded process in $\\mathbb{H}^{2}$, and (2) the matrix $\\mathcal{B}_{t}$ is of $M_{0}$-type for every $t$.\n\nSuppose the BSRE (43) accepts a unique solution $\\mathcal{X}$ such that each entry is a bounded process in $\\mathbb{H}^{2}$, then the FBSDE (21) has a unique solution $(\\boldsymbol{Q}, \\boldsymbol{Y}, \\boldsymbol{M})$ in $\\left(\\mathbb{S}^{2} \\times \\mathbb{H}^{2} \\times \\mathbb{M}\\right)^{N}$.\n\nProof. Based the Lipschitz nature of the FBSDE, there exists some $s \\in(0, T)$ such that: (1) FBSDE (21) has a unique regular decoupling field $u$ on the horizon $[s, T]$; (2) it also accepts a unique solution on this horizon with any deterministic initial condition. Fixing any $\\boldsymbol{\\eta}, \\tilde{\\boldsymbol{\\eta}} \\in \\mathbb{R}^{N}$ as two initial data, let us denote by $(\\boldsymbol{Q}, \\boldsymbol{Y}, \\boldsymbol{M})$ and $(\\tilde{\\boldsymbol{Q}}, \\tilde{\\boldsymbol{Y}}, \\tilde{\\boldsymbol{M}})$ the two corresponding solutions. It then holds:\n\n$$\n\\begin{aligned}\n& \\boldsymbol{Q}_{t}=\\boldsymbol{\\eta}+\\int_{s}^{t} \\rho\\left(r, \\boldsymbol{Y}_{r}\\right) d r \\\\\n& \\boldsymbol{Y}_{t}=-2 A \\boldsymbol{Q}_{T}-\\int_{t}^{T} 2 \\phi_{r} \\boldsymbol{Q}_{r} d r-\\int_{t}^{T} d \\boldsymbol{M}_{r} \\\\\n& \\boldsymbol{Y}_{t}=u\\left(t, \\boldsymbol{Q}_{t}\\right)\n\\end{aligned}\n$$\n\nfor any $t \\in[s, T]$; the case of $(\\tilde{\\boldsymbol{Q}}, \\tilde{\\boldsymbol{Y}}, \\tilde{\\boldsymbol{M}})$ is similar. If we define $(\\mathscr{Q}, \\mathscr{Y}, \\mathscr{M}):=(\\tilde{\\boldsymbol{Q}}-\\boldsymbol{Q}, \\tilde{\\boldsymbol{Y}}-$ $\\boldsymbol{Y}, \\tilde{\\boldsymbol{M}}-\\boldsymbol{M})$, by taking the difference of two FBSDEs, it is straightforward to see that the backward equation becomes\n\n$$\n\\mathscr{Y}_{t}=-2 A \\mathscr{Q}_{T}-\\int_{t}^{T} 2 \\phi_{r} \\mathscr{Q}_{r} d r-\\int_{t}^{T} d \\mathscr{M}_{r}\n$$\n\nAccording to Theorem 5.11, the forward equation can be obtained by\n\n$$\nd \\mathscr{Q}_{t}=\\left[\\rho\\left(t, \\tilde{\\boldsymbol{Y}}_{t}\\right)-\\rho\\left(t, \\boldsymbol{Y}_{t}\\right)\\right] d t=\\mathcal{B}_{t} \\mathscr{Y}_{t} d t\n$$\n\nwhere $\\mathcal{B}:=\\left(\\mathcal{B}_{t}\\right)_{t \\in[0, T]}$ is an $M_{0}$-matrix for any $t$ by Theorem 5.6. Indeed, $M_{0}$-matrices are closed under convex combinations. It is also not hard to see that $\\mathcal{B}$ is continuous with respect to time and element-wise bounded. We can then conclude that $(\\mathscr{Q}, \\mathscr{Y}, \\mathscr{M})$ solves the FBSDE\n\n$$\n\\left\\{\\begin{aligned}\nd \\mathscr{Q}_{t} & =\\mathcal{B}_{t} \\mathscr{Y}_{t} d t \\\\\nd \\mathscr{Y}_{t} & =2 \\phi_{t} \\mathscr{Q}_{t} d t+d \\mathscr{M}_{t} \\\\\n\\mathscr{Q}_{s} & =\\tilde{\\boldsymbol{\\eta}}-\\boldsymbol{\\eta}, \\quad \\mathscr{Y}_{T}=-2 A \\mathscr{Q}_{T}\n\\end{aligned}\\right.\n$$\n\nEquation (44) is the multi-dimensional version of the variational FBSDE in [30].\nTo examine the variational FBSDE, its linear structure suggests the affine ansatz\n\n$$\n\\mathscr{Y}_{t}=v\\left(t, \\mathscr{Q}_{t}\\right):=\\mathcal{X}_{t} \\mathscr{Q}_{t}\n$$\n\nfor some matrix-valued process $\\mathcal{X}$ to be specified. Via matching the coefficients in\n\n$$\nd \\mathscr{Y}_{t}=\\left(d \\mathcal{X}_{t}+\\mathcal{X}_{t} \\mathcal{B}_{t} \\mathcal{X}_{t} d t\\right) \\mathscr{Q}_{t}=2 \\phi_{t} \\mathscr{Q}_{t} d t+d \\mathscr{M}_{t}\n$$\n\nit turns out that $\\mathcal{X}$ solves the BSRE\n\n$$\nd \\mathcal{X}_{t}=\\left(2 \\phi_{t} I-\\mathcal{X}_{t} \\mathcal{B}_{t} \\mathcal{X}_{t}\\right) d t+\\mathcal{Z}_{t} d W_{t}, \\quad \\mathcal{X}_{T}=-2 A I\n$$\n\nEquation (46) is the multi-dimensional generalization of the characteristic BSDE in [30]. The existence of a unique bounded $\\mathcal{X}$ is ensured by the assumption. Upon examining the definition, we know the function $v$ defined in (45) serves as the unique regular decoupling field for the FBSDE (44) due to the boundedness of $\\mathcal{X}$. Here, we only need to focus on the bounded solution $\\mathcal{X}$. Indeed, the unboundedness will render the decoupling field non-Lipschitz, contradicting the existence of a regular decoupling field on $[s, T]$. Given the variational FBSDE (44), we can infer\n\n$$\n|u(s, \\tilde{\\eta})-u(s, \\eta)|=\\left|\\tilde{\\boldsymbol{Y}}_{s}-\\boldsymbol{Y}_{s}\\right|=\\left|\\mathscr{Y}_{s}\\right|=\\left|\\mathcal{X}_{s} \\mathscr{Q}_{s}\\right| \\leq\\left\\|\\mathcal{X}_{s}\\right\\|_{2} \\cdot|\\tilde{\\eta}-\\eta|\n$$\n\nwhere $\\left\\|\\mathcal{X}_{s}\\right\\|_{2}$ denotes the spectral norm of matrices. Since the BSRE is well-posed on the entire horizon and the solution $\\mathcal{X}$ is bounded, the estimate (47) infers that there is no $t_{\\min } \\geq 0$, such that $\\lim _{s \\searrow t_{\\min }} \\mathscr{L}_{u\\left(s, \\cdot\\right)}=\\infty$. Consequently, the decoupling field $u$ can be extended to the entire horizon $[0, T]$ and the FBSDE is then globally well-posed.", "tables": {}, "images": {}}, {"section_id": 7, "text": "# 6. General Game: Well-posedness and Properties \n\nRevisiting the linear case, it becomes evident that the ordering property plays a pivotal role in simplifying the $N$-player game down to a four-player scenario. This quartet comprises agents numbered $1,2, N-1$, and $N$, specifically those occupying the highest and lowest inventory levels. We can even condense this four-player dimension into just two when the competition is complete at the boundary, that is to say,\n\n$$\n\\psi^{1, b}\\left(\\boldsymbol{Y}_{t}\\right)=\\inf _{i \\neq 1} \\psi^{i, b}\\left(\\boldsymbol{Y}_{t}\\right) \\quad \\text { and } \\quad \\psi^{N, a}\\left(\\boldsymbol{Y}_{t}\\right)=\\inf _{i \\neq N} \\psi^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)\n$$\n\nfor all $t$. For a finite number of players, case (48) happens if and only if $q_{0}^{1}=q_{0}^{2}$ and $q_{0}^{N-1}=q_{0}^{N}$ because\n\n$$\n\\psi^{1, b}\\left(\\boldsymbol{Y}_{t}\\right)=\\psi^{2, b}\\left(\\boldsymbol{Y}_{t}\\right)=\\min _{i} \\psi^{i, b}\\left(\\boldsymbol{Y}_{t}\\right) \\quad \\text { and } \\quad \\psi^{N, a}\\left(\\boldsymbol{Y}_{t}\\right)=\\psi^{N-1, a}\\left(\\boldsymbol{Y}_{t}\\right)=\\min _{i} \\psi^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)\n$$\n\nas a direct consequence of Lemma (5.2). In this scenario, it suffices to solve the two-dimensional BSRE (43) since agent 2 (resp. $N-1$ ) is a 'copy' of agent 1 (resp. $N$ ). Utilizing this finite-player characterization, we investigate another scenario in an infinite-player setting, where identical players are no longer necessary.\n\nProposition 6.1. Assume the BSRE (43) is well-posed when $N=2$. Consider an infinite number of players indexed by $\\mathcal{I}$ with initial inventories satisfying $\\sup _{i \\in \\mathcal{I}}\\left|q_{0}^{i}\\right|<\\infty$. Suppose that there exist no-duplicate sequences $\\left(k_{n}\\right)_{n \\in \\mathbb{N}},\\left(l_{n}\\right)_{n \\in \\mathbb{N}} \\subseteq \\mathcal{I}$ such that\n\n$$\n\\lim _{n \\rightarrow \\infty} q_{0}^{k_{n}}=\\inf _{i \\in \\mathcal{I}} q_{0}^{i} \\quad \\text { and } \\quad \\lim _{n \\rightarrow \\infty} q_{0}^{l_{n}}=\\sup _{i \\in \\mathcal{I}} q_{0}^{i}\n$$\n\nthen (48) holds and there exists a Nash equilibrium.\nProof. Let $\\tilde{1}, \\tilde{2}, \\tilde{3}$ and $\\tilde{4}$ be four artificial players with initial inventories given by\n\n$$\nq_{0}^{\\tilde{1}}=q_{0}^{\\tilde{2}}=\\inf _{i \\in \\mathcal{I}} q_{0}^{i} \\quad \\text { and } \\quad q_{0}^{\\tilde{3}}=q_{0}^{\\tilde{4}}=\\sup _{i \\in \\mathcal{I}} q_{0}^{i}\n$$\n\nWe look at the four-player game of $(\\tilde{1}, \\tilde{2}, \\tilde{3}, \\tilde{4})$, the equilibrium of which exists by the wellposedness of two-dimensional BSRE (43) discussed above. Denote by $\\left(\\boldsymbol{\\beta}^{\\tilde{1}}, \\boldsymbol{\\beta}^{\\tilde{2}}, \\boldsymbol{\\beta}^{\\tilde{3}}, \\boldsymbol{\\beta}^{\\tilde{4}}\\right)$ the equilibrium profile and it holds for all $t$ that\n\n$$\n\\begin{aligned}\n& \\beta_{t}^{\\tilde{1}, b}=\\beta_{t}^{\\tilde{2}, b} \\leq \\beta_{t}^{\\tilde{3}, b}=\\beta_{t}^{\\tilde{4}, b} \\\\\n& \\beta_{t}^{\\tilde{4}, a}=\\beta_{t}^{\\tilde{3}, a} \\leq \\beta_{t}^{\\tilde{2}, a}=\\beta_{t}^{\\tilde{4}, a}\n\\end{aligned}\n$$\n\nNote that $\\left(\\boldsymbol{\\beta}^{\\tilde{1}}, \\boldsymbol{\\beta}^{\\tilde{2}}, \\boldsymbol{\\beta}^{\\tilde{3}}, \\boldsymbol{\\beta}^{\\tilde{4}}\\right)$ are all bounded due to Proposition 5.3. If processes $\\beta^{\\tilde{4}, a}$ and $\\beta^{\\tilde{1}, b}$ are regarded as the pseudo-best ask and bid strategies, for agent $i \\in \\mathcal{I}$ let us consider the stochastic optimal control problem, where the inventory controlled by $\\boldsymbol{\\delta}^{i} \\in \\mathbb{H}^{2} \\times \\mathbb{H}^{2}$ reads\n\n$$\nd Q_{t}^{i}=b_{t} \\Lambda\\left(\\delta_{t}^{i, b}-\\beta_{t}^{\\tilde{1}, b}\\right) d t-a_{t} \\Lambda\\left(\\delta_{t}^{i, a}-\\beta_{t}^{\\tilde{4}, a}\\right) d t\n$$\n\nThe agent $i$ aims at maximizing the associated control-version objective functional\n\n$$\n\\mathbb{E}\\left[\\int_{0}^{T} \\delta_{t}^{i, a} a_{t} \\Lambda\\left(\\delta_{t}^{i, a}-\\beta_{t}^{\\overline{\\mathbb{1}}, a}\\right) d t+\\int_{0}^{T} \\delta_{t}^{i, b} b_{t} \\Lambda\\left(\\delta_{t}^{i, b}-\\beta_{t}^{\\overline{1}, b}\\right) d t-\\int_{0}^{T} \\phi_{t}\\left(Q_{t}^{i}\\right)^{2} d t-A\\left(Q_{T}^{i}\\right)^{2}\\right]\n$$\n\nThe control problem above is slightly more general than the one studied in [24], where the original best ask and bid strategies $(0,0)$ is replaced by $\\left(\\beta^{\\overline{4}, a}, \\beta^{\\overline{1}, b}\\right)$. However, the stochastic maximum principle can still be applied to obtain the optimal feedback control\n\n$$\n\\hat{\\delta}_{t}^{i, a}=\\beta_{t}^{\\overline{4}, a}+\\delta^{*}\\left(Y_{t}^{i}-\\beta_{t}^{\\overline{4}, a}\\right) \\quad \\text { and } \\quad \\hat{\\delta}_{t}^{i, b}=\\beta_{t}^{\\overline{1}, b}+\\delta^{*}\\left(-Y_{t}^{i}-\\beta_{t}^{\\overline{1}, b}\\right)\n$$\n\nwhere the adjoint process $Y^{i}$ solves the FBSDE\n\n$$\n\\left\\{\\begin{array}{l}\nd Q_{t}^{i}=b_{t} \\Lambda\\left(\\delta^{*}\\left(-Y_{t}^{i}-\\beta_{t}^{\\overline{1}, b}\\right)\\right) d t-a_{t} \\Lambda\\left(\\delta^{*}\\left(Y_{t}^{i}-\\beta_{t}^{\\overline{4}, a}\\right)\\right) d t \\\\\nd Y_{t}^{i}=2 \\phi_{t} Q_{t}^{i} d t+d M_{t}^{i} \\\\\nQ_{0}^{i}=q_{0}^{i}, \\quad Y_{T}^{i}=-2 A Q_{T}^{i}\n\\end{array}\\right.\n$$\n\nSimilar to the techniques in [24], to solve the non-Lipschitz FBSDE (51) we first impose the regularizer $\\xi>0$ to the forward equation so that it becomes\n\n$$\nd Q_{t}^{i}=b_{t} \\Lambda\\left(\\delta^{*}\\left(-Y_{t}^{i}-\\beta_{t}^{\\overline{1}, b}\\right) \\vee(-\\xi) \\wedge \\xi\\right) d t-a_{t} \\Lambda\\left(\\delta^{*}\\left(Y_{t}^{i}-\\beta_{t}^{\\overline{4}, a}\\right) \\vee(-\\xi) \\wedge \\xi\\right) d t\n$$\n\nSince the equation is then Lipschitz, we prove the well-posedness the regularized FBSDE. Consequently, the solution $Y^{i}$ turns out to be bounded by some constant independent of $\\xi$, which helps us remove the regularizer $\\xi$ and obtain a solution solving the original equation. Finally, one can see the solution $\\left(Q^{i}, Y^{i}, M^{i}\\right) \\in \\mathbb{S}^{2} \\times \\mathbb{S}^{2} \\times \\mathbb{M}$ obtained for FBSDE (51) is also unique by a continuation argument as in [33]. Note that the control problem (50) and (51) are also solved by artificial agent $\\overline{2}$ and $\\overline{3}$; for illustration, we have\n\n$$\n\\beta_{t}^{\\overline{2}, a}=\\beta_{t}^{\\overline{4}, a}+\\delta^{*}\\left(Y_{t}^{\\overline{2}}-\\beta_{t}^{\\overline{4}, a}\\right) \\quad \\text { and } \\quad \\beta_{t}^{\\overline{2}, b}=\\beta_{t}^{\\overline{1}, b}+\\delta^{*}\\left(-Y_{t}^{\\overline{2}}-\\beta_{t}^{\\overline{1}, b}\\right)\n$$\n\nwhere $Y^{\\overline{2}}$ solves\n\n$$\n\\left\\{\\begin{array}{c}\nd Q_{t}^{\\overline{2}}=b_{t} \\Lambda\\left(\\delta^{*}\\left(-Y_{t}^{\\overline{2}}-\\beta_{t}^{\\overline{1}, b}\\right)\\right) d t-a_{t} \\Lambda\\left(\\delta^{*}\\left(Y_{t}^{\\overline{2}}-\\beta_{t}^{\\overline{4}, a}\\right)\\right) d t \\\\\nd Y_{t}^{\\overline{2}}=2 \\phi_{t} Q_{t}^{\\overline{2}} d t+d M_{t}^{\\overline{2}} \\\\\nQ_{0}^{\\overline{2}}=q_{0}^{\\overline{2}}, \\quad Y_{T}^{\\overline{2}}=-2 A Q_{T}^{\\overline{2}}\n\\end{array}\\right.\n$$\n\nFor any $i \\in \\mathcal{I}$, referring to [24], the monotonicity of the control with respect to the initial inventory yields\n(1) $\\hat{\\delta}_{t}^{i, a} \\geq \\beta_{t}^{\\overline{3}, a}=\\beta_{t}^{\\overline{4}, a}$,\n(2) $\\hat{\\delta}_{t}^{i, b} \\geq \\beta_{t}^{\\overline{2}, b}=\\beta_{t}^{\\overline{1}, a}$,\n(3) $\\hat{\\delta}_{t}^{i, a}-\\beta_{t}^{\\overline{3}, a} \\leq C\\left(q_{0}^{\\overline{3}}-q_{0}^{i}\\right)$ and $\\hat{\\delta}_{t}^{i, b}-\\beta_{t}^{\\overline{2}, b} \\leq C\\left(q_{0}^{i}-q_{0}^{\\overline{3}}\\right)$\nfor all $t$, where $C>0$ is some constant. Considering the assumption on sequences $\\left(k_{n}\\right)_{n \\in \\mathbb{N}}$ and $\\left(l_{n}\\right)_{n \\in \\mathbb{N}}$, we conclude that\n\n$$\n\\inf _{i \\in \\mathcal{I}} \\hat{\\delta}_{t}^{i, b}=\\beta_{t}^{\\overline{2}, b}=\\lim _{n \\rightarrow \\infty} \\hat{\\delta}_{t}^{k_{n}, b} \\quad \\text { and } \\quad \\inf _{i \\in \\mathcal{I}} \\hat{\\delta}_{t}^{i, a}=\\beta_{t}^{\\overline{3}, a}=\\lim _{n \\rightarrow \\infty} \\hat{\\delta}_{t}^{l_{n}, a}\n$$\n\nFinally, recalling that both $\\left(k_{n}\\right)_{n \\in \\mathbb{N}}$ and $\\left(l_{n}\\right)_{n \\in \\mathbb{N}}$ are non-duplicate, the strategy profile $\\left(Q^{i}, Y^{i}, M^{i}\\right)_{i \\in \\mathcal{I}}$ is a Nash equilibrium since\n\n$$\n\\begin{aligned}\nd Q_{t}^{i} & =b_{t} \\Lambda\\left(\\delta^{*}\\left(-Y_{t}^{i}-\\beta_{t}^{\\tilde{\\imath}, b}\\right)\\right) d t-a_{t} \\Lambda\\left(\\delta^{*}\\left(Y_{t}^{i}-\\beta_{t}^{\\tilde{\\jmath}, a}\\right)\\right) d t \\\\\n& =b_{t} \\Lambda\\left(\\delta^{*}\\left(-Y_{t}^{i}-\\inf _{\\mathcal{I} \\ni j \\neq i} \\tilde{\\delta}_{t}^{j, b}\\right)\\right) d t-a_{t} \\Lambda\\left(\\delta^{*}\\left(Y_{t}^{i}-\\inf _{\\mathcal{I} \\ni j \\neq i} \\tilde{\\delta}_{t}^{j, a}\\right)\\right) d t\n\\end{aligned}\n$$\n\nIn other words, processes $\\beta^{\\tilde{\\jmath}, a}$ and $\\beta^{\\tilde{\\jmath}, b}$ are the genuine best ask and bid strategies.\nThe remainder of this section is dedicated to the well-posedness of BSRE (43). When the coefficients $a, b, \\phi$, and $A$ are all deterministic, then $\\mathcal{B}$ is also deterministic and thus the term $\\mathcal{Z}$ becomes zero, simplifying BSRE (43) into a matrix Riccati equation. Due to its extensive applications, the well-posedness of the matrix Riccati equation has attracted significant attention, with an early exploration credited to [36]. However, existing literature has predominantly focused on equations where the coefficients are either positive definite or symmetric. When $a, b, \\phi$ and $A$ are random, the term $\\mathcal{Z}$ must be non-zero, rendering (43) genuinely stochastic. While [31] introduced a stochastic adaptation of Bellman's quasi-linearization method in [36], similar to the deterministic scenario, cases when coefficients are neither symmetric nor positive definite are rarely studied. To circumvent such difficulties, we first study the deterministic (43) using the well-known Radon's lemma, followed by an analysis of the stochastic version, building upon insights gained in the previous step.\n\nAssume $a, b, \\phi$, and $A$ are all deterministic and consider the following linear matrix differential equations:\n\n$$\n\\binom{V^{\\prime}(t)}{U^{\\prime}(t)}=\\left(\\begin{array}{cc}\n0 & \\mathcal{B}_{t} \\\\\n2 \\phi_{t} I & 0\n\\end{array}\\right)\\binom{V(t)}{U(t)} ; \\quad\\binom{V(T)}{U(T)}=\\binom{I}{-2 A I}\n$$\n\nThe purpose of Radon's lemma is to establish a connection between the matrix Riccati equation (43) and the linear equation (52):\n\nLemma 6.2 ([16]). (1) Let $\\mathcal{X}$ be a solution of the deterministic Riccati equation (43) on some interval $\\mathcal{J} \\subseteq[0, T]$ such that $T \\in \\mathcal{J}$. Denote by $V$ the unique solution of the linear equation\n\n$$\nV^{\\prime}(t)=\\mathcal{B}_{t} \\mathcal{X}_{t} V(t) ; \\quad V(T)=I\n$$\n\nfor $t \\in \\mathcal{J}$ and set $U(t)=\\mathcal{X}_{t} V(t)$. Then, the matrix $\\binom{V(t)}{U(t)}$ defines for $t \\in \\mathcal{J}$ the solution of the linear differential equation (52);\n(2) Suppose $\\binom{V(t)}{U(t)}$ is on some interval $\\mathcal{J} \\subseteq[0, T]$ a solution of the linear differential equation (52) such that $\\operatorname{det} V(t) \\neq 0$ for all $t \\in \\mathcal{J}$, then\n\n$$\n\\mathcal{X}: \\mathcal{J} \\rightarrow \\mathbb{R}^{N \\times N}, \\quad t \\mapsto U(t) V(t)^{-1}=: \\mathcal{X}_{t}\n$$\n\nis a solution to the deterministic Riccati equation (43) on $\\mathcal{J}$.\nRadon's lemma reveals that the matrix Riccati equation (43) is locally equivalent to the linear differential equation (52). This equivalence persists until a potentially finite blow-up time, as indicated by (53). Furthermore, it is evident from (53) that the solution $\\mathcal{X}$ of the matrix Riccati equation experiences blow-ups at moments when $\\operatorname{det} V(t)$ vanishes. Hence, we shift our focus to the linear differential equation (52) and verify the non-singularity of $V$.\n\nTheorem 6.3. Assume the coefficients $a, b, \\phi$, and $A$ are all deterministic. Then the matrix Riccati equation (43) accepts a unique bounded solution $\\mathcal{X}$ for cases:\n(i) when $\\phi_{t}=0$ for all $t$;\n(ii) when $N=2$.\n\nMoreover, in both cases, the solution $\\mathcal{X}_{t}$ has row sum $-2 A-2 \\int_{t}^{T} \\phi_{s} d s$ for all $t$.\nProof. If $\\phi \\equiv 0$ as in case (i), then $U$ and $V$ can be solved one-by-one in the linear system (52). This allows us to write the solution explicitly as\n\n$$\nU(t)=-2 A I \\quad \\text { and } \\quad V(t)=I+2 A \\int_{t}^{T} \\mathcal{B}_{s} d s\n$$\n\nRecalling that $\\mathcal{B}_{s}$ is an $M_{0}$-matrix for all $s$, then $\\int_{t}^{T} \\mathcal{B}_{s} d s$ is also an $M_{0}$-matrix and $V(t)$ is then a $Z_{+}$-matrix with row sum 1. By Lemma 4.4, we know $V(t)$ is an $M$-matrix, the non-singularity of which can be deduced from its strict diagonal dominance. According to Lemma 6.2, the unique solution $\\mathcal{X}$ of matrix Riccati equation (43) can be represented by $\\mathcal{X}_{t}=U(t) V(t)^{-1}$. While $V(t)$ is a strictly diagonally dominant $M$-matrix, it further implies $V(t)^{-1}$ is a non-negative matrix and is strictly diagonally dominant of column entries. Defining $\\overrightarrow{1}=(1, \\ldots, 1)$, the fact $V(t) \\cdot \\overrightarrow{1}=\\overrightarrow{1}$ yields\n\n$$\n\\overrightarrow{1}=I \\cdot \\overrightarrow{1}=V(t)^{-1} \\cdot V(t) \\cdot \\overrightarrow{1}=V(t)^{-1} \\cdot \\overrightarrow{1}\n$$\n\nThis tells us that $V(t)^{-1}$ has row sum 1. Denote by $C\\left([0, T] ; \\mathbb{R}^{2 \\times 2}\\right)$ the set of matrix-valued functions on $[0, T]$ that is element-wise continuous. Let $C_{1}\\left([0, T] ; \\mathbb{R}^{2 \\times 2}\\right) \\subset C\\left([0, T] ; \\mathbb{R}^{2 \\times 2}\\right)$ be the class such that, for any fixed $t$, the associated matrix is a $Z_{+}$-matrix with row sum 1 . In the set $C\\left([0, T] ; \\mathbb{R}^{2 \\times 2}\\right)$, consider the norm\n\n$$\n\\|P\\|_{\\ell}:=\\sup _{t \\in[0, T]} e^{-\\ell(T-t)} \\cdot\\|P(t)\\|_{F}\n$$\n\nwhere $\\ell$ is a positive constant to be specified, and $\\|\\cdot\\|_{F}$ represents the Frobenius norm. The supremum in the $\\|\\cdot\\|_{\\ell}$ ensures that both $C\\left([0, T] ; \\mathbb{R}^{2 \\times 2}\\right)$ and $C_{1}\\left([0, T] ; \\mathbb{R}^{2 \\times 2}\\right)$ are complete with respect to $\\|\\cdot\\|_{\\ell}$. Picking any $P \\in C_{1}\\left([0, T] ; \\mathbb{R}^{2 \\times 2}\\right)$, let us solve the linear equation\n\n$$\nU^{\\prime}(t)=2 \\phi_{t} P(t) ; \\quad U(T)=-2 A I\n$$\n\nand denote by $U$ its solution. This yields\n\n$$\n-U(t)=2 A I+2 \\int_{t}^{T} \\phi_{s} P(s) d s\n$$\n\nand consequently $-U(t)$ is a $Z_{+}$-matrix with row sum $2 A+2 \\int_{t}^{T} \\phi_{s} d s$ for any $t$. Given such $U$, we move on to the other linear equation\n\n$$\nV^{\\prime}(t)=\\mathcal{B}_{t} U(t) ; \\quad V(T)=I\n$$\n\nand its solution $V$ reads\n\n$$\nV(t)=I+\\int_{t}^{T} \\mathcal{B}_{s}[-U(s)] d s\n$$\n\nConsidering the following facts: (1) $\\mathcal{B}_{s}$ is an $M_{0}$-matrix; (2) $-U(s)$ is $Z_{+}$-matrix with a uniform row sum $2 A+2 \\int_{t}^{T} \\phi_{s} d s$; (3) both of them are 2-by-2 matrices, some direct calculations infer $\\mathcal{B}_{s}[-U(s)]$ is an $M_{0}$-matrix. Indeed, we apply the 2-dimensional condition only for the property\n\nthat $M$-matrices are closed under multiplication in 2-dimension. The matrix $V(t)$ is thus a $Z_{+}$-matrix with row sum 1 . In summary, the above procedure defines a map\n\n$$\nC_{1}\\left([0, T] ; \\mathbb{R}^{2 \\times 2}\\right) \\ni P \\hookrightarrow \\mathfrak{T}(P)=V \\in C_{1}\\left([0, T] ; \\mathbb{R}^{2 \\times 2}\\right)\n$$\n\nWe proceed to show $\\mathfrak{T}$ is a contraction with respect to $\\|\\cdot\\|_{\\ell}$ for some large $\\ell$.\nFor any $P, \\tilde{P} \\in C_{1}\\left([0, T] ; \\mathbb{R}^{2 \\times 2}\\right)$, write $V=\\mathfrak{T}(P)$ and $\\tilde{V}=\\mathfrak{T}(\\tilde{P})$. Utilizing the Fubini's theorem, the map $\\mathfrak{T}$ can be briefly written as\n\n$$\n\\begin{aligned}\nV(t) & =I+2 \\int_{t}^{T} \\mathcal{B}_{s}\\left(A I+\\int_{s}^{T} \\phi_{u} P(u) d u\\right) d s \\\\\n& =I+2 A \\int_{t}^{T} \\mathcal{B}_{s} d s+2 \\int_{t}^{T}\\left(\\int_{t}^{u} \\mathcal{B}_{s} d s\\right) \\phi_{u} P(u) d u\n\\end{aligned}\n$$\n\nWe can then see it holds for all $t$ that\n\n$$\n\\begin{aligned}\n\\|\\tilde{V}(t)-V(t)\\|_{F} & \\leq 2 \\int_{t}^{T}\\left\\|\\phi_{u}\\left(\\int_{t}^{u} \\mathcal{B}_{s} d s\\right)\\right\\|_{F} \\cdot\\left\\|\\tilde{P}_{u}-P_{u}\\right\\|_{F} d u \\\\\n& \\leq C \\int_{t}^{T} e^{\\ell(T-u)} \\cdot e^{-\\ell(T-u)}\\left\\|\\tilde{P}_{u}-P_{u}\\right\\|_{F} d u \\\\\n& \\leq C \\frac{e^{\\ell(T-t)}-1}{\\ell}\\|\\tilde{P}-P\\|_{\\ell}\n\\end{aligned}\n$$\n\nwhich immediately yields\n\n$$\n\\begin{aligned}\ne^{-\\ell(T-t)}\\|\\tilde{V}(t)-V(t)\\|_{F} & \\leq C \\frac{e^{\\ell(T-t)}-1}{\\ell e^{\\ell(T-t)}}\\|\\tilde{P}-P\\|_{\\ell} \\\\\n\\|\\tilde{V}-V\\|_{\\ell} & \\leq \\frac{C}{\\ell}\\|\\tilde{P}-P\\|_{\\ell}\n\\end{aligned}\n$$\n\nIt suffices to pick $\\ell>C$ for $\\mathfrak{T}$ to be a contraction. By the Banach fixed-point theorem, the map $\\mathfrak{T}$ accepts a unique fixed point, corresponding to the unique solution of the linear differential equation (52). Therefore, we can conclude for all $t$ that:\n(1) $V(t)$ as the solution of (52) is a $Z_{+}$-matrix with row sum 1 and thus is non-singular;\n(2) $-U(t)$ is a $Z_{+}$-matrix with row sum $2 A+2 \\int_{t}^{T} \\phi_{s} d s$.\n\nDiscussed above, the matrix $V(t)^{-1}$ is then a non-negative matrix with row sum 1 . We can now see $-U(t) V(t)^{-1}$ has the row sum $-2\\left(A+\\int_{t}^{T} \\phi_{s} d s\\right)$.\n\nRemark 6.4. Case (i) in Theorem 6.3 pertains to the differential game of $N$ risk-neutral players, while case (ii) is concerned with the two-player differential game. The following Theorem 6.5 addresses the two-player stochastic differential game.\n\nOne crucial characteristic of the solution, shown in Theorem 6.3, is the uniform row sum of the solution $\\mathcal{X}_{t}$ across all $t$. This attribute helps solve the stochastic Riccati equation and further enables the derivation of additional properties of the solution.\n\nTheorem 6.5. If $N=2$, then the BSRE (43) accepts a unique bounded solution $\\mathcal{X}$. Furthermore, for all $t$ the matrix $\\mathcal{X}_{t}$ is non-positive with row sum $-2 \\mathbb{E}_{t}\\left[A+\\int_{t}^{T} \\phi_{s} d s\\right]$, and is strictly diagonally dominant of column entries.\n\nProof. Since the solution exhibits a uniform row sum of $-2 A-2 \\int_{t}^{T} \\phi_{s} d s$ for all $t$ in the deterministic case, we consider the ansatz that the row sum becomes $\\mathcal{S}_{t}:=\\mathbb{E}_{t}\\left[-2 A-2 \\int_{t}^{T} \\phi_{s} d s\\right]$ in the stochastic context. Specifically, we propose the form\n\n$$\n\\mathcal{X}_{t}=\\left[\\begin{array}{ll}\n\\mathcal{X}_{11}(t) & \\mathcal{X}_{12}(t) \\\\\n\\mathcal{X}_{21}(t) & \\mathcal{X}_{22}(t)\n\\end{array}\\right]=\\left[\\begin{array}{cc}\n\\chi_{1}(t) & \\mathcal{S}_{t}-\\chi_{1}(t) \\\\\n\\mathcal{S}_{t}-\\chi_{2}(t) & \\chi_{2}(t)\n\\end{array}\\right]\n$$\n\nwhere $\\chi_{1}, \\chi_{2}$ are some processes to be determined. Noting that $\\mathcal{B}$ can be represented as\n\n$$\n\\mathcal{B}_{t}=\\left[\\begin{array}{cc}\n\\mathfrak{b}_{1}(t) & -\\mathfrak{b}_{1}(t) \\\\\n-\\mathfrak{b}_{2}(t) & \\mathfrak{b}_{2}(t)\n\\end{array}\\right]\n$$\n\nfor some bounded non-negative processes $\\mathfrak{b}_{1}$ and $\\mathfrak{b}_{2}$, we compute\n\n$$\n\\begin{aligned}\n& \\mathcal{X}_{t} \\mathcal{B}_{t} \\mathcal{X}_{t} \\\\\n& \\quad=\\left[\\begin{array}{cc}\n\\left(\\mathfrak{b}_{1} \\chi_{1}-\\mathfrak{b}_{2} \\mathcal{S}+\\mathfrak{b}_{2} \\chi_{1}\\right) \\cdot\\left(\\chi_{1}-\\mathcal{S}+\\chi_{2}\\right) & -\\left(\\mathfrak{b}_{1} \\chi_{1}-\\mathfrak{b}_{2} \\mathcal{S}+\\mathfrak{b}_{2} \\chi_{1}\\right) \\cdot\\left(\\chi_{1}-\\mathcal{S}+\\chi_{2}\\right) \\\\\n-\\left(\\mathfrak{b}_{1} \\chi_{2}-\\mathfrak{b}_{1} \\mathcal{S}+\\mathfrak{b}_{2} \\chi_{2}\\right) \\cdot\\left(\\chi_{1}-\\mathcal{S}+\\chi_{2}\\right) & \\left(\\mathfrak{b}_{1} \\chi_{2}-\\mathfrak{b}_{1} \\mathcal{S}+\\mathfrak{b}_{2} \\chi_{2}\\right) \\cdot\\left(\\chi_{1}-\\mathcal{S}+\\chi_{2}\\right)\n\\end{array}\\right]\n\\end{aligned}\n$$\n\nwhere the $t$ variable is omitted for conciseness whenever appropriate. Since $\\mathbb{E}_{t}\\left[-2 A-2 \\int_{0}^{T} \\phi_{s} d s\\right]$ is a martingale, we define $\\mathcal{H} \\in \\mathbb{H}^{2}$ such that\n\n$$\n\\mathbb{E}_{t}\\left[-2 A-2 \\int_{0}^{T} \\phi_{s} d s\\right]=\\int_{0}^{t} \\mathcal{H}_{s} d W_{s}\n$$\n\nPlugging (54) back to (43), suppose the BSDE\n\n$$\nd \\chi_{1}(t)=\\left[-\\left(\\mathfrak{b}_{1} \\chi_{1}-\\mathfrak{b}_{2} \\mathcal{S}+\\mathfrak{b}_{2} \\chi_{1}\\right)\\left(\\chi_{1}-\\mathcal{S}+\\chi_{2}\\right)+2 \\phi_{t}\\right] d t+\\mathcal{Z}_{11}(t) d W_{t}\n$$\n\nwith $\\chi_{1}(T)=-2 A$ is well-posed, we can have\n\n$$\n\\begin{aligned}\nd \\mathcal{X}_{12}(t) & =d \\mathcal{S}_{t}-d \\chi_{1}(t) \\\\\n& =2 \\phi_{t} d t+\\mathcal{H}_{t} d W_{t}-\\left[-\\left(\\mathfrak{b}_{1} \\chi_{1}-\\mathfrak{b}_{2} \\mathcal{S}+\\mathfrak{b}_{2} \\chi_{1}\\right)\\left(\\chi_{1}-\\mathcal{S}+\\chi_{2}\\right)+2 \\phi_{t}\\right] d t-\\mathcal{Z}_{11}(t) d W_{t} \\\\\n& =\\left(\\mathfrak{b}_{1} \\chi_{1}-\\mathfrak{b}_{2} \\mathcal{S}+\\mathfrak{b}_{2} \\chi_{1}\\right)\\left(\\chi_{1}-\\mathcal{S}+\\chi_{2}\\right) d t+\\left(\\mathcal{H}_{t}-\\mathcal{Z}_{11}(t)\\right) d W_{t}\n\\end{aligned}\n$$\n\nand $\\mathcal{X}_{12}(T)=-2 A+2 A=0$. Since it suffices to let $\\mathcal{Z}_{12}(t)=\\mathcal{H}_{t}-\\mathcal{Z}_{11}(t)$, the hypothesis on the position of $\\mathcal{X}_{12}(t)$ has been checked; the one of $\\mathcal{X}_{21}(t)$ can be justified via similar calculations. We can now shift our focus to the BSDEs for $\\chi_{1}$ and $\\chi_{2}$ :\n\n$$\n\\begin{aligned}\n& d \\chi_{1}(t)=\\left[-\\left(\\mathfrak{b}_{1} \\chi_{1}-\\mathfrak{b}_{2} \\mathcal{S}+\\mathfrak{b}_{2} \\chi_{1}\\right) \\cdot\\left(\\chi_{1}-\\mathcal{S}+\\chi_{2}\\right)+2 \\phi_{t}\\right] d t+\\mathcal{Z}_{11}(t) d W_{t} ; \\quad \\chi_{1}(T)=-2 A \\\\\n& d \\chi_{2}(t)=\\left[-\\left(\\mathfrak{b}_{1} \\chi_{2}-\\mathfrak{b}_{1} \\mathcal{S}+\\mathfrak{b}_{2} \\chi_{2}\\right) \\cdot\\left(\\chi_{1}-\\mathcal{S}+\\chi_{2}\\right)+2 \\phi_{t}\\right] d t+\\mathcal{Z}_{22}(t) d W_{t} ; \\quad \\chi_{2}(T)=-2 A\n\\end{aligned}\n$$\n\nSetting $\\vartheta_{1}:=\\chi_{1}+\\chi_{2}-\\mathcal{S}$ and $\\vartheta_{2}:=\\chi_{1}-\\mathcal{S}$, the system (55) can be equivalently transformed to\n\n$$\n\\begin{aligned}\n& d \\vartheta_{1}(t)=\\left[-\\left(\\mathfrak{b}_{1}(t)+\\mathfrak{b}_{2}(t)\\right) \\vartheta_{1}(t)^{2}+2 \\phi_{t}\\right] d t+\\tilde{\\mathcal{Z}}_{1}(t) d W_{t} ; \\quad \\vartheta_{1}(T)=-2 A \\\\\n& d \\vartheta_{2}(t)=-\\vartheta_{1}(t)\\left[\\left(\\mathfrak{b}_{1}(t)+\\mathfrak{b}_{2}(t)\\right) \\vartheta_{2}(t)+\\mathfrak{b}_{1}(t) \\mathcal{S}_{t}\\right] d t+\\tilde{\\mathcal{Z}}_{2}(t) d W_{t} ; \\quad \\vartheta_{2}(T)=0\n\\end{aligned}\n$$\n\nNotice the first equation of (56) is decoupled and its well-posedness is studied in [24]. We thus know there exists a unique bounded solution $\\vartheta_{1}$, satisfying $\\vartheta_{1}(t) \\in[-2(\\bar{A}+\\bar{\\phi} T), 0]$ for all $t$. Whereas the second equation in (56) is linear, we can write the solution explicitly as\n\n$$\n\\vartheta_{2}(t)=\\mathbb{E}_{t}\\left[\\int_{t}^{T} \\vartheta_{1}(u) \\mathfrak{b}_{1}(u) \\mathcal{S}_{u} e^{\\int_{t}^{u} \\vartheta_{1}(s)\\left(\\mathfrak{b}_{1}(s)+\\mathfrak{b}_{2}(s)\\right) d s} d u\\right] \\in\\left[0,4 \\overline{\\mathfrak{b}}(\\bar{A}+\\bar{\\phi} T)^{2} T\\right]\n$$\n\nwhere $\\overline{\\mathrm{b}}$ is the upper bound for the process $\\mathrm{b}_{1}$. Bounded solutions $\\chi_{1}$ and $\\chi_{2}$ can then be constructed based on $\\vartheta_{1}$ and $\\vartheta_{2}$. On the other hand, given the process $\\vartheta_{1}$, the process $\\chi_{1}$ also satisfies the linear BSDE\n\n$$\nd \\chi_{1}(t)=\\left[-\\vartheta_{1}\\left(b_{1}+b_{2}\\right) \\chi_{1}+\\left(2 \\phi+b_{2} \\mathcal{S} \\vartheta_{1}\\right)\\right] d t+\\mathcal{Z}_{11}(t) d W_{t} ; \\quad \\chi_{1}(T)=-2 A\n$$\n\nthe unique solution of which reads\n\n$$\n\\begin{aligned}\n\\chi_{1}(t) & =-\\mathbb{E}\\left[2 A e^{\\int_{t}^{T} \\vartheta_{1}(u)\\left(b_{1}(u)+b_{2}(u)\\right) d u}+\\int_{t}^{T}\\left(2 \\phi_{u}+b_{2}(u) \\mathcal{S}(u) \\vartheta_{1}(u)\\right) e^{\\int_{t}^{u} \\vartheta_{1}(s)\\left(b_{1}(s)+b_{2}(s)\\right) d s} d u\\right] \\\\\n& \\leq 0\n\\end{aligned}\n$$\n\nCombining the results on $\\chi_{1}, \\vartheta_{1}$, and $\\vartheta_{2}$, in the matrix form (54) we can conclude that: (i) entries of the first row are non-positive; (2) the difference $\\mathcal{X}_{11}-\\mathcal{X}_{21} \\leq 0$. With a symmetric discussion for the $\\chi_{2}$, the following can be similarly achieved: (iii) entries of the second row are non-positive; (iv) the difference $\\mathcal{X}_{22}-\\mathcal{X}_{12} \\leq 0$. For the uniqueness, it suffices to see that any two bounded solutions solve the same Lipschitz BSDE, which only admits a unique solution.\n\nSince we have solved the two-dimensional case completely, the infinite-player game studied in the beginning of this section then has a Nash equilibrium.\n\nProposition 6.6. The infinite-player game described in Proposition 6.1 has a Nash equilibrium.\nThe remaining of this section is devoted to the economic interpretation. We regard the price impact as the price movement triggered by order imbalances. Given some $q_{0} \\in \\mathbb{R}$, consider the following condition:\n\n$$\nq_{0}^{i}=q_{0} \\text { for all } i\n$$\n\nSince (57) indicates that all agents share the same initial inventory, the ordering property 5.2 tells us that they also share the same strategy in the equilibrium. Hence, we treat the price competition under (57) as weak, and it holds for all $i$ that\n\n$$\nd Q_{t}^{i}=b_{t} \\Lambda(0) d t-a_{t} \\Lambda(0) d t\n$$\n\nand $Y^{i}$ can be subsequently computed explicitly. For simplicity, here we let $q_{0}=0$ and $\\phi_{t}=\\phi$, with $\\phi$ and $A$ being non-negative constants. Also, we let $\\Lambda$ be the exponential function as in Example 3.12. The ask price at time $t$ then reads\n\n$$\n\\begin{aligned}\nS_{t}+\\frac{1}{\\gamma} & +2[A+\\phi(T-t)] \\int_{0}^{t}\\left(a_{u}-b_{u}\\right) d u \\\\\n& +2 A \\mathbb{E}_{t}\\left[\\int_{t}^{T}\\left(a_{u}-b_{u}\\right) d u\\right]+2 \\phi \\mathbb{E}_{t}\\left[\\int_{t}^{T}(T-u)\\left(a_{u}-b_{u}\\right) d u\\right]\n\\end{aligned}\n$$\n\nwhere integral terms are considered as the price impact. The impact is further linear if $\\phi=0$. We regard the integral in the first line of (58) as the ex post impact since it encapsulates the influence of previous orders. Additionally, integrals in the second line of (58)-indicating the adjustment in correspondence to the expected future imbalances-are considered as the ex ante impact.\n\nWe then look at the two-player game for convenience. First, note that the decoupling field can be seen as a generalization of the derivative of the terminal payoff. More specifically, fixing any $s \\in[0, T]$, we can truncate the solution $\\left(\\boldsymbol{Q}_{t}, \\boldsymbol{Y}_{t}, \\boldsymbol{M}_{t}\\right)_{t \\in[0, T]}$ with respect to time, resulting in $\\left(\\boldsymbol{Q}_{t}, \\boldsymbol{Y}_{t}, \\boldsymbol{M}_{t}\\right)_{t \\in[0, s]}$. In reference to agent 1 , the corresponding strategy $\\left(\\psi^{1, a}\\left(\\boldsymbol{Y}_{t}\\right), \\psi^{1, b}\\left(\\boldsymbol{Y}_{t}\\right)\\right)_{t \\in[0, s]}$\n\nwill solve an optimal control problem if $u^{1}\\left(s,\\left(q^{1}, Q_{s}^{2}\\right)\\right)$, as a function of $q^{1}$, can be regarded as the derivative of a new terminal penalty at time $s$. The stochastic maximum principle implies that a sufficient condition for this is: the terminal penalty is concave with respect to $q^{1}$. To verify the concavity, the definition of the matrix $\\chi$ and Theorem 6.5 yield\n\n$$\nu^{1}\\left(s,\\left(\\hat{q}^{1}, q^{2}\\right)\\right)-u^{1}\\left(s,\\left(q^{1}, q^{2}\\right)\\right)=-C\\left(\\hat{q}^{1}-q^{1}\\right)\n$$\n\nfor any $\\hat{q}^{1}, q^{1} \\in \\mathbb{R}$, where $C$ is some non-negative random variable. If $P\\left(s, q^{1}, q^{2}\\right)$ is some function such that $\\partial P / \\partial q^{1}=u^{1}$, it can be inferred from (59) that $P$ is concave in $q^{1}$. Hence, the process $\\left(\\psi^{1, a}\\left(\\boldsymbol{Y}_{t}\\right), \\psi^{1, b}\\left(\\boldsymbol{Y}_{t}\\right)\\right)_{t \\in[0, s]}$ solves the stochastic control problem with $P\\left(s, \\cdot, Q_{s}^{2}\\right)$ as the terminal penalty. On the other hand, due the symmetry $u^{1}\\left(s,\\left(q^{1}, q^{2}\\right)\\right)=u^{2}\\left(s,\\left(q^{2}, q^{1}\\right)\\right)$, the new terminal penalty for agent 2 can be $P\\left(s, \\cdot, Q_{s}^{1}\\right)$. It suffices to look at one player.\n\nWe introduce the $\\mathcal{F}_{s}$-measurable random variable\n\n$$\n\\begin{aligned}\n& \\mathrm{q}:=\\mathbb{E}_{s}\\left[A \\int_{s}^{T} \\Lambda(0)\\left(a_{u}-b_{u}\\right) d u+\\int_{s}^{T} \\phi_{r}\\left(\\int_{s}^{r} \\Lambda(0)\\left(a_{u}-b_{u}\\right) d u\\right) d r\\right] \\\\\n& \\quad / \\mathbb{E}_{s}\\left[A+\\int_{s}^{T} \\phi_{r} d r\\right]\n\\end{aligned}\n$$\n\nwhere the penalty coefficients are forced to be non-zero. Note that q represents a weighted average of future order imbalances, determined by the penalty coefficients, and $\\mathrm{q}=0$ if $s=T$. By the definition of decoupling fields, the value of $u(s,(\\mathrm{q}, \\mathrm{q}))$ is determined by $\\left(Y_{s}^{1}, Y_{s}^{2}\\right)$ that solves the FBSDE\n\n$$\n\\left\\{\\begin{array}{l}\nd Q_{t}^{i}=b_{t} \\Lambda\\left(\\psi^{i, b}\\left(\\boldsymbol{Y}_{t}\\right)-\\bar{\\psi}^{i, b}\\left(\\boldsymbol{Y}_{t}\\right)\\right) d t-a_{t} \\Lambda\\left(\\psi^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)-\\bar{\\psi}^{i, a}\\left(\\boldsymbol{Y}_{t}\\right)\\right) d t \\\\\nd Y_{t}^{i}=2 \\phi_{t} Q_{t}^{i} d t+d M_{t}^{i} \\\\\nQ_{s}^{i}=\\mathrm{q}, \\quad Y_{T}^{i}=-2 A Q_{T}^{i}\n\\end{array}\\right.\n$$\n\nfor all $i$. Because the initial inventories are identical, it follows\n\n$$\nY_{s}^{i}=-\\mathbb{E}_{s}\\left[A\\left(\\mathrm{q}+\\int_{s}^{T} \\Lambda(0)\\left(b_{r}-a_{r}\\right) d r\\right)+\\int_{s}^{T} \\phi_{r}\\left(\\mathrm{q}+\\int_{s}^{r} \\Lambda(0)\\left(b_{u}-a_{u}\\right) d u\\right)\\right]\n$$\n\nDue to the choice (60), we can now see $Y_{s}^{i}=0$ and thus $u(s,(\\mathrm{q}, \\mathrm{q}))$ is a vector with zeros. The concavity implies that the agent is still penalizing the excessive inventories at time $s$. Moreover, conditional on $Q_{s}^{2}=\\mathrm{q}$, the penalty is applied to the deviation from q as a generalization of 0 at time $T$. For the case that $q^{2}>q$, Theorem 6.5 again yields\n\n$$\nu^{1}\\left(s,\\left(\\mathrm{q}, \\mathrm{q}^{2}\\right)\\right)=u^{1}(s,(\\mathrm{q}, \\mathrm{q}))-C\\left(q^{2}-\\mathrm{q}\\right) \\leq u^{1}(s,(\\mathrm{q}, \\mathrm{q}))=0\n$$\n\nwhere $C$ is some non-negative random variable. Notice the (generalized) derivative of $u^{1}$ with respect to $q^{1}$ is bounded away from 0 if the same condition holds for coefficients $\\phi$ and $A$. Then, there exists a random variable $q^{*} \\leq \\mathrm{q}$ such that $u^{1}\\left(s,\\left(q^{*}, q^{2}\\right)\\right)=0$. In the economic context, it signifies that if the inventory level of the other player is higher than the benchmark value q at time $s$, the target of her own inventory will be smaller than q . The case $q^{2}<\\mathrm{q}$ can be similarly discussed.", "tables": {}, "images": {}}, {"section_id": 8, "text": "# 7. Heterogeneous Risk Coefficients \n\nWhile the preceding sections mainly focus on homogeneous agents, this final section delves into heterogeneous risk coefficients under the linear setting. In addition to the well-posedness result,\n\nwe will present an example to show that the desirable ordering property in the homogeneous case breaks down.\n\nWe consider a two-player game in the linear setting of Section 2. Recall that the inventory and cash of the agent 1 are modelled by $X_{t}^{1}$ and $Q_{t}^{1}$ accordingly:\n\n$$\n\\begin{gathered}\nX_{t}^{1}=\\int_{0}^{t}\\left(S_{u}+\\delta_{u}^{1, a}\\right) a_{u}\\left(\\zeta-\\gamma\\left(\\delta_{u}^{1, a}-\\delta_{u}^{2, a}\\right)\\right) d u-\\int_{0}^{t}\\left(S_{u}-\\delta_{u}^{1, b}\\right) b_{u}\\left(\\zeta-\\gamma\\left(\\delta_{u}^{1, b}-\\delta_{u}^{2, b}\\right)\\right) d u \\\\\nQ_{t}^{1}=q_{0}^{1}-\\int_{0}^{t} a_{u}\\left(\\zeta-\\gamma\\left(\\delta_{u}^{1, a}-\\delta_{u}^{2, a}\\right)\\right) d u+\\int_{0}^{t} b_{u}\\left(\\zeta-\\gamma\\left(\\delta_{u}^{1, b}-\\delta_{u}^{2, b}\\right)\\right) d u\n\\end{gathered}\n$$\n\nNote that $\\bar{\\delta}^{1, a}$ can be replaced by $\\delta^{2, a}$. The ones of agent 2 are symmetric. Controlling $\\boldsymbol{\\delta}^{i} \\in$ $\\mathbb{H}^{2} \\times \\mathbb{H}^{2}$, the agent $i \\in\\{1,2\\}$ aims at maximizing the objective functional\n\n$$\n\\begin{aligned}\nJ\\left(\\boldsymbol{\\delta}^{i} ; \\boldsymbol{\\delta}^{-i}\\right):= & \\mathbb{E}\\left[X_{T}^{i}+S_{T} Q_{T}^{i}-\\int_{0}^{T} \\phi_{t}^{i}\\left(Q_{t}^{i}\\right)^{2} d t-A^{i}\\left(Q_{T}^{i}\\right)^{2}\\right] \\\\\n= & \\mathbb{E}\\left[\\int_{0}^{T} \\delta_{t}^{i, a} a_{t}\\left(\\zeta-\\gamma\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right)\\right) d t+\\int_{0}^{T} \\delta_{t}^{i, b} b_{t}\\left(\\zeta-\\gamma\\left(\\delta_{t}^{i, b}-\\bar{\\delta}_{t}^{i, b}\\right)\\right) d t\\right. \\\\\n& \\left.-\\int_{0}^{T} \\phi_{t}^{i}\\left(Q_{t}^{i}\\right)^{2} d t-A^{i}\\left(Q_{T}^{i}\\right)^{2}\\right]\n\\end{aligned}\n$$\n\nwhere penalties $\\phi^{i}:=\\left(\\phi_{t}^{i}\\right)_{t \\in[0, T]} \\in \\mathbb{H}^{2}$ and $A^{i} \\in L^{2}\\left(\\Omega, \\mathcal{F}_{T}\\right)$ are non-negative, satisfying $\\phi_{t}^{i} \\leq \\bar{\\phi}$ and $A^{i} \\leq \\bar{A}$ for some constants $\\bar{\\phi}, \\bar{A}>0$. The goal is to find a Nash equilibrium in the same sense as (3).\n\nTheorem 7.1. A strategy profile $\\left(\\boldsymbol{\\delta}^{j}\\right)_{1 \\leq j \\leq 2} \\in\\left(\\mathbb{H}^{2} \\times \\mathbb{H}^{2}\\right)^{2}$ forms a Nash equilibrium if and only if\n\n$$\n\\begin{aligned}\n& \\delta_{t}^{1, a}=\\frac{2}{3} Y_{t}^{1}+\\frac{1}{3} Y_{t}^{2}+\\frac{\\zeta}{\\gamma}, \\quad \\delta_{t}^{1, b}=-\\frac{2}{3} Y_{t}^{1}-\\frac{1}{3} Y_{t}^{2}+\\frac{\\zeta}{\\gamma} \\\\\n& \\delta_{t}^{2, a}=\\frac{1}{3} Y_{t}^{1}+\\frac{2}{3} Y_{t}^{2}+\\frac{\\zeta}{\\gamma}, \\quad \\delta_{t}^{2, b}=-\\frac{1}{3} Y_{t}^{1}-\\frac{2}{3} Y_{t}^{2}+\\frac{\\zeta}{\\gamma}\n\\end{aligned}\n$$\n\nwhere $\\left(Y^{1}, Y^{2}\\right)$ solves the following system of FBSDEs:\n\n$$\n\\begin{aligned}\n& \\left\\{\\begin{array}{l}\nd Q_{t}^{1}=\\zeta\\left(b_{t}-a_{t}\\right) d t+\\gamma\\left(a_{t}+b_{t}\\right)\\left(Y_{t}^{1}-Y_{t}^{2}\\right) / 3 d t \\\\\nd Y_{t}^{1}=2 \\phi_{t}^{1} Q_{t}^{1} d t+d M_{t}^{1} \\\\\nQ_{0}^{1}=q_{0}^{1}, \\quad Y_{T}^{1}=-A^{1} Q_{T}^{1}\n\\end{array}\\right. \\\\\n& \\left\\{\\begin{array}{l}\nd Q_{t}^{2}=\\zeta\\left(b_{t}-a_{t}\\right) d t+\\gamma\\left(a_{t}+b_{t}\\right)\\left(Y_{t}^{2}-Y_{t}^{1}\\right) / 3 d t \\\\\nd Y_{t}^{2}=2 \\phi_{t}^{2} Q_{t}^{2} d t+d M_{t}^{2} \\\\\nQ_{0}^{2}=q_{0}^{2}, \\quad Y_{T}^{2}=-A^{2} Q_{T}^{2}\n\\end{array}\\right.\n\\end{aligned}\n$$\n\nwith $M_{t}^{i} \\in \\mathbb{M}$ for all $i \\in\\{1,2\\}$.\nProof. With reference to the homogeneous case, the heterogeneity of the penalty parameters does not affect the concavity of the objective functional. By Theorem 2.4, strategy profile\n\n$\\left(\\boldsymbol{\\delta}^{j}\\right)_{1 \\leq j \\leq 2} \\in\\left(\\mathbb{M}^{2} \\times \\mathbb{M}^{2}\\right)^{2}$ forms a Nash equilibrium if and only if it solves\n\n$$\n\\left\\{\\begin{array}{l}\nd Q_{t}^{i}=-a_{t}\\left(\\zeta+\\gamma \\bar{\\delta}_{t}^{i, a}-\\gamma \\delta_{t}^{i, a}\\right) d t+b_{t}\\left(\\zeta+\\gamma \\bar{\\delta}_{t}^{i, b}-\\gamma \\delta_{t}^{i, b}\\right) d t \\\\\nd \\delta_{t}^{i, a}=d \\bar{\\delta}_{t}^{i, a} / 2+\\phi_{t} Q_{t}^{i} d t-d \\tilde{M}_{t}^{i} \\\\\nd \\delta_{t}^{i, b}=d \\bar{\\delta}_{t}^{i, b} / 2-\\phi_{t} Q_{t}^{i} d t+d \\tilde{M}_{t}^{i} \\\\\nQ_{0}^{i}=q_{0}^{i}, \\quad \\delta_{T}^{i, a}=\\zeta /(2 \\gamma)+\\bar{\\delta}_{T}^{i, a} / 2-A Q_{T}^{i}, \\quad \\delta_{T}^{i, b}=\\zeta /(2 \\gamma)+\\bar{\\delta}_{T}^{i, b} / 2+A Q_{T}^{i}\n\\end{array}\\right.\n$$\n\nwith $\\tilde{M}^{i} \\in \\mathbb{M}$ for all $i \\in\\{1,2\\}$. System (63)-(64) can be obtain from (65) via the transform (62).\n\nWe introduce the following processes and random variables:\n\n$$\n\\begin{gathered}\n\\boldsymbol{H}_{t}=\\frac{\\gamma}{3}\\left(a_{t}+b_{t}\\right)\\left[\\begin{array}{cc}\n1 & -1 \\\\\n-1 & 1\n\\end{array}\\right], \\quad \\boldsymbol{G}_{t}=\\binom{\\zeta\\left(b_{t}-a_{t}\\right)}{\\zeta\\left(b_{t}-a_{t}\\right)} \\\\\n\\boldsymbol{D}_{t}=\\left[\\begin{array}{cc}\n2 \\phi_{t}^{1} & 0 \\\\\n0 & 2 \\phi_{t}^{2}\n\\end{array}\\right], \\quad \\boldsymbol{A}=\\left[\\begin{array}{cc}\n2 A^{1} & 0 \\\\\n0 & 2 A^{2}\n\\end{array}\\right]\n\\end{gathered}\n$$\n\nSystem (63)-(64) can then be written neatly in the vector form\n\n$$\n\\left\\{\\begin{array}{l}\nd \\boldsymbol{Q}_{t}=\\boldsymbol{G}_{t} d t+\\boldsymbol{H}_{t} \\boldsymbol{Y}_{t} d t \\\\\nd \\boldsymbol{Y}_{t}=\\boldsymbol{D}_{t} \\boldsymbol{Q}_{t} d t+d \\boldsymbol{M}_{t} \\\\\n\\boldsymbol{Q}_{0}=\\boldsymbol{q}_{0}, \\quad \\boldsymbol{Y}_{T}=-\\boldsymbol{A} \\boldsymbol{Q}_{T}\n\\end{array}\\right.\n$$\n\nTheorem 7.2. The FBSDE (66) accepts a unique solution $(\\boldsymbol{Q}, \\boldsymbol{Y}, \\boldsymbol{M}) \\in\\left(\\mathbb{S}^{2} \\times \\mathbb{S}^{2} \\times \\mathbb{M}\\right)^{2}$. Moreover, the solution has the relation\n\n$$\n\\boldsymbol{Y}_{t}=\\boldsymbol{R}_{t} \\boldsymbol{Q}_{t}+\\boldsymbol{P}_{t}\n$$\n\nwhere the matrix-valued process $\\boldsymbol{R}$ solves the BSRE\n\n$$\nd \\boldsymbol{R}_{t}=\\left(\\boldsymbol{D}_{t}-\\boldsymbol{R}_{t} \\boldsymbol{H}_{t} \\boldsymbol{R}_{t}\\right) d t+\\boldsymbol{Z}_{t} d W_{t}, \\quad \\boldsymbol{R}_{T}=-\\boldsymbol{A}\n$$\n\nProof. Given the linearity of system (66), we think of the linear ansatz (67). By plugging (67) back to (66) and matching the coefficients, we can see $\\boldsymbol{R}$ solves the BSRE (68) and $\\boldsymbol{P}$ satisfies the linear BSDE\n\n$$\nd \\boldsymbol{P}_{t}=-\\left(\\boldsymbol{R}_{t} \\boldsymbol{H}_{t} \\boldsymbol{P}_{t}+\\boldsymbol{R}_{t} \\boldsymbol{G}_{t}\\right)+\\tilde{\\boldsymbol{Z}}_{t} d W_{t}, \\quad \\boldsymbol{P}_{T}=0\n$$\n\nLet us look at (68) and first remark that both $\\boldsymbol{D}_{t}$ and $\\boldsymbol{A}$ are symmetric positive semi-definite matrices for all $t$. The same is true for $\\boldsymbol{H}_{t}$ because it is a symmetric $M_{0}$-matrix. Equation (68) is similar to the type of BSRE studied in [32], from which we learn there exists a unique bounded solution $\\boldsymbol{R}$. Consequently, the linear BSDE (69) has bounded coefficients. The resulting Lipschitz property further guarantees the well-posedness of $\\boldsymbol{P}$. A solution $(\\boldsymbol{Q}, \\boldsymbol{Y}, \\boldsymbol{M})$ can be obtained by inserting (67) back to (66). Realizing that (67) is also a regular decoupling field, the solution is also unique according to Theorem 5.9.\n\nExample 7.3. In this example, we will see the ordering property may break down under heterogeneity risk preferences. The following conditions are examined:\n\n- order flows satisfy $a_{t}=b_{t}=3 / 2$ for all $t$;\n- random variables $A^{1}$ and $A^{2}$ are deterministic, with $A^{1}>A^{2}>0$;\n\n- running penalties satisfy $\\phi_{t}^{1}=\\phi_{t}^{2}=1$;\n- it holds $0<q_{0}^{1}<q_{0}^{2}<\\frac{A^{1}}{A^{2}} q_{0}^{1}$ and $T$ is large enough.\n\nDue to the lack of noises, BSRE (68) degenerates to the Riccati equation\n\n$$\n\\begin{aligned}\nd \\boldsymbol{R}_{t} & =\\left(\\boldsymbol{D}_{t}-\\boldsymbol{R}_{t} \\boldsymbol{H}_{t} \\boldsymbol{R}_{t}\\right) d t \\\\\n& =\\left(\\begin{array}{ll}\n{[1} & 0 \\\\\n{0} & 1\n\\end{array}\\right]-\\boldsymbol{R}_{t} \\gamma\\left[\\begin{array}{cc}\n1 & 0 \\\\\n-1 & 0\n\\end{array}\\right]\\left[\\begin{array}{cc}\n1 & 0 \\\\\n-1 & 0\n\\end{array}\\right]^{*} \\boldsymbol{R}_{t}\\right) d t\n\\end{aligned}\n$$\n\nsuch that $\\boldsymbol{R}_{T}=-\\boldsymbol{A}$. We apply the asymptotic result studied in Theorem 2.1 by [36], after checking that:\n\n- matrix $\\left[\\begin{array}{cc}1 & 0 \\\\ -1 & 0\\end{array}\\right]$ is stable because it is an $M_{0}$-matrix;\n- $\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right], \\mathbf{0}$ ) is observable since matrix $\\left[\\begin{array}{llll}1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0\\end{array}\\right]$ is of rank 2 .\n\nConsequently, we know there exists a matrix $\\boldsymbol{R}_{\\infty} \\in \\mathbb{R}^{2 \\times 2}$ that is the unique negative definite solution of algebraic Riccati equation\n\n$$\n\\begin{aligned}\n0 & =\\left[\\begin{array}{ll}\n1 & 0 \\\\\n0 & 1\n\\end{array}\\right]-\\boldsymbol{R} \\gamma\\left[\\begin{array}{cc}\n1 & 0 \\\\\n-1 & 0\n\\end{array}\\right]\\left[\\begin{array}{cc}\n1 & 0 \\\\\n-1 & 0\n\\end{array}\\right]^{*} \\boldsymbol{R} \\\\\n& =\\left[\\begin{array}{ll}\n1 & 0 \\\\\n0 & 1\n\\end{array}\\right]-\\boldsymbol{R} \\gamma\\left[\\begin{array}{cc}\n1 & -1 \\\\\n-1 & 1\n\\end{array}\\right] \\boldsymbol{R}\n\\end{aligned}\n$$\n\nMoreover, it holds that\n\n$$\n\\boldsymbol{R}_{\\infty}=\\lim _{t \\rightarrow-\\infty} \\boldsymbol{R}_{t}\n$$\n\nWe claim that $\\boldsymbol{R}_{\\infty}$ is both symmetric and persymmetric. Indeed, given $\\boldsymbol{R}_{\\infty}$ as the solution of (72), consider the permutation transform\n\n$$\n\\tilde{\\boldsymbol{R}}_{\\infty}:=\\left[\\begin{array}{ll}\n0 & 1 \\\\\n1 & 0\n\\end{array}\\right] \\boldsymbol{R}_{\\infty}\\left[\\begin{array}{ll}\n0 & 1 \\\\\n1 & 0\n\\end{array}\\right]\n$$\n\nBecause direct calculation yields\n\n$$\n\\begin{aligned}\n0 & =\\left[\\begin{array}{ll}\n0 & 1 \\\\\n1 & 0\n\\end{array}\\right]\\left[\\begin{array}{ll}\n1 & 0 \\\\\n0 & 1\n\\end{array}\\right]\\left[\\begin{array}{ll}\n0 & 1 \\\\\n1 & 0\n\\end{array}\\right]-\\left[\\begin{array}{ll}\n0 & 1 \\\\\n1 & 0\n\\end{array}\\right] \\boldsymbol{R}_{\\infty} \\gamma\\left[\\begin{array}{cc}\n1 & -1 \\\\\n-1 & 1\n\\end{array}\\right] \\boldsymbol{R}_{\\infty}\\left[\\begin{array}{ll}\n0 & 1 \\\\\n1 & 0\n\\end{array}\\right] \\\\\n& =\\left[\\begin{array}{ll}\n1 & 0 \\\\\n0 & 1\n\\end{array}\\right]-\\tilde{\\boldsymbol{R}}_{\\infty} \\gamma\\left[\\begin{array}{cc}\n1 & -1 \\\\\n-1 & 1\n\\end{array}\\right] \\tilde{\\boldsymbol{R}}_{\\infty}\n\\end{aligned}\n$$\n\nmatrix $\\tilde{\\boldsymbol{R}}_{\\infty}$ solves the same equation (72) as $\\boldsymbol{R}_{\\infty}$. The symmetric and persymmetric property thus can be deduced from the uniqueness of the solution. We then write\n\n$$\n\\boldsymbol{R}_{\\infty}=\\left[\\begin{array}{ll}\n\\mathrm{r}_{1} & \\mathrm{r}_{2} \\\\\n\\mathrm{r}_{2} & \\mathrm{r}_{1}\n\\end{array}\\right]\n$$\n\nNote that $\\mathrm{r}_{1}-\\mathrm{r}_{2}<0$ due to the negative definiteness. Defining\n\n$$\n\\left[\\begin{array}{l}\nY_{\\infty}^{1} \\\\\nY_{\\infty}^{2}\n\\end{array}\\right]:=\\boldsymbol{R}_{\\infty}\\left[\\begin{array}{l}\nq_{0}^{1} \\\\\nq_{0}^{2}\n\\end{array}\\right]\n$$\n\nwe can derive\n\n$$\nY_{\\infty}^{1}-Y_{\\infty}^{2}=\\left(\\mathrm{r}_{1}-\\mathrm{r}_{2}\\right)\\left(q_{0}^{1}-q_{0}^{2}\\right)>0\n$$\n\nSince the condition $a_{t}=b_{t}$ yields $\\boldsymbol{G}_{t}=\\boldsymbol{P}_{t}=0$, the decoupling field (67) tells us\n\n$$\n\\left[\\begin{array}{l}\nY_{0}^{1} \\\\\nY_{0}^{2}\n\\end{array}\\right]=\\boldsymbol{R}_{0}\\left[\\begin{array}{l}\nq_{0}^{1} \\\\\nq_{0}^{2}\n\\end{array}\\right]\n$$\n\nCombined with the asymptotic behavior (72), we can find $T$ large enough such that $Y_{0}^{1}-Y_{0}^{2}>0$.\nTo show it can not be true that $Y_{t}^{1}-Y_{t}^{2} \\geq 0$ for all $t$, let us assume $\\Delta Y_{t}:=Y_{t}^{1}-Y_{t}^{2} \\geq 0$ and it follows by definition\n\n$$\nQ_{T}^{1}=q_{0}^{1}+\\int_{0}^{T} \\Delta Y_{t} d t\n$$\n\nIf we similarly define $\\Delta Q_{t}:=Q_{t}^{1}-Q_{t}^{2}$, it turns out $(\\Delta Q, \\Delta Y)$ solves\n\n$$\n\\left\\{\\begin{array}{l}\nd \\Delta Q_{t}=2 \\Delta Y_{t} d t \\\\\nd \\Delta Y_{t}=\\Delta Q_{t} d t \\\\\n\\Delta Q_{0}=q_{0}^{1}-q_{0}^{2}\n\\end{array} \\quad \\Delta Y_{T}=-2 A^{2} \\Delta Q_{T}-2\\left(A^{1}-A^{2}\\right) Q_{T}^{1}\\right.\n$$\n\nWe then find\n\n$$\n\\begin{aligned}\n\\Delta Y_{T} & =-2 A^{2}\\left(q_{0}^{1}-q_{0}^{2}+2 \\int_{0}^{T} \\Delta Y_{t} d t\\right)-2\\left(A^{1}-A^{2}\\right)\\left(q_{0}^{1}+\\int_{0}^{T} \\Delta Y_{t} d t\\right) \\\\\n& =-2 A^{2}\\left(\\frac{A^{1}}{A^{2}} q_{0}^{1}-q_{0}^{2}\\right)-2\\left(A^{1}+A^{2}\\right) \\int_{0}^{T} \\Delta Y_{t} d t \\\\\n& <0\n\\end{aligned}\n$$\n\nTherefore, although $\\Delta Y_{0}>0$, it can not hold for all $t$ and there exist some time $s<T$ such that $\\Delta Y_{s}<0$. Finally, utilizing (62), the sign of $\\Delta Y$ determines which agent quotes a better price. For example, the positive value of $\\Delta Y_{0}$ indicates that agent 1 provides a worse sell price (but a better buy price) than agent 2. For an economical interpretation, we first remark that heterogeneity lies in the terminal penalty coefficient. As $T$ becomes sufficiently large, the solution $\\boldsymbol{R}_{0}$ converges to $\\boldsymbol{R}_{\\infty}$, solving the algebraic equation (71) independent of the terminal condition. Essentially, the influence exerted by the terminal penalty diminishes as we move backward in time. Consequently, agents are approximately homogeneous at the initial time. As discussed earlier, the better buy price offered by agent 1 results from the lower inventory level. However, as $T$ approaches, this approximation loses validity, leading to the 'crossing' of quotes.", "tables": {}, "images": {}}, {"section_id": 9, "text": "# REFERENCES \n\n[1] Robert Almgren and Neil Chriss. \"Optimal execution of portfolio transactions\". In: Journal of Risk 3 (2001), pp. 5-40.\n[2] Robert F Almgren. \"Optimal execution with nonlinear impact functions and tradingenhanced risk\". In: Applied mathematical finance 10.1 (2003), pp. 1-18.\n[3] Stefan Ankirchner et al. \"Optimal position targeting via decoupling fields\". In: The Annals of Applied Probability 30.2 (2020), pp. 644-672.\n[4] Marco Avellaneda and Sasha Stoikov. \"High-frequency trading in a limit order book\". In: Quantitative Finance 8.3 (2008), pp. 217-224.\n[5] Peter Bank, H Mete Soner, and Moritz Vo\u00df. \"Hedging with temporary price impact\". In: Mathematics and financial economics 11.2 (2017), pp. 215-239.\n\n[6] Erhan Bayraktar and Michael Ludkovski. \"Liquidation in limit order books with controlled intensity\". In: Mathematical Finance 24.4 (2014), pp. 627-650.\n[7] Dimitris Bertsimas and Andrew W Lo. \"Optimal control of execution costs\". In: Journal of financial markets 1.1 (1998), pp. 1-50.\n[8] Luciano Campi and Diego Zabaljauregui. \"Optimal market making under partial information with general intensities\". In: Applied Mathematical Finance 27.1-2 (2020), pp. 145 .\n[9] Ren\u00e9 Carmona. Lectures on BSDEs, Stochastic Control, and Stochastic Differential Games with Financial SIAM, 2016.\n[10] Ren\u00e9 Carmona, Fran\u00e7ois Delarue, et al. Probabilistic theory of mean field games with applications I-II. Springer, 2018.\n[11] \u00c1lvaro Cartea, Sebastian Jaimungal, and Jos\u00e9 Penalva. Algorithmic and high-frequency trading. Cambridge University Press, 2015.\n[12] Francis Clarke. Functional analysis, calculus of variations and optimal control. Vol. 264. Springer, 2013.\n[13] Frank H Clarke. Optimization and nonsmooth analysis. SIAM, 1990.\n[14] Christian Clason. \"Nonsmooth analysis and optimization\". In: arXiv preprint arXiv:1708.04180 (2017).\n[15] Rama Cont and Wei Xiong. \"Dynamics of market making algorithms in dealer markets: Learning and tacit collusion\". In: Mathematical Finance (2022).\n[16] Gerhard Freiling. \"A survey of nonsymmetric Riccati equations\". In: Linear algebra and its applications 351 (2002), pp. 243-270.\n[17] Alexander Fromm. \"Theory and applications of decoupling fields for forward-backward stochastic differential equations\". In: (2015).\n[18] Alexander Fromm and Peter Imkeller. \"Existence, uniqueness and regularity of decoupling fields to multidimensional fully coupled FBSDEs\". In: arXiv preprint arXiv:1310.0499 (2013).\n[19] Marek Galewski and Marius R\u01cedulescu. \"On a global implicit function theorem for locally Lipschitz maps via non-smooth critical point theory\". In: Quaestiones Mathematicae 41.4 (2018), pp. 515-528.\n[20] Olivier Gu\u00e9ant. \"Optimal market making\". In: Applied Mathematical Finance 24.2 (2017), pp. 112-154.\n[21] Olivier Gu\u00e9ant. The Financial Mathematics of Market Liquidity. Vol. 33. CRC Press, 2016.\n[22] Olivier Gu\u00e9ant, Charles-Albert Lehalle, and Joaquin Fernandez-Tapia. \"Dealing with the inventory risk: a solution to the market making problem\". In: Mathematics and financial economics 7 (2013), pp. 477-507.\n[23] Olivier Gu\u00e9ant, Charles-Albert Lehalle, and Joaquin Fernandez-Tapia. \"Optimal portfolio liquidation with limit orders\". In: SIAM Journal on Financial Mathematics 3.1 (2012), pp. $740-764$.\n[24] Ivan Guo, Shijia Jin, and Kihun Nam. \"Macroscopic Market Making\". In: arXiv preprint arXiv:2307.14129 (2023).\n[25] Thomas Ho and Hans R Stoll. \"Optimal dealer pricing under transactions and return uncertainty\". In: Journal of Financial economics 9.1 (1981), pp. 47-73.\n[26] Roger A Horn and Charles R Johnson. Topics in matrix analysis. Cambridge university press, 1994.\n\n[27] Kaitong Hu, Zhenjie Ren, and Nizar Touzi. \"On path-dependent multidimensional forwardbackward SDEs\". In: Numerical Algebra, Control and Optimization (2022).\n[28] Dariusz Idczak. \"A global implicit function theorem and its applications to functional equations\". In: arXiv preprint arXiv:1401.4049 (2014).\n[29] Jialiang Luo and Harry Zheng. \"Dynamic Equilibrium of Market Making with Price Competition\". In: Dynamic Games and Applications 11.3 (2021), pp. 556-579.\n[30] Jin Ma et al. \"On well-posedness of forward-backward SDEs-A unified approach\". In: The Annals of Applied Probability 25.4 (2015), pp. 2168-2214.\n[31] Shige Peng. \"A general stochastic maximum principle for optimal control problems\". In: SIAM Journal on control and optimization 28.4 (1990), pp. 966-979.\n[32] Shige Peng. \"Stochastic hamilton-jacobi-bellman equations\". In: SIAM Journal on Control and Optimization 30.2 (1992), pp. 284-304.\n[33] Shige Peng and Zhen Wu. \"Fully coupled forward-backward stochastic differential equations and applications to optimal control\". In: SIAM Journal on Control and Optimization 37.3 (1999), pp. 825-843.\n[34] Max O Souza and Yuri Thamsten. \"On regularized optimal execution problems and their singular limits\". In: Applied Mathematical Finance (2022), pp. 1-31.\n[35] James M Varah. \"A lower bound for the smallest singular value of a matrix\". In: Linear Algebra and its applications 11.1 (1975), pp. 3-5.\n[36] William M Wonham. \"On a matrix Riccati equation of stochastic control\". In: SIAM Journal on Control 6.4 (1968), pp. 681-697.", "tables": {}, "images": {}}, {"section_id": 10, "text": "# 8. Appendix: Stochastic Maximum Principle \n\nThis section is devoted to the game version of the stochastic maximum principle. We follow the argument in [9] that is devoted to the control problem, and start with the necessary condition. Fix an admissible strategy profile $\\left(\\boldsymbol{\\delta}^{j}\\right)_{1 \\leq j \\leq N} \\in(\\mathbb{A} \\times \\mathbb{A})^{N}$ and denote by $\\left(Q^{1}, \\ldots, Q^{N}\\right) \\in\\left(\\mathbb{S}^{2}\\right)^{N}$ the corresponding controlled inventory. Next, in view of player $i$, let us consider $\\boldsymbol{\\beta} \\in \\mathbb{A} \\times \\mathbb{A}$, which is uniformly bounded and satisfies $\\boldsymbol{\\delta}^{i}+\\boldsymbol{\\beta} \\in \\mathbb{A} \\times \\mathbb{A}$. The direction $\\boldsymbol{\\beta}$ will be used to compute the G\u00e2teaux derivative of $J^{i}$. For each $\\epsilon>0$ small enough, define an admissible control $\\boldsymbol{\\delta}^{i, \\epsilon} \\in \\mathbb{A} \\times \\mathbb{A}$ as $\\boldsymbol{\\delta}_{t}^{i, \\epsilon}=\\boldsymbol{\\delta}_{t}^{i}+\\epsilon \\boldsymbol{\\beta}_{t}$, and the corresponding controlled state is denoted by $Q^{i, \\epsilon} \\in \\mathbb{S}^{2}$. Let $V$ be the solution of the equation\n\n$$\nd V_{t}=\\partial_{\\delta} \\theta\\left(t, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\cdot \\boldsymbol{\\beta}_{t} d t\n$$\n\nwith the initial condition $V_{0}=0$, where\n\n$$\n\\theta\\left(t, \\boldsymbol{\\delta}^{i} ; \\boldsymbol{\\delta}^{-i}\\right):=-a_{t} \\Lambda\\left(\\delta^{i, a}-\\bar{\\delta}^{i, a}\\right)+b_{t} \\Lambda\\left(\\delta^{i, b}-\\bar{\\delta}^{i, b}\\right)\n$$\n\nIt is clear that $V$ is uniformly bounded in any finite time horizon.\nLemma 8.1. The functional $\\boldsymbol{\\delta} \\hookrightarrow J^{i}\\left(\\boldsymbol{\\delta} ; \\boldsymbol{\\delta}^{-i}\\right)$ is G\u00e2teaux differentiable and the derivative reads\n\n$$\n\\begin{aligned}\n\\frac{d}{d \\epsilon} J^{i}\\left(\\boldsymbol{\\delta}^{i}+\\epsilon \\boldsymbol{\\beta} ; \\boldsymbol{\\delta}^{-i}\\right)\\left.\\right|_{\\epsilon=0}: & =\\lim _{\\epsilon \\backslash 0} \\frac{1}{\\epsilon}\\left[J^{i}\\left(\\boldsymbol{\\delta}^{i}+\\epsilon \\boldsymbol{\\beta} ; \\boldsymbol{\\delta}^{-i}\\right)-J^{i}\\left(\\boldsymbol{\\delta}^{i} ; \\boldsymbol{\\delta}^{-i}\\right)\\right] \\\\\n& =\\mathbb{E}\\left[\\int_{0}^{T}\\left(\\partial_{q} f\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) V_{t}+\\partial_{\\boldsymbol{\\delta}} f\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\cdot \\boldsymbol{\\beta}_{t}\\right) d t-2 A^{i} V_{T} Q_{T}^{i}\\right]\n\\end{aligned}\n$$\n\nwhere $f$ is the running payoff given as\n\n$$\nf\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)=b_{t} \\delta_{t}^{i, b} \\Lambda\\left(\\delta_{t}^{i, b}-\\bar{\\delta}_{t}^{i, b}\\right)+a_{t} \\delta_{t}^{i, a} \\Lambda\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right)-\\phi_{t}^{i}\\left(Q_{t}^{i}\\right)^{2}\n$$\n\nProof. Regarding the ask side of the running payoff, we compute that\n\n$$\n\\begin{aligned}\n& \\frac{1}{\\epsilon} \\mathbb{E}\\left[\\int_{0}^{T} a_{t}\\left(\\delta_{t}^{i, a}+\\epsilon \\beta_{t}^{a}\\right) \\Lambda\\left(\\delta_{t}^{i, a}+\\epsilon \\beta_{t}^{a}-\\bar{\\delta}_{t}^{i, a}\\right) d t-\\int_{0}^{T} a_{t} \\delta_{t}^{i, a} \\Lambda\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right) d t\\right] \\\\\n& \\quad=\\mathbb{E}\\left[\\int_{0}^{T} a_{t} \\delta_{t}^{i, a} \\frac{1}{\\epsilon}\\left(\\Lambda\\left(\\delta_{t}^{i, a}+\\epsilon \\beta_{t}^{a}-\\bar{\\delta}_{t}^{i, a}\\right)-\\Lambda^{a}\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right)\\right) d t\\right]+\\mathbb{E}\\left[\\int_{0}^{T} a_{t} \\beta_{t}^{a} \\Lambda\\left(\\delta_{t}^{i, a}+\\epsilon \\beta_{t}^{a}-\\bar{\\delta}_{t}^{i, a}\\right) d t\\right]\n\\end{aligned}\n$$\n\nTo perform the limiting procedure, it suffices to notice\n\n$$\n\\begin{gathered}\n\\int_{0}^{T} a_{t} \\delta_{t}^{i, a} \\frac{1}{\\epsilon}\\left(\\Lambda\\left(\\delta_{t}^{i, a}+\\epsilon \\beta_{t}^{a}-\\bar{\\delta}_{t}^{i, a}\\right)-\\Lambda^{a}\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right)\\right) d t \\leq C \\int_{0}^{T} a_{t}\\left|\\delta_{t}^{i, a}\\right| d t \\\\\n\\int_{0}^{T} a_{t} \\beta_{t}^{a} \\Lambda\\left(\\delta_{t}^{i, a}+\\epsilon \\beta_{t}^{a}-\\bar{\\delta}_{t}^{i, a}\\right) d t \\leq C \\int_{0}^{T} a_{t} d t \\\\\na_{t} \\delta_{t}^{i, a} \\frac{1}{\\epsilon}\\left(\\Lambda\\left(\\delta_{t}^{i, a}+\\epsilon \\beta_{t}^{a}-\\bar{\\delta}_{t}^{i, a}\\right)-\\Lambda^{a}\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right)\\right) \\leq C a_{t}\\left|\\delta_{t}^{i, a}\\right| \\\\\na_{t} \\beta_{t}^{a} \\Lambda\\left(\\delta_{t}^{i, a}+\\epsilon \\beta_{t}^{a}-\\bar{\\delta}_{t}^{i, a}\\right) \\leq C a_{t}\n\\end{gathered}\n$$\n\nand the integrability on the right hand sides. Hence, the dominated convergence theorem yields\n\n$$\n\\begin{aligned}\n\\lim _{\\epsilon \\rightarrow 0} \\frac{1}{\\epsilon} \\mathbb{E}\\left[\\int_{0}^{T} a_{t}\\left(\\delta_{t}^{i, a}\\right.\\right. & \\left.+\\epsilon \\beta_{t}^{a}\\right) \\Lambda\\left(\\delta_{t}^{i, a}+\\epsilon \\beta_{t}^{a}-\\bar{\\delta}_{t}^{i, a}\\right) d t-\\int_{0}^{T} a_{t} \\delta_{t}^{i, a} \\Lambda\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right) d t\\right] \\\\\n& =\\mathbb{E}\\left[\\int_{0}^{T} a_{t} \\delta_{t}^{i, a}\\left(\\Lambda\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right)\\right)^{\\prime} \\beta_{t}^{a} d t\\right]+\\mathbb{E}\\left[\\int_{0}^{T} a_{t} \\beta_{t}^{a} \\Lambda\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right) d t\\right] \\\\\n& =\\mathbb{E}\\left[\\int_{0}^{T} \\partial_{\\delta^{a}} f\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\beta_{t}^{a} d t\\right]\n\\end{aligned}\n$$\n\nSince the bid side can be computed in the same way, the term with $\\partial_{\\delta} f$ in (73) is thus verified. With respect to the running inventory penalty, we further calculate that\n\n$$\n\\begin{aligned}\n& \\frac{1}{\\epsilon} \\mathbb{E}\\left[\\int_{0}^{T} \\phi_{t}^{i}\\left(Q_{t}^{i, \\epsilon}\\right)^{2} d t-\\int_{0}^{T} \\phi_{t}^{i}\\left(Q_{t}^{i}\\right)^{2} d t\\right] \\\\\n& =\\mathbb{E}\\left[\\int_{0}^{T} \\phi_{t}^{i}\\left(Q_{t}^{i, \\epsilon}+Q_{t}^{i}\\right)\\left(-\\int_{0}^{t} a_{u} \\frac{1}{\\epsilon}\\left[\\Lambda\\left(\\delta_{u}^{i, a}+\\epsilon \\beta_{u}^{a}-\\bar{\\delta}_{u}^{i, a}\\right)-\\Lambda\\left(\\delta_{u}^{i, a}-\\bar{\\delta}_{u}^{i, a}\\right)\\right] d u\\right.\\right. \\\\\n& \\left.\\left.+\\int_{0}^{t} b_{u} \\frac{1}{\\epsilon}\\left[\\Lambda\\left(\\delta_{u}^{i, b}+\\epsilon \\beta_{u}^{b}-\\bar{\\delta}_{u}^{i, b}\\right)-\\Lambda\\left(\\delta_{u}^{i, b}-\\bar{\\delta}_{u}^{i, b}\\right)\\right] d u\\right) d t\\right]\n\\end{aligned}\n$$\n\nSimilarly, being aware of the boundedness of $\\phi^{i}, Q^{i}, Q^{i, \\epsilon}, a, b$, as well as\n\n$$\n\\frac{1}{\\epsilon}\\left[\\Lambda\\left(\\delta_{u}^{i, a}+\\epsilon \\beta_{u}^{a}-\\bar{\\delta}_{u}^{i, a}\\right)-\\Lambda\\left(\\delta_{u}^{i, a}-\\bar{\\delta}_{u}^{i, a}\\right)\\right] \\quad \\text { and } \\quad \\frac{1}{\\epsilon}\\left[\\Lambda\\left(\\delta_{u}^{i, b}+\\epsilon \\beta_{u}^{b}-\\bar{\\delta}_{u}^{i, b}\\right)-\\Lambda\\left(\\delta_{u}^{i, b}-\\bar{\\delta}_{u}^{i, b}\\right)\\right]\n$$\n\nwe can conclude by the dominated convergence theorem that\n\n$$\n\\lim _{\\epsilon \\rightarrow 0} \\frac{1}{\\epsilon} \\mathbb{E}\\left[\\int_{0}^{T} \\phi_{t}^{i}\\left(Q_{t}^{i, \\epsilon}\\right)^{2} d t-\\int_{0}^{T} \\phi_{t}^{i}\\left(Q_{t}^{i}\\right)^{2} d t\\right]=2 \\mathbb{E}\\left[\\int_{0}^{T} \\phi_{t}^{i} Q_{t}^{i} V_{t} d t\\right]\n$$\n\nWhile the terminal penalty part can be justified in the same way, the proof is complete.\nLet $\\left(Y^{i}, M^{i}\\right)$ be the adjoint processes associated with $\\left(\\boldsymbol{\\delta}^{j}\\right)_{1 \\leq j \\leq N}$, i.e., processes $(Y, Z)$ solve the BSDE\n\n$$\nd Y_{t}^{i}=2 \\phi_{t}^{i} Q_{t}^{i} d t+d M_{t}^{i}, \\quad Y_{T}^{i}=-2 A^{i} Q_{T}^{i}\n$$\n\nThe following duality relation provides an expression of the G\u00e2teaux derivative of the cost functional in terms of the Hamiltonian of the system.\n\nLemma 8.2. The duality relation is given by\n\n$$\n\\mathbb{E}\\left[Y_{T}^{i} V_{T}\\right]=\\mathbb{E}\\left[\\int_{0}^{T}\\left(\\partial_{\\delta} \\theta\\left(t, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\cdot \\boldsymbol{\\beta}_{t} Y_{t}^{i}-\\partial_{\\dot{\\delta}} f\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) V_{t}\\right) d t\\right]\n$$\n\nSuch duality further implies\n\n$$\n\\left.\\frac{d}{d \\epsilon} J^{i}\\left(\\boldsymbol{\\delta}^{i}+\\epsilon \\boldsymbol{\\beta} ; \\boldsymbol{\\delta}^{-i}\\right)\\right|_{\\epsilon=0}=\\mathbb{E}\\left[\\int_{0}^{T} \\partial_{\\delta} H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\cdot \\boldsymbol{\\beta}_{t} d t\\right]\n$$\n\nPROOF. The integration by parts yields\n\n$$\n\\begin{aligned}\nY_{T}^{i} V_{T} & =Y_{0}^{i} V_{0}+\\int_{0}^{T} Y_{t}^{i} d V_{t}+\\int_{0}^{T} V_{t} d Y_{t}^{i} \\\\\n& =\\int_{0}^{T} Y_{t} \\partial_{\\delta} \\theta\\left(t, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\cdot \\boldsymbol{\\beta}_{t} d t+\\int_{0}^{T} 2 \\phi_{t}^{i} V_{t} Q_{t}^{i} d t+\\int_{0}^{T} V_{t} d M_{t}^{i}\n\\end{aligned}\n$$\n\nThe duality is obtain through taking the expectation. Using this relation, we can further compute\n\n$$\n\\begin{aligned}\n& \\left.\\frac{d}{d \\epsilon} J^{i}\\left(\\boldsymbol{\\delta}^{i}+\\epsilon \\boldsymbol{\\beta} ; \\boldsymbol{\\delta}^{-i}\\right)\\right|_{\\epsilon=0} \\\\\n& =\\mathbb{E}\\left[\\int_{0}^{T}\\left(\\partial_{\\dot{\\delta}} f\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) V_{t}+\\partial_{\\delta} f\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\cdot \\boldsymbol{\\beta}_{t}\\right) d t+V_{T} Y_{T}^{i}\\right] \\\\\n& =\\mathbb{E}\\left[\\int_{0}^{T} Y_{t}^{i} \\partial_{\\delta} \\theta\\left(t, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\cdot \\boldsymbol{\\beta}_{t} d t+\\int_{0}^{T} \\partial_{\\delta} f\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\cdot \\boldsymbol{\\beta}_{t}\\right) d t\\right] \\\\\n& =\\mathbb{E}\\left[\\int_{0}^{T} \\partial_{\\delta} H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\cdot \\boldsymbol{\\beta}_{t} d t\\right]\n\\end{aligned}\n$$\n\nWith these preliminary steps, we have now arrived at the necessary condition for optimality.\nTheorem 8.3 (Necessary condition). If an admissible strategy profile $\\left(\\boldsymbol{\\delta}^{j}\\right)_{1 \\leq j \\leq N}$ is a Nash equilibrium, $\\left(Q^{j}\\right)_{1 \\leq j \\leq N}$ are the corresponding controlled inventories, and $\\left(Y^{j}, M^{j}\\right)_{1 \\leq j \\leq N}$ are the associated adjoint processes, then it holds for any player $i$ that\n\n$$\nH^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\geq H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\beta} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)\n$$\n\n$d t \\times d \\mathbb{P}-$ a.s. for any $\\boldsymbol{\\beta} \\in[-\\xi, \\xi] \\times[-\\xi, \\xi]$.\nProof. Fix any $i \\in\\{1, \\ldots, N\\}$. Due to the convexity of the admissible space, given any admissible and bounded $\\boldsymbol{\\beta} \\in \\mathbb{A} \\times \\mathbb{A}$, we can choose the perturbation $\\boldsymbol{\\delta}^{i, \\epsilon}=\\boldsymbol{\\delta}^{i}+\\epsilon\\left(\\boldsymbol{\\beta}-\\boldsymbol{\\delta}^{i}\\right)$ which is still admissible. Since $\\left(\\boldsymbol{\\delta}^{j}\\right)_{1 \\leq j \\leq N}$ is a Nash equilibrium, the following inequality should hold:\n\n$$\n\\left.\\frac{d}{d \\epsilon} J^{i}\\left(\\boldsymbol{\\delta}^{i}+\\epsilon\\left(\\boldsymbol{\\beta}-\\boldsymbol{\\delta}^{i}\\right) ; \\boldsymbol{\\delta}^{-i}\\right)\\right|_{\\epsilon=0}=\\mathbb{E}\\left[\\int_{0}^{T} \\partial_{\\delta} H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\cdot\\left(\\boldsymbol{\\beta}_{t}-\\boldsymbol{\\delta}_{t}^{i}\\right) d t\\right] \\leq 0\n$$\n\nFrom this we can see\n\n$$\n\\partial_{\\delta} H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\cdot\\left(\\boldsymbol{\\beta}-\\boldsymbol{\\delta}_{t}^{i}\\right) \\leq 0\n$$\n\n$d t \\times d \\mathbb{P}$-a.s. for all $\\boldsymbol{\\beta} \\in[-\\xi, \\xi] \\times[-\\xi, \\xi]$. Look at the ask side for example. Regarding the condition (74), it can only happen at time $t$ if one of the following three cases holds:\n\n$$\n\\begin{array}{lll}\n\\delta_{t}^{i, a} \\in(-\\xi,+\\xi) & \\text { with } & \\partial_{\\delta^{a}} H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)=0 \\\\\n\\delta_{t}^{i, a}=-\\xi \\leq \\beta^{a} & \\text { with } & \\partial_{\\delta^{a}} H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\leq 0 \\\\\n\\delta_{t}^{i, a}=+\\xi \\geq \\beta^{a} & \\text { with } & \\partial_{\\delta^{a}} H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\geq 0\n\\end{array}\n$$\n\nSuppose that\n\n$$\n\\partial_{\\delta^{a}} H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)=-a_{t}\\left(\\Lambda^{a}\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right)\\right)^{\\prime}\\left[Y_{t}-\\delta_{t}^{i, a}-\\frac{\\Lambda\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right)}{\\left(\\Lambda\\left(\\delta_{t}^{i, a}-\\bar{\\delta}_{t}^{i, a}\\right)\\right)^{2}}\\right]=0\n$$\n\nthe monotonicity of $\\delta+\\frac{\\Lambda(\\delta)}{(\\Lambda(\\delta))^{\\prime}}$ (see Assumption 3.1) implies that $\\delta_{t}^{i, a}$ maximizes the corresponding part of the Hamiltonian. In another case, think of $\\delta_{t}^{i, a}=-\\xi$ with $\\partial_{\\delta^{a}} H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right) \\leq 0$. Since $H^{i}$ is first increasing and then decreasing, this property infers that $\\delta_{t}^{i, a}=-\\xi$ is the maximizer of the Hamiltonian on the interval $[-\\xi, \\xi]$. While the remaining case and the bid side can be discussed in a similar fashion, all three cases imply that the strategy $\\boldsymbol{\\delta}^{i}$ maximizes the $H^{i}$ along the optimal paths. The proof is complete since the previous discussion holds for any player.\n\nThe sufficient condition is more straightforward to derive, stated as below.\nTheorem 8.4 (Sufficient condition). Let $\\left(\\boldsymbol{\\delta}^{j}\\right)_{1 \\leq j \\leq N}$ be an admissible strategy profile, $\\left(Q^{1} \\ldots, Q^{N}\\right)$ be the corresponding controlled inventories, and $\\left(Y^{j}, M^{j}\\right)_{1 \\leq j \\leq N}$ be the associated adjoint processes. If it holds $d t \\times d \\mathbb{P}$-a.s. that\n\n$$\nH^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)=\\sup _{\\boldsymbol{\\beta} \\in[-\\xi, \\xi]^{2}} H^{i}\\left(t, Q_{t}^{i}, Y_{t}^{i}, \\boldsymbol{\\beta} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)\n$$\n\nfor all $i \\in\\{1, \\ldots, N\\}$, then $\\left(\\boldsymbol{\\delta}^{j}\\right)_{1 \\leq j \\leq N}$ is a Nash equilibrium.\nProof. Fix any $i \\in\\{1, \\ldots, N\\}$. Let $\\boldsymbol{\\beta} \\in \\mathbb{A} \\times \\mathbb{A}$ be a generic admissible strategy and $Q^{i^{\\prime}}$ be the state process associated with the profile $\\left(\\boldsymbol{\\beta}, \\boldsymbol{\\delta}^{-i}\\right)$. Due to the concaveness of the terminal penalty, we have\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[-A^{i}\\left(Q_{T}^{i}\\right)^{2}+A^{i}\\left(Q_{T}^{i^{\\prime}}\\right)^{2}\\right] & \\geq \\mathbb{E}\\left[-2 A^{i} Q_{T}^{i}\\left(Q_{T}^{i}-Q_{T}^{i^{\\prime}}\\right)\\right] \\\\\n& =\\mathbb{E}\\left[Y_{T}^{i}\\left(Q_{T}^{i}-Q_{T}^{i^{\\prime}}\\right)\\right] \\\\\n& =\\mathbb{E}\\left[\\int_{0}^{T} 2 \\phi_{t}^{i} Q_{t}^{i}\\left(Q_{t}^{i}-Q_{t}^{i^{\\prime}}\\right) d t+\\int_{0}^{T} Y_{t}^{i} d\\left(Q_{t}^{i}-Q_{t}^{i^{\\prime}}\\right)\\right]\n\\end{aligned}\n$$\n\nBy the definition of the Hamiltonian, one can also obtain\n\n$$\n\\begin{aligned}\n\\mathbb{E} \\int_{0}^{T}\\left[f\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)\\right. & -f\\left(t, Q_{t}^{i^{\\prime}}, \\boldsymbol{\\beta}_{t} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)] d t \\\\\n& =\\mathbb{E} \\int_{0}^{T}\\left[H\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)-H\\left(t, Q_{t}^{i^{\\prime}}, \\boldsymbol{\\beta}_{t} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)\\right] d t-\\mathbb{E} \\int_{0}^{T} Y_{t}^{i} d\\left(Q_{t}^{i}-Q_{t}^{i^{\\prime}}\\right)\n\\end{aligned}\n$$\n\nwhere we recall that $f$ is the running payoff of agent $i$. Combining two results above, we can get\n\n$$\n\\begin{aligned}\nJ^{i}\\left(\\boldsymbol{\\delta}^{i} ; \\boldsymbol{\\delta}^{-i}\\right)-J^{i}\\left(\\boldsymbol{\\beta} ; \\boldsymbol{\\delta}^{-i}\\right) & =\\mathbb{E} \\int_{0}^{T}\\left[f\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)-f\\left(t, Q_{t}^{i^{\\prime}}, \\boldsymbol{\\beta}_{t} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)\\right] d t+\\mathbb{E}\\left[-2 A^{i}\\left(Q_{T}^{i}\\right)^{2}+2 A^{i}\\left(Q_{T}^{i^{\\prime}}\\right)^{2}\\right] \\\\\n& \\geq \\mathbb{E} \\int_{0}^{T}\\left[H\\left(t, Q_{t}^{i}, \\boldsymbol{\\delta}_{t}^{i} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)-H\\left(t, Q_{t}^{i^{\\prime}}, \\boldsymbol{\\beta}_{t} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)+2 \\phi_{t}^{i} Q_{t}^{i}\\left(Q_{t}^{i}-Q_{t}^{i^{\\prime}}\\right)\\right] d t \\\\\n& \\geq \\mathbb{E} \\int_{0}^{T}\\left[H\\left(t, Q_{t}^{i}, \\boldsymbol{\\beta}_{t} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)-H\\left(t, Q_{t}^{i^{\\prime}}, \\boldsymbol{\\beta}_{t} ; \\boldsymbol{\\delta}_{t}^{-i}\\right)+2 \\phi_{t}^{i} Q_{t}^{i}\\left(Q_{t}^{i}-Q_{t}^{i^{\\prime}}\\right)\\right] d t \\\\\n& =\\mathbb{E} \\int_{0}^{T} \\phi_{t}^{i}\\left(Q_{t}^{i}-Q_{t}^{i^{\\prime}}\\right)^{2} d t \\\\\n& \\geq 0\n\\end{aligned}\n$$\n\nThe proof is complete since the previous discussion holds for any player.", "tables": {}, "images": {}}, {"section_id": 11, "text": "# 9. Appendix: Non-smooth Analysis and Implicit Function \n\nLet $X$ be a separable Banach space. Given function $F: X \\rightarrow \\mathbb{R}$, the generalized directional derivative in $x \\in X$ with respect to the direction $h \\in X$ is given by\n\n$$\nF^{\\circ}(x ; h):=\\limsup _{\\substack{y \\rightarrow x \\\\ t \\rightarrow 0}} \\frac{1}{t}[F(y+t h)-F(y)]\n$$\n\nIn addition, we review the Rademacher's theorem.\nTheorem 9.1 (Rademacher). For some $m, l \\in \\mathbb{N}$, let $U \\subseteq \\mathbb{R}^{m}$ be open and $F: U \\rightarrow \\mathbb{R}^{l}$ be locally Lipschitz continuous. Then $F$ is Fr\u00e9chet differentiable in almost every $x \\in U$.\n\nIn view of Rademacher's theorem, we introduce the generalized derivative and the generalized Jacobian matrix as follows.\n\nDefinition 9.2. (1) For a locally Lipschitz function $F: X \\rightarrow \\mathbb{R}$, its (Clarke) generalized derivative in $x \\in X$ is defined by\n\n$$\n\\partial F(x):=\\left\\{x^{*} \\in X^{*}:\\left\\langle x^{*}, h\\right\\rangle_{X} \\leq F^{\\circ}(x ; h), \\forall h \\in X\\right\\}\n$$\n\nHere, $\\langle\\cdot, \\cdot\\rangle_{X}$ denotes the duality product between $X$ and $X^{*}$. Specifically, if $X=\\mathbb{R}^{m}$, then $F$ is differentiable on $\\mathbb{R}^{m} \\backslash E_{F}$ for a set $E_{F} \\subseteq \\mathbb{R}^{m}$ of Lebesgue measure 0 . Then, the generalized derivative can be characterized by\n\n$$\n\\partial F(x)=\\operatorname{co}\\left\\{\\lim _{n \\rightarrow \\infty} \\nabla F\\left(x_{n}\\right): x_{n} \\rightarrow x, x_{n} \\notin E_{F}\\right\\}\n$$\n\nwhere co $A$ denotes the convex hull of $A \\subseteq \\mathbb{R}^{m}$.\n(2) For a locally Lipschitz function $F: \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{l}$, its (Clarke) generalized Jacobian in $x \\in \\mathbb{R}^{m}$ is defined as\n\n$$\n\\partial F(x):=\\operatorname{co}\\left\\{\\lim _{n \\rightarrow \\infty} \\nabla F\\left(x_{n}\\right): x_{n} \\rightarrow x, x_{n} \\notin E_{F}\\right\\}\n$$\n\nHere, we let $F$ be differentiable on $\\mathbb{R}^{m} \\backslash E_{F}$ for a set $E_{F} \\subseteq \\mathbb{R}^{m}$ of Lebesgue measure 0 .\n\nRemark 9.3. Unlike some literature, we will not use $\\partial_{C}$ to denote the generalized derivative. Instead, we will rely on the subscript notation to represent the partial derivative. For illustration, $\\partial_{x} F(x, y)$ denotes the generalized derivative of $F$ with respect to its first variable; $\\partial F(x, y)$ denotes the generalized derivative of $F$ with respect to the variable $(x, y)$.\nIt is worth noting that in the smooth case, the generalized derivatives and classical derivatives coincide, so there should be no ambiguity in our notation.\n\nWith these prerequisites in place, we now proceed to present the proof of the implicit function theorem.\n\nProof. (Propostion 3.9) Given the first two conditions, one already knows there exists a unique locally Lipschitz function $f: \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$ such that $F(x, y)=0$ and $x=f(y)$ are equivalent in the set $\\mathbb{R}^{n} \\times \\mathbb{R}^{m}$, according to Theorem 4 in [19]. It suffices to verify the global Lipschitz property.\n\nFirst, the proof of Theorem 4 is accomplished by concatenating the local result given by Theorem 2 in [19]. For every $y \\in \\mathbb{R}^{m}$, the resulting function $f$ is Lipschitz in a neighborhood containing $y$, and thus is locally Lipschitz overall. Subsequently, the proof of Theorem 2 is built upon the inverse function theorem, referring to Theorem 7.1.1 in [13]. Illustrated by the Corollary on page 256 in [13], we can define the function $\\tilde{F}: \\mathbb{R}^{m+n} \\rightarrow \\mathbb{R}^{m+n}$ by\n\n$$\n\\tilde{F}(x, y)=[y, F(x, y)]\n$$\n\nand apply the inverse function theorem to $\\tilde{F}$ to justify the local version of the implicit function theorem (i.e., Theorem 2 in [19]). The function $f$ is then Lipschitz (in a neighborhood) because of the Lipschitz inverse according to Theorem 7.1.1. Finally, the Lipschitz coefficient of the Lipschitz inverse is $1 / \\delta$, provided that the distance between the distance between $\\partial \\tilde{F}(\\hat{x}, \\hat{y}) \\tilde{S}-$ letting $\\tilde{S}$ signify the unit sphere in $\\mathbb{R}^{m+n}$-and 0 is $2 \\delta$, for a $(\\hat{x}, \\hat{y}) \\in \\mathbb{R}^{n} \\times \\mathbb{R}^{m}$ fixed at the beginning.\n\nTherefore, given that there exists a constant $v>0$ such that the distance between $\\partial \\tilde{F}(x, y) \\tilde{S}$ and 0 is at least $v$ for all $(x, y) \\in \\mathbb{R}^{n} \\times \\mathbb{R}^{m}$, the above procedure tells us that the function $f$ is Lipschitz in every small neighborhood, with the Lipschitz coefficient being bounded uniformly by $2 / v$. It follows $f$ is (globally) Lipschitz.\n\nWe finish with the calculus rules of the generalized derivative.\nTheorem 9.4 ([14], [13]). Let $F: X \\rightarrow \\mathbb{R}$ be locally Lipschitz continuous near $x \\in X$ and $\\kappa \\in \\mathbb{R}$, then\n\n$$\n\\partial(\\kappa F)(x)=\\kappa \\partial F(x)\n$$\n\nLet $G: X \\rightarrow \\mathbb{R}$ also be locally Lipschitz continuous near $x \\in X$, then\n\n$$\n\\partial(F+G)(x) \\subseteq \\partial F(x)+\\partial G(x):=\\{f+g: f \\in \\partial F(x), g \\in \\partial G(x)\\}\n$$\n\nThe above are also true for the case $F, G: \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{l}$.", "tables": {}, "images": {}}], "id": "2406.05662v2", "authors": ["Ivan Guo", "Shijia Jin"], "categories": ["q-fin.TR", "math.PR", "q-fin.MF"], "abstract": "Building on the macroscopic market making framework as a control problem,\nthis paper investigates its extension to stochastic games. In the context of\nprice competition, each agent is benchmarked against the best quote offered by\nthe others. We begin with the linear case. While constructing the solution\ndirectly, the \\textit{ordering property} and the dimension reduction in the\nequilibrium are revealed. For the non-linear case, we extend the decoupling\napproach by introducing a multidimensional \\textit{characteristic equation} to\nanalyse the well-posedness of the forward-backward stochastic differential\nequations. Properties of the coefficients in this characteristic equation are\nderived using tools from non-smooth analysis. Several new well-posedness\nresults are presented.", "updated": "2025-04-10T01:11:15Z", "published": "2024-06-09T06:37:09Z"}