{"title": "Exact Exploratory Bi-factor Analysis: A Constraint-based Optimisation\n  Approach", "sections": [{"section_id": 0, "text": "## Optimisation Approach\n\nJiawei Qiao, Yunxiao Chen and Zhiliang Ying", "tables": {}, "images": {}}, {"section_id": 1, "text": "#### Abstract\n\nBi-factor analysis is a form of confirmatory factor analysis widely used in psychological and educational measurement. The use of a bi-factor model requires the specification of an explicit bi-factor structure on the relationship between the observed variables and the group factors. In practice, the bi-factor structure is sometimes unknown, in which case an exploratory form of bi-factor analysis is needed to find the bi-factor structure. Unfortunately, there are few methods for exploratory bi-factor analysis, with the exception of a rotation-based method proposed in Jennrich and Bentler (2011, 2012). However, the rotation-based method only finds approximate bi-factor structures, as it does not yield an exact bi-factor loading structure, even after applying hard thresholding. In this paper, we propose a constraint-based optimisation method that learns an exact bi-factor loading structure from data, overcoming the issue with the rotation-based method. The key to the proposed method is a mathematical characterisation of the bi-factor loading structure as a set of equality constraints, which allows us to formulate the exploratory bi-factor analysis problem as a constrained optimisation problem in a continuous domain and solve the optimisation problem with an augmented Lagrangian method. The power of the proposed method is shown via simulation studies and a real data example. Extending the proposed method to exploratory hierarchical factor analysis is also discussed. Code implementing the proposed method is open-source and publicly available at https://anonymous.4open.science/r/Bifactor-ALM-method-757D.\n\n\nKeywords: Bi-factor model, augmented Lagrangian method, exploratory bi-factor analysis, hierarchical factor model", "tables": {}, "images": {}}, {"section_id": 2, "text": "## 1 Introduction\n\nThe bi-factor model was originally proposed by Holzinger and Swineford (1937) for linear factor analysis and further extended by Gibbons and Hedeker (1992), Gibbons et al. (2007), Cai et al. (2011), among others, to nonlinear factor analysis settings to account for dichotomous, ordinal, and nominal data. These models\n\nassume that the observed variables can be accounted for by $(G+1)$ factors, with a general factor, onto which all items load directly, and $G$ group factors that each is associated with a subset of variables. Such a specification leads to good interpretations in many real-world applications. These models have received wide applications in psychological and educational measurement; see e.g., Bradlow et al. (1999); Cai et al. (2016); Chen et al. (2012); DeMars (2006, 2012); Gibbons et al. (2009); Gignac and Watkins (2013); Jeon et al. (2013); Reise et al. (2007); Rijmen (2010). However, we note that all these applications of bi-factor analysis are confirmatory in the sense that one needs to pre-specify the number of group factors and the relationship between the observed variables and the group factors. Such prior knowledge may not always be available. In that case, an exploratory form of bi-factor analysis is needed.\n\nExploratory bi-factor analysis can be seen as a special case of exploratory factor analysis, which dates back to the seminal work of Thurstone (1947) concerning finding a \u201csimple structure\u201d of loadings. Various rotation methods have been proposed for exploratory factor analysis. A short list of relevant works includes Kaiser (1958), McCammon (1966), Jennrich and Sampson (1966), McKeon (1968), Crawford and Ferguson (1970), Yates (1987), Jennrich (2006), Jennrich (2004), Jennrich and Bentler (2011, 2012), and Liu et al. (2023). We refer the readers to Browne (2001) for a review of rotation methods for exploratory factor analysis.\n\nHowever, standard exploratory factor analysis methods do not apply to the bi-factor analysis setting, and few methods have been developed for exploratory bi-factor analysis. An exception is the seminal work of Jennrich and Bentler (2011, 2012), who proposed a rotation-based method for exploratory bi-factor analysis with orthogonal or oblique factors. However, their approach has some limitations. First, as a common issue with rotation-based methods, their method does not yield many zero loadings, and thus, the resulting loading structure does not have an exact bi-factor structure. Although a post-hoc thresholding procedure (i.e., treating loadings with an absolute value below a threshold as zero) can be applied to obtain a cleaner loading pattern, it does not work well when some variables show relatively large loadings on more than one group factor after the rotation. In fact, one cannot always find a threshold that yields an exact bi-factor structure that each variable loads on one and only one group factor. Second, as noted in Jennrich and Bentler (2012), their method fails completely in the best case where there is a rotation of an initial loading matrix that has an exact bi-factor structure. This failure is due to that their rotation method cannot incorporate the zero constraints on the correlations between the general factor and the group factors.\n\nThis paper proposes a constrained optimisation method for exploratory bi-factor analysis, which overcomes the issues with the rotation-based method. The contribution is four-fold. First, we provide a mathematical characterisation of the bi-factor loading structure as a set of nonlinear equality constraints, which allows us to formulate the exploratory bi-factor analysis problem as a constrained optimisation problem.\n\nIn other words, it turns a discrete model selection problem into a continuous optimisation problem, which reduces the computational demand in some sense. It is shown that in the aforementioned best case where the rotation method fails, the global solutions to the optimisation can perfectly recover the true bi-factor structure. Second, we propose an augmented Lagrangian method (ALM, Bertsekas, 2014) for solving this optimisation problem, which is a standard numerical optimisation method for solving constrained optimisation with robust empirical performance and good theoretical properties. Third, we combine the proposed method with the Bayesian information criterion (BIC, Schwarz, 1978) for selecting the number of group factors. Compared with existing exploratory factor analysis methods for determining the number of factors, our method is tailored to the bi-factor model structure and, thus, tends to be statistically more efficient when the data is indeed generated by a bi-factor model. Finally, we demonstrate that the proposed method can be extended to learning the loading structure of hierarchical factor models (Schmid and Leiman, 1957; Yung et al., 1999), a higher-order extension of the bi-factor model that has received wide applications (see, e.g., Brunner et al., 2012, and references therein). The bi-factor model can be viewed as a special hierarchical factor model with a two-layer factor structure, with the general factor in one layer and the group factors in the other. Similar to exploratory bi-factor analysis, the proposed method yields exact hierarchical factor loading structures without a need for post-hoc treatments.\n\nThe rest of the paper is organised as follows. In Section 2, we formulate the exploratory bi-factor analysis problem as a constrained optimisation problem and propose an ALM for solving it. We also propose a BICbased procedure for selecting the number of group factors. Simulation studies and a real data example are presented in Sections 3 and 4, respectively, to evaluate the performance of the proposed method. We conclude with discussions in Section 5. The appendix in the supplementary material includes additional details about the computation, the simulation studies and the real data example, an extension of the proposed method to exploratory hierarchical factor analysis, and proof of the theoretical results.", "tables": {}, "images": {}}, {"section_id": 3, "text": "# 2 Exploratory Bi-factor Analysis by Constrained Optimisation\n### 2.1 Bi-factor Model Structure and a Constrained Optimisation Formulation\n\nFor the ease of exposition and simplification of the notation, we focus on the linear bi-factor model, while noting that the constraints that we derive for the bi-factor loading matrix below can be combined with the likelihood function of other bi-factor models (e.g., Gibbons and Hedeker, 1992; Gibbons et al., 2007; Cai et al., 2011) for their exploratory analysis. We focus on the extended bi-factor model, also known as the oblique bi-factor model, as considered in Jennrich and Bentler (2012) and Fang et al. (2021). This model is\n\nmore general than the standard bi-factor model, in the sense that the latter assumes all the factors to be uncorrelated while the former allows the group factors to be correlated. As established in Fang et al. (2021), this extended bi-factor model is identifiable under mild conditions. We also point out that the proposed method can be easily adapted to the standard bi-factor model.\n\nConsider a dataset with $N$ observation units from a certain population and $J$ observed variables. The extended bi-factor model assumes that there exists a general factor and $G$ group factors. The group factors are loaded by independent clusters of variables, where each variable belongs to only one cluster. The model further assumes that the population covariance matrix of the observed variables can be decomposed as\n\n$$\n\\Sigma=\\Lambda \\Phi \\Lambda^{\\top}+\\Psi\n$$\n\nwhere $\\Lambda=\\left(\\lambda_{j g}\\right)_{J \\times(G+1)}$ is the loading matrix, $\\Phi=\\left(\\phi_{g g^{\\prime}}\\right)_{(G+1) \\times(G+1)}$ is the correlation matrix of the factors, which is assumed to be strictly positive definite, and $\\Psi$ is a $J \\times J$ diagonal matrix with diagonal entries $\\psi_{1}, \\ldots, \\psi_{J}$. Let $\\mathcal{B}_{g} \\subset\\{1, \\ldots, J\\}$ denote the cluster of variables loading on the $g$ th group factor. Then the bi-factor model assumption implies that $\\mathcal{B}_{g} \\cap \\mathcal{B}_{g^{\\prime}}=\\varnothing, g \\neq g^{\\prime}$, and $\\cup_{g=1}^{G} \\mathcal{B}_{g}=\\{1, \\ldots, J\\}$. The following zero constraints on the loading matrix $\\Lambda$ hold:\n\n$$\n\\lambda_{j, g+1}=0 \\text { for all } j \\notin \\mathcal{B}_{g}\n$$\n\nIn addition, the correlation matrix $\\Phi$ satisfies $\\phi_{1 k}=0$ for all $k \\neq 1$, meaning that all the group factors are uncorrelated with the general factor. This constraint on $\\Phi$ is necessary to ensure that the extended bi-factor model is identifiable (Fang et al., 2021), as otherwise, there will be a rotational indeterminacy issue.\n\nNow suppose that the number of group factors $G$ is known, while the clusters $\\mathcal{B}_{g}, g=1, \\ldots, G$, are unknown. Section 2.3 considers the selection of $G$ when it is unknown. The bi-factor structure means that for each $j$, there is at most one non-zero element in $\\left(\\lambda_{j, 2}, \\ldots, \\lambda_{j, G+1}\\right)^{\\top}$. Consequently, the loading matrix $\\Lambda$ should satisfy the following $J(G-1) G / 2$ constraints:\n\n$$\n\\lambda_{j k} \\lambda_{j k^{\\prime}}=0, \\text { for all } k, k^{\\prime}=2, \\ldots, G+1, k \\neq k^{\\prime}, j=1, \\ldots, J\n$$\n\nTherefore, the exploratory bi-factor analysis problem can be translated into the following constrained\n\noptimisation problem\n\n$$\n\\begin{aligned}\n\\min _{\\Lambda, \\Psi, \\Psi} & l\\left(\\Lambda \\Phi \\Lambda^{\\top}+\\Psi ; S\\right) \\\\\n\\text { s.t. } & \\lambda_{j k} \\lambda_{j k^{\\prime}}=0, \\text { for all } k, k^{\\prime}=2, \\ldots, G+1, k \\neq k^{\\prime}, j=1, \\ldots, J \\\\\n& \\phi_{1 k}=0, k=2, \\ldots, G+1, \\Phi \\text { is correlation matrix, } \\\\\n& \\text { and } \\Psi \\text { is a diagonal matrix, }\n\\end{aligned}\n$$\n\nwhere $l$ is a loss function and $S$ is the sample covariance matrix of observed data. We focus on the case when $l$ is the fit function based on the normal likelihood\n\n$$\nl\\left(\\Lambda \\Phi \\Lambda^{\\top}+\\Psi ; S\\right)=N\\left(\\log \\left(\\operatorname{det}\\left(\\Lambda \\Phi \\Lambda^{\\top}+\\Psi\\right)\\right)+\\operatorname{tr}\\left(S\\left(\\Lambda \\Phi \\Lambda^{\\top}+\\Psi\\right)^{-1}\\right)-\\log (\\operatorname{det}(S))-J\\right)\n$$\n\nwhile noting that this loss function can be replaced by other loss functions for factor analysis (see, e.g., Chen et al., 2023), including the Frobeneious norm of $\\Lambda \\Phi \\Lambda^{\\top}+\\Psi-S$ that is used in the least square estimator for factor analysis. We can also replace the sample covariance matrix in (2) with the sample correlation matrix, which is equivalent to performing exploratory bi-factor analysis based on variance-standardised variables.\n\nThe following theorem shows that the proposed method can perfectly recover the true bi-factor loading structure in the best case when $S=\\Sigma^{*}$, where $\\Sigma^{*}$ is the true covariance matrix of data. Note that the rotation method proposed in Jennrich and Bentler (2012) completely fails in this case. Before giving the statement of the theorem, we introduce some additional notations. For any matrix $A=\\left(a_{i, j}\\right)_{i=1, \\ldots, m, j=1, \\ldots, n}$, $\\mathcal{S}_{1} \\subset\\{1, \\ldots, m\\}$ and $\\mathcal{S}_{2} \\subset\\{1, \\ldots, n\\}$, let $A\\left[\\mathcal{S}_{1}, \\mathcal{S}_{2}\\right]=\\left(a_{i, j}\\right)_{i \\in \\mathcal{S}_{1}, j \\in \\mathcal{S}_{2}}$ be the submatrix of $A$ consisting of elements that lie in rows belonging to set $\\mathcal{S}_{1}$ and columns belonging to set $\\mathcal{S}_{2}$. For example, consider a matrix $A$ with more than two rows and three columns. With index sets $\\mathcal{S}_{1}=\\{1,2\\}$ and $\\mathcal{S}_{2}=\\{1,3\\}$, the submatrix $A\\left[\\mathcal{S}_{1}, \\mathcal{S}_{2}\\right]$ is a two-by-two matrix, taking the form\n\n$$\nA\\left[\\mathcal{S}_{1}, \\mathcal{S}_{2}\\right]=A[\\{1,2\\},\\{1,3\\}]=\\left(\\begin{array}{ll}\na_{11} & a_{13} \\\\\na_{21} & a_{23}\n\\end{array}\\right)\n$$\n\nFor any set $\\mathcal{S}$, let $|\\mathcal{S}|$ be the cardinality of $\\mathcal{S}$.\nLet $\\left\\{\\mathcal{B}_{g}^{*}, g=1, \\ldots, G\\right\\}$ be the true non-overlapping clusters of the $J$ variables, satisfying for each $j \\in \\mathcal{B}_{g}^{*}$, $\\lambda_{j, g+1}^{*} \\neq 0, g=1, \\ldots, G$. Further let $\\mathcal{H}^{*}=\\left\\{g \\mid \\Lambda^{*}\\left[B_{g}^{*},\\{1,1+g\\}\\right]\\right.$ has column rank 2$\\}$ be the set of group factors for which the group loadings are linearly independent of the corresponding common loadings. Let\n\n$\\mathcal{D}$ be the set of diagonal matrix with its diagonal entries taking values either 1 or -1 , and $\\mathcal{P}$ be the set of permutation matrix $P$ such that each row and column of $P$ has exactly one nonzero entry of value 1 and $P_{11}=1$. Each matrix in $\\mathcal{D}$ corresponds to a simultaneous sign flip of certain factors and the corresponding loading parameters. Each matrix in $\\mathcal{P}$ corresponds to a swapping of certain columns in the loading matrix associated with the group factors or, equivalently, a relabelling of the group factors. They are introduced to account for the sign-indeterminacy of the $G+1$ factors and the label indeterminacy of the group factors, respectively. See Theorem 1 and Remark 1 below for more explanations.\n\nLet $\\Lambda^{*}, \\Phi^{*}$ and $\\Psi^{*}$ be the true values of the corresponding parameter matrices. The following conditions are sufficient for the identifiability of the bi-factor structure and its parameters.\n\nCondition 1. Given $S=\\Sigma^{*}=\\Lambda^{*} \\Phi^{*}\\left(\\Lambda^{*}\\right)^{\\top}+\\Psi^{*}$. Suppose that there exists another pair of parameters $\\Lambda, \\Phi, \\Psi$ satisfy the bi-factor structure constraints, we have $\\Lambda^{*} \\Phi^{*}\\left(\\Lambda^{*}\\right)^{\\top}=\\Lambda \\Phi(\\Lambda)^{\\top}$ and $\\Psi^{*}=\\Psi$.\n\nCondition 2. $\\left|\\mathcal{H}^{*}\\right| \\geqslant 2$. In addition, there exists $g_{1} \\in \\mathcal{H}^{*}$ such that $\\left|\\mathcal{B}_{g_{1}}^{*}\\right| \\geqslant 3$ and any 2 rows of $\\Lambda^{*}\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1,1+g_{1}\\right\\}\\right]$ are linearly independent.\n\nTheorem 1. Suppose that Conditions 1 and 2 hold. For any parameters $\\Lambda, \\Phi, \\Psi$ that satisfy $S=\\Sigma^{*}=$ $\\Lambda \\Phi(\\Lambda)^{\\top}+\\Psi$, there exist a diagonal sign-flip matrix $D \\in \\mathcal{D}$ and a permutation matrix $P \\in \\mathcal{P}$ such that $\\Lambda=\\Lambda^{*} P D$ and $\\Phi=D P^{\\top} \\Phi^{*} P D$.\n\nThe proof of Theorem 1 is given in Appendix G.1.\nRemark 1. We note that without additional information, the best we can achieve is to recover $\\Lambda^{*}$ and $\\Phi^{*}$ up to $\\Lambda=\\Lambda^{*} P D$ and $\\Phi=D P^{\\top} \\Phi^{*} P D$, where the permutation matrix $P$ and sign-flip matrix $D$ are necessary to account for the label and sign indeterminacies of the factor model. In that case, $\\Lambda^{*} \\Phi^{*}\\left(\\Lambda^{*}\\right)^{\\top}=\\Lambda \\Phi(\\Lambda)^{\\top}$, and thus, the model implied covariance matrix is the same. A similar indeterminacy issue also appears in exploratory factor analysis; see, e.g., Remark 1 in Liu et al. (2023).\n\nRemark 2. Condition 1 ensures the separation between low rank matrix $\\Lambda^{*} \\Phi^{*}\\left(\\Lambda^{*}\\right)^{\\top}$ and diagonal matrix $\\Psi^{*}$. A sufficient condition for Condition 1 that can be easily checked in practice is given in Condition 3 below, which requires that each group has at least three non-zero group loadings and there exist at least three groups whose group loadings are linearly independent of the corresponding common loadings. We refer to Theorem 5.1 in Anderson and Rubin (1956) and Theorem 2 in Fang et al. (2021) for alternative sufficient conditions of Condition 1.\n\nCondition 3. $\\left|\\mathcal{B}_{g}^{*}\\right| \\geqslant 3$ for all $g=1, \\ldots, G$ and $\\left|\\mathcal{H}^{*}\\right| \\geqslant 3$.\n\nRemark 3. Condition 2 is similar to Condition E3S for Proposition 1 in Fang et al. (2021), where the latter is used to ensure the identifiability of parameters when the bi-factor structure is known. It is a sufficient condition that ensures if there is a pair of $\\Lambda$ and $\\Phi$ that also satisfies the constraints of a bi-factor model and $\\Lambda \\Phi \\Lambda^{\\top}=\\Lambda^{*} \\Phi^{*}\\left(\\Lambda^{*}\\right)^{\\top}$, then there must be a permutation matrix $P$ and sign-flip matrix $D$ such that $\\Lambda=\\Lambda^{*} P D$ and $\\Phi=D P^{\\top} \\Phi^{*} P D$. This condition first requires the existence of at least two group factors, for each of which the group loadings are linearly independent of the corresponding common loadings. It further requires that there exists a group factor $g_{1}$ among these group factors, such that (1) $g_{1}$ has at least three nonzero group loadings, and (2) any two-by-two submatrix of $\\Lambda^{*}$, whose rows correspond to any two variables loading on $g_{1}$ and columns correspond to the common factor and the group factor $g_{1}$, is of full rank. We note that the requirement of Condition 2 is very mild. In fact, the set of parameters not satisfying this condition has zero Lebesgue measure in the parameter space for bi-factor models satisfying that there are at least two group factors $g_{1}$ and $g_{2}$ such that $\\left|\\mathcal{B}_{\\mathrm{g}_{1}}^{*}\\right| \\geqslant 3$ and $\\left|\\mathcal{B}_{\\mathrm{g}_{2}}^{*}\\right| \\geqslant 2$.", "tables": {}, "images": {}}, {"section_id": 4, "text": "# 2.2 Proposed ALM \n\nFollowing the previous discussion, we see that we can perform exploratory bi-factor analysis by solving the optimisation problem with some equality constraints and the constraint that $\\Phi$ is a correlation matrix. To deal with the constraints in $\\Phi$, we consider a reparameterisation of $\\Phi$ based on a Cholesky decomposition, where the explicit form of the reparametrisation is given in Appendix A. With slight abuse of notation, we reexpress the covariance matrix as $\\Phi(\\gamma)$, where $\\gamma$ is a $G(G-1) / 2$ dimensional unconstrained parameter vector. In addition, we use $\\boldsymbol{\\psi}=\\left(\\psi_{1}, \\ldots, \\psi_{J}\\right)^{\\top}$ to denote the vector of diagonal entries of $\\Psi$ and reexpress the residual covariance matrix as $\\Psi(\\boldsymbol{\\psi})$. Thus, the optimisation problem (2) is now simplified as\n\n$$\n\\begin{aligned}\n\\min _{\\Lambda, \\gamma, \\boldsymbol{\\psi}} & l\\left(\\Lambda \\Phi(\\gamma) \\Lambda^{\\top}+\\Psi(\\boldsymbol{\\psi}) ; S\\right) \\\\\n\\text { s.t. } & \\lambda_{j k} \\lambda_{j k^{\\prime}}=0, \\text { for all } k, k^{\\prime}=2, \\ldots, G+1, k \\neq k^{\\prime}, j=1, \\ldots, J\n\\end{aligned}\n$$\n\nwhich is an equality-constrained optimisation problem.\nThe standard approach for solving such a problem is the augmented Lagrangian method (e.g., Bertsekas, 2014). This method aims to find a solution to (3) by solving a sequence of unconstrained optimisation problems. Let $t$ denote the $t$ th unconstrained optimisation problem in the ALM. The corresponding objective function, also known as the augmented Lagrangian function, takes the form\n\n$$\n\\min _{\\Lambda, \\gamma, \\boldsymbol{\\psi}} \\quad l\\left(\\Lambda \\Phi(\\gamma) \\Lambda^{\\top}+\\Psi(\\boldsymbol{\\psi}) ; S\\right)+\\left(\\sum_{j=1}^{J} \\sum_{k=2}^{G} \\sum_{k^{\\prime}=k+1}^{G+1} \\beta_{j k k^{\\prime}}^{(t-1)} \\lambda_{j k} \\lambda_{j k^{\\prime}}\\right)+\\frac{1}{2} c^{(t-1)}\\left(\\sum_{j=1}^{J} \\sum_{k=2}^{G} \\sum_{k^{\\prime}=k+1}^{G+1}\\left(\\lambda_{j k} \\lambda_{j k^{\\prime}}\\right)^{2}\\right)\n$$\n\nwhere $c^{(t-1)}>0$ and $\\beta_{j k k^{\\prime}}^{(t-1)}$ s are auxiliary coefficients of the ALM determined by the initial values when $t=1$ and the previous optimisation when $t \\geqslant 2$. Details of the ALM are given in Algorithm 1 below, in which the function $h$ returns the second-largest value of a vector.\n\nThe ALM can be seen as a penalty method for solving constrained optimization problems. It replaces a constrained optimization problem with a series of unconstrained problems. It adds a penalty term, i.e., the third term in (4), to the objective to enforce the constraints. The tuning parameter $c^{(t-1)}$ can be seen as the weight of the penalty term. In fact, as $c^{(t)}$ goes to infinity while $\\beta_{j k k^{\\prime}}^{(t)}$ s remain bounded, the solution has to converge to one satisfying the equality constraints in (3), as otherwise, the objective function value in (4) will diverge to infinity. However, the ALM is not purely a penalty method in the sense that it also adds the second term in (4) to mimic a Lagrange multiplier (see, e.g., Chapter 12, Nocedal and Wright, 1999), for which $\\beta_{j k k^{\\prime}}^{(t-1)}$ s are the weights. An advantage of the ALM is that, with the inclusion of the Lagrangian term (i.e., the second term), the method is guaranteed to converge to a local solution satisfying the equality constraints without requiring $c^{(t)}$ to go to infinity. This is important, as when $c^{(t)}$ is very large, the optimisation problem (4) becomes ill-conditioned and thus hard to solve.\n\n```\nAlgorithm 1 Augmented Lagrangian Method for Exact Exploratory Bi-factor Analysis\nInput: Initial value \\(\\Lambda^{(0)}, \\boldsymbol{\\gamma}^{(0)}\\) and \\(\\boldsymbol{\\psi}^{(0}\\), initial Lagrangian parameters \\(\\beta_{j, k, k^{\\prime}}^{(0)}\\) for \\(j=1, \\ldots, J, k=2, \\ldots, G\\)\n    and \\(k^{\\prime}=k+1, \\ldots, G+1\\), initial penalty coefficient \\(c^{(0)}>0\\), constants \\(c_{\\theta} \\in(0,1)\\) and \\(c_{\\sigma}>1\\), tolerances\n    \\(\\delta_{1}, \\delta_{2}>0\\).\n    while \\(t=1,2, \\ldots\\) do\n        Solve the following problem:\n        \\(\\Lambda^{(t)}, \\gamma^{(t)}, \\psi^{(t)}\\)\n    \\(=\\arg \\min _{\\Lambda, \\gamma, \\psi} \\quad l\\left(\\Lambda \\Phi(\\gamma) \\Lambda^{\\top}+\\Psi(\\psi) ; S\\right)+\\left(\\sum_{j=1}^{J} \\sum_{k=2}^{G} \\sum_{k^{\\prime}=k+1}^{G+1} \\beta_{j k k^{\\prime}}^{(t-1)} \\lambda_{j k} \\lambda_{j k^{\\prime}}\\right)+\\frac{1}{2} c^{(t-1)}\\left(\\sum_{j=1}^{J} \\sum_{k=2}^{G} \\sum_{k^{\\prime}=k+1}^{G+1}\\left(\\lambda_{j k} \\lambda_{j k^{\\prime}}\\right)^{2}\\right) \\cdot\\)\n    Update \\(\\beta_{j k k^{\\prime}}^{(t)}\\) and \\(c^{(t)\\) according to equations (5) and (6)\n    \\(f_{j k k^{\\prime}}^{(t)}=\\beta_{j k k^{\\prime}}^{(t-1)}+c^{(t-1)} \\lambda_{j k}^{(t)} \\lambda_{j k^{\\prime}}^{(t)}\\)\n    and\n    \\(c^{(t)}=\\left\\{\\begin{array}{l} c_{\\sigma} c^{(t-1)} \\text { if }\\left(\\sum_{j=1}^{J} \\sum_{k=2}^{G} \\sum_{k^{\\prime}=k+1}^{G+1}\\left(\\lambda_{j k}^{(t)} \\lambda_{j k^{\\prime}}^{(t)}\\right)^{2}\\right)^{1 / 2}>c_{\\theta}\\left(\\sum_{j=1}^{J} \\sum_{k=2}^{G} \\sum_{k^{\\prime}=k+1}^{G+1}\\left(\\lambda_{j k}^{(t-1)} \\lambda_{j k^{\\prime}}^{(t-1)}\\right)^{2}\\right)^{1 / 2} ; \\\\ c^{(t-1)} \\text { otherwise. }\\end{array}\\right.\\)\n    if \\(\\left(\\frac{1}{2} \\Lambda^{(t)}-\\Lambda^{(t-1)} \\frac{2}{3} \\frac{2}{F}+\\frac{2}{3} \\gamma^{(t)}-\\gamma^{(t-1)} \\frac{2}{3}+\\frac{2}{3} \\psi^{(t)}-\\psi^{(t-1)} \\frac{2}{3}\\right)^{1 / 2} / \\sqrt{J(G+2)+G(G-1) / 2}<\\delta_{1}\\),\n    5: and \\(\\max _{j \\in\\{1, \\ldots, J\\}} h\\left(\\left|\\lambda_{j 2}^{(t)}\\right|, \\ldots,\\left|\\lambda_{j, G+1}^{(t)}\\right|\\right)<\\delta_{2}\\) then\n        Break\n    end if\n    end while\nOutput: \\(\\Lambda^{(t)}, \\gamma^{(t)}, \\psi^{(t)}\\)\n\nThe updating rule of $\\beta_{j k k^{\\prime}}^{(t)}$ and $c^{(t)}$ follows equation (1) and (47) in Chapter 2.2 of Bertsekas (2014). The updating rule for $\\beta_{j k k^{\\prime}}^{(t)}$ follows the first-order optimality condition based on optimisations (3) and (4). The updating rule for $c^{(t)}$ ensures that it will become sufficiently large, which is necessary to guarantee the solution of the algorithm to converge to the feasible region defined by the zero constraints. On the other hand, it also prevents $c^{(t)}$ from growing too quickly with which the optimisation (4) is ill-conditioned. As shown in Chapter 2.2 of Bertsekas (2014), as long as the sequences $\\left\\{\\beta_{j k k^{\\prime}}^{(t)}\\right\\}$ remain bounded, the sequence $\\left\\{c^{(t)}\\right\\}$ remains bounded. We follow the recommended choices of $c_{\\theta}=0.25$ and $c_{\\sigma}=10$ in Bertsekas (2014), while pointing out that the performance of Algorithm 1 is quite robust against the choices of these tuning parameters; see Appendix C for a sensitivity analysis. The convergence of Algorithm 1 is guaranteed by Proposition 2.7 of Bertsekas (2014).\n\nWe remark on the stopping criterion in the implementation of Algorithm 1. We monitor the convergence of the algorithm based on two criteria: (1) the change in parameter values in two consecutive steps, measured by\n\n$$\n\\left(\\left\\|\\Lambda^{(t)}-\\Lambda^{(t-1)}\\right\\|_{F}^{2}+\\left\\|\\gamma^{(t)}-\\gamma^{(t-1)}\\right\\|^{2}+\\left\\|\\boldsymbol{\\psi}^{(t)}-\\boldsymbol{\\psi}^{(t-1)}\\right\\|^{2}\\right)^{1 / 2} / \\sqrt{J(G+2)+G(G-1) / 2}\n$$\n\nwhere $\\|\\cdot\\|_{F}$ denotes the Frobeneious norm of a matrix and $\\|\\cdot\\|$ denotes the standard Euclidian norm, and (2) the distance between the estimate and the space of bi-factor loading matrices measured by\n\n$$\n\\max _{j \\in\\{1, \\ldots, J\\}} h\\left(\\left|\\lambda_{j 2}^{(t)}\\right|, \\ldots,\\left|\\lambda_{j, G+1}^{(t)}\\right|\\right)\n$$\n\nWe stop the algorithm when both criteria are below their pre-specified thresholds, $\\delta_{1}$ and $\\delta_{2}$, respectively. The first criterion is a standard criterion for monitoring parameter convergence. This criterion being sufficiently small suggests the convergence of the algorithm. The second criterion is used to ensure that the solution is sufficiently close to the feasible set of optimisation defined by the equality constraints. This criterion being below $\\delta_{2}$ means that for each variable $j$, there can only be one group loading whose absolute value is above the threshold $\\delta_{2}$, and all the rest have absolute values below the threshold. Based on this, we can obtain an estimate of the bi-factor structure. More specifically, let $T$ be the last iteration number. Then the estimated bi-factor model structure is given by\n\n$$\n\\widehat{\\mathcal{B}}_{g}=\\left\\{j:\\left|\\lambda_{j, g+1}^{(T)}\\right|>\\delta_{2}\\right\\}\n$$\n\nBy our choice of the stopping criterion, the resulting $\\widehat{\\mathcal{B}}_{g}, g=1, \\ldots, G$, gives a partition of all the variables, and thus, the bi-factor structure is satisfied. For simulation studies in Section 3, we choose $\\delta_{1}=\\delta_{2}=10^{-2}$. For real data analysis in Section 4, we choose $\\delta_{1}=\\delta_{2}=10^{-4}$ to get a more accurate and reliable result.\n\nThe optimisation problem (4) is non-convex and can get stuck in a local minimum. Thus, we recommend\n\nrunning the proposed algorithm multiple times with random starting points and choosing the solution with the smallest objective function value. The algorithm can also suffer from slow convergence, especially when the penalty term becomes large. When the algorithm does not converge within $T_{\\max }$ iterations, we suggest using the estimated parameters at the $T_{\\max }$ th iteration as the initial parameters and restarting the optimisation until a good proportion of them converge. In the simulation study in Section 3 below, the estimated parameters obtained using 50 random starting points are close to the global minimum in most cases in the simulation study. For the real data example in Section 4, 200 random starting points are used to ensure a reliable result. We set $T_{\\max }=100$ in all of our numerical studies.", "tables": {}, "images": {}}, {"section_id": 5, "text": "# 2.3 Selecting the Number of Group Factors \n\nIn Sections 2.1 and 2.2, the number of group factors $G$ is treated as known. In practice, we can select its value based on the BIC (Schwarz, 1978). Let $l_{G}$ denote the minimum loss function value in (2) when the number of group factors is $G$. As $l_{G}$ differs from twice the negative log-likelihood of the bi-factor model with $G$ group factors by a constant, and the numbers of nonzero parameters in $\\Lambda$ and $\\Psi$ do not depend on $G$, it is not difficult to see that the BIC of the bi-factor model with $G$ group factors differs from $l_{G}+((G-1) G \\log (N)) / 2$ by a constant. Note that $(G-1) G / 2$ is the number of free parameters in the correlation matrix $\\Phi$. Thus, we write\n\n$$\n\\mathrm{BIC}_{G}=l_{G}+((G-1) G \\log (N)) / 2\n$$\n\nIn practice, we choose the number of group factors $G$ from a candidate set $\\mathcal{G}$. For each value of $G \\in \\mathcal{G}$, we run the ALM described in Section 2.2 to obtain the value of $l_{G}$. We then compute $\\mathrm{BIC}_{G}$ and choose $\\widehat{G}$ with the smallest BIC value, i.e.,\n\n$$\n\\widehat{G}=\\underset{G \\in \\mathcal{G}}{\\arg \\min } \\mathrm{BIC}_{G}\n$$", "tables": {}, "images": {}}, {"section_id": 6, "text": "## 3 Simulation Study\n### 3.1 Study I\n\nIn this study, we compare the proposed method with the oblique bi-factor rotation in Jennrich and Bentler (2012) regarding their performance in the estimation accuracy of parameters and the recovery of the bi-factor structure. We consider two different settings for the data generation mechanism: (1) the observed data are generated from an exact bi-factor model, and (2) the observed data are generated from an approximate bi-factor model, where the loading matrix is generated by adding small perturbations to an exact bi-factor loading matrix.\n\nThe oblique bi-factor rotation method first estimates the loading matrix $\\widehat{\\Lambda}$ under the exploratory factor analysis setting by the optimisation problem\n\n$$\n\\widehat{\\Lambda}, \\widehat{\\psi}=\\underset{\\Lambda \\in \\mathbb{R}^{J+(G+1)}, \\psi \\in \\mathbb{R}^{J}}{\\arg \\min } l\\left(\\Lambda \\Lambda^{\\top}+\\Psi(\\psi) ; S\\right)\n$$\n\nWe restrict $\\lambda_{i j}=0$ for $i=2, \\ldots, G$ and $j=i+1, \\ldots, G+1$ to avoid the rotational indeterminacy of $\\widehat{\\Lambda}$, as suggested in Anderson and Rubin (1956). Then the rotated solutions $\\widehat{\\Lambda}^{o b l q}$ and $\\widehat{\\Phi}^{o b l q}$ are obtained by finding a rotation matrix that solves the optimisation problem for oblique bi-factor rotation (Jennrich and Bentler, 2012). The implementation in the R package GPArotation (Bernaards and Jennrich, 2005) is used for solving this optimisation problem, which is based on a gradient projection algorithm. The optimisation problem for rotation is also nonconvex and thus may converge to local solutions. For a fair comparison, we also use 50 random starting points for the initial rotation matrix, which is the same as the number of random starting points that are used when running Algorithm 1.\n\nWe first examine the accuracy in estimating the loading matrix. We calculate the mean squared error (MSE) for $\\widehat{\\Lambda}$, after adjusting for the label and sign indeterminacy as considered in Theorem 1 and further discussed in Remark 1. More specifically, let $\\mathcal{P}$ and $\\mathcal{D}$ be the sets of permutation and sign flip matrices, respectively, as defined in Theorem 1. We define the MSE for $\\widehat{\\Lambda}$ as\n\n$$\n\\mathrm{MSE}_{\\widehat{\\Lambda}}=\\min _{P \\in \\mathcal{P}, D \\in \\mathcal{D}}\\left\\|\\widehat{\\Lambda}-\\Lambda^{*} P D\\right\\|_{F}^{2} /(J(1+G))\n$$\n\nNote that when data are generated from an approximate bi-factor model, $\\Lambda^{*}$ does not have an exact bi-factor structure. This MSE is calculated for the loading matrix estimates from both methods.\n\nTo compare the two methods in terms of their performance in recovering the bi-factor structure, we derive a sparse loading structure from the rotated solution by hard thresholding, a procedure also performed in Jennrich and Bentler (2012) for examining structure recovery. We let\n\n$$\n\\widehat{\\mathcal{B}}_{g}^{o b l q}=\\left\\{j:\\left|\\lambda_{j, g+1}^{o b l q}\\right|>\\delta\\right\\}\n$$\n\nfor $g=1, \\ldots, G$ and some hard thresholding parameter $\\delta>0$. In the analysis below, we consider three choices of hard thresholding parameter $\\delta \\in\\{0.1,0.2,0.3\\}$. We note that $\\widehat{\\mathcal{B}}_{g}^{o b l q}, g=1, \\ldots, G$, may not yield an exact bi-factor structure as it is not guaranteed to return only one nonzero group loading parameter for each variable.\n\nLet $\\left\\{\\mathcal{B}_{g}^{*}, g=1, \\ldots, G\\right\\}$ be the true non-overlapping clusters of the $J$ variables, and let $\\left\\{\\mathcal{B}_{g}, g=1, \\ldots, G\\right\\}$\n\nbe their estimates, either from the proposed method or the rotation method. When data are generated from an approximate bi-factor model, the true group clusters $\\left\\{\\mathcal{B}_{g}^{*}, g=1, \\ldots, G\\right\\}$ are based on the corresponding bi-factor loading matrix before the perturbation. As the group factors can only be recovered up to label swapping, as Theorem 1 suggests, we measure the matching between the true and estimated structure up to a permutation of the factor labels. Specifically, the following two evaluation criteria are considered:\n\n- Exact Match Criterion (EMC): $\\max _{\\sigma \\in \\widehat{P}} \\prod_{g=1}^{G} \\mathbf{1}\\left(\\mathcal{B}_{\\sigma(g)}=\\mathcal{B}_{g}^{*}\\right)$, which equals 1 when the bi-factor structure is correctly learned and 0 otherwise. Here, $(\\sigma(1), \\ldots, \\sigma(G))$ is a permutation of $1, \\ldots, G$, and $\\widehat{\\mathcal{P}}$ is the set of all such permutations.\n- Average Correctness Criterion (ACC): $\\max _{\\sigma \\in \\widehat{P}} \\sum_{g=1}^{G}\\left(\\left|\\mathcal{B}_{\\sigma(g)} \\cap \\mathcal{B}_{g}^{*}\\right|+\\left|\\mathcal{B}_{\\sigma(g)}^{C} \\cap \\mathcal{B}_{g}^{* C}\\right|\\right) /(J G)$, which is the proportion of correctly identified zero and nonzero group loadings. Here for any set $\\mathcal{B}, \\mathcal{B}^{C}=$ $\\{1, \\ldots, J\\} \\backslash \\mathcal{B}$ is the complement of set $\\mathcal{B}$.\n\nHere, the EMC measures the perfect recovery of the true bi-factor structure, while the ACC can be viewed as a smooth version of EMC that measures the level of partial recovery. $\\mathrm{EMC}=1$ when $\\mathrm{ACC}=1$ and, EMC $=0$ when $\\mathrm{ACC}<1$. A larger value of ACC indicates a higher level of partial recovery of the true bi-factor structure. More specifically, for a given permutation $\\sigma \\in \\widehat{\\mathcal{P}}$, the quantity $\\left|\\mathcal{B}_{\\sigma(g)} \\cap \\mathcal{B}_{g}^{*}\\right|+\\left|\\mathcal{B}_{\\sigma(g)}^{C} \\cap \\mathcal{B}_{g}^{* C}\\right|$ computes the number of correctly identified nonzero and zero loadings for group factor $g$. For example, consider a case with $J=15$ items and $\\mathcal{B}_{1}^{*}=\\{1,4,7,10,13\\}$ for the first group factor. If $\\mathcal{B}_{\\sigma(1)}=\\mathcal{B}_{1}^{*}$, then for the first group factor, we have $\\left|\\mathcal{B}_{\\sigma(1)} \\cap \\mathcal{B}_{1}^{*}\\right|+\\left|\\mathcal{B}_{\\sigma(1)}^{C} \\cap \\mathcal{B}_{1}^{* C}\\right|=J=15$, i.e., all the nonzero and zero loadings have been correctly identified. If, instead, $\\mathcal{B}_{\\sigma(1)}=\\{1,2,7,10,13\\}$, then $\\left|\\mathcal{B}_{\\sigma(1)} \\cap \\mathcal{B}_{1}^{*}\\right|+\\left|\\mathcal{B}_{\\sigma(1)}^{C} \\cap \\mathcal{B}_{1}^{* C}\\right|=13$, i.e., 13 out of the 15 nonzero and zero loadings have been correctly identified. The quantity $\\sum_{g=1}^{G}\\left(\\left|\\mathcal{B}_{\\sigma(g)} \\cap \\mathcal{B}_{g}^{*}\\right|+\\right.$ $\\left.\\left|\\mathcal{B}_{\\sigma(g)}^{C} \\cap \\mathcal{B}_{g}^{* C}\\right|\\right) /(J G)$ thus computes the proportion of correctly identified zero and nonzero group loadings under the given permutation $\\sigma$. The ACC considers all possible permutations of the group factor labels to account for the label indeterminacy.\n\nTo examine the recovery of the bi-factor structure, we consider $(J, G) \\in\\{(15,3),(30,5)\\}$ and $N \\in$ $\\{500,2000\\}$. These choices, combined with the two settings for the data generation mechanism, lead to eight simulation settings. For each setting, we let $\\mathcal{B}_{g}^{*}=\\{g, g+G, \\ldots, g+G(J / G-1)\\}$ for $g=1, \\ldots, G$, $\\Psi^{*}=\\mathbb{I}_{J \\times J}$, and $\\Phi^{*}=\\Phi^{*}\\left(\\gamma^{*}\\right)$ follow the reparameterization in Section 2.2, where the entries of $\\gamma^{*}$ are i.i.d., following a Uniform $(-0.5,0.5)$ distribution. Under the settings where data are generated from an exact\n\nbi-factor model, we generate the true loading matrix $\\Lambda^{*}$ by\n\n$$\n\\lambda_{j k}^{*}=\\left\\{\\begin{array}{l}\nu_{j k} \\text { if } k=1 \\\\\n0 \\text { if } k>1, j \\notin \\mathcal{B}_{k-1}^{*} \\\\\n\\left(1-2 x_{j k}\\right) u_{j k} \\text { if } k>1, j \\in \\mathcal{B}_{k-1}^{*}\n\\end{array}\\right.\n$$\n\nfor $j=1, \\ldots, J$ and $k=1, \\ldots, G+1$. In (8), $u_{j k} \\mathrm{~s}$ are i.i.d., following a Uniform $(0.2,1)$ distribution, and $x_{j k} \\mathrm{~s}$ are i.i.d., following a Bernoulli( 0.5 ) distribution. Under the settings where data are generated from an approximate bi-factor model, we generate the true loading matrix $\\Lambda^{*}$ by\n\n$$\n\\lambda_{j k}^{*}=\\left\\{\\begin{array}{l}\nu_{j k} \\text { if } k=1 \\\\\n\\left(1-2 x_{j k}\\right) w_{j k} \\text { if } k>1, j \\notin \\mathcal{B}_{k-1}^{*} \\\\\n\\left(1-2 x_{j k}\\right) u_{j k} \\text { if } k>1, j \\in \\mathcal{B}_{k-1}^{*}\n\\end{array}\\right.\n$$\n\nfor $j=1, \\ldots, J$ and $k=1, \\ldots, G+1$. Here, $u_{j k} \\mathrm{~s}$ and $x_{j k} \\mathrm{~s}$ are generated in the same way as those in the exact bi-factor model, and $w_{j k}$ are i.i.d., following a Uniform( $0,0.1)$ distribution. In (9), the nonzero values of $\\lambda_{j k}^{*}$ when $k>1$ and $j \\notin \\mathcal{B}_{k-1}^{*}$ represent the perturbation of $\\Lambda^{*}$ from an exact bi-factor structure.\n\nFor each setting, we first generate $\\Lambda^{*}$ and $\\Phi^{*}$ once and use them to generate 100 datasets. The true parameter values for these simulations are given in Appendix B. The results about the estimation of the loading matrix are shown in Table 1. When data are generated from an exact bi-factor model, the proposed method outperforms the rotation method in terms of the MSE of the estimated loading matrix, as shown in Table 1(a). When data are generated from an approximate bi-factor model, as shown in Table 1(b), the proposed method is slightly better under the small-sample settings when $N=500$ but slightly worse under the large-sample settings when $N=2000$. The disadvantage of the proposed method under the large-sample settings is due to the bias brought by model misspecification. That is, the data generation model is not an exact bi-factor model, while the proposed method restricts its estimates in the space of exact bi-factor models.\n\nThe results about the recovery of the bi-factor structure based on the EMC and ACC metrics are shown in Tables 2 and 3, respectively. For the rotation method, the threshold $\\delta=0.2$ yields the best results among the three threshold choices under all the simulation settings and for both performance metrics. However, even the results of the rotation method under this choice of threshold are not as good as those from the proposed method, especially when we look at the EMC metric. For example, when $J=30, G=5$, and $N=500$, the rotation method with $\\delta=0.2$ can only correctly recover the entire bi-factor structure 15 times\n\namong 100 simulations, while the proposed method can correctly recover it 85 times.\nTable 1: Simulation results of the MSE of $\\widehat{\\Lambda}$ estimated by the proposed ALM method and the exploratory bi-factor rotation method.\n\n![table_0](table_0)\n\n(a) The exact bi-factor model cases.\n\n![table_1](table_1)\n\n(b) The approximate bi-factor model cases.\n\nTable 2: Simulation results of the EMC of the proposed ALM method and the exploratory bi-factor rotation method with three choices of hard thresholding parameter $\\delta$.\n\n![table_2](table_2)\n\n(a) The exact bi-factor model cases.\n\n![table_3](table_3)\n\n(b) The approximate bi-factor model cases.", "tables": {"table_0": "| $(J, G)$ | $N$ | ALM | Rotation |\n| :--: | :--: | :--: | :--: |\n| $(15,3)$ | 500 | $2.10 \\times 10^{-3}$ | $3.62 \\times 10^{-3}$ |\n|  | 2000 | $0.54 \\times 10^{-3}$ | $0.92 \\times 10^{-3}$ |\n| $(30,5)$ | 500 | $1.36 \\times 10^{-3}$ | $4.94 \\times 10^{-3}$ |\n|  | 2000 | $0.30 \\times 10^{-3}$ | $1.15 \\times 10^{-3}$ |", "table_1": "| $(J, G)$ | $N$ | ALM | Rotation |\n| :--: | :--: | :--: | :--: |\n| $(15,3)$ | 500 | $4.74 \\times 10^{-3}$ | $5.92 \\times 10^{-3}$ |\n|  | 2000 | $3.06 \\times 10^{-3}$ | $2.40 \\times 10^{-3}$ |\n| $(30,5)$ | 500 | $3.75 \\times 10^{-3}$ | $3.88 \\times 10^{-3}$ |\n|  | 2000 | $2.63 \\times 10^{-3}$ | $1.25 \\times 10^{-3}$ |", "table_2": "| $(J, G)$ | $N$ | ALM | $\\delta=0.1$ | $\\delta=0.2$ | $\\delta=0.3$ |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n| $(15,3)$ | 500 | 1.00 | 0.18 | 0.90 | 0.28 |\n|  | 2000 | 1.00 | 0.99 | 1.00 | 0.50 |\n| $(30,5)$ | 500 | 0.85 | 0.00 | 0.15 | 0.00 |\n|  | 2000 | 1.00 | 0.55 | 0.68 | 0.00 |", "table_3": "| $(J, G)$ | $N$ | ALM | $\\delta=0.1$ | $\\delta=0.2$ | $\\delta=0.3$ |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n| $(15,3)$ | 500 | 0.99 | 0.00 | 0.62 | 0.33 |\n|  | 2000 | 1.00 | 0.02 | 0.94 | 0.67 |\n| $(30,5)$ | 500 | 0.86 | 0.00 | 0.23 | 0.00 |\n|  | 2000 | 1.00 | 0.00 | 0.82 | 0.00 |"}, "images": {}}, {"section_id": 7, "text": "# 3.2 Study II \n\nIn this study, we examine the selection of the number of factors by $\\mathrm{BIC}_{G}$ in Section 2.3. We compare it with selecting the number of factors under the exploratory factor analysis model without assuming a bi-factor structure. For the proposed method, we set the candidate set $\\mathcal{G}=\\left\\{G^{*}-1, G^{*}, G^{*}+1\\right\\}$, where $G^{*}$ is the true number of group factors. For exploratory factor analysis, we also use the BIC for determining the number of factors, which is defined as\n\n$$\n\\mathrm{BIC}_{K}^{e}=l_{K}^{e}+(J K-K(K-1) / 2) \\log (N)\n$$\n\nwhere $K$ is the number of factors in the exploratory factor analysis model, and $l_{K}^{e}=l\\left(\\widehat{\\Lambda} \\widehat{\\Lambda}^{\\top}+\\Psi(\\widehat{\\psi}) ; S\\right)$ with $\\widehat{\\Lambda}$ and $\\widehat{\\psi}$ from (7). As the number of factors in the exploratory factor analysis model equals the number of\n\nTable 3: Simulation results of the ACC of the proposed ALM method and the exploratory bi-factor rotation method with three choices of hard thresholding parameter $\\delta$.\n\n![table_4](table_4)\n\n(a) The exact bi-factor model cases.\n\n![table_5](table_5)\n\n(b) The approximate bi-factor model cases.\ngroup factors plus one, we choose $K$ from the candidate set $\\mathcal{K}=\\{G+1: G \\in \\mathcal{G}\\}$. Let $\\widehat{K}=\\arg \\min _{K \\in \\mathcal{K}} \\mathrm{BIC}_{K}^{c}$. Then the estimate of $G$ by exploratory factor analysis is $\\widehat{G}=\\widehat{K}-1$. The selection accuracy is evaluated by the selection correctness (SC) criterion, defined as $\\mathbf{1}\\left(\\widehat{G}=G^{*}\\right)$, where $\\widehat{G}$ is obtained using the proposed method in Section 2.3 or under the exploratory factor analysis model described above.\n\nWe conduct simulations under four settings, with $\\left(J, G^{*}\\right) \\in\\{(15,3),(30,5)\\}$ and $N \\in\\{500,2000\\}$ and the data generation models being the same exact bi-factor models in Study I. For each setting, 100 independent simulations are performed. The results are given in Table 4, where the column indicated by $\\widehat{G}$ reports the average value of $\\widehat{G}$. We see that both methods can select the number of factors reasonably well, with their accuracy being $100 \\%$ when $G^{*}=3$ for both sample sizes. When $G^{*}=5$ and the sample size $N=2000$, the proposed method achieves an accuracy of $100 \\%$, and the exploratory factor analysis method achieves an accuracy of $99 \\%$. This is not surprising, given that the BIC has asymptotic consistency in selecting the number of factors under both models. It is worth noting that, when $G^{*}=5$ and for the smaller sample size $N=500$, which is the most challenging setting, the proposed method achieves an accuracy of $98 \\%$, while that of the exploratory factor analysis method is zero. More precisely, the exploratory factor analysis method selects $G=4$ in all the replications. It suggests that the proposed method has an advantage in smaller sample settings. This result is expected, as the exploratory factor analysis method doesn't utilize the information about the bi-factor structure. Consequently, it overestimates the number of parameters, which leads to a larger penalty term and, subsequently, a tendency to under-select $G$.\n\nTable 4: Simulation results of the selection of the number of factors by BIC.\n\n![table_6](table_6)", "tables": {"table_4": "| $(J, G)$ | $N$ | ALM | $\\delta=0.1$ | $\\delta=0.2$ | $\\delta=0.3$ |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n| $(15,3)$ | 500 | 1.000 | 0.966 | 0.998 | 0.976 |\n|  | 2000 | 1.000 | 0.999 | 1.000 | 0.987 |\n| $(30,5)$ | 500 | 0.998 | 0.892 | 0.987 | 0.973 |\n|  | 2000 | 1.000 | 0.996 | 0.998 | 0.980 |", "table_5": "| $(J, G)$ | $N$ | ALM | $\\delta=0.1$ | $\\delta=0.2$ | $\\delta=0.3$ |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n| $(15,3)$ | 500 | 0.999 | 0.864 | 0.989 | 0.978 |\n|  | 2000 | 1.000 | 0.928 | 0.999 | 0.991 |\n| $(30,5)$ | 500 | 0.998 | 0.848 | 0.989 | 0.978 |\n|  | 2000 | 1.000 | 0.927 | 0.999 | 0.980 |", "table_6": "|  | ALM |  |  | Exploratory |  |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n| $\\left(J, G^{*}\\right)$ | $N$ | $\\tilde{G}$ | SC | $\\tilde{G}$ | SC |\n| $(15,3)$ | 500 | 3 | 1 | 3 | 1 |\n|  | 2000 | 3 | 1 | 3 | 1 |\n| $(30,5)$ | 500 | 5.02 | 0.98 | 4 | 0 |\n|  | 2000 | 5 | 1 | 4.99 | 0.99 |"}, "images": {}}, {"section_id": 8, "text": "# 4 Real Data Analysis \n\nIn this section, we apply the exact exploratory bi-factor analysis to a personality assessment dataset based on the International Personality Item Pool (IPIP) NEO 120 personality inventory (Johnson, 2014) ${ }^{1}$. We investigate the structure of the Extraversion scale based on a sample of 1,107 UK male participants aged between 25 and 30 years. This scale consists of 24 items, which are designed to measure six facets of Extraversion, including Friendliness (E1), Gregariousness (E2), Assertiveness (E3), Activity Level(E4), Excitement-Seeking (E5) and Cheerfulness (E6); see Section E for the details. All the items are on a 1-5 Likert scale, and the reversely worded items have been reversely scored so that a larger score always means a higher level of extraversion. There is no missing data. Detailed descriptions of the items can be found in the Appendix E.\n\nUsing a candidate set $\\mathcal{G}=\\{2, \\ldots, 12\\}$, the BIC procedure given in Section 2.3 selects seven group factors. The estimated loading matrix is given in Table 5, and the estimated factor correlation matrix is given below. The estimated model fits the data well, as implied by the commonly used fit statistics, including RMSEA $=0.044$, SRMR $=0.031, \\mathrm{CFI}=0.965$, and $\\mathrm{TLI}=0.953$. We point out that the estimated bi-factor structure does not meet Condition 3, one of the sufficient conditions for Theorem 1. However, as shown in Appendix G.2, with some additional mild assumptions, this structure and its parameters are still identifiable.\n\nWe now examine the estimated model. We first notice that the loadings on the general factor are all positive. Consequently, this factor can be easily interpreted as the general extraversion factor. The seven group factors are closely related to the six aspects of extraversion. Specifically, we interpret the group factors G1, G3, G4 and G5 as the Friendliness, Cheerfulnes, Assertiveness, and Activity Level factors, respectively, as the items loading on them highly overlap with the items that are used to define the corresponding aspects. In particular, the items loading on G3 and G5 are exactly those that define the Cheerfulness and Activity Level aspects, respectively. The items loading on G1 include all the items that define the Friendliness aspect and an additional item \" 7 . Prefer to be alone\", a negatively worded item that is used to define the Gregariousness aspect. This additional item aligns well with the Friendliness dimension, given the social nature behind it. In addition, the items loading on G4 consist of all the items that define the Assertiveness\n\n[^0]\n[^0]:    ${ }^{1}$ The data are downloaded from https://osf.io/tbmh5/\n\naspect and an additional item \"6. Talk to a lot of different people at parties\", which is used to define the Gregariousness aspect. This additional item aligns with the Assertiveness dimension in that talking to many different people at parties typically requires sufficient confidence, a key element of Assertiveness.\n\nTable 5: Estimated bi-factor loading matrix $\\hat{\\Lambda}$ with seven group factors.\n\n![table_7](table_7)\n\n$$\n\\widehat{\\Phi}=\\left(\\begin{array}{cccccccccc}\n1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & -0.24 & 0.54 & 0.37 & 0.16 & 0.51 & 0.08 \\\\\n0 & -0.24 & 1 & -0.04 & 0.05 & -0.09 & -0.01 & 0.51 \\\\\n0 & 0.54 & -0.04 & 1 & 0.30 & 0.28 & 0.20 & 0.25 \\\\\n0 & 0.37 & 0.05 & 0.30 & 1 & 0.38 & 0.15 & 0.29 \\\\\n0 & 0.16 & -0.09 & 0.28 & 0.38 & 1 & 0.11 & 0.22 \\\\\n0 & 0.51 & -0.01 & 0.20 & 0.15 & 0.11 & 1 & 0.10 \\\\\n0 & 0.08 & 0.51 & 0.25 & 0.29 & 0.22 & 0.10 & 1\n\\end{array}\\right)\n$$\n\nThe group factors G2 and G7 may be viewed as two subdimensions of the Excitement-Seeking aspect, as each of them is loaded with two items that define the Excitement-Seeking aspect. Specifically, G2 is loaded with the items \"19. Enjoy being reckless\" and \"20. Act wild and crazy\", while G7 is loaded with the items \"17. Love excitement\" and \"18. Seek adventure\". We believe that G2 emphasises the thrill of the moment of excitement and the disregard for potential consequences, while G7 emphasizes the pursuit of meaningful and fulfilling experiences. Therefore, we interpret G2 as the Reckless Excitement-Seeking factor, while interpret G7 as the Meaningful Excitement-Seeking factor. Finally, G6 is loaded with two items, \"5. Love large parties\" and \" 8 . Avoid crowds\", where item 8 is reversely worded. Both items are used to define the Gregariousness aspect. Compared with items 6 and 7, which are also used to define the Gregariousness aspect but now load on two different group factors, these two items may better reflect the essence of Gregariousness - the tendency to enjoy the company of others. We thus interpret G6 as the Gregariousness factor. We also notice that most correlations between the group factors are positive, except for some of the correlations with G2. Specifically, we see that G2 (Reckless Excitement-Seeking) has a moderate negative correlation with G1 (Friendliness) while a reasonably high correlation with G7 (Meaningful Excitement-Seeking).\n\nWe have also applied the bi-factor rotation method of Jennrich and Bentler (2012) to the same data, which gives a solution with seven group factors. The resulting bi-factor structure is similar to that given by the proposed method, except that the rotation solution does not seem to contain a clear Friendliness factor; see Appendix F for further details.", "tables": {"table_7": "| Items | Sign | General | G1 | G2 | G3 | G4 | G5 | G6 | G7 |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n| 1 | +E1 | 0.85 | 0.26 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 2 | +E1 | 0.73 | 0.48 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 3 | -E1 | 0.74 | 0.57 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 4 | -E1 | 0.68 | 0.58 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 5 | +E2 | 0.94 | 0 | 0 | 0 | 0 | 0 | 0.26 | 0 |\n| 6 | +E2 | 1.01 | 0 | 0 | 0 | 0.17 | 0 | 0 | 0 |\n| 7 | -E2 | 0.53 | 0.52 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 8 | -E2 | 0.67 | 0 | 0 | 0 | 0 | 0 | 1.06 | 0 |\n| 9 | +E3 | 0.37 | 0 | 0 | 0 | 0.86 | 0 | 0 | 0 |\n| 10 | +E3 | 0.38 | 0 | 0 | 0 | 0.81 | 0 | 0 | 0 |\n| 11 | +E3 | 0.28 | 0 | 0 | 0 | 0.74 | 0 | 0 | 0 |\n| 12 | -E3 | 0.39 | 0 | 0 | 0 | 0.75 | 0 | 0 | 0 |\n| 13 | +E4 | 0.20 | 0 | 0 | 0 | 0 | 0.81 | 0 | 0 |\n| 14 | +E4 | 0.40 | 0 | 0 | 0 | 0 | 0.82 | 0 | 0 |\n| 15 | +E4 | 0.40 | 0 | 0 | 0 | 0 | 0.60 | 0 | 0 |\n| 16 | -E4 | 0.04 | 0 | 0 | 0 | 0 | 0.47 | 0 | 0 |\n| 17 | +E5 | 0.46 | 0 | 0 | 0 | 0 | 0 | 0 | 0.46 |\n| 18 | +E5 | 0.47 | 0 | 0 | 0 | 0 | 0 | 0 | 0.71 |\n| 19 | +E5 | 0.35 | 0 | 0.86 | 0 | 0 | 0 | 0 | 0 |\n| 20 | +E5 | 0.56 | 0 | 0.71 | 0 | 0 | 0 | 0 | 0 |\n| 21 | +E6 | 0.59 | 0 | 0 | 0.42 | 0 | 0 | 0 | 0 |\n| 22 | +E6 | 0.64 | 0 | 0 | 0.48 | 0 | 0 | 0 | 0 |\n| 23 | +E6 | 0.46 | 0 | 0 | 0.76 | 0 | 0 | 0 | 0 |\n| 24 | +E6 | 0.41 | 0 | 0 | 0.74 | 0 | 0 | 0 | 0 |"}, "images": {}}, {"section_id": 9, "text": "# 5 Discussions \n\nThis paper proposes a constraint-based optimisation method for exploratory bi-factor analysis. This method turns the problem of exploratory bi-factor analysis into an equality-constrained optimisation problem in a continuous domain and solves this optimisation problem by an augmented Lagrangian method. Compared with the rotation method of Jennrich and Bentler (2011, 2012), the proposed method can learn an exact loading structure without a post-hoc treatment step. In the simulation studies, the ALM method achieves higher estimation accuracy when data are generated from an exact bi-factor model. In addition, it has a higher chance of recovering the true bi-factor structure than the rotation method, whether data are generated from an exact or approximate bi-factor model. Moreover, the ALM method correctly estimates the number of the group factors in most of the simulation replications. In the real data analysis concerning an Extraversion personality scale, the ALM method yields a bi-factor structure with seven group factors. The identified group factors are psychologically interpretable.\n\nAn innovation of current research is turning a model selection problem, which is combinatory by nature, into a continuous optimization problem. This avoids a computationally intensive search procedure for fitting many possible models and comparing their fits, noting that the number of possible models grows exponentially with $J$. We admit that this continuous optimization formulation also has a limitation. The space for the bi-factor loading matrix characterised by the nonlinear equality constraints in (1) is highly nonconvex, and thus, the ALM may sometimes converge to a local minimum. To alleviate this issue, we suggest running the ALM with multiple random starting points and then choosing the solution with the smallest objective function value. Based on our simulation results, using 50 starting points seems sufficient to converge to somewhere close to the true parameters up to a label swapping of the group factors and a sign indeterminacy of loadings in almost all replications under the settings considered in the simulation study.\n\nThis research leads to several new directions for exploratory analysis of factor models with structure constraints on the loading matrix. First, as pointed out earlier, the proposed approach can be easily adapted to non-linear bi-factor models for dichotomous, ordinal, and nominal data. Under the confirmatory setting, these models are typically estimated by maximising the marginal log-likelihood function or other objective functions (e.g., a composite likelihood). Under the exploratory setting, one only needs to maximise the same objective function subject to the same bi-factor constraints in (1), for which the ALM adapts naturally. It is worth noting that, however, the marginal likelihood of the non-linear bi-factor models typically involves multidimensional integrals with respect to the factors, and they do not have an analytic form. Consequently, solving the Lagrangian augmented objective functions using the standard expectation-maximisation (EM) algorithm (Dempster et al., 1977; Bock and Aitkin, 1981) can be computationally intensive. One possible\n\nsolution is to use a stochastic approximation method (Zhang and Chen, 2022; Oka et al., 2024). These methods avoid the high computational cost of numerical integrals in the expectation-maximisation algorithm by constructing stochastic gradients of the marginal log-likelihood through Markov chain Monte Carlo sampling.\n\nSecond, the proposed constraints can also be combined with exploratory factor analysis techniques to learn a bi-factor structure in two steps. Suppose an initial loading matrix estimate $\\widehat{\\Lambda}$ has been obtained under the constraint that the factors are orthogonal (i.e., $\\Phi$ is an identity matrix). It may be obtained by a standard exploratory factor analysis method. In that case, we can find a bi-factor structure that best approximates $\\widehat{\\Lambda}$ (up to a rotation) by minimising $\\left\\|\\Lambda \\Phi(\\gamma) \\Lambda^{\\top}-\\widehat{\\Lambda}(\\widehat{\\Lambda})^{\\top}\\right\\|_{F}$ with respect to $\\Lambda$ and $\\gamma$ under the constraints in (1). This optimisation can again be solved by an ALM.\n\nThird, as we demonstrate in Appendix D, the set of constraints in (1) can be extended to characterise the loading structure of a hierarchical factor model (Schmid and Leiman, 1957; Yung et al., 1999), which can be used to learn a hierarchical factor structure. This exploratory hierarchical factor analysis may allow researchers to learn more refined and interpretable latent structures from psychometric data. However, one should note that exploratory hierarchical factor analysis is more complex than exploratory bi-factor analysis, as the factor hierarchy in the former can be much more complex than the two-layer hierarchy in the latter. The learning algorithm in Appendix D requires the factor hierarchy to be known (see, e.g., Panel (b) of Figure D.1). The problem becomes more challenging when the factor hierarchy is unknown, in which case we need to learn both the factor hierarchy and the loading pattern of the variables. We leave this problem for future investigation.\n\nFinally, we point out that the proposed method always returns an estimated bi-factor model, whether it fits the data or not. The simulation study in Section 3 shows that the proposed method has robust performance when data are generated by an approximate bi-factor model. However, under more general settings, it remains to test the goodness-of-fit of the estimated model to decide whether a bi-factor model suits the data. If the bi-factor model does not fit the data well, we may consider a more flexible factor model. For example, we may apply the bi-factor rotation method or a rotation method for traditional exploratory factor analysis to allow for more cross-loadings. Alternatively, we may learn approximate bi-factor models in an exploratory manner by relaxing the equality constraints in (2) with inequality constraints in the form of $\\left|\\lambda_{j k} \\lambda_{j k^{\\prime}}\\right| \\leqslant \\epsilon$, for all $j=1, \\ldots, J$, and $k, k^{\\prime}=2, \\ldots, G+1, k \\neq k^{\\prime}$, where $\\epsilon$ is a tuning parameter that controls the level of approximation to a bi-factor model. A larger value of $\\epsilon$ leads to a more flexible model space and, thus, a more satisfactory fit, while a smaller value of $\\epsilon$ leads to a better approximation to a bi-factor model that may have better interpretability. In this sense, $\\epsilon$ provides a trade-off between model goodness-of-fit and bi-factor interoperability. This inequality-constrained optimisation may be solved using an interior-point method, which can incorporate the inequality constraints through suitable barrier functions\n\n(e.g., log-barriers). We leave this idea for future investigation.", "tables": {}, "images": {}}, {"section_id": 10, "text": "# Appendix\n## A Reparameterization of $\\Phi$\n\nTo deal with the constraints in $\\Phi$, we consider the following reparameterisation that has been considered in Alfonzetti et al. (2024), which is also similar to the implementation in the state-of-the-art statistical software Stan (Stan Development Team, 2022):\n\n$$\n\\Phi=\\left(\\left[\\begin{array}{cc}\n1 & \\mathbf{0}^{\\top} \\\\\n\\mathbf{0} & U^{T}\n\\end{array}\\right]\\right)\\left(\\left[\\begin{array}{cc}\n1 & \\mathbf{0}^{\\top} \\\\\n\\mathbf{0} & U\n\\end{array}\\right]\\right)\n$$\n\nwhere $U$ is defined recursively by\n\n$$\nU_{i j}=\\left\\{\\begin{array}{l}\n0 \\text { if } i>j \\\\\n1 \\text { if } i=j=1 \\\\\nz_{i j} \\text { if } 1=i<j \\\\\n\\frac{z_{i j}}{z_{(i-1) j}} U_{(i-1) j}\\left(1-z_{(i-1) j}^{2}\\right)^{1 / 2} \\text { if } 1<i<j \\\\\n\\frac{U_{(i-1) j}}{z_{(i-1) j}}\\left(1-z_{(i-1) j}^{2}\\right)^{1 / 2} \\text { if } 1<i=j\n\\end{array}\\right.\n$$\n\nHere $z_{i j}=\\tanh \\left(\\gamma_{i j}\\right)$ is the Fisher's transformation of $G(G-1) / 2$ unconstrained parameters $\\gamma_{i j}$.", "tables": {}, "images": {}}, {"section_id": 11, "text": "## B Population Parameter Values in Simulations\n\nIn this section, we supplement the population values of factor loadings and factor correlations in Section 3. Under the setting $(J, G)=(15,3)$, the loading matrix $\\Lambda^{*}$ and $\\Phi^{*}$ in (8) and (9) are given in (B.1), (B.2),\n\n(B.3) and (B.4) respectively.\n\n$$\n\\begin{aligned}\n& \\Lambda^{*}=\\left(\\begin{array}{cccc}\n0.36 & -0.60 & 0 & 0 \\\\\n0.89 & 0 & 0.64 & 0 \\\\\n0.94 & 0 & 0 & 0.92 \\\\\n0.90 & 0.33 & 0 & 0 \\\\\n0.45 & 0 & -0.90 & 0 \\\\\n0.24 & 0 & 0 & 0.86 \\\\\n0.45 & -0.60 & 0 & 0 \\\\\n0.74 & 0 & -0.75 & 0 \\\\\n0.64 & 0 & 0 & -0.60 \\\\\n0.50 & -0.83 & 0 & 0 \\\\\n0.54 & 0 & -0.43 & 0 \\\\\n0.43 & 0 & 0 & 0.86 \\\\\n0.46 & -0.33 & 0 & 0 \\\\\n0.67 & 0 & 0.34 & 0 \\\\\n0.90 & 0 & 0 & -0.83\n\\end{array}\\right) \\\\\n& \\Phi^{*}=\\left(\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0.29 & 0.11 \\\\\n0 & 0.29 & 1 & 0.01 \\\\\n0 & 0.11 & 0.01 & 1\n\\end{array}\\right)\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n& \\Lambda^{*}=\\left(\\begin{array}{cccc}\n0.36 & -0.6 & -0.05 & 0.06 \\\\\n0.89 & 0.04 & 0.64 & 0.09 \\\\\n0.94 & -0.09 & -0.08 & 0.92 \\\\\n0.90 & 0.33 & 0.02 & -0.09 \\\\\n0.45 & -0.07 & -0.90 & -0.06 \\\\\n0.24 & -0.02 & 0.09 & 0.86 \\\\\n0.45 & -0.60 & -0.09 & 0.02 \\\\\n0.74 & 0.05 & -0.75 & 0.09 \\\\\n0.64 & 0.05 & -0.02 & -0.60 \\\\\n0.50 & -0.83 & 0.05 & 0.06 \\\\\n0.54 & 0.02 & -0.43 & 0.07 \\\\\n0.43 & 0.03 & -0.09 & 0.86 \\\\\n0.46 & -0.33 & 0.00 & 0.04 \\\\\n0.67 & 0.05 & 0.34 & 0.04 \\\\\n0.90 & 0.00 & -0.06 & -0.83\n\\end{array}\\right) \\\\\n& \\Phi^{*}=\\left(\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & -0.22 & -0.07 \\\\\n0 & -0.22 & 1 & 0.46 \\\\\n0 & -0.07 & 0.46 & 1\n\\end{array}\\right)\n\\end{aligned}\n$$\n\nUnder the setting $(J, G)=(30,5)$, the loading matrix $\\Lambda$ in (8) and (9) are given in (B.5) and (B.6). The\n\ncorrelation matrix $\\Phi$ in (8) and (9) are given in (B.7) and (B.8).\n\n$$\n\\Lambda^{*}=\\left(\\begin{array}{cccccccc}\n0.40 & -0.90 & 0 & 0 & 0 & 0 \\\\\n0.53 & 0 & -0.62 & 0 & 0 & 0 \\\\\n0.21 & 0 & 0 & -0.78 & 0 & 0 \\\\\n0.69 & 0 & 0 & 0 & -0.81 & 0 \\\\\n0.57 & 0 & 0 & 0 & 0 & 0.90 \\\\\n0.91 & -0.93 & 0 & 0 & 0 & 0 \\\\\n0.31 & 0 & -0.47 & 0 & 0 & 0 \\\\\n0.41 & 0 & 0 & -0.79 & 0 & 0 \\\\\n0.31 & 0 & 0 & 0 & -0.35 & 0 \\\\\n0.90 & 0 & 0 & 0 & 0 & -0.59 \\\\\n0.59 & 0.80 & 0 & 0 & 0 & 0 \\\\\n0.83 & 0 & -0.96 & 0 & 0 & 0 \\\\\n0.84 & 0 & 0 & -0.89 & 0 & 0 \\\\\n0.29 & 0 & 0 & 0 & -0.23 & 0 \\\\\n0.90 & 0 & 0 & 0 & 0 & 0.77 \\\\\n0.68 & -0.56 & 0 & 0 & 0 & 0 \\\\\n0.95 & 0 & 0.89 & 0 & 0 & 0 \\\\\n0.87 & 0 & 0 & 0.61 & 0 & 0 \\\\\n0.45 & 0 & 0 & 0 & 0.41 & 0 \\\\\n0.52 & 0 & 0 & 0 & 0 & 0.51 \\\\\n0.43 & -0.42 & 0 & 0 & 0 & 0 \\\\\n0.43 & 0 & -0.30 & 0 & 0 & 0 \\\\\n0.34 & 0 & 0 & -0.31 & 0 & 0 \\\\\n0.73 & 0 & 0 & 0 & 0.53 & 0 \\\\\n0.69 & 0 & 0 & 0 & 0 & -0.83 \\\\\n0.30 & 0.34 & 0 & 0 & 0 & 0 \\\\\n0.25 & 0 & -0.60 & 0 & 0 & 0 \\\\\n0.58 & 0 & 0 & 0.37 & 0 & 0 \\\\\n0.28 & 0 & 0 & 0 & -0.28 & 0 \\\\\n0.85 & 0 & 0 & 0 & 0 & 0.82\n\\end{array}\\right)\n$$\n\n$\\Delta^{*}=$| 0.40 | -0.90 | -0.07 | 0.01 | 0.01 | 0.02 |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n| 0.53 | 0.02 | -0.62 | -0.06 | 0.09 | 0.00 |\n| 0.21 | 0.01 | -0.01 | -0.78 | -0.02 | -0.03 |\n| 0.69 | -0.05 | 0.01 | 0.08 | -0.81 | -0.07 |\n| 0.57 | 0.05 | 0.06 | -0.09 | 0.03 | 0.90 |\n| 0.91 | -0.93 | -0.09 | -0.01 | 0.05 | 0.04 |\n| 0.31 | 0.02 | -0.47 | 0.04 | 0.05 | -0.05 |\n| 0.41 | 0.04 | -0.07 | -0.79 | 0.02 | 0.05 |\n| 0.31 | 0.05 | 0.01 | -0.07 | -0.35 | -0.04 |\n| 0.90 | 0.05 | -0.07 | -0.10 | 0.03 | -0.59 |\n| 0.59 | 0.80 | -0.05 | -0.10 | -0.05 | 0.02 |\n| 0.83 | 0.10 | -0.96 | -0.07 | 0.06 | -0.03 |\n| 0.84 | 0.03 | 0.08 | -0.89 | -0.01 | -0.04 |\n| 0.29 | 0.09 | -0.05 | -0.01 | -0.23 | 0.04 |\n| 0.90 | -0.10 | -0.04 | 0.07 | -0.08 | 0.77 |\n| 0.68 | -0.56 | 0.02 | -0.01 | -0.07 | -0.08 |\n| 0.95 | 0.05 | 0.89 | -0.03 | 0.04 | -0.08 |\n| 0.87 | 0.09 | 0.01 | 0.61 | -0.07 | 0.05 |\n| 0.45 | 0.04 | -0.04 | 0.00 | 0.41 | 0.06 |\n| 0.52 | -0.04 | -0.05 | -0.10 | -0.03 | 0.51 |\n| 0.43 | -0.42 | -0.07 | -0.04 | -0.07 | -0.08 |\n| 0.43 | 0.02 | -0.30 | 0.05 | -0.09 | 0.06 |\n| 0.34 | 0.05 | -0.02 | -0.31 | 0.05 | -0.04 |\n| 0.73 | -0.07 | 0.10 | 0.09 | 0.53 | 0.04 |\n| 0.69 | -0.09 | -0.03 | -0.08 | -0.05 | -0.83 |\n| 0.30 | 0.34 | 0.09 | -0.04 | 0.01 | 0.01 |\n| 0.25 | 0.02 | -0.60 | 0.09 | 0.04 | 0.06 |\n| 0.58 | -0.08 | -0.03 | 0.37 | -0.02 | 0.08 |\n| 0.28 | -0.08 | 0.04 | -0.03 | -0.28 | -0.01 |\n| 0.85 | -0.06 | 0.07 | 0.08 | -0.09 | 0.82 |\n\n$$\n\\begin{aligned}\n& \\Phi^{*}=\\left(\\begin{array}{cccccc}\n1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & -0.37 & -0.26 & -0.41 & -0.07 \\\\\n0 & -0.37 & 1 & -0.08 & -0.14 & -0.26 \\\\\n0 & -0.26 & -0.08 & 1 & 0.42 & 0.06 \\\\\n0 & -0.41 & -0.14 & 0.42 & 1 & 0.20 \\\\\n0 & -0.07 & -0.26 & 0.06 & 0.20 & 1\n\\end{array}\\right) \\\\\n& \\Phi^{*}=\\left(\\begin{array}{cccccccc}\n1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & -0.15 & 0.15 & 0.10 & -0.19 \\\\\n0 & -0.15 & 1 & 0.22 & -0.01 & -0.03 \\\\\n0 & 0.15 & 0.22 & 1 & -0.03 & -0.15 \\\\\n0 & 0.10 & -0.01 & -0.03 & 1 & 0.28 \\\\\n0 & -0.19 & -0.03 & -0.15 & 0.28 & 1\n\\end{array}\\right)\n\\end{aligned}\n$$", "tables": {}, "images": {}}, {"section_id": 12, "text": "# C Sensitivity Analysis \n\nIn this section, we carry out a sensitivity analysis on the parameters $c_{\\theta}$ and $c_{\\sigma}$ of the proposed ALM method. We consider the same exact bi-factor model settings as in Study I of Section 3.1. For each settings, we choose $c_{\\theta} \\in\\{0.25,0.5,0.75\\}$ and $c_{\\sigma} \\in\\{5,10,15\\}$, resulting in 9 possible combinations of $\\left(c_{\\theta}, c_{\\sigma}\\right)$. The estimation of loading matrix, the computation time of ALM, and the results of the recovery of the bi-factor structure are shown in Table C. 1 to Table C.4. From the sensitivity analysis, we can see that the ALM's results are relatively stable with respect to the choice of parameters $c_{\\theta}$ and $c_{\\sigma}$.", "tables": {}, "images": {}}, {"section_id": 13, "text": "## D Extension to Hierarchical Factor Analysis\n## D. 1 Constrained Optimisation for Exploratory Hierarchical Factor Analysis\n\nTo further demonstrate the advantages of the constraint-based approach, we discuss how it can be extended for exploratory hierarchical factor analysis. Following the terminology adopted in Yung et al. (1999), we\n\nTable C.1: Sensitivity Analysis of MSE of $\\widehat{\\Lambda}$.\n\n![table_8](table_8)\n\n(a) $J=15, G=3, n=500$\n\n![table_9](table_9)\n\n(b) $J=15, G=3, n=2000$\n\n![table_10](table_10)\n\n(c) $J=30, G=5, n=500$\n\n![table_11](table_11)\n\n(d) $J=30, G=5, n=2000$\n\nTable C.2: Sensitivity Analysis of EMC.\n\n![table_12](table_12)\n\n\n![table_13](table_13)\n\n(c) $J=30, G=5, n=500$\n\n![table_14](table_14)\n\n(b) $J=15, G=3, n=2000$\n\n![table_15](table_15)\n\n(d) $J=30, G=5, n=2000$\n\nTable C.3: Sensitivity Analysis of ACC.\n\n![table_16](table_16)\n\n(a) $J=15, G=3, n=500$\n\n![table_17](table_17)\n\n(c) $J=30, G=5, n=500$\n\n![table_18](table_18)\n\n(b) $J=15, G=3, n=2000$\n\n![table_19](table_19)\n\n(d) $J=30, G=5, n=2000$\n\nTable C.4: Sensitivity Analysis of Computation time(s).\n\n![table_20](table_20)\n\n(a) $J=15, G=3, n=500$\n\n![table_21](table_21)\n\n(c) $J=30, G=5, n=500$\n\n![table_22](table_22)\n\n(b) $J=15, G=3, n=2000$\n\n![table_23](table_23)\n\n(d) $J=30, G=5, n=2000$\n\n![img-0.jpeg](img-0.jpeg)\n(a) The path diagram of a three-layer hierarchical factor model.\n![img-1.jpeg](img-1.jpeg)\n(b) The corresponding factor hierarchy.\n\nFigure D.1: The illustrative example of a three-layer hierarchical factor model.\nconsider general hierarchical factor models. Such a model has several layers of factors. In each layer, each observed variable loads on exactly one of the factors in that layer. The numbering of the layers is determined by the number of factors in the layer, starting from the layer with the largest number of factors. Each factor in a lower layer is nested within a factor in a higher layer, in the sense that the variables loading on the lower-layer factor must also all load on a higher-layer factor. All the factors are assumed to be uncorrelated (i.e., $\\Phi$ is an identity matrix), though this assumption may be relaxed to allow some correlations between factors within the same layer as in the extended bi-factor model.\n\nPanel (a) of Figure D. 1 provides the path diagram of a hierarchical factor model that has three layers, with factor $F_{1}$ in layer 3 , factors $F_{2}$ and $F_{3}$ in layer 2 , and factors $F_{4}-F_{7}$ in layer 1 . The corresponding factor hierarchy is summarised in Panel (b) of Figure D. 1 that takes the form of a tree, where $F_{2}$ and $F_{3}$ are nested within $F_{1}, F_{4}$ and $F_{5}$ are nested within $F_{2}$, and $F_{6}$ and $F_{7}$ are nested within $F_{3}$. In what follows, we show how the loading structure of this three-layer hierarchical model can be learned by a constrained optimisation method, assuming that the factor hierarchy in Panel (b) of Figure D. 1 is known while the variables loading on each factor are unknown. The goal is to learn how the observed variables load on the seven factors.\n\nFollowing the same notation for bi-factor analysis, the population covariance matrix of observed variables under the hierarchical factor model can be written as\n\n$$\n\\Sigma=\\Lambda \\Lambda^{\\top}+\\Psi\n$$\n\nwhere $\\Lambda$ is a $J \\times 7$ matrix, and $\\Psi$ is a $J \\times J$ diagonal matrix. Note that we no longer need the correlation\n\nmatrix $\\Phi$ in the expression as it is now an identity matrix. The constraints implied by the hierarchical factor structure become:\n\n$$\n\\begin{array}{ll}\n\\lambda_{j 2} \\lambda_{j 3}=0, & \\lambda_{j 2} \\lambda_{j 6}=0, \\quad \\lambda_{j 2} \\lambda_{j 7}=0 \\\\\n\\lambda_{j 3} \\lambda_{j 4}=0, & \\lambda_{j 3} \\lambda_{j 5}=0 \\\\\n\\lambda_{j 4} \\lambda_{j 5}=0, & \\lambda_{j 6} \\lambda_{j 7}=0, \\quad j=1, \\ldots, J\n\\end{array}\n$$\n\nConsequently, the corresponding hierarchical factor model can be learned by minimising the loss function $l\\left(\\Lambda \\Lambda^{\\top}+\\Psi(\\boldsymbol{\\psi}) ; S\\right)$, subject to the constraints in (D.1).\n\nAlthough the above discussion focuses on the specific hierarchical factor structure in Figure D.1, when given a different factor hierarchy, it is easy to derive similar constraints as in (D.1) by induction. Based on the constraints, the corresponding hierarchical factor model can be learned by an ALM.\n\nFinally, we note that the factor hierarchy is typically unknown in practice. In that case, we need an algorithm that simultaneously learns the factor hierarchy and the variable loadings on the hierarchical factors. As there are exponentially many choices for the structure of factor hierarchy, this problem is more challenging than the setting when the factor hierarchy is known. It is also more challenging than exploratory bi-factor analysis with unknown group factors, as the bi-factor model has a simple two-layer factor hierarchy that is completely determined by the number of factors.", "tables": {"table_8": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | $2.10 \\times 10^{-3}$ | $2.10 \\times 10^{-3}$ | $2.10 \\times 10^{-3}$ |\n| 10 | $2.10 \\times 10^{-3}$ | $2.10 \\times 10^{-3}$ | $2.10 \\times 10^{-3}$ |\n| 15 | $2.10 \\times 10^{-3}$ | $2.10 \\times 10^{-3}$ | $2.10 \\times 10^{-3}$ |", "table_9": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | $0.54 \\times 10^{-3}$ | $0.54 \\times 10^{-3}$ | $0.54 \\times 10^{-3}$ |\n| 10 | $0.54 \\times 10^{-3}$ | $0.54 \\times 10^{-3}$ | $0.54 \\times 10^{-3}$ |\n| 15 | $0.54 \\times 10^{-3}$ | $0.54 \\times 10^{-3}$ | $0.54 \\times 10^{-3}$ |", "table_10": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | $1.36 \\times 10^{-3}$ | $1.38 \\times 10^{-3}$ | $1.39 \\times 10^{-3}$ |\n| 10 | $1.36 \\times 10^{-3}$ | $1.42 \\times 10^{-3}$ | $1.33 \\times 10^{-3}$ |\n| 15 | $1.42 \\times 10^{-3}$ | $1.36 \\times 10^{-3}$ | $1.44 \\times 10^{-3}$ |", "table_11": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | $0.30 \\times 10^{-3}$ | $0.30 \\times 10^{-3}$ | $0.30 \\times 10^{-3}$ |\n| 10 | $0.30 \\times 10^{-3}$ | $0.30 \\times 10^{-3}$ | $0.30 \\times 10^{-3}$ |\n| 15 | $0.30 \\times 10^{-3}$ | $0.30 \\times 10^{-3}$ | $0.30 \\times 10^{-3}$ |", "table_12": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 1.00 | 1.00 | 1.00 |\n| 10 | 1.00 | 1.00 | 1.00 |\n| 15 | 1.00 | 1.00 | 1.00 |\n| (a) $J=15, G=3, n=500$ |  |  |  |", "table_13": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 0.86 | 0.86 | 0.85 |\n| 10 | 0.85 | 0.84 | 0.85 |\n| 15 | 0.83 | 0.86 | 0.83 |", "table_14": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 1.00 | 1.00 | 1.00 |\n| 10 | 1.00 | 1.00 | 1.00 |\n| 15 | 1.00 | 1.00 | 1.00 |", "table_15": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 1.00 | 1.00 | 1.00 |\n| 10 | 1.00 | 1.00 | 1.00 |\n| 15 | 1.00 | 1.00 | 1.00 |", "table_16": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 1.000 | 1.000 | 1.000 |\n| 10 | 1.000 | 1.000 | 1.000 |\n| 15 | 1.000 | 1.000 | 1.000 |", "table_17": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 0.998 | 0.998 | 0.998 |\n| 10 | 0.998 | 0.997 | 0.998 |\n| 15 | 0.997 | 0.998 | 0.997 |", "table_18": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 1.000 | 1.000 | 1.000 |\n| 10 | 1.000 | 1.000 | 1.000 |\n| 15 | 1.000 | 1.000 | 1.000 |", "table_19": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 1.000 | 1.000 | 1.000 |\n| 10 | 1.000 | 1.000 | 1.000 |\n| 15 | 1.000 | 1.000 | 1.000 |", "table_20": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 0.13 | 0.13 | 0.13 |\n| 10 | 0.13 | 0.13 | 0.12 |\n| 15 | 0.10 | 0.09 | 0.08 |", "table_21": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 0.52 | 0.51 | 0.50 |\n| 10 | 0.49 | 0.47 | 0.41 |\n| 15 | 0.36 | 0.33 | 0.30 |", "table_22": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 0.10 | 0.09 | 0.10 |\n| 10 | 0.10 | 0.09 | 0.09 |\n| 15 | 0.07 | 0.06 | 0.06 |", "table_23": "| $c_{\\sigma} c_{\\theta}$ | 0.25 | 0.5 | 0.75 |\n| :--: | :--: | :--: | :--: |\n| 5 | 0.38 | 0.37 | 0.37 |\n| 10 | 0.37 | 0.33 | 0.28 |\n| 15 | 0.23 | 0.22 | 0.24 |"}, "images": {"img-0.jpeg": "data:image/jpeg;base64,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", "img-1.jpeg": "data:image/jpeg;base64,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"}}, {"section_id": 14, "text": "# D. 2 Simulation \n\nIn this section, we examine the recovery of the hierarchical structure of our method. For $J \\in\\{20,40\\}$ and $N \\in\\{500,2000\\}$, a data generation model is considered, resulting in a total of 4 simulation settings. With slight abuse of notation, we denote by $\\mathcal{B}_{g}^{*}$ as the true item groups related to the $g$ th factor. In the data generation model, $B_{1}^{*}=\\{1, \\ldots, J\\}, B_{2}^{*}=\\{1, \\ldots, J / 2\\}, B_{3}^{*}=\\{J / 2, \\ldots, J\\}, B_{4}^{*}=\\{1, \\ldots, J / 4\\}$, $B_{5}^{*}=\\{J / 4, \\ldots, J / 2\\}, B_{6}^{*}=\\{J / 2, \\ldots, 3 J / 4\\}, B_{7}^{*}=\\{3 J / 4, \\ldots, J\\} . \\Psi^{*}=\\mathbb{I}_{J \\times J}$, and $\\Lambda^{*}$ follows\n\n$$\n\\lambda_{j k}^{*}=\\left\\{\\begin{array}{l}\nu_{j k} \\text { if } k=1 \\\\\n0 \\text { if } k>1, j \\notin \\mathcal{B}_{k-1}^{*} \\\\\n\\left(1-2 x_{j k}\\right) u_{j k} \\text { if } k>1, j \\in \\mathcal{B}_{k-1}^{*}\n\\end{array}\\right.\n$$\n\nfor $j=1, \\ldots, J$ and $k=1, \\ldots, G+1$. Here, $u_{j k} \\mathrm{~s}$ are i.i.d., following a Uniform $(0.2,1)$ distribution, and $x_{j k} \\mathrm{~s}$ are i.i.d., following a Bernoulli( 0.5 ) distribution.\n\nThe estimated parameters $\\widehat{\\Lambda}$ and $\\widehat{\\Psi}$ follow the same ALM algorithm in Section 2.2 except that the distance\n\nbetween the estimate and the space of the hierarchical factor loading matrices measured by\n\n$$\n\\max _{j \\in\\{1, \\ldots, J\\}} \\tilde{h}\\left(\\left|\\lambda_{j 2}^{(t)}\\right|, \\ldots,\\left|\\lambda_{j, G+1}^{(t)}\\right|\\right)\n$$\n\nwhere the function $\\tilde{h}$ returns the third-largest value of a vector. The estimated hierarchical factor model structure is then given by\n\n$$\n\\widehat{\\mathcal{B}}_{g}=\\left\\{j:\\left|\\lambda_{j, g+1}^{(T)}\\right|>\\delta_{2}\\right\\}\n$$\n\nWe also choose $\\delta_{2}=10^{-2}$ on the following simulation study.\nSince label-switching problem exists in factors that are nested within the same hierarchical factor, there exists 8 possible permutations of labels resulting in the same hierarchical structure. We denote by $\\mathcal{R}$ as the set of the 8 permutations. Then, the evaluation criteria for the recovery of the hierarchical structure are defined as:\n\n- Exact Match Criterion(EMC): $\\max _{\\sigma \\in \\mathcal{R}} \\prod_{g=1}^{G} \\mathbf{1}\\left(\\mathcal{B}_{\\sigma(g)}=\\mathcal{B}_{g}^{*}\\right)$, which equals 1 when the bi-factor structure is correctly learned and 0 otherwise.\n- Average Correctness Criterion(ACC): $\\max _{\\sigma \\in \\mathcal{R}} \\sum_{g=1}^{G}\\left(\\left|\\mathcal{B}_{g}^{*} \\cap \\mathcal{B}_{\\sigma(g)}\\right|+\\left|\\mathcal{B}_{\\sigma(g)}^{C} \\cap \\mathcal{B}_{g}^{* C}\\right|\\right) /(J G)$.\n\nFor each setting, we first generate $\\Lambda^{*}$ once and use them to generate 100 datasets. The averaged results under 100 replication are shown in Table D.1. From the simulation results, we find that our method performs well on the recovery of hierarchical structure.\n\nTable D.1: Simulation results of the recovery of hierarchical factor structure.\n\n![table_24](table_24)", "tables": {"table_24": "| $J$ | $N$ | EMC | ACC |\n| :--: | :--: | :--: | :--: |\n| 20 | 500 | 0.94 | 0.998 |\n|  | 2000 | 1.00 | 1.000 |\n| 40 | 500 | 0.88 | 0.988 |\n|  | 2000 | 1.00 | 1.000 |"}, "images": {}}, {"section_id": 15, "text": "# E Extraversion Scale Item Key \n\nTable E.1: Extraversion Item Key\n\n![table_25](table_25)", "tables": {"table_25": "| Item | Sign | Facet | Item |\n| :--: | :--: | :--: | :--: |\n| 1 | +E1 | Friendliness | Make friends easily. |\n| 2 | +E1 | Friendliness | Feel comfortable around people. |\n| 3 | -E1 | Friendliness | Avoid contacts with others. |\n| 4 | -E1 | Friendliness | Keep others at a distance. |\n| 5 | +E2 | Gregariousness | Love large parties. |\n| 6 | +E2 | Gregariousness | Talk to a lot of different people at parties. |\n| 7 | -E2 | Gregariousness | Prefer to be alone. |\n| 8 | -E2 | Gregariousness | Avoid crowds. |\n| 9 | +E3 | Assertiveness | Take charge. |\n| 10 | +E3 | Assertiveness | Try to lead others. |\n| 11 | +E3 | Assertiveness | Take control of things. |\n| 12 | -E3 | Assertiveness | Wait for others to lead the way. |\n| 13 | +E4 | Activity Level | Am always busy. |\n| 14 | +E4 | Activity Level | Am always on the go. |\n| 15 | +E4 | Activity Level | Do a lot in my spare time. |\n| 16 | -E4 | Activity Level | Like to take it easy. |\n| 17 | +E5 | Excitement-Seeking | Love excitement. |\n| 18 | +E5 | Excitement-Seeking | Seek adventure. |\n| 19 | +E5 | Excitement-Seeking | Enjoy being reckless. |\n| 20 | +E5 | Excitement-Seeking | Act wild and crazy. |\n| 21 | +E6 | Cheerfulness | Radiate joy. |\n| 22 | +E6 | Cheerfulness | Have a lot of fun. |\n| 23 | +E6 | Cheerfulness | Love life. |\n| 24 | +E6 | Cheerfulness | Look at the bright side of life. |"}, "images": {}}, {"section_id": 16, "text": "## F Real Data Analysis using Bi-factor Rotation Method\n\nIn this section, we present the results of the same data in Section 4 by bi-factor rotation method as a comparison with our proposed method.\n\nUsing a candidate set $\\mathcal{G}=\\{2, \\ldots, 12\\}$, the BIC procedure of exploratory factor analysis given in Section 3.2 selects eight factors in total, which coincide with the number of factors selected by the BIC procedure of our proposed method. By applying the bi-factor rotation method(Jennrich and Bentler, 2012), we get the\n\nrotation solutions $\\widehat{\\Lambda}^{o b l q}$ in Table F. 1 and $\\widehat{\\Phi}^{o b l q}$ in equation (F.1).\nTable F.1: Estimated loading matrix $\\widehat{\\Lambda}^{o b l q}$ with seven group factors.\n\n![table_26](table_26)\n\n$$\n\\widehat{\\Phi}^{o b l q}=\\left(\\begin{array}{cccccccc}\n1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 0.19 & -0.14 & -0.17 & -0.15 & 0.10 & 0.05 \\\\\n0 & 0.19 & 1 & -0.10 & 0.00 & -0.07 & 0.11 & 0.39 \\\\\n0 & -0.14 & -0.10 & 1 & 0.02 & 0.07 & 0.06 & 0.07 \\\\\n0 & -0.17 & 0.00 & 0.02 & 1 & 0.21 & -0.07 & 0.11 \\\\\n0 & -0.15 & -0.07 & 0.07 & 0.21 & 1 & -0.09 & 0.01 \\\\\n0 & 0.10 & 0.11 & 0.06 & -0.07 & -0.09 & 1 & 0.00 \\\\\n0 & 0.05 & 0.39 & 0.07 & 0.11 & 0.01 & 0.00 & 1\n\\end{array}\\right)\n$$\n\nTo help to identify a bi-factor structure from $\\widehat{\\Lambda}^{o b l q}$, all loadings whose absolute value is less than 0.2 are\n\nset to zero, as is done in Jennrich and Bentler (2012). The adjusted loadings are presented in Table F.2. As expected, the loading structure does not conform strictly to a bi-factor model, with four items loading onto three factors.\n\nTable F.2: Estimated bi-factor loading matrix with seven group factors.\n\n![table_27](table_27)\n\nWe now analyze the estimated model in detail. In this result, we have adjusted the sign flip and column swapping to align with the result of the proposed method. All loadings on the general factor are positive, supporting the existence of a general extraversion factor. We interpret the group factors G3, G4, G5 as the Cheerfulness, Assertiveness and Activity Level factors respectively. G2, loaded with the items \"19 Enjoy being reckless\" and \"20 Act wild and crazy\" is interpreted as the Reckless Excitement-Seeking factor and consistent with the result from our proposed method. G7 is loaded with items \"4 Keep others at a distance\", \"17 Love excitement\", \"18 Seek adventure\" and \"19 Enjoy being reckless\". Even though G2 and G7 are loaded with item 19 in common, G7 emphasizes more on the pursuit of meaningful experiences. So we still interpret G7 as the Meaningful Excitement-Seeking factor. Additionally, G2 and G7 are positively correlated,\n\nas is the case in Section 4.\nThere is a notable difference between the results from the two methods. The result of the ALM method shows the clear presence of a Friendliness factor (G1) and a Gregariousness factor (G6). However, for the bi-factor rotation method, these does not seem to exist a clear Friendliness factor. Both G1 and G6 in the solution of the bi-factor rotation method are related to Gregariousness. Large loadings of the variables designed to measure Friendliness now spread out among several group factors.\n\nOverall, both methods suggest similar (approximate) bi-factor model structures, and the result from the proposed method tends to be neater and more interpretable.", "tables": {"table_26": "| Items | Sign | General | G1 | G2 | G3 | G4 | G5 | G6 | G7 |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n| 1 | +E1 | 0.86 | 0.01 | -0.06 | -0.08 | -0.03 | -0.04 | 0.42 | -0.08 |\n| 2 | +E1 | 0.85 | 0.03 | -0.11 | 0.03 | 0.06 | -0.12 | 0.07 | -0.01 |\n| 3 | -E1 | 0.91 | -0.02 | -0.12 | -0.01 | 0.03 | -0.09 | -0.02 | -0.05 |\n| 4 | -E1 | 0.87 | -0.14 | -0.04 | -0.01 | -0.10 | -0.14 | -0.03 | -0.20 |\n| 5 | +E2 | 0.88 | 0.69 | 0.00 | 0.00 | -0.02 | 0.00 | -0.01 | 0.01 |\n| 6 | +E2 | 0.92 | 0.25 | 0.03 | -0.12 | 0.09 | 0.05 | 0.22 | -0.03 |\n| 7 | -E2 | 0.72 | -0.06 | -0.03 | -0.04 | -0.08 | -0.16 | -0.21 | -0.12 |\n| 8 | -E2 | 0.85 | 0.22 | -0.02 | -0.05 | -0.06 | -0.07 | -0.29 | -0.08 |\n| 9 | +E3 | 0.52 | 0.02 | 0.02 | 0.00 | 0.79 | 0.02 | 0.04 | -0.03 |\n| 10 | +E3 | 0.52 | 0.04 | 0.00 | 0.00 | 0.75 | -0.03 | 0.03 | 0.01 |\n| 11 | +E3 | 0.44 | -0.03 | 0.00 | 0.05 | 0.62 | 0.04 | -0.08 | 0.01 |\n| 12 | -E3 | 0.55 | -0.09 | -0.04 | -0.02 | 0.62 | -0.05 | -0.06 | 0.06 |\n| 13 | +E4 | 0.32 | 0.05 | 0.01 | 0.00 | 0.02 | 0.82 | -0.02 | -0.06 |\n| 14 | +E4 | 0.51 | -0.07 | 0.02 | -0.02 | -0.01 | 0.74 | 0.06 | 0.06 |\n| 15 | +E4 | 0.49 | 0.02 | -0.08 | 0.15 | -0.02 | 0.51 | -0.06 | 0.14 |\n| 16 | -E4 | 0.19 | -0.14 | -0.04 | -0.14 | 0.08 | 0.37 | -0.19 | -0.07 |\n| 17 | +E5 | 0.46 | 0.09 | -0.03 | -0.04 | 0.02 | 0.02 | 0.06 | 0.49 |\n| 18 | +E5 | 0.53 | -0.05 | 0.02 | 0.00 | 0.01 | 0.03 | -0.04 | 0.62 |\n| 19 | +E5 | 0.28 | 0.05 | 0.48 | -0.02 | 0.02 | -0.12 | 0.00 | 0.33 |\n| 20 | +E5 | 0.48 | 0.00 | 1.10 | 0.00 | 0.00 | 0.01 | 0.00 | -0.02 |\n| 21 | +E6 | 0.64 | -0.12 | 0.04 | 0.26 | -0.04 | 0.01 | 0.28 | -0.01 |\n| 22 | +E6 | 0.69 | 0.06 | 0.11 | 0.40 | -0.01 | 0.01 | 0.09 | 0.08 |\n| 23 | +E6 | 0.63 | 0.02 | -0.01 | 0.63 | 0.03 | 0.01 | -0.05 | -0.01 |\n| 24 | +E6 | 0.58 | -0.04 | -0.03 | 0.60 | 0.00 | -0.02 | 0.01 | -0.04 |", "table_27": "| Items | Sign | General | G1 | G2 | G3 | G4 | G5 | G6 | G7 |\n| --: | :--: | --: | --: | --: | --: | --: | --: | --: | --: |\n| 1 | +E1 | 0.86 | 0 | 0 | 0 | 0 | 0 | 0.42 | 0 |\n| 2 | +E1 | 0.85 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 3 | -E1 | 0.91 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 4 | -E1 | 0.87 | 0 | 0 | 0 | 0 | 0 | 0 | -0.20 |\n| 5 | +E2 | 0.88 | 0.69 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 6 | +E2 | 0.92 | 0.25 | 0 | 0 | 0 | 0 | 0.22 | 0 |\n| 7 | -E2 | 0.72 | 0 | 0 | 0 | 0 | 0 | -0.21 | 0 |\n| 8 | -E2 | 0.85 | 0.22 | 0 | 0 | 0 | 0 | -0.29 | 0 |\n| 9 | +E3 | 0.52 | 0 | 0 | 0 | 0.79 | 0 | 0 | 0 |\n| 10 | +E3 | 0.52 | 0 | 0 | 0 | 0.75 | 0 | 0 | 0 |\n| 11 | +E3 | 0.44 | 0 | 0 | 0 | 0.62 | 0 | 0 | 0 |\n| 12 | -E3 | 0.55 | 0 | 0 | 0 | 0.62 | 0 | 0 | 0 |\n| 13 | +E4 | 0.32 | 0 | 0 | 0 | 0 | 0.82 | 0 | 0 |\n| 14 | +E4 | 0.51 | 0 | 0 | 0 | 0 | 0.74 | 0 | 0 |\n| 15 | +E4 | 0.49 | 0 | 0 | 0 | 0 | 0.51 | 0 | 0 |\n| 16 | -E4 | 0 | 0 | 0 | 0 | 0 | 0.37 | 0 | 0 |\n| 17 | +E5 | 0.46 | 0 | 0 | 0 | 0 | 0 | 0 | 0.49 |\n| 18 | +E5 | 0.53 | 0 | 0 | 0 | 0 | 0 | 0 | 0.62 |\n| 19 | +E5 | 0.28 | 0 | 0.48 | 0 | 0 | 0 | 0 | 0.33 |\n| 20 | +E5 | 0.48 | 0 | 1.10 | 0 | 0 | 0 | 0 | 0 |\n| 21 | +E6 | 0.64 | 0 | 0 | 0.26 | 0 | 0 | 0.28 | 0 |\n| 22 | +E6 | 0.69 | 0 | 0 | 0.40 | 0 | 0 | 0 | 0 |\n| 23 | +E6 | 0.63 | 0 | 0 | 0.63 | 0 | 0 | 0 | 0 |\n| 24 | +E6 | 0.58 | 0 | 0 | 0.60 | 0 | 0 | 0 | 0 |"}, "images": {}}, {"section_id": 17, "text": "# G Technical Proofs\n## G. 1 Proof of Theorem 1\n\nSuppose that $\\Lambda \\Phi(\\Lambda)^{\\top}+\\Psi=\\Lambda^{*} \\Phi^{*}\\left(\\Lambda^{*}\\right)^{\\top}+\\Psi^{*}$. Under Condition 1, we have $\\Lambda \\Phi(\\Lambda)^{\\top}=\\Lambda^{*} \\Phi^{*}\\left(\\Lambda^{*}\\right)^{\\top}$. For the simplicity of the notation, we substitute $\\Lambda\\left[\\mathcal{B}_{g}^{*},\\{1, \\ldots, G+1\\}\\right]$ for $\\Lambda\\left[\\mathcal{B}_{g}^{*},:\\right]$. The proof consists of three parts:(1) show the bi-factor structure of $\\mathcal{B}_{g_{1}}^{*}$ is unique, (2) show that combined with some group $g_{2} \\in \\mathcal{H}^{*}, g_{2} \\neq g_{1}$, $\\Lambda\\left[\\mathcal{B}_{g_{1}}^{*},:\\right]$ is identified up to a sign flip and a group permutation, (3) complete the proof of Theorem 1.\n\nWe first consider the equation\n\n$$\n\\Lambda\\left[\\mathcal{B}_{g_{1}}^{*},: \\left.\\right] \\Phi\\left(\\Lambda\\left[\\mathcal{B}_{g_{1}}^{*},:\\right]\\right)^{\\top}=\\Lambda^{*}\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1,1+g_{1}\\right\\}\\right]\\left(\\Lambda^{*}\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1,1+g_{1}\\right\\}\\right]\\right)^{\\top}\n$$\n\nSince the matrix on the right side of (G.1) has rank 2, there exist 2 possible bi-factor structures for the matrix on the left side of (G.1): (1) $\\Lambda\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1,1+g_{1}^{\\prime}\\right\\}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1,1+g_{1}^{\\prime}\\right\\}\\right]\\right)^{\\top}=\\Lambda^{*}\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1,1+g_{1}\\right\\}\\right]\\left(\\Lambda^{*}\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1,1+g_{1}\\right\\}\\right]\\right)^{\\top}$ for some $g_{1}^{\\prime} \\in\\{1, \\ldots, G\\}$ and (2) There exists a partition of $\\mathcal{B}_{g_{1}}^{*}=\\mathcal{B}_{g_{1,1}}^{*} \\cup \\mathcal{B}_{g_{1,2}}^{*}$ and $g_{1}^{\\prime}, g_{2}^{\\prime} \\in\\{1, \\ldots, G\\}$ such that\n\n$$\n\\left(\\begin{array}{ccc}\n\\boldsymbol{\\lambda}_{1} & \\boldsymbol{\\lambda}_{g_{1}^{\\prime}} & \\mathbf{0} \\\\\n\\boldsymbol{\\lambda}_{2} & \\mathbf{0} & \\boldsymbol{\\lambda}_{g_{2}^{\\prime}}\n\\end{array}\\right)\\left(\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n0 & 1 & \\phi_{1+g_{1}^{\\prime}, 1+g_{2}^{\\prime}} \\\\\n0 & \\phi_{1+g_{1}^{\\prime}, 1+g_{2}^{\\prime}} & 1\n\\end{array}\\right)\\left(\\begin{array}{ll}\n\\boldsymbol{\\lambda}_{1}^{\\top} & \\boldsymbol{\\lambda}_{2}^{\\top} \\\\\n\\boldsymbol{\\lambda}_{g_{1}^{\\prime}}^{\\top} & \\mathbf{0}^{\\top} \\\\\n\\mathbf{0}^{\\top} & \\boldsymbol{\\lambda}_{g_{2}^{\\prime}}^{\\top}\n\\end{array}\\right)=\\left(\\begin{array}{ll}\n\\boldsymbol{\\lambda}_{1}^{*} & \\boldsymbol{\\lambda}_{g_{1}}^{*} \\\\\n\\boldsymbol{\\lambda}_{2}^{*} & \\boldsymbol{\\lambda}_{g_{2}}^{*}\n\\end{array}\\right)\\left(\\begin{array}{ll}\n\\left(\\boldsymbol{\\lambda}_{1}^{*}\\right)^{\\top} & \\left(\\boldsymbol{\\lambda}_{2}^{*}\\right)^{\\top} \\\\\n\\left(\\boldsymbol{\\lambda}_{g_{1}}^{*}\\right)^{\\top} & \\left(\\boldsymbol{\\lambda}_{g_{2}}^{*}\\right)^{\\top}\n\\end{array}\\right)\n$$\n\nwhere $\\boldsymbol{\\lambda}_{i}=\\Lambda\\left[\\mathcal{B}_{g_{1}, i}^{*},\\{1\\}\\right], \\boldsymbol{\\lambda}_{g_{i}^{\\prime}}=\\Lambda\\left[\\mathcal{B}_{g_{1}, i}^{*},\\left\\{1+g_{i}^{\\prime}\\right\\}\\right], \\boldsymbol{\\lambda}_{i}^{*}=\\Lambda^{*}\\left[\\mathcal{B}_{g_{1}, i}^{*},\\{1\\}\\right]$ and $\\boldsymbol{\\lambda}_{g_{i}}^{*}=\\Lambda^{*}\\left[\\mathcal{B}_{g_{1}, i}^{*},\\left\\{1+g_{1}\\right\\}\\right]$ with $\\boldsymbol{\\lambda}_{g_{i}^{\\prime}} \\neq \\mathbf{0}$ for $i=1,2$.\n\nHere we consider the second case. Since the matrix on the right side of (G.2) has rank 2, we must have $\\left(\\boldsymbol{\\lambda}_{i}, \\boldsymbol{\\lambda}_{g_{i}^{\\prime}}\\right)$ has rank 1 for $i=1,2$, which leads to the fact that $\\left(\\boldsymbol{\\lambda}_{i}^{*}, \\boldsymbol{\\lambda}_{g_{i}}^{*}\\right)$ has rank 1. However, by\n\nCondition 2, there exists at least one of $\\left(\\boldsymbol{\\lambda}_{1}^{*}, \\boldsymbol{\\lambda}_{g_{1}}^{*}\\right)$ and $\\left(\\boldsymbol{\\lambda}_{2}^{*}, \\boldsymbol{\\lambda}_{g_{2}}^{*}\\right)$ has rank 2 . Thus, we must have $\\Lambda\\left[\\mathcal{B}_{g_{1}}^{*},\\{1,1+\\right.$ $\\left.g_{1}^{\\prime}\\}\\left[\\left(\\Lambda\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1,1+g_{1}^{\\prime}\\right\\}\\right]\\right)^{\\top}=\\Lambda^{*}\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1,1+g_{1}\\right\\}\\right]\\left(\\Lambda^{*}\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1,1+g_{1}\\right\\}\\right]\\right)^{\\top}$ for some $g_{1}^{\\prime} \\in\\{1, \\ldots, G\\}$. Without loss of generation, we assume $g_{1}^{\\prime}=g_{1}$.\n\nSecondly, there exits some $g_{2} \\in \\mathcal{H}^{*}$ and $g_{2} \\neq g_{1}$ by Condition 2. We consider the $\\mathcal{B}_{g_{1}}^{*} \\cup \\mathcal{B}_{g_{2}}^{*}$ rows and $\\mathcal{B}_{g_{1}}^{*} \\cup \\mathcal{B}_{g_{2}}^{*}$ columns of $\\Lambda \\Phi(\\Lambda)^{\\top}$ and $\\Lambda^{*} \\Phi^{*}\\left(\\Lambda^{*}\\right)^{\\top}$. Since the bi-factor structure of the $\\mathcal{B}_{g_{1}}^{*}$ rows and $\\mathcal{B}_{g_{1}}^{*}$ columns has already been known, there are two possible bi-factor structures: (1) There exists some $g_{2}^{\\prime} \\in\\{1, \\ldots, G\\}$ such that\nwhere $\\boldsymbol{\\lambda}_{i}=\\Lambda\\left[\\mathcal{B}_{g_{i}}^{*},\\{1\\}\\right], \\boldsymbol{\\lambda}_{g_{i}^{\\prime}}=\\Lambda\\left[\\mathcal{B}_{g_{i}}^{*},\\left\\{1+g_{i}^{\\prime}\\right\\}\\right], \\boldsymbol{\\lambda}_{i}^{*}=\\Lambda^{*}\\left[\\mathcal{B}_{g_{i}}^{*},\\{1\\}\\right]$ and $\\boldsymbol{\\lambda}_{g_{i}}^{*}=\\Lambda^{*}\\left[\\mathcal{B}_{g_{i}}^{*},\\left\\{1+g_{1}\\right\\}\\right]$ for $i=1,2$. $\\rho_{1,2}=\\phi_{1+g_{1}^{\\prime}, 1+g_{2}^{\\prime}}$ and $\\rho_{1,2}^{*}=\\phi_{1+g_{1}, 1+g_{2}}^{*}$.\n(2) There exists a partition of $\\mathcal{B}_{g_{2}}^{*}=\\mathcal{B}_{g_{2,1}}^{*} \\cup \\mathcal{B}_{g_{2,2}}^{*}$ and $g_{2}^{\\prime} \\in\\{1, \\ldots, G\\}$ such that\n\n$$\n\\begin{aligned}\n& \\left(\\begin{array}{ccc}\n\\boldsymbol{\\lambda}_{1} & \\boldsymbol{\\lambda}_{g_{1}} & 0 \\\\\n\\boldsymbol{\\lambda}_{2,1} & \\boldsymbol{\\lambda}_{2, g_{1}} & 0 \\\\\n\\boldsymbol{\\lambda}_{2,2} & 0 & \\boldsymbol{\\lambda}_{2, g_{2}^{\\prime}}\n\\end{array}\\right)\\left(\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n0 & 1 & \\rho_{1,2} \\\\\n0 & \\rho_{1,2} & 1\n\\end{array}\\right)\\left(\\begin{array}{ccc}\n\\boldsymbol{\\lambda}_{1}^{\\top} & \\boldsymbol{\\lambda}_{2,1}^{\\top} & \\boldsymbol{\\lambda}_{2,2}^{\\top} \\\\\n\\boldsymbol{\\lambda}_{g_{1}}^{\\top} & \\boldsymbol{\\lambda}_{2, g_{1}}^{\\top} & 0^{\\top} \\\\\n\\mathbf{0}^{\\top} & \\mathbf{0}^{\\top} & \\boldsymbol{\\lambda}_{2, g_{2}^{\\prime}}^{\\top}\n\\end{array}\\right) \\\\\n& =\\left(\\begin{array}{ccc}\n\\boldsymbol{\\lambda}_{1}^{*} & \\boldsymbol{\\lambda}_{g_{1}}^{*} & 0 \\\\\n\\boldsymbol{\\lambda}_{2,1}^{*} & \\mathbf{0} & \\boldsymbol{\\lambda}_{g_{2}, 1}^{*} \\\\\n\\boldsymbol{\\lambda}_{2,2}^{*} & \\mathbf{0} & \\boldsymbol{\\lambda}_{g_{2}, 2}^{*}\n\\end{array}\\right)\\left(\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n0 & 1 & \\rho_{1,2}^{*} \\\\\n0 & \\rho_{1,2}^{*} & 1\n\\end{array}\\right)\\left(\\begin{array}{ccc}\n\\left(\\boldsymbol{\\lambda}_{1}^{*}\\right)^{\\top} & \\left(\\boldsymbol{\\lambda}_{2,1}^{*}\\right)^{\\top} & \\left(\\boldsymbol{\\lambda}_{2,2}^{*}\\right)^{\\top} \\\\\n\\left(\\boldsymbol{\\lambda}_{g_{1}}^{*}\\right)^{\\top} & \\mathbf{0}^{\\top} & \\mathbf{0}^{\\top} \\\\\n\\mathbf{0}^{\\top} & \\left(\\boldsymbol{\\lambda}_{g_{2}, 1}^{*}\\right)^{\\top} & \\left(\\boldsymbol{\\lambda}_{g_{2}, 2}^{*}\\right)^{\\top}\n\\end{array}\\right),\n\\end{aligned}\n$$\n\nwhere $\\boldsymbol{\\lambda}_{1}=\\Lambda\\left[\\mathcal{B}_{g_{1}}^{*},\\{1\\}\\right], \\boldsymbol{\\lambda}_{g_{1}}=\\Lambda\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1+g_{1}\\right\\}\\right], \\boldsymbol{\\lambda}_{1}^{*}=\\Lambda^{*}\\left[\\mathcal{B}_{g_{1}}^{*},\\{1\\}\\right], \\boldsymbol{\\lambda}_{g_{1}}^{*}=\\Lambda^{*}\\left[\\mathcal{B}_{g_{1}}^{*},\\left\\{1+g_{1}\\right\\}\\right], \\boldsymbol{\\lambda}_{2, i}=$ $\\Lambda\\left[\\mathcal{B}_{g_{2}, i}^{*},\\{1\\}\\right], \\boldsymbol{\\lambda}_{2, i}^{*}=\\Lambda\\left[\\mathcal{B}_{g_{2}, i}^{*},\\{1\\}\\right], \\boldsymbol{\\lambda}_{g_{2}, i}^{*}=\\Lambda\\left[\\mathcal{B}_{g_{2}, i}^{*},\\left\\{1+g_{2}\\right\\}\\right]$ for $i=1,2, \\boldsymbol{\\lambda}_{2, g_{1}}=\\Lambda\\left[\\mathcal{B}_{g_{2}, 1}^{*},\\left\\{1+g_{1}\\right\\}\\right], \\boldsymbol{\\lambda}_{2, g_{2}^{\\prime}}=$ $\\Lambda\\left[\\mathcal{B}_{g_{2}, 2}^{*},\\left\\{1+g_{2}^{\\prime}\\right\\}\\right], \\rho_{1,2}=\\phi_{1+g_{1}, 1+g_{2}^{\\prime}}$ and $\\rho_{1,2}^{*}=\\phi_{1+g_{1}, 1+g_{2}}^{*}$.\n\nFor the second case in (G.4), there exists some $\\alpha$ such that $\\boldsymbol{\\lambda}_{1}=\\cos \\alpha \\boldsymbol{\\lambda}_{1}^{*}-\\sin \\alpha \\boldsymbol{\\lambda}_{g_{1}}^{*}$ and $\\boldsymbol{\\lambda}_{g_{1}}=\\sin \\alpha \\boldsymbol{\\lambda}_{1}^{*}+$ $\\cos \\alpha \\boldsymbol{\\lambda}_{g_{1}}^{*}$. Since the $\\mathcal{B}_{g_{2}}^{*}$ rows and the $\\mathcal{B}_{g_{2}}^{*}$ columns of $\\Lambda \\Phi(\\Lambda)^{\\top}$ and $\\Lambda^{*} \\Phi^{*}\\left(\\Lambda^{*}\\right)^{\\top}$ have rank 2 , under the bi-factor structure of the second case, we have that $\\left(\\boldsymbol{\\lambda}_{2,1}, \\boldsymbol{\\lambda}_{2, g_{1}}, \\boldsymbol{\\lambda}_{2,1}^{*}, \\boldsymbol{\\lambda}_{g_{2}, 1}^{*}\\right)$ has rank 1 and $\\left(\\boldsymbol{\\lambda}_{2,2}, \\boldsymbol{\\lambda}_{2, g_{2}^{\\prime}}, \\boldsymbol{\\lambda}_{2,2}^{*}, \\boldsymbol{\\lambda}_{g_{2}, 2}^{*}\\right)$ has rank 1. Noticing that $\\boldsymbol{\\lambda}_{g_{2}, 1}^{*} \\neq \\mathbf{0}$, we assume that $\\lambda_{2,1}^{*}=k_{1} \\boldsymbol{\\lambda}_{g_{2}, 1}^{*}, \\boldsymbol{\\lambda}_{2,1}=k_{2} \\boldsymbol{\\lambda}_{g_{2}, 1}^{*}$ and $\\boldsymbol{\\lambda}_{2, g_{1}}=k_{3} \\boldsymbol{\\lambda}_{g_{2}, 1}^{*}$. For the $\\mathcal{B}_{g_{2}, 1}^{*}$ rows and the $\\mathcal{B}_{g_{2}, 1}^{*}$ columns of (G.4), we have $1+k_{1}^{2}=k_{2}^{2}+k_{3}^{2}$. For the $\\mathcal{B}_{g_{1}}^{*}$ rows and the $\\mathcal{B}_{g_{2}, 1}^{*}$\n\ncolumns of (G.4), we have\n\n$$\n\\begin{aligned}\n& \\boldsymbol{\\lambda}_{1}^{*}\\left(\\boldsymbol{\\lambda}_{2,1}^{*}\\right)^{\\top}+\\rho_{1,2}^{*} \\boldsymbol{\\lambda}_{g_{1}}^{*}\\left(\\boldsymbol{\\lambda}_{g_{2}, 1}^{*}\\right)^{\\top} \\\\\n= & \\boldsymbol{\\lambda}_{1}\\left(\\boldsymbol{\\lambda}_{2,1}\\right)^{\\top}+\\boldsymbol{\\lambda}_{g_{1}}\\left(\\boldsymbol{\\lambda}_{2, g_{1}}\\right)^{\\top} \\\\\n= & k_{2}\\left(\\cos \\alpha \\boldsymbol{\\lambda}_{1}^{*}-\\sin \\alpha \\boldsymbol{\\lambda}_{g_{1}}^{*}\\right)\\left(\\boldsymbol{\\lambda}_{g_{2}, 1}^{*}\\right)^{\\top}+k_{3}\\left(\\sin \\alpha \\boldsymbol{\\lambda}_{1}^{*}+\\cos \\alpha \\boldsymbol{\\lambda}_{g_{1}}^{*}\\right)\\left(\\boldsymbol{\\lambda}_{g_{2}, 1}^{*}\\right)^{\\top} \\\\\n= & \\left(k_{2} \\cos \\alpha+k_{3} \\sin \\alpha\\right) \\boldsymbol{\\lambda}_{1}^{*}\\left(\\boldsymbol{\\lambda}_{g_{2}, 1}^{*}\\right)^{\\top}+\\left(k_{3} \\cos \\alpha-k_{2} \\sin \\alpha\\right) \\boldsymbol{\\lambda}_{g_{1}}^{*}\\left(\\boldsymbol{\\lambda}_{g_{2}, 1}^{*}\\right)^{\\top}\n\\end{aligned}\n$$\n\nThen, we have $k_{1}=k_{2} \\cos \\alpha+k_{3} \\sin \\alpha$ and $\\rho_{1,2}^{*}=k_{3} \\cos \\alpha-k_{2} \\sin \\alpha$, which leads to $k_{1}^{2}+\\left(\\rho_{1,2}^{*}\\right)^{2}=k_{2}^{2}+k_{3}^{2}$. Combined with $1+k_{1}^{2}=k_{2}^{2}+k_{3}^{2}$, we have $\\left|\\rho_{1,2}^{*}\\right|=1$, which contradicts to the fact that $\\Phi^{*}$ is positive definite. Thus, only the first case is allowed. Without loss of generation, we assume $g_{2}^{\\prime}=g_{2}$.\n\nFor the first case in (G.3), there exists some $\\alpha, \\beta$ such that $\\boldsymbol{\\lambda}_{1}=\\cos \\alpha \\boldsymbol{\\lambda}_{1}^{*}-\\sin \\alpha \\boldsymbol{\\lambda}_{g_{1}}^{*}, \\boldsymbol{\\lambda}_{g_{1}}=\\sin \\alpha \\boldsymbol{\\lambda}_{1}^{*}+$ $\\cos \\alpha \\boldsymbol{\\lambda}_{g_{1}}^{*}, \\boldsymbol{\\lambda}_{2}=\\cos \\beta \\boldsymbol{\\lambda}_{2}^{*}-\\sin \\beta \\boldsymbol{\\lambda}_{g_{2}}^{*}$ and $\\boldsymbol{\\lambda}_{g_{2}}=\\sin \\beta \\boldsymbol{\\lambda}_{2}^{*}+\\cos \\beta \\boldsymbol{\\lambda}_{g_{2}}^{*}$. We then have the following equation\n\n$$\n\\left(\\begin{array}{cc}\n\\cos \\alpha & \\sin \\alpha \\\\\n-\\sin \\alpha & \\cos \\alpha\n\\end{array}\\right)\\left(\\begin{array}{cc}\n1 & 0 \\\\\n0 & \\rho_{12}\n\\end{array}\\right)\\left(\\begin{array}{cc}\n\\cos \\beta & -\\sin \\beta \\\\\n\\sin \\beta & \\cos \\beta\n\\end{array}\\right)=\\left(\\begin{array}{cc}\n1 & 0 \\\\\n0 & \\rho_{12}^{*}\n\\end{array}\\right)\n$$\n\nwhich leads to $1=\\cos \\alpha \\cos \\beta+\\rho_{12} \\sin \\alpha \\sin \\beta$. Since $\\left|\\rho_{12}\\right|<1$, we have $\\cos \\alpha \\cos \\beta=1$ and $\\sin \\alpha \\sin \\beta=0$. Without loss of generation, we assume $\\cos \\alpha=\\cos \\beta=1$. Then we have $\\boldsymbol{\\lambda}_{1}=\\boldsymbol{\\lambda}_{1}^{*}, \\boldsymbol{\\lambda}_{g_{1}}=\\boldsymbol{\\lambda}_{g_{1}}^{*}, \\boldsymbol{\\lambda}_{2}=\\boldsymbol{\\lambda}_{2}^{*}$, $\\boldsymbol{\\lambda}_{g_{2}}=\\boldsymbol{\\lambda}_{g_{2}}^{*}$ and $\\rho_{12}=\\rho_{12}^{*}$.\n\nFor any group $g_{3} \\neq g_{1}, g_{2}$, we consider the $\\mathcal{B}_{g 1}^{*} \\cup \\mathcal{B}_{g 3}^{*}$ rows and $\\mathcal{B}_{g 1}^{*} \\cup \\mathcal{B}_{g 3}^{*}$ columns of $\\Lambda \\Phi(\\Lambda)^{\\top}$ and $\\Lambda^{*} \\Phi^{*}\\left(\\Lambda^{*}\\right)^{\\top}$. Similar to the the proof of $g_{2}$, there exists only one possible bi-factor structure : For some $g_{3}^{\\prime} \\in\\{1, \\ldots, G\\}$, we have\n\n$$\n\\left(\\begin{array}{ccc}\n\\boldsymbol{\\lambda}_{1} & \\boldsymbol{\\lambda}_{g_{1}^{\\prime}} & 0 \\\\\n\\boldsymbol{\\lambda}_{3} & \\boldsymbol{0} & \\boldsymbol{\\lambda}_{g_{3}^{\\prime}}\n\\end{array}\\right)\\left(\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n1 & 1 & \\rho_{1,3} \\\\\n0 & \\rho_{1,3} & 1\n\\end{array}\\right)\\left(\\begin{array}{ccc}\n\\boldsymbol{\\lambda}_{1}^{\\top} & \\boldsymbol{\\lambda}_{3}^{\\top} \\\\\n\\boldsymbol{\\lambda}_{g_{1}^{\\prime}}^{\\top} & 0^{\\top} \\\\\n\\mathbf{0}^{\\top} & \\boldsymbol{\\lambda}_{g_{3}^{\\prime}}^{\\top}\n\\end{array}\\right)=\\left(\\begin{array}{ccc}\n\\boldsymbol{\\lambda}_{1}^{*} & \\boldsymbol{\\lambda}_{g_{1}}^{*} & 0 \\\\\n\\boldsymbol{\\lambda}_{3}^{*} & \\boldsymbol{0} & \\boldsymbol{\\lambda}_{g_{3}}^{*}\n\\end{array}\\right)\\left(\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n0 & 1 & \\rho_{1,3}^{*} \\\\\n0 & \\rho_{1,3}^{*} & 1\n\\end{array}\\right)\\left(\\begin{array}{ccc}\n\\left(\\boldsymbol{\\lambda}_{1}^{*}\\right)^{\\top} & \\left(\\boldsymbol{\\lambda}_{3}^{*}\\right)^{\\top} \\\\\n\\left(\\boldsymbol{\\lambda}_{g_{1}}^{*}\\right)^{\\top} & 0^{\\top} \\\\\n\\mathbf{0}^{\\top} & \\left(\\boldsymbol{\\lambda}_{g_{3}}^{*}\\right)^{\\top}\n\\end{array}\\right)\n$$\n\nwhere $\\boldsymbol{\\lambda}_{i}=\\Lambda\\left[\\mathcal{B}_{g_{i}}^{*},\\{1\\}\\right], \\boldsymbol{\\lambda}_{g_{i}^{\\prime}}=\\Lambda\\left[\\mathcal{B}_{g_{i}}^{*},\\left\\{1+g_{i}^{\\prime}\\right\\}\\right], \\boldsymbol{\\lambda}_{i}^{*}=\\Lambda^{*}\\left[\\mathcal{B}_{g_{i}}^{*},\\{1\\}\\right]$ and $\\boldsymbol{\\lambda}_{g_{i}}^{*}=\\Lambda^{*}\\left[\\mathcal{B}_{g_{i}}^{*},\\left\\{1+g_{1}\\right\\}\\right]$ for $i=1,3$. $\\rho_{1,3}=\\phi_{1+g_{1}^{\\prime}, 1+g_{3}^{\\prime}}$ and $\\rho_{1,3}^{*}=\\phi_{1+g_{1}, 1+g_{3}}^{*}$. We then have\n\n$$\n\\begin{aligned}\n& \\boldsymbol{\\lambda}_{1}^{*}\\left(\\boldsymbol{\\lambda}_{3}^{*}\\right)^{\\top}+\\rho_{1,3}^{*} \\boldsymbol{\\lambda}_{g_{1}}^{*}\\left(\\boldsymbol{\\lambda}_{g_{3}}^{*}\\right)^{\\top}=\\boldsymbol{\\lambda}_{1}\\left(\\boldsymbol{\\lambda}_{3}\\right)^{\\top}+\\rho_{1,3} \\boldsymbol{\\lambda}_{g_{1}}\\left(\\boldsymbol{\\lambda}_{g_{3}^{\\prime}}\\right)^{\\top} \\\\\n& \\boldsymbol{\\lambda}_{3}^{*}\\left(\\boldsymbol{\\lambda}_{3}^{*}\\right)^{\\top}+\\boldsymbol{\\lambda}_{g_{3}}^{*}\\left(\\boldsymbol{\\lambda}_{g_{3}}^{*}\\right)^{\\top}=\\boldsymbol{\\lambda}_{3}\\left(\\boldsymbol{\\lambda}_{3}\\right)^{\\top}+\\boldsymbol{\\lambda}_{g_{3}}\\left(\\boldsymbol{\\lambda}_{g_{3}}\\right)^{\\top}\n\\end{aligned}\n$$\n\nSince we have proved $\\boldsymbol{\\lambda}_{1}^{*}=\\boldsymbol{\\lambda}_{1}$ and $\\boldsymbol{\\lambda}_{g_{1}}^{*}=\\boldsymbol{\\lambda}_{g_{1}}$, we then have $\\boldsymbol{\\lambda}_{3}^{*}=\\boldsymbol{\\lambda}_{3}, \\boldsymbol{\\lambda}_{g_{3}}^{*}=\\boldsymbol{\\lambda}_{g_{3}^{\\prime}}, \\rho_{1,3}^{*}=\\rho_{1,3}$ or $\\boldsymbol{\\lambda}_{g_{3}}^{*}=-\\boldsymbol{\\lambda}_{g_{3}^{\\prime}}$,\n\n$\\rho_{1,3}^{*}=-\\rho_{1,3}$.\nNow, since $\\Lambda$ has $G$ group factors, according to the previous proof, each variable belonging to $\\mathcal{B}_{i}^{*}$ loads on a unique group factor according to $\\Lambda$ and the loadings of the general factor and the group factors are determined up to a sign flip for $i=1, \\ldots, G$. Thus, there exist a diagonal sign-flip matrix $D \\in \\mathcal{D}$ and a permutation matrix $P \\in \\mathcal{P}$ such that $\\Lambda=\\Lambda^{*} P D$. It is straightforward to further check that $\\Phi=D P^{\\top} \\Phi^{*} P D$. Thus, the proof is completed.", "tables": {}, "images": {}}, {"section_id": 18, "text": "# G. 2 Identifiability of Estimated Bi-factor Structure in Real Data Example \n\nFor any matrix $A$, we use $\\operatorname{rank}(A)$ to denote the rank of $A$. The following condition is a necessary condition for the identifiability of the extended bi-factor model under a known bi-factor structure, as proposed in Theorem 3 of Fang et al. (2021).\n\nCondition 4. $\\left|\\mathcal{B}_{g}\\right| \\geqslant 2$ for all $g=1, \\ldots, G$.\n\nWe then propose the following condition for the identifiability of parameters when the true bi-factor structure is the same as the estimated structure in Section 4.\n\nCondition 5. For any $m \\times n$ dimensional submatrix of $\\Phi\\{\\{2, \\ldots, 1+G\\},\\{2, \\ldots, 1+G\\}\\}, 1 \\leqslant m, n \\leqslant G$, it's rank is $\\min (m, n)$.\n\nCondition 6. For any $g$ such that $\\left|\\mathcal{B}_{g}^{*}\\right| \\geqslant 3$, any 2 rows of $\\Lambda^{*}\\left[\\mathcal{B}_{g}^{*},\\{1,1+g\\}\\right]$ are linearly independent.\nRemark 4. Condition 5 restricts that the correlation matrix of group factors does not degenerate. In Theorem 2, we restrict the parametric space of $\\Phi$ to the space satisfying Condition 5. We note that $\\widehat{\\Lambda}$ in Section 4 satisfies Condition 5. Condition 6 is easy to check in practice and $\\widehat{\\Lambda}$ in Section 4 satisfies Condition 6 .\n\nTheorem 2. Suppose the true bi-factor structure follows $\\widehat{\\Lambda}$ in Section 4. Let $\\Lambda^{*}, \\Phi^{*}$ and $\\Psi^{*}$ be the true parameters such that Conditions 4 -6 are satisfied. For any parameters $\\Lambda, \\Phi$ and $\\Psi$ that satisfy Conditions 4 and 5 and $\\Lambda^{*} \\Phi^{*}\\left(\\Lambda^{*}\\right)^{\\top}+\\Psi^{*}=\\Lambda \\Phi(\\Lambda)^{\\top}+\\Psi$, there exists a diagonal sign-flip matrix $D \\in \\mathcal{D}$ and a permutation matrix $P \\in \\mathcal{P}$ such that $\\Lambda=\\Lambda^{*} P D, \\Phi=D P^{\\top} \\Phi^{*} P D$ and $\\Psi^{*}=\\Psi$.\n\nProof of Theorem 2 : Without loss of generation, we assume that $\\left|\\mathcal{B}_{1}^{*}\\right|=\\left|\\mathcal{B}_{2}^{*}\\right|=5,\\left|\\mathcal{B}_{3}^{*}\\right|=\\left|\\mathcal{B}_{4}^{*}\\right|=4$ and $\\left|\\mathcal{B}_{5}^{*}\\right|=\\left|\\mathcal{B}_{6}^{*}\\right|=\\left|\\mathcal{B}_{7}^{*}\\right|=2$. Suppose that there exists $\\Lambda, \\Phi$ and $\\Psi$ and $\\Sigma=\\Lambda \\Phi \\Lambda^{\\top}+\\Psi$ such that $\\Sigma=\\Sigma^{*}$. The proof consists of two parts: (1) Show that $\\Lambda\\left[\\cup_{i=1}^{4} \\mathcal{B}_{i}^{*}, \\vdots\\right]$ and $\\Lambda^{*}\\left[\\cup_{i=1}^{4} \\mathcal{B}_{i}^{*}, \\vdots\\right]$ has the same bi-factor structure. Without loss of generality, we further assume that $\\Lambda\\left[\\mathcal{B}_{i}^{*},\\{1+i\\}\\right] \\neq \\mathbf{0}$ for $i=1, \\ldots, 4$. We show that there exists some $5 \\times 5$ sign flip matrix $\\widehat{D}$ such that $\\Lambda\\left[\\cup_{i=1}^{4} \\mathcal{B}_{i}^{*},\\{1, \\ldots, 5\\}\\right]=\\Lambda^{*}\\left[\\cup_{i=1}^{4} \\mathcal{B}_{i}^{*},\\{1, \\ldots, 5\\}\\right] \\widehat{D}$,\n\n$\\Phi\\left[\\{1, \\ldots, 5\\},\\{1, \\ldots, 5\\}\\right]=\\widetilde{D} \\Phi^{*}[\\{1, \\ldots, 5\\},\\{1, \\ldots, 5\\}] \\widetilde{D}$ and $\\psi_{j}=\\psi_{j}^{*}$ for $j \\in \\cup_{i=1}^{4} \\mathcal{B}_{i}^{*}$. (2) Show that $\\Lambda$ and $\\Lambda^{*}$ have the same bi-factor structure for the rest of the variables and complete the proof.\n\nWe now prove the first part. Let $\\mathcal{F}_{i}=\\left\\{g: \\Lambda\\left[\\mathcal{B}_{i}^{*},\\{1+g\\}\\right] \\neq \\mathbf{0}\\right\\} \\cup\\{1\\}$ be the set of factors such that the variables belonging to $\\mathcal{B}_{i}^{*}$ load on these factors for $i=1, \\ldots, 4$. We note that $\\left|\\mathcal{F}_{i}\\right| \\geqslant 2$ for $i=1, \\ldots, 4$. When $\\left|\\mathcal{F}_{i}\\right|=2$, all variables that belong to $\\mathcal{B}_{i}^{*}$ load on the same group factor. We claim that\n\n$$\n\\operatorname{rank}\\left(\\Lambda\\left[\\mathcal{B}_{i}^{*}, \\mathcal{F}_{i}\\right]\\right)=\\left|\\mathcal{F}_{i}\\right| \\text { if }\\left|\\mathcal{F}_{i}\\right| \\leqslant\\left|\\mathcal{B}_{i}^{*}\\right| \\text { for } i=1, \\ldots, 4\n$$\n\nIf $\\left|\\mathcal{F}_{i}\\right| \\leqslant\\left|\\mathcal{B}_{i}^{*}\\right|$, there exists some $g_{i} \\in \\mathcal{F}_{i}, g_{i} \\neq 1$ and $j_{g_{i}}, j_{g_{i}}^{\\prime} \\in \\mathcal{B}_{i}^{*}$ such that $\\lambda_{j_{g_{i}}, 1+g_{i}} \\neq 0$ and $\\lambda_{j_{g_{i}}^{\\prime}, 1+g_{i}} \\neq 0$. For $1 \\leqslant i^{\\prime} \\leqslant 4, i^{\\prime} \\neq i$, consider the equation $\\Sigma\\left[\\left\\{j_{g_{i}}, j_{g_{i}}^{\\prime}\\right\\}, \\mathcal{B}_{i}^{*}\\right]=\\Sigma^{*}\\left[\\left\\{j_{g_{i}}, j_{g_{i}}^{\\prime}\\right\\}, \\mathcal{B}_{i}^{*}\\right]$, which is equivalent to\n\n$$\n\\begin{aligned}\n& \\Lambda\\left[\\left\\{j_{g_{i}}, j_{g_{i}}^{\\prime}\\right\\},\\left\\{1,1+g_{i}\\right\\}\\right] \\Phi\\left[\\left\\{1,1+g_{i}\\right\\}, \\mathcal{F}_{i^{\\prime}}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{i^{\\prime}}^{*}, \\mathcal{F}_{i^{\\prime}}\\right]\\right)^{\\top} \\\\\n= & \\Lambda^{*}\\left[\\left\\{j_{g_{i}}, j_{g_{i}}^{\\prime}\\right\\},\\{1,1+i\\}\\right] \\Phi^{*}\\left[\\{1,1+i\\},\\left\\{1,1+i^{\\prime}\\right\\}\\right]\\left(\\Lambda^{*}\\left[\\mathcal{B}_{i^{\\prime}}^{*},\\left\\{1,1+i^{\\prime}\\right\\}\\right]\\right)^{\\top}\n\\end{aligned}\n$$\n\nNoticing that by Condition 5 and 6 hold for $\\Phi^{*}$ and $\\Lambda^{*}$,\n\n$$\n\\Lambda^{*}\\left[\\left\\{j_{g_{i}}, j_{g_{i}}^{\\prime}\\right\\},\\{1,1+i\\}\\right] \\Phi^{*}\\left[\\{1,1+i\\},\\left\\{1,1+i^{\\prime}\\right\\}\\right]\\left(\\Lambda^{*}\\left[\\mathcal{B}_{i^{\\prime}}^{*},\\left\\{1,1+i^{\\prime}\\right\\}\\right]\\right)^{\\top}\n$$\n\nhas rank 2. Thus, $\\Lambda\\left[\\left\\{j_{g_{i}}, j_{g_{i}}^{\\prime}\\right\\},\\left\\{1,1+g_{i}\\right\\}\\right]$ should have rank 2. Otherwise, $\\Lambda\\left[\\left\\{j_{i}, j_{i}^{\\prime}\\right\\},\\left\\{1,1+g_{i}\\right\\}\\right] \\Phi\\left[\\{1,1+\\right.$ $\\left.g_{i}\\right\\}, \\mathcal{F}_{i^{\\prime}}\\left[\\left(\\Lambda\\left[\\mathcal{B}_{i^{\\prime}}^{*}, \\mathcal{F}_{i^{\\prime}}\\right]\\right)^{\\top}\\right.$ has at most rank 1, which contradicts (G.6). Then, since for each $g_{i}^{\\prime} \\in \\mathcal{F}_{i}, g_{i}^{\\prime} \\neq 1$, there exists some $j_{g_{i}^{\\prime}}$ such that $\\lambda_{j_{g_{i}^{\\prime}}, g_{i}^{\\prime}} \\neq 0$, it is easy to check that (G.5) holds.\n\nThen, consider the equation $\\Sigma\\left[\\mathcal{B}_{i}^{*}, \\mathcal{B}_{i^{\\prime}}^{*}\\right]=\\Sigma^{*}\\left[\\mathcal{B}_{i}^{*}, \\mathcal{B}_{i^{\\prime}}^{*}\\right]$ for $1 \\leqslant i \\neq i^{\\prime} \\leqslant 4$, which is equivalent to\n\n$$\n\\Lambda\\left[\\mathcal{B}_{i}^{*}, \\mathcal{F}_{i}\\right] \\Phi\\left[\\mathcal{F}_{i}, \\mathcal{F}_{i^{\\prime}}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{i^{\\prime}}^{*}, \\mathcal{F}_{i^{\\prime}}\\right]\\right)^{\\top}=\\Lambda^{*}\\left[\\mathcal{B}_{i}^{*},\\{1,1+i\\}\\right] \\Phi\\left[\\{1,1+i\\},\\left\\{1,1+i^{\\prime}\\right\\}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{i^{\\prime}}^{*},\\left\\{1,1+i^{\\prime}\\right\\}\\right]\\right)^{\\top}\n$$\n\nWith the same argument, $\\Lambda^{*}\\left[\\mathcal{B}_{i}^{*},\\{1,1+i\\}\\right] \\Phi\\left[\\{1,1+i\\},\\left\\{1,1+i^{\\prime}\\right\\}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{i^{\\prime}}^{*},\\left\\{1,1+i^{\\prime}\\right\\}\\right]\\right)^{\\top}$ has rank 2. By Sylvester's rank inequality, we have\n\n$$\n\\begin{aligned}\n& \\operatorname{rank}\\left(\\Lambda\\left[\\mathcal{B}_{i}^{*}, \\mathcal{F}_{i}\\right] \\Phi\\left[\\mathcal{F}_{i}, \\mathcal{F}_{i^{\\prime}}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{i^{\\prime}}^{*}, \\mathcal{F}_{i^{\\prime}}\\right]\\right)^{\\top}\\right) \\\\\n\\geqslant & \\operatorname{rank}\\left(\\left(\\Lambda\\left[\\mathcal{B}_{i}^{*}, \\mathcal{F}_{i}\\right]\\right)+\\operatorname{rank}\\left(\\Phi\\left[\\mathcal{F}_{i}, \\mathcal{F}_{i^{\\prime}}\\right]\\right)+\\operatorname{rank}\\left(\\Lambda\\left[\\mathcal{B}_{i^{\\prime}}^{*}, \\mathcal{F}_{i^{\\prime}}\\right]\\right)-\\left|\\mathcal{F}_{i}\\right|-\\left|\\mathcal{F}_{i^{\\prime}}\\right| .\n\\end{aligned}\n$$\n\nWe consider the following case\n\n1. $\\left|\\mathcal{F}_{i}\\right| \\leqslant\\left|\\mathcal{B}_{i}^{*}\\right|$ for all $1 \\leqslant i \\leqslant 4$. In this case, according to claim (G.5) and Condition 5, inequality (G.7)\n\nleads to\n\n$$\n\\operatorname{rank}\\left(\\Lambda\\left[\\mathcal{B}_{i}^{*}, \\mathcal{F}_{i}\\right] \\Phi\\left[\\mathcal{F}_{i}, \\mathcal{F}_{i^{\\prime}}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{i^{\\prime}}^{*}, \\mathcal{F}_{i^{\\prime}}\\right]\\right)^{\\top}\\right) \\geqslant \\min \\left(\\left|\\mathcal{F}_{i}\\right|,\\left|\\mathcal{F}_{i^{\\prime}}\\right|\\right)\n$$\n\nfor any $1 \\leqslant i \\neq i^{\\prime} \\leqslant 4$. We then have $\\min \\left(\\left|\\mathcal{F}_{i}\\right|,\\left|\\mathcal{F}_{i^{\\prime}}\\right|\\right)=2$. By applying this argument to all pairs $\\left(i, i^{\\prime}\\right)$, $1 \\leqslant i<i^{\\prime} \\leqslant 4$, we conclude that there exists at most one $\\mathcal{F}_{i}$ such that $\\left|\\mathcal{F}_{i}\\right| \\geqslant 3$ for $1 \\leqslant i \\leqslant 4$.\n\nIf there exists some $i$ such that $\\left|\\mathcal{F}_{i}\\right| \\geqslant 3$ for $i=1, \\ldots, 4$. Without loss of generality, we assume $\\left|\\mathcal{F}_{1}\\right| \\geqslant 3$ and $\\left|\\mathcal{F}_{i}\\right|=2$ for $i=2,3,4$. We claim that $\\left|\\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right|=3$, in other words, the variables belonging to $\\mathcal{B}_{2}^{*}$ and $\\mathcal{B}_{3}^{*}$ load on different factors. Otherwise, $\\left|\\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right|=2$. Consider the equation\n\n$$\n\\Sigma\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}\\right]=\\Sigma^{*}\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}\\right]\n$$\n\nwhich is equivalent to\n\n$$\n\\begin{aligned}\n& \\Lambda\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right] \\Phi\\left[\\mathcal{F}_{2} \\cup \\mathcal{F}_{3}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right]\\right)^{\\top}+\\Psi\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}\\right] \\\\\n= & \\Lambda^{*}\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*},\\{1,3,4\\}\\right] \\Phi^{*}\\left[\\{1,3,4\\},\\{1,3,4\\}\\right]\\left(\\Lambda^{*}\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*},\\{1,3,4\\}\\right]\\right)^{\\top}+\\Psi^{*}\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}\\right] .\n\\end{aligned}\n$$\n\nSince $\\Lambda^{*}$ satisfies Condition 6 , noticing that $\\left|\\mathcal{B}_{2}^{*}\\right| \\geqslant 4$ and $\\left|\\mathcal{B}_{3}^{*}\\right| \\geqslant 4$, it is easy to check that the matrix $\\Lambda^{*}\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*},\\{1,3,4\\}\\right]$ satisfies the condition for Theorem 5.1 of Anderson and Rubin (1956), that is, if any row of $\\Lambda^{*}\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*},\\{1,3,4\\}\\right]$ is deleted, there still remains two disjoint submatrices of $\\Lambda^{*}\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*},\\{1,3,4\\}\\right]$ with rank 3. By applying Theorem 5.1 of Anderson and Rubin (1956), we have $\\Psi\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}\\right]=\\Psi^{*}\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}\\right]$. Thus, we further have\n\n$$\n\\begin{gathered}\n\\Lambda\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right] \\Phi\\left[\\mathcal{F}_{2} \\cup \\mathcal{F}_{3}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right]\\right)^{\\top} \\\\\n=\\Lambda^{*}\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*},\\{1,3,4\\}\\right] \\Phi^{*}\\left[\\{1,3,4\\},\\{1,3,4\\}\\right]\\left(\\Lambda^{*}\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*},\\{1,3,4\\}\\right]\\right)^{\\top}\n\\end{gathered}\n$$\n\nIf $\\left|\\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right|=2$, then the rank of the matrix in the first line of (G.9) is 2 , which contradicts the fact that the rank of the matrix in the second line of (G.9) is 3 . Thus, $\\left|\\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right|=3$. We note that with a similar argument used in (G.8) and (G.9), we also have $\\left|\\mathcal{F}_{2} \\cup \\mathcal{F}_{4}\\right|=3,\\left|\\mathcal{F}_{3} \\cup \\mathcal{F}_{4}\\right|=3$ and $\\left|\\cup_{i=2,3,4} \\mathcal{F}_{i}\\right|=4$. Then, consider the equation\n\n$$\n\\Sigma\\left[\\mathcal{B}_{1}^{*}, \\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}\\right]=\\Sigma^{*}\\left[\\mathcal{B}_{1}^{*}, \\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}\\right]\n$$\n\nwhich is equivalent to\n\n$$\n\\begin{gathered}\n\\Lambda\\left[\\mathcal{B}_{1}^{*}, \\mathcal{F}_{1}\\right] \\Phi\\left[\\mathcal{F}_{1}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right)^{\\top}\\right. \\\\\n\\left.=\\Lambda^{*}\\left[\\mathcal{B}_{1}^{*},\\{1,2\\}\\right] \\Phi^{*}\\left[\\{1,2\\},\\{1,3,4\\}\\right]\\left(\\Lambda^{*}\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*},\\{1,3,4\\}\\right]\\right)^{\\top}\\right.\n\\end{gathered}\n$$\n\nWe note that the rank of the matrix in the second line of (G.10) is 2 . According to Sylvester's rank inequality\n\n$$\n\\begin{aligned}\n& \\operatorname{rank}\\left(\\Lambda\\left[\\mathcal{B}_{1}^{*}, \\mathcal{F}_{1}\\right] \\Phi\\left[\\mathcal{F}_{1}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right)^{\\top}\\right)\\right. \\\\\n& \\geqslant \\operatorname{rank}\\left(\\Lambda\\left[\\mathcal{B}_{1}^{*}, \\mathcal{F}_{1}\\right]\\right)+\\operatorname{rank}\\left(\\Phi\\left[\\mathcal{F}_{1}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right]\\right)+\\operatorname{rank}\\left(\\Lambda\\left[\\mathcal{B}_{2}^{*} \\cup \\mathcal{B}_{3}^{*}, \\mathcal{F}_{2} \\cup \\mathcal{F}_{3}\\right]\\right)-\\left|\\mathcal{F}_{1}\\right|-3 \\\\\n& =\\left|\\mathcal{F}_{1}\\right|+\\min \\left(\\left|\\mathcal{F}_{1}\\right|, 3\\right)+3-\\left|\\mathcal{F}_{1}\\right|-3 \\\\\n& =3\n\\end{aligned}\n$$\n\nwhich contradicts (G.10).\nThus, in the case, $\\left|\\mathcal{F}_{i}\\right|=2$ for $i=1, \\ldots, 4$. Consider the equation\n\n$$\n\\Sigma\\left[\\cup_{i=1, \\ldots, 4} \\mathcal{B}_{i}^{*}, \\cup_{i=1, \\ldots, 4} \\mathcal{B}_{i}^{*}\\right]=\\Sigma^{*}\\left[\\cup_{i=1, \\ldots, 4} \\mathcal{B}_{i}^{*}, \\cup_{i=1, \\ldots, 4} \\mathcal{B}_{i}^{*}\\right]\n$$\n\nBy the similar argument discussed in (G.8), (G.9) and further applying Theorem 1 to (G.11), we conclude that in this case, $\\Lambda\\left[\\cup_{i=1}^{4} \\mathcal{B}_{i}^{*},:\\right]$ and $\\Lambda^{*}\\left[\\cup_{i=1}^{4} \\mathcal{B}_{i}^{*},:\\right]$ has the same bi-factor structure. Without loss of generality, we further assume that $\\mathcal{F}_{i}=\\{1,1+i\\}$ for $i=1, \\ldots, 4$. Then, there exists some $5 \\times 5$ sign flip matrix $\\widetilde{D}$ such that $\\Lambda\\left[\\cup_{i=1}^{4} \\mathcal{B}_{i}^{*},\\{1, \\ldots, 5\\}\\right]=\\Lambda^{*}\\left[\\cup_{i=1}^{4} \\mathcal{B}_{i}^{*},\\{1, \\ldots, 5\\}\\right] \\widetilde{D}, \\Phi[\\{1, \\ldots, 5\\},\\{1, \\ldots, 5\\}]=$ $\\widetilde{D} \\Phi^{*}[\\{1, \\ldots, 5\\},\\{1, \\ldots, 5\\}] \\widetilde{D}$ and $\\psi_{j}=\\psi_{j}^{*}$ for $j \\in \\cup_{i=1}^{4} \\mathcal{B}_{i}^{*}$.\n2. There exists some $1 \\leqslant i \\leqslant 4$ such that $\\left|\\mathcal{F}_{i}\\right|=1+\\left|\\mathcal{B}_{i}^{*}\\right| \\geqslant 5$. In this case, according to (G.7)\n\n$$\n\\operatorname{rank}\\left(\\Lambda\\left[\\mathcal{B}_{i}^{*}, \\mathcal{F}_{i}\\right] \\Phi\\left[\\mathcal{F}_{i}, \\mathcal{F}_{i^{\\prime}}\\right]\\left(\\Lambda\\left[\\mathcal{B}_{i^{\\prime}}^{*}, \\mathcal{F}_{i^{\\prime}}\\right]\\right)^{\\top}\\right) \\geqslant 3 \\text { if }\\left|\\mathcal{F}_{i^{\\prime}}\\right| \\geqslant 4\n$$\n\nThus, $\\left|\\mathcal{F}_{i^{\\prime}}\\right| \\leqslant 3<\\left|\\mathcal{B}_{i^{\\prime}}^{*}\\right|$ for all $1 \\leqslant i^{\\prime} \\leqslant 4, i^{\\prime} \\neq i$. Without loss of generality, let $i=1$. For $i^{\\prime}=2,3,4$, by the same argument in case 1 , we have $\\mathcal{F}_{2}=\\left\\{1,1+g_{2}\\right\\}, \\mathcal{F}_{3}=\\left\\{1,1+g_{3}\\right\\}$ and $\\mathcal{F}_{4}=\\left\\{1,1+g_{4}\\right\\}$ for different $g_{2}, g_{3}$ and $g_{4}$. Moreover, $\\operatorname{rank}\\left(\\Lambda\\left[\\cup_{i=2,3,4} \\mathcal{B}_{i}^{*}, \\cup_{i=2,3,4} \\mathcal{F}_{i}\\right]\\right)=4$.\n\nThen, consider the equation $\\Sigma\\left[\\mathcal{B}_{1}^{*}, \\cup_{i=2,3,4} \\mathcal{B}_{i}^{*}\\right]=\\Sigma^{*}\\left[\\mathcal{B}_{1}^{*}, \\cup_{i=2,3,4} \\mathcal{B}_{i}^{*}\\right]$, which is equivalent to\n\n$$\n\\begin{gathered}\n\\Lambda\\left[\\mathcal{B}_{1}^{*}, \\mathcal{F}_{1}\\right] \\Phi\\left[\\mathcal{F}_{1}, \\cup_{i=2,3,4} \\mathcal{F}_{i}\\right]\\left(\\Lambda\\left[\\cup_{i=2,3,4} \\mathcal{B}_{i}^{*}, \\cup_{i=2,3,4} \\mathcal{F}_{i}\\right]\\right)^{\\top} \\\\\n=\\Lambda^{*}\\left[\\mathcal{B}_{1}^{*},\\{1,2\\}\\right] \\Phi^{*}\\left[\\{1,2\\},\\{1,3,4,5\\}\\right]\\left(\\Lambda\\left[\\cup_{i=2,3,4} \\mathcal{B}_{i}^{*},\\{1,3,4,5\\}\\right]\\right)^{\\top}\n\\end{gathered}\n$$\n\nIt is straightforward that $\\Lambda^{*}\\left[\\mathcal{B}_{1}^{*},\\{1,2\\}\\right] \\Phi^{*}[\\{1,2\\},\\{1,3,4,5\\}]\\left(\\Lambda\\left[\\cup_{i=2,3,4} \\mathcal{B}_{i}^{*},\\{1,3,4,5\\}\\right]\\right)^{\\top}$ has rank 2 according to Condition 5 and 6 . While, since $\\left|\\cup_{i=2,3,4} \\mathcal{F}_{i}\\right|=4<\\left|\\mathcal{F}_{1}\\right|$, according to Sylvester's rank inequality,\n\n$$\n\\begin{aligned}\n& \\operatorname{rank}\\left(\\Lambda\\left[\\mathcal{B}_{1}^{*}, \\mathcal{F}_{1}\\right] \\Phi\\left[\\mathcal{F}_{1}, \\cup_{i=2,3,4} \\mathcal{F}_{i}\\right]\\left(\\Lambda\\left[\\cup_{i=2,3,4} \\mathcal{B}_{i}^{*}, \\cup_{i=2,3,4} \\mathcal{F}_{i}\\right]\\right)^{\\top}\\right) \\\\\n& \\geqslant \\operatorname{rank}\\left(\\Lambda\\left[\\mathcal{B}_{1}^{*}, \\mathcal{F}_{1}\\right]\\right)+\\operatorname{rank}\\left(\\Phi\\left[\\mathcal{F}_{1}, \\cup_{i=2,3,4} \\mathcal{F}_{i}\\right]\\right)+\\operatorname{rank}\\left(\\Lambda\\left[\\cup_{i=2,3,4} \\mathcal{B}_{i}^{*}, \\cup_{i=2,3,4} \\mathcal{F}_{i}\\right]\\right)-\\left|\\mathcal{F}_{1}\\right|-4 \\\\\n& =\\left|\\mathcal{F}_{1}\\right|-1+4+4-\\left|\\mathcal{F}_{1}\\right|-4 \\\\\n& =3\n\\end{aligned}\n$$\n\nwhich contradicts to equation (G.12). Thus, this case does not exist.\nNext, we prove the second part. We denote by $\\mathcal{B}_{5}^{*}=\\left\\{j_{5}, j_{6}\\right\\}, \\mathcal{B}_{6}^{*}=\\left\\{j_{7}, j_{8}\\right\\}$ and $\\mathcal{B}_{7}^{*}=\\left\\{j_{9}, j_{10}\\right\\}$. Since $\\Lambda, \\Phi$ and $\\Psi$ satisfy Condition 4 , there exists three types of possible of bi-factor structure of $\\mathcal{B}_{5}, \\mathcal{B}_{6}$ and $\\mathcal{B}_{7}$ and we discuss the three cases one by one. Without loss of generality, we assume $D^{\\prime}$ given in the first part equals the identity matrix.\n\n1. None of the bi-factor structures of the variables belonging to $\\mathcal{B}_{i}^{*}, i=5,6,7$, is correct. Without loss of generality, we assume $\\mathcal{B}_{5}=\\left\\{j_{5}, j_{10}\\right\\}, \\mathcal{B}_{6}=\\left\\{j_{6}, j_{7}\\right\\}$ and $\\mathcal{B}_{7}=\\left\\{j_{8}, j_{9}\\right\\}$. In this case, we consider the equation\n\n$$\n\\Sigma\\left[\\mathcal{B}_{1}^{*}, \\mathcal{B}_{5}^{*}\\right]=\\Sigma^{*}\\left[\\mathcal{B}_{1}^{*}, \\mathcal{B}_{5}^{*}\\right]\n$$\n\nwhich is equivalent to\n\n$$\n\\begin{aligned}\n& \\Lambda\\left[\\mathcal{B}_{1}^{*},\\{1\\}\\right] \\lambda_{j_{5}, 1}+\\phi_{2,6} \\Lambda\\left[\\mathcal{B}_{1}^{*},\\{2\\}\\right] \\lambda_{j_{5}, 6}=\\Lambda^{*}\\left[\\mathcal{B}_{1}^{*},\\{1\\}\\right] \\lambda_{j_{5}, 1}^{*}+\\phi_{2,6}^{*} \\Lambda^{*}\\left[\\mathcal{B}_{1}^{*},\\{2\\}\\right] \\lambda_{j_{5}, 6}^{*} \\\\\n& \\Lambda\\left[\\mathcal{B}_{1}^{*},\\{1\\}\\right] \\lambda_{j_{6}, 1}+\\phi_{2,7} \\Lambda\\left[\\mathcal{B}_{1}^{*},\\{2\\}\\right] \\lambda_{j_{6}, 7}=\\Lambda^{*}\\left[\\mathcal{B}_{1}^{*},\\{1\\}\\right] \\lambda_{j_{6}, 1}^{*}+\\phi_{2,6}^{*} \\Lambda^{*}\\left[\\mathcal{B}_{1}^{*},\\{2\\}\\right] \\lambda_{j_{6}, 6}^{*}\n\\end{aligned}\n$$\n\nSince the first part is proved, we have assumed that $\\Lambda\\left[\\mathcal{B}_{1}^{*},\\{1\\}\\right]=\\Lambda^{*}\\left[\\mathcal{B}_{1}^{*},\\{1\\}\\right]$ and $\\Lambda\\left[\\mathcal{B}_{1}^{*},\\{2\\}\\right]=$ $\\Lambda^{*}\\left[\\mathcal{B}_{1}^{*},\\{2\\}\\right]$. Noticing that $\\Lambda^{*}\\left[\\mathcal{B}_{1}^{*},\\{1\\}\\right]$ and $\\Lambda^{*}\\left[\\mathcal{B}_{1}^{*},\\{2\\}\\right]$ are linearly independent, we have $\\lambda_{j_{5}, 1}=\\lambda_{j_{5}, 1}^{*}$ and $\\lambda_{j_{6}, 1}=\\lambda_{j_{6}, 1}^{*}$. Similarly, by considering the equations $\\Sigma\\left[\\mathcal{B}_{1}^{*}, \\mathcal{B}_{6}^{*}\\right]=\\Sigma^{*}\\left[\\mathcal{B}_{1}^{*}, \\mathcal{B}_{6}^{*}\\right]$ and $\\Sigma\\left[\\mathcal{B}_{1}^{*}, \\mathcal{B}_{7}^{*}\\right]=$ $\\Sigma^{*}\\left[\\mathcal{B}_{1}^{*}, \\mathcal{B}_{7}^{*}\\right]$, we have $\\lambda_{j_{7}, 1}=\\lambda_{j_{7}, 1}^{*}, \\lambda_{j_{8}, 1}=\\lambda_{j_{8}, 1}^{*}, \\lambda_{j_{9}, 1}=\\lambda_{j_{9}, 1}^{*}$ and $\\lambda_{j_{10}, 1}=\\lambda_{j_{10}, 1}^{*}$.\n\nBy considering the equation\n\n$$\n\\Sigma\\left[j_{5}, j_{6}\\right]=\\Sigma^{*}\\left[j_{5}, j_{6}\\right]\n$$\n\nwhich is equivalent to $\\lambda_{j_{5}, 1} \\lambda_{j_{6}, 1}+\\phi_{6,7} \\lambda_{j_{5}, 6} \\lambda_{j_{6}, 7}=\\lambda_{j_{5}, 1}^{*} \\lambda_{j_{6}, 1}^{*}+\\lambda_{j_{5}, 6}^{*} \\lambda_{j_{6}, 6}^{*}$. We further have\n\n$$\n\\phi_{6,7} \\lambda_{j_{5}, 6} \\lambda_{j_{6}, 7}=\\lambda_{j_{5}, 6}^{*} \\lambda_{j_{6}, 6}^{*}\n$$\n\nWe can similarly have the equations\n\n$$\n\\begin{aligned}\n\\phi_{6,7} \\lambda_{j_{5}, 6} \\lambda_{j_{7}, 7} & =\\phi_{6,7}^{*} \\lambda_{j_{5}, 6}^{*} \\lambda_{j_{7}, 7}^{*} \\\\\n\\phi_{6,7} \\lambda_{j_{10}, 6} \\lambda_{j_{6}, 7} & =\\phi_{6,8}^{*} \\lambda_{j_{10}, 8}^{*} \\lambda_{j_{6}, 6}^{*} \\\\\n\\phi_{6,7} \\lambda_{j_{10}, 6} \\lambda_{j_{7}, 8} & =\\phi_{7,8}^{*} \\lambda_{j_{10}, 8}^{*} \\lambda_{j_{7}, 7}^{*}\n\\end{aligned}\n$$\n\nBy combining the equations (G.13) and (G.14), we have $\\phi_{6,7}^{*} \\phi_{6,8}^{*}=\\phi_{7,8}^{*}$. In a symmetric manner, we further have $\\phi_{6,8}^{*} \\phi_{7,8}^{*}=\\phi_{6,7}^{*}$ and $\\phi_{6,7}^{*} \\phi_{7,8}^{*}=\\phi_{6,8}^{*}$. Since $\\phi_{6,7}^{*}, \\phi_{6,8}^{*}$ and $\\phi_{7,8}^{*} \\neq 0$, we have $\\left|\\phi_{6,7}^{*} \\phi_{6,8}^{*} \\phi_{7,8}^{*}\\right|=$ 1 , which leads to $\\left|\\phi_{6,7}^{*}\\right|=\\left|\\phi_{6,8}^{*}\\right|=\\left|\\phi_{7,8}^{*}\\right|=1$ and violates the assumption that $\\Phi^{*}$ is positive definite. Thus, this case does not exist.\n2. Only one of the bi-factor structures of the variables belonging to $\\mathcal{B}_{i}^{*}, i=5,6,7$, is correct. Without loss of generality, we assume $\\mathcal{B}_{5}=\\left\\{j_{5}, j_{6}\\right\\}, \\mathcal{B}_{6}=\\left\\{j_{7}, j_{9}\\right\\}$ and $\\mathcal{B}_{7}=\\left\\{j_{8}, j_{10}\\right\\}$. By the same argument in the first case, we have $\\lambda_{j_{i}, 1}=\\lambda_{j_{i}, 1}^{*}$ for $i=5, \\ldots, 10$. Next, consider the equations on the diagonal entries of\n\n$$\n\\Sigma\\left[\\mathcal{B}_{6}^{*} \\cup \\mathcal{B}_{7}^{*}, \\mathcal{B}_{6}^{*} \\cup \\mathcal{B}_{7}^{*}\\right]=\\Sigma^{*}\\left[\\mathcal{B}_{6}^{*} \\cup \\mathcal{B}_{7}^{*}, \\mathcal{B}_{6}^{*} \\cup \\mathcal{B}_{7}^{*}\\right]\n$$\n\nwe have the following 6 equations\n\n$$\n\\begin{aligned}\n& \\phi_{7,8} \\lambda_{j_{7}, 7} \\lambda_{j_{8}, 8}=\\lambda_{j_{7}, 7}^{*} \\lambda_{j_{8}, 7}^{*} \\\\\n& \\lambda_{j_{7}, 7} \\lambda_{j_{9}, 7}=\\phi_{7,8}^{*} \\lambda_{j_{7}, 7}^{*} \\lambda_{j_{9}, 8}^{*} \\\\\n& \\phi_{7,8} \\lambda_{j_{7}, 7} \\lambda_{j_{10}, 8}=\\phi_{7,8}^{*} \\lambda_{j_{7}, 7}^{*} \\lambda_{j_{10}, 8}^{*} \\\\\n& \\phi_{7,8} \\lambda_{j_{8}, 8} \\lambda_{j_{9}, 7}=\\phi_{7,8}^{*} \\lambda_{j_{8}, 7}^{*} \\lambda_{j_{9}, 8}^{*} \\\\\n& \\lambda_{j_{8}, 8} \\lambda_{j_{10}, 8}=\\phi_{7,8}^{*} \\lambda_{j_{8}, 7}^{*} \\lambda_{j_{10}, 8}^{*} \\\\\n& \\phi_{7,8} \\lambda_{j_{9}, 7} \\lambda_{j_{10}, 8}=\\lambda_{j_{9}, 8}^{*} \\lambda_{j_{10}, 8}^{*}\n\\end{aligned}\n$$\n\nAccording to the first equation above, we have $\\phi_{7,8} \\neq 0$. By the 6 equations, we also have $\\left(\\phi_{7,8}^{*}\\right)^{4} \\phi_{7,8}^{4}=$ $\\phi_{7,8}^{2}$. Then we have $\\left|\\phi_{7,8}^{*}\\right|=\\left|\\phi_{7,8}\\right|=1$, which violates the assumption that $\\Phi^{*}$ is positive definite. Thus, this case does not exist.\n3. The bi-factor structure is correct. Without loss of generality, we assume $\\mathcal{B}_{5}=\\left\\{j_{5}, j_{6}\\right\\}, \\mathcal{B}_{6}=\\left\\{j_{7}, j_{8}\\right\\}$ and $\\mathcal{B}_{7}=\\left\\{j_{9}, j_{10}\\right\\}$. Similar to the previous argument, we first have $\\lambda_{j_{i}, 1}=\\lambda_{j_{i}, 1}^{*}$ for $i=5, \\ldots, 10$. Moreover, we have $\\phi_{2,6} \\lambda_{5,6}=\\phi_{2,6}^{*} \\lambda_{5,6}^{*}, \\phi_{2,6} \\lambda_{6,6}=\\phi_{2,6}^{*} \\lambda_{6,6}^{*}$ and $\\lambda_{5,6} \\lambda_{6,6}=\\lambda_{5,6}^{*} \\lambda_{6,6}^{*}$. These 3 equations leads to $\\phi_{2,6}=\\phi_{2,6}^{*}, \\lambda_{5,6}=\\lambda_{5,6}^{*}$ and $\\lambda_{6,6}=\\lambda_{6,6}^{*}$ or $\\phi_{2,6}=-\\phi_{2,6}^{*}, \\lambda_{5,6}=-\\lambda_{5,6}^{*}$ and $\\lambda_{6,6}=-\\lambda_{6,6}^{*}$. With the same argument, the loadings and correlations related with the variables belonging to $\\mathcal{B}_{6}^{*}$ and $\\mathcal{B}_{7}^{*}$\n\nare also determined up to a sign flip. The check of $\\psi_{j}=\\psi_{j}^{*}$ for $j \\in \\mathcal{B}_{i}^{*}, i=5,6,7$ are straight forward.", "tables": {}, "images": {}}, {"section_id": 19, "text": "# References \n\nAlfonzetti, G., Bellio, R., Chen, Y., and Moustaki, I. (2024). Pairwise stochastic approximation for confirmatory factor analysis of categorical data. British Journal of Mathematical and Statistical Psychology.\n\nAnderson, T. and Rubin, H. (1956). Statistical inference in factor analysis. In Proceedings of the Berkeley Symposium on Mathematical Statistics and Probability, page 111. University of California Press.\n\nBernaards, C. A. and Jennrich, R. I. (2005). Gradient projection algorithms and software for arbitrary rotation criteria in factor analysis. Educational and psychological measurement, 65(5):676-696.\n\nBertsekas, D. P. (2014). Constrained optimization and Lagrange multiplier methods. Academic press.\n\nBock, R. D. and Aitkin, M. (1981). Marginal maximum likelihood estimation of item parameters: Application of an em algorithm. Psychometrika, 46(4):443-459.\n\nBradlow, E. T., Wainer, H., and Wang, X. (1999). A bayesian random effects model for testlets. Psychometrika, 64:153-168.\n\nBrowne, M. W. (2001). An overview of analytic rotation in exploratory factor analysis. Multivariate Behavioral Research, 36:111-150.\n\nBrunner, M., Nagy, G., and Wilhelm, O. (2012). A tutorial on hierarchically structured constructs. Journal of Personality, 80(4):796-846.\n\nCai, L., Choi, K., Hansen, M., and Harrell, L. (2016). Item response theory. Annual Review of Statistics and Its Application, 3(1):297-321.\n\nCai, L., Yang, J. S., and Hansen, M. (2011). Generalized full-information item bifactor analysis. Psychological methods, 16(3):221.\n\nChen, F. F., Hayes, A., Carver, C. S., Laurenceau, J.-P., and Zhang, Z. (2012). Modeling general and specific variance in multifaceted constructs: A comparison of the bifactor model to other approaches. Journal of Personality, 80(1):219-251.\n\nChen, Y., Moustaki, I., and Zhang, S. (2023). On the estimation of structural equation models with latent variables. Handbook of structural equation modeling, pages 145-162.\n\nCrawford, C. B. and Ferguson, G. A. (1970). A general rotation criterion and its use in orthogonal rotation. Psychometrika, 35(3):321-332.\n\nDeMars, C. E. (2006). Application of the bi-factor multidimensional item response theory model to testletbased tests. Journal of Educational Measurement, 43(2):145-168.\n\nDeMars, C. E. (2012). Confirming testlet effects. Applied Psychological Measurement, 36(2):104-121.\n\nDempster, A. P., Laird, N. M., and Rubin, D. B. (1977). Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society: Series B (Methodological), 39(1):1-22.\n\nFang, G., Guo, J., Xu, X., Ying, Z., and Zhang, S. (2021). Identifiability of bifactor models. Statistica Sinica, 31:2309-2330.\n\nGibbons, R. D., Bock, R. D., Hedeker, D., Weiss, D. J., Segawa, E., Bhaumik, D. K., Kupfer, D. J., Frank, E., Grochocinski, V. J., and Stover, A. (2007). Full-information item bifactor analysis of graded response data. Applied Psychological Measurement, 31(1):4-19.\n\nGibbons, R. D. and Hedeker, D. R. (1992). Full-information item bi-factor analysis. Psychometrika, $57(3): 423-436$.\n\nGibbons, R. D., Rush, A. J., and Immekus, J. C. (2009). On the psychometric validity of the domains of the pdsq: An illustration of the bi-factor item response theory model. Journal of Psychiatric Research, $43(4): 401-410$.\n\nGignac, G. E. and Watkins, M. W. (2013). Bifactor modeling and the estimation of model-based reliability in the wais-iv. Multivariate Behavioral Research, 48(5):639-662.\n\nHolzinger, K. J. and Swineford, F. (1937). The bi-factor method. Psychometrika, 2(1):41-54.\n\nJennrich, R. I. (2004). Rotation to simple loadings using component loss functions: The orthogonal case. Psychometrika, 69:257-273.\n\nJennrich, R. I. (2006). Rotation to simple loadings using component loss functions: The oblique case. Psychometrika, 71:173-191.\n\nJennrich, R. I. and Bentler, P. M. (2011). Exploratory bi-factor analysis. Psychometrika, 76:537-549.\n\nJennrich, R. I. and Bentler, P. M. (2012). Exploratory bi-factor analysis: The oblique case. Psychometrika, $77(3): 442-454$.\n\nJennrich, R. I. and Sampson, P. (1966). Rotation for simple loadings. Psychometrika, 31(3):313-323.\n\nJeon, M., Rijmen, F., and Rabe-Hesketh, S. (2013). Modeling differential item functioning using a generalization of the multiple-group bifactor model. Journal of Educational and Behavioral Statistics, 38(1):32-60.\n\nJohnson, J. A. (2014). Measuring thirty facets of the five factor model with a 120 -item public domain inventory: Development of the ipip-neo-120. Journal of Research in Personality, 51:78-89.\n\nKaiser, H. F. (1958). The varimax criterion for analytic rotation in factor analysis. Psychometrika, 23(3):187200 .\n\nLiu, X., Wallin, G., Chen, Y., and Moustaki, I. (2023). Rotation to sparse loadings using $l^{p}$ losses and related inference problems. Psychometrika, 88(2):527-553.\n\nMcCammon, R. B. (1966). Principal component analysis and its application in large-scale correlation studies. The Journal of Geology, 74(5, Part 2):721-733.\n\nMcKeon, J. (1968). Rotation for maximum association between factors and tests. Unpublished manuscript, Biometric Laboratory, George Washington University.\n\nNocedal, J. and Wright, S. J. (1999). Numerical optimization. Springer.\n\nOka, M., Chen, Y., and Mounstaki, I. (2024). Learning high-dimensional latent variable models via doubly stochastic optimisation by unadjusted langevin. arXiv preprint arXiv:2406.09311.\n\nReise, S. P., Morizot, J., and Hays, R. D. (2007). The role of the bifactor model in resolving dimensionality issues in health outcomes measures. Quality of Life Research, 16:19-31.\n\nRijmen, F. (2010). Formal relations and an empirical comparison among the bi-factor, the testlet, and a second-order multidimensional irt model. Journal of Educational Measurement, 47(3):361-372.\n\nSchmid, J. and Leiman, J. M. (1957). The development of hierarchical factor solutions. Psychometrika, $22(1): 53-61$.\n\nSchwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics, 6(2):461-464.\n\nStan Development Team (2022). The stan core library. Version 2.33.\n\nThurstone, L. L. (1947). Multiple Factor Analysis. University of Chicago Press, Chicago.\n\nYates, A. (1987). Multivariate exploratory data analysis: A perspective on exploratory factor analysis. State University of New York Press.\n\nYung, Y.-F., Thissen, D., and McLeod, L. D. (1999). On the relationship between the higher-order factor model and the hierarchical factor model. Psychometrika, 64:113-128.\n\nZhang, S. and Chen, Y. (2022). Computation for latent variable model estimation: A unified stochastic proximal framework. Psychometrika, 87(4):1473-1502.", "tables": {}, "images": {}}], "id": "2409.00679v2", "authors": ["Jiawei Qiao", "Yunxiao Chen", "Zhiliang Ying"], "categories": ["stat.ME", "math.ST", "stat.TH"], "abstract": "Bi-factor analysis is a form of confirmatory factor analysis widely used in\npsychological and educational measurement. The use of a bi-factor model\nrequires the specification of an explicit bi-factor structure on the\nrelationship between the observed variables and the group factors. In practice,\nthe bi-factor structure is sometimes unknown, in which case an exploratory form\nof bi-factor analysis is needed to find the bi-factor structure. Unfortunately,\nthere are few methods for exploratory bi-factor analysis, with the exception of\na rotation-based method proposed in Jennrich and Bentler (2011, 2012). However,\nthis method only finds approximate bi-factor structures, as it does not yield\nan exact bi-factor loading structure, even after applying hard thresholding. In\nthis paper, we propose a constraint-based optimisation method that learns an\nexact bi-factor loading structure from data, overcoming the issue with the\nrotation-based method. The key to the proposed method is a mathematical\ncharacterisation of the bi-factor loading structure as a set of equality\nconstraints, which allows us to formulate the exploratory bi-factor analysis\nproblem as a constrained optimisation problem in a continuous domain and solve\nthe optimisation problem with an augmented Lagrangian method. The power of the\nproposed method is shown via simulation studies and a real data example.\nExtending the proposed method to exploratory hierarchical factor analysis is\nalso discussed. The codes are available on\n``https://anonymous.4open.science/r/Bifactor-ALM-method-757D\".", "updated": "2025-04-11T23:56:24Z", "published": "2024-09-01T09:44:37Z"}