{"title": "Sampling permutations satisfying constraints within the lopsided local\n  lemma regime", "sections": [{"section_id": 0, "text": "#### Abstract\n\nSampling a random permutation with restricted positions, or equivalently approximating the permanent of a $0-1$ matrix, is a fundamental problem in computer science, with several notable results achieved over the years. However, existing algorithms typically exhibit high computational complexity. Achieving the optimal running time remains elusive, even for nontrivial subsets of the problem. Furthermore, existing algorithms primarily focus on a single permutation, leaving many combinatorial problems involving multiple constrained permutations unaddressed.\n\nFor a single permutation, we achieve the optimal running time $O\\left(n^{2}\\right)$ for approximating the permanent of a very dense $n \\times n 0-1$ matrix, where each row and column contains at most $\\sqrt{(n-2) / 20}$ zeros. This result serves as a fundamental building block in our sampling algorithm for multiple permutations.\n\nWe further introduce a general model called permutations with disjunctive constraints (PDC) for handling multiple constrained permutations. We propose a novel Markov chain-based algorithm for sampling nearly uniform solutions of PDC within a lopsided Lov\u00e1sz Local Lemma (LLL) regime. For uniform PDC formulas, where all constraints are of the same width and all permutations are of the same size, our algorithm runs in nearly linear time with respect to the number of variables.\n\nPrevious approaches for sampling LLL relied on the variable model, where the underlying probability space is a product space. In contrast, the sampling problem of PDC encounters a fundamental challenge: the random variables within each permutation in the joint probability space are not mutually independent, leading to long-range correlations that previous factorization techniques cannot cut down. To tackle this challenge, we introduce a novel sampling framework called correlated factorization and a new concept in the path coupling analysis, termed the inactive vertex. As a result, a sampling LLL beyond the variable model is established.", "tables": {}, "images": {}}, {"section_id": 1, "text": "## Contents\n\n1. Introduction ..... 1\n2. Technical overview ..... 5\n3. Preliminaries ..... 8\n4. Results on a single permutation ..... 12\n5. Structure-preserved state compression ..... 15\n6. Sampling algorithm with state compression ..... 17\n7. Analysis of the sample subroutine ..... 24\n8. Rapid mixing of the idealized permutation-wise Glauber dynamics ..... 28\n9. Analysis of the main algorithm ..... 39\n10. Applications ..... 42\nAcknowledgement ..... 43\nReferences ..... 43\nAppendix A. Missing proofs in section 3 ..... 46\nAppendix B. Missing proofs in section 5 ..... 47\nAppendix C. Missing proofs in section 6 ..... 48\nAppendix D. Missing proofs in section 8 ..... 50\nAppendix E. Missing proofs in section 9 ..... 74", "tables": {}, "images": {}}, {"section_id": 2, "text": "# 1. Introduction \n\nGiven a positive integer $n$, sampling all the permutations of $[n]$ uniformly at random is one of the most fundamental problems in probability theory. This problem, usually known as card shuffling for mathematicians, has a long history [RMB84], and has led to numerous profound results [Ald83, AD86, Dia88, BD92]. Compared to the original card shuffling problem, which involves no specific constraints on the permutations, the sampling of permutations that satisfy various constraints has also attracted significant attention in the fields of probability, statistics, and computer science. Numerous important problems can be viewed as specialized instances of the problem of sampling permutations with constraints. The following are some well-studied examples:\n\n- sampling permutations with restricted positions. An instance of permutations with restricted positions (PRP) includes a positive integer $n$ and a collection of sets $R_{1}, R_{2}, \\ldots, R_{n} \\subseteq[n]$. The sampling of PRP is the problem of sampling permutations of $[n]$ uniformly at random from $\\prod_{i \\in[n]} R_{i}$.\n- sampling perfect matchings of a bipartite graph. Given a bipartite graph with $n$ vertices in each of the two partitions, a perfect matching is a subset of edges such that each vertex is adjacent to exactly one edge.\n- approximating the permanent of a 0-1 matrix. Given a $0-1$ square matrix $A=\\left(a_{i, j}\\right)_{n \\times n}$ where $a_{i, j} \\in\\{0,1\\}$ for any $i, j \\in[n]$, the permanent of $A$ is defined as\n\n$$\n\\operatorname{per}(A) \\triangleq \\sum_{\\sigma} \\prod_{i \\in[n]} a_{i, \\sigma(i)}\n$$\n\nwhere the sum is over all permutations $\\sigma$ of $[n]$. Computing the permanent of a matrix is one of the first problems shown to be \\#P-complete [Val79], even if the matrix is a 0-1 matrix where the row and column sums are at least $n / 2$. By the self-reducibility property of the problem [JVV86], any polynomial time algorithm for generating a random permutation $\\sigma$ where $\\prod_{i \\in[n]} a_{i, \\sigma(i)} \\neq 0$ can be used to efficiently approximate $\\operatorname{per}(A)$.\nThe equivalence of these three problems is well-known in the literature.\nSeveral effective algorithms have been introduced for both sampling PRP and approximating the permanent of a 0-1 matrix. Broder [Bro86] initially devised a Markov chain method based on switching for PRP sampling and permanent approximation. He also proved that, even for $\\gamma$-dense $0-1$ matrices where the row and column sums are at least $\\gamma n$ with a fixed $\\gamma \\in(0,1)$, calculating the permanent exactly remains \\#P-hard. Later, Jerrum and Sinclair demonstrated that Broder's Markov chain operates in $O\\left(n^{8} \\log n\\right)$ time for $1 / 2$-dense matrices [JS89]. Jerrum, Sinclair, and Vigoda introduced another Markov chain where the parameters were fine-tuned to approach the target distribution [JSV04]. This innovation led to an algorithm capable of approximating the permanent in $O\\left(n^{10}(\\log n)^{3}\\right)$ time, establishing the first fully polynomial randomized approximation scheme (FPRAS) for the permanent of matrices with nonnegative entries. Bez\u00e1kov\u00e1 et al. later enhanced this time complexity to $O\\left(n^{7}(\\log n)^{4}\\right)$ [BSVV08]. For $\\gamma$-dense cases where $\\gamma>1 / 2$, Huber and Law introduced a more refined sampling algorithm for PRPs with running time $O\\left(n^{4} \\log n+n^{2+(1-\\gamma) /(2 \\gamma-1)}\\right)$ [HL08].\n\nBeyond single permutations with restricted positions, many combinatorial problems can be modeled as multiple permutations with constraints. Examples include Latin squares [KD15], independent transversals and perfect matchings in multipartite hypergraphs [EGL94, AGS09], the strong chromatic number [HS17], and hypergraph packing [LS07]. There are few results on sampling multiple permutations with constraints, and all are limited to specific problems. McKay and Wormald developed an algorithm based on \"switchings\" to generate random Latin rectangles [MW91]. Cooper, Dyer, and Handley introduced the first rigorous polynomial mixing-time bound, $O\\left(n^{10} \\log n\\right)$, for natural Markov chains that sample discordant permutations and Latin rectangles [CDH11].\n\nMultiple permutations satisfying given constraints can be captured within the framework of constraint satisfaction problems (CSP). Formally, given any positive integer $m$, an instance of CSP on $m$ permutations is denoted by $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$, where $(\\mathcal{P}, \\mathcal{Q})$ specifies the permutations and $\\mathcal{C}$ specifies the constraints. In this setup, $\\mathcal{P}=\\left(P_{1}, \\ldots, P_{m}\\right)$ is a list of variable sets, with $P_{1}, \\ldots, P_{m}$ being disjoint sets. Similarly, $\\mathcal{Q}=\\left(Q_{1}, \\ldots, Q_{m}\\right)$ is a list of sets of numbers, where each $Q_{i}$ has the same size as its corresponding $P_{i}$.\n\nIntuitively, $P_{i}$ represents the variables in one permutation, and $Q_{i}$ is the set of values those variables can take. An assignment of values to all the variables in $V \\triangleq P_{1} \\cup \\cdots \\cup P_{m}$ is called valid if, for each $i$, the values assigned to the variables in $P_{i}$ form a permutation of the values in $Q_{i}$. The constraints $\\mathcal{C}$ define the conditions that any valid assignment must satisfy. Specifically, we focus on disjunctive constraints as in SAT, where each constraint $C \\in \\mathcal{C}$ has the form $\\left(v_{1} \\neq c_{1}\\right) \\vee \\cdots \\vee\\left(v_{f} \\neq c_{f}\\right)$, with $\\ell>0$; here, each $v_{i}$ is a variable and $c_{i}$ is a value it can take. A satisfying assignment for $\\Phi$ is a valid one that meets all the constraints in $\\mathcal{C}$. Two constraints $C=\\cdots \\vee(v \\neq c) \\vee \\cdots$ and $C^{\\prime}=\\cdots \\vee\\left(v^{\\prime} \\neq c^{\\prime}\\right) \\vee \\cdots$ are called related (denoted as $C \\sim C^{\\prime}$ ) if either $v=v^{\\prime}$, or $v$ and $v^{\\prime}$ belong to the same set $P_{i}$ and $c=c^{\\prime}$. In the context of the lopsided Lov\u00e1sz Local Lemma (LLL), this relation reflects a negative dependence between the events of $C$ and $C^{\\prime}$ being violated [HS17]. In this paper, we focus on a formula $\\Phi$ for permutations with disjunctive constraints (PDC) and the following are key parameters of $\\Phi$ :\n\n- width $k=k_{\\Phi} \\triangleq \\max _{C \\in \\mathcal{C}}|\\mathrm{vbl}(C)|$ where $\\mathrm{vbl}(C)$ denotes the set of variables used by $C$;\n- variable degree $d=d_{\\Phi} \\triangleq \\max _{v \\in V}\\left|\\left\\{C \\in \\mathcal{C} \\mid v \\in \\mathrm{vbl}(C)\\right\\}\\right|$;\n- constraint degree $\\Delta=\\Delta_{\\Phi} \\triangleq \\max _{C \\in \\mathcal{C}}\\left|\\left\\{C^{\\prime} \\in \\mathcal{C} \\mid C^{\\prime} \\sim C\\right\\}\\right| ;{ }^{1}$\n- minimal permutation set size $q=q_{\\Phi} \\triangleq \\min _{P \\in \\mathcal{P}}|P|$;\n- violation probability $p=p_{\\Phi}=\\max _{C \\in \\mathcal{C}} \\mathbb{P}[\\neg C]$, where $\\mathbb{P} \\triangleq \\mathbb{P}_{\\Phi}$ denotes the uniform distribution over all valid assignments, and $\\neg C$ denotes the event that $C$ is violated.\nCurrently, no effective algorithm is available for sampling PDC.\n1.1. Sampling LLL. Uniformly sampling a random solution that satisfies a set of constraints has garnered significant attention in recent years. The Lov\u00e1sz Local Lemma (LLL) is a powerful tool for sampling constraint-satisfying solutions, demonstrating the feasibility of avoiding all \"bad\" events under certain weak dependency conditions [EL75]. It has been shown that CSP sampling is tractable only within an LLL-like regime $p \\Delta^{2} \\gtrsim 1$, where $\\gtrsim$ disregards lower-order terms and constant factors [BGG*19, GGW23]. Efficient algorithms for near-uniform sampling of solutions in this regime are collectively known in the literature as the sampling LLL. Recent progress in this field is notable [GJL19, Moi19, GLLZ19, GGGY20, Har20, FGYZ21, FHY21, JPV21a, JPV21b, HSW21, GGW21, FGW22, HWY22, HWY23, WY24]. Prior approaches to the sampling LLL are based on product probability spaces defined by sets of mutually independent random variables, commonly known as the variable model [MT10, HLL*17]. However, the sampling problem for PDC extends beyond this variable model. In PDC, the underlying probability space is a joint space in which the random variables associated with each permutation are not mutually independent. This inherent dependency among variables makes PDC sampling particularly challenging.\n\nTo understand the technical barrier in the sampling of PDC, let's examine the sampling of PRP, a specific case of PDC involving a single permutation. Existing fast algorithms for the sampling LLL leverage formula factorization. Given a CSP instance $\\Phi$, if a subset of $\\Phi$ 's variables is correctly assigned, a proportion of the constraints will be satisfied. By removing all satisfied constraints, the remaining CSP can be factorized into disjoint sub-formulas of logarithmic size, making sampling on the reduced formula straightforward. However, this approach does not apply to PRP. A PRP cannot be factorized into smaller instances even if most constraints are satisfied, as its variables must collectively form a single permutation. Similarly, for PDC formulas involving multiple permutations, the techniques used in the sampling LLL also fail due to the interdependence of the large permutations.\n\nTo characterize the joint probability space of PDC, a more suitable tool is the lopsided LLL [ES91], which can yield improved bounds on PDC formulas compared to the standard LLL. The lopsided LLL is a variant of the LLL that applies to lopsidependent \"bad\" events exhibiting negative correlation. Specifically, given a collection $\\mathcal{B}$ of bad events in a probability space, for any event $A$ defined on that space and any subset $S \\subseteq \\mathcal{B}$, we say that $A$ is non-lopsidependent with respect to $S$ if\n\n$$\n\\operatorname{Pr}\\left[A \\mid \\bigwedge_{B \\in S} \\bar{B}\\right] \\leq \\operatorname{Pr}[A]\n$$\n\n[^0]\n[^0]:    ${ }^{\\mathrm{I}}$ The constraint degree $\\Delta$ should be distinguished from the lopsidependency degree $D$, which is the maximum degree of the lopsidependency graph: $D \\triangleq \\max _{C \\in \\mathcal{C}}\\left|\\left\\{C^{\\prime} \\in \\mathcal{C} \\backslash\\{C\\} \\mid C \\sim C^{\\prime}\\right\\}\\right|$. Note that $\\Delta=D+1$.\n\nIn other words, the events in $S$ are either independent of or positively correlated with $A$. Furthermore, the lopsidependency among events can be represented by the lopsidependency graph, an undirected graph $G=(\\mathcal{B}, E)$ that satisfies the following property: for any $B \\in \\mathcal{B}$ and any subset $S \\subseteq \\mathcal{B} \\backslash\\{\\Gamma(B) \\cup\\{B\\}\\}$, where $\\Gamma(B)$ denotes the neighbors of $B$ in $G$, the event $B$ is non-lopsidependent with respect to $S$. The lopsided LLL then provides a condition ensuring that the probability of none of the events in $\\mathcal{B}$ occurring is positive (see Theorem 3.1). As a fundamental tool in probabilistic combinatorics, the lopsided LLL underpins a wide range of applications [ES91, HS14]. However, research within this framework has so far been limited to existential and constructive results, leaving a significant gap: sampling algorithms tailored to the lopsided LLL condition remain elusive. The design of a PDC sampling algorithm can offer critical insights into developing sampling algorithms in the lopsided LLL context. Such a breakthrough would not only address this long-standing deficiency but also pave the way for a wealth of new techniques, greatly advancing the sampling applications based on the lopsided LLL.\n\nIn summary, two related problems in the sampling of constrained permutations need to be addressed:\n\n- Optimal algorithm for the sampling of permutations with constraints. Current sampling algorithms primarily rely on the Markov chain method. To establish rapid mixing of these Markov chains, the canonical path approach is often used, but this tends to yield loose bounds on running time. The current best algorithm for approximating the permanent has a running time of $O\\left(n^{7}(\\log n)^{4}\\right)$ [BSVV08]. Even for $\\gamma$-dense PRPs, the novel rejection sampling algorithm requires $O\\left(n^{4} \\log n+n^{2+(1-\\gamma) /(2 \\gamma-1)}\\right)$ [HL08]. The running times of these algorithms remain far from optimal. Developing optimal-time sampling algorithms for even a nontrivial subset of the problem would be highly significant, as it could offer valuable insights into the strategies that an optimal algorithm should employ.\n- Efficient algorithm for the sampling of multiple permutations. Existing sampling algorithms for multiple permutations with constraints are limited to specific problems, and no efficient sampling algorithm currently exists for the general PDC model, which captures a wide range of important combinatorial problems. Developing an efficient sampling algorithm for PDC would address the sampling challenges of these combinatorial objects by providing a robust method for sampling permutations with complex constraints. Furthermore, such an algorithm would represent a crucial step in extending the sampling LLL from the standard LLL condition to the more general lopsided LLL, thereby broadening the scope of sampling techniques to accommodate intricate dependency structures. Consequently, an efficient sampling algorithm for PDC remains highly desirable.\nIndeed, prior to our work, no nontrivial class of PRPs was known for which the sampling algorithm achieved optimal running time. Additionally, it was not known whether the sampling problem for PDC is polynomial-time tractable under a lopsided LLL condition.\n1.2. Main results. In this paper, we resolve the aforementioned open questions. For a single permutation, we propose a fast sampling algorithm that runs in optimal $O\\left(n^{2}\\right)$ time for a specific class of PRPs. Moreover, this algorithm constitutes a key technique in our approach to sampling PDC formulas. For multiple permutations, we introduce a fast algorithm for sampling satisfying assignments of PDC formulas in the lopsided LLL regime. This is the first sampling LLL beyond the variable model. Furthermore, our method achieves nearly linear runtime for uniform PDC formulas, where all constraints have the same width and all permutations are of equal size.\n\nResults on a single permutation. Let $\\gamma \\in(0,1]$. Given any $n \\times n 0-1$ matrix, we define it as very dense if each row sum and each column sum are greater than $n-\\sqrt{(n-2) / 20}$. Similarly, for any integer $n \\geq 2$ and any sets $R_{1}, \\ldots, R_{n} \\subseteq[n]$, we call the instance very dense if $\\left|R_{i}\\right| \\geq n-\\sqrt{(n-2) / 20}$ for each $i \\in[n]$, and $\\left|\\left\\{k \\in[n] \\mid j \\in R_{k}\\right\\}\\right| \\geq n-\\sqrt{(n-2) / 20}$ for each $j \\in[n]$.\n\nOur first result for very dense $0-1$ matrices provides a tight approximation of the permanent. For any $x \\geq 0$ and $y>0$, define\n\n$$\ng(x, y) \\triangleq 2 \\pi y \\cdot \\exp \\left(\\frac{1}{3 y}\\right) \\cdot\\left(\\frac{y}{\\mathrm{e}}\\right)^{y} \\cdot\\left(1-\\frac{x}{y^{2}}\\right)^{y}\n$$\n\nThen we have the following theorem.\n\nTheorem 1.1. For any 0-1 matrix $A$ of size $n \\times n$, let $\\rho$ denote the total number of $0 s$ in $A$. If each row sum and each column sum are larger than $n-\\sqrt{(n-2) / 20}$, then we have\n\n$$\n\\frac{q(\\rho, n)}{\\sqrt{2 \\pi n} \\mathrm{e}^{2}} \\leq \\operatorname{per}(A) \\leq 19 \\cdot \\frac{q(\\rho, n)}{\\sqrt{2 \\pi n} \\mathrm{e}^{2}}\n$$\n\nThis theorem is restated as Theorem 4.3 in the context of PRP. It serves as a basic ingredient for our sampling and approximate counting algorithms for very dense PRP, just as in Theorems 1.2 and 4.4. The bound we establish in this theorem is remarkably sharp, tight up to a constant factor. The conditions on the row sum and the column sum guarantee that the degree of the lopsidependent graph is bounded such that the lopsided LLL is applicable (see Section 3.2). Using the lopsided LLL, we achieve a good approximation of the permanent, accurate to within a constant factor. This conclusion appears somewhat surprising because the lower bound provided by LLL is typically considered to be loose.\n\nBased on Theorem 1.1, we have the following exact sampler for PRP in the lopsided LLL regime.\nTheorem 1.2 (Sampler for very dense PRP in the lopsided LLL regime). There exists an exact sampler such that given as input any integer $n \\geq 2$ and any $R_{1}, \\cdots, R_{n} \\subseteq[n]$ where $\\left|R_{i}\\right| \\geq n-\\sqrt{(n-2) / 20}$ for each $i \\in[n]$ and $\\left|\\left\\{k \\in[n] \\mid j \\in R_{k}\\right\\}\\right| \\geq n-\\sqrt{(n-2) / 20}$ for each $j \\in[n]$, it outputs a random permutation uniformly from $\\prod_{i \\in[n]} R_{i}$, in expected running time $O\\left(n^{2}\\right)$. In addition, there is also an approximate sampler such that given as input any $\\varepsilon \\in(0,1)$ with an instance satisfying the same condition, it outputs random permutations with total variance distance of $\\varepsilon$ from the uniform distribution, in running time $O\\left(n^{2} \\cdot \\log (1 / \\varepsilon)\\right)$.\n\nIt is important to note that any sampling algorithm for very dense PRP must have a running time of at least $\\Omega\\left(n^{2}\\right)$, as reading the input incurs a cost of $\\Omega\\left(n^{2}\\right)$. Therefore, our algorithm attains an optimal running time. Previously, the best sampling algorithm for very dense PRP had a running time of $\\tilde{O}\\left(n^{4}\\right)$ [HL08]. Theorem 1.2 provides a significant speedup for these instances. We also obtain a fast approximate counting algorithm for very dense PRP, which is stated in Theorem 4.4. Theorems 1.2 and 4.4 are basic ingredients for our sampler of PDC.\n\nResults on multiple permutations. Recall the parameters $p, \\Delta, k, q$ of $\\Phi$. A PDC formula $\\Phi$ is $(k, q)$ uniform if all constraints have the same length $k$ and all permutations have the same size $q$. We have the following theorem for $(k, q)$-uniform PDC formulas.\n\nTheorem 1.3. The following holds for any sufficiently large $q_{\\min }$ and some constant $c>0$. There is an algorithm such that given as input any $\\varepsilon \\in(0,1)$ and any $(k, q)$-uniform PDC formula $\\Phi$ with $n$ variables where $\\Phi$ satisfies $q \\geq q_{\\min }$ and\n\n$$\nk \\geq 24, \\quad q^{k} \\geq c k^{24} \\Delta^{32}\n$$\n\nit outputs random valid assignments of $\\Phi$ with total variance distance of $\\varepsilon$ from the uniform distribution of all satisfying assignments of $\\Phi$, in time $\\widetilde{O}\\left(k \\Delta^{2} n^{1.001} / \\varepsilon\\right)$.\n\nThe formal statement of our theorem is provided in Theorem 9.1. The sampling problem for hypergraph coloring can be reduced to that for $(k, q)$-uniform formulas ${ }^{2}$. Combined with known hardness results for hypergraph coloring [ $\\mathrm{BGG}^{+} 19$, GGW23], this reduction implies that the sampling problem for $(k, q)$ uniform formulas is intractable when $\\Delta^{2} \\gtrsim q^{k}$. Therefore, to render the problem tractable, it is natural to assume an LLL-like regime in which $q^{k} \\gtrsim \\Delta^{c}$ for some constant $c$. Our theorem establishes such a regime for $(k, q)$-uniform formulas. Furthermore, our algorithm runs in nearly linear time in $n$, which is significantly faster than previous algorithms for multiple permutations [CDH11].\n\nAdditionally, we have the following algorithm for general PDC formulas.\n\n[^0]\n[^0]:    ${ }^{2}$ The main idea of the reduction is as follows. Consider the problem of $q$-coloring a $k$-uniform hypergraph. For each variable $\\varepsilon$ of the hypergraph, introduce $q-1$ dummy variables, denoted $v_{1}, \\ldots, v_{q-1}$. Let $P_{v}=\\left\\{v, v_{1}, \\ldots, v_{q-1}\\right\\}$ represent a set of variables in the PDC, with the domain $Q_{v}=\\{0,1, \\ldots, q-1\\}$. By further decomposing the non-monochromatic constraints into disjunctive constraints, the reduction is completed.\n\nTheorem 1.4. The following holds for any sufficiently large $q_{\\min }$ and some constant $c>0$. There exists an algorithm such that given as input any $\\varepsilon \\in(0,1)$ and any PDC formula $\\Phi$ with $n$ variables where $\\Phi$ satisfies $q \\geq q_{\\min }$ and\n\n$$\nc p k^{518} \\Delta^{786} \\leq 1\n$$\n\nit outputs random valid assignments of $\\Phi$ with total variance distance of $\\varepsilon$ from the uniform distribution of all satisfying assignments of $\\Phi$, in time $\\widetilde{O}\\left(k \\Delta n^{7} / \\varepsilon^{2}\\right)$.\n\nThe formal statement of the theorem appears in Theorem 9.2. While the constants in (2) can be further optimized, obstacles remain in achieving bounds comparable to those in the sampling LLL for the variable model [JPV21a, HSW21, HWY22, HWY23, WY24]. In particular, the extra condition $q \\geq q_{\\min }$ can be eliminated by employing the mark/unmark paradigm [Moi19], which is capable of handling small variables and permutations; however, this modification may complicate the overall algorithm design. Moreover, the time complexity in Theorem 1.4 is higher than that in Theorem 1.3 due to challenges posed by extreme instances in general PDC sampling, where one permutation is significantly larger than the others. Nevertheless, the time complexity of our sampling algorithm for general PDC is comparable to that of the PRP sampling algorithm [JSV04]. Given that the sampling challenge for PDC is inherently more complex than that for PRP, the demonstrated time complexity is considered acceptable.\n\nOur marginal sampler for drawing from marginal distributions (Algorithm 3) is a core component of the sampling LLL. This sampler diverges from all previous marginal samplers designed for product probability spaces. Notably, it enables the rapid sampling of nearly uniform satisfying solutions in the joint probability space of PDC, transcending the variable model within the local lemma framework, an advancement not previously achieved. Our marginal sampler is established based on the fast sampling and approximation algorithms for very dense PRP (Theorems 1.2 and 4.4). By combining these tools, we develop a novel sampling framework called correlated factorization (see Section 2.2.2) for the joint probability space. Consequently, the marginal sampler is established.\n\nOur sampling algorithm has intriguing applications, such as factors of independent transversals in multipartite hypergraphs. The problem of establishing sufficient conditions for the existence of independent transversals and their factors in multipartite hypergraphs has been widely explored in the literature [EGL94, Yus21], though many questions remain open. For the sampling of factors of independent transversals, no nontrivial algorithm has previously been proposed. We demonstrate, via reduction, that the sampling problem becomes intractable beyond the LLL-like regime. Additionally, we present the first efficient sampling algorithm for this problem within the LLL-like regime. These results are formally stated in Section 10.", "tables": {}, "images": {}}, {"section_id": 3, "text": "# 2. Technical overview \n\nIn this paper, we provide an optimal algorithm for the sampling of very dense PRP and a novel algorithm for the sampling of PDC in the lopsided LLL regime. In this section, we will provide a detailed exposition of the algorithmic techniques.\n2.1. Techniques for handling a single permutation. In this subsection, we summarize our techniques for handling very dense PRPs, which also serve as essential building blocks for sampling PDC.\n\nOur approximation and sampling algorithms for very dense PRPs follow the approach outlined in [Hub06]. Given a $0-1$ matrix $A$, Huber proposed an upper bound $U(A)$ for the permanent $\\operatorname{per}(A)$ (see Lemma 4.2) and subsequently designed a novel sampling algorithm for PRP based on this bound. The algorithm runs in approximately $O\\left(n^{2}\\right)$ - $U(A) / \\operatorname{per}(A)$ time. Consequently, to demonstrate the algorithm's efficiency, it suffices to derive a lower bound $L(A)$ for $\\operatorname{per}(A)$ and show that the ratio $U(A) / L(A)$ is small. Previously, the lower bound $L(A)$ was estimated using Van der Waerden's inequality, which tends to be loose when the number of zeros in the rows and columns of $A$ varies significantly.\n\nInstead of relying on Van der Waerden's inequality, we derive a tighter lower bound for very dense matrices using the lopsided LLL. Let $A$ be a $0-1$ matrix of size $n \\times n$, and let $\\sigma=(\\sigma(1), \\ldots, \\sigma(n))$ be a uniformly random permutation of $[n]$. Define $\\mathcal{E}_{i, j}$ as the bad event $\\sigma(i)=j$ for every $i, j \\in[n]$ such that $A_{i, j}=0$. Consequently, we have $\\operatorname{per}(A)=n!\\cdot \\operatorname{Pr}\\left\\{\\bigcup_{i, j} \\mathcal{E}_{i, j}\\right\\}$. Moreover, the lopsidependency structure\n\namong these bad events is captured by the lopsidependency graph. When $A$ is a very dense $0-1$ matrix, the degree of this graph is well-bounded, allowing the application of the lopsided LLL to obtain a lower bound for $\\operatorname{Pr}\\left[\\overline{\\bigcup_{i, j} \\mathcal{E}_{i, j}}\\right]$. Remarkably, the lower bound derived using the lopsided LLL for $\\operatorname{per}(A)$ differs from $U(A)$ by only a constant factor, thereby serving as a tight lower bound for $\\operatorname{per}(A)$ up to that constant factor (see Theorem 1.1). Thus, the PRP algorithm in [Hub06] effectively runs in approximately $O\\left(n^{2}\\right)$ time (see Theorem 1.2).\n2.2. Techniques for handling multiple permutations. Our sampling algorithm for PDC follows the Markov chain framework for sampling a solution of CSP in the LLL regime. This framework uses state compression to project the state space onto a smaller, well-connected space, where the barrier of disconnectivity could be circumvented because the images of the projection might collide. The Markov chain simulates a single-site Glauber dynamics in the compressed state space to draw an approximate sample from the uniform distribution $\\mu$ of all solutions. In each step of the Glauber dynamics, the assignment of a randomly selected variable $v$ is updated according to the marginal distribution of $v$, conditioned on the projected assignments $X$ of other variables. The standard rejection sampling is employed to update the assignment of $v$. To make the update efficient, each constraint should be satisfied by $X$ with a fairly high probability. This allows the remaining CSP formula to be factorized into disjoint sub-formulas of logarithmic sizes after removing all the satisfied constraints. To demonstrate the rapid mixing of Glauber dynamics, path coupling [FGYZ21, FHY21] and information percolation [JPV21a, HSW21] are employed to show a long connected path between two uncoupled variables is impossible.\n\nOur sampling algorithm for PDC also leverages the state compression technique. In contrast to the state compression designed for the product probability space [FHY21], we design a novel structure-preserved state compression for the joint probability space of PDC. Then our algorithm simulates a permutationwise Glauber dynamics in the compressed state space to draw an approximate sample from the uniform distribution $\\mu$ of all solutions, rather than simulating a Glauber dynamics as in previous methods. The permutation-wise Glauber dynamics is employed here to simultaneously update the assignments of all variables within a permutation set, considering the dependency between these variables. In each transition of the permutation-wise Glauber dynamics, a permutation set $P$ is picked uniformly at random and then the assignments of all the variables in $P$ are updated according to the marginal distribution on $P$, conditioned on the projected assignments $X$ of other variables in the compressed state space. However, even after removing satisfied constraints under $X$ and factorizing the remaining PDC formula, the sub-formula containing $P$ remains large if $P$ itself is large. To make the update in each step efficient, we introduce a sampling framework called correlated factorization, where the sub-formula containing $P$ is further broken down into two correlated parts, allowing one part to be sampled almost independently of the other. To demonstrate the permutation-wise Glauber dynamics is fast mixing, we employ the path coupling technique. The presence of long-range correlations from large permutations introduces new challenges. A key concept in our analysis is the inactive vertex, where the discrepancy at the vertex cannot further spread out through any constraint. We establish the contraction property of the discrepancy by showing that most vertices in a large assigned permutation set are inactive.\n\nIn the following, we present our techniques individually. These techniques are designed to address long-range correlations between the variables. They may inspire the development of other sampling algorithms based on the lopsided LLL that extend beyond the variable model. For each PDC formula $\\Phi$, let $\\mu_{\\Phi}$ denote the uniform distribution over its solutions.\n2.2.1. Structure-preserved state compression. Similar to the Glauber dynamics for sampling CSP solutions in the LLL regime, the state space of the permutation-wise Glauber dynamics for PDC may also be disconnected. To overcome this challenge, we propose a structure-preserved state compression for PDC.\n\nConsider the PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ defined over $m$ permutations, where $\\mathcal{P}=\\left(P_{1}, P_{2}, \\ldots, P_{m}\\right)$ and $\\mathcal{Q}=\\left(Q_{1}, Q_{2}, \\ldots, Q_{m}\\right)$. A structure-preserved state compression of $\\Phi$ involves decomposing each permutation set $P_{i}$ into several smaller sets, denoted $P_{i, 1}, \\ldots, P_{i, f_{i}}$. Instead of operating on the original solution space, our permutation-wise Glauber dynamics runs on the compressed state space. In each\n\ncompressed state, every subset $P_{i, j} \\subseteq P_{i}$ is paired with a corresponding domain $Q_{i, j} \\subseteq Q_{i}$ such that $\\left|Q_{i, j}\\right|=\\left|P_{i, j}\\right|$ and the domains $Q_{i, 1}, \\ldots, Q_{i, t_{i}}$ partition $Q_{i}$. This state comprises all valid assignments in which the partial assignment for the variables in $P_{i, j}$ is a permutation of the values in $Q_{i, j}$. In effect, each compressed state represents all solutions of the PDC formula $\\Phi^{\\prime}=\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}, \\mathcal{C}\\right)$, where $\\mathcal{P}^{\\prime}=\\left(P_{1,1}, \\ldots, P_{1, t_{1}}, \\ldots, P_{m, 1}, \\ldots, P_{m, t_{m}}\\right)$ and $\\mathcal{Q}^{\\prime}=\\left(Q_{1,1}, \\ldots, Q_{1, t_{1}}, \\ldots, Q_{m, 1}, \\ldots, Q_{m, t_{m}}\\right)$. This approach allows multiple solutions of $\\Phi$ to be represented within the same state, effectively overcoming issues of disconnectivity (see Lemma 5.7).\n\nRecall that two constraints $C=\\cdots \\vee(v \\neq c) \\vee \\cdots$ and $C^{\\prime}=\\cdots \\vee\\left(v^{\\prime} \\neq c^{\\prime}\\right) \\vee \\cdots$ are defined to be related, denoted $C \\sim C^{\\prime}$, if either $v=v^{\\prime}$, or $v$ and $v^{\\prime}$ belong to the same set $P_{i}$ and $c=c^{\\prime}$. Consequently, any two unrelated constraints neither share a variable nor forbid the same value for variables within the same permutation set. Importantly, this relationship is maintained even when each $P_{i}$ is partitioned into individual subsets $P_{i, 1}, \\ldots, P_{i, t_{i}}$; that is, the non-association $C+C^{\\prime}$ persists within the compressed states. Let $\\Phi^{\\prime}$ denote the corresponding PDC formula for a compressed state. Then, the lopsidependency graph for $\\Phi^{\\prime}$ is a subgraph of that for $\\Phi$, thereby preserving the original lopsidependency structure within each compressed state (see Lemma 5.1). This property is fundamental to our proofs.\n2.2.2. Correlated factorization. Given a PDC formula $\\Phi$ defined on $m$ permutations and a state compression of $\\Phi$, where each permutation set $P_{i}$ is decomposed into multiple individual permutation sets denoted as $P_{i, 1}, \\cdots, P_{i, t_{i}}$, we assume that the formula induced by each state in the compressed state space still satisfies a strong lopsided LLL condition. The subsequent challenge is how to implement the transition of the permutation-wise Glauber dynamics. Given the current state of the permutation-wise Glauber dynamics, w.l.o.g., let $P_{m}$ be the picked permutation set at the current transition. At this state, each permutation set in $P_{i, 1}, \\cdots, P_{i, t_{i}}$ has been assigned a subset of $Q_{i}$ as its domain for each $i \\in[m]$. Our task is to update the domains of $P_{m, 1}, \\cdots, P_{m, t_{m}}$ according to the current domains of the permutation sets $P_{1,1}, \\cdots, P_{1, t_{1}}, \\cdots, P_{m \\sim 1,1}, \\cdots, P_{m \\sim 1, t_{m-1}}$. Given the domains of these permutation sets, many constraints of the PDC formula $\\Phi$ have been satisfied. After removing these satisfied constraints, $\\Phi$ is \"factorized\" into subformulas, where the correlated variables are assigned to the same subformula. Since all variables in $P_{m}$ are correlated, they are assigned to the same subformula, denoted as $\\Phi^{\\prime}=\\left(\\mathcal{P}^{\\prime} \\cup\\left\\{P_{m}\\right\\}, \\mathcal{Q}^{\\prime} \\cup\\left\\{Q_{m}\\right\\}, \\mathcal{C}^{\\prime}\\right)$, where $\\mathcal{P}^{\\prime}$ represents the permutation sets correlated with $P_{m}$ and $\\mathcal{Q}^{\\prime}$ represents their domains. We remark that all permutation sets in $\\mathcal{P}^{\\prime}$ are small as a result of the decomposition. A crucial step in implementing the transition is to draw a sample from $\\mu_{\\Phi^{\\prime}}$, the uniform distribution over the solutions of $\\Phi^{\\prime}$. If $P_{m}$ is small, then $\\Phi^{\\prime}$ is also small, allowing for efficient rejection sampling from $\\mu_{\\Phi^{\\prime}}$. However, this task becomes significantly more challenging when $P_{m}$ is large.\n\nGiven a subformula $\\Phi^{\\prime}=\\left(\\mathcal{P}^{\\prime} \\cup\\left\\{P_{m}\\right\\}, \\mathcal{Q}^{\\prime} \\cup\\left\\{Q_{m}\\right\\}, \\mathcal{C}^{\\prime}\\right)$ where $P_{m}$ is large, the constraint set $\\mathcal{C}^{\\prime}$ can be partitioned into four disjoint subsets $\\mathcal{C}_{0}, \\mathcal{C}_{1}, \\mathcal{C}_{1}^{*}, \\mathcal{C}_{2}$ :\n\n- $C \\in \\mathcal{C}_{0}$ if $C$ does not depend on any variable in $P_{m}$;\n- $C \\in \\mathcal{C}_{1}$ if $C$ depends on exactly one variable in $P_{m}$ and no other variables outside of $P_{m}$;\n- $C \\in \\mathcal{C}_{1}^{*}$ if $C$ depends on exactly one variable in $P_{m}$ along with other variables outside of $P_{m}$;\n- $C \\in \\mathcal{C}_{2}$ if $C$ depends on at least two variables in $P_{m}$.\n\nLet $\\Phi^{\\dagger}=\\left(\\mathcal{P}^{\\prime} \\cup\\left\\{P_{m}\\right\\}, \\mathcal{Q}^{\\prime} \\cup\\left\\{Q_{m}\\right\\}, \\mathcal{C}_{0} \\cup \\mathcal{C}_{1} \\cup \\mathcal{C}_{1}^{*}\\right)$. By the lopsided LLL, most solutions of $\\Phi^{\\dagger}$ are also solutions of $\\Phi^{\\prime}$ since the constraints in $\\mathcal{C}_{2}$ are rarely unsatisfied when $P_{m}$ is large. Consequently, one can sample from $\\mu_{\\Phi^{\\prime}}$ using standard rejection sampling: first draw a sample $\\sigma$ from $\\mu_{\\Phi^{\\dagger}}$ and then accept $\\sigma$ if it also satisfies $\\Phi^{\\prime}$. The main challenge then is to sample from $\\mu_{\\Phi^{\\dagger}}$.\n\nLet $\\Phi_{0}=\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}, \\mathcal{C}_{0}\\right)$ and $\\Phi_{1}=\\left(\\left\\{P_{m}\\right\\},\\left\\{Q_{m}\\right\\}, \\mathcal{C}_{1}\\right)$. If $\\mathcal{C}_{1}^{*}=\\emptyset$, then $\\Phi^{\\dagger}$ can be further factorized into $\\Phi_{0}$ and $\\Phi_{1}$. Additionally, $\\Phi_{0}$ can be broken down into smaller subformulas because all permutation sets in $\\mathcal{P}^{\\prime}$ are smaller, and many constraints in $\\Phi$ are satisfied. Moreover, the sampling of $\\Phi_{1}$ aligns with the PRP sampling problem. Therefore, we can first draw a random solution $x$ for $\\Phi_{0}$ using rejection sampling and then draw a random solution $y$ for $\\Phi_{1}$ using Theorem 1.2. The concatenation of $x$ and $y$ then yields a random solution for $\\Phi^{\\dagger}$.\n\nUnfortunately, $\\mathcal{C}_{1}^{*}$ is typically not empty. Despite this, we still factorize $\\Phi_{0}$ from $\\Phi^{\\dagger}$, even though the variables in $\\Phi_{0}$ are correlated with $P_{m}$. We show that the distribution $\\mu_{\\Phi_{0}}$ closely approximates the marginal distribution of $\\mu_{\\Phi^{\\dagger}}$ on the variables in $\\Phi_{0}$. Thus, the following efficient sampler for $\\mu_{\\Phi^{\\dagger}}$ can be constructed:\n\n- Sample a random solution $x$ for $\\Phi_{0}$ using rejection sampling.\n- Given $x$ as the assignment for the variables in $\\Phi_{0}, \\Phi^{\\dagger}$ becomes a PRP formula $\\Phi_{x}^{\\dagger}$ on $P_{m}$. Sample a random solution $y$ for $\\Phi_{x}^{\\dagger}$ with the sampling algorithm for PRP (see Theorem 1.2).\n- Accept the concatenation $z$ of $x$ and $y$ as a solution of $\\Phi^{\\dagger}$ with a probability proportional to the solution size of $\\Phi_{x}^{\\dagger}$, which can be estimated with the approximate counting algorithm for PRP (see Theorem 4.4).\nThis final step adjusts $z$ to follow the distribution $\\mu_{\\Phi^{\\dagger}}$. We call this framework correlated factorization. The main idea of our framework is as follows: although the variables in $\\Phi_{0}$ and $P_{m}$ are correlated, the solution size of the PRP formula $\\Phi_{x}^{\\dagger}$ for random $x$ has a good concentration, allowing the variables in $\\Phi_{0}$ to be sampled nearly independently of $P_{m}$.\n2.2.3. Inactive vertices in path coupling. We employ the path coupling rather than the canonical path to obtain a tight mixing time of our permutation-wise Glauber dynamics. Within a single step of the coupling procedure (Algorithm 8), discrepancies may spread among variables within the same permutation set and across variables linked by the same constraint. Our objective is to establish that the discrepancy exhibits a contraction property, meaning it diminishes over time. However, the long-range correlation due to large permutations introduces new challenges to our analysis. Specifically, for a given permutation set $P$, if any variable $v$ in $P$ is uncoupled currently, all the variables in $P$ can potentially become uncoupled in the subsequent step of the algorithm. This issue is especially troublesome when $P$ is large, as it leads to a substantial increase in the number of uncoupled vertices, impeding the reduction of discrepancies.\n\nA key concept in our proof is the notion of an inactive vertex. Given two partial assignments $X_{1}, X_{2}$ for a formula $\\Phi$, we call a vertex $v$ inactive if all constraints associated with $v$ are satisfied under both assignments $X_{1}$ and $X_{2}$. Otherwise, $v$ is called active. For an inactive vertex $v$, it is possible that $X_{1}(v) \\neq X_{2}(v)$. However, this discrepancy at $v$ cannot further spread out through any constraint. As a result, the discrepancy can be bounded by considering only the active discrepant vertices. Our key insight is the following: while discrepancies within a large permutation set $P$ can spread rapidly across $P$, most vertices in $P$ are inactive. This is primarily because, given the large size of $P$, the constraints associated with $P$ are likely to be satisfied with a high probability under a random assignment of $P$. Consequently, the growth in active discrepancies is constrained. Nevertheless, achieving the contraction property for the discrepancy demands significant analytical effort.\n2.2.4. Summary. Although our sampling algorithm for PDC follows the general Markov chain framework employed in prior sampling LLL, it introduces a fundamentally novel marginal sampler (Algorithm 3) that departs significantly from existing approaches. The marginal sampler is a central component in the Markov chain approach, which updates the assignment of a single site at each transition. In previous LLL-based sampling algorithms, the marginal sampler is typically implemented via simple rejection sampling. However, this method breaks down in the PDC setting due to the presence of long-range correlations among variables within large permutations. To overcome this critical barrier, we develop a new marginal sampler based on a fine-grained decomposition of the subformula associated with a large permutation into several correlated components. The design crucially leverages a structural property of one key component, a very dense PRP, whose solution size is shown to exhibit strong concentration. This insight allows us to rigorously bound the correlations between components and ensure correct sampling. Moreover, to guarantee the correct marginal distribution over the subformula, we propose new sampling and approximation algorithms specifically tailored to very dense PRPs. These methods not only extend the algorithmic toolbox for handling dense permutation structures but also contribute a novel perspective to the design of marginal samplers under complex dependencies. Our contribution thus advances the state-of-the-art in sampling for PRPs and offers a principled approach to marginal sampling for long-range correlated structures beyond the variable model in the LLL framework.", "tables": {}, "images": {}}, {"section_id": 4, "text": "# 3. Preliminaries \n\n3.1. Notations. Throughout this paper, let $\\mathbb{R}$ be the set of real numbers, $\\mathbb{R}_{+}$be the set of non-negative real numbers, and $\\mathbb{N}_{+}$be the set of non-negative integers. For any positive integer $n$, we use $[n]$ to\n\ndenote the set $\\{1,2, \\ldots, n\\}$, and $n$ ! to denote the factorial of $n$. For simplicity, we use $x_{[n]}$ to represent $x_{1}, x_{2}, \\cdots, x_{n}$. Similarly, we will use $x_{[n] \\backslash\\{i\\}}$ to represent $x_{1}, \\cdots, x_{i-1}, x_{i+1}, \\cdots, x_{n}$ and $x_{i,[n]}$ to represent $x_{i, 1}, x_{i, 2}, \\cdots, x_{i, n}$. Furthermore, to simplify notation, we sometimes use $x_{[n]}$ to denote the sequence $\\left(x_{[n]}\\right)=\\left(x_{1}, x_{2}, \\cdots, x_{n}\\right)$.\n\nGiven a PDC formula on $m$ permutations $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $\\mathcal{P}=\\left(P_{[m]}\\right)=\\left(P_{1}, P_{2}, \\cdots, P_{m}\\right)$ and $\\mathcal{Q}=\\left(Q_{[m]}\\right)=\\left(Q_{1}, Q_{2}, \\cdots, Q_{m}\\right)$, let $\\Omega_{\\Phi}$ be the set of all satisfying assignments of $\\Phi, \\Omega_{\\Phi}^{*}$ be the set of all valid assignments of $\\Phi$, and $V_{\\Phi} \\doteq P_{1} \\cup \\cdots \\cup P_{m}$ be the union of all sets of variables in $\\mathcal{P}$. The subscript $\\Phi$ could be omitted if it is clear from the context. For convenience, we refer to $P_{i}$ as a permutation set and $Q_{i}$ as its domain, and the correspondence between the permutation set and its domain can also be indicated by $Q_{i}=\\mathcal{Q}\\left(P_{i}\\right)$ for each $i \\in[m]$. Moreover, we will also treat non-repetitive sequences as sets, and abuse the set notations if it is clear from the context. For any sequence of permutation sets $S=\\left(P_{1}^{\\prime}, \\cdots, P_{f}^{\\prime}\\right) \\subseteq \\mathcal{P}$, let $\\mathcal{Q}(S)$ denote the sequence of domains $\\left(\\mathcal{Q}\\left(P_{1}^{\\prime}\\right), \\cdots, \\mathcal{Q}\\left(P_{f}^{\\prime}\\right)\\right)$. For any $T \\subseteq V$, let $\\mathcal{C}(T)$ be the set of constraints $C \\in \\mathcal{C}$ such that $v \\mathrm{bl}(C) \\cap T \\neq \\emptyset$, where $\\mathrm{vbl}(C)$ is the set of variables used by $C$. For each constraint $C \\in \\mathcal{C}$, we say $u \\in V$ is on $C$ if $u \\in v \\mathrm{bl}(C)$. Additionally, we say $P \\in \\mathcal{P}$ is on $C$ if $P \\cap v \\mathrm{bl}(C) \\neq \\emptyset$.\n\nFor convenience, we will use $a<_{q} b$ and $a>_{q} b$ to denote $a<b^{1+\\sigma_{q}(1)}$ and $a>b^{1-\\sigma_{q}(1)}$ respectively, where $q$ is the minimal permutation set size for the discussed PDC formula $\\Phi$. We denote $a=_{q} b$ if both $a<_{q} b$ and $a>_{q} b$ hold.\n\nGiven any assignment $\\sigma \\in \\Omega^{*}$, let $\\sigma(S)=\\bigcup_{v \\in S} \\sigma(v)$ denote the value of $S$ in $\\sigma$ for any subset of variables $S \\subseteq V$. In particular, we use the notation $\\sigma(v)$ instead of $\\sigma(\\{v\\})$ to denote the assignment of $v$ for any $v \\in V$. Moreover, we use $\\sigma_{S}$ to denote the partial assignment on any subset of variables $S \\subseteq V$ induced from $\\sigma$. In other words, for any variable $v$ in $S$, we have $\\sigma_{S}(v)=\\sigma(v)$. Sometimes, we may use $v=c$ or $v \\neq c$ to denote the event that $\\sigma(v)=c$ or $\\sigma(v) \\neq c$ for convenience.\n\nConsider the uniform probability space over the valid assignments in $\\Omega^{*}$. Recall that $\\neg C$ is the event that the constraint $C$ is violated. We also abuse $C$ to denote the event that $C$ is satisfied when there is no ambiguity. We say a PDC formula $\\Phi$ is satisfiable if there exist some satisfying assignments for $\\Phi$ and use $\\mu=\\mu_{\\Phi}$ to denote the uniform distribution over all satisfying assignments of $\\Phi$. For any $S \\subseteq V$, we use $\\mu_{S}$ to denote the marginal distribution among the partial assignment $\\sigma_{S}$ induced from $\\mu$. Again, we use $\\mu_{v}$ instead of $\\mu_{\\{v\\}}$ for any $v \\in V$ in convention.\n\nGiven a PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$, the simplification of $\\Phi$ is the formula $\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}^{\\prime}\\right)$ where $\\mathcal{C}^{\\prime} \\subseteq \\mathcal{C}$ is the set of unsatisfied constraints given that the variables in $P$ take values from $\\mathcal{Q}(P)$ for each $P \\in \\mathcal{P}$. The PDC formula $\\Phi$ can be naturally represented as a (multi-)hypergraph $H_{\\Phi}$ according to its simplification $\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}^{\\prime}\\right)$. Specifically, each variable $v \\in V$ corresponds to a vertex in $H_{\\Phi}$, each permutation $P \\in \\mathcal{P}$ corresponds to a hyperedge $P$, and each constraint $C \\in \\mathcal{C}^{\\prime}$ corresponds to a hyperedge $\\mathrm{vbl}(C)$ in $H_{\\Phi}$. We slightly abuse the notation and write $H_{\\Phi}=\\left(V, \\mathcal{P} \\cup \\mathcal{C}^{\\prime}\\right)$. Let $H_{i}=\\left(V_{i}, \\mathcal{P}_{i} \\cup \\mathcal{C}_{i}\\right)$, where $1 \\leq i \\leq K$, denote all $K \\geq 1$ connected components within $H_{\\Phi}$. Each connected component corresponds to a formula denoted as $\\Phi_{i}=\\left(\\mathcal{P}_{i}, \\mathcal{Q}_{i}, \\mathcal{C}_{i}\\right)$. We refer to $\\Phi_{1}, \\Phi_{2}, \\cdots, \\Phi_{K}$ as the factorization of $\\Phi$. It is evident that $\\Phi=\\Phi_{1} \\wedge \\Phi_{2} \\wedge \\cdots \\wedge \\Phi_{K}$, and the uniform distribution $\\mu_{\\Phi}$ over all satisfying assignments of $\\Phi$ is the product of the distributions $\\mu_{\\Phi_{i}}$ among the formulas $\\Phi_{i}$ for $1 \\leq i \\leq K$.\n3.2. Lopsided Lov\u00e1sz Local Lemma. Recall the definitions of lopsidependent events and the lopsidependency graph in Section 1.1. The lopsided LLL establishes a condition ensuring that the probability of none of the bad events occurring is greater than 0 . This condition can be stated as follows:\n\nTheorem 3.1 ([AS16]). Given a lopsidependency graph $G=(\\mathcal{B}, E)$ w.r.t. the events $\\mathcal{B}$, if there is a function $x: \\mathcal{B} \\rightarrow(0,1)$ such that for any $B \\in \\mathcal{B}$,\n\n$$\n\\operatorname{Pr}[B] \\leq x(B) \\prod_{B^{\\prime} \\in \\Gamma(B)}\\left(1-x\\left(B^{\\prime}\\right)\\right)\n$$\n\nthen\n\n$$\n\\operatorname{Pr}\\left[\\bigwedge_{B \\in \\mathcal{B}} \\bar{B}\\right] \\geq \\prod_{\\substack{B \\in \\mathcal{B} \\\\ 9}}(1-x(B))>0\n$$\n\nIn particular, if $\\mathrm{e} \\operatorname{Pr}[B](D+1) \\leq 1$ for each $B \\in \\mathcal{B}$ where $D$ is the maximum degree of $G$, then\n\n$$\n\\operatorname{Pr}\\left[\\bigwedge_{B \\in \\mathcal{B}} \\bar{B}\\right] \\geq \\prod_{B \\in \\mathcal{B}}(1-\\mathrm{e} \\operatorname{Pr}[B])>0\n$$\n\nBy Theorem 3.1, we can obtain upper bounds of the conditional probabilities of events, the proof of which is deferred to Appendix A.\n\nCorollary 3.2. Assume the condition (3) in Theorem 3.1. For any event $A$ and any subset $T \\subseteq \\mathcal{B}$, if $A$ is non-lopsidependent with the events in $\\mathcal{B} \\backslash T$, we have\n\n$$\n\\operatorname{Pr}\\left[A \\mid \\bigwedge_{B \\in \\mathcal{B}} \\bar{B}\\right] \\leq \\operatorname{Pr}[A] \\cdot \\prod_{B \\in T}(1-x(B))^{-1}\n$$\n\nIn particular, if $\\mathrm{e} \\operatorname{Pr}[B](D+1) \\leq 1$ for each $B \\in \\mathcal{B}$ where $D$ is the maximum degree of $G$, then\n\n$$\n\\operatorname{Pr}\\left[A \\mid \\bigwedge_{B \\in \\mathcal{B}} \\bar{B}\\right] \\leq \\operatorname{Pr}[A] \\cdot \\prod_{B \\in T}(1-\\mathrm{e} \\operatorname{Pr}[B])^{-1}\n$$\n\nGiven any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$, we apply the lopsided LLL by considering the uniform probability space over its valid assignments $\\Omega^{*}$ and the collection of \"bad\" events $\\mathcal{B}=\\mathcal{B}_{\\Phi} \\doteq\\{\\neg C \\mid C \\in \\mathcal{C}\\}$, where $\\neg C$ is the event that $C$ is violated. The lopsidependency between the events in $\\mathcal{B}$ can be characterized by the undirected graph $G_{\\Phi}^{\\text {lop }}=\\left(\\mathcal{B}, E_{\\Phi}^{\\text {lop }}\\right)$ where $\\left\\{\\neg C, \\neg C^{\\prime}\\right\\} \\in E_{\\Phi}^{\\text {lop }}$ if and only if $C \\sim C^{\\prime}$. Following the proof in [LS07], one can verify that $G_{\\Phi}^{\\text {lop }}$ is a lopsidependency graph of the events in $\\mathcal{B}$.\n\nRecall that $\\mathbb{P}$ is the uniform distribution over all valid assignments, and $\\neg C$ denotes the event that $C$ is violated. According to Theorem 3.1 and Corollary 3.2, we immediately have the following lemma.\n\nLemma 3.3. Given any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ satisfying $\\mathrm{e} p \\Delta \\leq 1$, it holds that\n\n$$\n\\mathbb{P}\\left[\\bigwedge_{C \\in \\mathcal{C}} C\\right] \\geq \\prod_{C \\in \\mathcal{C}}(1-\\mathrm{e} \\mathbb{P}[\\neg C])>0\n$$\n\nIn addition, for any subset of valid assignments $A \\subseteq \\Omega^{*}$ and subset of constraints $\\mathcal{C}^{\\prime} \\subseteq \\mathcal{C}$ such that $A$ is non-lopsidependent with the violation of the constraints in $\\mathcal{C} \\backslash \\mathcal{C}^{\\prime}$, we have\n\n$$\n\\mathbb{P}\\left[A \\mid \\bigwedge_{C \\in \\mathcal{C}} C\\right] \\leq \\mathbb{P}[A] \\cdot \\prod_{C \\in \\mathcal{C}^{\\prime}}(1-\\mathrm{e} \\mathbb{P}[\\neg C])^{-1}\n$$\n\n3.3. Markov chain and path coupling. The Markov Chain Monte Carlo (MCMC) method is widely used for approximate sampling. A Markov chain $\\left(X_{t}\\right)_{t \\geq 0}$ defined on a discrete state space $\\Omega$ can be specified by the transition matrix $M \\in \\mathbb{R}^{\\Omega \\times \\Omega}$ where $M(x, y)=\\operatorname{Pr}\\left[X_{t+1}=y \\mid X_{t}=x\\right]$ for all $t \\in \\mathbb{N}$ and $x, y \\in \\Omega$. Thus, the Markov chain can be denoted by the transition matrix $M$. A distribution $\\mu$ over the state space $\\Omega$ is called the stationary distribution of the Markov chain $M$ if $\\mu=\\mu M$. It is well known that $\\mu$ is a stationary distribution of $M$ if $M$ is reversible with respect to $\\mu$, or equivalently, satisfies the following detailed balance condition:\n\n$$\n\\forall x, y \\in \\Omega \\quad \\mu(x) M(x, y)=\\mu(y) M(y, x)\n$$\n\nThe following result on the convergence of Markov chain is well known.\nTheorem 3.4 ([LPW^17]). Consider the Markov chain $\\left\\{X_{t}\\right\\}_{t \\geq 0}$ defined on $\\Omega$ with the transition matrix $M \\in \\mathbb{R}^{\\Omega \\times \\Omega}$. If $M$ satisfies the following conditions:\n\n- irreducible: $\\forall x, y \\in \\Omega, \\exists t>0$ such that $M^{t}(x, y)>0$;\n- aperiodic: $\\forall x \\in \\Omega, \\operatorname{gcd}\\left(\\left\\{t>0 \\mid M^{t}(x, x)>0\\right\\}\\right)=1$;\nthen there is a unique stationary distribution $\\mu$. Furthermore, $\\forall x \\in \\Omega, \\lim _{t \\rightarrow+\\infty} \\operatorname{Pr}\\left[X_{t}=x\\right]=\\mu(x)$.\n\nGiven a Markov chain $M$ with stationary distribution $\\mu$, its convergence rate can then be captured by the mixing time defined as:\n\n$$\n\\tau_{\\min }(\\delta) \\doteq \\max _{X_{0} \\in \\Omega} \\min _{t}\\left\\{t \\mid d_{\\mathrm{TV}}\\left(X_{t}, \\mu\\right) \\leq \\delta\\right\\}\n$$\n\nwhere $d_{\\mathrm{TV}}(\\mu, v) \\doteq \\frac{1}{2} \\sum_{x \\in \\Omega}|\\mu(x)-v(x)|$ is the total variance distance defined for any probability distributions $\\mu$ and $v$ over $\\Omega$.\n\nCoupling is a useful method for bounding the discrepancy of the probability distributions. Given probability distributions $\\mu$ and $v$ defined on the same discrete space $\\Omega$, a coupling of $\\mu$ and $v$ is a joint distribution $(X, Y)$ over $\\Omega \\times \\Omega$ such that the marginal distribution of $X$ (resp. $Y$ ) is $\\mu$ (resp. $v$ ).\n\nLemma 3.5. Let $\\mathscr{C}$ be a coupling between $\\mu$ and $v$. It holds that $d_{\\mathrm{TV}}(\\mu, v) \\leq \\operatorname{Pr}_{(X, Y) \\sim \\mathscr{C}}[X \\neq Y]$, and there exists an optimal coupling that achieves equality.\n\nPath coupling is a useful technique for bounding the mixing time of the Markov chains. Consider a Markov chain $\\left(X_{t}\\right)_{t \\geq 0}$ defined on a discrete state space $\\Omega$ with stationary distribution $\\mu$. ( $\\Omega$ doesn't need to be the support of $\\mu$.) To construct a coupling between the Markov chain transition conditioned on every pair of configurations in $\\Omega$, it allows us to consider pairs on a pre-metric of $\\Omega$ instead, leading to a significantly simpler analysis. The notion of pre-metric can be stated as follows.\n\nDefinition 3.6 (pre-metric). A pre-metric on $\\Omega$ is a weighted connected undirected graph with $\\Omega$ as its vertices such that for any edge $(x, y)$, the weight of the edge is equal to the weighted shortest-path distance between $x$ and $y$. In other words, the length of every other path from $x$ to $y$ is at least the weight of the edge $(x, y)$.\n\nWe can extend the pre-metric to a metric, denoted as $d$, on $\\Omega$, where $d(x, y)$ is the shortest path distances in the pre-metric from $x$ to $y$ for any $x, y \\in \\Omega$. In the following, it is shown that if we can construct the couplings between pairs on the pre-metric such that the distance defined by $d$ exhibits contraction under the one-step transition of the Markov chain, then there exists a coupling between every pair of configurations in $\\Omega$ that exhibits the contraction property.\n\nLemma 3.7 ([BD97]). Consider a Markov chain $\\left(X_{t}\\right)_{t \\geq 0}$ defined on $\\Omega$ with stationary distribution $\\mu$. Let $G=(\\Omega, E)$ be a pre-metric on $\\Omega$ where each edge in $E$ has a weight no less than 1, $d(\\cdot, \\cdot)$ be the weighted shortest path distance on $G$, and $d_{\\max }$ be $\\max _{x, y \\in \\Omega} d(x, y)$. For any $\\varepsilon>0$, if there exists a coupling $\\left(X_{t}, Y_{t}\\right)_{t \\geq 0}$ of a Markov chain defined for each $(x, y) \\in E$ such that\n\n$$\n\\mathrm{E}\\left[d\\left(X_{t+1}, Y_{t+1}\\right) \\mid X_{t}=x, Y_{t}=y\\right] \\leq(1-\\varepsilon) d(x, y)\n$$\n\nfor each $(x, y) \\in E$, then there exists a coupling $\\left(X_{t}, Y_{t}\\right)_{t \\geq 0}$ such that the contraction (4) holds for each $(x, y) \\in \\Omega \\times \\Omega$. Moreover, we have $\\tau_{\\min }(\\delta) \\leq\\left|\\frac{1}{\\varepsilon} \\ln \\frac{d_{\\max }}{2}\\right|$ for each $\\delta>0$.\n3.4. Inequalities. McDiarmid's inequality is a powerful concentration result that provides a sharp bound on the probability that a function of random variables deviates from its expected value, assuming the function satisfies the bounded differences condition described below.\n\nDefinition 3.8 (functions with bounded differences). Let $\\mathrm{c}=\\left(c_{1}, \\ldots, c_{n}\\right) \\in \\mathbb{R}_{+}^{n}$ be a given vector. A function $f: \\Omega \\rightarrow \\mathbb{R}$ is said to have bounded differences with respect to c if for any $\\boldsymbol{x}=\\left(x_{1}, \\ldots, x_{n}\\right), \\boldsymbol{x}^{\\prime}=$ $\\left(x_{1}^{\\prime}, \\ldots, x_{n}^{\\prime}\\right) \\in \\Omega$, it holds that\n\n$$\n\\left|f(\\mathrm{x})-f\\left(\\mathrm{x}^{\\prime}\\right)\\right| \\leq \\sum_{i=1}^{n} c_{i} 1_{\\left\\{x_{i} \\neq x_{i}^{\\prime}\\right\\}}\n$$\n\nwhere each $c_{i}$ is referred to as the $i$-th difference coefficient of $f$.\nTheorem 3.9 (McDiarmid's inequality [McD89]). Suppose $f: \\Omega_{1} \\times \\cdots \\times \\Omega_{n} \\rightarrow \\mathbb{R}$ satisfies the bounded differences property with respect to some $\\mathrm{c} \\in \\mathbb{R}_{+}^{n}$, and let $\\mathrm{X}=\\left(X_{1}, \\ldots, X_{n}\\right)$ be a vector of independent random variables, with each $X_{i}$ taking values in $\\Omega_{i}$. Then for any $t>0$, the tail probability satisfies\n\n$$\n\\operatorname{Pr}\\left[|f(X)-\\mathrm{E}[f(X)]| \\geq t\\right] \\leq 2 \\exp \\left(-\\frac{2 t^{2}}{\\|\\mathrm{e}\\|_{2}^{2}}\\right)\n$$\n\nInitially conjectured by Minc [Min63] and subsequently proven by Bregman [Br\u00e873], Bregman's Theorem establishes a sharp upper bound on the permanent. According to the relationship between the permanent and the permutation, it also provides an upper bound on the number of permutations.\n\nTheorem 3.10 (Bregman's Theorem [Min63, Br\u00e873]). Let $n$ be a positive integer and $R_{1}, R_{2}, \\cdots, R_{n}$ be subsets of $[n]$. Let $r_{i}=\\left|R_{i}\\right|$ for each $i \\in[n]$. Then the number of permutations of $[n]$ in $\\prod_{i \\in[n]} R_{i}$ is upper bounded by $\\prod_{i \\in[n]}\\left(r_{i}!\\right)^{1 / r_{i}}$.\n\nThe following inequalities are also used throughout our subsequent discussion.\nProposition 3.11 (Bernoulli's inequality). Given any real numbers $a \\geq-1, b \\geq 1$, we have $(1+a)^{b} \\geq$ $1+a b$.\n\nProposition 3.12 (Stirling's formula). For any positive integer $n$, we have\n\n$$\n\\sqrt{2 \\pi n}\\left(\\frac{n}{\\mathrm{e}}\\right)^{n} \\exp \\left(\\frac{1}{12 n+1}\\right) \\leq n!\\leq \\sqrt{2 \\pi n}\\left(\\frac{n}{\\mathrm{e}}\\right)^{n} \\exp \\left(\\frac{1}{12 n}\\right)\n$$", "tables": {}, "images": {}}, {"section_id": 5, "text": "# 4. ReSULTS ON a SINGLE PERMUTATION \n\nThis section presents our results on PRP.\n4.1. Very dense PRP in the LLL regime. This subsection presents our results on very dense PRP.\n4.1.1. Lopsided LLL is almost tight for very dense PRP. For any positive integer $a$, define $f(a)$ recursively as follows.\n\n$$\nf(1) \\doteq e ; \\quad \\forall a \\geq 1, \\quad f(a+1)=f(a)+1+\\frac{1}{2 f(a)}+\\frac{0.6}{2 f(a)^{2}}\n$$\n\nThe following two lemmas have been proved in [Hub06].\nLemma 4.1. For any $a \\geq 2, f(a) \\leq a+0.5 \\ln a+1.65$.\nLemma 4.2. Given any integer $n \\geq 2$ and any $R_{1}, \\cdots, R_{n} \\subseteq[n]$, let $\\Omega$ denote the set of permutations of $[n]$ in $\\prod_{i \\in[n]} R_{i}$. Then we have\n\n$$\n|\\Omega| \\leq \\prod_{i \\in[n]} \\frac{f\\left(\\left|R_{i}\\right|\\right)}{\\mathrm{e}}\n$$\n\nRecall the function $g(x, y)$ defined in (1). The following theorem provides an approximation for the number of solutions of very dense PRP, which is tight up to a constant factor.\n\nTheorem 4.3 (lopsided LLL is almost tight for very dense PRP). Given any integer $n \\geq 2$ and any $R_{1}, \\cdots, R_{n} \\subseteq[n]$, assume that $\\left|R_{i}\\right| \\geq n-\\sqrt{(n-2) / 20}$ for each $i \\in[n]$ and $\\left|\\left\\{k \\in[n] \\mid j \\in R_{k}\\right\\}\\right| \\geq$ $n-\\sqrt{(n-2) / 20}$ for each $j \\in[n]$. Let $\\rho$ denote $n^{2}-\\sum_{i \\in[n]}\\left|R_{i}\\right|$ and $\\Omega$ denote the set of permutations of $[n]$ in $\\prod_{i \\in[n]} R_{i}$. Then we have\n\n$$\n\\frac{g(\\rho, n)}{\\sqrt{2 \\pi n} \\mathrm{e}^{2}} \\leq|\\Omega| \\leq \\prod_{i \\in[n]} \\frac{f\\left(\\left|R_{i}\\right|\\right)}{\\mathrm{e}} \\leq 19 \\cdot \\frac{g(\\rho, n)}{\\sqrt{2 \\pi n} \\mathrm{e}^{2}}\n$$\n\nThe above theorem serves as a basic ingredient for our sampling and approximate counting algorithms for very dense PRP, just as in Theorems 1.2 and 4.4. In Theorem 4.3, the conditions on $\\left|R_{i}\\right|$ for each $i \\in[n]$ and $\\left|\\left\\{k \\in[n] \\mid j \\in R_{k}\\right\\}\\right|$ for each $j \\in[n]$ guarantee that the degree of the lopsidependent graph is bounded such that the lopsided LLL is applicable ${ }^{3}$. The lower bound is proved with the lopsided LLL, which is tight up to a constant factor for the number of solutions of very dense PRP. This conclusion appears somewhat surprising because the lower bound provided by LLL is typically considered to be loose. In many cases, there can be an exponential gap between the lower bound established by LLL and the number of solutions. However, this is not the case for very dense PRP.\n\n[^0]\n[^0]:    ${ }^{8}$ To achieve a nearly tight bound, we have stronger requirement on the degree of the lopsided-dependent graph than $e p \\Delta<1$.\n\nProof of Theorem 4.3. By Lemma 4.2, to prove this theorem, it is sufficient to prove\n\n$$\n\\begin{aligned}\n|\\Omega| & \\geq \\frac{g(\\rho, n)}{\\sqrt{2 \\pi n} \\mathrm{e}^{2}} \\\\\n\\prod_{i \\in[n]} \\frac{f\\left(\\left|R_{i}\\right|\\right)}{\\mathrm{e}} & \\leq 19 \\cdot \\frac{g(\\rho, n)}{\\sqrt{2 \\pi n} \\mathrm{e}^{2}}\n\\end{aligned}\n$$\n\nProof of (7). Let $\\sigma=(\\sigma(1), \\cdots, \\sigma(n))$ be a uniformly random permutation of $[n]$. Let $A_{i, j}$ denote the bad event $\\sigma(i)=j$ for each $i \\in[n], j \\notin R_{i}$. The lopsidependency between these events can be characterized by the lopsidependency graph, and Theorem 3.1 can be applied. Let $\\Delta$ be the degree of the lopsidependency graph. Then we have\n\n$$\n\\Delta \\leq \\max _{i \\in[n]}\\left(n-\\left|R_{i}\\right|\\right)+\\max _{j \\in[n]}\\left|\\left\\{k \\in[n] \\mid j \\in R_{k}\\right\\}\\right| \\leq \\sqrt{(n-2) / 5}\n$$\n\nTherefore, if $n \\leq 6$, we have $\\Delta<1$. Thus, $\\Delta=0$. We have\n\n$$\n6 \\Delta+1 \\leq n\n$$\n\nIf $n>6$, we also have (10). In addition, we have\n\n$$\n\\rho=n^{2}-\\sum_{i \\in[n]}\\left|R_{i}\\right| \\leq n^{2}-n \\min _{i \\in[n]}\\left|R_{i}\\right|=n \\max _{i \\in[n]}\\left(n-\\left|R_{i}\\right|\\right) \\leq n \\Delta\n$$\n\nCombined with (9), we have\n\n$$\n\\frac{3 \\Delta}{(n-1)^{2}} \\leq \\frac{3 \\Delta}{3(n+1) \\Delta^{2}}=\\frac{1}{(n+1) \\Delta} \\leq \\frac{1}{\\rho+1}\n$$\n\nNext, we show that $x\\left(A_{i, j}\\right)$ can be set as $(1 / n) \\cdot(1-1 / n)^{-2 \\Delta}$ for each bad event $A_{i, j}$ in Theorem 3.1. This boils down to showing that\n\n$$\n1 / n \\leq 1 / n \\cdot(1-1 / n)^{-2 \\Delta} \\cdot\\left(1-(1 / n) \\cdot(1-1 / n)^{-2 \\Delta}\\right)^{\\Delta}\n$$\n\nsince the violation probability of each constraint can be bounded by $1 / n$, and the degree of the lopsidependency graph is bounded by $\\Delta$. Note that\n\n$$\n(1-1 / n)^{-2 \\Delta} \\geq \\exp (2 \\Delta / n) \\geq 1+2 \\Delta / n\n$$\n\nIn addition, by Proposition 3.11 we have\n\n$$\n\\left(1-(1 / n) \\cdot(1-1 / n)^{-2 \\Delta}\\right)^{\\Delta} \\geq 1-\\frac{\\Delta}{n \\cdot(1-1 / n)^{2 \\Delta}} \\geq 1-\\frac{\\Delta}{n-2 \\Delta}\n$$\n\nTherefore, (13) holds if\n\n$$\n\\left(1+\\frac{2 \\Delta}{n}\\right) \\cdot\\left(1-\\frac{\\Delta}{n-2 \\Delta}\\right) \\geq 1\n$$\n\nwhich follows from (10) through simple calculation. Let\n\n$$\ng^{\\prime}(\\rho, n)=\\sqrt{2 \\pi n} \\cdot\\left(\\frac{n}{\\mathrm{e}}\\right)^{n} \\cdot \\exp \\left(\\frac{1}{12 n+1}\\right) \\cdot\\left(1-\\frac{1}{n}\\right)^{\\rho} \\cdot \\frac{1}{\\mathrm{e}}\n$$\n\nBy Theorem 3.1, we have\n\n$$\n\\begin{aligned}\n& |\\Omega| \\geq n!\\cdot \\prod_{i \\in[n], j \\notin R_{i}}\\left(1-x\\left(A_{i, j}\\right)\\right)=n!\\cdot\\left(1-x\\left(A_{i, j}\\right)\\right)^{\\rho} \\\\\n& \\geq \\sqrt{2 \\pi n} \\cdot\\left(\\frac{n}{\\mathrm{e}}\\right)^{n} \\cdot \\exp \\left(\\frac{1}{12 n+1}\\right) \\cdot\\left(1-\\frac{1}{n} \\cdot\\left(1-\\frac{1}{n}\\right)^{-2 \\Delta}\\right)^{\\rho} \\\\\n& =\\sqrt{2 \\pi n} \\cdot\\left(\\frac{n}{\\mathrm{e}}\\right)^{n} \\cdot \\exp \\left(\\frac{1}{12 n+1}\\right) \\cdot\\left(1-\\frac{1}{n} \\cdot\\left(1+\\frac{1}{n-1}\\right)^{2 \\Delta}\\right)^{\\rho} \\\\\n& \\geq \\sqrt{2 \\pi n} \\cdot\\left(\\frac{n}{\\mathrm{e}}\\right)^{n} \\cdot \\exp \\left(\\frac{1}{12 n+1}\\right) \\cdot\\left(1-\\frac{1}{n}\\left(1+\\frac{3 \\Delta}{n-1}\\right)\\right)^{\\rho}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n& =\\sqrt{2 \\pi n} \\cdot\\left(\\frac{n}{\\mathrm{e}}\\right)^{n} \\cdot \\exp \\left(\\frac{1}{12 n+1}\\right) \\cdot\\left(1-\\frac{1}{n}\\right)^{\\rho} \\cdot\\left(1-\\frac{3 \\Delta}{(n-1)^{2}}\\right)^{\\rho} \\\\\n& \\geq \\sqrt{2 \\pi n} \\cdot\\left(\\frac{n}{\\mathrm{e}}\\right)^{n} \\cdot \\exp \\left(\\frac{1}{12 n+1}\\right) \\cdot\\left(1-\\frac{1}{n}\\right)^{\\rho} \\cdot \\frac{1}{\\mathrm{e}} \\quad \\text { (by }(1-1 /(\\rho+1))^{\\rho} \\geq 1 / \\mathrm{e} \\text { and (12)) } \\\\\n& =g^{\\prime}(\\rho, n)\n\\end{aligned}\n$$\n\nwhere ( $\\boldsymbol{\\Delta}$ ) holds since\n\n$$\n\\begin{aligned}\n\\left(1+\\frac{1}{n-1}\\right)^{2 \\Delta} & \\leq 1+\\frac{2 \\Delta}{n-1}+\\sum_{i \\geq 2} \\frac{2 \\Delta \\cdot(2 \\Delta-1) \\cdots(2 \\Delta-i+1)}{i!}\\left(\\frac{1}{n-1}\\right)^{i} \\quad \\text { (by binomial series) } \\\\\n& \\leq 1+\\frac{2 \\Delta}{n-1}+\\sum_{i \\geq 2}\\left(\\frac{2 \\Delta}{n-1}\\right)^{i} \\\\\n& \\leq 1+\\frac{2 \\Delta}{n-1}+\\left(\\frac{2 \\Delta}{n-1}\\right)^{2} \\cdot\\left(\\frac{1}{1-2 \\Delta /(n-1)}\\right) \\\\\n& =1+\\frac{2 \\Delta}{n-1}+\\frac{4 \\Delta^{2}}{(n-1)(n-1-2 \\Delta)} \\\\\n& \\leq 1+\\frac{3 \\Delta}{n-1}\n\\end{aligned}\n$$\n\nThus, we have\n\n$$\n\\begin{aligned}\n\\frac{|\\Omega|}{g(\\rho, n)} & \\geq \\frac{g^{\\prime}(\\rho, n)}{g(\\rho, n)} \\\\\n& =\\frac{\\sqrt{2 \\pi n} \\cdot \\exp (1 /(12 n+1)-1) \\cdot(n / e)^{n} \\cdot(1-1 / n)^{\\rho}}{2 \\pi n \\cdot \\exp (1 /(3 n)) \\cdot(n / e)^{n} \\cdot\\left(1-\\rho / n^{2}\\right)^{n}} \\\\\n& =\\frac{\\sqrt{2 \\pi n} \\cdot \\exp (1 /(12 n+1))}{2 \\pi n \\cdot \\exp (1 /(3 n)+1)} \\cdot\\left(\\frac{(1-1 / n)^{\\rho / n}}{1-\\rho / n^{2}}\\right)^{n} \\\\\n& \\geq \\frac{\\sqrt{2 \\pi n} \\cdot \\exp (1 /(12 n+1))}{2 \\pi n \\cdot \\exp (1 /(3 n)+1)} \\\\\n& \\geq \\frac{1}{\\sqrt{2 \\pi n} \\mathrm{e}^{2}}\n\\end{aligned}\n$$\n\nThus, (7) is proved.\nProof of (8). Note that\n\n$$\n\\begin{aligned}\n\\prod_{i \\in[n]} f\\left(\\left|R_{i}\\right|\\right) & \\leq \\prod_{i \\in[n]}\\left(\\left|R_{i}\\right|+0.5 \\ln \\left|R_{i}\\right|+1.65\\right) \\\\\n& =\\prod_{i \\in[n]}\\left|R_{i}\\right|\\left(1+\\frac{0.5 \\ln \\left|R_{i}\\right|+1.65}{\\left|R_{i}\\right|}\\right) \\\\\n& \\leq \\prod_{i \\in[n]}\\left|R_{i}\\right| \\exp \\left(\\frac{0.5 \\ln \\left|R_{i}\\right|+1.65}{\\left|R_{i}\\right|}\\right) \\\\\n& \\leq \\prod_{i \\in[n]}\\left|R_{i}\\right|\\left(5.3 \\sqrt{\\left|R_{i}\\right|}\\right)^{1 /\\left|R_{i}\\right|} \\quad \\text { (by } \\exp (1.65) \\leq 5.3)\n\\end{aligned}\n$$\n\nThus, we have\n\n$$\n\\prod_{i \\in[n]}\\left(\\frac{\\left|R_{i}\\right|}{\\mathrm{e}} \\cdot\\left(5.3 \\sqrt{\\left|R_{i}\\right|}\\right)^{1 /\\left|R_{i}\\right|}\\right) \\leq\\left(\\prod_{i \\in[n]} \\frac{\\left|R_{i}\\right|}{\\mathrm{e}}\\right) \\cdot\\left(5.3 \\sqrt{n}\\right)^{\\frac{n}{n \\cdot \\sqrt{(n-2) / 20}}} \\quad\\left(\\text { by } n-\\sqrt{(n-2) / 20} \\leq\\left|R_{i}\\right| \\leq n\\right)\n$$\n\n$$\n\\begin{aligned}\n& =\\left(5.3 \\sqrt{n}\\right)^{\\frac{n}{\\left.n-\\sqrt{(n-2) / 20}\\right.}} \\cdot\\left(\\frac{n}{\\varepsilon}\\right)^{n} \\cdot \\prod_{i \\in[n]}\\left(1-\\frac{n-\\left|R_{i}\\right|}{n}\\right) \\\\\n& \\leq\\left(5.3 \\sqrt{n}\\right)^{\\frac{n}{\\left.n-\\sqrt{(n-2) / 20}\\right.}} \\cdot\\left(\\frac{n}{\\varepsilon}\\right)^{n} \\cdot\\left(1-\\frac{\\rho}{n^{2}}\\right)^{n} \\quad \\text { (by AM-GM inequality) } \\\\\n& =\\frac{(5.3 \\sqrt{n})^{\\frac{n}{\\left.n-\\sqrt{(n-2) / 20}\\right.}} \\cdot g(\\rho, n)}{2 \\pi n \\cdot \\exp (1 / 3 n)} \\\\\n& \\leq \\frac{\\mathrm{e}^{2}(5.3 \\sqrt{n})^{\\frac{n}{\\left.n-\\sqrt{(n-2) / 20}\\right.}}}{\\sqrt{2 \\pi n} \\cdot \\exp (1 / 3 n)} \\cdot \\frac{g(x, n)}{\\sqrt{2 \\pi n}} \\mathrm{e}^{2} \\\\\n& \\leq 19 \\cdot \\frac{g(x, n)}{\\sqrt{2 \\pi n}} \\mathrm{e}^{2}\n\\end{aligned}\n$$\n\nBy the above two inequalities, (8) is immediate. The theorem is proved.\n4.1.2. Exact Sampling for very dense PRP in the LLL regime. In this subsection, we present our approximation and sampling algorithm for very dense PRP in the LLL regime. Our algorithms are identical to those in [Hub06], but our analysis has been significantly refined. Rather than lower bounding the number of permutations with Van der Waerden's inequality as in [Hub06], we lower bound the number of permutations with the lopsided LLL as shown in Theorem 4.3.\n\nSimilar to Theorem 1.2, we also have a fast approximate counting algorithm for very dense PRP.\nTheorem 4.4 (approximate counting for dense PRP in the LLL regime). There exists an algorithm such that given as input any real numbers $\\varepsilon, \\delta \\in(0,1)$, any integer $n \\geq 2$ and any $R_{1}, \\cdots, R_{n} \\subseteq[n]$ satisfying the condition in Theorem 4.3, it outputs a $1 \\pm \\varepsilon$ approximation of $|\\Omega|$ with probability at least $1-\\delta$, in running time $O\\left(n^{2} \\cdot \\varepsilon^{-2} \\cdot \\log (1 / \\delta)\\right)$, where $\\Omega$ is the set of permutations of $[n]$ in $\\prod_{i \\in[n]} R_{i}$.\n\nTheorems 1.2 and 4.4 are basic ingredients of our sampler for PDC, which are immediate by Theorem 4.3 and the following theorem adapted from [Hub06].\nTheorem 4.5. Let $\\varepsilon \\in(0,1), \\delta \\in(0,1), n \\geq 2$ be an integer, and $R_{1}, \\ldots, R_{n} \\subseteq[n]$. Define $\\Omega \\subseteq \\prod_{i=1}^{n} R_{i}$ as the set of all permutations $\\pi$ of $[n]$ where $\\pi(i) \\in R_{i}$ for each $i$. There exists an exact sampler that, given any $n, R_{1}, \\ldots, R_{n}$ as input, outputs a uniformly random permutation from $\\Omega$, in expected running time\n\n$$\nO\\left(n^{2} \\cdot \\frac{\\prod_{i \\in[n]} f\\left(\\left|R_{i}\\right|\\right)}{\\mathrm{e}^{n}|\\Omega|}\\right)\n$$\n\nIn addition, there also exists an approximate sampler such that given as input any $\\varepsilon, n, R_{1}, \\ldots, R_{n}$, it outputs a random permutation with total variance distance of $\\varepsilon$ from the uniform distribution of $\\Omega$, in running time\n\n$$\nO\\left(n^{2} \\cdot \\frac{\\prod_{i \\in[n]} f\\left(\\left|R_{i}\\right|\\right)}{\\mathrm{e}^{n}|\\Omega|} \\cdot \\log \\frac{1}{\\varepsilon}\\right)\n$$\n\nThere also exists an algorithm such that given as input any $\\varepsilon, \\delta, n, R_{1}, \\cdots, R_{n}$, it outputs a $1 \\pm \\varepsilon$ approximation of $|\\Omega|$ with probability at least $1-\\delta$, in running time\n\n$$\nO\\left(\\frac{n^{2}}{\\varepsilon^{2}} \\cdot \\frac{\\prod_{i \\in[n]} f\\left(\\left|R_{i}\\right|\\right)}{\\mathrm{e}^{n}|\\Omega|} \\cdot \\log \\frac{1}{\\delta}\\right)\n$$", "tables": {}, "images": {}}, {"section_id": 6, "text": "# 5. Structure-Preserved state compression \n\nIn this section, we introduce the state compression for PDC formulas. As discussed in Section 1, the Markov chain approach for sampling LLL is facilitated by the utilization of the state compression technique. This technique enables the projection of the state space onto a more compact subspace, overcoming the challenge of the disconnectivity barrier by ensuring the projected images potentially intersect and are well connected. Previous state compressions have been limited to product probability\n\nspaces. In this work, we present a novel structure-preserved state compression technique for PDC formulas, ensuring that the probability spaces of the projected images are still induced by permutations. Our state compression is realized by the decomposition of permutations.\n5.1. Decomposition of permutations. Recall that $x_{[n]}=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)$. For simplicity, we sometimes use the notations $x_{1}, x_{2}, \\ldots, x_{n}$ and $\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)$, as well as $x_{[n]}$ and $\\left(x_{[n]}\\right)$, interchangeably. Given a PDC formula on $m$ permutations $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with $\\mathcal{P}=P_{[m]}=\\left(P_{1}, \\cdots, P_{m}\\right)$ and $\\mathcal{Q}=Q_{[m]}=$ $\\left(Q_{1}, \\cdots, Q_{m}\\right)$, the decomposition of $\\mathcal{P}$ can be defined as the following sequence of permutation sets\n\n$$\n\\mathcal{P}^{\\prime}=\\left(P_{1,\\left[\\ell_{1}\\right]}, \\cdots, P_{m,\\left[\\ell_{m}\\right]}\\right)=\\left(P_{1,1}, \\cdots, P_{1, \\ell_{1}}, \\cdots, P_{m, 1}, \\cdots, P_{m, \\ell_{m}}\\right)\n$$\n\nwhere $\\ell_{i}>0$ and $P_{i,\\left[\\ell_{i}\\right]}=\\left(P_{i, 1}, \\cdots, P_{i, \\ell_{i}}\\right)$ is a partition of $P_{i}$ for each $i \\in[m]$. For any $i \\in[m]$ and $t \\in\\left[\\ell_{i}\\right]$, let $P=\\bigcup_{j \\geq t} P_{i, j}$. We denote by $\\mathcal{P}^{\\prime}[P]$ the partition $\\left(P_{i, t}, P_{i, t+1}, \\ldots, P_{i, \\ell_{i}}\\right)$ of $P$ in $\\mathcal{P}^{\\prime}$. Furthermore, with a slight abuse of notation, we use $\\mathcal{P}^{\\prime} \\backslash \\mathcal{P}^{\\prime}[P] \\cup\\{P\\}$ to denote the sequence of permutation sets\n\n$$\n\\left(P_{i,\\left[\\ell_{i}\\right]}, \\cdots, P_{i-1,\\left[\\ell_{i-1}\\right]}, P_{i, 1}, \\cdots, P_{i, t-1}, P, P_{i+1,\\left[\\ell_{i+1}\\right]}, \\cdots, P_{m, \\ell_{m}}\\right)\n$$\n\nIn particular, for each $i \\in[m]$, we have $\\mathcal{P}^{\\prime}\\left[P_{i}\\right]=P_{i,\\left[\\ell_{i}\\right]}$, and $\\mathcal{P}^{\\prime} \\backslash \\mathcal{P}^{\\prime}\\left[P_{i}\\right] \\cup\\left\\{P_{i}\\right\\}$ is the decomposition of $\\mathcal{P}$ obtained by replacing the partition of $P_{i}$ in $\\mathcal{P}^{\\prime}$ with $P_{i}$. For brevity, let $\\mathcal{P}^{\\prime} \\circ P_{i} \\triangleq \\mathcal{P}^{\\prime} \\backslash \\mathcal{P}^{\\prime}\\left[P_{i}\\right] \\cup\\left\\{P_{i}\\right\\}$. The notations about $\\mathcal{Q}$ can be defined in a similar way.\n\nFurthermore, given $\\mathcal{P}^{\\prime}=\\left(P_{1,\\left[\\ell_{1}\\right]}, \\cdots, P_{m,\\left[\\ell_{m}\\right]}\\right)$, and $\\mathcal{Q}^{\\prime}=\\left(Q_{1,\\left[\\ell_{1}\\right]}, \\cdots, Q_{m,\\left[\\ell_{m}\\right]}\\right)$, the pair $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right)$ forms a decomposition of $(\\mathcal{P}, \\mathcal{Q})$ if $\\left[P_{i, j}\\right]=\\left[Q_{i, j}\\right]$ for each $i \\in[m]$ and $j \\in\\left[\\ell_{i}\\right]$.\n\nConsider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a decomposition $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right)$ of $(\\mathcal{P}, \\mathcal{Q})$. The formula induced by $\\Phi$ and $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right)$, denoted as $\\Phi\\left[\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right]$, is the formula $\\Phi^{\\prime}=\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}, \\mathcal{C}^{\\prime}\\right)$, where $\\mathcal{C}^{\\prime} \\subseteq \\mathcal{C}$ is the set of unsatisfied constraints given that the variables in $P^{\\prime}$ take values from $\\mathcal{Q}^{\\prime}\\left(P^{\\prime}\\right)$ for each $P^{\\prime} \\in \\mathcal{P}^{\\prime}$. Furthermore, for any valid assignment $\\sigma$ of $\\Phi$, we define $\\mathcal{Q}\\left[\\Phi, \\mathcal{P}^{\\prime}, \\sigma\\right]$ as the decomposition $\\mathcal{Q}^{\\prime}$ of $\\mathcal{Q}$ such that $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right)$ is a decomposition of $(\\mathcal{P}, \\mathcal{Q})$, and $\\mathcal{Q}^{\\prime}(P)=\\sigma(P)=\\bigcup_{\\forall \\in P} \\sigma(v)$ for each $P \\in \\mathcal{P}^{\\prime}$.\n\nA crucial property of the formula induced by the decomposition is that the non-lopsidependent constraints in the original formula remain non-lopsidependent. This property follows directly from the definition of the lopsidependency graph for PDC formulas in Section 3.2; a proof is provided in Appendix B for reference.\n\nLemma 5.1. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$. For any $\\sigma \\in \\Omega^{*}$ and any constraints $C_{1}, C_{2} \\in \\mathcal{C}$, if $\\left\\{\\neg C_{1}, \\neg C_{2}\\right\\} \\notin E_{\\Phi}^{\\text {Lop }}$, then $\\left\\{\\neg C_{1}, \\neg C_{2}\\right\\} \\notin E_{\\Phi^{\\prime}}^{\\text {Lop }}$ where $\\Phi^{\\prime}=$ $\\Phi\\left[\\mathcal{P}^{\\prime}, \\mathcal{Q}\\left[\\Phi, \\mathcal{P}^{\\prime}, \\sigma\\right]\\right]$.\n\nFor any $\\zeta \\in(0,1]$, we introduce the notion of $\\zeta$-decomposition.\nDefinition 5.2. Given any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a real number $\\zeta \\in(0,1]$, a decomposition $\\mathcal{P}^{\\prime}$ is called a $\\zeta$-decomposition of $\\mathcal{P}$ if\n\n$$\n\\forall P_{1} \\in \\mathcal{P}, P_{2} \\in \\mathcal{P}^{\\prime}\\left[P_{1}\\right], \\quad\\left\\|P_{1}\\right\\|^{\\zeta}-\\left|P_{2}\\right\\|=O(1)\n$$\n\nRemark 5.3. For any constant $\\zeta \\in(0,1 / 2]$ and any $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $q_{\\Phi}$ is sufficiently large, a $\\zeta$-decomposition of $\\mathcal{P}$ always exists.\n\nThe following lemma establishes an upper bound on the violation probability of the decomposed formulas, the proof of which can be found in Appendix B for reference.\n\nLemma 5.4. Consider a PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a $\\zeta$-decomposition $\\mathcal{P}^{\\prime}=\\left(P_{1}^{\\prime}, \\ldots, P_{l}^{\\prime}\\right)$ of $\\mathcal{P}$. Assume $\\mathcal{Q}^{\\prime}=\\left(Q_{1}^{\\prime}, \\ldots, Q_{l}^{\\prime}\\right)$ satisfies that, for each $i \\in[\\ell],\\left[Q_{i}^{\\prime}\\right]=\\left[P_{i}^{\\prime}\\right]$ and $Q_{i}^{\\prime} \\subseteq \\mathcal{Q}(P)$, where $P$ is the unique permutation set in $\\mathcal{P}$ containing $P_{i}^{\\prime}$. Let $\\Phi^{\\prime}=\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}, \\mathcal{C}\\right)$. Then, we have $p_{\\Phi^{\\prime}} \\leqslant q p_{\\Phi^{\\prime}}^{\\zeta}$.\n5.2. State compression by decomposition. For any formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$, let $\\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$ denote the set $\\left\\{\\mathcal{Q}^{\\prime} \\mid\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right)\\right.$ is a decomposition of $(\\mathcal{P}, \\mathcal{Q})\\}$. The distribution $\\mu=\\mu_{\\Phi}$ naturally induces a distribution $v=v_{\\Phi, \\mathcal{P}^{\\prime}}$ over $\\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$ where\n\n$$\n\\forall \\mathcal{Q}^{\\prime} \\in \\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right], \\quad v\\left(\\mathcal{Q}^{\\prime}\\right)=\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\mathcal{Q}\\left[\\Phi, \\mathcal{P}^{\\prime}, \\sigma\\right]=\\mathcal{Q}^{\\prime}\\right]\n$$\n\nThe following lemma is immediate by the aforementioned definitions.\n\nLemma 5.5. Given any formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$, we have\n\n$$\n\\forall \\sigma \\in \\Omega^{*}, \\quad \\mu(\\sigma)=v\\left(\\mathcal{Q}^{\\prime}\\right) \\cdot \\mu_{\\Phi^{\\prime}}(\\sigma)\n$$\n\nwhere $\\mathcal{Q}^{\\prime}=\\mathcal{Q}\\left[\\Phi, \\mathcal{P}^{\\prime}, \\sigma\\right]$ and $\\Phi^{\\prime}=\\Phi\\left[\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right]$.\nLemma 5.5 characterizes an equivalent method to sample the random satisfying assignments from $\\mu$. Specifically, to sample a satisfying assignment of $\\Phi$ from $\\mu$ uniformly at random, one can\n(1) Sample a domain $\\mathcal{Q}^{\\prime}$ from the compressed state space $\\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$ according to $v$;\n(2) Sample a satisfying assignment of the induced formula $\\Phi\\left[\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right]$ uniformly at random.\n\nConsequently, it boils down to a sampler for the decomposition of $\\mathcal{Q}$ from $\\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$ for sampling the satisfying assignments of $\\Phi$.\n\nFor any $P \\in \\mathcal{P}$ and $\\mathcal{Q}^{\\prime} \\in \\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$, let $v_{P}^{\\mathcal{Q}^{\\prime}}$ denote the marginal distribution of the domains on $\\mathcal{P}^{\\prime}[P]$ induced by $v$, conditioned on the domains corresponding to $\\mathcal{P}^{\\prime} \\backslash \\mathcal{P}^{\\prime}[P]$ being fixed as $\\mathcal{Q}^{\\prime}\\left(\\mathcal{P}^{\\prime} \\backslash \\mathcal{P}^{\\prime}[P]\\right)$. We can establish the following lemma immediately from the definitions of $v_{P}^{\\mathcal{Q}^{\\prime}}$.\n\nLemma 5.6. Given any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$, any decomposition $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right)$ of $(\\mathcal{P}, \\mathcal{Q})$, and any $P \\in \\mathcal{P}$, let $\\Phi^{\\prime}$ be the formula $\\left(\\mathcal{P}^{\\prime} \\circ P, \\mathcal{Q}^{\\prime} \\circ \\mathcal{Q}(P), \\mathcal{C}\\right)$. Suppose $\\mathcal{P}^{\\prime}[P]=\\left(P_{1}^{\\prime}, P_{2}^{\\prime}, \\cdots, P_{\\ell}^{\\prime}\\right)$ for some integer $\\ell>0$. It holds that\n\n$$\n\\forall Q_{1}^{*}, Q_{2}^{*}, \\cdots, Q_{\\ell}^{*}, \\quad v_{P}^{\\mathcal{Q}^{\\prime}}\\left(Q_{1}^{*}, Q_{2}^{*}, \\cdots, Q_{\\ell}^{*}\\right)=\\underset{\\sigma \\backslash \\mu_{\\Phi^{\\prime}}}{\\operatorname{Pr}}\\left[\\sigma\\left(P_{\\ell}^{\\prime}\\right)=Q_{\\ell}^{*} \\text { for all } i \\in[\\ell]\\right]\n$$\n\nLemma 5.6 characterizes an equivalent method to sample the domains from $v_{P}^{\\mathcal{Q}^{\\prime}}$. To sample $Q_{1}^{*} \\cdots, Q_{\\ell}^{*}$ from $v_{P}^{\\mathcal{Q}^{\\prime}}$, one can first draw a sample $\\sigma$ from $\\mu_{\\Phi^{\\prime}}$, and then let $Q_{\\ell}^{*}=\\sigma\\left(P_{\\ell}^{\\prime}\\right)$ for each $P_{\\ell}^{\\prime} \\in \\mathcal{P}^{\\prime}[P]$. Thus, we introduce the idealized permutation-wise Glauber dynamics for sampling $Q^{\\prime}$ from $v$ as follows:\n\nIdealized permutation-wise Glauber dynamics for $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$ :\n\n1. initialize $\\mathcal{Q}^{\\prime} \\leftarrow \\mathcal{Q}\\left[\\Phi, \\mathcal{P}^{\\prime}, \\sigma\\right]$ where $\\sigma \\leftarrow$ a valid assignment of $\\Phi$ uniformly at random;\n2. repeat the following for sufficiently many iterations:\na) pick a permutation set $P \\in \\mathcal{P}$ uniformly at random;\nb) update the domains of $\\mathcal{P}^{\\prime}[P]$ by redrawing its value independently from $v_{P}^{\\mathcal{Q}^{\\prime}}$ :\ni) draw $\\sigma \\sim \\mu_{\\Phi^{\\prime}}$ where $\\Phi^{\\prime}=\\left(\\mathcal{P}^{\\prime} \\circ P, \\mathcal{Q}^{\\prime} \\circ \\mathcal{Q}(P), \\mathcal{C}\\right)$;\nii) let $\\mathcal{Q}^{\\prime}\\left(P^{\\prime}\\right) \\leftarrow \\sigma\\left(P^{\\prime}\\right)$ for each $P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]$;\n\nThe following lemma ensures the correctness of the idealized permutation-wise Glauber dynamics, the proof of which is postponed to Appendix B.\n\nLemma 5.7. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ together with a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$. Suppose that for every $\\mathcal{Q}^{\\prime} \\in \\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$ and the corresponding formula $\\Phi^{\\prime}=\\Phi\\left[\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right]$, we have $\\forall p_{\\Phi^{\\prime}} \\Delta_{\\Phi^{\\prime}} \\leq 1$. Then, the idealized permutation-wise Glauber dynamics is irreducible, aperiodic, and reversible with respect to $v$. Consequently, it converges to the stationary distribution $v$.", "tables": {}, "images": {}}, {"section_id": 7, "text": "# 6. SAMPLING ALGORITHM WITH STATE COMPRESSION \n\nIn this section, we introduce the MCMC-based algorithm for sampling the satisfying assignments of the PDC formula.\n6.1. Sampling algorithm. Given a PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$, the main idea of our sampling algorithm is to construct a good decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$, simulate the idealized permutation-wise Glauber dynamics for the decomposition $\\mathcal{Q}^{\\prime}$ of $\\mathcal{Q}$ as shown in Section 5.2, and then sample the satisfying assignment of $\\Phi\\left[\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right]$ uniformly at random.\n\n6.1.1. Decomposition construction. We consider the formulas with the decomposition of permutations satisfying the following conditions.\nCondition 6.1. Let $\\Delta, k, n \\geq 1$ and $L \\geq 2$ be integers, and let $p, \\eta \\in(0,1)$ be real numbers. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ satisfying $\\Delta_{\\Phi} \\leq \\Delta, k_{\\Phi} \\leq k$ and $|V|=n$, and let $\\mathcal{P}^{\\prime}$ be a decomposition of $\\mathcal{P}$. Then, for each $P \\in \\mathcal{P}$ and every $P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]$, we have\n\n$$\n\\left|P^{\\prime}\\right| \\leq L \\quad \\text { and } \\quad\\left|\\left|P^{\\prime}\\right|-\\min \\left\\{\\left|P\\right|^{\\eta}, L\\right\\}\\right|=O(1)\n$$\n\nMoreover, for any $\\mathcal{Q}^{\\prime} \\in \\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$ and $\\Phi^{\\prime}=\\Phi\\left[\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right]$, we have $p_{\\Phi^{\\prime}} \\leq p$.\nWith the decomposition satisfying Condition 6.1, one can verify that each permutation set $P \\in \\mathcal{P}$ where $|P|<L^{1 / \\eta}$ is decomposed into permutation sets $P^{\\prime} \\in \\mathcal{P}^{\\prime}$ satisfying $\\left|P^{\\prime}\\right|=_{q}|P|^{\\eta}$. In this way, for any $\\mathcal{Q}^{\\prime} \\in \\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$, the violation probability of each constraint in $\\Phi\\left[\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right]$ is approximately upper bounded by $p^{\\eta}$. In addition, by Lemma 3.3, one can further show that for any random $\\mathcal{Q}^{\\prime}$ appearing in the idealized permutation-wise Glauber dynamics in Section 5.2, each constraint in $\\mathcal{C}$ is satisfied with a probability around $1-p^{1-\\eta}$, given that the variables in $P^{\\prime}$ take values from $\\mathcal{Q}^{\\prime}\\left(P^{\\prime}\\right)$ for each $P^{\\prime} \\in \\mathcal{P}^{\\prime}$. Then most constraints in $\\mathcal{C}$ are satisfied in $\\Phi\\left[\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right]$. Furthermore, as shown in subsequent sections, we ensure that each permutation set $P^{\\prime} \\in \\mathcal{P}^{\\prime}$ has a size not exceeding $L$ such that the algorithm can be realized efficiently.\n\nIt is worth noting that constructing the decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$, which satisfies Condition 6.1, can be easily accomplished by partitioning each $P \\in \\mathcal{P}$ into subsets of appropriate sizes. This process is of time complexity $O(|V|)$.\n6.1.2. MCMC-based sampling algorithm. Consider any instance satisfying Condition 6.1 with an error parameter $e \\in(0,1)$. The main algorithm (Algorithm 1) then implements a block Markov chain on space $\\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$ to sample the decomposition $\\mathcal{Q}^{\\prime}$ of $\\mathcal{Q}$ from the distribution $v$. It simulates the permutation-wise Glauber dynamics for $T=\\lceil 2 n \\log (3 n / \\varepsilon)\\rceil$ steps to draw a random $\\mathcal{Q}^{\\prime}$ distributed approximately as $v$. At each step, a permutation set $P \\in \\mathcal{P}$ is picked uniformly at random, and $\\mathcal{Q}^{\\prime}(\\mathcal{P}[P])$ is resampled approximately from the marginal distribution $v_{p}^{\\mathcal{Q}^{\\prime}}$. Finally, the algorithm draws a random satisfying assignment of the formula $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}, \\mathcal{C}\\right)$ almost uniformly at random, where $\\mathcal{Q}^{\\prime}$ is distributed approximately from $v$. According to Lemma 5.5, this process generates a random assignment that approximately follows the distribution of $\\mu$.\n\nOne of the most technically challenging steps in the sampling algorithm is to draw a sample from the marginal distribution $v_{p}^{\\mathcal{Q}^{\\prime}}$. Recall the factorization of a formula defined in Section 3. Consider the factorization of the formula $\\Phi^{\\prime}=\\left(\\mathcal{P}^{\\prime} \\circ P, \\mathcal{Q}^{\\prime} \\circ \\mathcal{Q}(P), \\mathcal{C}\\right)$, where the domains on $\\mathcal{P}^{\\prime} \\backslash \\mathcal{P}^{\\prime}[P]$ are fixed as $\\mathcal{Q}^{\\prime}\\left(\\mathcal{P}^{\\prime} \\backslash \\mathcal{P}^{\\prime}[P]\\right)$ and the domains $\\mathcal{Q}^{\\prime}\\left(\\mathcal{P}^{\\prime}[P]\\right)$ are replaced by $\\mathcal{Q}(P)$. It is evident that the marginal distribution induced by $\\mu_{\\Phi^{\\prime}}$ on the variables in $P$ is determined exclusively by the factorized formula $\\Phi^{\\prime}$ that contains $P$ in Algorithm 1. In other words, $\\mu_{\\Phi^{\\prime}}$ and $\\mu_{\\Phi^{\\prime}}$ have the same marginal distribution on the variables in $P$. Combining with Lemma 5.6, one can draw a sample from $v_{p}^{\\mathcal{Q}^{\\prime}}$ by sampling $\\sigma \\sim \\mu_{\\Phi^{\\prime}}$ and updating $\\mathcal{Q}^{\\prime}\\left(P^{\\prime}\\right)$ to $\\sigma\\left(P^{\\prime}\\right)$ for each $P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]$. To draw $\\sigma \\sim \\mu_{\\Phi^{\\prime}}$, we call the subroutine $\\operatorname{Sample}(\\cdot)$ which is the core of our algorithm.\n\nIn the last step of the main algorithm, to draw a random solution for the formula $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}, \\mathcal{C}\\right)$, we first factorize $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}, \\mathcal{C}\\right)$ to formulas $\\Phi_{1}, \\cdots, \\Phi_{K}$, and then draw a random solution $\\sigma_{i}$ for each factorized formula $\\Phi_{i}$ by the rejection sampling. The solution of $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}, \\mathcal{C}\\right)$ is the concatenation of all $\\sigma_{i}$. We shall ensure that the factorized formulas $\\Phi_{1}, \\ldots, \\Phi_{K}$ have small sizes, which can be achieved by that each permutation set $P^{\\prime} \\in \\mathcal{P}^{\\prime}$ has a size not exceeding $L$ by Condition 6.1, and each constraint $C \\in \\mathcal{C}$ is satisfied with high probability given that the variables in $P^{\\prime}$ take values from $\\mathcal{Q}^{\\prime}\\left(P^{\\prime}\\right)$ for each $P^{\\prime} \\in \\mathcal{P}^{\\prime}$. Thus, the rejection sampling can be efficient for these factorized formulas.\n\nOur rejection sampling algorithm for drawing from $\\mu_{\\Phi_{i}}$ is given in Algorithm 2. The correctness of this algorithm is folklore. We state without proof.\nLemma 6.2. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a truncated threshold $T \\geq 0$. Conditioned on RejectionSampling $(\\Phi, T)$ terminating at Line 3, it returns a satisfying assignment $\\sigma$ of $\\Phi$ uniformly at random. Furthermore, $d_{\\mathrm{TV}}\\left(\\sigma, \\mu_{\\Phi}\\right)$ is upper bounded by the probability that RejectionSampling $(\\Phi, T)$ terminates at Line 4.\n\n```\nAlgorithm 1: \\(\\mathrm{MCMC}\\left(\\Phi, \\mathcal{P}^{\\prime}, \\varepsilon\\right)\\)\n    Input: a PDC formula \\(\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})\\), a decomposition \\(\\mathcal{P}^{\\prime}\\) of \\(\\mathcal{P}\\) satisfying Condition 6.1, and a\n        error parameter \\(0<\\varepsilon<1\\).\n    Output: a random valid assignment of \\(\\Phi\\).\n    \\(\\sigma \\leftarrow\\) a valid assignment of \\(\\Phi\\) uniformly at random;\n    \\(\\mathcal{Q}^{\\prime} \\leftarrow \\mathcal{Q}\\left[\\Phi, \\mathcal{P}^{\\prime}, \\sigma\\right]\\);\n    \\(T \\leftarrow\\lceil 2 n \\log (3 n / \\varepsilon)\\rceil\\);\n    for \\(t=1\\) to \\(T\\) do\n        pick a permutation set \\(P\\) from \\(\\mathcal{P}\\) uniformly at random;\n        factorize \\(\\left(\\mathcal{P}^{\\prime} \\circ P, \\mathcal{Q}^{\\prime} \\circ \\mathcal{Q}(P), \\mathcal{C}\\right)\\) to disjoint formulas and let \\(\\Phi^{\\prime}\\) be the formula containing \\(P\\);\n        \\(\\sigma \\leftarrow \\operatorname{Sample}\\left(\\Phi^{\\prime}, P, \\varepsilon /(3(T+1))\\right)\\);\n        For each \\(P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]\\) do \\(\\mathcal{Q}^{\\prime}\\left(P^{\\prime}\\right) \\leftarrow \\sigma\\left(P^{\\prime}\\right)\\);\n    Let \\(\\Phi_{1}, \\ldots, \\Phi_{K}\\) be the factorization of \\(\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}, \\mathcal{C}\\right)\\);\n    for \\(i=1\\) to \\(K\\) do\n    \\(\\sigma_{i} \\leftarrow\\) RejectionSampling \\(\\left(\\Phi_{i},\\lceil(n / \\varepsilon) \\log (3 n(T+1) / \\varepsilon)\\rceil\\right)\\);\n    return the concatenation of \\(\\sigma_{1}, \\sigma_{2}, \\cdots, \\sigma_{K}\\);\nAlgorithm 2: RejectionSampling \\((\\Phi, T)\\)\n    Input: a PDC formula \\(\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})\\) and a truncated threshold \\(T\\).\n    Output: a random valid assignment of \\(\\Phi\\).\n    for \\(t=1\\) to \\(T\\) do\n        generate a valid assignment \\(\\sigma\\) of \\(\\Phi\\) uniformly and independently at random;\n        if \\(\\sigma\\) is a satisfying assignment of \\(\\Phi\\) then return \\(\\sigma\\);\n    return a valid assignment \\(\\sigma\\) of \\(\\Phi\\) uniformly at random ;\n```\n\n6.2. The Sample subroutine. In this section, we describe the $\\operatorname{Sample}(\\cdot)$ subroutine, which is the core component of our sampling algorithm. Given any instance satisfying Condition 6.1, we will show that the following invariant is satisfied by the input of $\\operatorname{Sample}(\\cdot)$ subroutine in Algorithm 1 under certain conditions. The correctness of the Sample subroutine is guaranteed by this invariant.\n\nCondition 6.3 (invariant for Sample subroutine). Let integers $\\Delta, k, n, L \\geq 1$ and real number $p \\in(0,1)$ satisfying $8 e p \\Delta^{2} \\leq 1$. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a permutation set $P \\in \\mathcal{P}$ satisfying the following conditions:\n\n- $\\Delta_{\\Phi} \\leq \\Delta, k_{\\Phi} \\leq k, p_{\\Phi} \\leq p,\\left|V_{\\Phi}\\right| \\leq n$, and $\\Phi$ cannot be further factorized to smaller formulas;\n- $\\left|P^{\\prime}\\right| \\leq L$ for each $P^{\\prime} \\in \\mathcal{P} \\backslash\\{P\\}$.\n\nOur $\\operatorname{Sample}(\\cdot)$ subroutine significantly differs from previous marginal samplers of sampling LLL. Significant effort is devoted to tackling the challenges arising from large permutations, which give rise to long-term correlations among the random variables. The conventional approach of factorizing the formula fails when dealing with large permutations, as they, along with their neighbor elements in the factorized formula, need to be sampled collectively.\n\nConsequently, in addition to exploiting factorization, we also analyze the correlation between the large permutation and its neighbors using concentration inequalities. The favorable concentration suggests a weak correlation between the large permutation and its neighbors. Hence, the neighboring permutations and the large permutation in one factorized formula can be sampled sequentially, where the large permutation is sampled with the sampling algorithm for PRP. The weak correlation only affects the time complexity of the subroutine by a polynomial factor.\n\nAccording to Condition 6.3, the input formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ of $\\operatorname{Sample}(\\cdot)$ cannot be further factorized. To draw a random satisfying assignment of $\\Phi$, instead of factorizing $\\Phi$ directly, we begin by omitting the constraints in $\\mathcal{C}(P)$ and factorizing $(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C} \\backslash \\mathcal{C}(P))$ into formulas $\\Phi_{1}, \\Phi_{2}, \\cdots, \\Phi_{K}$. By definition, there must be a factorized formula $(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\emptyset)$ which we designate as $\\Phi_{K}$. We shall ensure that, with\n\nhigh probability, the factorized formulas $\\Phi_{1}, \\Phi_{2}, \\cdots, \\Phi_{K-1}$ have small sizes throughout the execution of Algorithm 1, which can be formalized as the following condition.\n\nCondition 6.4. Consider any instance satisfying Condition 6.3 with real number $\\varepsilon \\in(0,1)$. Let $\\Phi_{1}, \\ldots, \\Phi_{K}$ be the factorization of $(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C} \\backslash \\mathcal{C}(P))$ where $\\Phi_{K}=(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\emptyset)$, and $\\Phi_{i}=\\left(\\mathcal{P}_{i}, \\mathcal{Q}_{i}, \\mathcal{C}_{i}\\right)$ for each $i \\in[K-1]$. It holds that\n\n$$\n\\max \\left\\{\\left|\\mathcal{C}_{1}\\right|, \\cdots,\\left|\\mathcal{C}_{K-1}\\right|\\right\\} \\leq \\Delta \\log (n / \\varepsilon)\n$$\n\nRemark 6.5. In the following pages, we will consistently refer to the PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ that cannot be further factorized to smaller formulas with a permutation set $P \\in \\mathcal{P}$. For convenience, we preserve the notations $\\Phi_{1}, \\Phi_{2}, \\ldots, \\Phi_{K}$ for the factorized formulas of $(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C} \\backslash \\mathcal{C}(P))$, where $\\Phi_{K}=$ $(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\emptyset)$, and $\\Phi_{i}=\\left(\\mathcal{P}_{i}, \\mathcal{Q}_{i}, \\mathcal{C}_{i}\\right)$ for each $i \\in[K-1]$. Moreover, we use $\\mu_{[i]}$ to denote $\\mu_{\\Phi_{1}} \\times \\cdots \\times \\mu_{\\Phi_{i}}$ for any $i \\in[K]$.\n\nIn the remaining part of this section, we present the high-level ideas and crucial lemmas for sampling the satisfying assignments of any instances satisfying Condition 6.4.\n\nWe begin with the natural accept-reject sampler for sampling $\\sigma \\sim \\mu_{\\Phi}$, which is to repeat the following steps until success:\n\n- draw $\\sigma_{1}, \\cdots, \\sigma_{K}$ from $\\mu_{\\Phi_{1}}, \\cdots, \\mu_{\\Phi_{K}}$, independently;\n- accept the concatenation of $\\sigma_{1}, \\ldots, \\sigma_{K}$ as $\\sigma$ if the concatenation is a solution of $\\Phi$.\n\nThe correctness of the sampler is folklore. The challenge lies in demonstrating its efficiency.\n6.2.1. Easy-to-handle factorized formulas. We first claim that if $2 \\mathrm{e} \\Delta \\leq \\log \\left(\\mathrm{e}^{4} n / \\varepsilon\\right)$ or $p_{\\max }|P| \\Delta \\leq$ $1 / 4$ where $p_{\\max }=\\max _{C \\in \\mathcal{C}(P)} \\mathbb{P}_{\\Phi}(\\neg C)$, the accept-reject sampler has an efficient implementation. The efficiency relies on the following result by the lopsided LLL, which is proved in Appendix C.\n\nLemma 6.6. Let integers $\\Delta, n \\geq 1$ and real numbers $p, \\varepsilon \\in(0,1)$ satisfying $8 \\mathrm{e} p \\Delta^{2} \\leq 1$. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $\\Delta_{\\Phi} \\leq \\Delta, p_{\\Phi} \\leq p,\\left|V_{\\Phi}\\right| \\leq n$ that cannot be further factorized to smaller formulas with a permutation set $P \\in \\mathcal{P}$. Let $\\sigma_{1}, \\cdots, \\sigma_{K}$ be independently drawn from $\\mu_{\\Phi_{1}}, \\cdots, \\mu_{\\Phi_{K}}, \\sigma$ be the concatenation of $\\sigma_{1}, \\ldots, \\sigma_{K}$, and $p_{\\max }=\\max _{C \\in \\mathcal{C}(P)} \\mathbb{P}_{\\Phi}[\\neg C]$. If $2 \\mathrm{e} \\Delta \\leq \\log \\left(\\mathrm{e}^{4} n / \\varepsilon\\right)$ or $p_{\\max }|P| \\Delta \\leq 1 / 4$, then\n\n$$\n\\operatorname{Pr}_{\\sigma_{[K]} \\sim \\mu_{[K]}}\\left[\\sigma \\in \\Omega_{\\Phi}\\right] \\geq \\frac{\\varepsilon}{\\mathrm{e}^{4} n}\n$$\n\nBy Condition 6.4, the formulas $\\Phi_{1}, \\Phi_{2}, \\cdots, \\Phi_{K-1}$ are small. Then one can draw $\\sigma_{i} \\sim \\mu_{\\Phi_{i}}$ for each $i \\in[K-1]$ efficiently by the rejection sampling. To draw $\\sigma_{K} \\sim \\mu_{\\Phi_{K}}$ for $\\Phi_{K}=(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\emptyset)$, it is sufficient to generate a random permutation of $\\mathcal{Q}(P)$ on $P$. Combined with Lemma 6.6, one can draw $\\sigma \\sim \\mu$ with probability $1-\\varepsilon$ by repeating the aforementioned subroutine for poly $(n, 1 / \\varepsilon)$ rounds. This is realized in Lines 3-9 of Algorithm 3.\n6.2.2. Challenging factorized formulas. The major challenge arises in the case where $2 \\mathrm{e} \\Delta \\geq \\log \\left(\\mathrm{e}^{4} n / \\varepsilon\\right)$ and $p_{\\max }|P| \\Delta \\geq 1 / 4$. In this circumstance, the probability that the concatenation of $\\sigma_{1}, \\cdots, \\sigma_{K}$ in the aforementioned procedure is a satisfying assignment of $\\Phi$ can be very small and then the sampler is no longer efficient. Thus, the subroutine in Lines 3-9 fails and new ideas are needed. One approach to address this challenge is to design a more efficient sampler that is built upon the assignments $\\sigma_{1}, \\cdots, \\sigma_{K-1}$ sampled independently from $\\mu_{\\Phi_{1}}, \\cdots, \\mu_{\\Phi_{K-1}}$.\n\nSpecifically, given $\\sigma_{[K-1]}$ where $\\sigma_{i}$ is sampled from $\\mu_{\\Phi_{i}}$ for each $i \\in[K-1]$, all constraints $C \\in \\mathcal{C} \\backslash \\mathcal{C}(P)$ are satisfied. This is because $C$ must be present in one of the formulas $\\Phi_{1}, \\Phi_{2}, \\cdots, \\Phi_{K-1}$ and is then satisfied by one of $\\sigma_{1}, \\cdots, \\sigma_{K-1}$. In addition, each unsatisfied constraint $C \\in \\mathcal{C}(P)$ can be simplified to a constraints $C^{\\prime}$ defined on $\\mathrm{vbl}(C) \\cap P$, since all the variables in $\\mathrm{vbl}(C) \\backslash P$ are fixed. Let\n\n$$\n\\mathcal{C}\\left[\\sigma_{[K-1]}\\right] \\triangleq\\left\\{\\text { simplification of } C \\text { given } \\sigma_{[K-1]} \\mid C \\in \\mathcal{C} \\text { and } C \\text { is unsatisfied under } \\sigma_{[K-1]}\\right\\}\n$$\n\ndenote the simplified constraints $C \\in \\mathcal{C}$ which are unsatisfied under the condition that $V_{\\Phi_{i}}$ is assigned as $\\sigma_{i}$ for each $i \\in[K-1]$. We remark that $\\mathrm{vbl}(C) \\subseteq P$ for each $C \\in \\mathcal{C}\\left[\\sigma_{[K-1]}\\right]$ by the definition of $\\mathcal{C}\\left[\\sigma_{[K-1]}\\right]$.", "tables": {}, "images": {}}, {"section_id": 8, "text": "# Algorithm 3: $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$ \n\nInput: a PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$, a permutation set $P \\in \\mathcal{P}$ satisfying Condition 6.3, and a parameter $0<\\varepsilon<1$.\nOutput: a random valid assignment of $\\Phi$\n1 Let $\\Phi_{1}, \\ldots, \\Phi_{K}$ be the factorization of $(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C} \\backslash \\mathcal{C}(P))$ where $\\Phi_{K}=(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\emptyset)$;\n$2 p_{\\max } \\leftarrow \\max _{C \\in \\mathcal{C}(P)} \\mathbb{P}_{\\Phi}(\\neg C)$\n3 if $2 e \\Delta \\leq \\log \\left(e^{4} n / \\varepsilon\\right)$ or $p_{\\max }|P| \\Delta \\leq 1 / 4$ then\n$4 \\quad T \\leftarrow\\left\\lceil e^{4} n / \\varepsilon \\cdot \\log (2 / \\varepsilon)\\right]$;\nfor $j=1$ to $T$ do\nfor $i=1$ to $K-1$ do\n$\\sigma_{i} \\leftarrow$ RejectionSampling $\\left(\\Phi_{i}, \\lceil(n / \\varepsilon) \\cdot \\log (2 n T / \\varepsilon)\\rceil\\right)$;\n$\\sigma_{K} \\leftarrow$ a random permutation of $\\mathcal{Q}(P)$ on $P$;\nif the concatenation of $\\sigma_{1}, \\cdots, \\sigma_{K}$ is a solution of $\\Phi$ then return the concatenation;\nelse\nfor $i=1$ to $K-1$ do\n$\\sigma_{i} \\leftarrow$ RejectionSampling $\\left(\\Phi_{i}, \\lceil(n / \\varepsilon) \\cdot \\log (12 n / \\varepsilon)\\rceil\\right)$;\n$x \\leftarrow \\max \\{\\rho(\\sigma[K-1])-|P| / 6,0\\}, \\mathcal{N} \\leftarrow g(x,|P|)$;\n$T \\leftarrow\\lceil 2 \\sqrt{2 \\pi|P|} \\cdot \\mathrm{e}^{3} /(1-\\exp (-6 e \\ln 2 \\cdot \\Delta) \\cdot \\log (6 / \\varepsilon)\\rceil$;\nfor $j=1$ to $T$ do\nfor $t=1$ to $K-1$ do\n$\\sigma_{t} \\leftarrow$ RejectionSampling $\\left(\\Phi_{t}, \\lceil(n / \\varepsilon) \\cdot \\log (6 n T / \\varepsilon)\\rceil\\right)$;\nif $x \\leq \\rho(\\sigma[K-1]) \\leq x+|P| / 2$ then\n$\\Phi^{\\prime} \\leftarrow\\left(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\mathcal{C}\\left[\\sigma_{[K-1]}\\right]\\right), \\Phi^{\\prime \\prime} \\leftarrow\\left(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\mathcal{C}^{1}\\left[\\sigma_{[K-1]}\\right]\\right)$;\ndraw $\\tau$ from $\\mu_{\\Phi^{\\prime \\prime}}$ with total variance distance $\\frac{\\tau}{6 T}$ by calling the sampler in Theorem 1.2;\nif $\\tau$ is also a solution of $\\Phi^{\\prime}$ then\n$r \\sim \\operatorname{Unif}[0,1]$\nestimate $\\left|\\Omega_{\\Phi^{\\prime \\prime}}\\right|$ within multiplicative error $1 \\pm \\frac{\\tau}{12 T}$ with probability $1-\\frac{\\tau}{6 T}$ by calling the counting algorithm in Theorem 4.4, and let $\\tilde{N}$ be the estimation;\nif $r \\leq \\tilde{N} / \\mathcal{N}$ then\nreturn the concatenation of $\\sigma_{1}, \\ldots, \\sigma_{K-1}, \\tau$;\n26 return an arbitrary valid assignment of $\\Phi$ uniformly at random;\n\nWe then define the simplified formula with the sampled satisfying assignments on $\\Phi_{[K-1]}$ as follows,\n\n$$\n\\Phi\\left[\\sigma_{[K-1]}\\right]=\\left(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\mathcal{C}\\left[\\sigma_{[K-1]}\\right]\\right)\n$$\n\nA natural idea for sampling $\\sigma \\sim \\mu$ is to sample the satisfying assignment $\\tau$ of $\\Phi\\left[\\sigma_{[K-1]}\\right]$ uniformly at random, and output the concatenation of $\\sigma_{1}, \\cdots, \\sigma_{K-1}, \\tau$. However, upon closer examination, one can see that the method exhibits inherent deviation due to the non-uniform nature of the marginal distribution on $P$ induced by $\\mu$. To adjust the probability, we could further apply the technique of filtration. Therefore, one can draw $\\sigma \\sim \\mu$ by repeating the following subroutine until success:\n\n- draw $\\sigma_{1}, \\cdots, \\sigma_{K-1}$ from $\\mu_{\\Phi_{1}}, \\cdots, \\mu_{\\Phi_{K-1}}$, independently;\n- draw $\\tau$ from $\\mu_{\\Phi\\left[\\sigma_{[K-1]}\\right]}$ where $\\Phi\\left[\\sigma_{[K-1]}\\right]$ is defined in (15);\n- accept the concatenation of $\\sigma_{1}, \\ldots, \\sigma_{K-1}, \\tau$ as $\\sigma$ with probability $\\left|\\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}\\right| / \\mathcal{N}$ where $\\mathcal{N}$ is an upper bound of $\\left|\\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}\\right|$ for all possible $\\sigma_{[K-1]}$.\n\nIn this sampler, the concatenation of $\\sigma_{1}, \\ldots, \\sigma_{K-1}, \\tau$ is accepted as $\\sigma$ with probability proportional to $\\left|\\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}\\right|$. It can be verified that $\\sigma$ follows the distribution of $\\mu$.\n\nHowever, there are still some technical issues with the aforementioned sampler. First, the assignment $\\tau$ should be sampled efficiently from $\\mu_{\\Phi\\left[\\sigma_{[K-1]}\\right]}$. Additionally, the upper bound $\\mathcal{N}$ should not be too large to avoid frequent rejections of the concatenation of $\\sigma_{1}, \\ldots, \\sigma_{K-1}, \\tau$. We collectively tackle these challenges by reducing them to the counting and sampling task for PRP.\n\nLet\n\n$$\n\\mathcal{C}^{1}\\left[\\sigma_{[K-1]}\\right] \\doteq\\left\\{C \\in \\mathcal{C}\\left[\\sigma_{[K-1]}\\right]| | \\operatorname{vbl}(C) \\mid=1\\right\\}, \\quad \\rho\\left(\\sigma_{[K-1]}\\right)=\\left|\\mathcal{C}^{1}\\left[\\sigma_{[K-1]}\\right]\\right|\n$$\n\nand\n\n$$\n\\Phi^{1}\\left[\\sigma_{[K-1]}\\right] \\doteq\\left(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\mathcal{C}^{1}\\left[\\sigma_{[K-1]}\\right]\\right)\n$$\n\nObviously, $\\mathcal{C}^{1}\\left[\\sigma_{[K-1]}\\right] \\subseteq \\mathcal{C}\\left[\\sigma_{[K-1]}\\right]$. Since each constraint $C \\in \\mathcal{C}^{1}\\left[\\sigma_{[K-1]}\\right]$ satisfies $\\operatorname{vbl}(C)=1$, one can verify that $\\Phi^{1}\\left[\\sigma_{[K-1]}\\right]$ is exactly a random PRP. Therefore, instead of sampling the satisfying assignment from $\\mu_{\\Phi\\left[\\sigma_{[K-1]}\\right]}$, we first draw a sample $\\tau$ from $\\mu_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]$ by filtration, and then accept it if $\\tau \\in \\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}$. In addition, this method also resolves the challenge of the upper bound estimation in the filtration by calling the counting algorithm for PRP. To summarize, we now sample $\\sigma \\sim \\mu_{\\Phi}$ by repeating the following subroutine until success:\n\n- draw $\\sigma_{1}, \\cdots, \\sigma_{K-1}$ from $\\mu_{\\Phi_{1}}, \\cdots, \\mu_{\\Phi_{K-1}}$, independently;\n- draw a sample from $\\mu_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]$ and accept the sample as $\\tau$ with probability $\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right| / \\mathcal{N}$, where $\\mathcal{N}$ is an upper bound of $\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right|$ for all possible $\\sigma_{[K-1]}$;\n- if $\\tau$ is also a solution of $\\Phi\\left[\\sigma_{[K-1]}\\right]$, accept the concatenation of $\\sigma_{1}, \\ldots, \\sigma_{K-1}, \\tau$ as $\\sigma$.\n\nOne can verify that $\\sigma$ sampled from the above sampler follows the distribution of $\\mu$.\nTo make this sampler efficient, the following conditions are also needed:\n(1) $\\tau \\sim \\mu_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]$ can be drawn efficiently;\n(2) the probability that $\\tau$ is a solution of $\\Phi\\left[\\sigma_{[K-1]}\\right]$ is lower bounded by $1 / \\operatorname{poly}(n, 1 / \\varepsilon)$;\n(3) for all possible $\\Phi^{1}\\left[\\sigma_{[K-1]}\\right]$ and some positive constant $c$\n\n$$\n\\left(\\frac{n}{\\varepsilon}\\right)^{-c} \\leq \\frac{\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right|}{\\mathcal{N}} \\leq 1\n$$\n\nFor the first item, $\\tau \\sim \\mu_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]$ can be drawn by calling the sampling algorithm for PRP, recalling that $\\Phi^{1}\\left[\\sigma_{[K-1]}\\right]$ is exactly an instance of PRP. For the second item, we have that the majority of solutions of $\\Phi^{1}\\left[\\sigma_{[K-1]}\\right]$ also satisfy the constraints of $\\Phi\\left[\\sigma_{[K-1]}\\right]$ by the following lemma. The lemma is immediate by the lopsided LLL, the proof of which is deferred to Appendix C.\n\nLemma 6.7. Let $\\Delta \\geq 1$. Consider any formula $\\Phi=(\\{P\\}, \\mathcal{Q}, \\mathcal{C})$ where $\\Delta_{\\Phi} \\leq \\Delta$ satisfying $|P| \\geq 2 \\varepsilon \\Delta$. Let $\\mathcal{C}^{\\prime}$ denote $\\left\\{C \\in \\mathcal{C}| | \\operatorname{vbl}(C) \\mid=1\\right\\}$ and $\\Phi^{\\prime}=\\left(\\{P\\}, \\mathcal{Q}, \\mathcal{C}^{\\prime}\\right)$. It holds that\n\n$$\n\\operatorname{Pr}_{\\sigma \\sim \\mu_{\\Phi^{\\prime}}}\\left[\\sigma \\in \\Omega_{\\Phi}\\right] \\geq 1-\\frac{2 \\Delta}{|P|-1}\n$$\n\nNow, let's consider the last item, which requires that $\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right| / \\mathcal{N}$ is lower bounded by $1 / \\operatorname{poly}(n, 1 / \\varepsilon)$. The main challenge to this item is that the following two conditions cannot be satisfied at the same time:\n\n- $\\mathcal{N}$ is an upper bound of $\\left|\\Phi^{1}\\left[\\sigma_{[K-1]}\\right]\\right|$ for all possible $\\Phi^{1}\\left[\\sigma_{[K-1]}\\right]$;\n- $\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right| / \\mathcal{N}$ is lower bounded by $1 / \\operatorname{poly}(n, 1 / \\varepsilon)$ for all possible $\\sigma_{[K-1]}$.\n\nBecause for some certain special $\\sigma_{[K-1]}$, the set $\\mathcal{C}^{1}\\left[\\sigma_{[K-1]}\\right]$ can be $\\emptyset$, leading to $\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right|=|P|!$. However, for some other $\\sigma_{[K-1]}, \\mid \\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]$ can be as small as $|P|!/ \\exp (-\\Delta)$.\n\nTherefore, rather than a general upper bound of $\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right|$ for all possible $\\sigma_{[K-1]}$, we aim to obtain an estimator $\\mathcal{N}$ where $\\mathcal{N} \\geq\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right|$ for most $\\sigma_{[K-1]}$. In this way, we can deal with the majority of $\\sigma_{[K-1]}$ and then sample a large portion of solutions of the original formula $\\Phi$ uniformly. Since the unsampled solutions originate from the negligible portion of $\\sigma_{[K-1]}$, their absence only introduces a slight deviation in the distribution. Formally, we try to obtain an estimator $\\mathcal{N}$ such that\n\n$$\n\\operatorname{Pr}_{\\sigma_{[K-1]} \\sim \\mu_{[K-1]}}\\left[\\left(\\frac{n}{\\varepsilon}\\right)^{-c} \\leq \\frac{\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right|}{\\mathcal{N}} \\leq 1\\right] \\geq 1-1 / \\operatorname{poly}(n, 1 / \\varepsilon)\n$$\n\nOur estimator is defined as follows. Recall the definition of $g(x, y)$ in (1) and the definition of $\\rho\\left(\\sigma_{[K-1]}\\right)$ in (16). For any $\\sigma_{[K-1]}$ where $\\rho\\left(\\sigma_{[K-1]}\\right)$ satisfies (21), the following lemma shows that $g(x,|P|)$ is an estimator satisfying (18).\n\nLemma 6.8 (Estimator for the number of solutions, restatement of Theorem 4.3). Let integer $\\Delta \\geq 1$. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $\\Delta_{\\Phi} \\leq \\Delta$ that cannot be further factorized to smaller formulas with a permutation set $P \\in \\mathcal{P}$. Assume $|P| \\geq 5 \\Delta^{2}+2$. For any satisfying assignment $\\sigma_{[K-1]}$ of $\\Phi_{[K-1]}$, we have\n\n$$\n\\frac{g\\left(\\rho\\left(\\sigma_{[K-1]}\\right),|P|\\right)}{\\sqrt{2 \\pi|P|} \\mathrm{e}^{2}} \\leq\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right| \\leq g\\left(\\rho\\left(\\sigma_{[K-1]}\\right),|P|\\right)\n$$\n\nIn addition, for any nonnegative integer $x$ where\n\n$$\n\\rho\\left(\\sigma_{[K-1]}\\right)-|P| / 2 \\leq x \\leq \\rho\\left(\\sigma_{[K-1]}\\right) \\leq|P| \\Delta\n$$\n\nwe have\n\n$$\n\\frac{g(x,|P|)}{\\sqrt{2 \\pi|P|} \\mathrm{e}^{3}} \\leq\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right| \\leq g(x,|P|)\n$$\n\nLemma 6.8 is merely the restatement of Theorem 4.3 and its correctness can be verified by modifying the statements in the proof of Theorem 4.3. Combining with Lemma 6.8, to obtain an upper bound $\\mathcal{N}$ satisfying (19), one only needs to obtain a random $x>0$ with probability at least $1-1 / \\operatorname{poly}(n, 1 / \\varepsilon)$ such that\n\n$$\n\\operatorname{Pr}_{\\sigma_{[K-1]} \\sim \\mu_{[K-1]}}\\left[x \\leq \\rho\\left(\\sigma_{[K-1]}\\right) \\leq x+|P| / 2\\right] \\geq 1-1 / \\operatorname{poly}(n, 1 / \\varepsilon)\n$$\n\nand set $\\mathcal{N}$ as $g(x,|P|)$. Fortunately, $\\rho\\left(\\sigma_{[K-1]}\\right)$ where $\\sigma_{[K-1]} \\sim \\mu_{[K-1]}$ exhibits good concentration.\nLemma 6.9 (Concentration property of $\\rho$ ). Consider any instance satisfying Condition 6.4, and assume $|P| \\geq 1728 \\mathrm{e}^{3} \\ln 2 \\cdot k^{3} L^{2} \\Delta^{8}, 2 \\mathrm{e} \\Delta \\geq \\log \\left(\\mathrm{e}^{4} n / \\varepsilon\\right)$. It holds that\n\n$$\n\\operatorname{Pr}_{\\sigma_{[K-1]} \\sim \\mu_{[K-1]}}\\left\\{\\left|\\rho\\left(\\sigma_{[K-1]}\\right)-\\mathrm{E}\\left[\\rho\\left(\\sigma_{[K-1]}\\right)\\right]\\right| \\geq|P| / 12\\right\\} \\leq \\exp (-6 \\mathrm{e} \\ln 2 \\cdot \\Delta)\n$$\n\nLemma 6.9 is proved by McDiarmid's inequality, and its proof is deferred to Appendix C. The intuition can be stated as follows. Given any instance $(\\Phi, P, \\varepsilon)$ satisfying Condition 6.4 where $|P| \\geq$ $1728 \\mathrm{e}^{3} \\ln 2 \\cdot k^{3} L^{2} \\Delta^{8}$ and the factorized formulas $\\Phi_{1}, \\ldots, \\Phi_{K-1}$ are small, each solution $\\sigma_{i}$ of $\\Phi_{i}$ has minor impact on $\\rho\\left(\\sigma_{[K-1]}\\right)=\\left|\\mathcal{C}^{1}\\left[\\sigma_{[K-1]}\\right]\\right|$. While $\\sigma_{1}, \\ldots, \\sigma_{K-1}$ are drawn from $\\mu_{\\Phi_{1}}, \\ldots, \\mu_{\\Phi_{K-1}}$ independently, $\\rho\\left(\\sigma_{[K-1]}\\right)$ concentrations around its mean with high probability.\n\nBy Lemma 6.9, one can draw $\\sigma_{[K-1]}$ from $\\mu_{[K-1]}$ randomly and set $x=\\max \\left\\{\\rho\\left(\\sigma_{[K-1]}\\right)-|P| / 6,0\\right\\}$ and $\\mathcal{N}=g(x,|P|)$. It is easy to verify that (22) holds. With $x$ and $\\mathcal{N}$, one can draw $\\sigma$ distributed approximately as $\\mu$ by repeating the following subroutine until success:\n\n- draw $\\sigma_{1}, \\cdots, \\sigma_{K-1}$ from $\\mu_{\\Phi_{1}}, \\cdots, \\mu_{\\Phi_{K-1}}$, independently.\n- if (21) is satisfied, draw a sample from $\\mu_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]$ and accept the sample as $\\tau$ with probability $\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right| / \\mathcal{N}$; otherwise, skip the last step.\n- if $\\tau$ is also a solution of $\\Phi\\left[\\sigma_{[K-1]}\\right]$, accept the concatenation of $\\sigma_{1}, \\ldots, \\sigma_{K-1}, \\tau$ as $\\sigma$.\n\nBy Lemma 6.8 and (22), one can draw $\\sigma \\sim \\mu_{\\Phi}$ with probability $1-\\varepsilon$ by repeating the above subroutine for poly $(n, 1 / \\varepsilon)$ rounds. This sampler is realized in Lines 11-25 of Algorithm 3.", "tables": {}, "images": {}}, {"section_id": 9, "text": "# 7. Analysis of the sample subroutine \n\nIn this section, we first analyze the $\\operatorname{Sample}(\\cdot)$ subroutine for the instance satisfying Conditions 6.4.\n7.1. The correctness of Sample subroutine. The following is the main theorem in this section.\n\nTheorem 7.1. Consider any instance satisfying Condition 6.4. Let $p_{\\max }=\\max _{C \\in \\mathcal{C}(P)} \\mathbb{P}_{\\Phi}(\\neg C)$. If either $p_{\\max }|P| \\Delta \\leq 1 / 4$ or $|P| \\geq 1728 \\mathrm{e}^{3} \\ln 2 \\cdot k^{3} L^{2} \\Delta^{6}$, the $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$ returns a random valid assignment $\\sigma$ of $\\Phi$ satisfying $d_{\\mathrm{TV}}\\left(\\sigma, \\mu_{\\Phi}\\right) \\leq \\varepsilon$ in time $\\widetilde{O}\\left(n^{4} / \\varepsilon^{2}\\right)$.\n\nAs mentioned in Section 6.2, the algorithmic techniques differ for the easy-to-handled factorized formulas and the challenging factorized formulas. These differences are captured by Lemmas 7.3 and 7.4, respectively, which imply Theorem 7.1 immediately. Before that, we first analyze the performance of the rejection sampling algorithm on the factorized formula, which serves as a basic subroutine throughout the sampling algorithm.\n\nLemma 7.2. Consider any instance satisfying Condition 6.4. For each $i \\in[K-1]$, we have\n\n$$\n\\mathbb{P}_{\\Phi_{i}}\\left[\\bigwedge_{C \\in \\mathcal{C}_{i}} C\\right] \\geq \\frac{\\varepsilon}{n}\n$$\n\nProof. By Condition 6.4, we have $\\left|\\mathcal{C}_{i}\\right| \\leq \\Delta \\log (n / \\varepsilon)$ for each $i \\in[K-1]$. Thus, we have\n\n$$\n\\mathbb{P}_{\\Phi_{i}}\\left[\\bigwedge_{C \\in \\mathcal{C}_{i}} C\\right] \\geq \\prod_{C \\in \\mathcal{C}_{i}}\\left(1-\\mathrm{e}_{\\Phi_{i}}[\\neg C]\\right) \\geq(1-\\mathrm{e} p)^{\\Delta \\log (n / \\varepsilon)} \\geq 2^{-\\log (n / \\varepsilon)}=\\frac{\\varepsilon}{n}\n$$\n\nwhere the first inequality holds by Lemma 3.3, and the last inequality holds by Proposition 3.11 and $2 \\mathrm{e} p \\Delta \\leq 1$.\n7.1.1. Analysis for the easy-to-handled factorized formulas. Suppose one of the following conditions holds: $2 \\mathrm{e} \\Delta \\leq \\log \\left(\\mathrm{e}^{4} n / \\varepsilon\\right)$ or $p_{\\max }|P| \\Delta \\leq 1 / 4$ where $p_{\\max }=\\max _{C \\in \\mathcal{C}(P)} \\mathbb{P}_{\\Phi}(\\neg C)$. As stated in Section 6.2, the accept-reject sampler exhibits a high acceptance rate, as shown in Lemma 6.6. Combining with Lemma 7.2, we obtain the following lemma.\n\nLemma 7.3. Consider any instance satisfying Condition 6.4, and suppose any of the following conditions hold: $2 \\mathrm{e} \\Delta \\leq \\log \\left(\\mathrm{e}^{4} n / \\varepsilon\\right)$ or $p_{\\max }|P| \\Delta \\leq 1 / 4$ where $p_{\\max }=\\max _{C \\in \\mathcal{C}(P)} \\mathbb{P}_{\\Phi}(\\neg C)$. The $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$ returns a random valid assignment $\\sigma$ of $\\Phi$ satisfying $d_{\\mathrm{TV}}(\\sigma, \\mu) \\leq \\varepsilon$. Furthermore, the time complexity of $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$ is $\\widetilde{O}\\left(n^{2} / \\varepsilon^{2}\\right)$.\nProof. We compare $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$ with the idealized rejection sampler, which repeats the following process for $T \\leftarrow\\left\\lceil\\mathrm{e}^{4} n / \\varepsilon \\cdot \\log (2 / \\varepsilon)\\right\\rceil$ times until success:\n\n- draw $\\sigma_{1}^{\\prime}, \\cdots, \\sigma_{K}^{\\prime}$ from $\\mu_{\\Phi_{1}}, \\cdots, \\mu_{\\Phi_{K}}$, independently;\n- accept the concatenation of $\\sigma_{1}^{\\prime}, \\ldots, \\sigma_{K}^{\\prime}$ as $\\sigma^{\\prime}$ if the concatenation is a solution of $\\Phi$.\n\nAccording to Lemmas 6.2 and 6.6, we have $d_{\\mathrm{TV}}\\left(\\sigma^{\\prime}, \\mu_{\\Phi}\\right) \\leq \\varepsilon / 2$.\nTo prove that $d_{\\mathrm{TV}}\\left(\\sigma, \\mu_{\\Phi}\\right) \\leq \\varepsilon$, it suffices to show that $d_{\\mathrm{TV}}\\left(\\sigma, \\sigma^{\\prime}\\right) \\leq \\varepsilon / 2$ by establishing a coupling according to the Lemma 3.5. Throughout the execution of $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$, let $\\mathcal{B}_{j}$ denote the event that there are some $i \\in[K-1]$ such that $\\sigma_{i}$ is returned at Line 4 in RejectionSampling $\\left(\\Phi_{i},\\lceil(n / \\varepsilon) \\cdot \\log (2 n T / \\varepsilon)\\rceil\\right)$ at the iteration $j$ for each $j \\in[T]$, and $\\mathcal{B} \\doteq \\bigcup_{j \\in[T]} \\mathcal{B}_{j}$. The random assignment $\\sigma$ and $\\sigma^{\\prime}$ can be coupled perfectly if $\\mathcal{B}$ does not occur. Consequently, the coupling error can be bounded by the probability of the event $\\mathcal{B}$. According to Lemma 7.2, 6.2, and the union bound, for each iteration $j \\in[T]$,\n\n$$\n\\operatorname{Pr}\\left[\\mathcal{B}_{j}\\right] \\leq \\sum_{i \\in[K-1]}\\left(1-\\frac{\\varepsilon}{n}\\right)^{\\lceil(n / \\varepsilon) \\cdot \\log (2 n T / \\varepsilon)\\rceil} \\leq \\sum_{i \\in[K-1]} \\frac{\\varepsilon}{2 n T} \\leq \\frac{\\varepsilon}{2 T}\n$$\n\nTherefore, the probability of $\\mathcal{B}$ can be bounded by $\\varepsilon / 2$.\nOne can verify that the running time of the algorithm is $\\widetilde{O}\\left(n^{2} / \\varepsilon^{2}\\right)$.\n\n7.1.2. Analysis for the challenging factorized formulas. In this part, we analyze $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$ subroutine given that $2 \\mathrm{e} \\Delta \\geq \\log \\left(\\mathrm{e}^{4} n / \\varepsilon\\right)$, and $p_{\\max }|P| \\Delta>1 / 4$ where $p_{\\max }=\\max _{C \\in \\mathcal{C}(P)} \\mathbb{P}_{\\Phi}[\\neg C]$. The main result is the following lemma.\nLemma 7.4. Consider instances satisfying Condition 6.4, and assume $|P| \\geq 1728 \\mathrm{e}^{3} \\ln 2 \\cdot k^{3} L^{2} \\Delta^{8}, 2 \\mathrm{e} \\Delta \\geq$ $\\log \\left(\\mathrm{e}^{4} n / \\varepsilon\\right), p_{\\max }|P| \\Delta>1 / 4$ where $p_{\\max }=\\max _{C \\in \\mathcal{C}(P)} \\mathbb{P}_{\\Phi}[\\neg C]$. The $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$ returns a random valid assignment $\\sigma$ of $\\Phi$ satisfying $d_{\\mathrm{TV}}(\\sigma, \\mu) \\leq \\varepsilon$. The time complexity of $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$ is $\\widetilde{O}\\left(n^{4} / \\varepsilon^{2}\\right)$.\n\nIn the subsequent discussion, we frequently refer to the instances satisfying the following condition.\nCondition 7.5. Let integer $\\Delta \\geq 1$. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $\\Delta_{\\Phi} \\leq \\Delta$ that cannot be further factorized to smaller formulas with a permutation set $P \\in \\mathcal{P}$. Let $\\Phi_{1}, \\ldots, \\Phi_{K}$ be the factorization of $(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C} \\backslash \\mathcal{C}(P))$ where $\\Phi_{K}=(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\emptyset)$, and $\\Phi_{i}=\\left(\\mathcal{P}_{i}, \\mathcal{Q}_{i}, \\mathcal{C}_{i}\\right)$ for each $i \\in[K-1]$.\n\nRecall the definitions of $\\Phi\\left[\\sigma_{[K-1]}\\right], \\Phi^{1}\\left[\\sigma_{[K-1]}\\right], \\rho\\left(\\sigma_{[K-1]}\\right)$ and $g(x, y)$ in Section 6.2. Consider any instance satisfying Condition 7.5. We use $\\Omega_{[K-1]}$ to denote the set of satisfying assignments $\\sigma_{[K-1]}$ for $\\Phi_{[K-1]}$. Given a subset of satisfying assignments $\\sigma_{[K-1]}$ of $\\Phi_{[K-1]}$, denoted as $\\widehat{\\Omega}$, we introduce the following idealized rejection sampler Algorithm 4, which is parameterized by $\\widehat{\\Omega}$, a positive integer $\\mathcal{N}$, and real numbers $\\alpha, \\beta \\in[0,1]$. This sampler is designed for the convenience of our analysis. We will prove Lemma 7.4 by comparing Algorithm 4 with Algorithm 3.\n\n```\nAlgorithm 4: \\(\\operatorname{IdealSample}(\\Phi, P, \\varepsilon)\\)\n    Input: a PDC formula \\(\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})\\), a permutation set \\(P \\in \\mathcal{P}\\) satisfying Condition 7.5, and a\n        parameter \\(0<\\varepsilon<1\\).\n    Output: a random valid assignment of \\(\\Phi\\)\n    1 Let \\(\\Phi_{1}, \\ldots, \\Phi_{K}\\) be the factorization of \\((\\mathcal{P}, \\mathcal{Q}, \\mathcal{C} \\backslash \\mathcal{C}(P))\\) where \\(\\Phi_{K}=(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\emptyset)\\);\n    \\(2 T \\leftarrow\\lceil 2 /(\\alpha \\beta) \\cdot \\log (6 / \\varepsilon)\\rceil\\);\n    3 for \\(j=1\\) to \\(T\\) do\n        draw \\(\\sigma_{1}, \\cdots, \\sigma_{K-1}\\) from \\(\\mu_{\\Phi_{1}}, \\cdots, \\mu_{\\Phi_{K-1}}\\) independently and uniformly at random;\n        if \\(\\sigma_{[K-1]} \\in \\widehat{\\Omega}\\) then\n            \\(\\Phi^{\\prime} \\leftarrow\\left(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\mathcal{C}\\left[\\sigma_{[K-1]}\\right]\\right), \\Phi^{\\prime \\prime} \\leftarrow\\left(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\mathcal{C}^{1}\\left[\\sigma_{[K-1]}\\right]\\right) ;\\)\n            draw a satisfying assignment \\(\\tau\\) of the formula \\(\\Phi^{\\prime \\prime}\\);\n            if \\(\\tau \\in \\Omega_{\\Phi^{\\prime}}\\) then\n                \\(r \\sim \\operatorname{Unif}[0,1]\\);\n                if \\(r \\leq\\left|\\Omega_{\\Phi^{\\prime \\prime}}\\right| / \\mathcal{N}\\) then\n                    return the concatenation of \\(\\sigma_{1}, \\ldots, \\sigma_{K-1}, \\tau\\) as \\(\\sigma\\);\n```\n\n12 return an arbitrary valid assignment $\\sigma$ of $\\Phi$;\n\nThe following lemma bounds the error of the idealized sampler in Algorithm 4.\nLemma 7.6. Consider any instance satisfying Condition 7.5. Assume $e p_{\\Phi} \\Delta \\leq 1$ and $|P| \\geq 5 \\Delta^{2}+2$. Given any non-empty subset $\\widehat{\\Omega} \\subseteq \\Omega_{[K-1]}$, a positive integer $\\mathcal{N}$, and $\\alpha, \\beta \\in[0,1]$ such that for any $\\sigma_{[K-1]} \\in \\widehat{\\Omega}$\n\n$$\n\\frac{|\\widehat{\\Omega}|}{\\left|\\Omega_{[K-1]}\\right|} \\geq \\alpha, \\quad \\beta \\leq \\frac{\\left|\\Omega_{\\Phi^{2}}\\left[\\sigma_{[K-1]}\\right]\\right|}{\\mathcal{N}} \\leq 1\n$$\n\nthe IdealSample $(\\Phi, P, \\epsilon)$ returns a random valid assignment of $\\Phi$ satisfying\n\n$$\nd_{\\mathrm{TV}}(\\sigma, \\mu) \\leq(1-\\alpha) \\cdot 2 \\sqrt{2 \\pi|P|} \\cdot \\exp (3+2 \\Delta)+\\varepsilon / 6\n$$\n\nProof. Let $\\widehat{\\Omega}_{0}$ be the subset of concatenation of satisfying assignments $\\sigma_{1}, \\sigma_{2}, \\cdots, \\sigma_{K}$ of $\\Phi_{K}$ such that $\\sigma[K-1] \\in \\widehat{\\Omega}$. In Algorithm 4, we can see that $\\sigma \\in \\widehat{\\Omega}_{0}$ when it is returned at Line 11. The probability\n\nthat the algorithm outputs $\\sigma$ is proportional to\n\n$$\n\\frac{|\\widehat{\\Omega}|}{\\left|\\Omega_{[K-1]}\\right|} \\cdot|\\widehat{\\Omega}|^{-1} \\cdot\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right|^{-1} \\cdot\\left|\\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}\\right| \\cdot\\left|\\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}\\right|^{-1} \\cdot \\frac{\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right|}{\\mathcal{N}}=\\frac{1}{\\left|\\Omega_{[K-1]}\\right| \\cdot \\mathcal{N}}\n$$\n\nwhich implies that $\\sigma$ follows the uniform distribution over all satisfying assignments in $\\widehat{\\Omega}_{0}$, conditioned on $\\sigma$ being returned at Line 11 .\n\nLet $E_{1}$ be the collection of satisfying assignments in $\\Omega \\backslash \\widehat{\\Omega}_{0}$, and $E_{2}$ be the event that $\\sigma$ is returned at Line 12 in Algorithm 4. By the coupling argument with Lemma 3.5, one can verify that\n\n$$\nd_{\\mathrm{TV}}(\\sigma, \\mu) \\leq \\mu\\left(E_{1}\\right)+\\operatorname{Pr}\\left[E_{2}\\right]\n$$\n\nwhere $\\operatorname{Pr}$ is the randomness in Algorithm 4. Therefore, it boils down to establishing the upper bounds for $\\mu\\left(E_{1}\\right)$ and $\\operatorname{Pr}\\left[E_{2}\\right]$.\n\nWe define $A$ and $B$ as the maximum and minimum sizes of $\\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}$, respectively, as follows:\n\n$$\nA \\doteq \\max _{\\sigma_{[K-1]} \\in \\Omega_{[K-1]}}\\left|\\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}\\right|, \\quad B \\doteq \\min _{\\sigma_{[K-1]} \\in \\Omega_{[K-1]}}\\left|\\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}\\right|\n$$\n\nAccording to Lemma 6.8, we have\n\n$$\nA \\leq \\max _{\\sigma_{[K-1]} \\in \\Omega_{[K-1]}}\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right| \\leq g(0,|P|)\n$$\n\nMeanwhile, by Lemma 6.7 and 6.8, we have\n\n$$\nB \\geq \\min _{\\sigma_{[K-1]} \\in \\Omega_{[K-1]}}\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right| \\cdot \\frac{|P|-1-2 \\Delta}{|P|-1} \\geq g(|P| \\Delta,|P|) \\cdot \\frac{|P|-1-2 \\Delta}{|P|-1} \\cdot \\frac{1}{\\sqrt{2 \\pi|P|} \\mathrm{e}^{2}}\n$$\n\nTherefore, it holds that\n\n$$\n\\begin{aligned}\n\\mu_{\\Phi}\\left(E_{1}\\right) & =\\left(\\sum_{\\sigma_{[K-1]} \\in \\Omega_{[K-1]} \\backslash \\widehat{\\Omega}}\\left|\\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}\\right|\\right) /\\left(\\sum_{\\sigma_{[K-1]} \\in \\Omega_{[K-1]}}\\left|\\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}\\right|\\right) \\\\\n& \\leq\\left(\\sum_{\\sigma_{[K-1]} \\in \\Omega_{[K-1]} \\backslash \\widehat{\\Omega}} A\\right) /\\left(\\sum_{\\sigma_{[K-1]} \\in \\Omega_{[K-1]}} B\\right) \\\\\n& \\leq\\left(1-\\frac{|\\widehat{\\Omega}|}{\\left|\\Omega_{[K-1]}\\right|}\\right) \\cdot \\frac{|P|-1}{|P|-1-2 \\Delta} \\cdot \\sqrt{2 \\pi|P|} \\mathrm{e}^{3} \\cdot\\left(1-\\frac{\\Delta}{|P|}\\right)^{-|P|} \\\\\n& \\leq(1-\\alpha) \\cdot 2 \\cdot \\sqrt{2 \\pi|P|} \\cdot \\exp (3+2 \\Delta) . \\quad \\text { (by } \\frac{|P|-1}{|P|-1-2 \\Delta} \\leq 2 \\text { and Proposition 3.11) }\n\\end{aligned}\n$$\n\nWe then consider the probability of the event $E_{2}$. Note that in each iteration of the loop $j$, the algorithm outputs $\\sigma$ at Line 11 with probability\n\n$$\n\\frac{|\\widehat{\\Omega}|}{\\left|\\Omega_{\\Phi_{[K-1]}}\\right|} \\cdot \\frac{\\left|\\Omega_{\\Phi\\left[\\sigma_{[K-1]}\\right]}\\right|}{\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right|} \\cdot \\frac{\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right|}{\\mathcal{N}} \\geq \\frac{\\alpha \\beta}{2}\n$$\n\nwhich holds by Lemma 6.7 and $\\frac{|P|-1-2 \\Delta}{|P|-1} \\geq \\frac{1}{2}$. Consequently, we have\n\n$$\n\\operatorname{Pr}\\left[E_{2}\\right] \\leq\\left(1-\\frac{\\alpha \\beta}{2}\\right)^{\\left\\lceil2 /(\\alpha \\beta) \\cdot \\log (6 / \\varepsilon)\\right\\rceil} \\leq \\varepsilon / 6\n$$\n\nPlugging the upper bound of $\\mu\\left(E_{1}\\right)$ and $\\operatorname{Pr}\\left[E_{2}\\right]$ in (25), the proof is immediate.\nNow we are ready to finish the proof of Lemma 7.4.\n\nProof of Lemma 7.4. We analyze $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$ by coupling Algorithm 3 and Algorithm 4.\nLet $B_{1}$ be the event that there exists some $i \\in[K-1]$ such that $\\sigma_{t}$ is returned at Line 4 in the subroutine RejectionSampling $\\left(\\Phi_{t}, \\lceil(n / \\varepsilon) \\cdot \\log (12 n / \\varepsilon)\\rceil\\right)$, some $t \\in[K-1]$ such that $\\sigma_{t}$ is returned at Line 4 in the subroutine RejectionSampling $\\left(\\Phi_{t}, \\lceil(n / \\varepsilon) \\cdot \\log (6 n T / \\varepsilon)\\rceil\\right)$, some $j \\in[T]$ such that\n\n$$\n\\widetilde{N} \\notin\\left[\\left(1-\\frac{\\varepsilon}{12 T}\\right) \\cdot\\left|\\Omega_{\\Phi^{\\prime \\prime}}\\right|,\\left(1+\\frac{\\varepsilon}{12 T}\\right) \\cdot\\left|\\Omega_{\\Phi^{\\prime \\prime}}\\right|\\right]\n$$\n\nin $j$-th iteration. According to Lemma 7.2 and union bound, one can verify that $\\operatorname{Pr}\\left[B_{1}\\right] \\leq 5 \\varepsilon / 12$. In addition, if the event $B_{1}$ does not occur, we have $\\sigma_{[K-1]} \\sim \\mu_{[K-1]}$ by Lemma 6.2, and the estimation of $\\left|\\Omega_{\\Phi^{\\prime \\prime}}\\right|$ with accuracy guarantee.\n\nWe also define $B_{2}$ as the event that\n\n$$\nx \\notin\\left[\\mathrm{E}_{\\sigma_{[K-1]} \\sim \\mu_{[K-1]}}\\left[\\rho\\left(\\sigma_{[K-1]}\\right)\\right]-\\left|P\\right| / 4, \\mathrm{E}_{\\sigma_{[K-1]} \\sim \\mu_{[K-1]}}\\left[\\rho\\left(\\sigma_{[K-1]}\\right)\\right]-\\left|P\\right| / 12\\right]\n$$\n\nBy Lemma 6.9, we have $\\operatorname{Pr}\\left[B_{2} \\mid \\overline{B_{1}}\\right] \\leq \\exp (-6 \\mathrm{e} \\ln 2 \\cdot \\Delta)$. Given that the event $B_{2}$ does not occur, for any $\\sigma_{[K-1]}$ such that\n\n$$\n\\left|\\rho\\left(\\sigma_{[K-1]}\\right)-\\mathrm{E}_{\\sigma_{[K-1]} \\sim \\mu_{[K-1]}}\\left[\\rho\\left(\\sigma_{[K-1]}\\right)\\right]\\right| \\leq|P| / 12\n$$\n\nit holds that\n\n$$\n\\rho\\left(\\sigma_{[K-1]}\\right)-|P| / 2 \\leq x \\leq \\rho\\left(\\sigma_{[K-1]}\\right)\n$$\n\nand $\\left|\\Omega_{\\Phi^{1}}\\left[\\sigma_{[K-1]}\\right]\\right| / \\mathcal{N} \\geq \\sqrt{2 \\pi|P|} \\mathrm{e}^{3}$ by Lemma 6.8. Again, by Lemma 6.9, we have\n\n$$\n\\operatorname{Pr}_{\\sigma_{[K-1]} \\sim \\mu_{[K-1]}}[x \\leq \\rho(\\sigma[K-1]) \\leq x+|P| / 2] \\geq 1-\\exp (-6 \\mathrm{e} \\ln 2 \\cdot \\Delta)\n$$\n\nThen we establish a coupling between $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$ and $\\operatorname{IdealSample}(\\Phi, P, \\varepsilon)$ given that the events $B_{1}$ and $B_{2}$ do not occur. Let $\\widetilde{\\Omega}=\\left\\{\\sigma_{[K-1]} \\in \\Omega_{\\Phi_{[K-1]}} \\mid x \\leq \\rho(\\sigma[K-1]) \\leq x+|P| / 2\\right\\}, \\mathcal{N}=g(x,|P|)$, $\\alpha=1-\\exp (-6 \\mathrm{e} \\ln 2 \\cdot \\Delta)$, and $\\beta=1 /\\left(\\sqrt{2 \\pi|P|} \\mathrm{e}^{3}\\right)$. One can verify that these satisfiying the conditions in Lemma 7.6 by the aforementioned properties given that $B_{2}$ does not occur. Let $\\tau_{1}$ be the assignment at Line 20 in $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$, and $\\tau_{2}$ be the assignment at Line 7 in Ideal $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$. The coupling is specified as follows:\n\n- share the randomness of assignment $\\sigma_{[K-1]}$ and $r$;\n- couple $\\tau_{1}, \\tau_{2}$ by the optimal coupling if $r \\leq\\left(1-\\frac{\\varepsilon}{12 T}\\right) \\cdot \\frac{\\left|\\Omega_{\\Phi^{\\prime \\prime}}\\right|}{\\mathcal{N}}$ or $r \\geq\\left(1+\\frac{\\varepsilon}{12 T}\\right) \\cdot \\frac{\\left|\\Omega_{\\Phi^{\\prime \\prime}}\\right|}{\\mathcal{N}}$.\n\nOne can verify that the coupling errors come from the event that $\\tau_{1} \\neq \\tau_{2}$ and\n\n$$\nr \\in\\left[\\left(1-\\frac{\\varepsilon}{12 T}\\right) \\cdot\\left|\\Omega_{\\Phi^{\\prime \\prime}}\\right| / \\mathcal{N},\\left(1+\\frac{\\varepsilon}{12 T}\\right) \\cdot\\left|\\Omega_{\\Phi^{\\prime \\prime}}\\right| / \\mathcal{N}\\right]\n$$\n\nBy Lemma 3.5, given that the event $B_{1}$ and $B_{2}$ do not occur, we have\n\n$$\nd_{\\mathrm{TV}}\\left(\\operatorname{Sample}(\\Phi, P, \\varepsilon), \\operatorname{IdealSample}(\\Phi, P, \\varepsilon)\\right) \\leq \\frac{\\varepsilon}{3}\n$$\n\nCombining all these with Lemma 7.6, we have\n\n$$\n\\begin{aligned}\nd_{\\mathrm{TV}}\\left(\\operatorname{Sample}\\left(\\Phi, P, \\varepsilon\\right), \\mu_{\\Phi}\\right) & \\leq \\frac{11 \\varepsilon}{12}+\\exp (-6 \\mathrm{e} \\ln 2 \\cdot \\Delta) \\cdot 2 \\sqrt{2 \\pi|P|} \\cdot \\exp (3+2 \\Delta)+\\exp (-6 \\mathrm{e} \\ln 2 \\cdot \\Delta) \\\\\n& \\leq \\frac{11 \\varepsilon}{12}+2 \\exp (-6 \\mathrm{e} \\ln 2 \\cdot \\Delta) \\cdot 2 \\sqrt{2 \\pi n} \\cdot \\exp (3+2 \\Delta) \\\\\n& \\leq \\varepsilon\n\\end{aligned}\n$$\n\n(by $2 \\mathrm{e} \\Delta \\geq \\log \\left(\\mathrm{e}^{4} n / \\varepsilon\\right)$ )\nAccording to Theorems 1.2 and 4.4, one can verify that the running time of Algorithm 3 is $\\widetilde{O}\\left(n^{4} / \\varepsilon^{2}\\right)$.", "tables": {}, "images": {}}, {"section_id": 10, "text": "# 8. Rapid mixing of the idealized permutation-wise Glauber dynamics \n\nGiven any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with width $k=k_{\\Phi}$, constraint degree $\\Delta=\\Delta_{\\Phi}$, and a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$, we show that the idealized permutation-wise Glauber dynamics in Section 5.2 is rapid mixing in an LLL-like regime in this section.\n\nLemma 8.1. The following holds for any sufficiently large $q_{\\min }$ and some constant $c>0$. Given any $P D C$ formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $q \\geq q_{\\min }$ with decomposition $\\mathcal{P}^{\\prime}$ satisfying Condition 6.1 and $\\varepsilon \\in(0,1)$, if $c p k^{128} \\Delta^{192} \\leq 1$, then the idealized permutation-wise Glauber dynamics $M_{\\text {Glauber }}$ defined in Section 5.2 satisfies\n\n$$\n\\tau_{\\min }\\left(M_{\\text {Glauber }}, \\varepsilon\\right) \\leq\\left\\lceil 2 n \\log \\frac{n}{\\varepsilon}\\right\\rceil\n$$\n\nMoreover, assume $\\Phi$ is $(k, q)$-uniform and the decomposition $\\mathcal{P}^{\\prime}$ satisfies $\\|P|-r \\mid=O(1)$ for each $P \\in \\mathcal{P}^{\\prime}$ and some integer $r$. If $k \\geq 24$ and $c k^{12} \\Delta^{16} \\leq r^{k}$, then (26) holds.\n\nIn the subsequent discussion, the proofs of some lemmas are deferred to Appendix D.\n8.1. Mixing time. As we mentioned in Lemma 5.7, the permutation-wise Glauber dynamics has the unique stationary distribution $v$. In this section, we apply the path coupling argument to establish the rapid mixing property of the idealized permutation-wise Glauber dynamics, subject to the condition stated in Lemma 8.1. Given any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a decomposition $\\mathcal{P}^{\\prime}=\\left(P_{1}^{\\prime}, \\cdots, P_{t}^{\\prime}\\right)$ of $\\mathcal{P}$, define\n$\\mathcal{V} \\doteq\\left\\{\\mathcal{Q}^{\\prime}=\\left(Q_{1}^{\\prime}, Q_{2}^{\\prime}, \\cdots, Q_{t}^{\\prime}\\right) \\mid \\forall i \\in[t],\\left|Q_{i}^{\\prime}\\right|=\\left|P_{i}^{\\prime}\\right|\\right.$ and $Q_{i}^{\\prime} \\subseteq \\mathcal{Q}(P)$ for the unique $P \\in \\mathcal{P}$ where $\\left.P_{i}^{\\prime} \\subseteq P\\right\\}$. By definition, the set $\\mathcal{V}$ contains all decompositions of $\\mathcal{Q}$ from $\\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$. In subsequent discussion, we instead analyze the extended permutation-wise Glauber dynamics $\\widetilde{M}_{\\text {Glauber }}$ on $\\mathcal{V}$. Given $\\mathcal{Q}^{\\prime} \\in \\mathcal{V}$, we pick $P \\in \\mathcal{P}$ uniformly at random, sample $\\sigma \\sim \\mu_{\\Phi^{\\prime}}$ where $\\Phi^{\\prime}=\\left(\\mathcal{P}^{\\prime} \\circ P, \\mathcal{Q}^{\\prime} \\circ \\mathcal{Q}(P), \\mathcal{C}\\right)$, and update its domains according to $\\sigma$. One can verify that the transition of $\\widetilde{M}_{\\text {Glauber }}$ on $\\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$ is consistent with $M_{\\text {Glauber }}$ and the stationary distribution of $\\widetilde{M}_{\\text {Glauber }}$ is $v$.\n\nAs mentioned in Section 3.3, to establish the rapid mixing property of the idealized permutation-wise Glauber dynamics, it suffices to define a pre-metric on $\\mathcal{V}$ and construct the couplings between transitions of $\\widetilde{M}_{\\text {Glauber }}$ conditioned on pairs in the pre-metric that exhibit contraction.\n\nPre-metric. We define the pre-metric $\\mathcal{G}=(\\mathcal{V}, \\mathcal{E})$ where\n\n$$\n\\mathcal{E} \\doteq\\left\\{\\left\\{\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}\\right\\} \\mid \\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime} \\in \\mathcal{V} \\text { and } \\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}}\\left|\\mathcal{Q}_{1}^{\\prime}\\left(P^{\\prime}\\right) \\backslash \\mathcal{Q}_{2}^{\\prime}\\left(P^{\\prime}\\right)\\right|=1\\right\\}\n$$\n\nBy Definition 3.6, one can verify that the weighted graph $\\mathcal{G}=(\\mathcal{V}, \\mathcal{E})$, where each $\\left\\{\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}\\right\\} \\in \\mathcal{E}$ is associated with weight 1 , is a pre-metric on $\\mathcal{V}$. Furthermore, the weighted shortest path distance metric induced by $\\mathcal{G}$ can be explicitly defined as the discrepancy between configurations in $\\mathcal{V}$, which is determined by evaluating the number of distinct elements within the domains of the permutation sets in $\\mathcal{P}^{\\prime}$. This can be defined as follows:\n\n$$\n\\forall \\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime} \\in \\mathcal{V}, S \\subseteq \\mathcal{P}^{\\prime}, \\quad \\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}, S\\right) \\doteq \\sum_{P^{\\prime} \\in S}\\left|\\mathcal{Q}_{1}^{\\prime}\\left(P^{\\prime}\\right) \\backslash \\mathcal{Q}_{2}^{\\prime}\\left(P^{\\prime}\\right)\\right|\n$$\n\nWith a slight abuse of notation, let $\\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}, P\\right) \\doteq \\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}, \\mathcal{P}^{\\prime}[P]\\right)$ for any permutation set $P \\in \\mathcal{P}$, and $\\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}\\right) \\doteq \\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}, \\mathcal{P}^{\\prime}\\right)$.\n\nLemma 8.2. For any $\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime} \\in \\mathcal{V}, \\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}\\right)$ is the weighted shortest path distance on $\\mathcal{G}$.\nOne-step coupling. Let $X_{1}^{\\prime}, X_{2}^{\\prime}$ be two domains of $\\mathcal{P}^{\\prime}$ satisfying $\\operatorname{Dis}\\left(X_{1}^{\\prime}, X_{2}^{\\prime}\\right)=1$. We shall construct a coupling of the one-step transitions of the extended permutation-wise Glauber dynamics $\\left(X_{1}^{\\prime}, X_{2}^{\\prime}\\right) \\rightarrow$ $\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}\\right)$ satisfying\n\n$$\n\\mathrm{E}\\left[\\operatorname{Dis}\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}\\right) \\mid\\left(X_{1}^{\\prime}, X_{2}^{\\prime}\\right)\\right] \\leq 1-\\frac{1}{2|\\mathcal{P}|}\n$$\n\nNote that for any $\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime} \\in \\mathcal{V}$, $\\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}\\right) \\leq \\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}}\\left|\\mathcal{Q}_{1}^{\\prime}\\left(P^{\\prime}\\right)\\right|=|V|$. Combined with (28), Lemma 8.1 is proved by Lemmas 3.7 and 5.7.\n\nFor any $\\left\\{X_{1}^{\\prime}, X_{2}^{\\prime}\\right\\} \\in \\mathcal{E}$, let $\\mathcal{I}$ denote the unique permutation set in $\\mathcal{P}^{\\prime}$ satisfying $\\left|X_{1}^{\\prime}(\\mathcal{I}) \\backslash X_{2}^{\\prime}(\\mathcal{I})\\right|=1$. We then specify the one-step coupling $\\left(X_{1}^{\\prime}, X_{2}^{\\prime}\\right) \\rightarrow\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}\\right)$ as follows:\n(1) Pick $P \\in \\mathcal{P}$ uniformly at random;\n(2) Let $\\Phi_{1}=\\left(\\mathcal{P}^{\\prime} \\circ P, X_{1}^{\\prime} \\circ \\mathcal{Q}(P), \\mathcal{C}\\right), \\Phi_{2}=\\left(\\mathcal{P}^{\\prime} \\circ P, X_{2}^{\\prime} \\circ \\mathcal{Q}(P), \\mathcal{C}\\right)$;\n(3) If $\\mathcal{I} \\subseteq P$, sample $\\sigma \\sim \\mu_{\\Phi_{1}}$, and set $Y_{1}^{\\prime}\\left(P^{\\prime}\\right)=\\sigma\\left(P^{\\prime}\\right)$ and $Y_{2}^{\\prime}\\left(P^{\\prime}\\right)=\\sigma\\left(P^{\\prime}\\right)$ for each $P^{\\prime} \\in \\mathcal{P}^{\\prime}$; Otherwise, sample $\\left(\\sigma_{1}, \\sigma_{2}\\right)$ jointly from a coupling of distributions $\\mu_{\\Phi_{1}}$ and $\\mu_{\\Phi_{2}}$, and set $Y_{1}^{\\prime}\\left(P^{\\prime}\\right)=$ $\\sigma_{1}\\left(P^{\\prime}\\right), Y_{2}^{\\prime}\\left(P^{\\prime}\\right)=\\sigma_{2}\\left(P^{\\prime}\\right)$ for each $P^{\\prime} \\in \\mathcal{P}^{\\prime}$.\nIt is easy to verify that the transitions $X_{1}^{\\prime} \\rightarrow Y_{1}^{\\prime}$ and $X_{2}^{\\prime} \\rightarrow Y_{2}^{\\prime}$ are both faithful copies of the $\\widetilde{M}_{\\text {Glauber }}$.\nAnalysis of the path coupling. The core technical aspect of path coupling lies in demonstrating the contraction of distance through one-step coupling of each pair of domains from the pre-metric. More precisely, we shall show that (28) holds for any $\\left\\{X_{1}^{\\prime}, X_{2}^{\\prime}\\right\\} \\in \\mathcal{E}$. Given any pair of formulas $\\left\\{X_{1}^{\\prime}, X_{2}^{\\prime}\\right\\} \\in$ $\\mathcal{E}$, we define the discrepancy $\\mathcal{D}_{P}$ of each permutation $P \\in \\mathcal{P}$ with respect to the one-step coupling $\\left(X_{1}^{\\prime}, X_{2}^{\\prime}\\right) \\rightarrow\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}\\right)$ as follows:\n\n$$\n\\mathcal{D}_{P}=\\mathrm{E}\\left[\\operatorname{Dis}\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}, P\\right) \\mid P \\text { is picked }\\right]\n$$\n\nBy definition, we have $\\mathcal{D}_{P}=0$ if $\\mathcal{I} \\subseteq P$. Then we have\n\n$$\n\\begin{aligned}\n\\mathrm{E}\\left[\\operatorname{Dis}\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}\\right) \\mid\\left(X_{1}^{\\prime}, X_{2}^{\\prime}\\right)\\right] & =1+\\frac{1}{|\\mathcal{P}|} \\sum_{P \\in \\mathcal{P}} \\mathcal{D}_{P}-\\frac{1}{|\\mathcal{P}|} \\\\\n& =1-\\frac{1}{|\\mathcal{P}|}\\left(1-\\sum_{P \\in \\mathcal{P}} \\mathcal{D}_{P}\\right)\n\\end{aligned}\n$$\n\nTo prove the inequality in (28), it is sufficient to prove the following lemma.\nLemma 8.3. For any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$ satisfying the condition in Lemma 8.1, there exists a collection of one-step couplings $\\left(X_{1}^{\\prime}, X_{2}^{\\prime}\\right) \\rightarrow\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}\\right)$ for any $\\left\\{X_{1}^{\\prime}, X_{2}^{\\prime}\\right\\} \\in \\mathcal{E}$ such that\n\n$$\n\\sum_{P \\in \\mathcal{P}} \\mathcal{D}_{P} \\leq \\frac{1}{2}\n$$\n\nwhere $\\mathcal{D}_{P}$ is defined in (29).\nThe remainder of this section is devoted to proving Lemma 8.3.\n8.2. Coupling construction. In this section, we clarify the one-step coupling construction stated in Lemma 8.3. Before that, we first introduce more notations.\n\nGiven any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}), \\mathcal{C}^{\\prime} \\subseteq \\mathcal{C}$, and $S \\subseteq V$, we use $\\Lambda\\left(\\mathcal{C}^{\\prime}, S\\right)$ to denote the set of forbidden values for the variables in $S$ imposed by the constraints in $\\mathcal{C}^{\\prime}$. Formally,\n\n$$\n\\Lambda\\left(\\mathcal{C}^{\\prime}, S\\right)=\\left\\{c \\mid \\exists C \\in \\mathcal{C}^{\\prime}, v \\in S \\cap \\mathrm{vbl}(C) \\text { such that the literal } v \\neq c \\text { appears in } C\\right\\}\n$$\n\nFor simplicity, we use the notation $\\Lambda(C, \\cdot)$ and $\\Lambda(\\cdot, v)$ to denote $\\Lambda(\\{C\\}, \\cdot)$ and $\\Lambda(\\cdot,\\{v\\})$ for any $C \\in \\mathcal{C}$, $v \\in V$, respectively.\n\nGiven any two formulas $\\Phi_{1}=\\left(\\mathcal{P}, \\mathcal{Q}_{1}, \\mathcal{C}_{1}\\right), \\Phi_{2}=\\left(\\mathcal{P}, \\mathcal{Q}_{2}, \\mathcal{C}_{2}\\right)$ and $P \\in \\mathcal{P}$, let $Q^{1}$ and $Q^{2}$ denote the domains of $P$ in $\\Phi_{1}$ and $\\Phi_{2}$, respectively. We say $P$ is active in $\\Phi_{1}$ and $\\Phi_{2}$ if $Q^{1} \\cap \\Lambda\\left(\\mathcal{C}_{1}, P\\right) \\neq$ $\\emptyset \\vee Q^{2} \\cap \\Lambda\\left(\\mathcal{C}_{2}, P\\right) \\neq \\emptyset$. Otherwise, we say $P$ is inactive in $\\Phi_{1}$ and $\\Phi_{2}$. We will omit $\\Phi_{1}$ and $\\Phi_{2}$ if they are clear from the context.\n\nThroughout this section, we fix positive integers $k, \\Delta$ and consider any formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $k_{\\Phi} \\leq k, \\Delta_{\\Phi} \\leq \\Delta$, and each $P \\in \\mathcal{P}$ is sufficiently large. Moreover, for any decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$ and any $P \\in \\mathcal{P}$, we will always assume that the partition $\\mathcal{P}^{\\prime}[P]=\\left(P_{1}, \\cdots, P_{\\ell}\\right)$ satisfies $\\left|P_{\\ell}\\right|-\\left|P_{j}\\right|=O(1)$. for each $P \\in \\mathcal{P}, i, j \\in[\\ell]$. We also fix positive integers $\\gamma, \\alpha$, which are the parameters in our one-step coupling construction. We will first introduce the coupling subroutines for the permutations in Section 8.2.1, which will serve as the key component of our one-step coupling algorithm in Section 8.2.2.\n\n8.2.1. Couplings for permutations. In this section, we introduce coupling subroutines for instances that satisfy the following condition, which will hold throughout the coupling algorithm in our later discussion.\n\nCondition 8.4. Let $p, p^{\\prime}, \\theta \\in(0,1)$ satisfy $p^{\\prime} \\leq p^{\\theta}, 8 \\mathrm{e} \\Delta p^{\\theta} \\leq 1$. Let $t$ be a positive integer. Given any two formulas $\\Phi_{1}=\\left(\\mathcal{P}, \\mathcal{Q}_{1}, \\mathcal{C}_{1}\\right), \\Phi_{2}=\\left(\\mathcal{P}, \\mathcal{Q}_{2}, \\mathcal{C}_{2}\\right)$ and any $P \\in \\mathcal{P}$ where $p_{\\Phi_{1}} \\leq p^{\\prime}, p_{\\Phi_{2}} \\leq p^{\\prime}$, let $\\mathcal{P}^{\\prime}$ be a decomposition of $\\mathcal{P}$ such that for each decomposition $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}_{1}^{\\prime}\\right)$ of $\\left(\\mathcal{P}, \\mathcal{Q}_{1}\\right)$ and each decomposition $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}\\right)$ of $\\left(\\mathcal{P}, \\mathcal{Q}_{2}\\right)$, we have $p_{\\Phi_{1}^{\\prime}}<_{q} p^{\\theta}, p_{\\Phi_{2}^{\\prime}}<_{q} p^{\\theta}$ where $\\Phi_{1}^{\\prime}=\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}_{1}^{\\prime}, \\mathcal{C}_{1}\\right), \\Phi_{2}^{\\prime}=\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}, \\mathcal{C}_{2}\\right)$. Assume that $\\mathcal{P}^{\\prime}[P]=\\left(P_{1}, \\cdots, P_{r}\\right)$ satisfies $\\left\\|P_{i}\\right\\|-t^{\\theta} \\mid=O(1)$ for each $i \\in[t]$. Let $T_{1} \\subseteq \\mathcal{Q}_{1}(P), T_{2} \\subseteq \\mathcal{Q}_{2}(P)$ be two sets where $\\left|T_{1}\\right|=\\left|T_{2}\\right| \\leq 1, \\mathcal{Q}_{1}(P) \\backslash T_{1}=\\mathcal{Q}_{2}(P) \\backslash T_{2}$.\n\nGiven the instances satisfying Condition 8.4, define the distributions $v^{1}, v^{2}, v_{i}^{1}, v_{i}^{2}$ where $i \\in[t]$ as follows\n\n$$\n\\begin{aligned}\n& \\forall Q_{1}, \\cdots, Q_{t}, \\quad v^{1}\\left(Q_{[t]}\\right) \\triangleq \\operatorname{Pr}_{\\sigma \\sim \\mu_{\\Phi_{1}}}\\left[\\sigma\\left(P_{i}\\right)=Q_{i} \\text { for all } i \\in[t]\\right] \\\\\n& \\forall Q_{1}, \\cdots, Q_{t}, \\quad v^{2}\\left(Q_{[t]}\\right) \\triangleq \\operatorname{Pr}_{\\sigma \\sim \\mu_{\\Phi_{2}}}\\left[\\sigma\\left(P_{i}\\right)=Q_{i} \\text { for all } i \\in[t]\\right] \\\\\n& \\forall Q, \\quad v_{i}^{1}(Q) \\triangleq \\operatorname{Pr}_{\\sigma \\sim \\mu_{\\Phi_{1}}}\\left[\\sigma\\left(P_{i}\\right)=Q \\mid T_{1} \\subseteq \\sigma\\left(P_{i}\\right)\\right], \\quad v_{i}^{2}(Q) \\triangleq \\operatorname{Pr}_{\\sigma \\sim \\mu_{\\Phi_{2}}}\\left[\\sigma\\left(P_{i}\\right)=Q \\mid T_{2} \\subseteq \\sigma\\left(P_{i}\\right)\\right]\n\\end{aligned}\n$$\n\nThe following lemma is useful in our later analysis, which provides an upper bound for the event that there exists some forbidden values in a permutation set.\n\nLemma 8.5. Given any instance satisfying Condition 8.4 with $T_{1}=T_{2}=\\emptyset$, we have\n\n$$\n\\forall i \\in[t], t \\in[2], \\quad \\operatorname{Pr}_{Q_{[t] \\sim v^{2}}}\\left[Q_{i} \\cap \\Lambda\\left(\\mathcal{C}_{t}, P_{i}\\right) \\neq \\emptyset\\right] \\leq \\frac{2 k \\Lambda\\left|P_{i}\\right|^{2}}{|P|}\n$$\n\nIn subsequent pages, we introduce the coupling of the distributions $v^{1}$ and $v^{2}$. Our strategy tries to couple the domain of the permutation set for some $i \\in[t]$ according to the distribution $v_{i}^{1}$ and $v_{i}^{2}$, which is specified in the $\\mathrm{CP}\\left(\\Phi_{1}, \\Phi_{2}, \\mathcal{P}^{\\prime}, P, P_{i}, t, T_{1}, T_{2}\\right)$ (Algorithm 5).\n\n```\nAlgorithm 5: \\(\\mathrm{CP}\\left(\\Phi_{1}, \\Phi_{2}, \\mathcal{P}^{\\prime}, P, P_{i}, t, T_{1}, T_{2}\\right)\\)\n    Succ \\(\\leftarrow\\) False;\n    if \\(t>\\gamma\\) then\n        \\(S \\leftarrow \\mathcal{Q}_{1}(P) \\backslash\\left(\\Lambda\\left(\\mathcal{C}_{1}, P_{i}\\right) \\cup \\Lambda\\left(\\mathcal{C}_{2}, P_{i}\\right) \\cup T_{1}\\right) ;\\)\n        \\(\\alpha \\leftarrow\\binom{|S|}{|P_{i}|-|T_{1}|} \\cdot\\left(\\left|P_{i}\\right|-\\left|T_{1}\\right|\\right)!\\cdot \\prod_{j=|T_{1}|}^{|P_{i}|-1}\\left(|P|-j-2 \\Delta\\right) /(|P|-j)^{2} ;\\)\n        \\(\\alpha \\leftarrow \\alpha \\cdot \\mathbb{1}\\left[T_{1} \\cap \\Lambda\\left(\\mathcal{C}_{1}, P_{i}\\right)=T_{2} \\cap \\Lambda\\left(\\mathcal{C}_{2}, P_{i}\\right)=\\emptyset\\right] ;\\)\n    else\n        \\(S \\leftarrow \\mathcal{Q}_{1}(P) \\backslash T_{1}, q \\leftarrow|P|-\\left|P_{i}\\right|+1, p^{\\prime} \\leftarrow p^{\\theta}\\left|P_{i}\\right| / q\\);\n        \\(\\alpha \\leftarrow\\left(\\left(1-4 q e p^{\\prime} \\Delta\\right) /\\left(1+4 e p^{\\prime} \\Delta\\right)\\right)^{\\left|P_{i}\\right|-\\left|T_{1}\\right|} ;\\)\n    draw \\(r \\sim \\operatorname{Unif}[0,1]\\);\n    if \\(r \\leq \\alpha\\) then\n        select a subset \\(T \\subseteq S\\) uniformly at random with $|T|=\\left|P_{i}\\right|-\\left|T_{1}\\right|\\);\n        \\(Q_{i}^{1} \\leftarrow T \\cup T_{1}, Q_{i}^{2} \\leftarrow T \\cup T_{2}\\);\n        if \\(t \\leq \\gamma\\) or \\(r \\geq 1-4 \\Delta\\left|P_{i}\\right| / \\ell\\) then Succ \\(\\leftarrow\\) True;\n    else\n        draw \\(Q_{i}^{1}\\) randomly so that its overall distribution aligns with \\(v_{i}^{1}\\);\n        draw \\(Q_{i}^{2}\\) randomly so that its overall distribution aligns with \\(v_{i}^{2}\\);\n    return \\(\\left(Q_{i}^{1}, Q_{i}^{2}\\right.\\), Succ \\()\\)\n```\n\nIn Algorithm 5, we apply different domain-coupling procedures according to the size of each permutation set. Specifically:\n\n- When $t>\\gamma$ (i.e., $P_{t}$ is \"large\"): We couple only the unforbidden values on $P_{t}$ from $\\mathcal{Q}_{1}(P)$ and $\\mathcal{Q}_{2}(P)$, using $\\alpha$ as a lower bound on the probability of successful coupling. In this setting, if $T_{1}=T_{2}=\\emptyset$ and $\\operatorname{Succ}$ becomes True, then $Q_{t}^{1} \\backslash T_{1}=Q_{t}^{2} \\backslash T_{2}$ and $P_{t}$ is inactive; consequently, no discrepancy can propagate beyond $P_{t}$ (whether through constraints on $P_{t}$ or the permutation set $P)$.\n- When $t \\leq \\gamma$ (i.e., $P_{t}$ is \"small\"): We couple the entire domain. In that case, if $T_{1}=T_{2}=\\emptyset$ and Succ is True, the discrepancy can propagate only through constraints on $P_{t}$.\nThe following lemma formalizes these observations.\nLemma 8.6. In Algorithm 5, if Succ $=$ True, then $Q_{t}^{1} \\backslash T_{1}=Q_{t}^{2} \\backslash T_{2}$ and $T_{1} \\subseteq Q_{t}^{1}, T_{2} \\subseteq Q_{t}^{2}$. In addition, if $T_{1}=T_{2}=\\emptyset$, Succ $=$ True and $t>\\gamma$, then all the constraints in $\\mathcal{C}_{1}\\left(P_{t}\\right) \\cup \\mathcal{C}_{2}\\left(P_{t}\\right)$ are satisfied under the condition that the variables in $P_{t}$ take values from $Q_{t}^{1}$ and $Q_{t}^{2}$.\nProof. If $\\operatorname{Succ}_{t}=$ True, then $Q_{t}^{1}$ and $Q_{t}^{2}$ must be assigned in Line 12. Thus, $Q_{t}^{1} \\backslash T_{1}=Q_{t}^{2} \\backslash T_{2}=T$. Furthermore, if $T_{1}=T_{2}=\\emptyset$, Succ $=$ True and $t>\\gamma$, we have $S \\cap \\Lambda\\left(\\mathcal{C}_{1}, P_{t}\\right)=\\emptyset$ and $Q_{t}^{1}=T$. Combined with $T \\subseteq S$, we have $Q_{t}^{1} \\cap \\Lambda\\left(\\mathcal{C}_{1}, P_{t}\\right)=\\emptyset$. For constraint $C \\in \\mathcal{C}_{1}\\left(P_{t}\\right)$, there is a vertex $v \\in P_{t} \\cap \\mathrm{vb}(C)$. Because $C$ is a disjunctive constraint, there is a value $c$ such that $C$ is satisfied if $v \\neq c$. Therefore, $c \\in \\Lambda\\left(\\mathcal{C}_{1}, P_{t}\\right)$. Combined with $Q_{t}^{1} \\cap \\Lambda\\left(\\mathcal{C}_{1}, P_{t}\\right)=\\emptyset$, we have $c \\notin Q_{t}^{1}$. Thus, $C$ is satisfied under the condition that the variables in $P_{t}$ take values from $Q_{t}^{1}$. The proof also works for constraint $C \\in \\mathcal{C}_{2}\\left(P_{t}\\right)$.\n\nIf the event Succ $=$ False occurs, even though the discrepancy might be curtailed, we treat it as having propagated and continue revealing additional domains of the permutation set.\n\nThe following lemma provides an upper bound for the probability of the event Succ $=$ False.\nLemma 8.7. Given any instance satisfying Condition 8.4 and $i \\in[\\ell]$, at Line 17 in Algorithm 5, $\\left(Q_{t}^{1}, Q_{t}^{2}\\right)$ is a coupling of $v_{t}^{1}, v_{t}^{2}$. In addition, we have\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Succ}=\\text { False }\\right]<_{q} \\begin{cases}4 \\Delta\\left|P_{t}\\right| / \\ell & \\text { if } t>\\gamma \\text { and } T_{1} \\cap \\Lambda\\left(\\mathcal{C}_{1}, P_{t}\\right)=T_{2} \\cap \\Lambda\\left(\\mathcal{C}_{2}, P_{t}\\right)=\\emptyset \\\\ 5 \\mathrm{e} \\Delta p^{\\theta}\\left|P_{t}\\right|^{2} & \\text { otherwise }\\end{cases}\n$$\n\nFurthermore, if $t>\\gamma$ and $\\ell \\geq 4 \\Delta\\left|P_{t}\\right|$, we have $\\operatorname{Pr}\\left[\\operatorname{Succ}=\\right.$ False $]=4 \\Delta\\left|P_{t}\\right| / \\ell$.\nGiven any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$, any $P \\in \\mathcal{P}$ and any decomposition $\\left(P_{\\{\\ell\\}^{\\prime}}^{\\prime} Q_{\\{\\ell\\}^{\\prime}}^{\\prime}\\right)$ of $(P, \\mathcal{Q}(P))$, with a little abuse of notations, let\n\n$$\n\\Phi\\left[P_{\\{\\ell\\}^{\\prime}}^{\\prime} Q_{\\{\\ell\\}^{\\prime}}^{\\prime}\\right] \\doteq\\left(\\mathcal{P} \\backslash\\{P\\} \\cup\\left\\{P_{\\{\\ell\\}^{\\prime}}^{\\prime}\\right\\}, \\mathcal{Q} \\backslash\\{\\mathcal{Q}(P)\\} \\cup\\left\\{Q_{\\{\\ell\\}^{\\prime}}^{\\prime}\\right\\}, \\mathcal{C}\\right)\n$$\n\nbe the formula induced by $\\Phi$ and $P_{\\{\\ell\\}^{\\prime}}^{\\prime} Q_{\\{\\ell\\}^{\\prime}}^{\\prime}$. Similarly, for any $i \\in[\\ell]$, with a little abuse of notations, let\n\n$$\n\\Phi\\left[P_{t}^{\\prime}, Q_{t}^{\\prime}\\right] \\doteq\\left(\\mathcal{P} \\backslash\\{P\\} \\cup\\left\\{P_{t}^{\\prime}, P \\backslash P_{t}^{\\prime}\\right\\}, \\mathcal{Q} \\backslash\\{\\mathcal{Q}(P)\\} \\cup\\left\\{Q_{t}^{\\prime}, \\mathcal{Q}(P) \\backslash Q_{t}^{\\prime}\\right\\}, \\mathcal{C}\\right)\n$$\n\nbe the formula induced by $\\Phi$ and $P_{t}^{\\prime}, Q_{t}^{\\prime}$.\nWe are now ready to introduce the coupling for domains of permutation sets.\nCouplings for permutations with equal domains. Given the instance satisfying Condition 8.4 with $T_{1}=T_{2}=\\emptyset$ and any $i \\in[\\ell]$, a coupling of $v^{1}, v^{2}$ is specified in $\\mathrm{CP}_{\\text {perm }}\\left(\\Phi_{1}, \\Phi_{2}, \\mathcal{P}^{\\prime}, P, P_{t}, t\\right)$ (Algorithm 6).\n\nIn Algorithm 6, we first call the coupling subroutine $\\mathrm{CP}(\\cdot)$ on $P_{t}$. According to Lemma 8.6, if Succ $=$ True, the discrepancy cannot propagate through the permutation on $P$. In this case, we return $P_{t}$, which corresponds to the variables with an assigned domain. Otherwise, if Succ $=$ False, the discrepancy propagates through the permutation on $P$. Thus, we attempt to assign domains to the entire permutation $P$. Moreover, we return $P$ and $S \\cup\\left\\{P_{t}\\right\\}$, where $P$ contains the variables with assigned domains and $S \\cup\\left\\{P_{t}\\right\\}$ records the active permutation sets.\n\nThe analysis of our coupling algorithm is presented in the following lemma, which can be easily verify by Lemma 8.7\nLemma 8.8. Given any instance satisfying Condition 8.4 with $T_{1}=T_{2}=\\emptyset$ and any $i \\in[\\ell]$, in Algorithm 6, either $\\left(Q_{\\{\\ell\\}^{\\prime}}^{1} Q_{\\{\\ell\\}^{\\prime}}^{2}\\right)$ is a coupling of $v^{1}, v^{2}$ at Line 7 or $\\left(Q_{t}^{1}, Q_{t}^{2}\\right)$ is a coupling of $v_{t}^{1}, v_{t}^{2}$ at Line 9. In addition, if $t>\\gamma$ and $\\ell \\geq 4 \\Delta\\left|P_{t}\\right|$, then $\\operatorname{Pr}\\left[\\operatorname{Succ}=\\right.$ False $]=4 \\Delta\\left|P_{t}\\right| / \\ell$.\n\n```\n\\(\\operatorname{CP}_{\\text {perm }}\\left(\\Phi_{1}, \\Phi_{2}, \\mathcal{P}^{\\prime}, P, P_{t}, t\\right)\\)\n    initialize \\(Q_{\\{\\ell\\}}^{1}\\) and \\(Q_{\\{\\ell\\}}^{2}\\) arbitrarily;\n    \\(\\left(Q_{1}^{1}, Q_{i}^{2}\\right.\\), Succ \\(\\left.) \\leftarrow \\mathrm{CP}\\left(\\Phi_{1}, \\Phi_{2}, \\mathcal{P}^{\\prime}, P, P_{t}, t, \\emptyset, \\emptyset\\right)\\right)\\)\n    if Succ \\(=\\) False then\n        sample \\(Q_{\\{\\ell\\} \\backslash\\{i\\}}^{1}\\) such that \\(Q_{\\{\\ell\\}}^{1} \\sim v^{1}\\);\n        sample \\(Q_{\\{\\ell\\} \\backslash\\{i\\}}^{2}\\) such that \\(Q_{\\{\\ell\\}}^{2} \\sim v^{2}\\);\n        \\(S \\leftarrow\\left\\{P_{j} \\mid j \\in[\\ell], P_{j}\\right.\\) is active \\(\\}\\);\n        \\(\\operatorname{return}\\left(\\Phi_{1}\\left[\\mathcal{P}^{\\prime}[P], Q_{\\{\\ell\\}}^{1}\\right], \\Phi_{2}\\left[\\mathcal{P}^{\\prime}[P], Q_{\\{\\ell\\}}^{2}\\right], P, S \\cup\\left\\{P_{t}\\right\\}\\right)\\);\n    else\n        \\(\\left\\{\\right.\\) return \\(\\left.\\left(\\Phi_{1}\\left[P_{t}, Q_{t}^{1}\\right], \\Phi_{2}\\left[P_{t}, Q_{t}^{2}\\right], P_{t}, \\emptyset\\right\\}\\right)\\).\n```\n\nCouplings for permutations with different domains. Given any instance satisfying Condition 8.4 with $p^{\\prime}=p, t=|P|, T_{1}=\\left\\{c_{1}\\right\\}, T_{2}=\\left\\{c_{2}\\right\\}$, we use $f_{1}, f_{2}$ to denote the distributions where\n\n$$\n\\forall j \\in[\\ell], \\quad f_{1}(j)=\\operatorname{Pr}_{\\sigma \\sim \\mu_{\\varepsilon_{1}}}\\left[c_{1} \\in \\sigma\\left(P_{j}\\right)\\right], f_{2}(j)=\\operatorname{Pr}_{\\sigma \\sim \\mu_{\\varepsilon_{2}}}\\left[c_{2} \\in \\sigma\\left(P_{j}\\right)\\right]\n$$\n\nFor any $j \\in[\\ell]$, let $V_{j}$ be the set of variables $v \\in P_{j}$ such that there exist some constraints $C \\in \\mathcal{C}$ which contains the literal $v=c_{1}$ or $v=c_{2}$. Define\n\n$$\n\\begin{aligned}\n& f_{\\min }(j) \\doteq \\max \\left\\{(1+4 \\mathrm{e} \\Delta p)\\left|P_{j}\\right| /|P|-4 \\mathrm{e} \\Delta p\\left|P_{j}\\right|,\\left(\\left|P_{j}\\right|-\\left|V_{j}\\right|\\right) \\cdot\\left(|P|-2 \\Delta\\right) /|P|^{2}\\right\\} \\\\\n& f_{\\max }(j) \\doteq(1+4 \\mathrm{e} p \\Delta)\\left|P_{j}\\right| /|P|\n\\end{aligned}\n$$\n\nThe following lemma establishes bounds for $f_{1}$ and $f_{2}$. The following lemma establishes bounds for $f_{1}$ and $f_{2}$.\nLemma 8.9. For $f_{1}, f_{2}$ defined in (36), we have for any $j \\in[\\ell]$,\n\n$$\nf_{\\min }(j) \\leq \\min \\left\\{f_{1}(j), f_{2}(j)\\right\\} \\leq \\max \\left\\{f_{1}(j), f_{2}(j)\\right\\} \\leq f_{\\max }(j)\n$$\n\nProof. The lemma is immediate from Lemma D.1, Lemma D. 2 and the Union bound.\n\n```\nAlgorithm 7: InitialCouple \\(\\left(\\Phi_{1}, \\Phi_{2}, \\mathcal{P}^{\\prime}, P\\right)\\)\n    initialize \\(Q_{\\{\\ell\\}}^{1}\\) and \\(Q_{\\{\\ell\\}}^{2}\\) arbitrarily and let \\(S \\leftarrow \\emptyset\\);\n    let \\((i, j)\\) be sampled from a coupling of \\(\\left(f_{1}, f_{2}\\right)\\) where \\(\\operatorname{Pr}[i=j=r] \\geq f_{\\min }(r)\\) for each \\(r \\in[\\ell]\\);\n    if \\(i=j\\) then\n        \\(\\left(Q_{i}^{1}, Q_{i}^{2}\\right.\\), Succ \\(\\left.) \\leftarrow \\mathrm{CP}\\left(\\Phi_{1}, \\Phi_{2}, \\mathcal{P}^{\\prime}, P, P_{t},|P|,\\left\\{c_{1}\\right\\},\\left\\{c_{2}\\right\\}\\right)\\right)\\)\n        if Succ \\(=\\) False then\n            sample \\(Q_{\\{\\ell\\} \\backslash\\{i\\}}^{1}\\) such that \\(Q_{\\{\\ell\\}}^{1} \\sim v^{1}\\);\n            sample \\(Q_{\\{\\ell\\} \\backslash\\{i\\}}^{2}\\) such that \\(Q_{\\{\\ell\\}}^{2} \\sim v^{2}\\);\n        else\n            if \\(P_{t}\\) is active then \\(S \\leftarrow\\left\\{P_{t}\\right\\}\\);\n            \\(\\left\\{\\right.\\) return \\(\\left(\\Phi_{1}\\left[P_{t}, Q_{t}^{1}\\right], \\Phi_{2}\\left[P_{t}, Q_{t}^{2}\\right], P_{t}, S\\right\\}\\);\n    else\n        sample \\(Q_{\\{\\ell\\}}^{1}\\) such that \\(Q_{\\{\\ell\\}}^{1}\\) follows the condition distribution of \\(v^{1}\\) conditional on \\(c_{1} \\in Q_{t}\\);\n        sample \\(Q_{\\{\\ell\\}}^{2}\\) such that \\(Q_{\\{\\ell\\}}^{2}\\) follows the condition distribution of \\(v^{2}\\) conditional on \\(c_{2} \\in Q_{j}\\);\n    \\(S \\leftarrow\\left\\{P_{t} \\mid t \\in[\\ell], P_{t}\\right.\\) is active \\(\\}\\);\n    return \\(\\left(\\Phi_{1}\\left[\\mathcal{P}^{\\prime}[P], Q_{\\{\\ell\\}}^{1}\\right], \\Phi_{2}\\left[\\mathcal{P}^{\\prime}[P], Q_{\\{\\ell\\}}^{2}\\right], P, S\\right)\\);\n```\n\nThe coupling of $v^{1}, v^{2}$ is specified in InitialCouple $\\left(\\Phi_{1}, \\Phi_{2}, \\mathcal{P}^{\\prime}, P\\right)$ (Algorithm 7). At Line 2 in the Algorithm 7, the existence of such a coupling of $\\left(f_{1}, f_{2}\\right)$ is by Lemma 8.9.\n\nIn Algorithm 7, we first try to assign $c_{1}, c_{2}$ to the same permutation set among $\\mathcal{P}^{\\prime}[P]$. If $c_{1}, c_{2}$ have not been assigned to the same permutation set, we assign the entire permutation and return 5 , which corresponds to the collection of permutation sets that could potentially propagate the discrepancy. Otherwise, if $c_{1}, c_{2}$ have been assigned to the same permutation set, we implement a similar coupling strategy as $\\mathrm{CP}_{\\text {perm }}(\\cdot)$ subroutine, conditioned on $c_{1}, c_{2}$ being assigned in $P_{i}$ respectively.\n\nThe following lemma bounds the expected number of permutation sets in $P$ that could propagate the discrepancy and its proof is deferred to Appendix D.3.\nCondition 8.10. The following holds for $\\theta \\in(0,1 / 2], p, \\gamma$ and $P$ :\n(a) if $|P| \\leq \\gamma$, then $\\left.5 \\mathrm{e} p^{\\theta}|P|^{3 \\theta} \\leq 1, \\mathrm{e}\\left(p|P|^{2}+p^{\\theta}|P|^{1+2 \\theta}\\right) \\min \\left\\{2 \\Delta|P|^{2 \\theta-1}, 1\\right\\} \\leq 1\\right)$;\n(b) if $|P|>\\gamma$, then $|P|^{2 \\theta} \\min \\left\\{2 \\Delta|P|^{2 \\theta-1}, 1\\right\\} \\leq 1$.\n\nLemma 8.11. Given any instance satisfying Condition 8.4 with $p_{\\Phi_{1}} \\leq p, p_{\\Phi_{2}} \\leq p,|P|=t, T_{1}=\\left\\{c_{1}\\right\\}, T_{2}=$ $\\left\\{c_{2}\\right\\}$ and Condition 8.10, we have\n\n$$\n\\mathrm{E}\\left\\{\\sum_{P^{\\prime} \\in S}\\left|P^{\\prime}\\right|\\right\\}<_{q}(36 k+4) \\Delta\n$$\n\n8.2.2. One-step coupling construction. We complete the one-step coupling construction in this section.\n\nLet $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ be any PDC formula with a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$ satisfying Condition 6.1. Let $\\left\\{X_{1}^{\\prime}, X_{2}^{\\prime}\\right\\} \\in \\mathcal{E}$ and let $\\mathcal{I}$ denote the unique permutation set in $\\mathcal{P}^{\\prime}$ for which $\\left|X_{1}^{\\prime}(\\mathcal{I}) \\backslash X_{2}^{\\prime}(\\mathcal{I})\\right|=1$. Consider a constant $\\theta$ such that either $\\theta=\\eta$ or $2 \\theta \\leq \\eta$; a $\\theta / \\eta$-decomposition $\\mathcal{D}$ of $\\mathcal{P}^{\\prime}$; a $\\theta$-decomposition $\\mathcal{D}^{\\prime}$ of $\\mathcal{P}^{\\prime}$; and a parameter $\\alpha \\leq L$. For sufficiently large $q_{\\min }$ with $q_{\\min } \\leq q_{\\Phi}$, the existence of the decompositions $\\mathcal{D}$ and $\\mathcal{D}^{\\prime}$ is guaranteed. Our one-step coupling is specified by $\\operatorname{Couple}\\left(\\Phi, \\mathcal{P}^{\\prime}, X_{1}^{\\prime}, X_{2}^{\\prime}, \\mathcal{I}, \\theta, \\alpha\\right)$ (see Algorithm 8).\n\nThe core idea behind our coupling strategy is to eliminate the discrepancy by assigning domains to the sub-permutation sets in each $P \\in \\mathcal{P}^{\\prime}$ and ensuring that the boundary constraints are satisfied, thereby halting further discrepancy propagation. We denote by $V_{\\text {set }}$ the set of variables whose domains have been assigned in the corresponding permutation sets in $\\mathcal{P}_{\\theta}$ during the coupling process. Our goal is to prevent the discrepancy from spreading from $V_{\\text {set }}$ to $V \\backslash V_{\\text {set }}$.\n\nIn our framework, the discrepancy can propagate in two distinct ways:\n\n- Type-I discrepancy: For some $P \\in \\mathcal{P}^{\\prime}$, there exists a sub-permutation set $P^{\\prime} \\in \\mathcal{P}_{\\theta}[P]$ within $V_{\\text {set }}$ whose assigned domain differs between the coupled configurations. In this case, the discrepancy propagates through $P$.\n- Type-II discrepancy: For some constraint $C \\in \\mathcal{C}$ that involves variables from both $V_{\\text {set }}$ and $V \\backslash V_{\\text {set }}$, if $C$ is not satisfied, the discrepancy can propagate through $C$.\nWe sequentially reveal the domains of the permutation sets in $\\mathcal{P}^{\\dagger}$ and couple them by invoking the subroutines InitialCouple $(\\cdot)$ and $\\mathrm{CP}_{\\text {perm }}(\\cdot)$. For Type-I discrepancies, our coupling strategy, described previously via InitialCouple $(\\cdot)$ and $\\mathrm{CP}_{\\text {perm }}(\\cdot)$, reveals the entire permutation $P$; hence, we only need to track the Type-II discrepancy. Specifically, we employ $\\mathcal{C}_{u}$ to collect the constraints that could potentially contribute to a Type-II discrepancy, and we use $\\mathcal{P}_{u}$ to gather the permutation sets that might propagate the discrepancy through their associated constraints.\n\nFor technical reasons, our coupling strategy differs depending on whether the permutation set selected for update, denoted by $\\mathcal{L}$, is considered \"large\" or \"small\" (as determined by the parameter $\\alpha$ ). If $|\\mathcal{L}| \\geq \\alpha$, we remove the constraints associated with $\\mathcal{L}$ from $\\mathcal{C}_{u}$ to avoid assigning domains in $\\mathcal{L}$ when alternative choices are available. We then apply a more sophisticated coupling on $\\mathcal{L}$ to bound its discrepancy until no constraint in $\\mathcal{C} \\backslash \\mathcal{C}(\\mathcal{L})$ intersects both $V_{\\text {set }}$ and $V \\backslash V_{\\text {set }}$. Conversely, if $|\\mathcal{L}|<\\alpha$, we treat the constraints on $\\mathcal{L}$ the same as all other constraints during the coupling procedure.\n\nOur coupling process continues when there are constraints in $\\mathcal{C}_{u}$ that intersect both $V_{\\text {set }}$ and $V \\backslash V_{\\text {set }}$. In that case, we select one such constraint along with an unassigned permutation set associated with it and update its domains using the $\\mathrm{CP}_{\\text {perm }}(\\cdot)$ subroutine (see Lines 20 and 21). After updating the domains, we update both $\\mathcal{C}_{u}$ and $\\mathcal{P}_{u}$. One subtle detail is that some assigned permutation sets are not initially added to $\\mathcal{P}_{u}$ because they were coupled via $\\mathrm{CP}_{\\text {perm }}(\\cdot)$; however, these sets can still propagate discrepancy through unsatisfied constraints. Therefore, we add them to $\\mathcal{P}_{u}$ at Line 18.\n\nIn Algorithm 8, we also maintain several sets to facilitate discrepancy analysis. Specifically, we let $\\mathcal{P}_{\\mathcal{P}}^{*}$ denote the collection of sub-permutation sets in $\\mathcal{P}_{\\theta}$ that failed to couple in the subroutine $\\mathrm{CP}(\\cdot)$. Additionally, we let $\\mathcal{P}_{\\perp}$ represent the set of all \"bad\" sub-permutation sets in $\\mathcal{P}_{\\theta}$, namely those that are either active or have failed to couple in $\\mathrm{CP}(\\cdot)$. We further define the sets $\\mathcal{C}_{s}$ and $\\mathcal{C}_{\\perp}$ as follows:\n\n$$\n\\mathcal{C}_{s} \\triangleq\\left\\{C \\in \\mathcal{C} \\mid P \\in \\mathcal{Z} \\text { for each } P \\in \\mathcal{P}_{\\theta} \\text { on } C\\right\\}\n$$\n\n$\\mathcal{C}_{\\perp} \\triangleq\\left\\{C \\in \\mathcal{C}_{s} \\mid \\operatorname{vbl}(C) \\subseteq V_{\\text {set }}, C\\right.$ is unsatisfied in $\\Phi_{1}$ or $\\Phi_{2}$, no $\\left.P \\in \\mathcal{P}_{\\perp}\\right.$ is on $\\left.C\\right\\}$.\nIn other words, $\\mathcal{C}_{s}$ is the set of constraints in $\\mathcal{C}$ whose associated sub-permutation sets in $\\mathcal{P}_{\\theta}$ are all \"small\", while $\\mathcal{C}_{\\perp}$ consists of those constraints in $\\mathcal{C}_{s}$ that remain unsatisfied despite having no associated \"bad\" sub-permutation sets.\n\n```\nAlgorithm 8: Couple \\(\\left(\\Phi, \\mathcal{P}^{\\prime}, X_{1}^{\\prime}, X_{2}^{\\prime}, \\mathcal{I}, \\theta, \\alpha\\right)\\)\n    Input: a PDC formula \\(\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})\\), a decomposition \\(\\mathcal{P}^{\\prime}\\) of \\(\\mathcal{P}\\) satisfying Condition 6.1, a pair\n        of domains \\(\\left\\{X_{1}^{\\prime}, X_{2}^{\\prime}\\right\\} \\in \\mathcal{E}, \\mathcal{I} \\in \\mathcal{P}^{\\prime}\\) where \\(\\left[X_{1}^{\\prime}(\\mathcal{I}) \\backslash X_{2}^{\\prime}(\\mathcal{I})\\right]=1\\), a constant \\(\\theta\\) where \\(\\theta=\\eta\\) or\n        \\(2 \\theta \\leq \\eta\\), a \\(\\theta / \\eta\\)-decomposition \\(\\mathcal{D}\\) of \\(\\mathcal{P}^{\\prime}\\) and a \\(\\theta\\)-decomposition \\(\\mathcal{D}^{\\prime}\\) of \\(\\mathcal{P}^{\\prime}\\), and \\(\\alpha \\leq L\\).\n    Output: a pair of domains \\(\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}\\right)\\).\n    pick a permutation set \\(\\mathcal{L}\\) from \\(\\mathcal{P}\\) uniformly at random;\n    \\(2 \\mathcal{P}^{\\dagger} \\leftarrow \\mathcal{P}^{\\prime} \\backslash \\mathcal{P}^{\\prime}[\\mathcal{L}] \\cup\\{\\mathcal{L}\\}\\)\n    \\(\\Phi_{1} \\leftarrow\\left(\\mathcal{P}^{\\dagger}, X_{1}^{\\prime} \\backslash X_{1}^{\\prime}\\left(\\mathcal{P}^{\\prime}[\\mathcal{L}]\\right) \\cup\\{\\mathcal{Q}(\\mathcal{L})\\}, \\mathcal{C}\\right), \\Phi_{2} \\leftarrow\\left(\\mathcal{P}^{\\dagger}, X_{2}^{\\prime} \\backslash X_{2}^{\\prime}\\left(\\mathcal{P}^{\\prime}[\\mathcal{L}]\\right) \\cup\\{\\mathcal{Q}(\\mathcal{L})\\}, \\mathcal{C}\\right)\\);\n    \\(4 \\mathcal{C}_{u} \\leftarrow\\left\\{C \\in \\mathcal{C} \\mid C\\right.\\) is unsatisfied in \\(\\Phi_{1}\\) or \\(\\Phi_{2}\\}\\);\n    if \\(\\mathcal{I} \\subseteq \\mathcal{L}\\) then\n        \\(\\sigma_{1} \\leftarrow\\) a random solution of \\(\\Phi_{1}, \\sigma_{2} \\leftarrow \\sigma_{1}\\);\n    else\n        if \\(\\|\\mathcal{L}\\| \\geq \\alpha\\) then\n            \\(\\mathcal{C}_{u} \\leftarrow \\mathcal{C}_{u} \\backslash \\mathcal{C}(\\mathcal{L}), \\mathcal{P}_{\\theta} \\leftarrow \\mathcal{D}^{\\prime}, A \\leftarrow\\left\\{P \\in \\mathcal{P}^{\\prime}| | P \\mid \\leq \\gamma\\right\\}, \\mathcal{Z} \\leftarrow \\cup_{P \\in A} \\mathcal{D}^{\\prime}[P] ;\\)\n        else\n            \\(\\mathcal{P}_{\\theta} \\leftarrow \\mathcal{D}^{\\prime} \\backslash \\mathcal{D}^{\\prime}[\\mathcal{L}] \\cup \\mathcal{D}[\\mathcal{L}], A \\leftarrow\\left\\{P \\in \\mathcal{P}^{\\dagger}| | P \\mid \\leq \\gamma\\right\\}, \\mathcal{Z} \\leftarrow \\cup_{P \\in A} \\mathcal{P}_{\\theta}[P] ;\\)\n        \\(\\left(\\Phi_{1}, \\Phi_{2}, V_{\\text {set }}^{\\prime}, \\mathcal{P}_{0}\\right) \\leftarrow\\) InitialCouple \\(\\left(\\Phi_{1}, \\Phi_{2}, \\mathcal{P}_{\\theta}, \\mathcal{I}\\right)\\);\n        \\(V_{\\text {set }} \\leftarrow V_{\\text {set }}^{\\prime}, \\mathcal{P}_{u} \\leftarrow \\mathcal{P}_{0}, \\mathcal{P}_{\\perp} \\leftarrow \\mathcal{P}_{0}, \\mathcal{P}_{\\perp}^{\\prime} \\leftarrow \\mathcal{P}_{0}\\);\n        while True do\n            for each \\(C \\in \\mathcal{C}_{u}\\left(V_{\\text {set }}^{\\prime}\\right)\\) do\n                if \\(C\\) is satisfied in both \\(\\Phi_{1}\\) and \\(\\Phi_{2}\\) or \\(\\operatorname{vbl}(C) \\subseteq V_{\\text {set }}\\) then \\(\\mathcal{C}_{u} \\leftarrow \\mathcal{C}_{u} \\backslash\\{C\\}\\);\n                if \\(\\operatorname{vbl}(C) \\subseteq V_{\\text {set }}\\) and \\(C\\) is unsatisfied in \\(\\Phi_{1}\\) or \\(\\Phi_{2}\\) then\n                \\(\\left.\\quad \\mathcal{P}_{u} \\leftarrow \\mathcal{P}_{u} \\cup\\{P \\in \\mathcal{Z} \\mid C \\in \\mathcal{C}(P)\\}\\right)\\)\n            if \\(\\exists C \\in \\mathcal{C}_{u} \\cap \\mathcal{C}\\left(P^{*}\\right)\\) for some \\(P^{*} \\in \\mathcal{P}_{u}\\) then\n                let \\(C\\) be the first such constraint and \\(v\\) be the first variable in \\(\\operatorname{vbl}(C) \\backslash V_{\\text {set }}\\);\n                let \\(P^{\\prime} \\in \\mathcal{P}_{\\theta}[P]\\) for some \\(P \\in \\mathcal{P}^{\\dagger}\\) be the unique permutation set in \\(\\mathcal{P}_{\\theta}\\) where \\(v \\in P^{\\prime}\\);\n                \\(\\left(\\Phi_{1}, \\Phi_{2}, V_{\\text {set }}^{\\prime}, \\mathcal{P}_{\\perp}^{\\prime}\\right) \\leftarrow \\mathrm{CP}_{\\text {perm }}\\left(\\Phi_{1}, \\Phi_{2}, \\mathcal{P}_{\\theta}, P \\backslash V_{\\text {set }}, P^{\\prime},|P|\\right)\\);\n                \\(V_{\\text {set }} \\leftarrow V_{\\text {set }} \\cup V_{\\text {set }}^{\\prime}, \\mathcal{P}_{\\perp} \\leftarrow \\mathcal{P}_{\\perp} \\cup \\mathcal{P}_{\\perp}^{\\prime}, \\mathcal{P}_{u} \\leftarrow \\mathcal{P}_{u} \\cup \\mathcal{P}_{\\perp}^{\\prime}, \\mathcal{P}_{\\perp}^{\\prime} \\leftarrow \\mathcal{P}_{\\perp}^{\\prime} \\cup\\left(\\mathcal{P}_{\\perp}^{\\prime} \\cap\\left\\{P^{\\prime}\\right\\}\\right)\\);\n            else\n                \\(\\left(\\sigma_{1}, \\sigma_{2}\\right) \\leftarrow\\) the coupling of \\(\\mu_{\\Phi_{1}}, \\mu_{\\Phi_{2}}\\) where \\(\\mathrm{E}\\left[\\sum_{P \\in \\mathcal{P}^{\\prime}\\{\\mathcal{L}\\}} \\mid \\sigma_{1}(P) \\backslash \\sigma_{2}(P)\\right]]\\) is minimal;\n                break;\n    \\(27 Y_{1}^{\\prime}\\left(P^{\\prime}\\right) \\leftarrow \\sigma\\left(P^{\\prime}\\right)\\) and \\(Y_{2}^{\\prime}\\left(P^{\\prime}\\right) \\leftarrow \\sigma\\left(P^{\\prime}\\right)\\) for each \\(P^{\\prime} \\in \\mathcal{P}^{\\prime}\\);\n    return \\(\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}\\right)\\)\n```\n\nLet $\\mathcal{P}_{u}^{i}$ denote the updated $\\mathcal{P}_{u}$ at Line 19 during the $i$-th iteration of the while loop from Line 14 to Line 26 in Algorithm 8. Similarly, let $\\mathcal{P}_{\\perp}^{i}, \\Phi_{1}^{i}, \\Phi_{2}^{i}$ and $V_{\\text {set }}^{i}$ denote the updated $\\mathcal{P}_{\\perp}, \\Phi_{1}, \\Phi_{2}$ and $V_{\\text {set }}$ at Line 19 during the $i$-th iteration of the while loop, respectively. Additionally, define\n\n$$\n\\mathcal{C}_{\\perp}^{i} \\triangleq\\left\\{C \\in \\mathcal{C}_{s} \\mid \\operatorname{vbl}(C) \\subseteq V_{\\text {set }}^{i}, C \\text { is unsatisfied in } \\Phi_{1}^{i} \\text { or } \\Phi_{2}^{i}\\right.\\), no \\(\\left.P \\in \\mathcal{P}_{\\perp}^{i}\\right) \\text { is on } C\\}\n$$\n\nWe have the following simple observations for Algorithm 8.\nObservation 8.12. The following conditions are satisfied by Algorithm 8:\n\n- $\\mathcal{P}_{\\perp} \\subseteq \\mathcal{P}_{\\theta}, \\mathcal{C}_{\\perp} \\subseteq \\mathcal{C}_{s}$, and $C \\subseteq V_{\\text {set }}$ for each $C \\in \\mathcal{C}_{\\perp}$;\n- for any $P \\in \\mathcal{P}_{\\perp}$ and any $C \\in \\mathcal{C}(P)$, we have $C \\notin \\mathcal{C}_{\\perp}$;\n- for the $C$ and $P^{\\prime}$ in Lines 20-21 of Algorithm 8, we have $C \\in \\mathcal{C}\\left(P^{\\prime}\\right)$.\n\nOne can verify that the correctness of the coupling algorithm as follows.\nLemma 8.13. In Algorithm 8, $\\left\\{X_{1}^{\\prime}, X_{2}^{\\prime}\\right\\} \\rightarrow\\left\\{Y_{1}^{\\prime}, Y_{2}^{\\prime}\\right\\}$ is a one-step coupling of the extended permutationwise Glauber dynamics $\\widetilde{M}_{\\text {Glauber }}$.\nProof. One can verify that for any input instance of the subroutine InitialCouple $(\\cdot)$ and $\\mathrm{CP}_{\\text {perm }}(\\cdot)$, Condition 8.4 holds. Therefore, the lemma follows immediately from the Lemma 8.8 and Lemma 8.11.\n8.3. Discrepancy Analysis. In this section, we present a probabilistic analysis that yields quantitative bounds on the discrepancy using witness combinatorial structures, thereby completing the proof of Lemma 8.3.\n\nThe witness in Algorithm 8 can be characterized by the combinatorial structure over the permutations $\\mathcal{P}_{\\theta}$ and the constraints $\\mathcal{C}_{s}$. We emphasize that the random variable $\\mathcal{P}_{\\theta}$ in Algorithm 8 depends on $\\mathcal{L}$. The following definition captures the propagation between these units. The discrepancy can propagate through the entire permutation, and this can be captured as follows:\n\n$$\n\\mathcal{E}_{P} \\triangleq\\left\\{\\left(P_{1}, P_{2}\\right) \\mid \\exists P \\in \\mathcal{P}^{\\prime} \\text { s.t. } P_{1}, P_{2} \\in \\mathcal{P}_{\\theta}[P]\\right\\}\n$$\n\nMeanwhile, the discrepancy can also propagate through the constraints as follows:\n\n$$\n\\mathcal{E}_{C} \\doteq\\left\\{\\left(C_{1}, C_{2}\\right) \\mid\\left(C_{1}, C_{2} \\in \\mathcal{C}\\right) \\wedge\\left(\\exists P \\in \\mathcal{Z} \\text { s.t. } C_{1}, C_{2} \\in \\mathcal{C}(P)\\right)\\right\\}\n$$\n\nFor any subsets $S_{1}, S_{2} \\subseteq \\mathcal{P}_{\\theta}$, let $\\mathcal{E}_{P}\\left(S_{1}, S_{2}\\right)$ denote the set $\\left\\{(u, v) \\mid u \\in S_{1}, v \\in S_{2},(u, v) \\in \\mathcal{E}_{P}\\right\\}$. The discrepancy propagation can then be captured by the propagation trajectory.\nDefinition 8.14 (propagation trajectory). For each $u, v \\in \\mathcal{P}_{\\theta} \\cup \\mathcal{C}$ such that $u \\neq v$ and each $t \\geq 0$, a sequence $\\left(u=v_{0}, v_{1}, v_{2}, \\ldots, v_{t+1}=v\\right)$ is called a propagation trajectory from $u$ to $v$ with length $t$ if the following holds:\n\n- $\\left(v_{i}, v_{i+1}\\right) \\in \\mathcal{E}_{C}$ for each $i \\in[t-1]$;\n- either $u \\in \\mathcal{P}_{\\theta}$ and $v_{1} \\in \\mathcal{C}(u)$, or $\\left(u, v_{1}\\right) \\in \\mathcal{E}_{C}$;\n- either $v \\in \\mathcal{P}_{\\theta}$ and $v_{t} \\in \\mathcal{C}(v)$, or $\\left(v_{t}, v\\right) \\in \\mathcal{E}_{C}$.\n\nFor each $u, v \\in \\mathcal{P}_{\\theta} \\cup \\mathcal{C}$ where $u \\neq v$, let $d(u, v)$ denote the minimum length of the propagation trajectory from $u$ to $v$. For any $S_{1}, S_{2} \\subseteq \\mathcal{P}_{\\theta} \\cup \\mathcal{C}$ and $t \\geq 0$, let $\\mathcal{S}\\left(S_{1}, S_{2}, t\\right)$ denote $\\left\\{(u, v) \\mid u \\in S_{1}, v \\in S_{2}, d(u, v)=t\\right\\}$. For simplicity, we further use $\\mathcal{S}^{*}\\left(S_{1}, S_{2}, t\\right)$ to denote $\\bigcup_{0 \\leq i \\leq t} \\mathcal{S}\\left(S_{1}, S_{2}, i\\right)$.\n\nWith these definitions and notations, we define the witness as follows.\nDefinition 8.15 (witness sequence). A witness sequence, or w.s. for short, is a sequence $\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ where $v_{0} \\in \\mathcal{P}_{\\theta}[\\mathcal{I}]$ and the following conditions hold for each $i \\in[t]$ and $0 \\leq j<i$ :\n\n- $\\left(\\left(v_{i-1}, v_{i}\\right) \\in \\mathcal{E}_{P} \\wedge i>1\\right)$ or $\\left(v_{i-1}, v_{i}\\right) \\in \\mathcal{S}^{*}\\left(\\mathcal{P}_{\\theta} \\cup \\mathcal{C}_{s}, \\mathcal{P}_{\\theta} \\cup \\mathcal{C}_{s}, 2\\right)$;\n- $\\left(v_{i} \\neq v_{j}\\right) \\wedge\\left(\\left(v_{i}, v_{j}\\right) \\notin \\mathcal{E}_{C}\\right) \\wedge\\left(v_{i} \\notin \\mathcal{C}\\left(v_{j}\\right)\\right.$ if $v_{j} \\in \\mathcal{P}_{\\theta}\\right) \\wedge\\left(\\left(v_{i}, v_{j}\\right) \\notin \\mathcal{E}_{P}\\right.$ if $\\left.j \\in[i-2]\\right)$.\n\nGiven any w.s. $s=\\left(v_{0}, \\cdots, v_{t}\\right)$, define\n\n$$\nV_{P}(s) \\doteq\\left\\{v_{i} \\in \\mathcal{P}_{\\theta} \\mid 1<i \\leq t,\\left(v_{i-1}, v_{i}\\right) \\in \\mathcal{E}_{P}\\right\\}, \\quad V_{C}(s) \\doteq\\left\\{v_{i} \\in \\mathcal{P}_{\\theta} \\backslash V_{P}(s) \\mid i \\in[t]\\right\\}\n$$\n\nwhere collect the permutations in $v_{1}, \\cdots, v_{t}$. We use $V_{P}, V_{C}$ to denote $V_{P}(s), V_{C}(s)$ if $s$ is clear from the context. We say $s=\\left(v_{0}, \\cdots, v_{t}\\right)$ occurs if $v_{0} \\in \\mathcal{P}_{0}, V_{C} \\subseteq \\mathcal{P}_{\\perp}^{*}$, and $v_{i} \\in \\mathcal{C}_{\\perp} \\cup \\mathcal{P}_{\\perp} \\backslash \\mathcal{P}_{0}$ for each $i \\in[t]$.\n\nLet $\\mathcal{R} \\doteq\\{P \\in \\mathcal{P} \\mid \\mathcal{I} \\nsubseteq P,|P| \\leq \\alpha\\}$ and $\\overline{\\mathcal{R}}=\\{P \\in \\mathcal{P} \\mid \\mathcal{I} \\nsubseteq P,|P|>\\alpha\\}$. Define the subsets of witness sequences as follows:\n\n- Consider the case where $\\mathcal{P}_{\\theta}=\\mathcal{D}^{\\prime}$. Let $\\mathcal{W}$ denote the set of all witness sequences. For any $P \\in \\mathcal{D}^{\\prime} \\backslash \\mathcal{Z}$, let $\\mathcal{W}[P]$ denote $\\left\\{\\left(v_{0}, \\cdots, v_{t}\\right) \\in \\mathcal{W} \\mid v_{t}=P\\right\\}$. For any $P \\in \\mathcal{D}^{\\prime} \\cap \\mathcal{Z}$, let $\\mathcal{W}[P]$ denote $\\left\\{\\left(v_{0}, \\cdots, v_{t}\\right) \\in \\mathcal{W} \\mid v_{t}=P\\right.$ or $\\left(v_{t}, P\\right) \\in \\mathcal{S}^{*}\\left(\\mathcal{D}^{\\prime} \\cup \\mathcal{C}, \\mathcal{Z}, 1\\right)\\} ;$\n\n- For any $P \\in \\mathcal{R}, P^{\\prime} \\in \\mathcal{D}[P]$, let $\\mathcal{W}\\left[P, P^{\\prime}\\right]$ be the witness sequences $\\left(v_{0}, \\cdots, v_{t}=P^{\\prime}\\right)$ under $\\mathcal{L}=P$.\n\nWe shall reduce the discrepancy analysis to the probabilistic analysis of witness sequences via the following witness percolation lemma and its proof is deferred to Appendix D.4.1.\nLemma 8.16 (Witness percolation). For each $P \\in \\mathcal{P}_{u} \\backslash \\mathcal{P}_{0}$, there exists a w.s. $\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ occurring in Algorithm 8 where $v_{t}=P$ or $\\left(v_{t}, P\\right) \\in \\mathcal{S}^{*}\\left(\\mathcal{P}_{\\theta} \\cup \\mathcal{C}_{s}, \\mathcal{Z}, 1\\right)$. In addition, if $P \\in \\mathcal{P}_{\\perp}$ or $P \\notin \\mathcal{Z}$, then $v_{t}=P$.\n\nBy Lemma 8.16, we have the following two corollaries immediately.\nCorollary 8.17. Given any $P \\in \\mathcal{P}, P^{\\prime} \\in \\mathcal{D}^{\\prime}[P]$ where $\\mathcal{I} \\nsubseteq P$ and $|P|>\\alpha$, assume $\\mathcal{L}=P$ and $P^{\\prime} \\in \\mathcal{P}_{u}$. Then there exists a w.s. in $\\mathcal{W}\\left[P^{\\prime}\\right]$ occurring in Algorithm 8.\nCorollary 8.18. Given any $P \\in \\mathcal{P}, P^{\\prime} \\in \\mathcal{D}[P]$ where $\\mathcal{I} \\nsubseteq P$ and $|P| \\leq \\alpha$, assume $\\mathcal{L}=P$ and $P^{\\prime} \\in \\mathcal{P}_{\\perp}$. Then there exists a w.s. in $\\mathcal{W}\\left[P, P^{\\prime}\\right]$ occurring in Algorithm 8.\n\nWith these facts, we are now ready to bound the discrepancy. We deal with the discrepancy analysis for the permutation sets in $\\mathcal{R}$ and $\\overline{\\mathcal{R}}$ in Lemmas 8.19 and 8.21 , respectively.\nLemma 8.19. We have\n\n$$\n\\sum_{P \\in \\mathcal{R}} \\mathrm{E}\\left[\\operatorname{Dis}\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}, \\mathcal{L}\\right) \\mid \\mathcal{L}=P\\right] \\leq \\sum_{P \\in \\mathcal{R}} \\sum_{P^{\\prime} \\in \\mathcal{D}[P]} \\sum_{s \\in \\mathcal{W}\\left[P, P^{\\prime}\\right]} \\operatorname{Pr}\\left[s \\text { occurs } \\mid \\mathcal{L}=P\\right]\\left|P^{\\prime}\\right|\n$$\n\nProof. Assume $\\mathcal{L}=P$ for some $P \\in \\mathcal{R}$. According to Line 11 in Algorithm 8, we have $\\mathcal{P}_{\\theta}=$ $\\mathcal{D}^{\\prime} \\backslash \\mathcal{D}^{\\prime}[P] \\cup \\mathcal{D}[P]$. Given $\\Phi_{1}, \\Phi_{2}$ at Line 25 , let $\\left(\\tau_{1}, \\tau_{2}\\right)$ be a coupling of $\\mu_{\\Phi_{1}}, \\mu_{\\Phi_{2}}$ where $\\tau_{1}\\left(P^{\\prime}\\right)=\\tau_{2}\\left(P^{\\prime}\\right)$ for each $P^{\\prime} \\in \\mathcal{D}[P] \\backslash \\mathcal{P}_{\\perp}$. According to the construction of $\\mathcal{P}_{\\perp}$, one can verify that $\\mathcal{P}_{\\perp} \\subseteq V_{\\text {set }}$ and the values on the variables in $V \\backslash V_{\\text {set }}$ can be coupled. Moreover, for any permutation set $P \\in \\mathcal{P}_{\\theta} \\backslash \\mathcal{P}_{\\perp}$, it is assigned by the same domains in $\\Phi_{1}$ and $\\Phi_{2}$. Therefore, the existence of coupling follows immediately. Therefore, we have\n\n$$\n\\sum_{P^{\\prime} \\in \\mathcal{D}[P]}\\left|\\tau_{1}\\left(P^{\\prime}\\right) \\backslash \\tau_{2}\\left(P^{\\prime}\\right)\\right| \\leq \\sum_{P^{\\prime} \\in \\mathcal{D}[P] \\cap \\mathcal{P}_{\\perp}}\\left|P^{\\prime}\\right|\n$$\n\nBy $\\mathcal{D}$ is a $\\theta / \\eta$-decomposition of $\\mathcal{P}^{\\prime}$, we have $\\mathcal{D}[P]$ is a a $\\theta / \\eta$-decomposition of $\\mathcal{P}^{\\prime}[P]$. Thus, we have\n\n$$\n\\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]}\\left|\\tau_{1}\\left(P^{\\prime}\\right) \\backslash \\tau_{2}\\left(P^{\\prime \\prime}\\right)\\right| \\leq \\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]} \\sum_{P^{\\prime} \\in \\mathcal{D}\\left[P^{\\prime}\\right]}\\left|\\tau_{1}\\left(P^{\\prime}\\right) \\backslash \\tau_{2}\\left(P^{\\prime}\\right)\\right|=\\sum_{P^{\\prime} \\in \\mathcal{D}[P]}\\left|\\tau_{1}\\left(P^{\\prime}\\right) \\backslash \\tau_{2}\\left(P^{\\prime}\\right)\\right| \\leq \\sum_{P^{\\prime} \\in \\mathcal{D}\\left[P^{\\prime}\\right] \\cap \\mathcal{P}_{\\perp}}\\left|P^{\\prime}\\right|\n$$\n\nwhere the last inequality holds by (40). Thus, under the condition $\\mathcal{L}=P$, we have\n\n$$\n\\mathrm{E}\\left[\\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]}\\left|\\tau_{1}\\left(P^{\\prime \\prime}\\right) \\backslash \\tau_{2}\\left(P^{\\prime \\prime}\\right)\\right|\\right] \\leq \\mathrm{E}\\left[\\sum_{P^{\\prime} \\in \\mathcal{D}[P] \\cap \\mathcal{P}_{\\perp}}\\left|P^{\\prime}\\right|\\right]=\\sum_{P^{\\prime} \\in \\mathcal{D}[P]} \\operatorname{Pr}\\left[P^{\\prime} \\in \\mathcal{P}_{\\perp}\\right]\\left|P^{\\prime}\\right|\n$$\n\nwhere the expectation is taken over the random variables $\\Phi_{1}, \\Phi_{2}, \\tau_{1}, \\tau_{2}$. Moreover, by Lemma 8.16, for each $P^{\\prime} \\in \\mathcal{P}_{\\perp}$, there exists a w.s. $\\left(v_{0}, v_{1}, \\cdots, v_{t}=P^{\\prime}\\right)$ occurring. Therefore,\n\n$$\n\\mathrm{E}\\left[\\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]}\\left|\\tau_{1}\\left(P^{\\prime \\prime}\\right) \\backslash \\tau_{2}\\left(P^{\\prime \\prime}\\right)\\right|\\right] \\leq \\sum_{P^{\\prime} \\in \\mathcal{D}[P]} \\sum_{s \\in \\mathcal{W}\\left[P, P^{\\prime}\\right]} \\operatorname{Pr}\\left[s \\text { occurs } \\mid \\mathcal{L}=P\\right]\\left|P^{\\prime}\\right|\n$$\n\nGiven any $\\Phi_{1}$ and $\\Phi_{2},\\left(\\sigma_{1}, \\sigma_{2}\\right)$ is an optimal coupling of $\\mu_{\\Phi_{1}}, \\mu_{\\Phi_{2}}$ where $\\mathrm{E}\\left[\\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]}\\left|\\sigma_{1}\\left(P^{\\prime \\prime}\\right) \\backslash \\sigma_{2}\\left(P^{\\prime \\prime}\\right)\\right|\\right]$ is minimal according to Line 25 . Thus, we have\n\n$$\n\\begin{aligned}\n\\mathrm{E}\\left[\\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]}\\left|\\sigma_{1}\\left(P^{\\prime \\prime}\\right) \\backslash \\sigma_{2}\\left(P^{\\prime \\prime}\\right)\\right|\\right] & \\leq \\mathrm{E}\\left[\\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]}\\left|\\tau_{1}\\left(P^{\\prime \\prime}\\right) \\backslash \\tau_{2}\\left(P^{\\prime \\prime}\\right)\\right|\\right] \\\\\n& \\leq \\sum_{P^{\\prime} \\in \\mathcal{D}[P]} \\sum_{s \\in \\mathcal{W}\\left[P, P^{\\prime}\\right]} \\operatorname{Pr}\\left[s \\text { occurs } \\mid \\mathcal{L}=P\\right]\\left|P^{\\prime}\\right|\n\\end{aligned}\n$$\n\nCombined with Line 28 and the definition of Dis in (27), we have\n\n$$\n\\mathrm{E}\\left[\\operatorname{Dis}\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}, P\\right)\\right]=\\mathrm{E}\\left[\\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]}\\left|\\sigma_{1}\\left(P^{\\prime \\prime}\\right) \\backslash \\sigma_{2}\\left(P^{\\prime \\prime}\\right)\\right|\\right] \\leq \\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]} \\sum_{s \\in \\mathcal{W}\\left[P, P^{\\prime}\\right]} \\operatorname{Pr}\\left[s \\text { occurs } \\mid \\mathcal{L}=P\\right]\\left|P^{\\prime}\\right|\n$$\n\nBy summing over different $P \\in \\mathcal{R}$, the lemma is immediate.\nBefore we introduce Lemma 8.21, we need more notations.\nDefinition 8.20. For any w.s. $s=\\left(v_{0}, \\cdots, v_{t}\\right)$, define\n\n$$\n\\begin{aligned}\n\\zeta & \\doteq 6000 \\Delta k^{3} d^{3} \\gamma^{2 \\theta} \\\\\nf(s) & = \\begin{cases}\\left|v_{t}\\right| k^{2} d^{2} \\gamma^{\\theta} & \\text { if } v_{t} \\in \\mathcal{P}_{\\theta} \\\\\nk^{2} d^{2} \\gamma^{2 \\theta} & \\text { otherwise }\\end{cases} \\\\\n\\widehat{f}(s) & = \\begin{cases}\\left|v_{t}\\right| \\zeta & \\text { if } v_{t} \\in \\mathcal{P}_{\\theta} \\\\\n\\gamma^{\\theta} \\zeta & \\text { otherwise }\\end{cases}\n\\end{aligned}\n$$\n\nOne can verify that $\\widehat{f}(s)$ is an upper bound of $f(s)$. Then we have the following lemma, the proof of which is deferred to Appendix D.4.2.\nLemma 8.21. We have\n\n$$\n\\sum_{P \\in \\bar{\\mathcal{R}}} \\mathrm{E}\\left[\\operatorname{Dis}\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}, \\mathcal{L}\\right) \\mid \\mathcal{L}=P\\right] \\leq 100 k d \\Delta^{2} \\alpha^{-1} \\sum_{s \\in V \\nu} f(s) \\max _{P^{\\prime} \\in \\mathcal{P}} \\operatorname{Pr}\\left[s \\text { occurs } \\mid \\mathcal{L}=P^{\\prime}\\right]\n$$\n\nBy Lemmas 8.19 and 8.21, it is crucial to establish the bounds for the probability of occurrence for a specific w.s.. As the coupling algorithm exhibits different properties on different components in the w.s., we shall first deal with the components separately. For any fixed $\\mathcal{I}$ and any given $P \\in \\mathcal{P}^{\\dagger}, P^{\\prime} \\in \\mathcal{P}_{\\theta}[P]$, define\n\n$$\n\\lambda_{1}\\left(P^{\\prime}\\right)=\\min \\left\\{30 k \\Delta|P|^{2 \\theta-1}, 1\\right\\}, \\quad \\lambda_{2}\\left(P^{\\prime}\\right)= \\begin{cases}30 \\Delta|P|^{2 \\theta-1}, & \\text { if }|P| \\geq \\gamma \\\\ 15 \\Delta p^{\\theta}|P|^{2 \\theta}, & \\text { otherwise }\\end{cases}\n$$\n\nFurthermore, the parameters $p, \\theta$ and $\\gamma$ will guarantee that if $|P| \\leq \\gamma$, then\n\n$$\n\\lambda_{2}\\left(P^{\\prime}\\right) \\leq \\lambda_{1}\\left(P^{\\prime}\\right)\n$$\n\nWe then define the function $\\rho$ for each w.s. $s=\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ as follows:\n\n$$\n\\rho(s)=p^{(1-\\theta)\\left(t-\\left|V_{P}\\right|-\\left|V_{C}\\right|\\right)} \\cdot \\operatorname{Pr}\\left[v_{0} \\in \\mathcal{P}_{0}\\right] \\prod_{v \\in V_{P}} \\lambda_{1}(v) \\prod_{v \\in V_{C}} \\lambda_{2}(v)\n$$\n\nThe following lemma shows that the upper bound of the probability for the w.s. occurrence can be bounded by $\\rho$. For each $v \\in V_{P}$, one can verify that $v \\in \\mathcal{P}_{\\perp} \\backslash \\mathcal{P}_{0}$ with probability at most $\\lambda_{1}(v)$ by Lemma 8.5. For any $v \\in V_{C}$, one can verify that $v \\in \\mathcal{P}_{\\perp}^{\\star}$ if the w.s. occurs, and the probability is bounded by $\\lambda_{2}(v)$ according to Lemma 8.7. As for the constraints in $\\mathcal{C}_{\\perp}$, all permutation sets on it are assigned values, yet it remains unsatisfied, which happens with probability at most $p^{1-\\theta}$. The lemma is immediate by combining these facts. Its detailed proof is provided in Appendix D.4.3.\nLemma 8.22. Assume $8 e \\Delta p^{\\theta} \\leq 1$. For any w.s. $\\left(v_{0}, \\cdots, v_{t}\\right)$, we have\n\n$$\n\\operatorname{Pr}\\left[\\left(v_{0}, \\cdots, v_{t}\\right) \\text { occurs }\\right]<_{q} \\rho\\left(v_{0}, \\cdots, v_{t}\\right)\n$$\n\nConsider the following conditions, where condition (5) is from Condition 8.4, condition (6) is from (44), conditions (7) and (8) are from the definitions of $\\alpha$ and $\\theta$ in Algorithm 8, and the other conditions are used in following proofs.\n\nCondition 8.23. Let $p, \\theta \\in(0,1)$ and $\\Delta \\geq 1$. It holds that\n(1) if $|P| \\geq \\gamma$, then $61 \\Delta|P|^{3 \\theta-1} \\zeta\\left(1+|P|^{1-\\theta} \\min \\left\\{2 k \\Delta|P|^{2 \\theta-1}, 1\\right\\}\\right) \\leq 1$;\n(2) if $|P|<\\gamma$, then $31 \\Delta p^{\\theta}|P|^{3 \\theta} \\zeta\\left(1+|P|^{1-\\theta} \\min \\left\\{2 k \\Delta|P|^{2 \\theta-1}, 1\\right\\}\\right) \\leq 1$;\n(3) $2(18 k+2) k^{2} d^{2} \\gamma^{\\theta} \\Delta \\leq \\alpha\\left(500 k d \\Delta^{2}\\right)^{-1}$;\n(4) $3 p^{1-\\theta} \\gamma^{\\theta} \\zeta \\leq 1$;\n(5) $8 e \\Delta p^{\\theta} \\leq 1$;\n(6) $2 p^{\\theta} \\gamma^{\\theta} \\leq 1$.\n(7) $\\alpha \\leq L$;\n\n(8) $\\theta=\\eta / c$ for some integer $c$.\n\nThe final ingredients are the following two lemmas.\nLemma 8.24. Given any instance satisfying Conditions 8.10 and 8.23, if $|\\mathcal{L}|>\\alpha$, then\n\n$$\n\\sum_{s \\in \\mathcal{V}} \\rho(s) \\cdot f(s)<_{q} \\alpha\\left(500 k d \\Delta^{2} \\gamma^{\\theta}\\right)^{-1}\n$$\n\nLemma 8.25. Given any instance satisfying Conditions 8.10 and 8.23, we have\n\n$$\n\\sum_{P \\in \\mathcal{R}} \\sum_{P^{\\prime} \\in \\mathcal{D}\\{P\\}} \\sum_{s \\in V \\in\\left\\{P, P^{\\prime}\\right\\}} \\rho(s)\\left|P^{\\prime}\\right|<_{q} 1 / 5\n$$\n\nThe proofs of Lemma 8.24 and Lemma 8.25 are deferred to Appendix D.4.4. Now we are ready to prove Lemma 8.3.\n\nProof of Lemma 8.3. At first, we solve Conditions 8.10 and 8.23. One can verify that the following conditions imply Conditions 8.10 and 8.23 .\n(1) $\\theta=\\eta$ or $2 \\theta \\leq \\eta$;\n(2) $8 \\mathrm{e} \\Delta p^{\\theta} \\leq 1,3 p^{\\theta} \\gamma^{\\theta} \\leq 1$;\n(3) $2 \\times 10^{4} k^{3} d^{3} \\Delta^{3} \\gamma^{\\theta} \\leq \\alpha \\leq L$;\n(4) $2 \\times 10^{4} k^{3} d^{3} \\Delta \\gamma^{3 \\theta} p^{1-\\theta} \\leq 1$;\n(5) if $|P|>\\gamma$, then $2 \\times 10^{6} k^{4} d^{3} \\Delta^{3} \\gamma^{2 \\theta}|P|^{4 \\theta-1} \\leq 1$;\n(6) if $|P| \\leq \\gamma$ and $2 \\Delta|P|^{2 \\theta-1} \\leq 1$, then $4 \\mathrm{e} p \\Delta|P|^{2 \\theta+1} \\leq 1,10^{6} k^{4} d^{3} \\Delta^{3} \\gamma^{2 \\theta} p^{\\theta}|P|^{4 \\theta} \\leq 1$;\n(7) if $|P| \\leq \\gamma$ and $2 \\Delta|P|^{2 \\theta-1}>1$ then $2 \\mathrm{e} p|P|^{2} \\leq 1,10^{6} k^{3} d^{3} \\Delta^{2} \\gamma^{2 \\theta} p^{\\theta}|P|^{1+2 \\theta} \\leq 1$.\n\nFor general PDC formula, set the parameters as follows:\n\n$$\n\\theta=\\frac{1}{8}, \\quad \\gamma=\\Theta\\left(k^{16} d^{12} \\Delta^{12}\\right), \\quad p=O\\left(k^{-128} d^{-96} \\Delta^{-96}\\right), \\quad \\alpha=\\Theta\\left(k^{5} d^{4.5} \\Delta^{4.5}\\right)\n$$\n\nOne can verify that all the conditions are satisfied. Thus, we have\n\n$$\n\\begin{aligned}\n& \\sum_{P \\in \\mathcal{R}} \\mathrm{E}\\left[\\operatorname{Dis}\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}, \\mathcal{L}\\right) \\mid \\mathcal{L}=P\\right] \\\\\n\\leq & 100 k d \\Delta^{2} \\alpha^{-1} \\sum_{s \\in \\mathcal{V}} f(s) \\max _{P^{\\prime} \\in \\mathcal{P}} \\operatorname{Pr}\\left[s \\text { occurs } \\mid \\mathcal{L}=P^{\\prime}\\right] \\\\\n\\leq & 100 k d \\Delta^{2} \\alpha^{-1} \\sum_{s \\in \\mathcal{V}} \\rho(s) \\cdot f(s) \\\\\n\\leq & 1 / 4\n\\end{aligned}\n$$\n\n(by Lemma 8.21)\n(by Lemmas 8.22 and $q_{\\min }$ is large)\n\nIn addition, we also have\n\n$$\n\\begin{aligned}\n& \\sum_{P \\in \\mathcal{R}} \\mathrm{E}\\left[\\operatorname{Dis}\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}, \\mathcal{L}\\right) \\mid \\mathcal{L}=P\\right] \\\\\n= & \\sum_{P \\in \\mathcal{R}} \\sum_{P^{\\prime} \\in \\mathcal{D}\\{P\\}} \\sum_{s \\in V \\in\\left\\{P, P^{\\prime}\\right\\}} \\operatorname{Pr}\\left[s \\text { occurs } \\mid \\mathcal{L}=P\\right]\\left|P^{\\prime}\\right| \\\\\n\\leq & \\sum_{P \\in \\mathcal{R}} \\sum_{P^{\\prime} \\in \\mathcal{D}\\{P\\}} \\sum_{s \\in V \\in\\left\\{P, P^{\\prime}\\right\\}} \\rho(s)\\left|P^{\\prime}\\right| \\\\\n\\leq & 1 / 4\n\\end{aligned}\n$$\n\n(by Lemma 8.19)\n(by Lemma 8.23 and Lemmas 8.22)\nby Lemmas 8.24 and $q_{\\min }$ is large)\n\nCombining the two inequalities, Lemma 8.3 is immediate.\nFor the $(k, q)$-uniform PDC formula, recall the definition of $r$ in Lemma 8.1. We have $p<_{q} r^{-k}$. If $k \\geq 24$, set\n\n$$\n\\gamma=r+\\Theta(1), \\quad \\theta=1 / 2, \\quad p=r^{-k}=O\\left(k^{-12} d^{-8} \\Delta^{-8}\\right), \\quad \\alpha=\\Theta\\left(k^{3} d^{3} \\Delta^{3} r^{1 / 2}\\right)\n$$\n\nWe have\n\n$$\n\\forall P \\in \\mathcal{P}^{\\prime}, \\quad|P| \\leq \\gamma, \\quad \\gamma^{2 \\theta} p^{\\theta}|P|^{4 \\theta}<_{q} r^{-(k-6) \\theta}=p^{\\theta(k-6) / k}, \\quad \\gamma^{3 \\theta} p^{1-\\theta}<_{q} r^{3 \\theta-k \\theta}=p^{\\theta(k-3) / k}\n$$\n\nThus, all the conditions in (1)-(7) are satisfied. We also have Lemma 8.3.", "tables": {}, "images": {}}, {"section_id": 11, "text": "# 9. Analysis of the main algorithm \n\nIn this section, we analyze the performance of our main sampling algorithm (Algorithm 1), and complete the proofs of the following theorems.\n\nTheorem 9.1. The following holds for any sufficiently large $q_{\\min }$ and some constant c. There exists an algorithm such that given as input any $\\varepsilon \\in(0,1)$ and any $(k, q)$-uniform PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with $n$ variables satisfying $q \\geq q_{\\min }, k \\geq 24$ and\n\n$$\nq^{k} \\geq c \\zeta k^{24} \\Delta^{32}\n$$\n\nfor some $\\zeta>1$, it outputs a random valid assignment $\\sigma$ of $\\Phi$ such that $d_{\\mathrm{TV}}(\\sigma, \\mu) \\leq \\varepsilon$ in running time $\\widetilde{O}\\left(k \\Delta^{2} n\\left(\\frac{\\theta}{\\varepsilon}\\right)^{\\theta}\\right)$ where $\\theta=c \\zeta^{-1 / 2} k^{-12} \\Delta^{-15}$.\n\nIn addition, we have the following result for general PDC formulas.\nTheorem 9.2. The following holds for any sufficiently large $q_{\\min }$ and some constant c. There exists an algorithm such that given as input any $\\varepsilon \\in(0,1)$ and any $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with $n$ variables satisfying $q \\geq q_{\\min }$ and\n\n$$\nc p k^{518} \\Delta^{786} \\leq 1\n$$\n\nit outputs a random valid assignment $\\sigma$ of $\\Phi$ such that $d_{\\mathrm{TV}}(\\sigma, \\mu) \\leq \\varepsilon$ in running time $\\widetilde{O}\\left(\\Delta n^{7} / \\varepsilon^{2}\\right)$.\n9.1. Factorization. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$ satisfying Condition 6.1 and an error parameter $\\varepsilon \\in(0,1)$. As shown in Section 6.2, the efficiency and the correctness of $\\operatorname{MCMC}\\left(\\Phi, \\mathcal{P}^{\\prime}, \\varepsilon\\right)$ require that the input of the $\\operatorname{Sample}(\\cdot)$ subroutine satisfies Condition 6.4. For each $t \\in[T+1]$, let $\\mathcal{Q}_{t}^{\\prime}$ be the updated domain $\\mathcal{Q}^{\\prime}$ at step $t$ in $\\operatorname{MCMC}\\left(\\Phi, \\mathcal{P}^{\\prime}, \\varepsilon\\right)$ (Algorithm 1). We also use $\\Phi_{1}=\\left(\\mathcal{P}_{1}, \\mathcal{Q}_{1}, \\mathcal{C}_{1}\\right), \\cdots, \\Phi_{K}=\\left(\\mathcal{P}_{K}, \\mathcal{Q}_{K}, \\mathcal{C}_{K}\\right)$ to denote the factorization of the random formula $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}_{t}^{\\prime}, \\mathcal{C}\\right)$ where $K$ is also a random variable. Let $\\mathcal{B}_{t}$ be the event that there exists some $i \\in[K]$ such that $\\left|\\mathcal{C}_{t}\\right|>\\Delta \\log (n / \\delta)$ where $\\delta=\\frac{\\varepsilon}{3(T+1)}$. The following lemma bound the probability of the occurrence of the event $\\mathcal{B}_{t}$.\n\nLemma 9.3. Given any $\\varepsilon \\in(0,1)$ and any $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$ satisfying Condition 6.1, $8 c p_{\\Phi}^{\\theta} \\Delta \\leq 1,8 c \\Delta \\leq L$, and $2 c p_{\\Phi}^{0.999(1-\\eta)} \\Delta^{2} L^{2} \\leq 1$, it holds that $\\operatorname{Pr}\\left[\\mathcal{B}_{t}\\right] \\leq \\delta$ for each $t \\in[T+1]$ with $\\delta=\\frac{\\varepsilon}{3(T+1)}$ in Algorithm 1.\n\nTo prove Lemma 9.3, we introduce the following events for convenience. For each $t \\in[T+1]$, we define $\\mathcal{B}_{C}$ for any $C \\in \\mathcal{C}$ to denote the event that $C$ is unsatisfied in the formula $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}_{t}^{\\prime}, \\mathcal{C}\\right)$, and there exists a factorized formula $\\Phi_{C}=\\left(\\mathcal{P}_{C}, \\mathcal{Q}_{C}, \\mathcal{C}_{C}\\right)$ in $\\Phi_{[K]}$ containing the constraint $C$ and $\\left|\\mathcal{C}_{C}\\right|>\\Delta \\log (n / \\delta)$. Applying the union bound, it suffices to bound the probability of the event $\\mathcal{B}_{C}$ for any $C \\in \\mathcal{C}$ since\n\n$$\n\\operatorname{Pr}\\left[\\mathcal{B}_{t}\\right] \\leq \\operatorname{Pr}\\left[\\bigcup_{C \\in \\mathcal{C}} \\mathcal{B}_{C}\\right] \\leq \\sum_{C \\in \\mathcal{C}} \\operatorname{Pr}\\left[\\mathcal{B}_{C}\\right]\n$$\n\nWe then construct the witness of the bad events $\\mathcal{B}_{C}$ for any $C \\in \\mathcal{C}$. We introduce the dependency graph $G_{\\phi}^{\\text {dep }}\\left[P^{\\prime}\\right]$ induced by $\\Phi$ and $\\mathcal{P}^{\\prime}$. Let $G_{\\phi}^{\\text {dep }}\\left[P^{\\prime}\\right]=\\left(\\mathcal{C}, E_{\\phi}^{\\text {dep }}\\right)$ be an undirected graph with the constraints $\\mathcal{C}$ as its vertices. For any $C, C^{\\prime} \\in \\mathcal{C},\\left\\{C, C^{\\prime}\\right\\} \\in E_{\\phi}^{\\text {dep }}$ if and only if $(\\operatorname{vbl}(C) \\cap P \\neq \\emptyset) \\wedge\\left(\\operatorname{vbl}\\left(C^{\\prime}\\right) \\cap P \\neq \\emptyset\\right)$ for some $P \\in \\mathcal{P}^{\\prime}$. That is, $\\left\\{C, C^{\\prime}\\right\\} \\in E_{\\phi}^{\\text {dep }}$ if the constraints $C$ and $C^{\\prime}$ are related to some permutation in $\\mathcal{P}^{\\prime}$. We also use $\\left(G_{\\phi}^{\\text {dep }}\\left[P^{\\prime}\\right]\\right)^{2}$ to denote the undirected graph with the same vertices where any two vertices are adjacent when their distance in $G_{\\phi}^{\\text {dep }}\\left[P^{\\prime}\\right]$ is at most 2 . For any $C \\in \\mathcal{C}$, we call $C$ a bad constraint if $C$ is not satisfied in the formula $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}_{t}^{\\prime}, \\mathcal{C}\\right)$.\n\nThe witness is characterized by the following lemma, and its proof is deferred to Appendix E.\nLemma 9.4. If the event $\\mathcal{B}_{C}$ occurs, then there exists a collection of bad constraints $\\left\\{C_{1}, \\cdots, C_{\\ell}\\right\\} \\subseteq \\mathcal{C}$ with $\\ell=\\log (n / \\delta)$ such that 1) $C \\in\\left\\{C_{1}, \\cdots, C_{\\ell}\\right\\}$; 2) $\\left\\{C_{1}, \\cdots, C_{\\ell}\\right\\}$ forms an independent set in the lopsidependency graph $G_{\\phi}^{\\text {Lop }}$ and a connected component in $\\left(G_{\\phi}^{\\text {dep }}\\left[P^{\\prime}\\right]\\right)^{2}$.\n\nThe number of witnesses can be bounded by the following lemma in [BCKL13].\nLemma 9.5. Let $G=(V, E)$ be a graph with maximum degree $\\Delta$ and $v \\in V$ be a vertex. Then the number of connected induced subgraphs of size $\\ell$ containing $v$ is at most $\\left(\\mathrm{e} \\Delta^{2}\\right)^{\\ell-1} / 2$.\n\nThe following lemma bounds the probability of the event that a given collection of constraints is bad, and its proof can be found in Appendix E.\n\nLemma 9.6. Given any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ with a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$ satisfying Condition 6.1, $8 e p_{\\Phi}^{\\eta} \\Delta \\leq 1$, and $8 e \\Delta \\leq L$, it holds that for any collection of lopsided independent constraints $\\mathcal{C}^{\\prime} \\subseteq \\mathcal{C}$,\n\n$$\n\\operatorname{Pr}\\left[\\text { The constraints } \\mathcal{C}^{\\prime} \\text { are bad in }\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}_{\\ell}, \\mathcal{C}\\right)\\right]<_{q} \\prod_{C \\in \\mathcal{C}^{\\prime}} \\mathbb{P}_{\\Phi}[\\neg C]^{0.999(1-\\eta)}\n$$\n\nWe are now ready to complete the proof of Lemma 9.3.\nProof of Lemma 9.3. By Lemma 9.4, when the event $\\mathcal{B}_{C}$ happens, there exists a collection of bad constraints $\\left\\{C, C_{2}, \\cdots, C_{\\ell}\\right\\} \\subseteq \\mathcal{C}$ which is an independent set in the lopsidependency graph $G_{\\Phi}^{\\text {Lop }}$, and a connected component in the power graph of the dependency graph $\\left(G_{\\Phi}^{\\text {dep }}\\left[P^{\\prime}\\right]\\right)^{2}$. Applying Lemmas 9.6, 9.5 and the union bound, we have\n\n$$\n\\operatorname{Pr}\\left[\\mathcal{B}_{C}\\right] \\leq \\frac{\\left(\\mathrm{e} \\Delta^{2} L^{2}\\right)^{\\log (n / \\delta)-1}}{2} \\cdot p^{0.999(1-\\eta) \\cdot \\log (n / \\delta)} \\leq \\frac{\\delta}{n \\Delta}\n$$\n\nwhere the first inequality holds because the maximum degree of $G_{\\Phi}^{\\text {dep }}\\left[P^{\\prime}\\right]$ is less than $\\Delta L$, and the last inequality holds by $2 p^{0.999(1-\\eta)} \\cdot e \\Delta^{2} L^{2} \\leq 1$. Consequently,\n\n$$\n\\operatorname{Pr}\\left[\\mathcal{B}_{\\ell}\\right] \\leq \\sum_{C \\in \\mathcal{C}} \\operatorname{Pr}\\left[\\mathcal{B}_{C}\\right] \\leq \\delta\n$$\n\nwhich implies the lemma immediately.\nWe are now ready to complete the proof of Theorem 9.2 and Theorem 9.1.\n9.2. Analysis for $(k, q)$-uniform PDC formulas. In this section, we complete the proof of Theorem 9.1\n\nGiven a sufficiently large $q_{\\min }$ and any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $q \\geq q_{\\min }$, we have $p_{\\Phi}={ }_{q} q^{-k}$. Let $L={ }_{q} q^{\\eta}$. For any $\\eta \\in(0,1 / 2)$, one can verify that the existence of the decomposition satisfying Condition 6.1. In this case, we further refine the implementation of Algorithm 1 and its subroutine Algorithm 3.\n\n- In Algorithm 1, we replace the number of loops at Line 3 to $\\lceil 2(n / q) \\log (3 n / \\varepsilon)\\rceil$ where $n / q$ is the number of permutation sets in $\\mathcal{P}$ since the contraction in (28) is $1-1 /(2|P|)$. Moreover, let $\\sigma_{i} \\leftarrow$ RejectionSampling $\\left(\\Phi_{i},\\lceil(n / \\varepsilon)^{\\theta / 10} \\log (3 n(T+1) / \\varepsilon)\\rceil\\right)$ at Line 11 for some $\\theta \\in(0,1)$ in Algorithm 1. We also terminate the algorithm if we detect some formula has more than $\\Delta \\log \\left(\\frac{n}{\\varepsilon /(3 T+1)}\\right)$ constraints at Line 6 .\n- In Algorithm 3, let $T \\leftarrow\\lceil\\log (2 / \\varepsilon)\\rceil$ instead at Line 4 and $\\sigma_{i} \\leftarrow$ RejectionSampling $\\left(\\Phi_{i},\\lceil(n / \\varepsilon)^{\\theta / 10}\\right.$. $\\log (2 n T / \\varepsilon)\\rceil$ ) instead at Line 7 for some $\\theta \\in(0,1)$.\nWe list the following conditions for convenience:\n(1) $8 \\mathrm{e} q^{-\\eta k} \\Delta \\leq 1,2 \\mathrm{e} q^{-0.999 k+\\eta \\cdot(0.999 k+2)} \\Delta^{2} \\leq 1$;\n(2) $4 q^{-\\eta(k-1)} \\Delta \\leq 1, q^{\\eta k} \\geq 20 \\mathrm{e} \\Delta / \\theta$ for some $\\theta \\in(0,1)$;\n(3) $k \\geq 24, c k^{12} \\Delta^{16} \\leq q^{\\eta k}$;\n(4) $q^{\\eta} \\geq c\\left(d k^{2} \\Delta^{2}\\right)^{1+5 /(3 k)}$ for some constant $c$.\n\nOne can verify that (1), (2) and (3) hold when\n\n$$\nk \\geq 24, \\quad q^{k} \\geq c \\zeta k^{24} \\Delta^{32}\n$$\n\nfor some $\\zeta>1$ and constant $c$, by setting $\\eta=1 / 2$ and $\\theta=\\mathrm{c} \\zeta^{-1 / 2} k^{-12} \\Delta^{-15}$.\nWe first claim the correctness of the refined algorithm conditioned on (49). The condition (2) ensures that $p_{\\max }|P| \\Delta \\leq 1 / 4$ always holds at Line 3 in Algorithm 3 since $p_{\\max }=_{q} q^{-\\eta(k-1)-1}$. Therefore,\n\nwe only implement from Line 3 to (9). One can verify that given the input satisfying Condition 6.4 and $q^{n k} \\geq 20 \\mathrm{e} \\Delta / \\theta$, $\\operatorname{Sample}(\\Phi, P, \\varepsilon)$ still returns a random valid assignment $\\sigma$ of $\\Phi$ with total variation distance bounded by $\\varepsilon$ by the following facts:\n\n- In Lemma 6.6, we have $\\operatorname{Pr}_{\\sigma_{[K]^{-} \\rho[K]}}\\left[\\sigma \\in \\Omega_{\\Phi}\\right] \\geq 1 / 2$.\n- Given that $q^{n k} \\geq 20 \\mathrm{e} \\Delta / \\theta$, we set $x(\\neg C)=\\frac{\\theta}{20 \\Delta}$. One can verify that Theorem 3.1 holds and for each $i \\in[K-1]$ in Algorithm 3, we have\n\n$$\n\\mathbb{P}_{\\Phi_{t}}\\left[\\bigwedge_{C \\in \\mathcal{C}_{t}} C\\right] \\geq\\left(1-\\frac{\\theta}{20 \\Delta}\\right)^{\\Delta \\log (n / \\varepsilon)} \\geq\\left(1-\\frac{1}{15 \\Delta / \\theta+1}\\right)^{\\Delta \\log (n / \\varepsilon)} \\geq \\exp \\left(-\\frac{\\theta}{15} \\log \\frac{n}{\\varepsilon}\\right) \\geq\\left(\\frac{n}{\\varepsilon}\\right)^{\\theta / 10}\n$$\n\nMoreover, the rapid mixing property is implied by (3) or (4) according to Lemma 8.1.\nLet $X_{T}$ denote the random assignment of $M_{\\text {Glauber }}$ runs for $T=\\left\\lceil 2 n / q \\log \\frac{n}{\\varepsilon}\\right\\rceil$ steps, and $\\tau$ be the random assignment sampled from $\\mu_{\\Phi^{\\prime}}$ where $\\Phi^{\\prime}=\\left(\\mathcal{P}^{\\prime}, X_{T}, \\mathcal{C}\\right)$. Recall that $\\sigma$ is the random valid assignment returned by Algorithm 1. We claim that $d_{\\mathrm{TV}}(\\sigma, \\tau) \\leq \\frac{2 \\varepsilon}{3}$. At each step of the idealized permutation-wise Glauber dynamics, we couple $M_{\\text {Glauber }}$ and $\\operatorname{MCMC}\\left(\\Phi, \\mathcal{P}^{\\prime}, \\varepsilon\\right)$ by sharing the randomly chosen permutation $P$. Moreover, we apply the optimal coupling between the $\\operatorname{Sample}(\\cdot)$ subroutine and the idealized update on the domains in $\\mathcal{P}[P]$. The coupling errors come from the following two circumstances:\n(1) The input ( $\\Phi^{\\prime}, P, \\frac{\\varepsilon}{3(T+1)}$ ) of $\\operatorname{Sample}(\\cdot)$ subroutine does not satisfy Condition 6.4;\n(2) The intrinsic error comes from $\\operatorname{Sample}\\left(\\Phi^{\\prime}, P, \\frac{\\varepsilon}{3(T+1)}\\right)$ even when $\\left(\\Phi^{\\prime}, P, \\frac{\\varepsilon}{3(T+1)}\\right)$ satisfying Condition 6.4 .\nAccording to Lemma 9.3, the probability of the first case mentioned above can be bounded by $\\frac{\\varepsilon}{3(T+1)}$ at each step. Furthermore, conditioned on $\\left(\\Phi^{\\prime}, P, \\frac{\\varepsilon}{3(T+1)}\\right)$ satisfying condition 6.4 , coupling error from $\\operatorname{Sample}(\\cdot)$ subroutine can be upper bounded by $\\frac{\\varepsilon}{3(T+1)}$ according to Theorem 7.1. The statement holds immediately. Recall that $v$ is the stationary distribution of the idealized permutation-wise Glauber dynamics. According to (3) or (4), we have $d_{\\mathrm{TV}}\\left(X_{t}, v\\right) \\leq \\frac{\\varepsilon}{3}$ by Lemma 8.1, and hence, $d_{\\mathrm{TV}}\\left(\\sigma, \\mu_{\\Phi}\\right) \\leq$ $d_{\\mathrm{TV}}\\left(X_{t}, v\\right)+d_{\\mathrm{TV}}(\\sigma, \\tau) \\leq \\varepsilon$.\n\nAs for the efficiency, we emphasize the time complexity of the factorization at Line 11 and the $\\operatorname{Sample}(\\cdot)$ subroutine:\n\n- In the factorization process, we take each permutation $P \\in \\mathcal{P}^{\\prime}$ as a \"vertex\". At Line 6 in Algorithm 1, we transverse all constraints in $\\mathcal{C}(P)$ and implement the DFS algorithm to check whether there exists a connected component containing more than $\\Delta \\log \\left(\\frac{n}{\\varepsilon /(3 T+1)}\\right)$ constraints. Overall, one can verify that it can be done in $O\\left(q k \\Delta^{2} \\log \\left(\\frac{n}{\\varepsilon /(3 T+1)}\\right)\\right)$.\n- According to the execution of Algorithm 1, the $\\operatorname{Sample}(\\cdot)$ subroutine is called only when $\\Phi_{1}, \\cdots, \\Phi_{K-1}$ have no more than $\\Delta \\log (n / \\varepsilon)$ constraints. Note that $K \\leq q \\Delta$. Therefore, we should resample the value on at most $q \\Delta^{2} \\log (n / \\varepsilon)$ constraints. Instead of sampling the whole formulas $\\Phi_{1}, \\cdots, \\Phi_{K-1}$, it suffices to reveal the values of the variables on these constraints at Line 7. This process requires $O\\left(k q \\Delta^{2} \\log (n / \\varepsilon)\\right)$ time. Additionally, to implement (9), we need to further reveal the variables involved in the constraints $\\mathcal{C}(P)$ and some formulas $\\Phi_{i}$ where $i \\in[K-1]$, provided they have not already been revealed at Line 7. However, these variables can be simply sampled uniformly at random in $O(q \\Delta)$ time. As mentioned before, the rejection sampling repeats for $\\lceil(n / \\varepsilon)^{\\theta / 10} \\log (3 n(T+1) / \\varepsilon)\\rceil$ ) round. Overall, $\\operatorname{Sample}(\\cdot)$ subroutine runs in $\\widetilde{O}\\left(k q \\Delta^{2}(n / \\varepsilon)^{\\theta / 10}\\right)$ time.\nOverall, the time complexity of the refined algorithm is $\\widetilde{O}\\left(k \\Delta^{2} n\\left(\\frac{n}{\\varepsilon}\\right)^{\\theta}\\right)$. Combinging all these facts, the lemma is immediate.\n9.3. Analysis for general PDC formulas. In this section, we complete the proof of Theorem 9.2.\n\nGiven a sufficiently large $q_{\\min }$ and any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $q \\geq q_{\\min }$, one can verify that the existence of the decomposition satisfying Condition 6.1. We list the following conditions for convenience:\n\n(1) $8 c p_{\\Phi}^{\\eta} \\Delta \\leq 1,8 \\mathrm{e} \\Delta \\leq L, 2 c p_{\\Phi}^{0.999(1-\\eta)} \\Delta^{2} L^{2} \\leq 1$;\n(2) $p_{\\Phi}^{\\eta} \\cdot 6912 \\mathrm{e}^{3} \\ln 2 \\cdot k^{3} L^{2} \\Delta^{9} \\leq 1$;\n(3) $c p_{\\Phi}^{\\eta} k^{128} \\Delta^{192} \\leq 1, c k^{128} \\Delta^{192} \\leq L$.\n\nBy setting $\\eta=1 / 2$ and $L=_{q} k^{128} \\Delta^{192}$, one can verify that (1), (2), and (3) hold when $c p k^{518} \\Delta^{786} \\leq 1$ for some constant $c$.\n\nLet $\\left(\\Phi^{\\prime}, P, \\delta\\right)$ be the input of the $\\operatorname{Sample}(\\cdot)$ subroutine in Algorithm 1 where $\\delta=\\frac{c}{3(T+1)}$. Note that $p_{\\Phi^{\\prime}} \\leq \\min \\left\\{p^{\\eta}, 1 / L\\right\\}$. Therefore, (1) implies the conditions specified in Lemma 9.3 and the instance $\\left(\\Phi^{\\prime}, P, \\delta\\right)$ satisfying Condition 6.4 with high probability. Moreover, to ensure the correctness of $\\operatorname{Sample}(\\cdot)$ subroutine under Condition 6.4, we require that either $p_{\\max }|P| \\Delta \\leq 1 / 4$ or $|P| \\geq 1728 \\mathrm{e}^{3} \\ln 2 \\cdot k^{3} L^{2} \\Delta^{8}$ by Theorem 7.1. Specifically, we require that $p_{\\max }|P| \\Delta \\leq 1 / 4$ when $|P|<1728 \\mathrm{e}^{3} \\ln 2 \\cdot k^{3} L^{2} \\Delta^{8}$. Note that the PDC formula $\\Phi^{\\prime}$ is defined on the decomposition $\\mathcal{P}^{\\prime} \\circ P$. We claim that for each unsatisfied constraint $C \\in \\mathcal{C}(P),|\\mathrm{vbl}(C)| \\geq 2$. This is because when $|\\mathrm{vbl}(C)|=1$ and $C \\in \\mathcal{C}(P)$, its violation probability is at most $1 /|P|$ which contradicts to $c p k^{518} \\Delta^{786} \\leq 1$. When $|\\mathrm{vbl}(C)| \\geq 2$, one can verify that $\\mathbb{P}_{\\Phi^{\\prime}}[\\sim C] \\leq \\max \\left\\{p_{\\Phi^{\\prime}}^{\\eta} \\frac{1}{|P| L}\\right\\}$ for each $C \\in \\mathcal{C}(P)$. Therefore $p_{\\max }|P| \\Delta \\leq 1 / 4$ holds when $|P|<1728 \\mathrm{e}^{3} \\ln 2 \\cdot k^{3} L^{2} \\Delta^{8}$ by (2). Moreover, the rapid mixing property holds since (3) implys the specified conditions in Lemma 8.1. Combining all these facts, the correctness is immediate follows from similar argument in the proof of Theorem 9.1.\n\nAs for the time complexity, the construction of the decomposition can be done in $O(n)$ times. In each iteration of $t$, the algorithm initially locates the factorized formula containing $P$ in $\\left(\\mathcal{P}^{\\prime} \\circ P, \\mathcal{Q}^{\\prime} \\circ \\mathcal{Q}(P), \\mathcal{C}\\right)$, which costs $\\widetilde{O}(|V|+|\\mathcal{C} \\cup \\mathcal{P}|)=\\widetilde{O}(n+n \\Delta+n)=\\widetilde{O}(n \\Delta)$ times. Moreover, the $\\operatorname{Sample}(\\cdot)$ subroutine cost at most $n^{4} / \\delta^{2}$ by Theorem 7.1 where $\\delta=\\frac{c}{3(T+1)}$. As the algorithm iterates for $T$ times, the total time complexity is $\\widetilde{O}\\left(\\Delta n^{7} / \\varepsilon^{2}\\right)$.\n\nCombining all these facts, the lemma is immediate.", "tables": {}, "images": {}}, {"section_id": 12, "text": "# 10. Applications \n\nIn this section, we apply our sampling algorithm for PDC to the sampling of factors of independent transversals in multipartite hypergraphs.\n\nA $k$-uniform hypergraph is a set of hyperedges each of which contains exactly $k$ vertices. An $m$-partite hypergraph is a hypergraph in which the vertices are partitioned into $m$ disjoint sets and each hyperedge contains at most one vertex of each set. Given an $m$-partite hypergraph $H=\\left(V_{1}, V_{2}, \\cdots, V_{m}, E\\right)$, let $V$ denote $V_{1} \\cup \\cdots \\cup V_{m}$. If $\\left|V_{i}\\right|=q$ for every $i \\in[m], H$ is called $q$-balanced. An independent transversal of $H$ is a set of $m$ vertices, containing exactly one vertex from each part, such that it does not contain all vertices of any hyperedge. A factor of independent transversals of $H$ is a collection of disjoint independent transversals that spans all of the vertices in $V$. We remark that only balanced partite hypergraphs have factors of independent transversals.\n\nThe factor of independent transversals is closely related to the perfect matching in multipartite hypergraphs. A matching in a hypergraph is a set of hyperedges, in which every two hyperedges are disjoint. A perfect matching is a matching covering all the vertices. For any balanced $k$-partite $k$-uniform hypergraph $H=\\left(V_{1}, V_{2}, \\cdots, V_{k}, E\\right)$, each factor of independent transversals in $H$ is exactly a perfect matching of the hypergraph $\\overleftrightarrow{H}=\\left(V_{1}, V_{2}, \\cdots, V_{k}, \\widetilde{E}\\right)$ where $\\widetilde{E}=V_{1} \\times \\cdots \\times V_{k} \\backslash E$.\n\nIndependent transversals of multipartite hypergraphs were initially studied by Erd\u0151s, Gy\u00e1rf\u00e1s, and Luczak [EGL94]. The problem of establishing sufficient conditions for the existence of independent transversals and their factors in $q$-balanced $m$-partite $k$-uniform hypergraphs has been widely explored in the literature, though results are only available for certain special cases. The original work of Erd\u0151s, Gy\u00e1rf\u00e1s, and Luczak focuses on sparse hypergraphs [EGL94], while many subsequent studies concentrate on the simplest case, $k=2$, where the hypergraph degrades into a graph [Yus97, Yus21, GS22]. Through the connection between factors of independent transversals and perfect matchings, a tight condition can be derived for the existence of a factor of independent transversals in $k$-partite $k$-uniform hypergraphs [AGS09]. Moreover, it is worth noting that finding a factor of independent transversals in a multipartite hypergraph is NP-hard, as finding a perfect matching in a given balanced 3-partite 3-uniform hypergraph was one of the first problems proven to be NP-hard [Kar09].\n\nHere, we provide a fast algorithm for sampling factors of independent transversals in multipartite hypergraphs. Given a $q$-balanced $m$-partite $k$-uniform hypergraph $H=\\left(V_{1}, V_{2}, \\cdots, V_{m}, E\\right)$, let $d$ denote its maximum vertex degree. The sampling of a random factor of independent transversals in $H$ can be modeled as the sampling of a PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ as follows. Here, $\\mathcal{P}=\\left(P_{1}, P_{2}, \\cdots, P_{m}\\right)$ where $P_{i}$ contains the vertices in $V_{i}$ and $\\mathcal{Q}=\\left(Q_{1}, Q_{2}, \\cdots, Q_{m}\\right)$ where $Q_{i}=[q]$ for each $i \\in[m]$, and $\\mathcal{C}$ contains all the constraints corresponding to the following conditions:\n\n- $\\left(v_{1} \\neq i\\right) \\vee \\cdots \\vee\\left(v_{k} \\neq i\\right)$ for each $\\left(v_{1}, \\cdots, v_{k}\\right) \\in E$ and $i \\in[q]$.\n\nThus, the probability $p$ that a constraint is violated is bounded by $q^{-k}$. Additionally, one can verify that the degree of the lopsidependency graph is $2 k d q$, because each constraint contains $k$ variables, each variable can be contained in $d$ constraints, and can take at most $q$ different values. By Theorem 1.3, we have the following theorem.\n\nTheorem 10.1. The following holds for any sufficiently large $q_{\\min }$ and some constant $c>0$. There is an algorithm such that given as input any $\\varepsilon \\in(0,1)$ and any $q$-balanced $m$-partite $k$-uniform hypergraph $H$ with maximum vertex degree $d$ satisfying $q \\geq q_{\\min }, k>32$ and\n\n$$\nq^{k-32} \\geq c k^{56} d^{32}\n$$\n\nthe algorithm terminates in time $\\widetilde{O}\\left(k^{3} d^{2} q^{3.001} m^{1.001} / \\varepsilon\\right)$ and outputs a random factor of independent transversals of $H$ that is $\\varepsilon$-close in the total variation distance to the uniform distribution of all factors.\n\nThe theorem demonstrates that for large $q, k$, sampling a factor of independent transversals in a $q$ balanced $m$-partite $k$-uniform hypergraph is efficient if a constant power of the maximum vertex degree is bounded by $q^{k}$. We emphasize that sampling of factors of independent transversals outside the LLL-like regime is intractable. By introducing $q-1$ dummy variables for each vertex, sampling $q$-colorings for a $k$-uniform hypergraph with $m$ vertices can be reduced to sampling factors of independent transversals in a $q$-balanced, $m$-partite, $k$-uniform hypergraph. Moreover, sampling hypergraph colorings is intractable beyond the LLL-like regime [GGW21]. Therefore, to make sampling factors of independent transversals tractable, it is natural to assume an LLL-like regime. Our theorem establishes such a regime, and the algorithm achieves an almost linear running time in $n$. To the best of our knowledge, no prior nontrivial sampling algorithm for factors of independent transversals has been proposed.", "tables": {}, "images": {}}, {"section_id": 13, "text": "# Acknowledgement \n\nWe thank Qingyuan Li, Fangjie Peng, Haoran Wang, and Yitong Yin for helpful discussion.", "tables": {}, "images": {}}, {"section_id": 14, "text": "## References\n\n[AD86] David Aldous and Persi Diaconis. Shuffling cards and stopping times. The American Mathematical Monthly, 93(5):333-348, 1986.\n[AGS09] Ron Aharoni, Agelos Georgakopoulos, and Philipp Spr\u00fcssel. Perfect matchings in r-partite r-graphs. European Journal of Combinatorics, 30(1):39-42, 2009.\n[Ald83] David Aldous. Random walks on finite groups and rapidly mixing markov chains. In S\u00e9minaire de Probabilit\u00e9s XVII 1981/82: Proceedings, pages 243-297. Springer, 1983.\n[AS16] Noga Alon and Joel H. Spencer. The Probabilistic Method. Wiley Publishing, 4th edition, 2016.\n[BCKL13] Christian Borgs, Jennifer Chayes, Jeff Kahn, and L\u00e1szl\u00f3 Lov\u00e1sz. Left and right convergence of graphs with bounded degree. Random Structures \\& Algorithms, 42, 012013.\n[BD92] Dave Bayer and Persi Diaconis. Trailing the dovetail shuffle to its lair. The Annals of Applied Probability, pages 294-313, 1992.\n[BD97] Russ Bubley and Martin Dyer. Path coupling: A technique for proving rapid mixing in markov chains. In 1997 IEEE 38th Annual Symposium on Foundations of Computer Science, page 223, 1997.\n[BGG*19] Ivona Bez\u00e1kov\u00e1, Andreas Galanis, Leslie A. Goldberg, Heng Guo, and Daniel \u0160tefankovi\u010d. Approximation via correlation decay when strong spatial mixing fails. SIAM J. Comput., 48(2):279-349, 2019.\n\n[Br\u00e873] Lev Meerovich Br\u00e8gman. Some properties of nonnegative matrices and their permanents. In Doklady Akademii Nauk, volume 211/1, pages 27-30. Russian Academy of Sciences, 1973.\n[Bro86] Andrei Z Broder. How hard is it to marry at random?(on the approximation of the permanent). In Proceedings of the eighteenth annual ACM symposium on Theory of computing, pages $50-58,1986$.\n[BSVV08] Ivona Bez\u00e1kov\u00e1, Daniel Stefankovic, Vijay V. Vazirani, and Eric Vigoda. Accelerating simulated annealing for the permanent and combinatorial counting problems. SIAM J. Comput., 37(5):1429-1454, 2008.\n[CDH11] Colin Cooper, Martin Dyer, and Andrew J Handley. Networks of random cycles. In Proceedings of the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms, pages 933-944. SIAM, 2011.\n[Dia88] Persi Diaconis. Group representations in probability and statistics. Lecture notes-monograph series, 11:i-192, 1988.\n[EGL94] Paul Erd\u0151s, Andr\u00e1s Gy\u00e1rf\u00e1s, and Tomasz Luczak. Independent transversals in sparse partite hypergraphs. Combinatorics, Probability and Computing, 3(3):293-296, 1994.\n[EL75] Paul Erd\u0151s and L\u00e1szl\u00f3 Lov\u00e1sz. Problems and results on 3-chromatic hypergraphs and some related questions. Infinite and finite sets, volume 10 of Colloquia Mathematica Societatis J\u00e1nos Bolyai, pages 609-628, 1975.\n[ES91] Paul Erd\u0151s and Joel Spencer. Lopsided lov\u00e1sz local lemma and latin transversals. Discrete Applied Mathematics, 30(2-3):151-154, 1991.\n[FGW22] Weiming Feng, Heng Guo, and Jiaheng Wang. Improved bounds for randomly colouring simple hypergraphs. Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques, 2022.\n[FGYZ21] Weiming Feng, Heng Guo, Yitong Yin, and Chihao Zhang. Fast sampling and counting $k$-sat solutions in the local lemma regime. Journal of the ACM (JACM), 68(6):1-42, 2021.\n[FHY21] Weiming Feng, Kun He, and Yitong Yin. Sampling constraint satisfaction solutions in the local lemma regime. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 1565-1578, 2021.\n[GGGY20] Andreas Galanis, Leslie Ann Goldberg, Heng Guo, and Kuan Yang. Counting solutions to random CNF formulas. In ICALP, volume 168 of LIPIcs, pages 53:1-53:14, 2020.\n[GGW21] Andreas Galanis, Heng Guo, and Jiaheng Wang. Inapproximability of counting hypergraph colourings. arXiv preprint arXiv:2107.05486, 2021.\n[GGW23] Andreas Galanis, Heng Guo, and Jiaheng Wang. Inapproximability of counting hypergraph colourings. ACM Transactions on Computation Theory, 14(3-4):1-33, 2023.\n[GJL19] Heng Guo, Mark Jerrum, and Jingcheng Liu. Uniform sampling through the Lov\u00e1sz local lemma. J. ACM, 66(3):Art. 18, 31, 2019.\n[GLLZ19] Heng Guo, Chao Liao, Pinyan Lu, and Chihao Zhang. Counting hypergraph colorings in the local lemma regime. SIAM Journal on Computing, 48(4):1397-1424, 2019.\n[GS22] Stefan Glock and Benny Sudakov. An average degree condition for independent transversals. Journal of Combinatorial Theory, Series B, 154:370-391, 2022.\n[Har20] David G Harris. New bounds for the moser-tardos distribution. Random Structures \\& Algorithms, 57(1):97-131, 2020.\n[HL08] Mark Huber and Jenny Law. Fast approximation of the permanent for very dense problems. In Proceedings of the nineteenth annual ACM-SIAM symposium on Discrete algorithms, pages 681-689, 2008.\n[HLL*17] Kun He, Liang Li, Xingwu Liu, Yuyi Wang, and Mingji Xia. Variable-version lov\u00e1sz local lemma: Beyond shearer's bound. In 2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS), pages 451-462. IEEE, 2017.\n[HS14] David G. Harris and Aravind Srinivasan. A constructive algorithm for the Lov\u00e1sz local lemma on permutations. In Proceedings of ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 907-925, 2014.\n[HS17] David G. Harris and Aravind Srinivasan. A constructive Lov\u00e1sz local lemma for permutations. Theory Comput., 13:Paper No. 17, 41, 2017.\n\n[HSW21] Kun He, Xiaoming Sun, and Kewen Wu. Perfect sampling for (atomic) lov\u00e1sz local lemma. CoRR, abs/2107.03932, 2021.\n[Hub06] Mark Huber. Exact sampling from perfect matchings of dense regular bipartite graphs. Algorithmica, 44:183-193, 2006.\n[HWY22] Kun He, Chunyang Wang, and Yitong Yin. Sampling lov\u00e1sz local lemma for general constraint satisfaction solutions in near-linear time. In 2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS), pages 147-158. IEEE, 2022.\n[HWY23] Kun He, Chunyang Wang, and Yitong Yin. Deterministic counting lov\u00e1sz local lemma beyond linear programming. In Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 3388-3425. SIAM, 2023.\n[JPV21a] Vishesh Jain, Huy Tuan Pham, and Thuy Duong Vuong. On the sampling lov\u00e1sz local lemma for atomic constraint satisfaction problems. CoRR, abs/2102.08342, 2021.\n[JPV21b] Vishesh Jain, Huy Tuan Pham, and Thuy Duong Vuong. Towards the sampling lov\u00e1sz local lemma. In 62nd IEEE Annual Symposium on Foundations of Computer Science, FOCS 2021, Denver, CO, USA, February 7-10, 2022, pages 173-183. IEEE, 2021.\n[JS89] Mark Jerrum and Alistair Sinclair. Approximating the permanent. SIAM journal on computing, 18(6):1149-1178, 1989.\n[JSV04] Mark Jerrum, Alistair Sinclair, and Eric Vigoda. A polynomial-time approximation algorithm for the permanent of a matrix with nonnegative entries. Journal of the ACM (JACM), $51(4): 671-697,2004$.\n[JVV86] Mark R. Jerrum, Leslie G. Valiant, and Vijay V. Vazirani. Random generation of combinatorial structures from a uniform distribution. Theoret. Comput. Sci., 43(2-3):169-188, 1986.\n[Kar09] Richard M Karp. Reducibility among combinatorial problems. In 50 Years of Integer Programming 1958-2008: from the Early Years to the State-of-the-Art, pages 219-241. Springer, 2009.\n[KD15] A Donald Keedwell and J\u00f3zsef D\u00e9nes. Latin squares and their applications. Elsevier, 2015.\n[LPW ${ }^{+}$17] David Asher Levin, Y. Peres, Elizabeth L. Wilmer, James Propp, and David B. Wilson. Markov chains and mixing times. American Mathematical Society, 2017.\n[LS07] Linyuan Lu and L\u00e1szl\u00f3 Sz\u00e9kely. Using lov\u00e1sz local lemma in the space of random injections. the electronic journal of combinatorics, 14(1):R63, 2007.\n[McD89] Colin McDiarmid. On the method of bounded differences. Surveys in combinatorics, 141(1):148-188, 1989.\n[Min63] Henryk Minc. Upper bounds for permanents of (0, 1)-matrices. Bulletin of the American Mathematical Society, 69(6):789-791, 1963.\n[Moi19] Ankur Moitra. Approximate counting, the lov\u00e1sz local lemma, and inference in graphical models. Journal of the ACM (JACM), 66(2):1-25, 2019.\n[MT10] Robin A. Moser and G\u00e1bor Tardos. A constructive proof of the general Lov\u00e1sz local lemma. J. ACM, 57(2):11, 2010.\n[MW91] Brendan D McKay and Nicholas C Wormald. Uniform generation of random latin rectangles. J. Combin. Math. Combin. Comput, 9(179186):16, 1991.\n[RMB84] Alfr\u00e9d R\u00e9nyi and Zsuzsanna Makkai-Bencs\u00e1th. A diary on information theory. Akad\u00e9miai Kiad\u00f3 Budapest, 1984.\n[Val79] Leslie G Valiant. The complexity of computing the permanent. Theoretical computer science, 8(2):189-201, 1979.\n[WY24] Chunyang Wang and Yitong Yin. A sampling Lov\u00e1sz local lemma for large domain sizes. In FOCS, 2024.\n[Yus97] Raphael Yuster. Independent transversals and independent coverings in sparse partite graphs. Combinatorics, Probability and Computing, 6(1):115-125, 1997.\n[Yus21] Raphael Yuster. On factors of independent transversals in $k$-partite graphs. arXiv preprint arXiv:2103.09139, 2021.\n\nProof of Corollary 3.2. We first claim that for any event $B \\in \\mathcal{B}$ and a subset $S \\subseteq \\mathcal{B} \\backslash\\{B\\}$,\n\n$$\n\\operatorname{Pr}\\left[B \\mid \\bigwedge_{B^{\\prime} \\in S} \\overline{B^{\\prime}}\\right] \\leq x(B)\n$$\n\nWe apply induction on the size of $S$. When $|S|=0$, the statement (50) holds immediately by the assumption of the condition (3) in Theorem 3.1. Suppose the statement (50) is true for any $S$ such that $|S|<s$, we show it for any subset $S$ where $|S|=s$ as follows:\n\nRecall that $\\Gamma(B)$ is the set of neighbors of $B$ in the lopsidependency graph $G$ for any event $B \\in \\mathcal{B}$. Let $S_{1}=S \\cap \\Gamma(B)$, and $S_{2}=S \\backslash \\Gamma(B)$. We have\n\n$$\n\\operatorname{Pr}\\left[B \\mid \\bigwedge_{B^{\\prime} \\in S} \\overline{B^{\\prime}}\\right]=\\frac{\\operatorname{Pr}\\left[B \\wedge\\left(\\bigwedge_{B^{\\prime} \\in S_{1}} \\overline{B^{\\prime}}\\right) \\mid \\bigwedge_{B^{\\prime} \\in S_{2}} \\overline{B^{\\prime}}\\right]}{\\operatorname{Pr}\\left[\\bigwedge_{B^{\\prime} \\in S_{1}} \\overline{B^{\\prime}} \\mid \\bigwedge_{B^{\\prime} \\in S_{2}} \\overline{B^{\\prime}}\\right]}\n$$\n\nThe numerator in (51) can be bounded by\n\n$$\n\\begin{aligned}\n\\operatorname{Pr}\\left[B \\wedge\\left(\\bigwedge_{B^{\\prime} \\in S_{1}} \\overline{B^{\\prime}}\\right) \\mid \\bigwedge_{B^{\\prime} \\in S_{2}} \\overline{B^{\\prime}}\\right] & \\leq \\operatorname{Pr}\\left[B \\mid \\bigwedge_{B^{\\prime} \\in S_{2}} \\overline{B^{\\prime}}\\right] \\\\\n& \\leq \\operatorname{Pr}[B] \\quad \\text { (due to non-lopsidependency) } \\\\\n& \\leq x(B) \\prod_{B^{\\prime} \\in \\Gamma(B)}\\left(1-x\\left(B^{\\prime}\\right)\\right)\n\\end{aligned}\n$$\n\nAs for the denominator in (51), if $\\left|S_{1}\\right|=0$, the denominator is 1 and (50) follows from (52). Otherwise, $\\left|S_{1}\\right|>0$ and $\\left|S_{2}\\right|<s$, we can apply the induction hypothesis to $S_{2}$. Let $S_{1}=\\left\\{B_{1}, B_{2}, \\cdots, B_{r}\\right\\}$ where $r=\\left|S_{2}\\right|$. It holds that\n\n$$\n\\begin{aligned}\n& \\operatorname{Pr}\\left[\\bigwedge_{B^{\\prime} \\in S_{1}} \\overline{B^{\\prime}} \\mid \\bigwedge_{B^{\\prime} \\in S_{2}} \\overline{B^{\\prime}}\\right]=\\left(1-\\operatorname{Pr}\\left[B_{1} \\mid \\bigwedge_{B^{\\prime} \\in S_{2}} \\overline{B^{\\prime}}\\right]\\right)\\left(1-\\operatorname{Pr}\\left[B_{2} \\mid \\bar{B}_{1} \\wedge\\left(\\bigwedge_{B^{\\prime} \\in S_{2}} \\overline{B^{\\prime}}\\right)\\right]\\right) \\cdots \\cdots \\\\\n& \\left(1-\\operatorname{Pr}\\left[B_{r} \\mid \\bar{B}_{1} \\wedge \\cdots \\wedge \\bar{B}_{r-1} \\wedge\\left(\\bigwedge_{B^{\\prime} \\in S_{2}} \\overline{B^{\\prime}}\\right)\\right]\\right) \\\\\n& \\geq\\left(1-x\\left(B_{1}\\right)\\right)\\left(1-x\\left(B_{2}\\right)\\right) \\cdots\\left(1-x\\left(B_{r}\\right)\\right) \\quad \\text { (induction hypothesis) } \\\\\n& =\\prod_{B^{\\prime} \\in S_{1}}\\left(1-x\\left(B^{\\prime}\\right)\\right) \\\\\n& \\geq \\prod_{B^{\\prime} \\in \\Gamma(B)}\\left(1-x\\left(B^{\\prime}\\right)\\right) . \\quad\\left(S_{1} \\subseteq \\Gamma(B)\\right)\n\\end{aligned}\n$$\n\nCombining (51), (52) and (53), we get $\\operatorname{Pr}\\left[B \\mid \\bigwedge_{B^{\\prime} \\in S} \\overline{B^{\\prime}}\\right] \\leq x(B)$ and the statement (50) is proved.\nNow Corollary 3.2 can be proved. For any event $A$ defined on the probability space, suppose $T$ is a collection of events in $\\mathcal{B}$ such that $A$ is non-lopsidependent with events in $\\mathcal{B} \\backslash T$. We have\n\n$$\n\\operatorname{Pr}\\left[A \\mid \\bigwedge_{B \\in \\mathcal{B}} \\bar{B}\\right]=\\frac{\\operatorname{Pr}\\left[A \\wedge\\left(\\bigwedge_{B \\in T} \\bar{B}\\right) \\mid \\bigwedge_{B \\in \\mathcal{B} \\backslash T} \\bar{B}\\right]}{\\operatorname{Pr}\\left[\\bigwedge_{B \\in T} \\bar{B} \\mid \\bigwedge_{B \\in \\mathcal{B} \\backslash T} \\bar{B}\\right]}\n$$\n\nAgain, the numerator in (54) can be bounded by $\\operatorname{Pr}\\left[A \\mid \\bigwedge_{B \\in \\mathcal{B} \\backslash T} \\bar{B}\\right]$ which is at most $\\operatorname{Pr}[A]$ by the assumption of non-lopsidependence. Combining this fact with (53), we have\n\n$$\n\\operatorname{Pr}\\left[A \\mid \\bigwedge_{B \\in \\mathcal{B}} \\bar{B}\\right] \\leq \\operatorname{Pr}[A] \\prod_{B \\in T}(1-x(B))^{-1}\n$$\n\nwhich implies Corollary 3.2. The second part can be proved by setting $x(B)=\\mathrm{e} \\operatorname{Pr}[B]$.\n\nProof of Lemma 5.1. Let $C_{1} \\equiv\\left(v_{1} \\neq c_{1}\\right) \\vee\\left(v_{2} \\neq c_{2}\\right) \\vee \\cdots \\vee\\left(v_{k_{1}} \\neq c_{k_{1}}\\right)$ and $C_{2} \\equiv\\left(v_{1}^{\\prime} \\neq c_{1}^{\\prime}\\right) \\vee$ $\\left(v_{2}^{\\prime} \\neq c_{2}^{\\prime}\\right) \\vee \\cdots \\vee\\left(v_{k_{2}}^{\\prime} \\neq c_{k_{2}}^{\\prime}\\right)$. By definition, if $\\left(C_{1}, C_{2}\\right) \\in G_{\\Phi^{\\prime}}^{1 \\mathrm{op}}$, there exists some $P^{\\prime} \\in \\mathcal{P}^{\\prime}$ such that $v_{i}, v_{j}^{\\prime} \\in P^{\\prime}$ and $\\left(v_{i}=v_{j}^{\\prime} \\vee c_{i}^{\\prime}=c_{j}^{\\prime}\\right)$. Let $P \\in \\mathcal{P}$ be the permutation containing $P^{\\prime}$, then $v_{i}, v_{j}^{\\prime} \\in P$ and $\\left(v_{i}=v_{j}^{\\prime} \\vee c_{i}=c_{j}^{\\prime}\\right)$. Therefore, $\\left(C_{1}, C_{2}\\right) \\in G_{\\Phi}^{1 \\mathrm{op}}$. We have proved that $\\left(C_{1}, C_{2}\\right) \\in G_{\\Phi^{\\prime}}^{1 \\mathrm{op}}$ implies $\\left(C_{1}, C_{2}\\right) \\in G_{\\Phi^{\\prime}}^{1 \\mathrm{op}}$. Thus, by $\\left(C_{1}, C_{2}\\right) \\notin G_{\\Phi}^{1 \\mathrm{op}}$ we have $\\left(C_{1}, C_{2}\\right) \\notin G_{\\Phi^{\\prime}}^{1 \\mathrm{op}}$. The lemma is immediate.\n\nProof of Lemma 5.4. In what follows, we use $a^{\\sharp}$ to denote the falling factorial $a \\cdot(a-1) \\cdots(a-b+1)$.\nFor constraint $C \\in \\mathcal{C}$, suppose variables in $\\mathrm{vbl}(C)$ are in permutations $P_{1}, P_{2}, \\cdots, P_{m} \\in \\mathcal{P}$ with $q_{i} \\doteq\\left|P_{i}\\right|$, and define $k_{i} \\doteq\\left|\\mathrm{vbl}(C) \\cap P_{i}\\right|$, then the violation probability of $C$ is $\\prod_{i}\\left(\\frac{k_{i}}{q_{i}^{\\prime}}\\right)^{-1}$. Note that\n\n$$\n\\prod_{i}\\left(q_{i}^{k_{i}}\\right)^{-1} \\leq \\prod_{i}\\left(q_{i}^{\\frac{k_{i}}{k_{i}}}\\right)^{-1} \\leq p\n$$\n\nMoreover, in the decomposed formula $\\Phi^{\\prime}$, suppose $P_{i} \\in \\mathcal{P}$ is decomposed into $P_{1}^{\\prime}, P_{2}^{\\prime}, \\cdots, P_{t}^{\\prime}$ for each $i \\in[m]$. Define $q_{i j} \\doteq\\left|P_{j}^{\\prime}\\right|$ and $k_{i j} \\doteq\\left|\\mathrm{vbl}(C) \\cap P_{j}^{\\prime}\\right|$ for each $j \\in[t]$. One can verify that the violation probability of $C$ in the decomposed formula can be bounded as follows:\n\n$$\n\\prod_{i, j}\\left(\\frac{k_{i j}}{q_{i j}}\\right)^{-1} \\leq \\prod_{i, j}\\left(\\frac{c}{q_{i j}}\\right)^{k_{i j}}\n$$\n\nSince $\\mathcal{P}^{\\prime}$ is a $\\zeta$-decomposition of $\\mathcal{P}$, we have $q_{i}^{\\zeta}=_{q} q_{i j}$ for each $j \\in[t]$. Consequently, the violation probability of $C$ in the decomposed formula can then be upper bounded by\n\n$$\n\\prod_{i, j}\\left(q_{i j}^{k_{i j}}\\right)^{-1} \\leq \\prod_{i, j}\\left(\\frac{c}{q_{i j}}\\right)^{k_{i j}}=_{q} \\prod_{i, j}\\left(\\frac{c}{q_{i}^{\\zeta}}\\right)^{k_{i j}}=\\prod_{i}\\left(\\frac{c}{q_{i}^{\\zeta}}\\right)^{k_{i}}<_{q} \\prod_{i}\\left(q_{i}^{\\zeta \\cdot k_{i}}\\right)^{-1} \\leq p^{\\zeta}\n$$\n\nwhere the first inequality holds by (55) and the last inequality holds by (56). Hence, the lemma is immediate.\n\nProof of Lemma 5.7. For two states $\\mathcal{Q}_{1}, \\mathcal{Q}_{2} \\in \\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$, let $M\\left(\\mathcal{Q}_{1}, \\mathcal{Q}_{2}\\right)$ be the transition probability of our permutation-wise Glauber dynamics, which can be specified as follows:\n\n- If there exists some $P_{1}, P_{2} \\in \\mathcal{P}$ such that $P_{1} \\neq P_{2}$ and $\\mathcal{Q}_{1}\\left(P_{1}\\right) \\neq \\mathcal{Q}_{2}\\left(P_{1}\\right), \\mathcal{Q}_{1}\\left(P_{2}\\right) \\neq \\mathcal{Q}_{2}\\left(P_{2}\\right)$, we have $M\\left(\\mathcal{Q}_{1}, \\mathcal{Q}_{2}\\right)=0$ since in each step, only on permutation in $\\mathcal{P}$ can be updated.\n- If there exists a unique $P \\in \\mathcal{P}$ such that $\\mathcal{Q}_{1}(P) \\neq \\mathcal{Q}_{2}(P)$, we should first pick $P$ to sample, which happens with probability $1 /|\\mathcal{P}|$; then sample $\\sigma \\sim \\Phi^{\\prime}$ where $\\Phi^{\\prime}=\\left(\\mathcal{P}^{\\prime} \\circ P, \\mathcal{Q}^{\\prime} \\circ \\mathcal{Q}(P), \\mathcal{C}\\right)$ and $Q_{2}(P)=\\sigma(P)$. Therefore, $M\\left(\\mathcal{Q}_{1}, \\mathcal{Q}_{2}\\right)=1 /|\\mathcal{P}| \\cdot v_{P}^{\\mathcal{Q}_{1}}\\left(\\mathcal{Q}_{2}\\right)$. Note that the probability is non-zero since $\\epsilon p_{\\Phi^{\\prime}} \\Delta_{\\Phi^{\\prime}} \\leq 1$ for any $\\Phi^{\\prime}=\\Phi\\left[\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right]$ where $\\mathcal{Q}^{\\prime} \\in \\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$.\n- If $Q_{1}=Q_{2}$, we should ensure that the updated domains are consistent. Therefore, $M\\left(\\mathcal{Q}_{1}, \\mathcal{Q}_{2}\\right)=$ $\\sum_{P \\in \\mathcal{P}} v_{P}^{\\mathcal{Q}_{1}}\\left(\\mathcal{Q}_{2}\\right)$.\nAs discussed above, one can verify that the idealized permutation-wise Glauber dynamics is irreducible and aperiodic, which implies that $\\mathbb{P}$ has a unique stationary distribution by Theorem 3.4.\n\nFinally, we verify that $v$ is the stationary distribution, that is, $\\forall \\mathcal{Q}_{1}, \\mathcal{Q}_{2} \\in \\Omega\\left[\\Phi, \\mathcal{P}^{\\prime}\\right]$\n\n$$\nv\\left(\\mathcal{Q}_{1}\\right) M\\left(\\mathcal{Q}_{1}, \\mathcal{Q}_{2}\\right)=v\\left(\\mathcal{Q}_{2}\\right) M\\left(\\mathcal{Q}_{2}, \\mathcal{Q}_{1}\\right)\n$$\n\nIt is obvious that (57) holds when $\\mathcal{Q}_{1}=\\mathcal{Q}_{2}$ or $\\mathcal{Q}_{1}, \\mathcal{Q}_{2}$ differ in at least two permutation sets among $\\mathcal{P}^{\\prime}$. As for the case where $\\mathcal{Q}_{1}, \\mathcal{Q}_{2}$ differ in the unique permutation set $P \\in \\mathcal{P}$, we have\n\n$$\nv_{P}^{\\mathcal{Q}_{1}}\\left(\\mathcal{Q}_{2}\\right)=\\frac{v\\left(\\mathcal{Q}_{2}\\right)}{\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma(\\mathcal{P} \\backslash P)=\\mathcal{Q}_{1}(\\mathcal{P} \\backslash P)\\right]}, \\quad v_{P}^{\\mathcal{Q}_{2}}\\left(\\mathcal{Q}_{1}\\right)=\\frac{v\\left(\\mathcal{Q}_{1}\\right)}{\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma(\\mathcal{P} \\backslash P)=\\mathcal{Q}_{1}(\\mathcal{P} \\backslash P)\\right]}\n$$\n\nPlugging this into (57), the lemma is immediate.\n\n$$\nv_{Y \\circ P}(X)=\\frac{v(X)}{\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma[\\mathcal{P} \\backslash P]=Y[\\mathcal{P} \\backslash P]\\right]}\n$$\n\nSince $X[\\mathcal{P} \\backslash P]=Y[\\mathcal{P} \\backslash P], v(X) v_{X \\times P}(Y)=v(Y) v_{Y \\times P}(X)$, so $v(X) \\mathbb{P}(X, Y)=v(Y) \\mathbb{P}(Y, X)$. Therefore, the stationary distribution is $v$.", "tables": {}, "images": {}}, {"section_id": 15, "text": "# Appendix C. Missing Proofs in Section 6 \n\nIn the remaining section, we complete the proofs of the lemmas in Section 6.\nProof of Lemma 6.6. We first show that, for any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ satisfying $2 \\mathrm{e} p \\Delta \\leq 1$ with a permutation set $P \\in \\mathcal{P}$, the violation probability of each constraint in $\\mathcal{C}(P)$ does not deviate significantly in the uniform distribution among all valid assignments of $\\Phi$ that satisfy all constraints $\\mathcal{C} \\backslash \\mathcal{C}(P)$. Specifically, we have the following lemma.\n\nLemma C.1. Given any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ satisfying $2 \\mathrm{e} p \\Delta \\leq 1$ with a permutation set $P \\in \\mathcal{P}$, let $\\Phi_{1}, \\ldots, \\Phi_{K}$ be the factorization of $(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C} \\backslash \\mathcal{C}(P))$ where $\\Phi_{K}=(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\emptyset)$, and $\\sigma_{1}, \\cdots, \\sigma_{K}$ be independently drawn from $\\mu_{\\Phi_{1}}, \\cdots, \\mu_{\\Phi_{K}}$. For any constraint $C \\in \\mathcal{C}(P)$,\n\n$$\n\\operatorname{Pr}_{\\sigma_{[K]} \\sim \\mu_{[K]}}[\\neg C] \\leq 2 \\mathbb{P}[\\neg C]\n$$\n\nProof. Recall that $\\mathbb{P}$ is the uniform distribution of all valid assignments of $\\Phi$. We can apply the lopsided LLL to establish an upper bound on the probability of violation for each constraint $C \\in \\mathcal{C}(P)$ as follows,\n\n$$\n\\begin{aligned}\n\\operatorname{Pr}_{\\sigma_{[K]} \\sim \\mu_{[K]}}[\\neg C] & =\\mathbb{P}\\left[\\neg C \\mid \\bigwedge_{C^{\\prime} \\in \\mathcal{C} \\backslash \\mathcal{C}(P)} C^{\\prime}\\right] \\\\\n& \\leq \\mathbb{P}[\\neg C] \\cdot \\prod_{C^{\\prime} \\sim C, C^{\\prime} \\in \\mathcal{C} \\backslash \\mathcal{C}(P)}\\left(1-\\mathrm{e} \\mathbb{P}\\left[\\neg C^{\\prime}\\right]\\right)^{-1} \\\\\n& \\leq \\mathbb{P}[\\neg C] \\cdot(1-\\mathrm{e} p \\Delta)^{-1} \\leq 2 \\mathbb{P}[\\neg C] \\quad \\text { (by Proposition } 3.11 \\text { and } 2 \\mathrm{e} p \\Delta \\leq 1)\n\\end{aligned}\n$$\n\nFurthermore, the lopsided LLL can also provide a lower bound for the probability of satisfying all constraints in $C \\in \\mathcal{C}(P)$.\n\nLemma C.2. Let integer $\\Delta \\geq 1$. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $\\mathrm{e} p_{\\Phi} \\Delta_{\\Phi} \\leq 1, \\Delta_{\\Phi} \\leq \\Delta$ with a permutation set $P \\in \\mathcal{P}$ where $|P| \\geq 2 \\mathrm{e} \\Delta$, let $\\Phi_{1}, \\ldots, \\Phi_{K}$ be the factorization of $(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C} \\backslash \\mathcal{C}(P))$ where $\\Phi_{K}=(\\{P\\},\\{\\mathcal{Q}(P)\\}, \\emptyset)$, and $\\sigma_{1}, \\cdots, \\sigma_{K}$ be independently drawn from $\\mu_{\\Phi_{1}}, \\cdots, \\mu_{\\Phi_{K}}$. We have\n\n$$\n\\operatorname{Pr}_{[K] \\sim \\mu_{[K]}}\\left[\\bigwedge_{C \\in \\mathcal{C}(P)} C\\right] \\geq \\exp (-2 \\mathrm{e} \\Delta)\n$$\n\nProof. It suffices to show that for any $\\sigma_{[K-1]}$ drawn from $\\mu_{[K-1]}$,\n\n$$\n\\operatorname{Pr}_{\\tau \\sim \\mu_{K^{\\prime}}}\\left[\\bigwedge_{C \\in \\mathcal{C}(P)} C\\right] \\geq \\exp (-2 \\mathrm{e} \\Delta)\n$$\n\nwhere $\\Phi^{\\prime}=\\Phi\\left[\\sigma_{[K-1]}\\right]$. Recall that the notation $\\Phi\\left[\\sigma_{[K-1]}\\right]$ is defined in (15). By $\\mathbb{P}_{\\Phi^{\\prime}}[\\neg C] \\leq 1 /|P|$ for each constraint $C \\in \\mathcal{C}(P)$ and the assumption that $|P| \\geq 2 \\mathrm{e} \\Delta$, the lopsided LLL is applicable. Combining with Lemma 3.3, we have\n\n$$\n\\operatorname{Pr}_{\\tau \\sim \\mu_{K^{\\prime}}}\\left[\\bigwedge_{C \\in \\mathcal{C}(P)} C\\right] \\geq\\left(1-\\frac{\\mathrm{e}}{|P|}\\right)^{|P| \\Delta} \\geq\\left(1-\\frac{1}{2}\\right)^{2 \\mathrm{e} \\Delta} \\geq \\exp (-2 \\mathrm{e} \\Delta)\n$$\n\nwhere the third inequality holds by Proposition 3.11, and the proof is complete.\nWe are now ready to prove Lemma 6.6.\n\nProof of Lemma 6.6. In the case where $p_{\\max }|P| \\Delta \\leq 1 / 4$, we can directly apply the union bound as follows,\n\n$$\n\\operatorname{Pr}_{\\sigma_{[K]} \\sim \\rho_{[K]}}\\left[\\sigma_{[K]} \\in \\Omega_{\\Phi}\\right]=1-\\operatorname{Pr}_{\\sigma_{[K]} \\sim \\rho_{[K]}}\\left[\\bigvee_{C \\in \\mathcal{C}(P)} \\neg C\\right] \\geq 1-\\sum_{C \\in \\mathcal{C}(P)} 2 \\mathbb{P}_{\\Phi}[\\neg C] \\geq 1-2 p_{\\max }|P| \\Delta \\geq 1 / 2\n$$\n\naccording to Lemma C.1.\nOtherwise, we can assume $|P| \\geq 2 \\mathrm{e} \\Delta$ by the following argument. If $|P|<2 \\mathrm{e} \\Delta$, then we have $p_{\\max }|P| \\Delta \\leq 2 \\mathrm{e} p \\Delta^{2} \\leq \\frac{1}{4}$ by the assumption that $8 \\mathrm{e} p \\Delta^{2} \\leq 1$, which contradicts to $p_{\\max }|P| \\Delta \\geq 1 / 4$. Therefore, Lemma C. 2 is applicable. It holds that\n\n$$\n\\operatorname{Pr}_{\\sigma_{[K]} \\sim \\rho_{[K]}}\\left[\\sigma_{[K]} \\in \\Omega_{\\Phi}\\right]=\\operatorname{Pr}_{\\sigma_{[K]} \\sim \\rho_{[K]}}\\left[\\bigwedge_{C \\in \\mathcal{C}(P)} C\\right] \\geq 2^{-2 \\mathrm{e} \\Delta} \\geq \\frac{\\varepsilon}{\\mathrm{e}^{4} n}\n$$\n\nwhere the second inequality follows from $2 \\mathrm{e} \\Delta \\geq \\log \\left(\\mathrm{e}^{4} n / \\varepsilon\\right)$.\nCombining all these facts, the proof is immediate.\nProof of Lemma 6.7. By definition, we have\n\n$$\n\\operatorname{Pr}_{\\sigma \\sim \\rho_{\\mathrm{ff}}}\\left[\\sigma \\in \\Omega_{\\Phi}\\right]=\\mathbb{P}_{\\Phi}\\left[\\bigwedge_{C \\in \\mathcal{C} \\backslash \\mathcal{C}^{1}} C \\mid \\bigwedge_{C^{\\prime} \\in \\mathcal{C}^{1}} C^{\\prime}\\right]=1-\\mathbb{P}_{\\Phi}\\left[\\bigvee_{C \\in \\mathcal{C} \\backslash \\mathcal{C}^{1}} \\neg C \\mid \\bigwedge_{C^{\\prime} \\in \\mathcal{C}^{1}} C^{\\prime}\\right]\n$$\n\nIt suffices to bound the violation probability of each constraint in $\\mathcal{C} \\backslash \\mathcal{C}^{1}$ conditioned on the satisfaction of all constraints in $\\mathcal{C}^{1}$. Note that $\\mathbb{P}_{\\Phi}[\\neg C]=|P|^{-1}$ for any $C \\in \\mathcal{C}^{1}$, and $\\mathbb{P}_{\\Phi}[\\neg C] \\leq \\frac{1}{|P|[P-1]}$ for any $C \\in \\mathcal{C} \\backslash \\mathcal{C}^{1}$. The lopsided LLL is applicable given that $|P| \\geq 2 \\mathrm{e} \\Delta$. By Lemma 3.3, we have for each $C \\in \\mathcal{C} \\backslash \\mathcal{C}^{1}$,\n\n$$\n\\mathbb{P}_{\\Phi}\\left[\\neg C \\mid \\bigwedge_{C^{\\prime} \\in \\mathcal{C}^{1}} C^{\\prime}\\right] \\leq \\mathbb{P}_{\\Phi}[\\neg C] \\cdot \\prod_{C^{\\prime} \\in \\mathcal{C}^{1}: C^{\\prime} \\sim C}\\left(1-\\mathrm{e} \\mathbb{P}_{\\Phi}\\left[\\neg C^{\\prime}\\right]\\right)^{-1} \\leq \\frac{1}{|P|[P-1]} \\cdot\\left(1-\\frac{\\mathrm{e}}{|P|}\\right)^{-\\Delta} \\leq \\frac{2}{|P|[P-1]}\n$$\n\nwhere the last equality holds by Proposition 3.11 and $|P| \\geq 2 \\mathrm{e} \\Delta$. Combining with union bound and $\\left|\\mathcal{C} \\backslash \\mathcal{C}^{1}\\right| \\leq|P| \\Delta$, the proof is immediate.\n\nProof of Lemma 6.9. At last, we prove Lemma 6.9. According to the Condition 6.4, $\\Phi_{1}, \\cdots, \\Phi_{K-1}$ is a collection of small formulas. Then each solution $\\sigma_{i}$ of $\\Phi_{i}$ has minor impact on the size of $\\rho\\left(\\sigma_{[K-1]}\\right)=$ $\\left|\\mathcal{C}^{1}\\left[\\sigma_{[K-1]}\\right]\\right|$. This can be captured by the following lemma.\n\nLemma C.3. Consider any instance satisfying Condition 6.4. The function $\\rho$ has bounded differences with respect to $\\left\\{k L \\Delta^{2} \\log (n / \\varepsilon), \\cdots, k L \\Delta^{2} \\log (n / \\varepsilon)\\right\\}$ among all satisfying assignments $\\sigma_{[K-1]}$ of $\\Phi_{[K-1]}$. Proof. Given any pair of satisfying assignments $\\sigma_{[K-1]}=\\sigma_{1}, \\cdots, \\sigma_{K-1}$ and $\\sigma_{[K-1]}^{\\prime}=\\sigma_{1}^{\\prime}, \\cdots, \\sigma_{K-1}^{\\prime}$, we have\n\n$$\n\\left|\\rho\\left(\\sigma_{[K-1]}\\right)-\\rho\\left(\\sigma_{[K-1]}^{\\prime}\\right)\\right| \\leq \\sum_{i \\in[K-1]}\\left|\\rho\\left(\\sigma_{[K-i]} \\circ \\sigma_{[K-i+1, K-1]}^{\\prime}\\right)-\\rho\\left(\\sigma_{[K-i-1]} \\circ \\sigma_{[K-i, K-1]}^{\\prime}\\right)\\right|\n$$\n\nwhere $\\sigma_{[K-i]} \\circ \\sigma_{[K-i+1, K-1]}^{\\prime}$ is the sequence of $\\sigma_{1}, \\cdots, \\sigma_{K-i}, \\sigma_{K-i+1}^{\\prime}, \\cdots, \\sigma_{K-1}^{\\prime}$ for each $i \\in[K-1]$.\nRecall that $\\rho\\left(\\sigma_{[K-1]}\\right)=\\left|\\mathcal{C}^{1}\\left[\\sigma_{[K-1]}\\right]\\right|$ for any satisifying assignments $\\sigma_{[k-1]}$ of $\\Phi_{[K-1]}$. The discrepancy between the constraints in $\\rho\\left(\\sigma_{[K-i]} \\circ \\sigma_{[K-i+1, K-1]}^{\\prime}\\right)$ and those in $\\rho\\left(\\sigma_{[K-i-1]} \\circ \\sigma_{[K-i, K-1]}^{\\prime}\\right)$ only comes from the constraints intersecting with the formula $\\Phi_{i}$ in $\\mathcal{C}(P)$, for each $i \\in[K-1]$. Consequently, $\\left|\\rho\\left(\\sigma_{[K-i]} \\circ \\sigma_{[K-i+1, K-1]}^{\\prime}\\right)-\\rho\\left(\\sigma_{[K-i-1]} \\circ \\sigma_{[K-i, K-1]}^{\\prime}\\right)\\right|$ can be upper bounded by the number of constraints intersecting with the formula $\\Phi_{i}$ in $\\mathcal{C}(P)$.\n\nNote that each variable in $\\Phi_{i}$ intersects with at most $\\Delta$ constraints. Therefore, the number of constraints intersecting with the formula $\\Phi_{i}$ in $\\mathcal{C}(P)$ does not exceed the multiplication between $\\Delta$ and the number of variables in the formulas $\\Phi_{i}$. By Condition 6.4, $\\left|V_{\\Phi_{i}}\\right|$ is at most $k L \\Delta \\log (n / \\varepsilon)$.\n\nCombining all these facts, we have\n\n$$\n\\left|\\rho\\left(\\sigma_{[K-i]} \\circ \\sigma_{(K-i+1, K-1)}^{\\prime}\\right)-\\rho\\left(\\sigma_{[K-i-1]} \\circ \\sigma_{(K-i, K-1)}^{\\prime}\\right)\\right| \\leq \\Delta \\cdot(k L \\Delta \\log (n / \\varepsilon))\n$$\n\nPlugging (59) into (58), the proof is immediate.\nSince $\\Phi_{1}, \\cdots, \\Phi_{K-1}$ are disjoint, the distribution $\\mu_{\\Phi_{1}}, \\cdots, \\mu_{\\Phi_{K-1}}$ are mutually independent. Combining with Lemma C.3, we can apply the McDiarmid's inequality to exhibit the concentration of the function $\\rho\\left(\\sigma_{[K-1]}\\right)$.\nProof of Lemma 6.9. Note that\n\n$$\n\\begin{aligned}\n& \\exp \\left(-\\frac{2|P|^{2}}{144\\left(k L \\Delta^{2} \\log (n / \\varepsilon)\\right)^{2} \\cdot(K-1)}\\right) \\\\\n\\leq & \\exp \\left(-\\frac{|P|^{2}}{72\\left(k L \\Delta^{2} \\log (n / \\varepsilon)\\right)^{2} \\cdot k|P| \\Delta}\\right) \\\\\n= & \\exp \\left(-\\frac{|P|}{72 k^{3} L^{2} \\Delta^{5} \\log ^{2}(n / \\varepsilon)}\\right) \\\\\n\\leq & \\exp \\left(\\frac{-24 \\mathrm{e}^{3} \\ln 2 \\cdot \\Delta^{3}}{\\log ^{2}(n / \\varepsilon)}\\right) \\\\\n\\leq & \\exp \\left(-6 \\mathrm{e} \\ln 2 \\cdot \\Delta\\right)\n\\end{aligned}\n$$\n\n(by $|P| \\geq 1728 \\mathrm{e}^{3} \\ln 2 \\cdot k^{3} L^{2} \\Delta^{8}$ )\n(by $2 \\mathrm{e} \\Delta \\geq \\log \\left(\\mathrm{e}^{4} n / \\varepsilon\\right)$ )\nThen the lemma is immediate by Lemma C. 3 and Theorem 3.9.", "tables": {}, "images": {}}, {"section_id": 16, "text": "# Appendix D. Missing proofs in section 8\n## D.1. Missing proofs in Section 8.1.\n\nProof of Lemma 8.2. We first claim that for any $\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime} \\in \\mathcal{V}$, the weighted shortest path distance between $\\mathcal{Q}_{1}^{\\prime}$ and $\\mathcal{Q}_{2}^{\\prime}$ is at least $\\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}\\right)$. Suppose there is a path $\\left(\\mathcal{Q}_{1}=\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}, \\cdots, \\mathcal{Q}_{\\ell+1}=\\mathcal{Q}_{2}^{\\prime}\\right)$ between $\\mathcal{Q}_{1}^{\\prime}$ and $\\mathcal{Q}_{2}^{\\prime}$ in $\\mathcal{G}$ where $\\ell<\\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}\\right)$. Since $\\left\\{\\mathcal{Q}_{i}, \\mathcal{Q}_{i+1}\\right\\} \\in \\mathcal{E}$ for each $i \\in[\\ell]$, we have $\\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}}\\left|\\mathcal{Q}_{i}\\left(P^{\\prime}\\right) \\backslash \\mathcal{Q}_{i+1}\\left(P^{\\prime}\\right)\\right|=1$, which implies that $\\operatorname{Dis}\\left(\\mathcal{Q}_{1}, \\mathcal{Q}_{i+1}\\right) \\leq \\operatorname{Dis}\\left(\\mathcal{Q}_{1}, \\mathcal{Q}_{i}\\right)+1$. Therefore, $\\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}\\right)=\\operatorname{Dis}\\left(\\mathcal{Q}_{1}, \\mathcal{Q}_{\\ell+1}\\right) \\leq \\ell$, which contradicts our assumption.\n\nTo complete the proof, it suffices to construct a path in $\\mathcal{G}$ with length $\\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}\\right)$. For each $P^{\\prime} \\in \\mathcal{P}^{\\prime}$ where $\\left|\\mathcal{Q}_{1}^{\\prime}\\left(P^{\\prime}\\right) \\backslash \\mathcal{Q}_{2}^{\\prime}\\left(P^{\\prime}\\right)\\right| \\neq \\emptyset$, we eliminate the discrepancy between $\\mathcal{Q}_{1}^{\\prime}$ and $\\mathcal{Q}_{2}^{\\prime}$ by substituting the elements in $\\mathcal{Q}_{1}^{\\prime}\\left(P^{\\prime}\\right) \\backslash \\mathcal{Q}_{2}^{\\prime}\\left(P^{\\prime}\\right)$ to $\\mathcal{Q}_{2}^{\\prime}\\left(P^{\\prime}\\right) \\backslash \\mathcal{Q}_{1}^{\\prime}\\left(P^{\\prime}\\right)$ sequentially through the edges in $\\mathcal{E}$. As $\\left|\\mathcal{Q}_{1}^{\\prime}\\left(P^{\\prime}\\right) \\backslash \\mathcal{Q}_{2}^{\\prime}\\left(P^{\\prime}\\right)\\right|=$ $\\left|\\mathcal{Q}_{2}^{\\prime}\\left(P^{\\prime}\\right) \\backslash \\mathcal{Q}_{1}^{\\prime}\\left(P^{\\prime}\\right)\\right|$, the length of the aforementioned path is $\\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}}\\left|\\mathcal{Q}_{1}^{\\prime}\\left(P^{\\prime}\\right) \\backslash \\mathcal{Q}_{2}^{\\prime}\\left(P^{\\prime}\\right)\\right|=\\operatorname{Dis}\\left(\\mathcal{Q}_{1}^{\\prime}, \\mathcal{Q}_{2}^{\\prime}\\right)$.\nD.2. Probabilistic properties for PDC formulas. In this section, we introduce some useful probabilistic bounds for the analysis of the PDC formulas.\nD.2.1. Marginal bounds for individual value. The following lemma establishes the upper and lower bounds for the probability that a variable is assigned a specific value in the LLL regime.\n\nLemma D.1. Let $p \\in(0,1)$ and $\\Delta \\geq 1$ satisfying $8 \\mathrm{e} p \\Delta \\leq 1$. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $p_{\\Phi} \\leq p, \\Delta_{\\Phi} \\leq \\Delta$ with a permutation set $P \\in \\mathcal{P}$. For any $v \\in P$ and $c \\in \\mathcal{Q}(P)$, let $\\mathcal{C}^{\\prime} \\subseteq \\mathcal{C}$ be the set of constraints that the event $v=c$ is non-lopsidependent with the violation of the constraints in $\\mathcal{C} \\backslash \\mathcal{C}^{\\prime}$ in the formula $\\Phi$. Assume $\\mathbb{P}[\\neg C] \\leq p^{\\prime}$ for any $C \\in \\mathcal{C}^{\\prime}$. It holds that\n\n$$\n\\frac{1}{|P|}-4 \\mathrm{e} p^{\\prime} \\Delta \\leq \\operatorname{Pr}_{\\sigma \\sim \\mu}[\\sigma(v)=c] \\leq \\frac{1}{|P|}\\left(1+4 \\mathrm{e} p^{\\prime} \\Delta\\right)\n$$\n\nProof. By Lemma 3.3, we have\n\n$$\n\\operatorname{Pr}_{\\sigma \\sim \\mu}[\\sigma(v)=c] \\leq \\mathbb{P}[v \\leftarrow c] \\cdot\\left(1-\\mathrm{e} p^{\\prime}\\right)^{-2 \\Delta} \\leq \\frac{1}{|P|} \\cdot \\frac{1}{\\left(1-2 \\mathrm{e} p^{\\prime} \\Delta\\right)} \\leq \\frac{1}{|P|} \\cdot\\left(1+4 \\mathrm{e} p^{\\prime} \\Delta\\right)\n$$\n\nwhere the first inequality follows from that $\\left|\\mathcal{C}^{\\prime}\\right| \\leq 2 \\Delta$, and the second inequality follows from Proposition 3.11 .\n\nOn the other hand, by (60), we have\n\n$$\n\\operatorname{Pr}_{\\sigma \\rightarrow \\mu}[\\tau(v)=c]=1-\\sum_{c^{\\prime} \\in \\mathcal{Q}(P) \\backslash\\{c\\}} \\operatorname{Pr}_{\\sigma \\rightarrow \\mu}\\left[\\tau(v)=c^{\\prime}\\right] \\geq \\frac{1}{|P|}-4 \\mathrm{e} p^{\\prime} \\Delta\n$$\n\nMoreover, if the variable is not assigned a forbidden value, then we can refine the bound as follows. Recall that the quantity $\\Lambda(\\cdot)$ was defined in (31) of Section 8.2.\n\nLemma D.2. Given the instance stated in Lemma D.1, if we further assume that $c \\in \\mathcal{Q}(P) \\backslash \\Lambda(\\mathcal{C}, v)$, we have\n\n$$\n\\operatorname{Pr}_{\\sigma \\rightarrow \\mu}[\\sigma(v)=c] \\geq \\frac{1}{|P|}\\left(1-\\frac{2 \\Delta}{|P|}\\right)\n$$\n\nProof. For any $x \\in \\operatorname{supp}\\left(\\mu_{o}\\right)$, we use $\\Omega_{u \\circ x}$ to denote the set of all satisfying assignment $\\sigma \\in \\Omega$ such that $\\sigma(v)=x$, and $\\Omega_{u \\circ x}^{*}$ to denote the set of all valid assignment $\\sigma \\in \\Omega^{*}$ such that $\\sigma(v)=x$. For each $x \\in \\operatorname{supp}\\left(\\mu_{o}\\right) \\backslash\\{c\\}$, we define the mapping $f_{x}: \\sigma \\rightarrow \\tau$ from $\\Omega_{u \\circ x}$ to $\\Omega_{u \\circ c}^{*}$ satisfying\n\n$$\n\\tau(v)=\\sigma(u), \\tau(u)=\\sigma(v), \\text { and } \\tau(V \\backslash\\{u, v\\})=\\sigma(V \\backslash\\{u, v\\})\n$$\n\nwhere $u$ is the variable such that $\\sigma(u)=c$ and $u \\in P$. One can verify that the mapping is injective, which implies that\n\n$$\n\\operatorname{Pr}_{\\sigma \\rightarrow \\mu}\\left[\\sigma \\in \\Omega_{u \\circ x}, f_{x}(\\sigma) \\in \\Omega_{u \\circ c}\\right] \\leq \\operatorname{Pr}_{\\sigma \\rightarrow \\mu}\\left[\\sigma \\in \\Omega_{u \\circ c}\\right]\n$$\n\nDefine the collection of variables $V_{x} \\doteq\\{u \\in V \\backslash\\{v\\} \\mid x \\in \\Lambda(\\mathcal{C}, u)\\}$, and note that $\\left|V_{x}\\right| \\leq \\Delta$. Given any $\\sigma \\in \\Omega_{u \\circ x}$, if $u \\notin V_{x}$ and $\\sigma(u)=c$, we have $f_{x}(\\sigma) \\in \\Omega_{u \\circ c}$ since $c \\in \\mathcal{Q}(P) \\backslash \\Lambda(\\mathcal{C}, v)$. Let $\\mathcal{C}^{\\prime} \\subseteq \\mathcal{C}$ be the set of constraints that the event $v=x, u=c$ is non-lopsidependent with the violation of the constraints in $\\mathcal{C} \\backslash \\mathcal{C}^{\\prime}$. Combining all these facts with Lemma 3.3, it holds that for each $x \\in \\operatorname{supp}\\left(\\mu_{o}\\right) \\backslash\\{c\\}$,\n\n$$\n\\begin{aligned}\n\\operatorname{Pr}_{\\sigma \\rightarrow \\mu}\\left[\\sigma \\in \\Omega_{u \\circ x}, f_{x}(\\sigma) \\notin \\Omega_{u \\circ c}\\right] & \\leq \\sum_{u \\in V_{x}} \\operatorname{Pr}_{\\sigma \\rightarrow \\mu}[\\sigma(v)=x, \\sigma(u)=c] \\\\\n& \\leq \\sum_{u \\in V_{x}} \\mathbb{P}[\\sigma(v)=x, \\sigma(u)=c] \\cdot\\left(1-\\mathrm{e} p^{\\prime}\\right)^{-4 \\Delta} \\\\\n& \\leq \\frac{\\Delta}{|P|(|P|-1)} \\cdot\\left(1+8 \\mathrm{e} \\Delta p^{\\prime}\\right)\n\\end{aligned}\n$$\n\nwhere the second inequality holds since $\\left|\\mathcal{C}^{\\prime}\\right| \\leq 4 \\Delta$, and the last inequality holds by Proposition 3.11.\nCombining (61) and (62), we have\n\n$$\n\\begin{aligned}\n& \\sum_{x \\in \\operatorname{supp}\\left(\\mu_{o}\\right) \\backslash\\{c\\}} \\operatorname{Pr}_{\\sigma \\rightarrow \\mu}\\left[\\sigma \\in \\Omega_{u \\circ x}\\right] \\\\\n= & \\sum_{x \\in \\operatorname{supp}\\left(\\mu_{o}\\right) \\backslash\\{c\\}}\\left(\\operatorname{Pr}_{\\sigma \\rightarrow \\mu}\\left[\\sigma \\in \\Omega_{u \\circ x}, f_{x}(\\sigma) \\in \\Omega_{u \\circ c}\\right]+\\operatorname{Pr}_{\\sigma \\rightarrow \\mu}\\left[\\sigma \\in \\Omega_{u \\circ x}, f_{x}(\\sigma) \\notin \\Omega_{u \\circ c}\\right]\\right) \\\\\n\\leq & \\sum_{x \\in \\operatorname{supp}\\left(\\mu_{o}\\right) \\backslash\\{c\\}} \\operatorname{Pr}_{\\sigma \\rightarrow \\mu}\\left[\\sigma \\in \\Omega_{u \\circ c}\\right]+\\sum_{x \\in \\operatorname{supp}\\left(\\mu_{o}\\right) \\backslash\\{c\\}} \\Delta \\cdot\\left(1+8 \\mathrm{e} \\Delta p^{\\prime}\\right) /(|P|(|P|-1)) \\\\\n\\leq & \\left(|P|-1) \\cdot \\operatorname{Pr}_{\\sigma \\rightarrow \\mu}\\left[\\sigma \\in \\Omega_{u \\circ c}\\right]+\\Delta \\cdot\\left(1+8 \\mathrm{e} \\Delta p^{\\prime}\\right) /|P|\\right.\n\\end{aligned}\n$$\n\nwhich implies that\n\n$$\n\\operatorname{Pr}_{\\sigma \\rightarrow \\mu}[\\sigma(v)=c]=\\operatorname{Pr}_{\\sigma \\rightarrow \\mu}\\left[\\sigma \\in \\Omega_{u \\circ c}\\right] \\geq \\frac{1}{|P|}-\\frac{\\Delta}{|P|^{2}}\\left(1+8 \\mathrm{e} \\Delta p^{\\prime}\\right) \\geq \\frac{1}{|P|}\\left(1-\\frac{2 \\Delta}{|P|}\\right)\n$$\n\nD.2.2. Marginal bounds for multiple values. In this section, we establish bounds for the probability that a collection of variables is assigned multiple values in the LLL regime.\nLemma D.3. Let $p \\in(0,1), \\Delta \\geq 1$. Consider any PDC formula $\\Phi=(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C})$ where $p_{\\Phi} \\leq p, \\Delta_{\\Phi} \\leq \\Delta$ with a permutation set $P \\in \\mathcal{P}$, a decomposition $\\mathcal{P}^{\\prime}$ of $\\mathcal{P}$, a permutation set $P^{\\prime}=\\left\\{v_{1}, \\cdots, v_{t}\\right\\} \\in \\mathcal{P}^{\\prime}[P]$, and a domain $Q^{\\prime}=\\left\\{c_{1}, \\cdots, c_{t}\\right\\} \\subseteq \\mathcal{Q}(P)$. Assume that for any decomposition $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right)$ of $(\\mathcal{P}, \\mathcal{Q})$, we have $p_{\\Phi^{\\prime}} \\leq p$ where $\\Phi^{\\prime}=\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}, \\mathcal{C}\\right)$. If $8 \\mathrm{e} p \\Delta \\leq 1,\\left\\|P_{1}\\right|-\\left|P_{2}\\right\\|=O(1)$, for any $P_{1}, P_{2} \\in \\mathcal{P}[P]$, and $\\left|\\mathcal{P}^{\\prime}[P]\\right| \\geq 2$. We have\n\n$$\n\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q^{\\prime}\\right]>_{q}\\left(\\frac{1-4 \\mathrm{e} p^{\\prime} \\Delta\\left(|P|-\\left|P^{\\prime}\\right|+1\\right)}{1+4 \\mathrm{e} p^{\\prime} \\Delta}\\right)^{t}\\left(\\frac{|P|}{\\left|P^{\\prime}\\right|}\\right)^{-1}\n$$\n\nand\n\n$$\n\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q^{\\prime}\\right]<_{q}\\left(\\frac{1-4 \\mathrm{e} p^{\\prime} \\Delta\\left(|P|-\\left|P^{\\prime}\\right|+1\\right)}{1+4 \\mathrm{e} p^{\\prime} \\Delta}\\right)^{-t}\\left(\\frac{|P|}{\\left|P^{\\prime}\\right|}\\right)^{-1}\n$$\n\nwhere $p^{\\prime}=\\left|P^{\\prime}\\right| /\\left(|P|-\\left|P^{\\prime}\\right|+1\\right) \\cdot p$. Moreover, we also have\n\n$$\n\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q^{\\prime} \\mid c_{1} \\in \\sigma\\left(P^{\\prime}\\right)\\right]>_{q}\\left(\\frac{1-4 \\mathrm{e} p^{\\prime} \\Delta\\left(|P|-\\left|P^{\\prime}\\right|+1\\right)}{1+4 \\mathrm{e} p^{\\prime} \\Delta}\\right)^{t-1} \\cdot\\left(\\frac{|P|-1}{\\left|P^{\\prime}\\right|-1}\\right)^{-1}\n$$\n\nTo prove Lemma D.3, we first introduce more notations. For each $j \\in[t]$, let $\\Phi_{j}=\\left(\\mathcal{P}_{j}, \\mathcal{Q}_{j}, \\mathcal{C}\\right)$ be the formula where\n\n$$\n\\begin{gathered}\n\\mathcal{P}_{j}=(\\mathcal{P} \\backslash\\{P\\}) \\cup\\left\\{\\left\\{P^{\\prime} \\backslash\\left\\{v_{j}\\right\\}, P \\backslash P^{\\prime} \\cup\\left\\{v_{j}\\right\\}\\right\\}\\right\\} \\\\\n\\mathcal{Q}_{j}=(\\mathcal{Q} \\backslash\\{\\mathcal{Q}(P)\\}) \\cup\\left(\\left\\{Q^{\\prime} \\backslash\\left\\{c_{t}\\right\\}, \\mathcal{Q}(P) \\backslash Q^{\\prime} \\cup\\left\\{c_{t}\\right\\}\\right\\}\\right)\n\\end{gathered}\n$$\n\nThe violation probability for the constraints in these formulas can be upper bounded as follows.\nProposition D.4. For each $j \\in[t]$ and $C \\in \\mathcal{C}$, if $v_{j} \\in v \\mathrm{bl}(C)$ or $\\left(P \\backslash P^{\\prime}\\right) \\cap v \\mathrm{bl}(C) \\neq \\emptyset$, we have\n\n$$\n\\mathbb{P}_{\\Phi_{j}}[\\neg C] \\leq\\left|P^{\\prime}\\right| /\\left(|P|-\\left|P^{\\prime}\\right|+1\\right) \\cdot p\n$$\n\nWe are now ready to complete the proof of Lemma D.3.\nProof of Lemma D.3. Let $r=\\left(1-4 e p^{\\prime} \\Delta\\left(|P|-\\left|P^{\\prime}\\right|+1\\right)\\right) /\\left(1+4 e p^{\\prime} \\Delta\\right)$ in the following discussion. For each $j \\in[t]$, define\n\n$$\nB_{j} \\doteq\\left\\{\\sigma\\left(v_{j}\\right)=c_{t} \\mid \\sigma\\left(P^{\\prime} \\backslash\\left\\{v_{j}\\right\\}\\right)=Q^{\\prime} \\backslash\\left\\{c_{t}\\right\\}\\right\\}, \\quad A_{j}=\\left\\{\\sigma\\left(P^{\\prime} \\backslash\\left\\{v_{j}\\right\\}\\right)=Q^{\\prime} \\backslash\\left\\{c_{t}\\right\\}\\right\\}\n$$\n\nwhere $\\sigma \\sim \\mu_{\\Phi}$. By definition, we have\n\n$$\n\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q^{\\prime}\\right]=\\sum_{j \\in[t]} \\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[A_{j}\\right] \\cdot \\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[B_{j}\\right]=\\sum_{j \\in[t]} \\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[A_{j}\\right] \\cdot \\operatorname{Pr}_{\\tau \\sim \\mu_{\\theta_{j}}}\\left[\\tau\\left(v_{j}\\right)=c_{t}\\right]\n$$\n\nConsider the domain $Q^{\\prime \\prime}=\\left\\{c_{1}, c_{2}, \\cdots, c_{t}^{\\prime}\\right\\}$ where $c_{t}^{\\prime} \\neq c_{t}$ and $c_{t}^{\\prime} \\in \\mathcal{Q}(P)$. We first claim that\n\n$$\nr \\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q^{\\prime}\\right] \\leq \\operatorname{Pr}_{\\tau \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q^{\\prime \\prime}\\right]\n$$\n\nFor each $j \\in[t]$, let $\\mathcal{C}^{\\prime} \\subseteq \\mathcal{C}$ be the set of constraints that the event $v_{j}=c_{t}$ is non-lopsidependent with the violation of the constraints in $\\mathcal{C} \\backslash \\mathcal{C}^{\\prime}$ in the formula $\\Phi_{j}$. By definition, for any $C \\in \\mathcal{C}^{\\prime}$, either $v_{j} \\in v \\mathrm{bl}(C)$ or $\\left(P \\backslash P^{\\prime}\\right) \\cap v \\mathrm{bl}(C) \\neq \\emptyset$. According to Proposition D.4, we have $\\mathbb{P}_{\\Phi_{j}}[\\neg C]<_{q} p^{\\prime}<_{q} p$ for any constraint $C \\in \\mathcal{C}^{\\prime}$ as $\\left|\\mathcal{P}^{\\prime}[P]\\right| \\geq 2$. On the other hand, one can verify that $\\mathbb{P}_{\\Phi_{j}}[\\neg C]<_{q} p$ for any constraint $C \\in \\mathcal{C} \\backslash \\mathcal{C}^{\\prime}$. Combining with Lemma D. 1 and $8 \\mathrm{e} p \\Delta \\leq 1$, we have, for any $j \\in[t]$,\n\n$$\n\\operatorname{Pr}_{\\tau \\sim \\mu_{\\theta_{j}}}\\left[\\tau\\left(v_{j}\\right)=c_{t}\\right]<_{q} \\frac{1}{|P|-\\left|P^{\\prime}\\right|+1} \\cdot\\left(1+4 e p^{\\prime} \\Delta\\right)\n$$\n\nBy similar arguments, we have\n\n$$\n\\operatorname{Pr}_{\\tau \\sim \\mu_{\\theta_{j}}}\\left[\\tau\\left(v_{j}\\right)=c_{t}^{\\prime}\\right]>_{q} \\frac{1}{|P|-\\left|P^{\\prime}\\right|+1}-4 \\mathrm{e} p^{\\prime} \\Delta\n$$\n\nPlugging these into (66), it holds that\n\n$$\nr \\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q^{\\prime}\\right]=r \\operatorname{Pr}_{\\tau \\sim \\mu_{\\theta_{j}}}\\left[\\tau\\left(v_{j}\\right)=c_{t}\\right] \\cdot \\sum_{j \\in[t]} \\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[A_{j}\\right]<_{q} \\operatorname{Pr}_{\\tau \\sim \\mu_{\\theta_{j}}}\\left[\\tau\\left(v_{j}\\right)=c_{t}^{\\prime}\\right] \\cdot \\sum_{j \\in[t]} \\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[A_{j}\\right]\n$$\n\nwhich verifies the inequality (67).\nWe then consider any domains $Q^{\\prime \\prime}$ such that $\\left|Q^{\\prime}\\right|=\\left|Q^{\\prime \\prime}\\right|>1$. We construct a sequence of domains $\\left(Q_{1}^{\\prime}, Q_{2}^{\\prime}, \\cdots, Q_{m}^{\\prime}\\right)$ where $Q_{1}^{\\prime}=Q^{\\prime}, Q_{m}^{\\prime}=Q^{\\prime \\prime}, m=\\left|Q^{\\prime} \\backslash Q^{\\prime \\prime}\\right|$ and $\\left|Q_{j}^{\\prime} \\backslash Q_{j+1}^{\\prime}\\right|=1$ for each $j \\in[m-1]$. Combined with the fact that $m \\leq t$ and (67), we have\n\n$$\nr^{t} \\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q^{\\prime}\\right]<_{q} \\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q^{\\prime \\prime}\\right]<_{q} r^{-t} \\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q^{\\prime}\\right]\n$$\n\nwhich implies the inequalities (63) and (64). The correctness of (65) follows from similar arguments.\n\nAgain, we have an alternative bound for the case where the values are all non-forbidden.\nLemma D.5. Given the instance stated in Lemma D.3, if we further assume that $Q \\subseteq \\mathcal{Q}(P) \\backslash \\Lambda\\left(\\mathcal{C}, P^{\\prime}\\right)$ and $|Q|=\\left|P^{\\prime}\\right|$, we have\n\n$$\n\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q\\right] \\geq\\left(\\left|P^{\\prime}\\right|\\right) \\cdot \\prod_{j=0}^{|P^{\\prime}|-1}\\left(\\frac{1}{|P|-j}\\left(1-\\frac{2 \\Delta}{|P|-j}\\right)\\right)\n$$\n\nMoreover, we also have\n\n$$\n\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(P^{\\prime}\\right)=Q^{\\prime} \\mid c_{1} \\in \\sigma\\left(P^{\\prime}\\right)\\right] \\geq\\left(\\left|P^{\\prime}\\right|-1\\right)!\\cdot \\prod_{j=1}^{|P^{\\prime}|-1}\\left(\\frac{1}{|P|-j}\\left(1-\\frac{2 \\Delta}{|P|-j}\\right)\\right)\\right.\n$$\n\nProof. Let $P^{\\prime}=\\left\\{v_{1}, v_{2}, \\cdots, v_{t}\\right\\}$ and $Q=\\left\\{c_{1}, c_{2}, \\cdots, c_{t}\\right\\}$. We claim that, for any permutation $\\left(c_{1}^{\\prime}, c_{2}^{\\prime}, \\cdots, c_{t}^{\\prime}\\right)$ of $Q$, we have\n\n$$\n\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(v_{j}\\right)=c_{j}^{\\prime} \\text { for all } j \\in[t]\\right] \\geq \\prod_{j=0}^{t-1} \\frac{|P|-j-2 \\Delta}{(|P|-j)^{2}}\n$$\n\nCombining with the fact that the number of the permutations of a given domain of $P^{\\prime}$ equals $\\left|P^{\\prime}\\right|$ !, the lemma holds immediately from (68).\n\nIn the following, we prove the inequality (68). For each $j \\in\\{0,1, \\cdots, t-1\\}$, let $\\sigma_{j}$ be the partial assignment where $\\sigma_{j}\\left(v_{j^{\\prime}}\\right)=c_{j^{\\prime}}^{\\prime}$ for any $j^{\\prime} \\in[j]$, and $\\Psi_{j}=\\left(\\mathcal{P}_{j}, \\mathcal{Q}_{j}, \\mathcal{C}_{j}\\right)=\\Phi^{\\sigma_{j}}$ be the formula conditioned on the partial assignment $\\sigma_{j}$. In particular, $\\sigma_{0}$ is an empty assignment, $\\mathcal{P}_{0}=\\mathcal{P}, \\mathcal{Q}_{0}=\\mathcal{Q}$, and $\\mathcal{C}_{0}=\\mathcal{C}$. It holds that\n\n$$\n\\operatorname{Pr}_{\\sigma \\sim \\mu}\\left[\\sigma\\left(v_{j}\\right)=c_{j}^{\\prime} \\text { for all } j \\in[t]\\right]=\\prod_{j=0}^{t-1} \\operatorname{Pr}_{\\tau \\sim \\mu \\varphi_{j}}\\left[\\tau\\left(v_{j+1}\\right)=c_{j+1}^{\\prime}\\right]\n$$\n\nFor each $j \\in\\{0,1, \\cdots, t-1\\}$, let $P_{j}$ be the permutation containing $v_{j+1}$ in $\\Psi_{j}$. By definition, we have $P_{j} \\subseteq P$ satisfying $\\left|P_{j}\\right|=|P|-j$, and $c_{j+1}^{\\prime} \\in \\mathcal{Q}_{j}\\left(P_{j}\\right) \\backslash \\Lambda\\left(\\mathcal{C}_{j}, P_{j}\\right)$ since $Q \\subseteq \\mathcal{Q}(P) \\backslash \\Lambda\\left(\\mathcal{C}, P^{\\prime}\\right)$ by assumption. Furthermore, the constraints in $\\mathcal{C}\\left(P \\backslash P_{j}\\right)$ are satisfied. For the constraints $\\mathcal{C} \\backslash \\mathcal{C}\\left(P \\backslash P_{j}\\right)$, the violation probability is at most $p$ by the assumption that $e p_{\\Psi} \\Delta \\leq 1$ for any $\\Psi=\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}, \\mathcal{C}\\right)$ where $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}^{\\prime}\\right)$ is the decomposition of $(\\mathcal{P}, \\mathcal{Q})$. Therefore, the formula $\\Psi_{j}$ satisfies $8 e p_{\\Psi_{j}} \\Delta \\leq 1$. Combined with Lemma D.2, we have\n\n$$\n\\operatorname{Pr}_{\\tau \\sim \\mu \\varphi_{j}}\\left[\\tau\\left(v_{j+1}\\right)=c_{j+1}\\right] \\geq(|P|-j-2 \\Delta) /(|P|-j)^{2}\n$$\n\nPlugging (70) into (69), the inequality (68) holds.", "tables": {}, "images": {}}, {"section_id": 17, "text": "# D.3. Missing proofs in Section 8.2.\n\nProof of Lemma 8.5. It suffices to show that\n\n$$\n\\operatorname{Pr}\\left[Q_{t} \\cap \\Lambda\\left(\\mathcal{C}_{t}, P_{t}\\right) \\neq \\emptyset\\right] \\leq \\frac{2 k \\Delta\\left|P_{t}\\right|^{2}}{|P|}\n$$\n\nFor each variable $v \\in P_{t}$, there are at most $\\Delta$ constraints $C \\in \\mathcal{C}_{t}$ such that $v \\in \\mathrm{vb}(C)$, which implies that $\\left|\\mathcal{C}_{t}\\left(P_{t}\\right)\\right| \\leq \\Delta\\left|P_{t}\\right|$. Combining this with that $C$ is disjunctive and $|\\mathrm{vb}(C)| \\leq k$ for each $C \\in \\mathcal{C}_{t}$, we have $\\left|\\Lambda\\left(\\mathcal{C}_{t}, P_{t}\\right)\\right| \\leq k \\Delta\\left|P_{t}\\right|$ by the definition of $\\Lambda\\left(\\mathcal{C}_{t}, P_{t}\\right)$. Moreover, for each $c \\in \\Lambda\\left(\\mathcal{C}_{t}, P_{t}\\right)$, we have $\\operatorname{Pr}\\left[c \\in Q_{t}\\right] \\leq 2\\left|P_{t}\\right| /|P|$ by Lemma D. 1 and union bound. Then (71) follows immediately by union bound, and the proof is complete.\n\nProof of Lemma 8.7. Let $\\alpha^{\\prime} \\doteq \\alpha /\\binom{|S|}{|P_{t}|-|T_{1}|}{1}$. One can verify that $\\alpha^{\\prime}$ is the probability that $Q_{t}^{1}$ (or $Q_{t}^{2}$ ) is assigned the value $T \\cup T_{1}$ (or $T \\cup T_{2}$ ) in Line 12 for any $T \\subseteq S$ such that $|T|=\\left|P_{t}\\right|-\\left|T_{1}\\right|$. To show that $\\left(Q_{t}^{1}, Q_{t}^{2}\\right)$ is a coupling of $v_{t}^{1}$ and $v_{t}^{2}$, it is sufficient to claim that $v_{t}^{1}\\left(Q_{t}^{1}=T \\cup T_{1}\\right) \\geq \\alpha^{\\prime}$ holds, and the same holds for $v_{t}^{2}$ as well. This follows from Lemma D. 5 when $P_{t} \\notin \\mathcal{Z}$, and Lemma D. 3 when $P_{t} \\in \\mathcal{Z}$ by Condition 8.4.\n\nWe complete the proof by establishing the lower bounds for $\\alpha$ since $\\operatorname{Pr}[\\operatorname{Succ}=\\text { False }]=1-\\alpha$.\nCase I: $P_{t} \\in \\mathcal{Z}$. By definition, we have\n\n$$\n\\begin{aligned}\n\\alpha & =\\left(\\left(1-4 q e p^{\\prime} \\Delta\\right) /\\left(1+4 e p^{\\prime} \\Delta\\right)\\right)^{\\left(\\left|P_{t}\\right|-\\left|T_{1}\\right|\\right)} \\\\\n& \\geq\\left(\\left(1-4 q e p^{\\prime} \\Delta\\right)\\left(1-8 e p^{\\prime} \\Delta\\right)\\right)^{\\left(\\left|P_{1}\\right|-\\left|T_{1}\\right|\\right)} \\quad \\text { (by } p^{\\prime}<_{q} p^{\\theta} \\text { as }\\left|\\mathcal{P}^{\\prime}[P]\\right| \\geq 2 \\text { and } 8 e p^{\\theta} \\Delta \\leq 1) \\\\\n& \\geq\\left(1-5 q e p^{\\prime} \\Delta\\right)^{\\left(\\left|P_{t}\\right|-\\left|T_{1}\\right|\\right)}>_{q} 1-5 e p^{\\theta} \\Delta\\left|P_{t}\\right|^{2}\n\\end{aligned}\n$$\n\nCase II: $P_{t} \\notin \\mathcal{Z}$. We first assume that $\\ell \\geq 3 \\Delta$. Let $\\alpha_{1}=\\binom{|S|}{|P_{t}|-|T_{1}|} \\cdot\\left(\\left|P_{t}\\right|-\\left|T_{1}\\right|\\right)!\\cdot \\prod_{j=\\left|T_{1}\\right|}^{\\left|P_{t}\\right|-1} 1 /(|P|-j)$ and $\\alpha_{2}=\\prod_{j=\\left|T_{1}\\right|}^{\\left|P_{t}\\right|-1}(|P|-j-2 \\Delta) /(|P|-j)$. Note that $|S| \\geq\\left|P_{t}\\right|$ holds by $|S| \\geq|P|-2 \\Delta\\left|P_{t}\\right|$ and $\\ell \\geq 3 \\Delta$. We have\n\n$$\n\\begin{aligned}\n\\alpha_{1} & =\\frac{|S|(|S|-1) \\cdots\\left(|S|-\\left|P_{t}\\right|+\\left|T_{1}\\right|+1\\right)}{\\left(|P|-\\left|T_{1}\\right|\\right)\\left(|P|-\\left|T_{1}\\right|-1\\right) \\cdots\\left(|P|-\\left|P_{t}\\right|+\\left|T_{1}\\right|+1\\right)} \\\\\n& =\\frac{\\left(|P|-\\left|P_{t}\\right|\\right)\\left(|P|-\\left|P_{t}\\right|-1\\right) \\cdots\\left(|S|-\\left|P_{t}\\right|+\\left|T_{1}\\right|+1\\right)}{|P|(|P|-1) \\cdots(|S|+1)} \\\\\n& \\geq\\left(1-\\frac{\\left|P_{t}\\right|}{|S|}\\right)^{|P|-|S|} \\geq\\left(1-\\frac{\\left|P_{t}\\right|}{|P|-2 \\Delta\\left|P_{t}\\right|}\\right)^{2 \\Delta\\left|P_{t}\\right|} \\quad \\text { (by }|S| \\geq|P|-2 \\Delta\\left|P_{t}\\right|) \\\\\n& =\\left(1-\\frac{1}{\\ell-2 \\Delta}\\right)^{2 \\Delta\\left|P_{t}\\right|} \\geq 1-\\frac{2 \\Delta\\left|P_{t}\\right|}{\\ell-2 \\Delta} \\geq 1-\\frac{3 \\Delta\\left|P_{t}\\right|}{\\ell}\n\\end{aligned}\n$$\n\nAs for $\\alpha_{2}$, we have\n\n$$\n\\alpha_{2}=\\prod_{j=0}^{\\left|P_{t}\\right|-1}\\left(1-\\frac{2 \\Delta}{|P|-j}\\right) \\geq\\left(1-\\frac{2 \\Delta}{|P|-\\left|P_{t}\\right|}\\right)^{\\left|P_{t}\\right|} \\geq 1-\\frac{2 \\Delta\\left|P_{t}\\right|}{|P|-\\left|P_{t}\\right|}=1-\\frac{2 \\Delta}{\\ell-1}\n$$\n\nCombining all these facts, it holds that\n\n$$\n\\alpha=\\alpha_{1} \\alpha_{2} \\geq 1-\\frac{3 \\Delta\\left|P_{t}\\right|}{\\ell}-\\frac{2 \\Delta}{\\ell-1} \\geq 1-\\frac{4 \\Delta\\left|P_{t}\\right|}{\\ell}\n$$\n\nFor the case when $\\ell<3 \\Delta$, we have $4 \\Delta\\left|P_{t}\\right| / \\ell>1$, and the bound holds trivially.\nFinally, note that Succ $=$ True iff $r \\leq \\alpha$ and Succ remains True in Line 13. If $P_{t} \\notin \\mathcal{Z}$ and $\\ell \\geq 4 \\Delta\\left|P_{t}\\right|$, we have $\\left(\\ell-4 \\Delta\\left|P_{t}\\right|\\right) /(\\ell \\alpha) \\in[0,1]$ by $\\ell \\geq 4 \\Delta\\left|P_{t}\\right|$. Consequently,\n\n$$\n\\operatorname{Pr}[\\operatorname{Succ}=\\text { True })=\\operatorname{Pr}[r \\leq \\alpha] \\cdot \\operatorname{Pr}\\left[\\operatorname{Succ}=\\text { True } \\mid r \\leq \\alpha\\right]=\\alpha \\cdot \\frac{\\ell-4 \\Delta\\left|P_{t}\\right|}{\\ell \\alpha}=\\frac{\\ell-4 \\Delta\\left|P_{t}\\right|}{\\ell}\n$$\n\nwhich implies $\\operatorname{Pr}[\\operatorname{Succ}=\\text { False }]=4 \\Delta\\left|P_{t}\\right| / \\ell$.\n\nProof of Lemma 8.11. Let $\\operatorname{Bad}_{i}^{j}(Q)$ denote the event $Q \\cap \\Lambda\\left(\\mathcal{C}_{1}, P_{i}\\right) \\neq \\emptyset$ for each $i \\in[\\ell]$ and $j \\in[2]$. We will use $\\operatorname{Bad}(Q)$ to denote $\\operatorname{Bad}_{i}^{j}(Q)$ if $i$ and $j$ are clear from the context.\n\nBy Line 14 in Algorithm 7, we have\n\n$$\n\\mathrm{E}\\left[\\sum_{P^{\\prime} \\in S}\\left|P^{\\prime}\\right|\\right] \\leq \\sum_{r \\in[\\ell]} \\operatorname{Pr}\\left[\\operatorname{Bad}\\left(Q_{r}^{1}\\right)\\right]\\left|P_{r}\\right|+\\sum_{r \\in[\\ell]} \\operatorname{Pr}\\left[\\operatorname{Bad}\\left(Q_{r}^{2}\\right)\\right]\\left|P_{r}\\right|\n$$\n\nIn addition, we have\n\n$$\n\\sum_{r \\in[\\ell]} \\operatorname{Pr}\\left[\\operatorname{Bad}\\left(Q_{r}^{1}\\right)\\right]\\left|P_{r}\\right| \\leq \\operatorname{Pr}\\left[c_{1} \\in \\Lambda\\left(\\mathcal{C}_{1}, P_{i}\\right)\\right]\\left|P_{i}\\right|+\\operatorname{Pr}\\left[\\operatorname{Bad}_{i}^{1}\\left(Q_{i}^{1} \\backslash c_{1}\\right)\\right]\\left|P_{i}\\right|+\\sum_{r \\in[\\ell] \\backslash\\{i\\}} \\operatorname{Pr}\\left[\\operatorname{Bad}\\left(Q_{r}^{1}\\right)\\right]\\left|P_{r}\\right|\n$$\n\nWe claim that\n\n$$\n\\begin{gathered}\n\\operatorname{Pr}\\left[c_{1} \\in \\Lambda\\left(\\mathcal{C}_{1}, P_{i}\\right)\\right]\\left|P_{i}\\right|<_{q} 2 \\Delta \\\\\n\\operatorname{Pr}\\left[\\operatorname{Bad}_{i}^{1}\\left(Q_{i}^{1} \\backslash c_{1}\\right)\\right]\\left|P_{i}\\right|<_{q} 2 k \\Delta \\\\\n\\sum_{r \\in[\\ell] \\backslash\\{i\\}} \\operatorname{Pr}\\left[\\operatorname{Bad}\\left(Q_{r}^{1}\\right)\\right]\\left|P_{r}\\right|<_{q} 16 k \\Delta\n\\end{gathered}\n$$\n\nThus, we have\n\n$$\n\\sum_{r \\in[\\ell]} \\operatorname{Pr}\\left[\\operatorname{Bad}\\left(Q_{r}^{1}\\right)\\right]\\left|P_{r}\\right|<_{q}(18 k+2) \\Delta\n$$\n\nSimilarly, we also have\n\n$$\n\\sum_{r \\in[\\ell]} \\operatorname{Pr}\\left[\\operatorname{Bad}\\left(Q_{r}^{2}\\right)\\right]\\left|P_{r}\\right|<_{q}(18 k+2) \\Delta\n$$\n\nCombining the above two inequalities with (72), the lemma is immediate. In the following, we prove $(73),(74),(75)$ one by one.\n\nAt first, we prove (73). We have\n\n$$\n\\begin{aligned}\n\\operatorname{Pr}\\left[c_{1} \\in \\Lambda\\left(\\mathcal{C}_{1}, P_{i}\\right)\\right]\\left|P_{i}\\right| & \\leq\\left|P_{i}\\right| \\Delta \\max _{r \\in[\\ell]} f_{1}(r) \\\\\n\\text { (by Lemma 8.9) } & \\leq\\left|P_{i}\\right| \\Delta(1+4 \\mathrm{e} p \\Delta)\\left|P_{r}\\right| /|P| \\\\\n\\text { (by } 8 \\mathrm{e} \\Delta p^{2 \\theta} \\leq 1 \\text { in Condition 8.4) } & =2 \\Delta|P|^{\\theta-1} \\\\\n\\text { (by } \\theta \\in(0,1 / 2]) & \\leq 2 \\Delta\n\\end{aligned}\n$$\n\nIn the next, we prove (75) for two different cases.\nCase I: $t>\\gamma$. Let $\\mathcal{A}$ denote the event $\\left(c_{1} \\notin \\Lambda\\left(\\mathcal{C}_{1}, P_{i} \\cup P_{j}\\right)\\right) \\wedge\\left(c_{2} \\notin \\Lambda\\left(\\mathcal{C}_{2}, P_{i} \\cup P_{j}\\right)\\right)$. By (37), $\\sum_{r \\in[\\ell]}\\left|P_{r}\\right|=|P|$ and $\\sum_{r \\in[\\ell]}\\left|V_{r}\\right| \\leq 2 \\Delta$, we have\n\n$$\n\\operatorname{Pr}[i=j] \\geq \\sum_{r \\in[\\ell]} f_{\\min }(r) \\geq \\sum_{r \\in[\\ell]}\\left(\\left|P_{r}\\right|-\\left|V_{r}\\right|\\right)\\left(|P|-2 \\Delta\\right)|P|^{-2}=1-4 \\Delta|P|^{-1}\n$$\n\nIf $i=j$, by Lemma 8.7 we have\n\n$$\n\\operatorname{Pr}\\left[\\text { Succ }=\\text { False } \\mid \\mathcal{A} \\wedge i=j\\right]<_{q} 4 \\Delta|P|^{2 \\theta-1}\n$$\n\nIn addition, by (76) we have\n\n$$\n\\operatorname{Pr}[\\overline{\\mathcal{A}}] \\leq 8 \\Delta|P|^{\\theta-1}\n$$\n\nCombining above two inequalities, we have\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Succ}=\\text { False } \\wedge i=j\\right] \\leq \\operatorname{Pr}[\\overline{\\mathcal{A}}]+\\operatorname{Pr}\\left[\\operatorname{Succ}=\\text { False } \\wedge \\mathcal{A} \\wedge i=j\\right]<_{q} 12 \\Delta|P|^{2 \\theta-1}\n$$\n\nFor each $r \\in[\\ell] \\backslash\\{i\\}$, by Lemma 8.5 we have\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Bad}\\left(Q_{r}^{1}\\right) \\mid i=j \\wedge \\operatorname{Succ}=\\text { False }\\right]<_{q} \\min \\left\\{\\frac{2 k \\Delta\\left|P_{r}\\right|^{2}}{|P|-\\left|P_{i}\\right|}, 1\\right\\}=_{q} \\min \\left\\{2 k \\Delta|P|^{2 \\theta-1}, 1\\right\\}\n$$\n\nCombining (86) with (79), we have for each $r \\in[t] \\backslash\\{i\\}$ we have\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Bad}\\left(Q_{i}^{1}\\right) \\mid(i=j \\wedge \\operatorname{Succ}=\\text { False }) \\vee(i \\neq j)\\right]<_{q} \\min \\left\\{2 k \\Delta|P|^{2 \\theta-1}, 1\\right\\}\n$$\n\nIn addition, by (76) and (78), we have\n\n$$\n\\operatorname{Pr}\\left[(i=j \\wedge \\operatorname{Succ}=\\text { False }) \\vee(i \\neq j)\\right]<_{q} 16 \\Delta|P|^{2 \\theta-1}\n$$\n\nCombining (80) with (81), we have\n\n$$\n\\begin{aligned}\n\\sum_{r \\in[t] \\backslash\\{i\\}} \\operatorname{Pr}\\left[\\operatorname{Bad}\\left(Q_{i}^{1}\\right)\\right]\\left|P_{r}\\right| & <_{q} 16 \\Delta|P|^{2 \\theta-1} \\min \\left\\{2 k \\Delta|P|^{2 \\theta-1}, 1\\right\\}|P| \\\\\n& \\leq 16 \\Delta|P|^{2 \\theta} \\min \\left\\{2 k \\Delta|P|^{2 \\theta-1}, 1\\right\\} \\\\\n& \\leq 16 k \\Delta\n\\end{aligned}\n$$\n\n(by (b) in Condition 8.10)\nCase II: $t \\leq r$. By (37), we have\n\n$$\n\\operatorname{Pr}[i=j] \\geq \\sum_{r \\in[t]} f_{\\min }(r)=\\sum_{r \\in[t]}\\left((1+4 \\mathrm{e} \\Delta p)\\left|P_{r}\\right| /|P|-4 \\mathrm{e} \\Delta p\\left|P_{r}\\right|\\right)=1-4 \\mathrm{e} p \\Delta(|P|-1)\n$$\n\nIf $i=j$, by Lemma 8.7 we have\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Succ}=\\text { False } \\mid i=j\\right]<_{q} 5 \\mathrm{e} \\Delta p^{\\theta}|P|^{2 \\theta}\n$$\n\nCombined with (82), we have\n\n$$\n\\operatorname{Pr}\\left[(i=j \\wedge \\operatorname{Succ}=\\text { False }) \\vee(i \\neq j)\\right]<_{q} 4 \\mathrm{e} p \\Delta|P|+5 \\mathrm{e} \\Delta p^{\\theta}|P|^{2 \\theta}\n$$\n\nCombined (80) and (a) in Condition 8.10, we have\n\n$$\n\\sum_{r \\in[t] \\backslash\\{i\\}} \\operatorname{Pr}\\left[\\operatorname{Bad}\\left(Q_{r}^{1}\\right)\\right]\\left|P_{r}\\right|<_{q} 5 \\mathrm{e} \\Delta\\left(p|P|+p^{\\theta}|P|^{2 \\theta}\\right) \\min \\left\\{2 k \\Delta|P|^{2 \\theta-1}, 1\\right\\}|P| \\leq 10 k \\Delta\n$$\n\nAt last, we prove (74). Note that\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Bad}_{i}^{1}\\left(Q_{i}^{1} \\backslash c_{1}\\right)\\right] \\leq \\operatorname{Pr}\\left[\\operatorname{Bad}_{i}^{1}\\left(Q_{i}^{1} \\backslash c_{1}\\right) \\mid i \\neq j\\right]+\\operatorname{Pr}\\left[\\operatorname{Bad}_{i}^{1}\\left(Q_{i}^{1} \\backslash c_{1}\\right) \\mid i=j\\right]\n$$\n\nIf $t>\\gamma$, by Lemma 8.7 we have\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Bad}_{i}^{1}\\left(Q_{i}^{1} \\backslash c_{1}\\right) \\mid i=j\\right]<_{q} \\min \\left\\{2 k \\Delta|P|^{2 \\theta-1}, 1\\right\\}\n$$\n\nCombined with (85) and (76), we have\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Bad}_{i}^{1}\\left(Q_{i}^{1} \\backslash c_{1}\\right)\\right]<_{q} 4 \\Delta|P|^{-1}+\\min \\left\\{2 k \\Delta|P|^{2 \\theta-1}, 1\\right\\}\n$$\n\nTherefore,\n\n$$\n\\begin{aligned}\n\\operatorname{Pr}\\left[\\operatorname{Bad}_{i}^{1}\\left(Q_{i}^{1} \\backslash c_{1}\\right)\\right]\\left|P_{i}\\right| & <_{q} 4 \\Delta|P|^{\\theta-1}+|P|^{\\theta} \\min \\left\\{2 k \\Delta|P|^{2 \\theta-1}, 1\\right\\} \\\\\n& <_{q} \\Delta+k|P|^{2 \\theta} \\min \\left\\{2 \\Delta|P|^{2 \\theta-1}, 1\\right\\} \\\\\n& \\leq 2 k \\Delta\n\\end{aligned}\n$$\n\nIf $t \\leq \\gamma$, by Lemma 8.7 we have\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Bad}_{i}^{1}\\left(Q_{i}^{1} \\backslash c_{1}\\right) \\mid i=j\\right]<_{q} \\min \\left\\{5 \\mathrm{e} \\Delta p^{\\theta}|P|^{2 \\theta}, 1\\right\\}\n$$\n\nCombined with (85) and (82), we have\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Bad}_{i}^{1}\\left(Q_{i}^{1} \\backslash c_{1}\\right)\\right]<_{q} 4 \\mathrm{e} p \\Delta+\\min \\left\\{5 \\mathrm{e} \\Delta p^{\\theta}|P|^{2 \\theta}, 1\\right\\}\n$$\n\nTherefore,\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Bad}_{i}^{1}\\left(Q_{i}^{1} \\backslash c_{1}\\right)\\right]\\left|P_{i}\\right|<_{q} 4 \\mathrm{e} p \\Delta|P|^{\\theta}+|P|^{\\theta} \\min \\left\\{5 \\mathrm{e} \\Delta p^{\\theta}|P|^{2 \\theta}, 1\\right\\}\n$$\n\nMoreover, by (a) in Condition 8.10, we have\n\n$$\n\\begin{gathered}\n4 \\mathrm{e} p|P|^{\\theta}<_{q} \\min \\left\\{\\mathrm{e} p|P|^{2}, \\mathrm{e} p|P|^{\\theta+1}\\right\\} \\leq \\mathrm{e} p|P|^{2} \\min \\left\\{2 \\Delta|P|^{2 \\theta-1}, 1\\right\\} \\leq 1 \\\\\n|P|^{\\theta} \\min \\left\\{5 \\mathrm{e} p^{\\theta}|P|^{2 \\theta}, 1\\right\\} \\leq 5 \\mathrm{e} p^{\\theta}|P|^{3 \\theta} \\leq 1\n\\end{gathered}\n$$\n\nCombining above three inequalities,\n\n$$\n\\operatorname{Pr}\\left[\\operatorname{Bad}_{t}^{1}\\left(Q_{t}^{1} \\backslash c_{1}\\right)\\right]\\left|P_{t}\\right|<_{q} 2 \\Delta\n$$\n\nIn summary, (74) is proved and the lemma is immediate.", "tables": {}, "images": {}}, {"section_id": 18, "text": "# D.4. Missing proofs in Section 8.3. \n\nD.4.1. Witness Percolation. In this section, we complete the proof of Lemma 8.16.\n\nLemma D.6. For each $t>0$ and $P \\in \\mathcal{P}_{u}^{t}$, one of the following conditions holds:\n\n- $P \\in \\mathcal{P}_{\\perp}^{t}$;\n- $P \\in \\mathcal{Z}$, and there exist $P^{\\prime} \\in \\mathcal{P}_{\\perp}^{t}$ and $C \\in \\mathcal{C}$ such that $C \\in \\mathcal{C}(P) \\cap \\mathcal{C}\\left(P^{\\prime}\\right)$;\n- $P \\in \\mathcal{Z}$, and there exists $C \\in \\mathcal{C}_{\\perp}^{t} \\cap \\mathcal{C}(P)$.\n\nProof. For each $t>0$, the permutation sets $\\mathcal{P}_{u}^{t}$ is updated at Line 13, Line 18 or Line 23. For the updated permutation sets at Line 13 and Line 23, we have $P \\in \\mathcal{P}_{\\perp}^{t}$.\n\nAs for those permutation set $P$ updated at Line 18, we have $P \\in \\mathcal{Z}$. Moreover, there exists $C$ that is unsatisfied in $\\Phi_{1}$ or $\\Phi_{2}$. If $C \\in \\mathcal{C}_{\\perp}^{t}$, we have $C \\in \\mathcal{C}_{\\perp}^{t} \\cap \\mathcal{C}(P)$; Otherwise, there exists $P^{\\prime} \\in \\mathcal{P}_{\\perp}$, implying $C \\in \\mathcal{C}(P) \\cap \\mathcal{C}\\left(P^{\\prime}\\right)$.\nLemma D.7. $\\mathcal{P}_{u}^{1} \\subseteq \\mathcal{P}_{0}, \\mathcal{C}_{\\perp}^{1}=\\emptyset$.\nProof. In the first round of the while loop at Line 14, the $V_{\\text {set }}$ at Line 17 is exact the $V_{\\text {set }}^{\\prime}$ returned by InitialCouple at Line 12. Moreover, for the returned variables $\\left(\\Phi_{1}, \\Phi_{2}, V_{\\text {set }}^{\\prime}, \\mathcal{P}_{0}\\right)$ of InitialCouple subroutine and each permutation set $P \\subseteq V_{\\text {set }}^{\\prime}$, by checking Algorithm 7 one can verify that if any $C \\in \\mathcal{C}_{\\mathrm{u}}(P)$ is unsatisfied in $\\Phi_{1}$ or $\\Phi_{2}$, then $P$ is also in $\\mathcal{P}_{0}$. Therefore, we have the conclusion that $\\{P \\mid C \\in \\mathcal{C}(P)\\} \\subseteq \\mathcal{P}_{0}$ for each $C$ satisfying the conditions at Line 17. Combining this conclusion with Lines 13 and 18, we have $\\mathcal{P}_{u}^{1} \\subseteq \\mathcal{P}_{0}$ immediately. Combining this conclusion with Line 13 and the definition of $\\mathcal{C}_{\\perp}^{1}$, we have $\\mathcal{C}_{\\perp}^{1}=\\emptyset$.\n\nLemma D.8. For each $t>1$ and $P \\in \\mathcal{P}_{\\perp}^{t} \\backslash \\mathcal{P}_{\\perp}^{t-1}$, one of the following conditions holds:\n(1) there exists $P^{t} \\in \\mathcal{P}_{\\perp}^{t-1}$ such that $\\left(P^{t}, P\\right) \\in \\mathcal{S}^{*}\\left(\\mathcal{P}_{\\perp}, \\mathcal{P}_{\\perp}^{*}, 2\\right)$;\n(2) there exists $C \\in \\mathcal{C}_{\\perp}^{t-1}$ such that $(C, P) \\in \\mathcal{S}\\left(\\mathcal{C}_{\\perp}, \\mathcal{P}_{\\perp}^{*}, 1\\right)$;\n(3) there exists some $P^{t} \\in \\mathcal{P}_{\\perp}^{t} \\backslash \\mathcal{P}_{\\perp}^{t-1}$ such that $\\left(P^{t}, P\\right) \\in \\mathcal{E}_{P}\\left(\\mathcal{P}_{\\perp}^{*}, \\mathcal{P}_{\\perp} \\backslash \\mathcal{P}_{\\perp}^{*}\\right)$.\n\nProof. Given that $P$ is added to $\\mathcal{P}_{\\perp}^{t}$ in the $t$-th round, there must exist some constraints in $\\mathcal{C}_{u}^{t-1}$ that intersect with the permutation sets in $\\mathcal{P}_{u}^{t-1}$ at the beginning of the $t$-th round. Let $C$ and $P^{*}$ denote the corresponding constraint and permutation set specified in Line 19 at the beginning of the $t$-th round, and $P^{\\prime}$ be the permutation set specified in Line 21 of Algorithm 8.\n\nNote that $P^{*} \\in \\mathcal{P}_{u}^{t-1}, P \\in \\mathcal{P}_{\\perp}^{t}$ and $C \\in \\mathcal{C}\\left(P^{*}\\right) \\cap \\mathcal{C}\\left(P^{\\prime}\\right)$ by assumption. We can also infer that $P^{\\prime} \\in \\mathcal{P}_{\\perp}^{t} \\cap \\mathcal{P}_{\\perp}^{*}$, as otherwise we would have $\\mathcal{P}_{\\perp}^{t}=\\emptyset$ in Line 23 in the $t$-th round and then $\\mathcal{P}_{\\perp}^{t-1}=\\mathcal{P}_{\\perp}^{t}$, which is contradictory with $P \\in \\mathcal{P}_{\\perp}^{t} \\backslash \\mathcal{P}_{\\perp}^{t-1}$. Furthermore, for any $P^{*} \\in \\mathcal{P}_{\\perp}^{t} \\backslash \\mathcal{P}_{\\perp}^{t-1}$ where $P^{*} \\neq P^{\\prime}$, we have $\\left(P^{\\prime}, P^{*}\\right) \\in \\mathcal{E}\\left(\\mathcal{P}_{\\perp}^{*}, \\mathcal{P}_{\\perp} \\backslash \\mathcal{P}_{\\perp}^{*}\\right)$ according to the execution of Algorithms 8 and 7 , which implies the condition (3). Consequently, to complete the proof, it suffices to show that either condition (1) or (2) in this lemma holds as follows. By $P^{*} \\in \\mathcal{P}_{u}^{t-1}$ and Lemma D.6, there are three possibilities:\nCase I: $P^{*} \\in \\mathcal{P}_{\\perp}^{t-1}$. In this case, we have $\\left(P^{*}, P^{\\prime}\\right) \\in \\mathcal{S}\\left(\\mathcal{P}_{\\perp}, \\mathcal{P}_{\\perp}^{*}, 1\\right)$ by $P^{*} \\in \\mathcal{P}_{\\perp}^{t-1}, P \\in \\mathcal{P}_{\\perp}^{t}$, and $C \\in$ $\\mathcal{C}\\left(P^{*}\\right) \\cap \\mathcal{C}\\left(P^{\\prime}\\right)$, which implies the condition (1);\nCase II: $P^{*} \\in \\mathcal{Z}$, and there exists $P^{\\prime \\prime} \\in \\mathcal{P}_{\\perp}^{t-1}$ and $C^{\\prime} \\in \\mathcal{C}$ such that $C^{\\prime} \\in \\mathcal{C}\\left(P^{*}\\right) \\cap \\mathcal{C}\\left(P^{\\prime \\prime}\\right)$. We have $\\left(P^{\\prime}, C^{\\prime}, C, P^{\\prime}\\right)$ is a propagation trajectory by $C^{\\prime} \\in \\mathcal{C}\\left(P^{*}\\right) \\cap \\mathcal{C}\\left(P^{\\prime \\prime}\\right), C \\in \\mathcal{C}\\left(P^{*}\\right) \\cap \\mathcal{C}\\left(P^{*}\\right)$, and $P^{*} \\in \\mathcal{Z}$. Therefore, the condition (1) holds by $P^{\\prime \\prime} \\in \\mathcal{P}_{\\perp}, P^{\\prime} \\in \\mathcal{P}_{\\perp}^{*}$;\n\nCase III: $P^{*} \\in \\mathcal{Z}$, and there exists $C^{\\prime} \\in \\mathcal{C}_{\\perp}^{t-1} \\cap \\mathcal{C}\\left(P^{*}\\right)$. By $C^{\\prime} \\in \\mathcal{C}_{\\perp}^{t-1}, P^{\\prime} \\in \\mathcal{P}_{\\perp}$ and Observation 8.12, we have $C^{\\prime} \\in \\mathcal{C}_{\\perp}^{t-1} \\backslash \\mathcal{C}\\left(P^{\\prime}\\right)$. Combining with $C^{\\prime}, C \\in \\mathcal{C}\\left(P^{*}\\right), P^{*} \\in \\mathcal{Z}$, and $C \\in \\mathcal{C}\\left(P^{\\prime}\\right)$, we have $\\left(C^{\\prime}, C, P^{\\prime}\\right)$ is a propagation trajectory. Therefore, the condition (2) follows from $P^{\\prime} \\in \\mathcal{P}_{\\perp}^{*}$ and $C^{\\prime} \\in \\mathcal{C}_{\\perp}^{t-1} \\backslash \\mathcal{C}\\left(P^{\\prime}\\right)$.\n\nLemma D.9. For each $t>1$ and $C \\in \\mathcal{C}_{\\perp}^{t} \\backslash \\mathcal{C}_{\\perp}^{t-1}$, one of the following conditions holds:\n(1) there exists $P \\in \\mathcal{P}_{\\perp}^{t-1}$ such that $(P, C) \\in \\mathcal{S}^{*}\\left(\\mathcal{P}_{\\perp}, \\mathcal{C}_{\\perp}, 2\\right)$;\n(2) there exists $C^{\\prime} \\in \\mathcal{C}_{\\perp}^{t-1}$ such that $\\left(C^{\\prime}, C\\right) \\in \\mathcal{S}^{*}\\left(\\mathcal{C}_{\\perp}, \\mathcal{C}_{\\perp}, 1\\right)$.\n\nProof. Given that $C^{\\prime}$ is added to $\\mathcal{C}_{\\perp}^{t}$ in the $t$-th round, there must exist some constraints in $\\mathcal{C}_{u}^{t-1}$ that intersect with the permutation sets in $\\mathcal{P}_{u}^{t-1}$ at the beginning of the $t$-th round. Let $C$ and $P^{*}$ denote the corresponding constraint and permutation set specified in Line 19 at the beginning of the $t$-th round, and $P^{\\prime}$ be the permutation set specified in Line 21 of Algorithm 8.\n\nAccording to the execution of the coupling algorithm, we have $C \\in \\mathcal{C}\\left(P^{*}\\right) \\cap \\mathcal{C}\\left(P^{\\prime}\\right), P^{\\prime} \\notin \\mathcal{P}_{\\perp}^{t}$, and $C^{\\prime} \\in \\mathcal{C}\\left(P^{\\prime}\\right)$. In addition, by $C^{\\prime} \\in \\mathcal{C}_{\\perp} \\subseteq \\mathcal{C}_{s}$ and $C^{\\prime} \\in \\mathcal{C}\\left(P^{\\prime}\\right)$, we have $P^{\\prime} \\in \\mathcal{Z}$. We complete the proof via the discussion for $P^{*}$ according to Lemma D. 6 as follows:\nCase I: $P^{*} \\in \\mathcal{P}_{\\perp}$. In this case, we have $\\left(P^{*}, C, C^{\\prime}\\right)$ is a propagation trajectory since $C \\in \\mathcal{C}\\left(P^{*}\\right) \\cap \\mathcal{C}\\left(P^{\\prime}\\right)$, $C^{\\prime} \\in \\mathcal{C}\\left(P^{\\prime}\\right)$ and $P^{\\prime} \\in \\mathcal{Z}$. Therefore, the condition (1) holds by $P^{*} \\in \\mathcal{P}_{\\perp}$ and $C^{\\prime} \\in \\mathcal{C}_{\\perp}$;\nCase II: $P^{*} \\in \\mathcal{Z}$, and there exists $P^{\\prime \\prime} \\in \\mathcal{P}_{\\perp}^{t-1}$ and $C^{\\prime \\prime} \\in \\mathcal{C}$ such that $C^{\\prime \\prime} \\in \\mathcal{C}\\left(P^{*}\\right) \\cap \\mathcal{C}\\left(P^{\\prime \\prime}\\right)$. Combining with $C \\in \\mathcal{C}\\left(P^{*}\\right) \\cap \\mathcal{C}\\left(P^{\\prime}\\right), C^{\\prime} \\in \\mathcal{C}\\left(P^{\\prime}\\right)$, and $P^{*}, P^{\\prime} \\in \\mathcal{Z}$, we have $\\left(P^{\\prime \\prime}, C^{\\prime \\prime}, C, C^{\\prime}\\right)$ is a propagation trajectory. Therefore, the condition (1) holds by $P^{\\prime \\prime} \\in \\mathcal{P}_{\\perp}$ and $C^{\\prime} \\in \\mathcal{C}_{\\perp}$.\nCase III: $P^{*} \\in \\mathcal{Z}$, and there exists $C^{\\prime \\prime} \\in \\mathcal{C}_{\\perp}^{t-1} \\cap \\mathcal{C}\\left(P^{*}\\right)$. Note that $C^{\\prime \\prime} \\neq C^{\\prime}$ by definition. Combining with $C \\in \\mathcal{C}\\left(P^{*}\\right) \\cap \\mathcal{C}\\left(P^{\\prime}\\right)$ and $C^{\\prime} \\in \\mathcal{C}\\left(P^{\\prime}\\right)$, We have $\\left(C^{\\prime \\prime}, C, C^{\\prime}\\right)$ is a propagation trajectory. Therefore, the condition (2) holds by $C^{\\prime \\prime}, C^{\\prime} \\in \\mathcal{C}_{\\perp}$ and $C^{\\prime \\prime} \\neq C^{\\prime}$.\n\nLemma D.10. For each $P \\in \\mathcal{P}_{u} \\backslash \\mathcal{P}_{0}$, there exists a sequence $\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ such that\n(1) $v_{0} \\in \\mathcal{P}_{0}$ and $v_{t} \\notin \\mathcal{P}_{0}$ for each $i \\in[t]$;\n(2) $\\forall i \\in[t],\\left(\\left(v_{t-1}, v_{t}\\right) \\in \\mathcal{E}_{P}\\left(\\mathcal{P}_{\\perp}^{*}, \\mathcal{P}_{\\perp}\\right) \\wedge i>1\\right)$ or $\\left(v_{t-1}, v_{t}\\right) \\in \\mathcal{S}^{*}\\left(\\mathcal{P}_{\\perp}, \\mathcal{C}_{\\perp} \\cup \\mathcal{P}_{\\perp}^{*}, 2\\right) \\cup \\mathcal{S}^{*}\\left(\\mathcal{C}_{\\perp}, \\mathcal{C}_{\\perp} \\cup \\mathcal{P}_{\\perp}^{*}, 1\\right)$.\n(3) If $P \\in \\mathcal{Z}$, either $v_{t}=P$, or $\\left(v_{t}, P\\right) \\in \\mathcal{S}\\left(\\mathcal{P}_{\\perp}, \\mathcal{Z}, 1\\right)$, or $v_{t} \\in \\mathcal{C}(P)$; Otherwise, $v_{t}=P$.\n(4) If $P \\in \\mathcal{P}_{\\perp}$, then $v_{t}=P$.\n\nProof. By $P \\in \\mathcal{P}_{u} \\backslash \\mathcal{P}_{0}$ and Lemma D.7, we have $P \\notin \\mathcal{P}_{u}^{1}$. Suppose $P \\in \\mathcal{P}_{u}^{r} \\backslash \\mathcal{P}_{u}^{r-1}$ for some $r>1$. We construct a sequence in a backward way. At first, we determine the first element $u_{1}$ according to Lemma D.6.\n\n- if $P \\in \\mathcal{P}_{\\perp}^{r}$, let $u_{1}=P$.\n- Otherwise, if $P \\in \\mathcal{Z}$ and there exist $P^{\\prime} \\in \\mathcal{P}_{\\perp}^{r}$ and $C \\in \\mathcal{C}$ such that $C \\in \\mathcal{C}(P) \\cap \\mathcal{C}\\left(P^{\\prime}\\right)$, let $u_{1}=P^{\\prime}$\n- Otherwise, we have $P \\in \\mathcal{Z}$ and there exists $C \\in \\mathcal{C}_{\\perp}^{t} \\cap \\mathcal{C}(P)$. Let $u_{1}=C$.\n\nAccording to the construction of $u_{1}$, we have $u_{1} \\in \\mathcal{P}_{\\perp}^{r} \\cup \\mathcal{C}_{\\perp}^{r}$. In the next, given $u_{i} \\in \\mathcal{P}_{\\perp}^{r} \\cup \\mathcal{C}_{\\perp}^{r}$ where $i \\geq 1$, we construct $u_{i+1}$ or stop according to Lemmas D. 8 and D. 9 as follows.\n\n- if $u_{i} \\in \\mathcal{P}_{\\perp}^{1}$, stop the construction. Combined with Lemma D.7, we have $u_{i} \\in \\mathcal{P}_{\\perp}^{1} \\subseteq \\mathcal{P}_{0}$.\n- otherwise, if $u_{i} \\in \\mathcal{P}_{\\perp}^{r}$, we have $u_{i} \\in \\mathcal{P}_{\\perp}^{k} \\backslash \\mathcal{P}_{\\perp}^{k-1}$ for some $1<k \\leq r$. We have one of the following occurs according to Lemma D.8,\n- if there exists some $P^{\\prime} \\in \\mathcal{P}_{\\perp}^{k-1}$ where $\\left(P^{\\prime}, u_{i}\\right) \\in \\mathcal{S}\\left(\\mathcal{P}_{\\perp}, \\mathcal{P}_{\\perp}^{*}, \\leq 2\\right)$, let $u_{i+1} \\leftarrow P^{\\prime}$\n- Otherwise, if there exists some $C \\in \\mathcal{C}_{\\perp}^{k-1}$ where $\\left(C, u_{i}\\right) \\in \\mathcal{S}\\left(\\mathcal{C}_{\\perp}, \\mathcal{P}_{\\perp}^{*}, 1\\right)$, let $u_{i+1} \\leftarrow C$\n- Otherwise, some $P^{\\prime} \\in \\mathcal{P}_{\\perp}^{k} \\backslash \\mathcal{P}_{\\perp}^{k-1}$ where $\\left(P^{\\prime}, u_{i}\\right) \\in \\mathcal{E}\\left(\\mathcal{P}_{\\perp}^{r}, \\mathcal{P}_{\\perp} \\backslash \\mathcal{P}_{\\perp}^{*}\\right)$ exists. Let $u_{i+1} \\leftarrow P^{\\prime}$. In this case, we have $u_{i+1} \\in \\mathcal{P}_{\\perp}^{k} \\backslash \\mathcal{P}_{\\perp}^{k-1}$. Combined with $k>1$, we have $u_{i+1} \\notin \\mathcal{P}_{\\perp}^{1}$. Obviously, we have $u_{i+1} \\in \\mathcal{P}_{\\perp}^{k} \\cup \\mathcal{C}_{\\perp}^{k-1}$. Meanwhile, we also have $\\left(u_{i}, u_{i+1}\\right) \\in \\mathcal{E}\\left(\\mathcal{P}_{\\perp}^{r}, \\mathcal{P}_{\\perp}\\right) \\cup$ $\\mathcal{S}^{*}\\left(\\mathcal{P}_{\\perp}, \\mathcal{C}_{\\perp} \\cup \\mathcal{P}_{\\perp}^{*}, 2\\right) \\cup \\mathcal{S}^{*}\\left(\\mathcal{C}_{\\perp}, \\mathcal{C}_{\\perp} \\cup \\mathcal{P}_{\\perp}^{*}, 1\\right)$. In addition, if $u_{i+1} \\in \\mathcal{P}_{\\perp}^{k} \\backslash \\mathcal{P}_{\\perp}^{k-1}$, we have $u_{i+1} \\in \\mathcal{P}_{\\perp}^{*}$ and $u_{i} \\notin \\mathcal{P}_{\\perp}^{r}$.\n- Otherwise, $u_{i} \\in \\mathcal{C}_{\\perp}^{r}$ where $r \\geq 1$. Combined with $\\mathcal{C}_{\\perp}^{1}=\\emptyset$ due to Lemma D.7, we have $u_{i} \\in \\mathcal{C}_{\\perp}^{k} \\backslash \\mathcal{C}_{\\perp}^{k-1}$ for some $1<k \\leq r$. Thus, one of the following occurs according to Lemma D.9.\n- if there exists some $P^{\\prime} \\in \\mathcal{P}_{\\perp}^{k-1}$ such that $\\left(P^{\\prime}, u_{i}\\right) \\in \\mathcal{S}\\left(\\mathcal{P}_{\\perp}, \\mathcal{C}_{\\perp}, \\leq 2\\right)$, let $u_{i+1} \\leftarrow P^{\\prime}$\n- Otherwise, some $C^{\\prime} \\in \\mathcal{C}_{\\perp}^{k-1}$ where $\\left(C^{\\prime}, u_{i}\\right) \\in \\mathcal{S}\\left(\\mathcal{C}_{\\perp}, \\mathcal{C}_{\\perp}, \\leq 1\\right)$ exists. Let $u_{i+1} \\leftarrow C^{\\prime}$.\n\nObviously, we have $u_{i+1} \\in \\mathcal{P}_{\\perp}^{k-1} \\cup \\mathcal{C}_{\\perp}^{k-1}$. Meanwhile, we also have $\\left(v_{i-1}, v_{i}\\right) \\in \\mathcal{S}^{*}\\left(\\mathcal{P}_{\\perp}, \\mathcal{C}_{\\perp} \\cup\\right.$ $\\left.\\mathcal{P}_{\\perp}^{*}, 2\\right) \\cup \\mathcal{S}^{*}\\left(\\mathcal{C}_{\\perp}, \\mathcal{C}_{\\perp} \\cup \\mathcal{P}_{\\perp}^{*}, 1\\right)$.\nWe remark that this construction eventually stops. Because if $u_{i} \\in\\left(\\mathcal{P}_{u}^{k} \\backslash \\mathcal{P}_{u}^{k-1}\\right) \\cup\\left(\\mathcal{C}_{\\perp}^{k} \\backslash \\mathcal{C}_{\\perp}^{k-1}\\right)$ for some $1<k \\leq r$, then either $u_{i+1} \\in \\mathcal{P}_{\\perp}^{k-1} \\cup \\mathcal{C}_{\\perp}^{k-1}$ or $u_{i+1} \\in \\mathcal{P}_{\\perp}^{*} \\cap\\left(\\mathcal{P}_{\\perp}^{k} \\backslash \\mathcal{P}_{\\perp}^{k-1}\\right)$. Thus, we must have $u_{i+2} \\in \\mathcal{P}_{\\perp}^{k-1} \\cup \\mathcal{C}_{\\perp}^{k-1}$ by $u_{i+1} \\in \\mathcal{P}_{\\perp}^{*}$. According to the construction, one can verify that the sequence $\\left(u_{i}, u_{i-1}, \\cdots, u_{1}\\right)$ satisfy the required conditions.\n\nProof of Lemma 8.16. By Lemma D.10, there exists a sequence $s=\\left(u_{0}, \\cdots, u_{t}\\right)$ satisfying the conditions specified in Lemma D.10. In the following, we shall construct a w.s. $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$ induced from $s$ such that $v_{0} \\in \\mathcal{P}_{0}$ and $\\left(\\left(v_{i-1}, v_{i}\\right) \\in \\mathcal{E}_{P}\\left(\\mathcal{P}_{\\perp}^{*}, \\mathcal{P}_{\\perp}\\right) \\wedge i>1\\right)$ or $\\left(v_{i-1}, v_{i}\\right) \\in \\mathcal{S}^{*}\\left(\\mathcal{C}_{\\perp} \\cup \\mathcal{P}_{\\perp}^{*}, \\mathcal{C}_{\\perp} \\cup \\mathcal{P}_{\\perp}^{*}, 2\\right)$ for each $i \\in\\left[t^{\\prime}\\right]$, while preserving the conditions specified in Lemma D. 10 .\n(1) We first construct a new sequence $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$ satisfying the following condition:\n\n$$\nv_{i} \\neq v_{j} \\quad \\forall 0 \\leq i \\neq j \\leq t^{\\prime}\n$$\n\nLet $s^{\\prime} \\leftarrow s$ where $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$. According to the condition (1) specified in Lemma D.10, we have $v_{0} \\neq v_{i}$ for each $i \\in\\left[t^{\\prime}\\right]$. We repeat the following operation until (88) holds:\n(a) Let $i, j \\in\\left[t^{\\prime}\\right]$ satisfying $v_{i}=v_{j}$ and $i<j$;\n(b) Update $s^{\\prime} \\leftarrow\\left(v_{0}, v_{1}, \\cdots, v_{i-1}, v_{j}, \\cdots, v_{t^{\\prime}}\\right)$, i.e., delete all components from $v_{i}$ to $v_{j-1}$.\n\nLet $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$ be the resulting sequence on which no further operations can be performed. One can verify that $s^{\\prime}$ preserves the conditions specified in Lemma D. 10 .\n(2) We then construct a new sequence $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$ from the sequence constructed in the previous step, satisfying the following condition:\n\n$$\n\\left(v_{i}, v_{j}\\right) \\notin \\mathcal{E}_{P} \\text { if } j \\in[i-2] \\text { for each } i \\in\\left[t^{\\prime}\\right]\n$$\n\nLet $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$ be the sequence constructed in (1). We repeat the following operation until (89) holds:\n(a) Let $i \\in\\left[t^{\\prime}\\right]$ be the smallest index such that there exists $j, k \\in\\left[t^{\\prime}\\right]$ satisfying $i<j<k$ and $v_{i}, v_{j}, v_{k} \\subseteq P^{\\prime}$ for some $P^{\\prime} \\in \\mathcal{P}^{\\prime}$.\n(b) Update $s^{\\prime} \\leftarrow\\left(v_{0}, v_{1}, \\cdots, v_{i}, v_{k}, \\cdots, v_{t^{\\prime}}\\right)$, i.e., delete all component between $v_{i}$ and $v_{k}$.\n\nIn each operation, we can ensure that $\\left(v_{i}, v_{k}\\right) \\in \\mathcal{E}_{P}\\left(\\mathcal{P}_{\\perp}^{*}, \\mathcal{P}_{\\perp}\\right)$ since the chosen $i$ is the smallest index. Let $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$ be the resulting sequence on which no further operations can be performed. One can verify that $s^{\\prime}$ preserves the conditions specified in Lemma D.10,\n(3) We then construct a new sequence $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$ from the sequence constructed in the previous step, satisfying the following condition:\n\n$$\n\\left(\\left(v_{i}, v_{j}\\right) \\notin \\mathcal{E}_{C}\\right) \\wedge\\left(v_{i} \\notin \\mathcal{C}\\left(v_{j}\\right) \\text { if } v_{j} \\in \\mathcal{P}_{\\perp}\\right) \\text { for each } i \\in\\left[t^{\\prime}\\right] \\text { and } j \\in[i]\n$$\n\nHowever, the condition $\\left(v_{i} \\notin \\mathcal{C}\\left(v_{j}\\right)\\right.$ if $v_{j} \\in \\mathcal{P}_{\\perp}$ ) for each $i \\in\\left[t^{\\prime}\\right]$ and $j \\in[i]$ holds immediately, since if an edge is in $\\mathcal{C}_{\\perp}$, then each bucket on this edge is not in $\\mathcal{P}_{\\perp}$ or $\\mathcal{P}_{\\perp}^{*}$. To ensure (90), we first construct a sequence $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$ satisfying the following condition:\n\n$$\n\\left(v_{i}, v_{j}\\right) \\notin \\mathcal{E}_{C} \\text { for each } i \\in\\left[t^{\\prime}\\right] \\text { and } 0 \\leq j \\leq i-2\n$$\n\nLet $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$ be the sequence constructed in (2). We repeat the following operation until (91) holds:\n(a) Let $i \\in\\left[t^{\\prime}\\right]$ and $0 \\leq j \\leq i-2$ such that $\\left(v_{i}, v_{j}\\right) \\notin \\mathcal{E}_{C}$ ).\n(b) Update $s^{\\prime} \\leftarrow\\left(v_{0}, v_{1}, \\cdots, v_{j}, v_{i}, \\cdots, v_{t^{\\prime}}\\right)$, i.e., delete all component between $v_{i}$ and $v_{j}$.\n\nLet $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$ be the resulting sequence on which no further operations can be performed in the previous procedure. One can verify that $s^{\\prime}$ preserves the conditions specified in Lemma D. 10 and (91) holds. Finally, we further repeat the following operation:\n(a) Let $i \\in\\left[t^{\\prime}\\right]$ such that $v_{i} \\in \\mathcal{C}_{\\perp}, v_{i+1} \\in \\mathcal{C}_{\\perp}$.\n(b) Update $s^{\\prime} \\leftarrow\\left(v_{0}, v_{1}, \\cdots, v_{i}, v_{i+2}, \\cdots, v_{t^{\\prime}}\\right)$, i.e., delete $v_{i+1}$.\n\nNote that the above operation could only increase the distance $\\mathcal{S}^{*}\\left(\\mathcal{C}_{\\perp}, \\mathcal{C}_{\\perp} \\cup \\mathcal{P}_{\\perp}^{*}, 1\\right)$ to $\\mathcal{S}^{*}\\left(\\mathcal{C}_{\\perp}, \\mathcal{C}_{\\perp} \\cup\\right.$ $\\left.\\mathcal{P}_{\\perp}^{*}, 2\\right)$. Let $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t^{\\prime}}\\right)$ be the resulting sequence on which no further operations can be performed in the previous procedure. Combining with the preserved conditions specified\n\nin Lemma D.10, one can verify that $\\forall i \\in[t],\\left(\\left(v_{t-1}, v_{i}\\right) \\in \\mathcal{E}_{P}\\left(\\mathcal{P}_{\\perp}^{*}, \\mathcal{P}_{\\perp}\\right) \\wedge i>1\\right)$ or $\\left(v_{t-1}, v_{i}\\right) \\in$ $\\mathcal{S}^{*}\\left(\\mathcal{P}_{\\perp} \\cup \\mathcal{C}_{\\perp}, \\mathcal{C}_{\\perp} \\cup \\mathcal{P}_{\\perp}^{*}, 2\\right)$. Moreover, $\\left(v_{t} \\rightarrow P\\right) \\in \\mathcal{S}\\left(\\mathcal{C}_{\\perp}, \\mathcal{P}_{\\theta}, \\leq 1\\right)$ if $v_{t} \\in \\mathcal{C}_{\\perp}$.\nCombining all these properties, the proof is immediate.\nD.4.2. Bounding the discrepancy. We complete the proof of Lemma 8.21 in this section.\n\nThe proof of Lemma 8.21 relies on the following lemma.\nLemma D.11. Let $p \\in(0,1)$ and integer $\\Delta \\geq 1$ satisfy $\\epsilon p \\Delta \\leq 1$. Consider any formulas $\\Phi_{1}=\\left(\\mathcal{P}, \\mathcal{Q}_{1}, \\mathcal{C}\\right)$, $\\Phi_{2}=\\left(\\mathcal{P}, \\mathcal{Q}_{2}, \\mathcal{C}\\right)$ where $p_{\\Phi_{1}} \\leq p, p_{\\Phi_{2}} \\leq p, \\Delta_{\\Phi_{1}} \\leq \\Delta, \\Delta_{\\Phi_{2}} \\leq \\Delta$ with a permutation set $P \\in \\mathcal{P}$ where $\\mathcal{Q}_{1}(P)=\\mathcal{Q}_{2}(P), 4 \\in \\Delta \\leq|P|$ and a partition $\\left\\{P_{1}, \\cdots, P_{t}\\right\\}$ of $P$.\n\nLet $T=\\left\\{P^{\\prime} \\in \\mathcal{P} \\mid \\mathcal{Q}_{1}\\left(P^{\\prime}\\right) \\neq \\mathcal{Q}_{2}\\left(P^{\\prime}\\right)\\right\\}$. Let $S$ be any set of variables satisfying $P \\cap S=\\emptyset, \\cup_{P^{\\prime} \\in T} P^{\\prime} \\subseteq S$, and that in the factorizations of $\\left(\\mathcal{P}, \\mathcal{Q}_{1}, \\mathcal{C} \\backslash \\mathcal{C}(P)\\right)$ and $\\left(\\mathcal{P}, \\mathcal{Q}_{2}, \\mathcal{C} \\backslash \\mathcal{C}(P)\\right)$, each vertex $v \\in S$ is not connected to any $u \\notin S$. Let $\\left(\\sigma_{1}, \\sigma_{2}\\right)$ be an optimal coupling of $\\mu_{\\Phi_{1}}$ and $\\mu_{\\Phi_{2}}$ such that $\\mathrm{E}\\left[\\sum_{i \\in[t]}\\left|\\sigma_{1}\\left(P_{i}\\right) \\backslash \\sigma_{2}\\left(P_{i}\\right)\\right|\\right]$ is minimum. Then we have\n\n$$\n\\mathrm{E}\\left[\\sum_{i \\in[t]}\\left|\\sigma_{1}\\left(P_{i}\\right) \\backslash \\sigma_{2}\\left(P_{i}\\right)\\right|\\right] \\leq 100 \\Delta^{2}|P|^{-1}|\\mathcal{C}(S) \\cap \\mathcal{C}(P)|\n$$\n\nBefore we complete the proof of Lemma D.11, we introduce the following lemmas.\nLemma D.12. Given any PDCformulas $\\Phi_{1}=\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}_{1}\\right), \\Phi_{2}=\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}_{2}\\right)$ where $\\mathcal{P}=\\{P\\}$ and an integer $\\Delta \\geq 1$, assume $\\Delta_{\\Phi_{1}} \\leq \\Delta, \\Delta_{\\Phi_{2}} \\leq \\Delta, 4 \\in \\Delta \\leq|P|, \\mathcal{C}_{1} \\subseteq \\mathcal{C}_{2}$, and $|\\mathrm{vbl}(C)| \\leq 1$ for any $C \\in \\mathcal{C}_{2}$. Let $\\left(\\sigma_{1}, \\sigma_{2}\\right)$ be an optimal coupling between $\\mu_{\\Phi_{1}}$ and $\\mu_{\\Phi_{2}}$ such that $\\mathrm{E}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right]$ is minimum. Then we have\n\n$$\n\\mathrm{E}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right] \\leq \\frac{17 \\Delta\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right|}{|P|}\n$$\n\nProof. Note that for any constraint $C \\in \\mathcal{C}_{2}$, the violation probability is at most $1 /|P|$. Combined with $|P| \\geq k \\Delta$, we have\n\n$$\n\\left.\\epsilon p_{\\Phi_{1}} \\Delta_{\\Phi_{1}} \\leq 1, \\quad \\epsilon p_{\\Phi_{2}} \\Delta_{\\Phi_{2}} \\leq 1\\right.\n$$\n\nThen, we prove the lemma by induction.\nBase case: we first show that given $\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right|=1$, we have\n\n$$\n\\mathrm{E}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right)\\right] \\leq \\frac{17 \\Delta}{|P|}\n$$\n\nLet $\\{C\\}=\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1},\\{u\\}=\\mathrm{vbl}(C)$ and $c=\\Lambda(C, u)$. For convenience, we use $\\mu_{1}$ and $\\mu_{2}$ to denote $\\mu_{\\Phi_{1}}$ and $\\mu_{\\Phi_{2}}$, respectively. Moreover, the corresponding supports are denoted by $\\Omega_{1}$ and $\\Omega_{2}$. By definition, we have $\\Omega_{2} \\subseteq \\Omega_{1}$, and the density of $\\mu_{1}, \\mu_{2}$ are $1 /\\left|\\Omega_{1}\\right|, 1 /\\left|\\Omega_{2}\\right|$, respectively. Applying the Lemma 3.3 with the condition (92), we can compare the size of $\\Omega_{1}$ and $\\Omega_{2}$. Specifically, we have\n\n$$\n\\frac{\\left|\\Omega_{2}\\right|}{\\left|\\Omega_{1}\\right|}=\\left(1-\\operatorname{Pr}_{\\sigma-\\mu_{1}}[\\sigma(u)=c]\\right) \\geq\\left(1-\\frac{1}{|P|}\\left(1-\\frac{v}{|P|}\\right)^{-\\Lambda}\\right) \\geq\\left(1-\\frac{1}{|P|}\\left(1+\\frac{2 v \\Delta}{|P|}\\right)\\right)\n$$\n\nwhich implies\n\n$$\n\\frac{1}{\\left|\\Omega_{1}\\right|} \\geq \\frac{1}{\\left|\\Omega_{2}\\right|} \\cdot\\left(1-\\frac{1}{|P|}\\left(1+\\frac{2 v \\Delta}{|P|}\\right)\\right)\n$$\n\nThen, for any variable $v \\in P \\backslash\\{u\\}$ and $\\sigma \\in \\Omega_{1} \\backslash \\Omega_{2}$, we map it to a valid assignment $\\tau$ of $\\Phi_{1}$ by the mapping $\\tau=f(v, \\sigma)$ where\n\n$$\n\\tau(v)=\\sigma(u), \\tau(u)=\\sigma(v), \\text { and } \\tau_{P \\backslash\\{u, v\\}}=\\sigma_{P \\backslash\\{u, v\\}}\n$$\n\nOne can verify that the mapping $f(v, \\cdot)$ is injective for any $v \\in P \\backslash\\{u\\}$, and $f(\\cdot, \\sigma)$ is injective for any satisfying assignments $\\sigma \\in \\Omega_{1} \\backslash \\Omega_{2}$.\n\nWe then construct a coupling between $\\mu_{1}$ and $\\mu_{2}$ by specifying the density of the joint distribution $\\mathscr{C}: \\Omega_{1} \\times \\Omega_{2} \\rightarrow[0,1]$. Specifically, we would construct coupling tables $\\mathscr{C}_{1}, \\mathscr{C}_{2}, \\mathscr{C}_{3}: \\Omega_{1} \\times \\Omega_{2} \\rightarrow[0,1]$\n\nand let $\\mathscr{C}\\left(\\sigma_{1}, \\sigma_{2}\\right)=\\sum_{i \\in[3]} \\mathscr{C}_{i}\\left(\\sigma_{1}, \\sigma_{2}\\right)$ for any $\\sigma_{1} \\in \\Omega_{1}, \\sigma_{2} \\in \\Omega_{2}$. The coupling tables $\\mathscr{C}_{1}, \\mathscr{C}_{2}, \\mathscr{C}_{3}$ are constructed as follows (any unspecified entries are defined as 0 ):\n(1) For any $\\sigma \\in \\Omega_{2}$, define $\\mathscr{C}_{1}(\\sigma, \\sigma)=1 /\\left|\\Omega_{1}\\right|$;\n(2) For any $\\sigma \\in \\Omega_{1} \\backslash \\Omega_{2}$ and $v \\in P \\backslash\\{u\\}$ satisfying $f(v, \\sigma) \\in \\Omega_{2}$, define\n\n$$\n\\mathscr{C}_{2}(\\sigma, f(v, \\sigma))=\\min \\left\\{\\frac{1}{|P|-1} \\cdot \\frac{1}{\\left|\\Omega_{1}\\right|} \\cdot \\frac{1}{\\left|\\Omega_{2}\\right|} \\sim \\frac{1}{\\left|\\Omega_{1}\\right|}\\right\\}\n$$\n\n(3) Complete the coupling table $\\mathscr{C}_{3}$ such that for any $\\sigma \\in \\Omega_{1}$, we have $\\sum_{i \\in[3], \\tau \\in \\Omega_{2}} \\mathscr{C}_{i}(\\sigma, \\tau)=1 /\\left|\\Omega_{1}\\right|$; for any $\\tau \\in \\Omega_{2}$, we have $\\sum_{i \\in[3], \\sigma \\in \\Omega_{2}} \\mathscr{C}_{i}(\\sigma, \\tau)=1 /\\left|\\Omega_{2}\\right|$. That is, the coupling table $\\mathscr{C}_{3}$ is the residual density of the coupling between $\\mu_{1}$ and $\\mu_{2}$.\nWe claim that the mapping constructed above defines a valid coupling between $\\mu_{1}$ and $\\mu_{2}$. To verify this, it suffices to show that the marginal density specified by $\\mathscr{C}_{1}$ and $\\mathscr{C}_{2}$ is less than their marginal probability respectively:\n\n- For any $\\sigma \\in \\Omega_{2}$, one can verify that $\\sum_{i \\in[2], \\tau \\in \\Omega_{2}} \\mathscr{C}_{i}(\\sigma, \\tau)=1 /\\left|\\Omega_{1}\\right|$. For any $\\sigma \\in \\Omega_{1} \\backslash \\Omega_{2}$, the entries in $\\mathscr{C}_{1}(\\sigma, \\cdot)$ are all 0 . As for $\\mathscr{C}_{2}(\\sigma, \\cdot)$, there are at most $|P|-1$ non-zero entries and each less than $1 /\\left((|P|-1) \\cdot\\left|\\Omega_{1}\\right|\\right)$ by definition. Therefore, $\\sum_{i \\in[2], \\tau \\in \\Omega_{2}} \\mathscr{C}_{i}(\\sigma, \\tau) \\leq 1 /\\left|\\Omega_{1}\\right|$.\n- For any $\\tau \\in \\Omega_{2}$, we claim that there is at most one non-zero entry in $\\mathscr{C}_{2}(\\cdot, \\tau)$. As mentioned before, the mapping $f(v, \\cdot)$ is injective for any $v \\in P \\backslash\\{u\\}$. Consequently, if there are $\\sigma_{1}$ and $\\sigma_{2}$ such that $\\mathscr{C}_{2}\\left(\\sigma_{1}, \\tau\\right)>0$ and $\\mathscr{C}_{2}\\left(\\sigma_{2}, \\tau\\right)>0$, then $\\sigma_{1}$ and $\\sigma_{2}$ must map to $\\tau$ via distinct vertices in $P \\backslash\\{u\\}$. However, this situation cannot occur, as can be verified from the definition of the mapping $f(\\cdot, \\cdot)$, which assigns value $c$ to different vertices. Therefore, it follows that $\\sum_{i \\in[2], \\sigma \\in \\Omega_{2}} \\mathscr{C}_{i}(\\sigma, \\tau) \\leq 1 /\\left|\\Omega_{2}\\right|$.\nIn the coupling table constructed above, we have\n\n$$\n\\sum_{\\left(\\sigma_{1}, \\sigma_{2}\\right) \\in \\Omega_{1} \\times \\Omega_{2}} \\mathscr{C}_{2}\\left(\\sigma_{1}, \\sigma_{2}\\right) \\leq \\sum_{\\sigma \\in \\Omega_{1} \\backslash \\Omega_{2}} \\frac{1}{\\left|\\Omega_{1}\\right|}=\\left(1-\\frac{\\left|\\Omega_{2}\\right|}{\\left|\\Omega_{1}\\right|}\\right) \\leq \\frac{1}{|P|}\\left(1+\\frac{2 v \\Delta}{|P|}\\right)\n$$\n\nwhere the last inequality follows from (94).\nWe should also analyze the coupling table $\\mathscr{C}_{3}$. Let $\\Omega_{2}^{\\circ}$ be the collection of assignments $\\tau \\in \\Omega_{2}$ such that $\\tau=f(v, \\sigma)$ for the variable $v \\in P \\backslash\\{u\\}$ and assignment $\\sigma \\in \\Omega_{1} \\backslash \\Omega_{2}$. By the injection of the mapping, for any $\\sigma_{2} \\in \\Omega_{2}^{\\circ}$, we have\n\n$$\n\\begin{aligned}\n\\sum_{\\sigma_{1} \\in \\Omega_{1}} \\mathscr{C}_{3}\\left(\\sigma_{1}, \\sigma_{2}\\right) & =\\left(\\frac{1}{\\left|\\Omega_{2}\\right|} \\sim \\frac{1}{\\left|\\Omega_{1}\\right|}\\right)-\\min \\left\\{\\frac{1}{|P|-1} \\cdot \\frac{1}{\\left|\\Omega_{1}\\right|} \\cdot \\frac{1}{\\left|\\Omega_{2}\\right|} \\sim \\frac{1}{\\left|\\Omega_{1}\\right|}\\right\\} \\\\\n& =\\min \\left\\{\\frac{1}{\\left|\\Omega_{2}\\right|}\\left(1-\\frac{\\left|\\Omega_{2}\\right|}{\\left|\\Omega_{1}\\right|}\\right)-\\frac{1}{|P|-1} \\cdot \\frac{1}{\\left|\\Omega_{1}\\right|}, 0\\right\\} \\\\\n& \\leq \\frac{1}{\\left|\\Omega_{2}\\right|}\\left(\\frac{1}{|P|}\\left(1+\\frac{2 v \\Delta}{|P|}\\right)\\right)-\\frac{1}{\\left|\\Omega_{2}\\right|}\\left(\\frac{1}{|P|-1} \\cdot\\left(1-\\frac{1}{|P|}\\left(1+\\frac{2 v \\Delta}{|P|}\\right)\\right)\\right) \\\\\n& \\leq \\frac{1}{\\left|\\Omega_{2}\\right|} \\cdot \\frac{4 v \\Delta}{|P|^{2}}\n\\end{aligned}\n$$\n\nwhere the second inequality holds by (94) and (95). The above fact implies that\n\n$$\n\\sum_{\\sigma_{2} \\in \\Omega_{2}^{\\circ}} \\sum_{\\sigma_{1} \\in \\Omega_{1}} \\mathscr{C}_{3}\\left(\\sigma_{1}, \\sigma_{2}\\right) \\leq \\frac{4 v \\Delta}{|P|^{2}}\n$$\n\nMoreover, one can verify that for any $\\sigma_{2} \\in \\Omega_{2} \\backslash \\Omega_{2}^{\\circ}$,\n\n$$\n\\sum_{\\sigma_{1} \\in \\Omega_{1}} \\mathscr{C}_{3}\\left(\\sigma_{1}, \\sigma_{2}\\right)=\\frac{1}{\\left|\\Omega_{2}\\right|} \\sim \\frac{1}{\\left|\\Omega_{1}\\right|}\n$$\n\nConsequently, it holds that\n\n$$\n\\begin{aligned}\n\\sum_{\\sigma_{2} \\in \\Omega_{2} \\backslash \\Omega_{2}^{\\prime}} \\sum_{\\sigma_{1} \\in \\Omega_{1}} \\mathscr{C}_{3}\\left(\\sigma_{1}, \\sigma_{2}\\right) & \\leq \\sum_{\\sigma_{2} \\in \\Omega_{2} \\backslash \\Omega_{2}^{\\prime}}\\left(\\frac{1}{\\left|\\Omega_{2}\\right|}-\\frac{1}{\\left|\\Omega_{1}\\right|}\\right) \\\\\n& \\leq \\sum_{\\sigma_{2} \\in \\Omega_{2} \\backslash \\Omega_{2}^{\\prime}} \\frac{1}{\\left|\\Omega_{2}\\right|}\\left(\\frac{1}{|P|}\\left(1+\\frac{2 \\mathrm{e} \\Delta}{|P|}\\right)\\right) \\\\\n& =\\left(\\frac{1}{|P|}\\left(1+\\frac{2 \\mathrm{e} \\Delta}{|P|}\\right)\\right) \\cdot \\operatorname{Pr}_{\\sigma \\sim \\mu_{2}}\\left[\\sigma \\in \\Omega_{2} \\backslash \\Omega_{2}^{\\prime}\\right] \\\\\n& \\leq\\left(\\frac{1}{|P|}\\left(1+\\frac{2 \\mathrm{e} \\Delta}{|P|}\\right)\\right) \\cdot \\sum_{v \\in P \\backslash\\{u\\}} \\sum_{c^{\\prime} \\in \\Lambda\\left(C_{2}, v\\right) \\backslash\\{c\\}} \\operatorname{Pr}_{\\sigma \\sim \\mu_{2}}\\left[\\sigma(v)=c, \\sigma(u)=c^{\\prime}\\right] \\\\\n& \\leq\\left(\\frac{1}{|P|}\\left(1+\\frac{2 \\mathrm{e} \\Delta}{|P|}\\right)\\right) \\cdot(|P|-1) \\cdot \\Delta \\cdot \\frac{1}{|P||P-1|} \\cdot\\left(1+\\frac{4 \\mathrm{e} \\Delta}{|P|}\\right) \\\\\n& \\leq\\left(\\frac{1}{|P|}\\left(1+\\frac{2 \\mathrm{e} \\Delta}{|P|}\\right)\\right) \\cdot \\frac{2 \\Delta}{|P|}\n\\end{aligned}\n$$\n\nwhere the second inequality follows from (94) and the fourth inequality from Lemma 3.3.\nCombining (96). (97) and (98), there exists a coupling $\\mathscr{C}$ of $\\mu_{\\Phi_{1}}$ and $\\mu_{\\Phi_{2}}$ satisfying\n\n$$\n\\begin{aligned}\n& \\mathrm{E}_{\\left(\\sigma_{1}, \\sigma_{2}\\right) \\sim \\mathscr{C}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right] \\\\\n= & \\sum_{i \\in\\{\\Delta\\}} \\sum_{\\left(\\sigma_{1}, \\sigma_{2}\\right) \\in \\Omega_{1} \\times \\Omega_{2}} \\mathscr{C}_{i}\\left(\\sigma_{1}, \\sigma_{2}\\right) \\cdot\\left(\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right) \\\\\n= & 2 \\cdot \\sum_{\\left(\\sigma_{1}, \\sigma_{2}\\right) \\in \\Omega_{1} \\times \\Omega_{2}} \\mathscr{C}_{2}\\left(\\sigma_{1}, \\sigma_{2}\\right)+|P| \\cdot\\left(\\sum_{\\sigma_{2} \\in \\Omega_{2}^{\\prime}} \\sum_{\\sigma_{1} \\in \\Omega_{1}} \\mathscr{C}_{3}\\left(\\sigma_{1}, \\sigma_{2}\\right)+\\sum_{\\sigma_{2} \\in \\Omega_{2} \\backslash \\Omega_{2}^{\\prime}} \\sum_{\\sigma_{1} \\in \\Omega_{1}} \\mathscr{C}_{3}\\left(\\sigma_{1}, \\sigma_{2}\\right)\\right) \\\\\n\\leq & \\frac{2}{|P|}+\\frac{4 \\mathrm{e} \\Delta}{|P|}+\\frac{4 \\Delta}{|P|} \\leq \\frac{17 \\Delta}{|P|}\n\\end{aligned}\n$$\n\nwhich implies the desired bound (93) in the base case where $\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right|=1$.\nInduction step: Given $\\ell>1$, assume the statement holds for any pair of formulas $\\Phi_{1}, \\Phi_{2}$ where $\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right| \\leq \\ell-1$. We then prove the statement for any formulas $\\Phi_{1}=\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}_{1}\\right), \\Phi_{2}=\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}_{2}\\right)$ satisfying $\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right|=\\ell$. Suppose $\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}=\\left\\{C_{1}, C_{2}, \\cdots, C_{\\ell}\\right\\}$. We define the formula $\\Psi=\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}_{2} \\backslash\\left\\{C_{\\ell}\\right\\}\\right)$. According to the induction hypothesis, there exists a coupling $\\mathscr{C}_{1}$ between $\\mu_{\\Phi_{1}}$ and $\\mu_{\\Psi}$ such that\n\n$$\n\\mathrm{E}_{\\left(\\sigma_{1}, \\tau\\right) \\sim \\mathscr{C}_{1}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\tau(v)\\right]\\right] \\leq \\frac{17 \\Delta(\\ell-1)}{|P|}\n$$\n\nApplying the coupling construction for the base case, we have a coupling $\\mathscr{C}_{2}$ between $\\mu_{\\Psi}$ and $\\mu_{\\Phi_{2}}$ satisfying\n\n$$\n\\mathrm{E}_{\\left(\\tau, \\sigma_{2}\\right) \\sim \\mathscr{C}_{2}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\tau(v) \\neq \\sigma_{2}(v)\\right]\\right] \\leq \\frac{17 \\Delta}{|P|}\n$$\n\nWe then construct a coupling $\\mathscr{C}$ between $\\mu_{\\Phi_{1}}, \\mu_{\\Psi}$ and $\\mu_{\\Phi_{2}}$ where\n\n$$\n\\forall \\sigma_{1} \\in \\Omega_{\\Phi_{1}}, \\tau \\in \\Omega_{\\Psi}, \\sigma_{2} \\in \\Omega_{\\Phi_{2}}: \\quad \\mathscr{C}\\left(\\sigma_{1}, \\tau, \\sigma_{2}\\right)=\\mathscr{C}_{1}\\left(\\sigma_{1}, \\tau\\right) \\cdot \\frac{\\mathscr{C}_{2}\\left(\\tau, \\sigma_{2}\\right)}{\\mu_{\\Psi}(\\tau)}\n$$\n\nTherefore, the discrepancy in the optimal coupling $\\mathscr{C}_{\\text {opt }}$ between $\\mu_{\\Phi_{1}}$ and $\\mu_{\\Phi_{2}}$ satisfying\n\n$$\n\\mathrm{E}_{\\left(\\sigma_{1}, \\sigma_{2}\\right) \\sim \\mathscr{C}_{\\text {opt }}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right]\n$$\n\n$$\n\\begin{aligned}\n& \\leq \\mathrm{E}_{\\left(\\sigma_{1}, \\tau, \\sigma_{2}\\right) \\sim \\mathscr{C}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right] \\\\\n& \\leq \\mathrm{E}_{\\left(\\sigma_{1}, \\tau, \\sigma_{2}\\right) \\sim \\mathscr{C}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\tau(v)\\right]+\\sum_{v \\in P} \\mathbb{1}\\left[\\tau(v) \\neq \\sigma_{2}(v)\\right]\\right] \\\\\n& =\\mathrm{E}_{\\left(\\sigma_{1}, \\tau\\right) \\sim \\mathscr{C}_{1}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\tau(v)\\right]\\right]+\\mathrm{E}_{\\left(\\tau, \\sigma_{2}\\right) \\sim \\mathscr{C}_{2}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\tau(v) \\neq \\sigma_{2}(v)\\right]\\right] \\\\\n& \\leq \\frac{17 \\Delta\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right|}{|P|}\n\\end{aligned}\n$$\n\nwhere the last inequality holds by (99) and (100).\nPutting all these together, the proof is complete.\nWe also need the following lemma.\nLemma D.13. Given any PDCformulas $\\Phi_{1}=\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}_{1}\\right), \\Phi_{2}=\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}_{2}\\right)$ where $\\mathcal{P}=\\{P\\}$ and an integer $\\Delta \\geq 1$, assume $\\Delta_{\\Phi_{1}} \\leq \\Delta, \\Delta_{\\Phi_{2}} \\leq \\Delta, 2 \\mathrm{e} \\Delta \\leq|P|, \\mathcal{C}_{1} \\subseteq \\mathcal{C}_{2}$, and $|\\mathrm{vbl}(C)| \\geq 2$ for each $C \\in \\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}$. Let $\\left(\\sigma_{1}, \\sigma_{2}\\right)$ be an optimal coupling between $\\mu_{\\Phi_{1}}$ and $\\mu_{\\Phi_{2}}$ such that $\\mathrm{E}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right]$ is minimum. Then we have\n\n$$\n\\mathrm{E}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right] \\leq \\frac{2\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right|}{|P|-1}\n$$\n\nProof. Note that for any constraint $C \\in \\mathcal{C}_{2}$, the violation probability is at most $1 /|P|$. Combined with $2 \\mathrm{e} \\Delta \\leq|P|$, we have\n\n$$\n\\mathrm{e} p_{\\Phi_{1}} \\Delta_{\\Phi_{1}} \\leq 1, \\quad \\mathrm{e} p_{\\Phi_{2}} \\Delta_{\\Phi_{2}} \\leq 1\n$$\n\nThen, we prove the statement by induction.\nBase case: We first show that given $\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right|=1$, there exists an coupling $\\mathscr{C}$ between $\\mu_{\\Phi_{1}}$ and $\\mu_{\\Phi_{2}}$ such that\n\n$$\n\\mathrm{E}_{\\left(\\sigma_{1}, \\sigma_{2}\\right) \\sim \\mathscr{C}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right] \\leq \\frac{2}{|P|-1}\n$$\n\nWe construct the coupling by specifying the density of the joint distribution $\\mathscr{C}: \\Omega_{1} \\times \\Omega_{2} \\rightarrow[0,1]$. Specifically, we construct coupling tables $\\mathscr{T}_{1}, \\mathscr{T}_{2}: \\Omega_{1} \\times \\Omega_{2} \\rightarrow[0,1]$ and let $\\mathscr{C}\\left(\\sigma_{1}, \\sigma_{2}\\right)=\\sum_{t \\in\\{2\\}} \\mathscr{T}_{t}\\left(\\tau_{1}, \\tau_{2}\\right)$ for any $\\sigma_{1} \\in \\Omega_{1}$ and $\\sigma_{2} \\in \\Omega_{2}$. The coupling tables are defined as follows (any unspecified entries are defined as 0 ):\n(1) For any $\\sigma \\in \\Omega_{2}$, define $\\mathscr{T}_{1}(\\sigma, \\sigma)=\\mu_{\\Phi_{1}}(\\sigma)$;\n(2) Complete the coupling table $\\mathscr{T}_{2}$ to form a coupling.\n\nWe then analyze the coupling error of $\\mathscr{C}$.\nLet $\\{C\\}=\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}$, and use $\\mu_{1}$ and $\\mu_{2}$ to denote $\\mu_{\\Phi_{1}}$ and $\\mu_{\\Phi_{2}}$, respectively. Moreover, the corresponding supports are denoted by $\\Omega_{1}$ and $\\Omega_{2}$ for convenience. By definition, we have $\\Omega_{2} \\subseteq \\Omega_{1}$, and the density of $\\mu_{1}, \\mu_{2}$ are $1 /\\left|\\Omega_{1}\\right|, 1 /\\left|\\Omega_{2}\\right|$, respectively. Applying the Lemma 3.3 with the condition (101), we have\n\n$$\n\\begin{aligned}\n\\frac{\\left|\\Omega_{2}\\right|}{\\left|\\Omega_{1}\\right|} & =1-\\operatorname{Pr}_{\\sigma-\\mu_{1}}[C \\text { is unsatisfied under } \\sigma] \\\\\n& \\geq 1-\\frac{1}{|P|(|P|-1)}\\left(1-\\frac{\\mathrm{e}}{|P|}\\right)^{-\\Delta} \\quad\\left(\\mathbb{P}_{\\Phi_{1}}[C \\text { is unsatisfied }] \\leq \\frac{1}{|P|(|P|-1)}\\right) \\\\\n& \\geq 1-\\frac{1}{|P|(|P|-1)}\\left(1+\\frac{2 \\mathrm{e} \\Delta}{|P|}\\right) \\\\\n& \\geq 1-\\frac{2}{|P|(|P|-1)}\n\\end{aligned}\n$$\n\nwhich implies that for any $\\sigma \\in \\Omega_{2}$,\n\n$$\n\\mu_{1}(\\sigma) \\geq \\mu_{2}(\\sigma) \\cdot(1-2 /(|P|(|P|-1)))\n$$\n\nCombining all these facts, it holds that\n\n$$\n\\begin{aligned}\n\\Pr_{\\left(\\sigma_{1}, \\sigma_{2}\\right) \\sim \\mathscr{C}}\\left[\\sigma_{1} \\neq \\sigma_{2}\\right] & =1-\\operatorname{Pr}_{\\left(\\sigma_{1}, \\sigma_{2}\\right) \\sim \\mathscr{C}}\\left[\\sigma_{1}=\\sigma_{2}\\right] \\\\\n& =1-\\sum_{\\sigma \\in \\Omega_{2}} \\mu_{1}(\\sigma) \\\\\n& \\leq 1-\\sum_{\\sigma \\in \\Omega_{2}} \\mu_{2}(\\sigma) \\cdot(1-2 /(|P|(|P|-1))) \\\\\n& =\\frac{2}{|P|(|P|-1)}\n\\end{aligned}\n$$\n\nTherefore, we have\n\n$$\n\\mathrm{E}_{\\left(\\sigma_{1}, \\sigma_{2}\\right) \\sim \\mathscr{C}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right] \\leq \\operatorname{Pr}_{\\left(\\sigma_{1}, \\sigma_{2}\\right) \\sim \\mathscr{C}}\\left[\\sigma_{1} \\neq \\sigma_{2}\\right] \\cdot|P| \\leq \\frac{2}{|P|-1}\n$$\n\nwhere the last inequality follows from (103).\nInduction step: Given $\\ell>1$, assume the statement holds for any formulas $\\Phi_{1}, \\Phi_{2}$ where $\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right| \\leq \\ell-1$. The statement holds for any formulas $\\Phi_{1}=\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}_{1}\\right), \\Phi_{2}=\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}_{2}\\right)$ satisfying $\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right|=\\ell$ by similar argument stated in the proof of Lemma D. 12 .\n\nCombining with Lemma D. 12 and Lemma D.13, we have the following lemma according to the triangle inequality for the coupling.\nLemma D.14. Given any PDCformulas $\\Phi_{1}=\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}_{1}\\right), \\Phi_{2}=\\left(\\mathcal{P}, \\mathcal{Q}, \\mathcal{C}_{2}\\right)$ where $\\mathcal{P}=\\{P\\}$ and an integer $\\Delta \\geq 1$, assume $\\Delta_{\\Phi_{1}} \\leq \\Delta, \\Delta_{\\Phi_{2}} \\leq \\Delta, 4 \\mathrm{e} \\Delta \\leq|P|$ and $\\mathcal{C}_{1} \\subseteq \\mathcal{C}_{2}$. Let $\\left(\\sigma_{1}, \\sigma_{2}\\right)$ be an optimal coupling between $\\mu_{\\Phi_{1}}$ and $\\mu_{\\Phi_{2}}$ such that $\\mathrm{E}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right]$ is minimum. Then we have\n\n$$\n\\mathrm{E}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}(v) \\neq \\sigma_{2}(v)\\right]\\right] \\leq \\frac{17 \\Delta\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right|}{|P|-1}\n$$\n\nWe are now finishing the proof of Lemma D.11.\nProof of Lemma D.11. If $S=\\emptyset$, the two distributions can be coupled completely. Hence, in the subsequent discussion, it suffices to focus on the case where $S \\neq \\emptyset$.\n\nFor convenience, we use $U$ to denote the variables $V \\backslash(S \\cup P)$. Given any pair of feasible partial assignments $\\sigma_{1, S}, \\sigma_{2, S}$ on $S$ in $\\Phi_{1}$ and $\\Phi_{2}$, respectively, let $\\Psi_{1}=\\Phi_{1}^{\\sigma_{1, S}}$ and $\\Psi_{2}=\\Phi_{2}^{\\sigma_{2, S}}$ be the formulas conditioned on $\\sigma_{1, S}$ and $\\sigma_{2, S}$, respectively. We use $\\Omega_{U}$ to denote the support of the distribution $\\mu_{\\Psi, U}$ where $\\Psi=\\left(\\mathcal{P}, \\mathcal{Q}_{1}, \\mathcal{C} \\backslash \\mathcal{C}(P)\\right)$. Since $|P|>4 \\mathrm{e} \\Delta$, for any $\\sigma \\in \\Omega_{U}$, it is feasible in $\\Psi_{1}$ and $\\Psi_{2}$ by lopsided LLL. Consequently, the support of $\\mu_{\\Psi_{1}, U}$ and $\\mu_{\\Psi_{2}, U}$ is equal to $\\Omega_{U}$. Let $\\mathcal{C}_{1}, \\mathcal{C}_{2}$ be the sets of unsatisfied constraints in $\\mathcal{C}(P)$ in the formula $\\Psi_{1}$ and $\\Psi_{2}$, respectively. We define $\\Psi_{3}$ as the PDC formula obtained by removing the variables in $S$ while retaining the constraints $\\left(\\mathcal{C} \\backslash \\mathcal{C}(P)\\right) \\cup\\left(\\mathcal{C}_{1} \\cap \\mathcal{C}_{2}\\right)$. This formula will serve as an intermediate step in the construction of the coupling.\n\nIn the following, we specify a coupling between $\\mu_{\\Psi_{1}}$ and $\\mu_{\\Psi_{2}}$. We first construct a coupling $\\mathscr{C}_{U}$ between $\\mu_{\\Psi_{1}, U}$ and $\\mu_{\\Psi_{2}, U}$ by specifying the density of the joint distribution $\\mathscr{C}_{U}: \\Omega_{U} \\times \\Omega_{U} \\rightarrow[0,1]$. Specifically, we would construct coupling tables $\\mathscr{T}_{1}, \\mathscr{T}_{2}: \\Omega_{U} \\times \\Omega_{U} \\rightarrow[0,1]$ and let $\\mathscr{C}_{U}\\left(\\tau_{1}, \\tau_{2}\\right)=\\sum_{t \\in\\{2\\}} \\mathscr{T}_{t}\\left(\\tau_{1}, \\tau_{2}\\right)$ for any $\\tau_{1}, \\tau_{2} \\in \\Omega_{U}$. The coupling tables are defined as follows (any unspecified entries are defined as 0 ):\n(1) For any $\\tau \\in \\Omega_{U}$, define $\\mathscr{T}_{1}(\\tau, \\tau)=\\min \\left\\{\\mu_{\\Psi_{1}, U}(\\tau), \\mu_{\\Psi_{2}, U}(\\tau)\\right\\}$;\n(2) Complete the coupling table $\\mathscr{T}_{2}$ to form a coupling.\n\nFor any $\\tau \\in \\Omega_{U}$, let $\\Psi_{1}^{\\tau}=\\left(\\{P\\},\\{Q\\}, \\mathcal{C}_{1}^{\\tau}\\right)$, and $\\Psi_{3}^{\\tau}=\\left(\\{P\\},\\{Q\\}, \\mathcal{C}_{3}^{\\tau}\\right)$. Applying Lemma 3.3 with the condition that $2 \\mathrm{e} \\Delta \\leq|P|$, we have\n\n$$\n\\left(\\left|\\Omega_{\\Psi_{3}^{\\tau}}\\right|-\\left|\\Omega_{\\Psi_{1}^{\\tau}}\\right|\\right) /\\left|\\Omega_{\\Psi_{3}^{\\tau}}\\right|=\\operatorname{Pr}_{\\sigma \\rightarrow \\mu_{\\Psi_{3}^{\\tau}}}\\left[\\mathcal{C}_{1}^{\\tau} \\backslash \\mathcal{C}_{3}^{\\tau} \\text { are unsatisfied under } \\sigma\\right]\n$$\n\n$$\n\\begin{aligned}\n& \\leq \\sum_{C \\in \\mathcal{C}_{1}^{\\prime} \\backslash \\mathcal{C}_{3}^{\\prime}} \\operatorname{Pr}_{\\sigma \\rightarrow \\tau_{3}^{\\prime}}\\left[C \\text { is unsatisfied under } \\sigma\\right] \\\\\n& \\leq\\left|\\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}\\right| \\cdot \\frac{1}{|P|} \\cdot\\left(1+\\frac{2 \\mathrm{e} \\Delta}{|P|}\\right)\n\\end{aligned}\n$$\n\nwhich implies\n\n$$\n\\left(1-\\left|\\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}\\right| \\cdot \\frac{1}{|P|} \\cdot\\left(1+\\frac{2 \\mathrm{e} \\Delta}{|P|}\\right)\\right) \\cdot\\left|\\Omega_{\\Psi_{3}^{\\prime}}\\right| \\leq\\left|\\Omega_{\\Psi_{1}^{\\prime}}\\right| \\leq\\left|\\Omega_{\\Psi_{2}^{\\prime}}\\right|\n$$\n\nTo simplify the notation, let $r=1-\\left|\\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}\\right| /|P| \\cdot(1+2 \\mathrm{e} \\Delta /|P|)$. Consequently, we have\n\n$$\n\\mu_{\\Psi_{1}, U}(\\tau)=\\frac{\\left|\\Omega_{\\Psi_{1}^{\\prime}}\\right|}{\\sum_{\\tau^{\\prime} \\in \\Omega_{U}}\\left|\\Omega_{\\Psi_{1}^{\\prime \\prime}}\\right|} \\geq \\frac{r \\cdot\\left|\\Omega_{\\Psi_{2}^{\\prime}}\\right|}{\\sum_{\\tau^{\\prime} \\in \\Omega_{U}}\\left|\\Omega_{\\Psi_{2}^{\\prime \\prime}}\\right|}=r \\cdot \\mu_{\\Psi_{3}, U}(\\tau)\n$$\n\nCombining all these facts, it holds that\n\n$$\n\\begin{aligned}\n\\operatorname{Pr}_{\\left(\\tau_{1}, \\tau_{2}\\right) \\sim \\mathscr{C}_{U}}\\left[\\tau_{1} \\neq \\tau_{2}\\right] & =1-\\operatorname{Pr}_{\\left(\\tau_{1}, \\tau_{2}\\right) \\sim \\mathscr{C}_{U}}\\left[\\tau_{1}=\\tau_{2}\\right] \\\\\n& =1-\\sum_{\\tau \\in \\Omega_{U}} \\min \\left\\{\\mu_{\\Psi_{1}, U}(\\tau), \\mu_{\\Psi_{3}, U}(\\tau)\\right\\} \\\\\n& \\leq 1-\\sum_{\\tau \\in \\Omega_{U}} r \\cdot \\mu_{\\Psi_{3}, U}(\\tau) \\\\\n& =1-r=\\left|\\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}\\right| \\cdot \\frac{1}{|P|} \\cdot\\left(1+\\frac{2 \\mathrm{e} \\Delta}{|P|}\\right) \\\\\n& \\leq \\frac{2\\left|\\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}\\right|}{|P|}\n\\end{aligned}\n$$\n\nGiven any $\\tau_{1}, \\tau_{2} \\in \\Omega_{U}$, we complete our coupling construction by specifying the coupling between $\\mu_{\\Psi_{1}^{\\tau_{1}}}$ and $\\mu_{\\Psi_{2}^{\\tau_{2}}}$. When $\\tau_{1}=\\tau_{2}=\\tau$, let $\\Psi_{1}^{\\tau}=\\left(\\{P\\},\\{Q\\}, \\mathcal{C}_{1}^{\\tau}\\right)$, and $\\Psi_{3}^{\\tau}=\\left(\\{P\\},\\{Q\\}, \\mathcal{C}_{3}^{\\tau}\\right)$. By definition, we have $\\mathcal{C}_{3}^{\\tau} \\subseteq \\mathcal{C}_{1}^{\\tau}$ and $\\mathcal{C}_{1}^{\\tau} \\backslash \\mathcal{C}_{3}^{\\tau} \\subseteq \\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}$. According to Lemma D.14, there exists a coupling $\\mathscr{C}_{P}$ between $\\mu_{\\Psi_{1}^{\\tau}}$ and $\\mu_{\\Psi_{2}^{\\tau}}$ such that\n\n$$\n\\mathrm{E}_{\\left(\\tau_{1}^{\\prime}, \\tau_{2}^{\\prime}\\right) \\sim \\mathscr{C}_{P}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\tau_{1}^{\\prime}(v) \\neq \\tau_{2}^{\\prime}(v)\\right]\\right] \\leq \\frac{17 \\Delta\\left|\\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}\\right|}{|P|-1}\n$$\n\nOn the other hand, when $\\tau_{1} \\neq \\tau_{2}$, let $\\Psi_{1}^{\\tau_{1}}=\\left(\\{P\\},\\{Q\\}, \\mathcal{C}_{1}^{\\tau_{1}}\\right)$, and $\\Psi_{3}^{\\tau_{3}}=\\left(\\{P\\},\\{Q\\}, \\mathcal{C}_{3}^{\\tau_{3}}\\right)$. By definition, we have $\\left(\\mathcal{C}_{1}^{\\tau_{1}} \\backslash \\mathcal{C}_{3}^{\\tau_{2}}\\right) \\cup\\left(\\mathcal{C}_{1}^{\\tau_{1}} \\backslash \\mathcal{C}_{3}^{\\tau_{2}}\\right) \\subseteq \\mathcal{C}(P)$. According to Lemma D.14, there exists a coupling $\\mathscr{C}_{P}^{\\tau}$ between $\\mu_{\\Psi_{1}^{\\tau_{1}}}$ and $\\mu_{\\Psi_{2}^{\\tau_{2}}}$ such that\n\n$$\n\\mathrm{E}_{\\left(\\tau_{1}^{\\prime}, \\tau_{2}^{\\prime}\\right) \\sim \\mathscr{C}_{P}^{\\tau}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\tau_{1}^{\\prime}(v) \\neq \\tau_{2}^{\\prime}(v)\\right]\\right] \\leq \\frac{17 \\Delta|\\mathcal{C}(P)|}{|P|-1} \\leq \\frac{17|P| \\Delta^{2}}{|P|-1}\n$$\n\nWe are now ready to specify the coupling $\\left(\\sigma_{1}^{\\prime}, \\sigma_{2}^{\\prime}\\right) \\sim \\mathscr{C}_{1}$ between $\\mu_{\\Psi_{1}}$ and $\\mu_{\\Psi_{3}}$ as follows:\n(1) Sample $\\tau_{1}, \\tau_{2}$ from the distribution $\\mathscr{C}_{U}$;\n(2) If $\\tau_{1}=\\tau_{2}$, sample $\\tau_{1}^{\\prime}, \\tau_{2}^{\\prime}$ from $\\mathscr{C}_{P}$; Otherwise, sample $\\tau_{1}^{\\prime}, \\tau_{2}^{\\prime}$ from $\\mathscr{C}_{P}^{\\tau}$;\n(3) $\\sigma_{1, U}^{\\prime} \\leftarrow \\tau_{1}, \\sigma_{1, P}^{\\prime} \\leftarrow \\tau_{1}^{\\prime}, \\sigma_{2, U}^{\\prime} \\leftarrow \\tau_{2}$, and $\\sigma_{2, P}^{\\prime} \\leftarrow \\tau_{2}^{\\prime}$.\n\nOne can verify that $\\left(\\sigma_{1}^{\\prime}, \\sigma_{2}^{\\prime}\\right)$ is a coupling. Furthermore,\n\n$$\n\\begin{aligned}\n& \\mathrm{E}_{\\left(\\sigma_{1}^{\\prime}, \\sigma_{2}^{\\prime}\\right) \\sim \\mathscr{C}_{1}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}^{\\prime}(v) \\neq \\sigma_{2}^{\\prime}(v)\\right]\\right] \\\\\n\\leq & \\operatorname{Pr}\\left[\\tau_{1}=\\tau_{2}\\right] \\cdot \\mathrm{E}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\tau_{1}^{\\prime}(v) \\neq \\tau_{2}^{\\prime}(v)\\right]\\right]+\\operatorname{Pr}\\left[\\tau_{1} \\neq \\tau_{2}\\right] \\cdot \\mathrm{E}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\tau_{1}^{\\prime}(v) \\neq \\tau_{2}^{\\prime}(v)\\right]\\right]\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n& \\leq \\operatorname{Pr}\\left[\\tau_{1}=\\tau_{2}\\right] \\cdot \\frac{17 \\Delta\\left|\\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}\\right|}{|P|-1}+\\operatorname{Pr}\\left[\\tau_{1} \\neq \\tau_{2}\\right] \\cdot \\frac{17|P| \\Delta^{2}}{|P|-1} \\\\\n& \\leq \\frac{17 \\Delta\\left|\\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}\\right|}{|P|-1}+\\frac{2\\left|\\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}\\right|}{|P|} \\cdot \\frac{17|P| \\Delta^{2}}{|P|-1} \\leq \\frac{51 \\Delta^{2}\\left|\\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}\\right|}{|P|-1}\n\\end{aligned}\n$$\n\nBy similar arguments, we can show that there exists a coupling $\\mathscr{C}_{2}$ between $\\mu_{\\mathbb{P}_{2}}$ and $\\mu_{\\mathbb{P}_{3}}$ such that\n\n$$\n\\mathrm{E}_{\\left(\\sigma_{1}^{\\prime}, \\sigma_{2}^{\\prime}\\right) \\sim \\mathscr{C}_{2}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}^{\\prime}(v) \\neq \\sigma_{2}^{\\prime}(v)\\right]\\right] \\leq \\frac{51 \\Delta^{2}\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right|}{|P|-1}\n$$\n\nCombining all these facts with the triangle inequality, there exists a coupling $\\mathscr{C}$ between $\\mu_{\\mathbb{P}_{1}}$ and $\\mu_{\\mathbb{P}_{2}}$ such that\n\n$$\n\\mathrm{E}_{\\left(\\sigma_{1}^{\\prime}, \\sigma_{2}^{\\prime}\\right) \\sim \\mathscr{C}}\\left[\\sum_{v \\in P} \\mathbb{1}\\left[\\sigma_{1}^{\\prime}(v) \\neq \\sigma_{2}^{\\prime}(v)\\right]\\right] \\leq \\frac{51 \\Delta^{2}\\left|\\mathcal{C}_{1} \\backslash \\mathcal{C}_{2}\\right|}{|P|-1}+\\frac{51 \\Delta^{2}\\left|\\mathcal{C}_{2} \\backslash \\mathcal{C}_{1}\\right|}{|P|-1} \\leq 100 \\Delta^{2}|P|^{-1}|\\mathcal{C}(S) \\cap \\mathcal{C}(P)|\n$$\n\nProof of Lemma 8.21. Here, we use the notations from Algorithm 8 for discussion.\nLet $\\Phi_{1}=\\left(\\mathcal{P}_{1}, \\mathcal{Z}_{1}, \\mathcal{C}\\right), \\Phi_{2}=\\left(\\mathcal{P}_{2}, \\mathcal{Z}_{2}, \\mathcal{C}\\right)$ be the formulas at Line 25 in Algorithm 8 where $\\mathcal{P}_{1}=\\mathcal{P}_{2}$, and $\\mathcal{P}^{\\dagger}[P]=\\left(P_{1}, P_{2}, \\cdots, P_{t}\\right)$. Note that $\\mathcal{L} \\in \\mathcal{P}^{\\dagger}$, and $Z_{1}(\\mathcal{L})=Z_{2}(\\mathcal{L})$. Let $T=\\mathcal{P}_{u}$ and $S=\\bigcup_{P \\in T} P$. By definition, we have $\\mathcal{L} \\cap S=\\emptyset$, and that in the factorization of $\\left(\\mathcal{P}^{\\dagger}, Z_{1}, \\mathcal{C}_{u} \\backslash \\mathcal{C}(\\mathcal{L})\\right)$ and $\\left(\\mathcal{P}^{\\dagger}, Z_{2}, \\mathcal{C}_{u} \\backslash \\mathcal{C}(\\mathcal{L})\\right)$, each variable $v \\in S$ is not connected to any variable $u \\notin S$. Combining all these facts with Lemma D.11, it holds that\n\n$$\n\\begin{aligned}\n\\sum_{P \\in \\overline{\\mathcal{R}}} \\mathrm{E}\\left[\\operatorname{Dis}\\left(Y_{1}^{\\prime}, Y_{2}^{\\prime}, \\mathcal{L}\\right) \\mid \\mathcal{L}=P\\right] & =\\sum_{P \\in \\overline{\\mathcal{R}}} \\mathrm{E}\\left[\\sum_{i \\in\\{t\\}}\\left|\\sigma_{1}\\left(P_{i}\\right) \\backslash \\sigma_{2}\\left(P_{i}\\right)\\right| \\mid \\mathcal{L}=P\\right] \\\\\n& \\leq 100 \\Delta^{2} \\sum_{P \\in \\overline{\\mathcal{R}}} \\mathrm{E}[|\\mathcal{C}(S) \\cap \\mathcal{C}(\\mathcal{L})| \\mid \\mathcal{L}=P]|P|^{-1} \\\\\n& \\leq 100 \\Delta^{2} \\alpha^{-1} \\sum_{P \\in \\overline{\\mathcal{R}}} \\mathrm{E}[|\\mathcal{C}(S) \\cap \\mathcal{C}(\\mathcal{L})| \\mid \\mathcal{L}=P]\n\\end{aligned}\n$$\n\nAdditionally, we emphasize that for each $P \\in \\overline{\\mathcal{R}}$, we have $\\mathcal{P}_{\\theta}=\\mathcal{D}^{\\prime}$ under the condition $\\mathcal{L}=P$. Thus, we have\n\n$$\n\\begin{aligned}\n& \\sum_{P \\in \\overline{\\mathcal{R}}} \\mathrm{E}[|\\mathcal{C}(S) \\cap \\mathcal{C}(\\mathcal{L})| \\mid \\mathcal{L}=P] \\leq \\sum_{P \\in \\overline{\\mathcal{R}}} \\mathrm{E}\\left[\\sum_{P^{\\prime} \\in \\mathcal{P}_{u}}\\left|\\mathcal{C}\\left(P^{\\prime}\\right) \\cap \\mathcal{C}(\\mathcal{L})\\right| \\mid \\mathcal{L}=P\\right] \\\\\n= & \\sum_{P \\in \\overline{\\mathcal{R}}} \\mathrm{E}\\left[\\sum_{P^{\\prime} \\in \\mathcal{D}^{\\prime}} \\mathbb{1}\\left[P^{\\prime} \\in \\mathcal{P}_{u}\\right] \\cdot\\left|\\mathcal{C}\\left(P^{\\prime}\\right) \\cap \\mathcal{C}(\\mathcal{L})\\right| \\mid \\mathcal{L}=P\\right]=\\sum_{P^{\\prime} \\in \\mathcal{D}^{\\prime}} \\sum_{P \\in \\overline{\\mathcal{R}}}\\left(\\operatorname{Pr}\\left[P^{\\prime} \\in \\mathcal{P}_{u} \\mid \\mathcal{L}=P\\right] \\cdot\\left|\\mathcal{C}\\left(P^{\\prime}\\right) \\cap \\mathcal{C}(P)\\right|\\right) \\\\\n\\leq & \\sum_{P^{\\prime} \\in \\mathcal{D}^{\\prime}}\\left(\\max _{P \\in \\overline{\\mathcal{R}}} \\operatorname{Pr}\\left[P^{\\prime} \\in \\mathcal{P}_{u} \\mid \\mathcal{L}=P\\right] \\sum_{P \\in \\overline{\\mathcal{R}}}\\left|\\mathcal{C}\\left(P^{\\prime}\\right) \\cap \\mathcal{C}(P)\\right|\\right) \\leq k d \\sum_{P^{\\prime} \\in \\mathcal{D}^{\\prime}}\\left|P^{\\prime}\\right| \\max _{P \\in \\overline{\\mathcal{R}}} \\operatorname{Pr}\\left[P^{\\prime} \\in \\mathcal{P}_{u} \\mid \\mathcal{L}=P\\right]\n\\end{aligned}\n$$\n\nwhere the last inequality follows from the fact that each edge in $\\mathcal{C}\\left(P^{\\prime}\\right)$ can be reused for $k$ times.\nMoreover, according to Corollary 8.17 it holds that\n\n$$\n\\sum_{P^{\\prime} \\in \\mathcal{D}^{\\prime}}\\left|P^{\\prime}\\right| \\max _{P \\in \\overline{\\mathcal{R}}} \\operatorname{Pr}\\left[P^{\\prime} \\in \\mathcal{P}_{u} \\mid \\mathcal{L}=P\\right] \\leq \\sum_{P^{\\prime} \\in \\mathcal{D}^{\\prime}}\\left|P^{\\prime}\\right| \\sum_{s \\in \\mathrm{~V}\\left[P^{\\prime}\\right]} \\max _{P \\in \\overline{\\mathcal{R}}} \\operatorname{Pr}[s \\text { occurs } \\mid \\mathcal{L}=P]\n$$\n\nNote that in (109), the witness path can be summed more than once. The occurrence can be listed as the following cases:\n\nCase I:. For each witness path $s=\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ where $v_{t} \\in \\mathcal{D}^{\\prime} \\cap \\mathcal{Z}$, it could occur in the case where $v_{t}=P^{\\prime}$ or $\\left(v_{t}, P^{\\prime}\\right) \\in \\mathcal{S}^{*}\\left(\\mathcal{D}^{\\prime} \\cup \\mathcal{C}, \\mathcal{D}^{\\prime}, 1\\right)$. If it occurs in the case $v_{t}=P^{\\prime}$, it contributes\n\n$$\n\\left|v_{t}\\right| \\cdot \\max _{P \\in \\overline{\\mathcal{R}}} \\operatorname{Pr}[s \\text { occurs } \\mid \\mathcal{L}=P]\n$$\n\nin (109). Otherwise, we have $\\left(v_{t}, P^{\\prime}\\right) \\in \\mathcal{S}^{*}\\left(\\mathcal{D}^{\\prime} \\cup \\mathcal{C}, \\mathcal{Z}, 1\\right)$. By definition of $\\mathcal{S}^{*}\\left(\\mathcal{D}^{\\prime}, \\mathcal{Z}, 1\\right)$, it contributes\n\n$$\n\\left|v_{t}\\right| \\cdot d(k-1) \\cdot \\gamma^{\\theta} \\cdot \\max _{P \\in \\overline{\\mathcal{R}}} \\operatorname{Pr}[s \\text { occurs } \\mid \\mathcal{L}=P]\n$$\n\nwhere $\\gamma^{\\theta}$ is the upper bound of the size of $P^{\\prime}$.\nCase II:. For each witness path $s=\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ where $v_{t} \\in \\mathcal{D}^{\\prime} \\backslash \\mathcal{Z}$, it could occur in the case where $v_{t}=P^{\\prime}$. In this case, it contributes\n\n$$\n\\left|v_{t}\\right| \\cdot \\max _{P \\in \\overline{\\mathcal{R}}} \\operatorname{Pr}[s \\text { occurs } \\mid \\mathcal{L}=P]\n$$\n\nCase III:. For each witness path $s=\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ where $v_{t} \\in \\mathcal{C}_{s}$, it occurs in the case where $\\left(v_{t}, P^{\\prime}\\right) \\in$ $\\mathcal{S}^{*}\\left(\\mathcal{D}^{\\prime} \\cup \\mathcal{C}, \\mathcal{D}^{\\prime}, 1\\right)$. By definition, it contributes\n\n$$\nk \\cdot \\gamma^{\\theta} \\cdot d \\cdot k \\cdot \\gamma^{\\theta} \\cdot \\max _{P \\in \\overline{\\mathcal{R}}} \\operatorname{Pr}[s \\text { occurs } \\mid \\mathcal{L}=P]\n$$\n\nCombining these facts with the definition of $f(s)$, (107), (108) and (109), the lemma holds immediately.\nD.4.3. The probability of the occurrence of the witness path. In this section, we calculate the probability that a given witness sequence occurs and complete the proof of Lemma 8.22.\n\nGiven any instance in Algorithm 8, let $\\mathcal{A}^{0}$ be the random configuration of the coupling algorithm obtained after implementing the subroutine InitialCouple $(\\cdot)$, and $\\mathcal{A}^{t}$ be the random configuration of the coupling algorithm obtained after implementing the $t$-th subroutine $\\mathrm{CP}_{\\text {perm }}(\\cdot)$ for each $t \\geq 1$ in Algorithm 8. Given the random configuration $\\mathcal{A}$, let $\\ell(\\mathcal{A}, P)$ be the number of the assigned permutation sets among $\\mathcal{P}_{\\theta}[P]$ until there exists some $P^{\\prime} \\in \\mathcal{P}_{\\perp}$ in the configuration $\\mathcal{A}$ and $\\ell(P)=\\mathrm{e}^{-1}|P|^{1-\\theta}-(\\mathrm{e} \\Delta)^{-1}|P|^{1-2 \\theta} \\ln |P|$, for each $P \\in \\mathcal{P}^{\\dagger} \\backslash \\mathcal{I}$ such that $|P|>\\gamma$.\n\nGiven any w.s. $s=\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$, we define the following random variables for each integer $t \\geq 0$. For any $P \\in \\mathcal{P}^{\\dagger}$ such that $V_{C} \\cap \\mathcal{P}_{\\theta}[P] \\neq \\emptyset$ and $|P|>\\gamma$,\n\n$$\nM_{1}\\left(\\mathcal{A}^{t}, P\\right) \\doteq \\mathbb{1}\\left[\\left(v \\notin \\mathcal{P}_{\\perp}^{*}\\right) \\vee\\left(\\ell\\left(\\mathcal{A}^{t}, P\\right) \\geq \\ell(P)\\right)\\right] \\cdot \\prod_{i=\\ell\\left(\\mathcal{A}^{t}, P\\right)}^{\\ell(P)-1}\\left(1-4 \\Delta|P|^{\\theta} /\\left(|P|^{1-\\theta}-i\\right)\\right)\n$$\n\nwhere $v \\in V_{C} \\cap \\mathcal{P}_{\\theta}[P]$. Intuitively, $M_{1}\\left(\\mathcal{A}^{t}, P\\right)$ captures the circumstance where $P$ is consecutively successfully coupled. Furthermore, let\n\n$$\n\\begin{aligned}\nM_{2}\\left(\\mathcal{A}^{t}, P\\right) & \\doteqdot 15 \\Delta|P|^{2 \\theta-1} \\cdot \\mathbb{1}\\left[\\left(v \\notin \\mathcal{P}_{\\perp}^{*}\\right) \\wedge\\left(V_{\\text {set }} \\cap v=\\emptyset\\right) \\wedge\\left(\\ell\\left(\\mathcal{A}^{t}, P\\right)<\\ell(P)\\right)\\right] \\\\\n& +\\mathbb{1}\\left[\\left(v \\in \\mathcal{P}_{\\perp}^{*}\\right) \\wedge\\left(\\ell\\left(\\mathcal{A}^{t}, P\\right)<\\ell(P)\\right)\\right]\n\\end{aligned}\n$$\n\nany $P \\in \\mathcal{P}^{\\dagger}$ such that $V_{C} \\cap \\mathcal{P}_{\\theta}[P] \\neq \\emptyset$ and $|P| \\leq \\gamma$\n\n$$\nM_{3}\\left(\\mathcal{A}^{t}\\right) \\doteqdot \\prod_{v \\in V_{C} \\cap \\mathcal{P}_{\\theta}[P]:|P| \\leq \\gamma}\\left(15 \\Delta p^{\\theta}|P|^{2 \\theta} \\cdot \\mathbb{1}\\left[\\left(v \\notin \\mathcal{P}_{\\perp}^{*}\\right) \\wedge\\left(V_{\\text {set }} \\cap v=\\emptyset\\right)\\right]+\\mathbb{1}\\left[v \\in \\mathcal{P}_{\\perp}^{*}\\right]\\right)\n$$\n\nFinally, we define\n\n$$\nM_{4}\\left(\\mathcal{A}^{t}\\right) \\doteqdot \\prod_{v \\in V_{P}}\\left(\\min \\left\\{30 k \\Delta|P|^{2 \\theta-1}, 1\\right\\} \\cdot \\mathbb{1}\\left[\\left(v \\notin \\mathcal{P}_{\\perp} \\backslash \\mathcal{P}_{\\perp}^{*}\\right) \\wedge\\left(V_{\\text {set }} \\cap v=\\emptyset\\right)\\right]+\\mathbb{1}\\left[v \\in \\mathcal{P}_{\\perp} \\backslash \\mathcal{P}_{\\perp}^{*}\\right]\\right)\n$$\n\nFor each $C \\in \\mathcal{C}_{s}$, define\n\n$$\nM_{5}\\left(\\mathcal{A}^{t}\\right) \\doteqdot \\prod_{C \\in s / \\mathcal{C}_{s}} \\mathbb{P}_{\\Phi_{1}}[\\neg C] \\cdot \\mathbb{1}[\\text { the involved permutation sets not in } \\mathcal{P}_{\\perp}]\n$$\n\nCombining all these random variables, let\n\n$$\nM\\left(\\mathcal{A}^{t}\\right)=\\prod_{|P|>\\gamma: V_{C} \\cap \\mathcal{P}_{\\theta}[P] \\neq \\emptyset}\\left(M_{1}\\left(\\mathcal{A}^{t}, P\\right)+M_{2}\\left(\\mathcal{A}^{t}, P\\right)\\right) \\cdot M_{3}\\left(\\mathcal{A}^{t}\\right) \\cdot M_{4}\\left(\\mathcal{A}^{t}\\right) \\cdot M_{5}\\left(\\mathcal{A}^{t}\\right)\n$$\n\nOne can verify that the random variable $\\mathcal{M}$ is a supermartingale by the implementation of Algorithm 8.\nLemma D.15. For each $t \\geq 1$, we have $\\mathrm{E}\\left[M\\left(\\mathcal{A}^{t}\\right)\\right] \\leq \\mathcal{A}^{t-1}$.\nThe following inequality is used in the analysis.\nLemma D.16. Given integers $q>3 b \\geq 8, t>0$, and $\\Delta>0$, where $t \\leq q /(e b)-q \\ln q /\\left(e b^{2} \\Delta\\right)$, we have\n\n$$\n\\prod_{i=t}^{\\lfloor q / b\\rfloor}\\left(1-\\frac{4 b \\Delta}{i}\\right) \\leq q^{-4}\n$$\n\nProof. Let $r=\\lfloor q / b\\rfloor$. We have\n\n$$\n\\prod_{i=t}^{r}\\left(1-\\frac{4 b \\Delta}{i}\\right) \\leq \\prod_{i=t}^{r}\\left(1-\\frac{1}{i}\\right)^{4 b \\Delta} \\leq \\prod_{i=t}^{r} \\exp \\left(-\\frac{4 b \\Delta}{i}\\right)=\\exp \\left(-\\sum_{i=t}^{r} \\frac{4 b \\Delta}{i}\\right)\n$$\n\nwhere the second inequality holds by $1-x \\leq \\exp (-x)$ for any $x \\in \\mathbb{R}$. Moreover, let $H_{n}$ denote $\\sum_{i=1}^{n} \\frac{1}{i}$. We have\n\n$$\n\\sum_{i=t}^{r} \\frac{1}{i}=H_{r}-H_{t} \\geq \\ln (r+1)-\\ln t-1\n$$\n\nwhere the last inequality is by that\n\n$$\n\\ln (n+1) \\leq H_{n}=\\sum_{i=1}^{n} \\frac{1}{i} \\leq \\ln n+1\n$$\n\nCombining with (110), we have\n\n$$\n\\prod_{i=t}^{r}\\left(1-\\frac{4 b \\Delta}{i}\\right) \\leq \\exp \\left(-\\sum_{i=t}^{r} \\frac{4 b \\Delta}{i}\\right) \\leq\\left(\\frac{e t}{r+1}\\right)^{4 b \\Delta} \\leq\\left(\\frac{e b t}{q}\\right)^{4 b \\Delta}\n$$\n\nIn addition, by\n\n$$\nt \\leq \\frac{q}{e b}-\\frac{q \\ln q}{e b^{2} \\Delta}\n$$\n\nwe have\n\n$$\n\\left(\\frac{e b t}{q}\\right)^{4 b \\Delta} \\leq\\left(1-\\frac{\\ln q}{b \\Delta}\\right)^{4 b \\Delta} \\leq \\exp \\left(-\\frac{4 b \\Delta \\ln q}{b \\Delta}\\right)=q^{-4}\n$$\n\nwhere the second inequality holds by $1-x \\leq \\exp (-x)$ for any $x \\in \\mathbb{R}$. Combining with (111), the lemma is proved.\n\nWe are now ready to complete the proof of Lemma 8.22.\nProof of Lemma 8.22. According to Lemma D.15, it holds that\n\n$$\n\\begin{aligned}\n& \\mathrm{E}\\left[M\\left(\\mathcal{A}^{t}\\right)\\right] \\leq M\\left(\\mathcal{A}^{0}\\right) \\\\\n\\leq & p^{\\left(t-\\left|V_{P}\\right|-\\left|V_{C}\\right|\\right)} \\cdot \\prod_{v \\in V_{P}} \\lambda_{1}(v) \\prod_{v \\in V_{C}}\\left(15 \\Delta|P|^{2 \\theta-1}+\\prod_{i=1}^{\\ell(P)}\\left(\\max \\left\\{1-4 \\Delta|P|^{\\theta} /(\\ell+1-i), 0\\right\\}\\right)^{-1}\\right) \\\\\n\\leq & p^{\\left(t-\\left|V_{P}\\right|-\\left|V_{C}\\right|\\right)} \\cdot \\prod_{v \\in V_{P}} \\lambda_{1}(v) \\prod_{v \\in V_{C}}(15 \\Delta|P|^{2 \\theta-1}+|P|^{-4}) \\\\\n\\leq & p^{\\left(t-\\left|V_{P}\\right|-\\left|V_{C}\\right|\\right)} \\cdot \\prod_{v \\in V_{P}} \\lambda_{1}(v) \\prod_{v \\in V_{C}} \\lambda_{2}(v)\n\\end{aligned}\n$$\n\nwhere the second inequality follows from Lemma D.16.\nBy definition, for any $P \\in \\mathcal{P}^{\\dagger}$ such that $|P|>\\gamma$ and $V_{C} \\cap \\mathcal{P}_{\\theta}[P] \\neq \\emptyset$, we have\n\n$$\nM_{1}\\left(\\mathcal{A}^{t}, P\\right)+M_{2}\\left(\\mathcal{A}^{t}, P\\right) \\geq 1\n$$\n\nThus, for any w.s. $s=\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$, if $s$ occurs, one can verify that\n\n$$\nM\\left(\\mathcal{A}_{\\infty}\\right) \\geq p^{\\theta \\cdot\\left(t-\\left|V_{P}\\right|-\\left|V_{C}\\right|\\right)}\n$$\n\nCombining (112), (113) and Markov's inequality, we have\n\n$$\n\\begin{aligned}\n\\operatorname{Pr}\\left[\\left(v_{0}, \\cdots, v_{t}\\right) \\text { occurs }\\right] & \\leq \\operatorname{Pr}\\left[v_{0} \\in \\mathcal{P}_{0}\\right] \\cdot \\frac{\\mathrm{E}\\left[M\\left(\\mathcal{A}_{\\infty}\\right)\\right]}{p^{\\beta \\cdot\\left(t-\\left|V_{P}\\right|-\\left|V_{C}\\right|\\right)}} \\\\\n& \\leq p^{(1-\\theta)\\left(t-\\left|V_{P}\\right|-\\left|V_{C}\\right|\\right)} \\cdot \\operatorname{Pr}\\left[v_{0} \\in \\mathcal{P}_{0}\\right] \\prod_{v \\in V_{P}} \\lambda_{1}(v) \\prod_{v \\in V_{C}} \\lambda_{2}(v)\n\\end{aligned}\n$$\n\nwhich implies the lemma immediately.\nD.4.4. Refutation of long witness. In this section, we complete the proofs of Lemmas 8.24 and 8.25.\n\nWitness sequence and suffix. Define the set of suffices of a w.s. as follows.\nDefinition D. 17 (suffix of witness sequence). Let $\\mathcal{T}$ be $\\mathcal{W}$ or $\\bigcup_{P \\in \\mathcal{R}, P^{\\prime} \\in \\mathcal{D}[P]} \\mathcal{W}\\left[P, P^{\\prime}\\right]$. Given a w.s. $\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ where $t \\geq 0$, define\n\n$$\n\\begin{aligned}\n& \\operatorname{suf}\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right) \\doteq\\left\\{\\left(v_{0}, v_{1}, \\cdots, v_{t}, \\cdots, v_{t^{\\prime}}\\right) \\in \\mathcal{T} \\mid t^{\\prime}>t\\right\\} \\\\\n& \\operatorname{suf}_{1}\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right) \\doteq\\left\\{\\left(v_{0}, v_{1}, \\cdots, v_{t}, v_{t+1}\\right) \\in \\mathcal{T} \\mid v_{t+1} \\in V_{P}\\right\\} \\\\\n& \\operatorname{suf}_{2}\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right) \\doteq\\left\\{\\left(v_{0}, v_{1}, \\cdots, v_{t}, v_{t+1}\\right) \\in \\mathcal{T} \\mid v_{t+1} \\notin V_{P}\\right\\}\n\\end{aligned}\n$$\n\nWe remark that $\\operatorname{suf}_{1}(s)=\\emptyset$ for some $s \\in \\mathcal{T}$. Moreover, for each w.s. $s$ and $i \\in[2]$, let $\\operatorname{suf}_{i}^{*}(s) \\doteq$ $\\operatorname{suf}_{i}(s) \\cup\\{s\\}$. Similarly, let $\\operatorname{suf}^{*}(s) \\doteq \\operatorname{suf}(s) \\cup\\{s\\}$. Given any $s \\in \\mathcal{T}$, define\n\n$$\n\\widehat{\\beta}(s) \\doteq \\sum_{s^{\\prime} \\in \\operatorname{suff}^{*}(s)} \\rho\\left(s^{\\prime}\\right) \\cdot \\widehat{f}\\left(s^{\\prime}\\right), \\quad \\beta(s) \\doteq \\sum_{s^{\\prime} \\in \\operatorname{suff}^{*}(s)} \\rho\\left(s^{\\prime}\\right) \\cdot f\\left(s^{\\prime}\\right)\n$$\n\nThis subsection is devoted to prove the following lemma.\nLemma D.18. Consider the instance with $p, \\eta, \\Delta$ satisfying Condition 8.23. For any w.s. $s=$ $\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ where $t \\geq 1$ and $v_{t} \\notin V_{P}$, we have $\\widehat{\\beta}(s) \\leq \\rho\\left(v_{0}, v_{1}, \\cdots, v_{t-1}\\right)$.\n\nWe only prove Lemma D. 18 for the case\n\n$$\n\\mathcal{T}=\\bigcup_{P \\in \\mathcal{R}, P^{\\prime} \\in \\mathcal{D}[P]} \\mathcal{W}\\left[P, P^{\\prime}\\right]\n$$\n\nThe case $\\mathcal{T}=\\mathcal{W}$ can be proved similarly. In the following subsection, we always assume (115). Recall that $\\mathcal{P}_{\\theta}, \\mathcal{C}_{s}, \\mathcal{E}_{P}, S(\\cdot, \\cdot, \\cdot)$ and $\\mathcal{S}^{*}(\\cdot, \\cdot, \\cdot)$ are dependent on $\\mathcal{L}$. However, given any w.s. $\\left(v_{0}, \\cdots, v_{t}\\right) \\in \\mathcal{T}$, one can use these notations without specifying $\\mathcal{L}$, because $\\mathcal{L}$ is fixed by $v_{t} \\subseteq \\mathcal{L}$.\n\nBy Definition D.17, we have the following lemma.\nLemma D.19. For any $s=\\left(v_{0}, \\cdots, v_{t}\\right) \\in \\mathcal{T}$ where $t \\geq 1$, if $v_{t} \\in \\mathcal{C}_{s}$, we have\n\n$$\n\\widehat{\\beta}(s) \\leq \\rho(s) \\cdot \\widehat{f}(s)+\\sum_{s^{\\prime} \\in \\operatorname{suff}_{2}(s)} \\widehat{\\beta}\\left(s^{\\prime}\\right)\n$$\n\nif $v_{t} \\in \\mathcal{P}_{\\theta}$, we have\n\n$$\n\\widehat{\\beta}(s) \\leq \\sum_{s^{\\prime} \\in \\operatorname{suff}_{1}^{*}(s)}\\left(\\rho\\left(s^{\\prime}\\right) \\cdot \\widehat{f}\\left(s^{\\prime}\\right)+\\sum_{s^{\\prime \\prime} \\in \\operatorname{suff}_{2}\\left(s^{\\prime}\\right)} \\widehat{\\beta}\\left(s^{\\prime \\prime}\\right)\\right)\n$$\n\nProof. We only prove (117) here. The proof of (116) is similar. Given any $s=\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ where $t \\geq 1$, the following are all possibilities for the sequences in $\\omega \\in \\operatorname{suf}(s)$ :\n\n- Either there is a $v_{t+1}$ satisfying $\\left(v_{t}, v_{t+1}\\right) \\in \\mathcal{E}_{P}$ or not. If there is such a $v_{t+1}$, let $x=v_{t+1}$, otherwise, let $x=v_{t}$. By letting $s^{\\prime}=\\left(v_{0}, v_{1}, \\cdots, x\\right)$, we have $s^{\\prime} \\in \\operatorname{suff}_{1}^{*}(s)$.\n- Either $x$ has a next vertex in $\\omega$ or not. If there is no such a vertex, we have $\\rho(\\omega) f(\\omega)=\\rho\\left(s^{\\prime}\\right) f\\left(s^{\\prime}\\right)$. Otherwise, $x$ has a next vertex $\\tau$ in $\\omega$. If $x=v_{t}$, we have $\\left(v_{t}, v_{t+1}\\right) \\notin \\mathcal{E}_{P}$. Thus, $(x, \\tau)=\\left(v_{t}, v_{t+1}\\right) \\notin$ $\\mathcal{E}_{P}$. Otherwise, $x=v_{t+1}$. By $\\left(v_{t}, v_{t+1}\\right) \\in \\mathcal{E}_{P}$ and $\\left(v_{t}, v_{t+2}\\right) \\notin \\mathcal{E}_{P}$ due to Definition 8.15 , we have $(x, \\tau)=\\left(v_{t+1}, v_{t+2}\\right) \\in \\mathcal{E}_{P}$. In summary, we always have $(x, \\tau) \\notin \\mathcal{E}_{P}$. Let $s^{\\prime \\prime}=\\left(v_{0}, v_{1}, \\cdots, x, \\tau\\right)$. By $(x, \\tau) \\notin \\mathcal{E}_{P}$, we have $\\tau \\notin V_{P}$. Thus, $s^{\\prime \\prime} \\in \\operatorname{suff}_{2}\\left(s^{\\prime}\\right)$. Therefore,\n\n$$\n\\sum_{\\omega \\in \\operatorname{suff}^{*}\\left(s^{\\prime \\prime}\\right)} \\rho(\\omega) \\cdot \\widehat{f}(\\omega)=\\widehat{\\beta}\\left(s^{\\prime \\prime}\\right)\n$$\n\nCombining with Definition D.17, (117) is immediate.\nRecall the definitions of $\\mathcal{S}(\\cdot, \\cdot, \\cdot)$ and $\\mathcal{S}^{*}(\\cdot, \\cdot, \\cdot)$ in Definition 8.14. Given any $P^{\\prime} \\in \\mathcal{P}$, set $T$ and integer $i>0$, define\n\n$$\n\\mathcal{S}_{P^{\\prime}}(P, T, i)=\\left\\{\\begin{array}{ll}\n\\mathcal{S}(\\{P\\}, T, i) & \\text { if } P \\in \\mathcal{P}_{\\theta}, T \\subseteq \\mathcal{P}_{\\theta} \\cup \\mathcal{C}_{s} \\text { under } \\mathcal{L}=\\mathcal{P}^{\\prime} \\\\\n\\emptyset & \\text { otherwise. }\n\\end{array}\\right.\n$$\n\nDefine $\\mathcal{S}_{P^{\\prime}}^{*}(P, T, i), \\mathcal{S}_{P^{\\prime}}(C, T, i)$ and $\\mathcal{S}_{P^{\\prime}}^{*}(C, T, i)$ similarly. We will omit $P^{\\prime}$ from these notations if $P^{\\prime}$ is clear from the context. The following lemma is used in the proof of Lemma D.18. Its proof is immediate by the definition of $\\mathcal{S}(\\cdot, \\cdot, \\cdot)$ and $\\mathcal{S}^{*}(\\cdot, \\cdot, \\cdot)$.\nLemma D.20. For any $P^{\\prime} \\in \\mathcal{P}, P, C$, and integer $i>0$, we have\n\n$$\n\\left|\\bigcup_{P^{\\prime} \\in \\mathcal{R}} \\mathcal{S}_{P^{\\prime}}\\left(P, \\mathcal{P}_{\\theta}, i\\right)\\right| \\leq|P|(2 d k)^{i} \\gamma^{(i-1) \\theta}, \\quad\\left|\\bigcup_{P^{\\prime} \\in \\mathcal{R}} \\mathcal{S}_{P^{\\prime}}\\left(P, \\mathcal{C}_{s}, i\\right)\\right| \\leq|P| d^{i+1}(2 k)^{i} \\gamma^{i \\theta}\n$$\n\nTherefore,\n\n$$\n\\left|\\bigcup_{P^{\\prime} \\in \\mathcal{R}} \\mathcal{S}_{P^{\\prime}}^{*}\\left(P, \\mathcal{P}_{\\theta}, i\\right)\\right| \\leq i|P|(2 d k)^{i} \\gamma^{(i-1) \\theta}, \\quad\\left|\\bigcup_{P^{\\prime} \\in \\mathcal{R}} \\mathcal{S}_{P^{\\prime}}^{*}\\left(P, \\mathcal{C}_{s}, i\\right)\\right| \\leq i|P| d^{i+1}(2 k)^{i} \\gamma^{i \\theta}\n$$\n\nProof. We only prove the conclusion about $\\mathcal{S}_{P^{\\prime}}\\left(P, \\mathcal{P}_{\\theta}, i\\right)$ here. The proofs for other conclusions are similarly. Consider the propagation trajectory $\\left(u=P, v_{1}, \\cdots, v_{i+1}=P^{*}\\right)$ where $P^{*} \\in \\mathcal{P}_{\\theta}$. By Definition 8.14, we have $v_{1} \\in \\mathcal{C}(P),\\left(v_{j}, v_{j+1}\\right) \\in \\mathcal{E}_{C}$ for each $j \\in[i-1]$, and $v_{i} \\cap \\mathcal{C}\\left(P^{*}\\right)$. By $v_{1} \\in \\mathcal{C}(P)$, we have there are at most $d|P|$ choices for $v_{1}$. For any fixed $v_{j}$ where $j \\in[i-1]$, by $\\left(v_{j}, v_{j+1}\\right) \\in \\mathcal{E}_{C}$, we have there are at most $2 d k \\gamma^{\\theta}$ choice for $v_{j+1}$. Because the edge $v_{j}$ has at most $k$ variables. Each variable can determine one permutation set in $\\mathcal{D}$ and another permutation set in $\\mathcal{D}^{\\prime}$. If this permutation set is in $\\mathcal{Z}$, it can connect to at most $d \\gamma^{\\theta}$ edges. For any fixed $v_{i}$, by $v_{i} \\in \\mathcal{C}\\left(P^{*}\\right)$, we have there are at most $2 k$ choice for $P^{*}$, because $P^{*}$ can be chosen from either $\\mathcal{D}$ and $\\mathcal{D}^{\\prime}$. Thus, the conclusion about $\\mathcal{S}_{P^{*}}\\left(P, \\mathcal{P}_{\\theta}, i\\right)$ is immediate. The lemma is proved.\n\nWe have the following corollary by Lemma D.20. One can verify that it also holds for $\\mathcal{T}=\\mathcal{W}$.\nCorollary D.21. Given any w.s. $s=\\left(v_{0}, \\cdots, v_{t}\\right)$ where $t \\geq 0, v_{t} \\in \\mathcal{P}_{\\theta}$ and $s^{\\prime} \\in \\operatorname{suf}_{1}^{+}(s)$ we have\n\n$$\n\\left|\\operatorname{suf}_{2}(s)\\right| \\leq 20\\left|v_{t}\\right| d^{3} k^{2} \\gamma^{2 \\theta}, \\quad\\left|\\operatorname{suf}_{2}\\left(s^{\\prime}\\right)\\right|<_{q} 20\\left|v_{t}\\right| d^{3} k^{2} \\gamma^{2 \\theta}\n$$\n\nIn addition, if $v_{t} \\in \\mathcal{Z}$, we have\n\n$$\n\\left|\\operatorname{suf}_{2}(s)\\right| \\leq 20 d^{3} k^{2} \\gamma^{3 \\theta}\n$$\n\nProof. We only prove the upper bound of $\\left|\\operatorname{suf}_{2}\\left(s^{\\prime}\\right)\\right|$ when $v_{t} \\in \\mathcal{P}_{\\theta}$, the proofs for other cases are similar. Given any $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t-1}, v_{t}\\right) \\in \\operatorname{suf}_{1}^{+}(s)$ where $\\ell=t$ or $t+1$, consider the w.s. $s^{\\prime \\prime}=$ $\\left(v_{0}, \\cdots, v_{t}, v_{t+1}\\right) \\in \\operatorname{suf}_{2}\\left(s^{\\prime}\\right)$. By $s^{\\prime \\prime} \\in \\operatorname{suf}_{2}\\left(s^{\\prime}\\right)$, we have $v_{t+1} \\notin V_{P}$. Combined with Definition 8.15, we have $\\left(v_{t}, v_{t+1}\\right) \\in \\mathcal{S}^{*}\\left(v_{t}, \\mathcal{P}_{\\theta}, 2\\right)$ for each $v_{t+1} \\in \\mathcal{P}_{\\theta}$ and $\\left(v_{t}, v_{t+1}\\right) \\in \\mathcal{S}^{*}\\left(v_{t}, \\mathcal{C}_{s}, 2\\right)$ for each $v_{t+1} \\in \\mathcal{C}_{s}$. Combining with Lemma D.20, we have\n\n$$\n\\left|\\operatorname{suf}_{2}\\left(s^{\\prime}\\right)\\right| \\leq\\left|\\bigcup_{P^{\\prime} \\in \\mathcal{R}} \\mathcal{S}_{P^{\\prime}}^{*}\\left(v_{t}, \\mathcal{P}_{\\theta}, 2\\right)\\right|+\\left|\\bigcup_{P^{\\prime} \\in \\mathcal{R}} \\mathcal{S}_{P^{\\prime}}^{*}\\left(v_{t}, \\mathcal{C}_{s}, 2\\right)\\right| \\leq 2\\left|v_{t}\\right|(2 d k)^{2} \\gamma^{\\theta}+3\\left|v_{t}\\right| d^{3}(2 k)^{2} \\gamma^{2 \\theta}\n$$\n\nMoreover, by $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t-1}, v_{t}\\right) \\in \\operatorname{suf}_{1}^{+}(s)$ where $\\ell=t$ or $t+1$, we have either $v_{\\ell}=v_{t}$ or $v_{\\ell}=v_{t+1}$ and $\\left(v_{t}, v_{t+1}\\right) \\in \\mathcal{E}_{P}$. Thus, $\\left|v_{t}\\right|=_{q}\\left|v_{t}\\right|$. We have $\\left|\\operatorname{suf}_{2}\\left(s^{\\prime}\\right)\\right|<_{q} 20\\left|v_{t}\\right| d^{3} k^{2} \\gamma^{2 \\theta}$. The lemma is immediate.\n\nNow we can prove Lemma D. 18 .\nProof of Lemma D.18. We prove this lemma by structural induction. For any $s=\\left(v_{1}, v_{2}, \\cdots, v_{t}\\right) \\in \\mathcal{T}$, by Definition 8.15, we have $v_{i} \\in \\mathcal{P}_{\\theta} \\cup \\mathcal{C}_{s}$ and $v_{i} \\neq v_{j}$ for any different $i, j \\in[t]$. Thus, the possible choices of $v_{i}$ is bounded and $t$ is also bounded. We have $|\\mathcal{T}|$ is also bounded. Therefore, for any $s \\in \\mathcal{T}$, either $\\operatorname{suf}(s)=\\emptyset$ or there exists some $s^{\\prime} \\in \\operatorname{suf}(s)$ where $\\operatorname{suf}\\left(s^{\\prime}\\right)=\\emptyset$. Given any $s=\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right) \\in \\mathcal{T}$ where $t \\geq 1$ and $v_{t} \\notin V_{P}$, We first show that $\\widehat{\\beta}(s) \\leq \\rho\\left(v_{1}, v_{2}, \\cdots, v_{t-1}\\right)$ for any $s$ where $\\operatorname{suf}(s)=\\emptyset$. By $v_{t} \\notin V_{P}$,\n\nwe have either $v_{t} \\in V_{C}$ or $v_{t} \\in \\mathcal{C}_{s}$. By (114) and $\\operatorname{suf}(s)=\\emptyset$, we have $\\widehat{\\beta}(s)=\\rho(s) \\cdot \\widehat{f}(s)$. In the following, we show $\\widehat{\\beta}(s) \\leq \\rho\\left(v_{1}, v_{2}, \\cdots, v_{t-1}\\right)$ for two different cases.\nCase I: $v_{t} \\in V_{C}$. We have\n\n$$\n\\begin{aligned}\n\\widehat{\\beta}(s) & =\\rho(s) \\cdot \\widehat{f}(s) \\leq \\rho\\left(v_{0}, \\cdots, v_{t-1}\\right) \\cdot \\lambda_{2}\\left(v_{t}\\right) \\cdot \\widehat{f}(s) \\\\\n& =\\lambda_{2}\\left(v_{t}\\right)\\left|v_{t}\\right| \\zeta \\rho\\left(v_{0}, \\cdots, v_{t-1}\\right) \\leq \\rho\\left(v_{0}, \\cdots, v_{t-1}\\right)\n\\end{aligned}\n$$\n\nwhere the last inequality holds by (1) and (2) in Condition 8.23.\nCase II: $v_{t} \\in \\mathcal{C}_{s}$. We have\n\n$$\n\\begin{aligned}\n\\widehat{\\beta}(s) & =\\rho(s) \\cdot \\widehat{f}(s) \\leq \\rho\\left(v_{0}, \\cdots, v_{t-1}\\right) \\cdot p^{1-\\theta} \\cdot \\widehat{f}(s) \\\\\n& \\leq \\rho\\left(v_{0}, \\cdots, v_{t-1}\\right) \\cdot p^{1-\\theta} \\gamma^{\\theta} \\zeta \\leq \\rho\\left(v_{0}, \\cdots, v_{t-1}\\right)\n\\end{aligned}\n$$\n\nwhere the last inequality holds by (4) in Condition 8.23 .\nFor the induction step, given any w.s. $s=\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ where $t \\geq 1$ and $v_{t} \\notin V_{P}$, we assume that $\\widehat{\\beta}\\left(s^{\\prime}\\right) \\leq \\rho\\left(v_{0}, v_{1}, \\cdots, v_{t-1}\\right)$ for each $s^{\\prime}=\\left(v_{0}, v_{1}, \\cdots, v_{t}\\right)$ where $s^{\\prime} \\in \\operatorname{suf}(s)$ and $v_{t} \\notin V_{P}$. Similar to the base case, we prove the claim for induction cases by discussing the component $v_{t}$ respectively.\nCase I: $v_{t} \\in V_{C}$. Assume $s=\\left(v_{0}, \\cdots, v_{t}\\right)$. For any $s^{\\prime}=\\left(v_{0}, \\cdots, v_{t}, v_{t+1}\\right) \\in \\operatorname{suff}_{1}(s)$, we have $v_{t+1} \\in V_{P}$. Thus, $\\left(v_{t}, v_{t+1}\\right) \\in \\mathcal{E}_{P}$. Let $P_{1} \\in \\mathcal{P}, P_{2} \\in \\mathcal{P}^{\\prime}$ satisfy $v_{t} \\subseteq P_{2} \\subseteq P_{1}$. If $P_{1}^{\\theta}=_{q}\\left|v_{t}\\right|$, we have $v_{t} \\in \\mathcal{D}$. Thus $v_{t+1}$ is also in $\\mathcal{D}$. Therefore, there are at most $P_{1}^{1-\\theta}=_{q}\\left|v_{t}\\right|^{1 / \\theta-1}$ choices for $v_{t+1}$ for fixed $v_{t}$. Otherwise, $P_{2}^{\\theta}=_{q}\\left|v_{t}\\right|$, we have $v_{t} \\in \\mathcal{D}^{\\prime}$. Thus $v_{t+1}$ is also in $\\mathcal{D}^{\\prime}$. Therefore, there are at most $P_{2}^{1-\\theta}=_{q}\\left|v_{t}\\right|^{1 / \\theta-1}$ choices for $v_{t+1}$ for fixed $v_{t}$. In summary, we always have\n\n$$\n\\left|\\left\\{v_{t+1} \\mid\\left(v_{t}, v_{t+1}\\right) \\in \\mathcal{E}_{P}\\right\\}\\right|<_{q}\\left|v_{t}\\right|^{1 / \\theta-1}\n$$\n\nThus, we have\n\n$$\n\\left|\\operatorname{suff}_{1}(s)\\right| \\leq\\left|v_{t}\\right|^{1 / \\theta-1}\n$$\n\nMoreover, by (45) we have\n\n$$\n\\rho\\left(s^{\\prime}\\right)=\\rho(s) \\cdot \\lambda_{1}\\left(v_{t+1}\\right)=\\rho(s) \\cdot \\lambda_{1}\\left(v_{t}\\right)\n$$\n\nThus, we have\n\n$$\n\\sum_{s^{\\prime} \\in \\operatorname{suff}_{1}^{\\prime}(s)} \\rho\\left(s^{\\prime}\\right) \\leq \\rho(s)+\\sum_{s^{\\prime} \\in \\operatorname{suff}_{1}(s)} \\rho(s) \\cdot \\lambda_{1}\\left(v_{t}\\right) \\leq \\rho(s)\\left(1+\\left|v_{t}\\right|^{1 / \\theta-1} \\cdot \\lambda_{1}\\left(v_{t}\\right)\\right)\n$$\n\nTherefore, we have\n\n$$\n\\begin{aligned}\n\\widehat{\\beta}(s) & \\leq \\sum_{s^{\\prime} \\in \\operatorname{suff}_{1}^{\\prime}(s)}\\left(\\rho\\left(s^{\\prime}\\right) \\cdot \\widehat{f}\\left(s^{\\prime}\\right)+\\sum_{s^{\\prime \\prime} \\in \\operatorname{suff}_{2}\\left(s^{\\prime}\\right)} \\widehat{\\beta}\\left(s^{\\prime \\prime}\\right)\\right) \\\\\n& \\leq \\sum_{s^{\\prime} \\in \\operatorname{suff}_{1}^{\\prime}(s)}\\left(\\rho\\left(s^{\\prime}\\right) \\cdot \\widehat{f}\\left(s^{\\prime}\\right)+\\sum_{s^{\\prime \\prime} \\in \\operatorname{suff}_{2}\\left(s^{\\prime}\\right)} \\rho\\left(s^{\\prime}\\right)\\right) \\quad \\text { (by the inductive assumption) } \\\\\n& \\leq \\sum_{s^{\\prime} \\in \\operatorname{suff}_{2}^{\\prime}(s)}\\left(\\rho\\left(s^{\\prime}\\right) \\cdot\\left(\\left|v_{t}\\right| \\zeta+20\\left|v_{t}\\right| d^{3} k^{2} \\gamma^{2 \\theta}\\right)\\right) \\quad \\text { (by (41) and Corollary D.21) } \\\\\n& <_{q} \\sum_{s^{\\prime} \\in \\operatorname{suff}_{1}^{\\prime}(s)}\\left(2\\left|v_{t}\\right| \\zeta \\rho\\left(s^{\\prime}\\right)\\right) \\\\\n& <_{q} 2\\left|v_{t}\\right| \\zeta\\left(1+\\left|v_{t}\\right|^{1 / \\theta-1} \\lambda_{1}\\left(v_{t}\\right)\\right) \\rho(s) \\\\\n& <_{q} 2\\left|v_{t}\\right| \\zeta\\left(1+\\left|v_{t}\\right|^{1 / \\theta-1} \\lambda_{1}\\left(v_{t}\\right)\\right) \\lambda_{2}\\left(v_{t}\\right) \\rho\\left(\\left(v_{0}, \\cdots, v_{t-1}\\right)\\right) \\\\\n& \\leq \\rho\\left(v_{0}, \\cdots, v_{t-1}\\right) . \\quad \\text { (by (1), (2) in Condition 8.23) }\n\\end{aligned}\n$$\n\nCase II: $v_{t} \\in \\mathcal{C}_{s}$. We have\n\n$$\n\\begin{aligned}\n\\widehat{\\beta}(s) & \\leq \\rho(s) \\cdot \\widehat{f}(s)+\\sum_{s^{\\prime} \\in \\operatorname{uf}_{2}(s)} \\widehat{\\beta}\\left(s^{\\prime}\\right) \\\\\n& \\leq \\rho(s) \\cdot \\widehat{f}(s)+\\sum_{s^{\\prime} \\in \\operatorname{uf}_{2}(s)} \\rho(s) \\\\\n& \\leq \\rho(s) \\cdot\\left(\\gamma^{\\theta} \\zeta+20 d^{3} k^{2} \\gamma^{3 \\theta}\\right) \\\\\n& <_{q} \\rho\\left(v_{0}, \\cdots, v_{t-1}\\right) \\cdot 2 p^{1-\\theta} \\gamma^{\\theta} \\zeta \\\\\n& \\leq \\rho\\left(v_{0}, \\cdots, v_{t-1}\\right)\n\\end{aligned}\n$$\n\n(by (116))\nby the inductive assumption)\n(by (41) and Corollary D.21)\n(by (45))\n(by (43) in Condition 8.23)\n\nCombining the proofs for Cases I and II, the induction step is finished. The lemma is immediate.\nProofs of Lemmas 8.24 and 8.25. The following two lemmas are used in our proofs.\nLemma D.22. Assume $|\\mathcal{I}| \\leq \\gamma$. We have\n\n$$\n\\sum_{s \\in \\mathcal{W}} \\rho(s) \\cdot f(s) \\cdot \\mathbb{1}[|s|>1]<_{q}(300 \\Delta)^{-1} k d^{2} \\gamma^{\\theta}|\\mathcal{I}|^{\\theta} \\mathrm{E}\\left[\\left|\\mathcal{P}_{0}\\right|\\right]\n$$\n\nProof. By Definition 8.15, we have $v_{0} \\in \\mathcal{P}_{\\theta}[\\mathcal{I}]$ and $v_{1} \\notin V_{P}$. Combined with Definition D.17, we have $\\left(v_{0}, v_{1}\\right) \\in \\operatorname{uf}_{2}\\left(\\left(v_{0}\\right)\\right)$. Meanwhile, by $v_{0} \\in \\mathcal{P}_{\\theta}[\\mathcal{I}]$ and $|\\mathcal{I}|<\\gamma$, we have $v_{0} \\in \\mathcal{Z} \\subseteq \\mathcal{P}_{\\theta}$. Combined with Corollary D.21, we have $\\left|\\operatorname{uf}_{2}\\left(\\left(v_{0}\\right)\\right)\\right|<_{q} 20\\left|v_{0}\\right| d^{3} k^{2} \\gamma^{2 \\theta}$. Thus,\n\n$$\n\\left|\\left\\{v_{1} \\mid\\left(v_{0}, v_{1}\\right) \\in \\mathcal{W}\\right\\}\\right|=\\left|\\operatorname{uf}_{2}\\left(\\left(v_{0}\\right)\\right)\\right|<_{q} 20\\left|v_{0}\\right| d^{3} k^{2} \\gamma^{2 \\theta}\n$$\n\nThus, we have\n\n$$\n\\begin{aligned}\n\\sum_{s \\in \\mathcal{W}} \\rho(s) \\cdot f(s) \\cdot \\mathbb{1}[|s|>1] & =\\sum_{\\left(v_{0}, v_{1}\\right) \\in \\mathcal{W}} \\beta\\left(v_{0}, v_{1}\\right) \\\\\n& \\leq \\sum_{\\left(v_{0}, v_{1}\\right) \\in \\mathcal{W}} \\widehat{\\beta}\\left(v_{0}, v_{1}\\right) \\cdot k^{2} d^{2} \\gamma^{\\theta} / \\zeta \\quad \\text { (by Definition 8.20) } \\\\\n& \\leq \\sum_{\\left(v_{0}, v_{1}\\right) \\in \\mathcal{W}} \\rho\\left(\\left(v_{0}\\right)\\right) \\cdot k^{2} d^{2} \\gamma^{\\theta} / \\zeta \\quad \\text { (by } v_{1} \\notin V_{P} \\text { and Lemma D.18) } \\\\\n& \\leq \\sum_{\\left.v_{0} \\in \\mathcal{P}_{\\theta}[\\mathcal{I}]\\right.} \\rho\\left(\\left(v_{0}\\right)\\right) \\cdot 20\\left|v_{0}\\right| d^{3} k^{2} \\gamma^{2 \\theta} \\cdot k^{2} d^{2} \\gamma^{\\theta} / \\zeta \\\\\n& \\leq(300 \\Delta)^{-1} k d^{2} \\gamma^{\\theta} \\sum_{\\left.v_{0} \\in \\mathcal{P}_{\\theta}[\\mathcal{I}]\\right.} \\rho\\left(\\left(v_{0}\\right)\\right)|\\mathcal{I}|^{\\theta} \\\\\n& <_{q}(300 \\Delta)^{-1} k d^{2} \\gamma^{\\theta} \\sum_{\\left.v_{0} \\in \\mathcal{P}_{\\theta}[\\mathcal{I}]\\right.} \\operatorname{Pr}\\left[v_{0} \\in \\mathcal{P}_{0}\\right] \\cdot|\\mathcal{I}|^{\\theta} \\\\\n& =_{q}(300 \\Delta)^{-1} k d^{2} \\gamma^{\\theta}|\\mathcal{I}|^{\\theta} \\mathrm{E}\\left[\\left|\\mathcal{P}_{0}\\right|\\right]\n\\end{aligned}\n$$\n\nLemma D.23. Assume $|\\mathcal{I}|>\\gamma$. We have\n\n$$\n\\sum_{s \\in \\mathcal{W}} \\rho(s) f(s)<_{q} 2 k^{2} d^{2} \\gamma^{\\theta}|\\mathcal{I}|^{\\theta} \\mathrm{E}\\left[\\left|\\mathcal{P}_{0}\\right|\\right]\n$$\n\nThe following lemma is also used in the proof of Lemma D.23. Its proof is similar to that of Lemma D.19.\n\nLemma D.24. Assume $|\\mathcal{I}| \\geq \\gamma$. Let $T$ denote the set $\\{s \\in \\mathcal{W}| | s \\mid=1\\}$. Then\n\n$$\n\\sum_{s \\in \\mathcal{W}} \\rho(s) \\widehat{f}(s) \\leq \\sum_{s \\in T}\\left(\\rho(s) \\widehat{f}(s)+\\sum_{\\tau \\in \\operatorname{uf}_{2}(s)} \\widehat{\\beta}(\\tau)\\right)\n$$\n\nProof of Lemma D.23. Let $T$ denote the set $\\{s \\in \\mathcal{W}| | s \\mid=1\\}$. By Lemmas D. 24 and D.18, we have\n\n$$\n\\begin{aligned}\n\\sum_{s \\in \\mathcal{W}} \\rho(s) \\widehat{f}(s) & \\leq \\sum_{s \\in T}\\left(\\rho(s) \\widehat{f}(s)+\\sum_{\\tau \\in \\mathfrak{s u f}_{2}(s)} \\widehat{\\beta}(\\tau)\\right) \\leq \\sum_{s \\in T}\\left(\\rho(s) \\widehat{f}(s)+\\sum_{\\tau \\in \\mathfrak{s u f}_{2}(s)} \\rho(s)\\right) \\\\\n& =\\sum_{\\left(v_{0}\\right) \\in T}\\left(\\rho\\left(\\left(v_{0}\\right)\\right) \\widehat{f}\\left(\\left(v_{0}\\right)\\right)+\\sum_{\\tau \\in \\mathfrak{s u f}_{2}\\left(\\left(v_{0}\\right)\\right)} \\rho\\left(\\left(v_{0}\\right)\\right)\\right)\n\\end{aligned}\n$$\n\nIn addition, by (43) we have\n\n$$\n\\rho\\left(\\left(v_{0}\\right)\\right) \\widehat{f}\\left(\\left(v_{0}\\right)\\right) \\leq\\left|v_{0}\\right| \\zeta \\rho\\left(\\left(v_{0}\\right)\\right)\n$$\n\nMeanwhile, by Corollary D.21, we have\n\n$$\n\\sum_{\\tau \\in \\mathfrak{s u f}_{2}\\left(\\left(v_{0}\\right)\\right)} \\rho\\left(\\left(v_{0}\\right)\\right) \\leq 20\\left|v_{0}\\right| d^{3} k^{2} \\gamma^{2 \\theta} \\rho\\left(\\left(v_{0}\\right)\\right)\n$$\n\nCombining the above three inequalities with (41), we have\n\n$$\n\\sum_{s \\in \\mathcal{W}} \\rho(s) \\widehat{f}(s) \\leq \\sum_{\\left(v_{0}\\right) \\in T} 2\\left|v_{0}\\right| \\zeta \\rho\\left(\\left(v_{0}\\right)\\right)\n$$\n\nCombined with Definition 8.20, we have\n\n$$\n\\sum_{s \\in \\mathcal{W}} \\rho(s) f(s) \\leq \\sum_{\\left(v_{0}\\right) \\in T} 2\\left|v_{0}\\right| k^{2} d^{2} \\gamma^{\\theta} \\rho\\left(\\left(v_{0}\\right)\\right)\n$$\n\nCombined with (45), we have\n\n$$\n\\sum_{s \\in \\mathcal{W}} \\rho(s) f(s) \\leq 2 k^{2} d^{2} \\gamma^{\\theta} \\sum_{\\left(v_{0}\\right) \\in T}\\left|v_{0}\\right| \\rho\\left(\\left(v_{0}\\right)\\right) \\leq 2 k^{2} d^{2} \\gamma^{\\theta} \\sum_{\\left.v_{0} \\in \\mathcal{P}_{p} \\mid \\mathcal{I}\\right]}\\left|v_{0}\\right| \\operatorname{Pr}\\left[v_{0} \\in \\mathcal{P}_{0}\\right]<_{q} 2 k^{2} d^{2} \\gamma^{\\theta}|\\mathcal{I}|^{\\theta} \\mathrm{E}\\left[\\left|\\mathcal{P}_{0}\\right|\\right]\n$$\n\nThus, the lemma is immediate by above two inequalities.\nWe are now ready to complete the proof of Lemma 8.24.\nProof of Lemma 8.24. If $|\\mathcal{I}|<\\gamma$, by (42) and (45), we have\n\n$$\n\\begin{aligned}\n\\sum_{s \\in \\mathcal{W}} \\rho(s) \\cdot f(s) \\cdot \\mathbb{1}[|s|=1] & =\\sum_{\\left.v_{0} \\in \\mathcal{P}_{p} \\mid \\mathcal{I}\\right]} \\rho\\left(\\left(v_{0}\\right)\\right) \\cdot f\\left(v_{0}\\right)=\\sum_{\\left.v_{0} \\in \\mathcal{P}_{p} \\mid \\mathcal{I}\\right]} \\rho\\left(\\left(v_{0}\\right)\\right) \\cdot\\left|v_{0}\\right| k^{2} d^{2} \\gamma^{\\theta} \\\\\n& \\leq \\sum_{\\left.v_{0} \\in \\mathcal{P}_{p} \\mid \\mathcal{I}\\right]} \\rho\\left(\\left(v_{0}\\right)\\right) \\cdot|\\mathcal{I}|^{\\theta} k^{2} d^{2} \\gamma^{\\theta} \\leq|\\mathcal{I}|^{\\theta} k^{2} d^{2} \\gamma^{\\theta} \\cdot \\mathrm{E}\\left[\\left|\\mathcal{P}_{0}\\right|\\right]\n\\end{aligned}\n$$\n\nThus, we have\n\n$$\n\\begin{aligned}\n\\sum_{s \\in \\mathcal{W}} \\rho(s) \\cdot f(s)= & \\sum_{s \\in \\mathcal{W}} \\rho(s) \\cdot f(s) \\cdot \\mathbb{1}[|s|=1]+\\sum_{s \\in \\mathcal{W}} \\rho(s) \\cdot f(s) \\cdot \\mathbb{1}[|s| \\geq 1] \\\\\n& <_{q} 2 k^{2} d^{2} \\gamma^{\\theta}|\\mathcal{I}|^{\\theta} \\mathrm{E}\\left[\\left|\\mathcal{P}_{0}\\right|\\right]\n\\end{aligned}\n$$\n\nIf $|\\mathcal{I}| \\geq \\gamma$, by Lemma D. 23 we also have\n\n$$\n\\sum_{s \\in \\mathcal{W}} \\rho(s) f(s)<_{q} 2 k^{2} d^{2} \\gamma^{\\theta}|\\mathcal{I}|^{\\theta} \\mathrm{E}\\left[\\left|\\mathcal{P}_{0}\\right|\\right]\n$$\n\nTherefore, for any $\\mathcal{I}$ we have\n\n$$\n\\begin{aligned}\n\\sum_{s \\in \\mathcal{W}} \\rho(s) \\cdot f(s) & <_{q} 2 k^{2} d^{2} \\gamma^{\\theta}|\\mathcal{I}|^{\\theta} \\mathrm{E}\\left[\\left|\\mathcal{P}_{0}\\right|\\right] \\\\\n& <_{q} 2(18 k+2) k^{2} d^{2} \\gamma^{\\theta} \\Delta \\\\\n& <_{q} \\alpha\\left(500 k d \\Delta^{2}\\right)^{-1}\n\\end{aligned}\n$$\n\nThe lemma is proved.\nIn the next, we complete the proof of Lemma 8.25. Similar to Lemma D.22, one can also prove the following lemma.\n\nLemma D.25. We have\n\n$$\n\\sum_{P \\in \\mathcal{R}} \\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]} \\sum_{s \\in \\mathcal{W}\\left[P, P^{\\prime}\\right]} \\rho(s) f(s) \\mathbb{1}[|s|>1]<_{q}(300 \\Delta)^{-1} k d^{2} \\gamma^{\\theta}|\\mathcal{I}|^{\\theta} \\mathrm{E}\\left[\\left|\\mathcal{P}_{0}\\right|\\right]\n$$\n\nProof of Lemma 8.25. Given any $P \\in \\mathcal{R}, P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]$ and $s \\in \\mathcal{W}\\left[P, P^{\\prime}\\right]$, we have $|s| \\geq 1$. Because the first element $v_{0}$ in $s$ satisfies $v_{0} \\subseteq \\mathcal{I}$. Moreover, by $\\mathcal{R}=\\{P \\in \\mathcal{P} \\mid|P| \\leq \\alpha, \\mathcal{I} \\nsubseteq P\\}, P \\in \\mathcal{R}$ and $P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]$, we have $v_{0} \\neq P^{\\prime}$. Combining with $s \\in \\mathcal{W}\\left[P, P^{\\prime}\\right]$, we have $|s| \\geq 1$. Therefore, we have\n\n$$\n\\begin{aligned}\n\\sum_{P \\in \\mathcal{R}} \\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]} \\sum_{s \\in \\mathcal{W}\\left[P, P^{\\prime}\\right]} \\rho(s)\\left|P^{\\prime}\\right| & =\\sum_{P \\in \\mathcal{R}} \\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]} \\sum_{s \\in \\mathcal{W}\\left[P, P^{\\prime}\\right]} \\rho(s)\\left|P^{\\prime}\\right| \\mathbb{1}[|s|>1] \\\\\n& =\\sum_{P \\in \\mathcal{R}} \\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]} \\sum_{s \\in \\mathcal{W}\\left[P, P^{\\prime}\\right]} \\rho(s) f(s) \\mathbb{1}[|s|>1]\\left|P^{\\prime}\\right| / f(s) \\\\\n& \\leq \\sum_{P \\in \\mathcal{R}} \\sum_{P^{\\prime} \\in \\mathcal{P}^{\\prime}[P]} \\sum_{s \\in \\mathcal{W}\\left[P, P^{\\prime}\\right]} \\rho(s) f(s) \\mathbb{1}[|s|>1] /\\left(k^{2} d^{2} \\gamma^{\\theta}\\right) \\\\\n& \\leq(300 k \\Delta)^{-1}|\\mathcal{I}|^{\\theta} \\mathrm{E}\\left[\\left|\\mathcal{P}_{0}\\right|\\right] \\\\\n& <_{q}(300 k \\Delta)^{-1}(36 k+4) \\Delta \\quad \\text { (by Condition } 8.10 \\text { and Lemma 8.11) } \\\\\n& <_{q} \\frac{1}{5}\n\\end{aligned}\n$$\n\nThe lemma is immediate.", "tables": {}, "images": {}}, {"section_id": 19, "text": "# Appendix E. Missing Proofs in section 9 \n\nProof of Lemma 9.4. Given that the event $\\mathcal{B}_{C}$ occurs, let $G$ be the dependency graph, and $G^{\\prime}$ be the lopsidependency graph of formula $\\Phi_{C}=\\left(\\mathcal{P}_{C}, \\mathcal{Q}_{C}, \\mathcal{C}_{C}\\right)$, respectively. Note that both $G$ and $G^{\\prime}$ are the subgraph of $G_{\\phi}^{\\text {Lop }}$ and $G_{\\phi}^{\\text {dep }}\\left[P^{\\prime}\\right]$ respectively, and $G^{\\prime}$ is the subgraph of $G$. For any collection of constraints $S \\subseteq \\mathcal{C}$, let $\\Gamma_{\\text {dep }}^{+}(S)$ be the extended neighbors of $S$, i.e.,\n\n$$\n\\Gamma_{\\text {dep }}^{+}(S) \\doteq\\left\\{C \\in V\\left(G_{\\phi}^{\\text {dep }}\\left[P^{\\prime}\\right]\\right) \\mid C \\in S \\text { or there exists } C^{\\prime} \\in S \\text { such that }\\left\\{C, C^{\\prime}\\right\\} \\in E\\left(G_{\\phi}^{\\text {dep }}\\left[P^{\\prime}\\right]\\right)\\right\\}\n$$\n\nSimilarly, we can define the notation $\\Gamma_{\\text {Lop }}^{+}(S)$.\nGiven that $\\left|\\mathcal{C}_{C}\\right| \\geq \\Delta \\log (n / \\delta)$, we construct a collection of constraints $\\left\\{C_{1}, \\ldots, C_{t^{\\prime}}\\right\\}$ in a greedy way. We first initialize $T_{1}=\\{C\\}$ and then repeat the following operations: at the $i$-th step, select an arbitrary constraint $C_{i}$ in $\\mathcal{C}_{C} \\backslash \\Gamma_{\\text {dep }}^{+}\\left(T_{i-1}\\right)$ such that $\\operatorname{dist}_{\\left.G_{\\phi}^{\\text {dep }}\\left[P^{\\prime}\\right]}\\left(C_{i}, T_{i-1}\\right)=2$, and update $T_{i} \\leftarrow T_{i-1} \\cup\\left\\{C_{i}\\right\\}$. Let $t^{\\prime}$ be the step that $\\Gamma_{\\text {dep }}^{+}\\left(T_{t^{\\prime}}\\right)=\\mathcal{C}_{C}$. We can see that $T_{t^{\\prime}}=\\left\\{C, C_{1}, \\ldots, C_{t^{\\prime}}\\right\\}$ form a connected component in the power dependency graph $\\left(G_{\\phi}^{\\text {dep }}\\left[P^{\\prime}\\right]\\right)^{2}$. Moreover, $T_{t^{\\prime}}=\\left\\{C, C_{1}, \\ldots, C_{t^{\\prime}}\\right\\}$ is also an independent set in the $G_{\\phi}^{\\text {dep }}\\left[P^{\\prime}\\right]$, which also an independent set in lopsidependency graph $G_{\\phi}^{\\text {Lop }}$ immediately.\n\nWe again continue to construct a maximal independent set in the lopsidependency graph $G_{\\phi}^{\\text {Lop }}$ containing the constraints in $T_{t^{\\prime}}$ in a greedy way. Let $S_{1}=T_{t^{\\prime}}$ and repeat the following: at the $i$-th step, select an arbitrary constraint $C_{i}$ in $\\mathcal{C}_{C} \\backslash \\Gamma_{\\text {Lop }}^{+}\\left(S_{i-1}\\right)$, and update $S_{i} \\leftarrow S_{i-1} \\cup\\left\\{C_{i}\\right\\}$. Let $\\left\\{C_{1}, \\cdots, C_{t^{\\prime \\prime}}\\right\\}$ be the final set constructed, and $t^{\\prime} \\geq \\log (n / \\delta)$ due to its maximality. The proof is complete by selecting the subset containing $C$ in $\\left\\{C_{1}, \\cdots, C_{t^{\\prime \\prime}}\\right\\}$ with size $\\ell$.\n\nProof of Lemma 9.6. If all constraints in $\\mathcal{C}^{\\prime}$ are bad in $\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}_{t^{\\prime}}^{\\prime} \\mathcal{C}\\right)$, then for each constraint $C=\\left(v_{1} \\neq\\right.$ $\\left.c_{1}\\right) \\vee \\cdots \\vee\\left(v_{t} \\neq c_{t}\\right) \\in \\mathcal{C}^{\\prime}$, we have $c_{i} \\in \\mathcal{Q}_{t}^{\\prime}\\left(P^{\\prime}\\right)$ for each $i \\in[t]$ where $v_{i} \\in P^{\\prime} \\in \\mathcal{P}^{\\prime}$.\n\nEach time a permutation $P \\in \\mathcal{P}$ is resampled, let $\\left\\{P_{1}, P_{2}, \\cdots, P_{m}\\right\\} \\in \\mathcal{P}^{\\prime}[P]$ be the permutations contains some variables in $\\operatorname{vbl}(C)$ for $C \\in \\mathcal{C}^{\\prime}$ and $k_{i}$ be the number of those variables in $P_{i}$ for each $i \\in[m]$. W.L.O.G., we can always reorder these permutations such that $k_{1} \\geq k_{2} \\geq \\cdots \\geq k_{m} \\geq 1$. We first calculate the probability of the event that the forbidden values of the constraints $\\mathcal{C}^{\\prime}$ lie in the corresponding permutations, in the underlying distribution $\\mathbb{P}$. Sampling $P$ is equivalent to consecutively sampling $P_{1}, P_{2}, \\cdots, P_{m}$. Let $B_{i}$ be the event that when $P_{i}$ is sampled, the forbidden values of all\n\nconstraints $\\mathcal{C}^{\\prime}$ lie in $P_{i}$. It holds that\n\n$$\n\\mathbb{P}\\left[B_{i}\\right] \\leq \\frac{\\left|P_{i}\\right| \\frac{k_{i}}{\\left(|P|-\\left|P_{1}\\right|-\\cdots-\\left|P_{i-1}\\right|\\right) \\frac{k_{i}}{\\left|P\\right|}} \\leq\\left(\\frac{\\left|P_{i}\\right|}{|P|-\\left|P_{1}\\right|-\\cdots-\\left|P_{i-1}\\right|}\\right)^{k_{i}}\n$$\n\nExaming our algorithm carefully, the probability of the event $B_{i}$ in Algorithm 1 can be regarded as the deviation between the underlying distribution $\\mathbb{P}$. According to Lemma 5.4, we have $P_{\\Psi} \\leq \\min \\left\\{p_{q_{i}}^{\\eta}, 1 / L\\right\\}$ for any $\\Psi=\\left(\\mathcal{P}^{\\prime}, \\mathcal{Q}_{t}^{\\prime}, \\mathcal{C}\\right)$. By $8 e p_{\\phi}^{\\eta} \\Delta \\leq 1,8 \\mathrm{e} \\Delta \\leq L$, and Lemma D.3, we have\n\n$$\n\\operatorname{Pr}\\left[B_{i}\\right]<_{q} \\mathbb{P}\\left[B_{i}\\right] \\leq\\left(\\frac{\\left|P_{i}\\right|}{|P|-\\left|P_{1}\\right|-\\cdots-\\left|P_{i-1}\\right|}\\right)^{k_{i}}\n$$\n\nwhere $\\operatorname{Pr}\\left[\\cdot\\right]$ is the randomness in Algorithm 1.\nLet $k_{P} \\triangleq \\sum_{i=1}^{m} k_{i}$ be the number of forbidden values of $\\mathcal{C}^{\\prime}$ on $P$ and $m^{\\prime}=\\lfloor 0.999 m\\rfloor$. In our analysis, we only exploit the probability of the first $m^{\\prime}=\\lceil 0.999 m\\rceil$ terms because the last $\\lfloor 0.001 m\\rfloor$ terms are too large. Specifically, in the first $m^{\\prime}$ terms, the number of literals we exploit is $k_{P}^{\\prime} \\triangleq \\sum_{i=1}^{m^{\\prime}} k_{i} \\geq 0.999 k_{P}$ because $k_{1} \\geq k_{2} \\geq \\cdots \\geq k_{m}$, and the number of unused sub-permutations is at least $\\ell-\\lceil 0.001 m\\rceil \\geq\\lfloor 0.001 \\ell\\rfloor$ by the decomposition specified in Condition 6.1. Since $P_{1}, P_{2}, \\cdots P_{m}$ is evenly decomposed, each denominator $|P|-\\left|P_{1}\\right|-\\cdots-\\left|P_{i-1}\\right|>_{q}|P|$ for each $i \\in\\left[m^{\\prime}\\right]$. Moreover, we have $\\left|P_{i}\\right|<_{q}|P|^{\\eta}$. Therefore,\n\n$$\n\\begin{aligned}\n\\operatorname{Pr}\\left[\\int_{i=1}^{m} B_{i}\\right] & <_{q}\\left(\\frac{\\left|P_{1}\\right|}{|P|}\\right)^{k_{1}}\\left(\\frac{\\left|P_{2}\\right|}{|P|-\\left|P_{1}\\right|}\\right)^{k_{2}} \\cdots \\cdots\\left(\\frac{\\left|P_{m^{\\prime}}\\right|}{|P|-\\left|P_{1}\\right|-\\cdots-\\left|P_{m^{\\prime}-1}\\right|}\\right)^{k_{m^{\\prime}}} \\\\\n& <_{q}\\left(\\frac{|P|^{\\eta}}{|P|}\\right)^{k_{1}}\\left(\\frac{|P|^{\\eta}}{|P|}\\right)^{k_{2}} \\cdots \\cdots\\left(\\frac{|P|^{\\eta}}{|P|}\\right)^{k_{m^{\\prime}}} \\leq\\left(\\frac{|P|^{\\eta}}{|P|}\\right)^{0.999 k_{P}} \\leq \\mathbb{P}_{\\Phi}[-C]^{0.999(1-\\eta)}\n\\end{aligned}\n$$\n\nThe lemma follows immediately by applying the above bound to each constraint in $\\mathcal{C}^{\\prime}$.", "tables": {}, "images": {}}], "id": "2411.02750v2", "authors": ["Kun He", "Guoliang Qiu", "Xiaoming Sun"], "categories": ["cs.DS"], "abstract": "Sampling a random permutation with restricted positions, or equivalently\napproximating the permanent of a 0-1 matrix, is a fundamental problem in\ncomputer science, with several notable results achieved over the years.\nHowever, existing algorithms typically exhibit high computational complexity.\nAchieving the optimal running time remains elusive, even for nontrivial subsets\nof the problem. Furthermore, existing algorithms primarily focus on a {single}\npermutation, leaving many combinatorial problems involving {multiple}\nconstrained permutations unaddressed.\n  For a single permutation, we achieve the optimal running time $O(n^2)$ for\napproximating the permanent of a very dense $n \\times n$ 0-1 matrix, where each\nrow and column contains at most $\\sqrt{(n-2)/20}$ zeros. This result serves as\na fundamental building block in our sampling algorithm for multiple\npermutations.\n  We further introduce a general model called {permutations with disjunctive\nconstraints} (PDC) for handling multiple constrained permutations. We propose a\nnovel Markov chain-based algorithm for sampling nearly uniform solutions of PDC\nwithin a lopsided Lov{\\'a}sz Local Lemma (LLL) regime. For uniform PDC\nformulas, where all constraints are of the same width and all permutations are\nof the same size, our algorithm runs in nearly linear time with respect to the\nnumber of variables.\n  Previous approaches for sampling LLL relied on the variable model. In\ncontrast, the sampling problem of PDC encounters a fundamental challenge: the\nrandom variables within each permutation in the joint probability space are\n{not} mutually independent, leading to long-range correlations. To tackle this\nchallenge, we introduce a novel sampling framework called {correlated\nfactorization} and a new concept in the path coupling analysis, termed the\n{inactive vertex}.", "updated": "2025-04-04T01:59:19Z", "published": "2024-11-05T02:46:14Z"}