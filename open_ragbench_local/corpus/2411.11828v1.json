{"title": "Reinterpreting Delay and Procrastination", "sections": [{"section_id": 0, "text": "## Abstract\n\nI model a rational agent who spends resources between the current time and some fixed future deadline. Opportunities to spend resources arise randomly according to a Poisson process, and the quality of each opportunity follows a uniform distribution. The agent values their current resource stock at exactly the sum of expected utility from all future spending opportunities. Unlike in traditional discounted expected utility models, the agent exhibits correlation aversion, static (but not dynamic) preference reversals, and monotonicity with respect to payment timing. Connecting the agent's risk and time preference is intuitive, and doing so leads to a new model of procrastination where the agent misperceives their general attitude toward spending resources.\nJEL Codes: C61, D15, D81, D91", "tables": {}, "images": {}}, {"section_id": 1, "text": "## 1. Introduction\n\nDeadlines are ubiquitous. Projects have completion timelines; budgets expire; food goes bad. On a personal level, readers of this paper will be familiar with deadline pressure in any number of situations. My goal in writing this paper is to investigate how deadlines affect incentives, and I model a single rational agent who moves forward through time until they reach some fixed, known deadline $T$. I solve the problem how should the agent optimally spend resources when the timing and quality of allocation opportunities are uncertain. I take a broad view of what resources, spending, and quality mean in this context. If we model a budget, the agent literally spends money on goods, and higher quality means that a store or website has more items in stock when the agent visits. Perhaps the agent needs to eat several food items before they spoil, and quality of a spending opportunity represents how hungry the agent is in that moment. In all cases, quality can encompass the agent's mood or other subjective feeling toward the task at hand.\n\nWe imagine the agent has a resource stock $x$, and at any given time $t$, they encounter an opportunity to spend resources with probability $\\lambda d t$. Formally, spending opportunities follow a Poisson process with rate parameter $\\lambda$ on the interval $(-\\infty, T]$, and past time $T$, the agent never encounters another opportunity. Resources are valuable to the agent only to the extent that the agent can spend them, so the valuation for the resource stock comes from possible future opportunities and is null from $T$ onward. Whenever the agent reaches a spending opportunity, they first learn the quality $\\theta$ associated with the opportunity, which is uniform on $[0,1]$ and independent of other opportunities. Then the agent chooses $y$ resources to save, spends the remaining $x-y$ portion, and derives utility equal to $u(\\theta, x-y)$, where\n\n[^0]\n[^0]:    *University of Michigan, Department of Economics and Center for the Study of Complex Systems. Email: coko@umich.edu.\n\n$u$ is the agent's instantaneous utility function. Moving forward in time, the agent faces the same problem except with $y$ resources instead of $x$, so the agent's valuation of their resource stock solves a dynamic programming problem with $x$ and $t$ as the state variables. To avoid any confounding effects and to keep the model as simple as possible, I assume the agent simply adds together instantaneous utility from spending opportunities with no inherent time preference.\n\nThe assumptions of the previous paragraph lead to a solution with rich properties that can inform our understanding of deadlines and delay. A solution to the model is a saving rule $y(\\theta, t, x)$ that means the following: if the agent has $x$ resources at time $t$, and a spending opportunity arises with quality $\\theta$, the agent saves $y(\\theta, t, x)$ resources and spends $x-y(\\theta, t, x)$. We abreviate the spending rule to $y$ when the arguments are clear from context. Dual to $y$ is the agent's value function $V(t, x)$, which captures the expected sum of instantaneous utility from all future spending opportunities if the agent has $x$ resources at time $t$. Finding $y$ is equivalent to finding $V$, but as is typically the case in dynamic programming problems, $V$ is more tractable and will occupy more of our focus in this paper. As an example of solution properties, $V$ is decreasing in $t$, increasing in $x$, and concave in both arguments with negative cross-partial derivative. Properties of $V$ translate to properties of $y$, and for example, with all else being equal, the agent spends more at the next opportunity when it arrives later.\n\nDeadlines-This paper makes several contributions to the decision theory literature. First, I model deadlines in broad terms. I formalize deadline pressure and show explicitly how it arises from time and opportunity constraints, and a rational agent in my model will bow to deadline pressure by discounting the future more heavily near $T$. The agent becomes less selective about opportunity quality as they move forward in time because the agent tries to unload their resource stock before running out of opportunities at the deadline. For fixed $t$, higher $\\theta$ means higher spending, and the cutoff values of $\\theta$ that separate different outputs for $y$ are decreasing in time. Sufficiently close to $T$, the agent spends their entire resource stock whenever an opportunity arises with $\\theta$ greater than some threshold. The threshold is decreasing in time and equals 0 at $T$. Concavity of $V$ with respect to $t$ means that deadline pressure becomes more severe close to the deadline.\n\nModels involving a deadline and a stochastic cost or benefit for a task are already present in the literature. Heidhues and Strack (2021) and Hyndman and Bisin (2022) both consider a single rational agent who solves an optimal stopping problem to decide when to complete a task, and either the cost or reward from the task varies randomly. Heidhues and Strack (2021) consider a quasi-hyperbolic agent who may or may not be naive, and Hyndman and Bisin (2022) consider agents who exhibit both exponential and sophisticated or naive hyperbolic discounting. If $x$ is a single, indivisible resource, my model becomes intuitively very similar to the model of either paper except with a different discounting scheme for the agent. My work differs from both papers in my aims. I analyze the incentives created by deadlines, whereas Heidhues and Strack (2021) focus on identifiability of the agent's discount parameters, and Hyndman and Bisin (2022) investigate demand for commitment devices in the form of deadlines.\n\nDeadlines usually appear in the context of some other topic. This literature is too broad to survey in its entirety, but the following papers form a slice of the literature. Of particular interest is the effect of deadlines on job performance. Lambert, et al. (2017) examine the\n\neffects of deadlines on audits and conclude that more time pressure results in lower audit quality. See Kuutila, et al. (2020) for a review of the literature on deadlines, time pressure, and software engineering. Deadlines come up in the theoretical literature, particularly in mechanism design (Arefeva and Meng 2017; Green and Taylor 2016; Madsen 2022; Mierendorff 2016). Karag\u00f6zo\u011flu and Kocher (2019) examine how time pressure affects bargaining in an experiment. Bizzotto, R\u00fcdiger, and Vigier (2021) construct an information design problem with a deadline and exogenous information. Coey, Larsen, and Platt (2020) model a consumer-search problem with a deadline and find that as the deadline approaches, the consumer will pay more for a good. The intuition in all of these papers is similar to my findings, where the agent will spend more resources on lower-quality opportunities when under time pressure. See also Emanuel, Katzir, and Liberman (2022) for discussion of this idea from a psychological point of view.\n\nCorrelation Aversion-Second, I construct a rational agent whose valuation of resources is additive with respect to future instantaneous utility yet who nevertheless exhibits correlation aversion. Correlation aversion means that if an agent receives multiple random payments, the agent prefers their outcomes be less correlated, and this behavior is both desirable for a rational agent and typically associated with non-additive value functions. Two of the most common preference models in the intertemporal choice literature are additive discounting and Epstein-Zin preferences. ${ }^{1}$ Additive discounting is simple, has been standard in the literature for many decades, and cannot explain correlation aversion, whereas Epstein-Zin preferences are newer, more sophisticated, and do support correlation aversion. In terms of simplicity, the agent of this paper has a value function that lies somewhere between additive\n\n[^0]$$\nU\\left(c_{0}, c\\right)=u\\left(c_{0}\\right)+\\mathbb{E}\\left[\\sum_{t=1}^{\\infty} D(t) u\\left(c_{t}\\right)\\right]\n$$\n\nwhere $D$ is their discount function and $u$ is their instantaneous utility function. In particular, exponential discounting means $D(t)=\\delta^{t}$, and hyperbolic discounting means $D(t)=(1+\\delta t)^{-1}$.\n\nNotice that $U$ from the previous paragraph maps a real number and sequence of random variables to a real number, so $U(c)$ is a random variable. This is because $f(x)=U\\left(x, c_{2}, c_{3}, \\ldots\\right)$ maps real numbers to real numbers, and therefore $U(c)=f\\left(c_{1}\\right)$ is a transformation of a random variable. Let $\\rho$ and $\\sigma$ be increasing diffeomorphisms from the nonnegative reals to the nonnegative reals. If an agent exhibits Epstein-Zin preferences over a discrete and infinite time-horizon, that means their valuation satisfies the recursion relation\n\n$$\nU\\left(c_{0}, c\\right)=\\rho^{-1}\\left(\\rho \\circ u\\left(c_{0}\\right)+\\delta \\rho \\circ \\sigma^{-1} \\mathbb{E}[\\sigma \\circ U(c)]\\right)\n$$\n\nwhere $\\delta$ is a discount parameter. Traditionally, $\\rho$ and $\\sigma$ are power functions, and in Epstein and Zin (1989), $u$ is the identity function. Epstein-Zin preferences allow us to better control how an agent aggregates utility over multiple time periods.\n\n\n[^0]:    ${ }^{1}$ Additive discounting dates back to Samuelson (1937). Kreps and Porteus (1978) introduced a framework for modeling preference for timing of the resolution of uncertainty, and Epstein and Zin (1989) developed these ideas into a recursive model of individual preference. Additive discounting has received scrutiny in part because it cannot distinguish correlations between payment probabilities at different time periods. See Aase (2021) and Stanca (2023) for more discussion of this point.\n\n    It may be helpful for some readers to see a definition of both types of preference models. Let $c=\\left(c_{1}, c_{2}, \\ldots\\right)$ be a sequence of nonnegative random variables, where each sequence entry represents consumption in a different time period, and suppose $c_{0}$ is current, known consumption. Our task is to assign a real number $U$ to $\\left(c_{0}, c_{1}, c_{2}, \\ldots\\right)$ that encodes the value of the consumption stream. If an agent exhibits additive discounting over a discrete and infinite time-horizon, that means we can express their valuation as\n\n    $$\n    U\\left(c_{0}, c\\right)=\\mu^{-1}\\left(\\rho \\circ u\\left(c_{0}\\right)+\\delta \\rho \\circ \\sigma^{-1} \\mathbb{E}[\\sigma \\circ U(c)]\\right)\n    $$\n\ndiscounting and Epstein-Zin preferences, but the agent still exhibits correlation aversion. ${ }^{2}$ It follows that a non-additive valuation is not the simplest model that explains this phenomenon.\n\nRecent papers on recursive preferences encompass a variety of topics in decision theory, usually relating to preference for information or resolution of uncertainty. Whenever I say recursive preferences in this paper, I mean any value function that arises from a dynamic programming problem. Epstein-Zin is the most well-known form of recursive preferences, but it is not the only formulation. Al-Najjar and Shmaya (2019) consider a rational agent with Epstein-Zin preferences whose discount factor approaches 1, and they show in closed form that the agent exhibits ambiguity aversion. Evren (2019) investigates ambiguity aversion in agent with recursive but not Epstein-Zin preferences. Li (2020) models agents who avoid partial information. Falk and Zimmermann (2016) run an experiment where subjects usually prefer information sooner depending on context, and Brown, Gui, and Je (2022) and Nielsen (2020) conduct experiments to test demand for non-instrumental information. In a related theoretical contribution, Gul, Natenzon, and Pesendorfer (2021) introduce the concept of random lotteries to model agents who prefer non-instrumental information. Bommier, Kochov, and Le Grand (2017) classify recursive preference models that are monotone in payment possiblities, and Kochov and Song (2023) analyze infinitely repeated games when the agents have recursive preferences.\n\nLiquidity-Third, the agent in this paper exhibits monotonicity with respect to payment timing. Blavatskyy (2016) points out that in standard intertemporal choice models, an agent may prefer to delay a portion of a payment scheduled for today. Suppose the agent discounts a future payment by $\\delta$. (With only two payments, we can specify $\\delta$ while being agnostic about the form of the agent's discounting.) If the agent receives $\\$ 1$ today and $\\$ 1$ at a later time, the utility from these payments is $u(1)+\\delta u(1)$. If $u$ is concave, and $\\delta$ is large enough, the sum is greater than $u(2)$, even though it makes no sense for the agent to delay a monetary payment without reason. Monotonicity with respect to payment timing means that moving all or part of a payment later never helps the agent. Blavatskyy (2016) induces monotonicity by modeling intertemporal choice with rank-based utility, and I induce monotonicity by allowing the agent to hold resources resources until the next spending opportunity.\n\nI am implicitly providing the agent with some liquidity, and this assumption is significant for understanding and testing how people prioritize the timing of payments and consumption. In a review of experiments where subjects decide whether to receive money sooner or later, Cohen, et al. (2020, p. 300) write that such experiments are \"assuming that a monetary payment at date $t$ generates a dollar-equivalent incremental consumption event at time $t \\ldots$ This assumption is inconsistent both with the empirical evidence and with standard economic theory. Only perfectly liquidity-constrained consumers or perfectly myopic consumers would instantly consume every payment they receive.\" This paper contrasts with that experimental assumption because payments to the agent provide value through future spending opportunities rather than by going immediately into the agent's instantaneous utility function.\n\nRisk and Time-Fourth, I argue that my model provides an intuitive connection between\n\n[^0]\n[^0]:    ${ }^{2}$ As is the case with Epstein-Zin preferences, the agent in my model has a value function $V$ that is recursive, but the recursive preferences of this paper are not Epstein-Zin.\n\nrisk and time preference because we can interpret a more risk-seeking attitide with respect to $\\theta$ as \"waiting for the right moment,\" a motivation that will undoubtedly be familiar to many readers. A more risk-seeking agent spends resources sooner when they see high values of $\\theta$ and waits if $\\theta$ is lower. The relationship between risk and time has attracted attention for decades, and a big motivation behind Epstein-Zin preferences is their ability to separate an agent's attitudes toward risk and time. The literature is currently split on whether risk and time preference ought to affect each other. For example, de Castro, et al. (2023, p. 2) call it \"a drawback\" that \"in the [expected utility] model, risk aversion and [intertemporal substitution] cannot be disentangled,\" but Epper and Fehr-Duda (2024, p. 311) claim that \"[a] considerable body of experimental evidence suggests... that risk taking and time discounting are linked.\" By providing a straightforward explanation for why risk and time preference affect each other here, I suggest that it is plausible to connect risk and time more generally.\n\nA swath of recent papers have attempted to experimentally determine subjects' coefficient of risk aversion and elasticity of intertemporal substitution. Andersen, et al. (2008) first pointed out the importantance of measuring risk and time attitudes simultaneously, and Andreoni and Sprenger (2012) built on this idea when they introduced convex time budgets, an experimental technique that has become popular throughout the liteature. A large number of authors have adopted or expanded the approaches in these two papers (Andersen, et al. 2018; Apestegu\u00eda, Ballester, and Guti\u00e9rrez 2019; Balakrishnan, Haushofer, and Jakiela 2020; Bernedo Del Carpio, Alpizar, and Ferraro 2022; Blavatskyy and Maafi 2020; Cheung 2020; de Castro, et al. 2023; Sornasundaram and Eli 2022; Sun and Potters 2022). Some recent work has attempted to better fit data through prospect theory and probability weighting (Diecidue, Hardardottir, and Islam 2023; Holden, Tilahun, and Sommervoll 2022; Kemel and Paraschiv 2023; Lampe and Weber 2021). Finally, a few authors have specifically attempted to measure risk and time preference without relying on a preference model by measuring timing premia in the case of Meissner and Pfeiffer (2022) or correlations in the case of Rohde and Yu (2024).\n\nTheoretical work in this area has focused on the relationship between risk and time under different models. Fahrenwaldt, Jensen, and Steffensen (2020) and Lau (2019) formulate methods to separate risk and time preference using certainty equivalents. Chakraborty, Halevy, and Saito (2020) and Saito (2015) use a general framework to make statements about behavior of an agent who believes that the future is inherently uncertain. Epper and FehrDuda (2024) model an agent using rank-dependent utility in an attempt to explain seven different observations about human behavior. See Ericson and Laibson (2019) and Thimme (2017) for reviews of the literature on intertemporal choice.\n\nProcrastination-Fifth, if the agent misperceives their instantaneous utility function, we end up with a model of procrastination. I imagine that an agent overestimates their eagerness to complete a task and is \"waiting for the right moment\" more than they believe themself to be. Suppose the agent believes that their instantaneous utility is $\\tilde{u}$ instead of $u$, and suppose that instead of learning $\\theta$ at a spending opportunity, the agent observes the mathematical object that actually affects them, which is the function $f(x)=u(\\theta, x)$. If for any $\\theta$, there exists a $\\tilde{\\theta}$ such that for any $x, u(\\theta, x)=\\tilde{u}(\\tilde{\\theta}, x)$, then the agent believes that a spending opportunity with quality $\\theta$ has quality $\\tilde{\\theta}$. When $\\tilde{u}$ is more concave than $u$, then $\\tilde{\\theta}<\\theta$, and the agent believes they are getting many poor opportunities through bad luck.\n\nThe agent expects future opportunities to be better, so they reduce spending at the current opportunity because of likely unfounded optimism that arises from a lack of self-awareness.\n\nThis idea differs from traditional explanations of procrastination in economics, where present bias arises from a time-inconsistent utility function such as hyperbolic or quasihyperbolic discounting. For example, Augenblick and Rabin (2019), Bisin and Hyndman (2020), and Fedyk (2024) measure present bias in experiments where they model subjects using quasi-hyperbolic discounting. Niu (2023) models an agent with quasi-hyperblic discounting who allocates a continuous flow of effort to a task between a starting time and a final deadline. In these types of papers, agents always experience tension between what they plan and what they do, and commitment devices become an important tool for understanding how agents behave. In my model, a procrastinating agent has no interest in a commitment device.\n\nThis paper contributes to the more recent literature that explores agent beliefs as a motive for present bias and procrastination. Brunnemeier, Papakonstantinou, and Parker (2017) model an optimistic agent whose beliefs lead to delay in behavior, and Breig, Gibson, and Shrader (2020) and Cordes, Friedrichsen, and Shudy (2024) run experiments where they conclude that optimistic subjects delay task completion. Kaufmann (2022) and Zhang (2021) study projection bias and how projecting beliefs or tastes into the future affects an agent's time preference. Heidhues, K\u00f6szegi, and Strack (2024) analyze an agent who misperceives their objective function in past time periods, which is similar to how I model procrastination. The agent views their pervious motives as more benevolent than they actually were and ends up exhibiting present bias. The authors allow the agent to learn about their misperceived objective function, whereas in this paper, an agent who procrastinates cannot gain self-awareness so easily. In the psychology literature, Jagga, Srinivasan, and Srivastava (2021) and Zhang and Feng (2020) conduct experiments where subjects overrate their future interest in a task and procrastinate as a result.\n\nApart from the decision theory literature, my model has a similar flavor to the secretary problem from optimal stopping theory. ${ }^{3}$ Suppose an academic department wants to hire a new staff member. The faculty member in charge of hiring interviews the candidates sequentially, and they learn whether or not the current candidate is a better fit than all previous applicants. The department must make an offer immediately after the inteview, or the candidate finds a job elsewhere. In the traditional secretary problem, the department wants to maximize its chance of hiring the best candidate, and when the number of applicants gets large, the optimal strategy is to interview the first $1 / e$ candidates and accept the next applicant who is better than all previous applicants. My model differs from the secretary problem in that the agent of this paper knows the distribution of $\\theta$, spends multiple resources at a\n\n[^0]\n[^0]:    ${ }^{3}$ This paper is not a part of the literature on the secretary problem, but I mention it for completeness. The literature on this topic is abundant, and I cover only a subset of it here. See Bearden (2006) for a variant of the secretary problem where the hiring committee maximizes utility, which is one of the most conceptually similar papers to this one from the literature. Recent work on the secretary problem has focused on extending the results to different objectives or orderings of the candidates. Albers and Ladewig (2021) provide new results for the problem of selecting multiple candidates. Hoefer and Kodric (2017) explore the secretary problem in more general contexts such as picking subsets of a graph or a matroid. Jones (2020), Liu and Milenkovic (2022), and Liu, Milenkovic, and Moustakides (2023) consider variants of the problem where the order of candidates follows a Mallows distribution. Gnedin (2022) suggests improvements to the traditional $1 / e$ solution, and Demers (2019) investigates the stopping time of the optimal solution.\n\ntime, and maximizes expected utility instead of finding the best spending opportunity before $T$.\n\nIt is also worth being clear about the relationship between time and time discounting in my model. In evaluating homogeneity with respect to time, the decision theory literature considers three properties of time preference: stationarity, time invariance, and time consistency. We can most easily understand these properties in terms of a reference period and an evaluation period. An agent's current time is their reference period, and at the evaluation period, the agent chooses between two alternatives. Stationarity means the agent's choice is independent of the evaluation period, and time invariance means that changing both the reference period and the evaluation period in the same way does not affect the agent's choice. Time consistency means the agent's chooses an alternative independently of the reference period. See Halevy (2015) for discussion of these properties. Koopmans (1960) introduced stationarity, and Halevy (2015) formalized time invariance. I am less clear on the origins of time consistency, but the concept dates back at least to Samuelson (1937).\n\nThese properties affect the agent's behavior by prohibiting preference reversals. A preference reversal means that an agent previously prefered one option, but moving somehow forward in time prompted the agent to switch their choice. A static preference reversal means that changing the evaluation period (while fixing the reference period) caused the switch, and a dynamic preference reversal is the opposite. Dynamic preference reversals have received more attention than static preference reversals, to the point that some authors omit the word \"dynamic\" and use the general term \"preference reversal\" to refer to what I call dynamic preference reversal. An agent with stationary time preferences never exhibits static preference reversal, and an agent with time consistent time preferences never exhibits dynamic preference reversal. Time invariance makes both types of preference reversals equivalent. See Chen, et al. (2019) for more discussion of static versus dynamic preference reversals.\n\nBecause I study deadlines, my model by definition violates time invariance, and I show later in this paper that my model also violates stationarity. Because the agent's value function comes from a Bellman equation, the agent exhibits time consistency. If the agent of this paper chooses between a smaller-sooner or later-larger payment, the agent prefers the larger payment away from the deadline and the smaller payment near the deadline. Far away from the deadline, the agent recognizes that they will eventually switch to a smaller-sooner payment, so the preference reversal is static. The preference reversal is not dynamic because it happens in a time consistent fashion. Once the agent reaches the time period when they expect to switch to a smaller payment, they actually do so.\n\nThe rest of this paper is organized as follows. Section 2 introduces the model in detail. Section 3 solves the model in the case of a single, indivisible resource, and Section 4 extends the solution to arbitrary discrete resource stocks. Section 5 establishes properties of the value function surrounding multiple payments to the agent, namely correlation aversion and monotonicity with respect to payment timing. Section 6 connects risk and time preference, and section 7 concludes. I include mathematical proofs in an appendix.", "tables": {}, "images": {}}, {"section_id": 2, "text": "# 2. The Model \n\nIn this section, I define the model precisely. We consider a rational agent with a resource stock $x$. The agent spends their resources at various points in time and derives utility ac-\n\ncording to their instantaneous utility function $u$. By definition, $u$ takes two arguments, one for the quality $\\theta$ of the spending opportunity and one for the amount $x$ of resources spent. We assume that $u(0, x)=u(\\theta, 0)=0$ and that $u$ is smooth and strictly increasing in $x$ and $\\theta$. We also assume that $u$ is separable, so we can write $u(\\theta, x)=\\zeta(\\theta) \\mu(x)$. This technical assumption means that the marginal effects of $\\theta$ and $x$ on $u$ are independent of the other variable. Restricting attention to separable utility functions comes with some loss of generality, but I claim the model is still very general. It is also necessary to keep the problem tractable and consistent with previous work in the literature. We have an extra degree of freedom because $\\zeta$ and $\\mu$ can scale inversely to one another, so we assume without loss of generality that $\\zeta(1)=1$. Finally, we assume that $\\mu$ is concave in $x$. We do not make any assumptions about concavity of $\\zeta$, but some results from Section 4 hold only when $\\zeta$ is logconcave.\n\nTime itself is continuous, but opportunites to spend the resources are discrete and follow a Poisson process. In fact, the Poisson process is the technical assumption that allows the resource stock to jump discretely in a continuous-time environment. Whenever the agent reaches a new opportunity, they learn the quality parameter $\\theta$ associated with the opportunity and then decide what to save and what to spend. We assume that $V(t, x)$ encodes the sum of expected instantaneous utility from all future spending opportunities, so if the agent spends $x-y$ and saves $y$ resources at the current opportunity, they derive $u(\\theta, x-y)$ utility immediately and $V(t, y)$ value from future opportunities. It follows that the expected value of an opportunity at (future) time $t$ is\n\n$$\n\\mathbb{E} \\max \\{u(\\theta, x-y)+V(t, y)\\}\n$$\n\nwhere we maximize over possible choices of $y$ and then take expectation with respect to $\\theta$. The maximum operator occurs inside the expected value operator because the agent learns $\\theta$ before choosing $y$.\n\nTo write the Bellman equation, we note that the current value of the agent's resources must equal the expected sum of instantaneous utility from the next spending opportunity plus the value of whatever remains afterward. Equation (1) is exactly this quantity if the next spending opportunity occurs at some fixed time $t$, but in general, the timing of the next opportunity is random and could happen at any point before $T$. It follows that the agent's valuation is the expected expected value of equation (1) with respect to $t$, where we weight different times according to their probability of being the next opportunity. For a Poisson process with rate parameter $\\lambda$, the waiting time until the next event is an exponential distribution with rate parameter $\\lambda$, so the Bellman equation for $V$ is\n\n$$\nV(t, x)=\\int_{t}^{T} \\mathbb{E} \\max _{y}\\{u(\\theta, x-y)+V(s, y)\\} \\lambda e^{\\lambda(t-s)} d s\n$$\n\nEquation (2) completely determines the agent's behavior. The upper limit of the integral is $T$ because the agent never encounters opportunities past $T$, so $V(T, x)=0$. It follows that $V(t, 0)=0$. Because expected value and maximum operators commute with multiplication by a positive constant, we have the following theorem.\nTheorem 1. Suppose $k>0$, and let $V$ be the value function for an agent with instantaneous utility $u$. For an agent with utility ku, the value function is $k V$, and the spending rule remains unchanged.\n\nDifferentiating equation (2) gives us a differential equation for $V$. Applying the fundamental theorem of calculus, we get\n\n$$\n\\left.\\frac{d V}{d t}\\right|_{(t, x)}=\\lambda\\left[V(t, x)-\\mathbb{E} \\max _{y}\\{u(\\theta, x-y)+V(t, y)\\}\\right]\n$$\n\nand because $V(T, x)=0$, it follows that\n\n$$\n\\left.\\frac{d V}{d t}\\right|_{(T, x)}=-\\lambda \\mathbb{E} u(\\theta, x)<0\n$$\n\nThis means there exists a neighborhood of $T$ where $V$ is positive, and we can extend the result to all $t<T$ by applying continuous induction to equation (2). By considering the maximand of equation (3) with $y=x$, we see immediately that $d V / d t \\leq 0$. Comparing different values of $y$ allows us to make this inequality strict and establish monotonicity with respect to $x$. We have the following theorem.\n\nTheorem 2. When $t<T$ and $x>0, V$ is positive, strictly decreasing in $t$, and strictly increasing in $x$.", "tables": {}, "images": {}}, {"section_id": 3, "text": "# 3. A Single Resource \n\nThe case of a single, indivisible resource is simpler than the case with a divisible resource stock, so I discuss it first. To keep the notation as clean as possible, I drop the $x$ arguments from the functions in equation (2), so the Bellman equation becomes\n\n$$\nV(t)=\\int_{t}^{T} \\mathbb{E} \\max \\{u(\\theta), V(s)\\} \\lambda e^{\\lambda(t-s)} d s\n$$\n\nwith equivalent differential equation\n\n$$\nV^{\\prime}=\\lambda(V-\\mathbb{E} \\max \\{u(\\theta), V\\})\n$$\n\nThe probability space of $\\theta$-values is $[0,1]$ with the Lebesgue measure, and suppose we define both $u$ and a constant function with value $V(t)$ on this probability space. The derivative of $V$ is negative the area under $u$ above the flat line $V(t)$. Equation (4) has a nullcline at $V=u(1)$, and when $V<u(1)$, the derivative is negative. This means $V$ is decreasing as we already proved in Theorem 2, and as $t$ gets big negative, the function has an asymptote at $u(1)$. Notice also that if $V\\left(t_{1}\\right)<V\\left(t_{2}\\right)$, then $t_{2}<t_{1}$ and $V^{\\prime}\\left(t_{1}\\right)<V^{\\prime}\\left(t_{2}\\right)$. The (unsigned) area under $u$ and above $V\\left(t_{1}\\right)$ is greater than above $V\\left(t_{2}\\right)$, so the derivative at $t_{1}$ is more negative than at $t_{2}$. We arrive at the following result.\n\nTheorem 3. When the agent has a single resource, $V$ is concave.\nWhen the agent has only a single resource, the question of how much to spend becomes a question of whether to spend, and the agent spends their single resource whenever they\n\narrive at an opportunity with $u(\\theta) \\geq V(t)$. Let $\\phi$ be the cutoff value between spending and saving. The value of $\\phi$ changes with time and satisfies $u(\\phi)=V(t)$. It follows that\n\n$$\n\\phi(t)=u^{-1}(V(t))\n$$\n\nand differentiating gives us\n\n$$\n\\phi^{\\prime}(t)=\\frac{V^{\\prime}(t)}{u^{\\prime}\\left(u^{-1}(V(t))\\right)}=\\frac{V^{\\prime}(t)}{u^{\\prime}(\\phi)}\n$$\n\nNow let $w$ be a more concave instantaneous utility function than $u$ with corresponding value function $W .{ }^{4}$ We assume that $w$ satisfies the same properties as $u$, and $w(1)=u(1)$. If $\\psi$ is the cutoff corresponding to $W$, then $\\psi^{\\prime}=W^{\\prime} / w^{\\prime}(\\psi)$. We need two lemmas before we can establish the relationship between $V$ and $W$ as well as $\\phi$ and $\\psi$. The idea is that when $V$ and $W$ are the same value (which happens at different times $t$ ), more concave $w$ means that $W^{\\prime}<V^{\\prime}$, so $W$ decreases toward 0 at $T$ faster. But that's possible only if $V(t)<W(t)$. The opposite comparison happens for $\\phi$ and $\\psi$ because of the factors of $u^{\\prime}$ and $w^{\\prime}$ in the denominators of $\\phi^{\\prime}$ and $\\psi^{\\prime}$.\n\nLemma 4. Let $y$ and $z$ satisfy differential equations $y^{\\prime}=f(t, y)$ and $z^{\\prime}=g(t, z)$ with $f$ and $g$ negative, and suppose $y(T)=z(T)=0$. If $f<g<0$, then for $t<T, y(t)>z(t)$.\n\nLemma 5. Let $f$ and $g$ be increasing functions defined on the interval $[a, b]$. If $f$ is more concave than $g$, than for any $x$,\n\n$$\n\\int_{x}^{b} \\frac{f(s)-f(x)}{f^{\\prime}(x)} d s<\\int_{x}^{b} \\frac{g(s)-g(x)}{g^{\\prime}(x)} d s\n$$\n\nTheorem 6. Consider an agent with a single resource. If $w$ is more concave than $u$, then $V(t)<W(t)$ and $\\psi(t)<\\phi(t)$.\n\nA more risk-averse agent will always be more willing to spend their resource, which makes sense, but they also expect to do better than a less risk-averse agent. We can compare value functions this way because we normalized $u$ and $w$ such that their maximum values are equal, and I claim this modeling choice is reasonable. I am assuming that being more risk-seeking does not make an agent inherently happier when they encounter a high-quality opportunity. Rather, risk-averse in my model means the agent is more generally happy about the selection of opportunities available, and risk-seeking means the agent is less generally happy about the opportunities.", "tables": {}, "images": {}}, {"section_id": 4, "text": "# 4. Divisible Resources \n\nIn this section, I extend the solution to models with multiple or divisible resources. We will\n\n[^0]\n[^0]:    ${ }^{4}$ More concave means that the coefficient of risk aversion for $w$ is everywhere greater than for $u$. Formally,\n\n    $$\n    -\\frac{u^{\\prime \\prime}(\\theta)}{u^{\\prime}(\\theta)}<-\\frac{w^{\\prime \\prime}(\\theta)}{w^{\\prime}(\\theta)}\n    $$\n\nfreely use the decomposition $u(\\theta, x)=\\zeta(\\theta) \\mu(x)$. We assume that $x$ is divisible into $n$ pieces with cutpoints $0=x_{0}<x_{1}<\\cdots<x_{n}=x$, and to keep things simple, we suppose $x_{i} \\propto i$. This means all pieces of $x$ are the same size, so it doesn't matter what order the agent spends the pieces in, only how many they spend at a time. ${ }^{5}$ The scale of $x$ also doesn't matter, so we assume without loss of generality and for notational convenience that $x_{i}=i$. It is possible to model a rational agent with a continuous resource stock that admits any division into pieces, but I believe that modeling discrete portions more accurately captures situations where a person has few resources that don't divide easily. That being said, the math works out similarly in either case. We make use of discrete derivatives with respect to $x$, and we let $\\Delta$ be the discrete derivative operator. For a function $f, \\Delta f(x)=f(x+1)-f(x)$, and when I use $\\Delta$ in the rest of this paper, it will always refer to discrete derivative with respect to $x$.\n\nEquation (2) is still the Bellman equation for our setup, and equation (3) describes the behavior of the value function. The integrand of equation (2) involves maximizing over $n+1$ functions of the form $u(\\theta, i)+V(t, n-i)$ and then integrating with respect to $\\theta$. As in the previous section, it will be helpful to imagine graphing each maximand-component on $[0,1]$, which is the probability space of $\\theta$-values. Several observations are apparent. First, when $i=n$, which corresponds to spending everything, the maximand-component is proportional to $\\zeta$ and time-independent. Second, when $i=0$, which corresponds to saving everything, the maximand-component is constant with respect to $\\theta$ and decreasing in time. Third, for other values of $i$, the maximand-component is a scaled copy of $\\zeta$ raised by an amount that decreases in time. Larger constant of proportionality corresponds to smaller vertical intercept, so we have a tradeoff between the scale of each component-graph and its value at $\\theta=0$.\n\nThe saving rule $y$ satisfies intuitive properties in regard to $\\theta$. Suppose that $\\theta_{1}<\\theta_{2}$, and let $y^{*}$ be the output of the spending rule for $\\theta_{1}$. If $n-i<n-y^{*}$, then we know\n\n$$\nu\\left(\\theta_{1}, n-i\\right)+V(t, i) \\leq u\\left(\\theta_{1}, n-y^{*}\\right)+V\\left(t, y^{*}\\right)\n$$\n\nfrom the definition of $y^{*}$. Because $\\mu$ is increasing,\n\n$$\n\\begin{aligned}\n\\mu(n-i) & <\\mu\\left(n-y^{*}\\right) \\\\\n{\\left[\\zeta\\left(\\theta_{2}\\right)-\\zeta\\left(\\theta_{1}\\right)\\right] \\mu(n-i) } & <\\left[\\zeta\\left(\\theta_{2}\\right)-\\zeta\\left(\\theta_{1}\\right)\\right] \\mu\\left(n-y^{*}\\right) \\\\\nu\\left(\\theta_{2}, n-i\\right)-u\\left(\\theta_{1}, n-i\\right) & <u\\left(\\theta_{2}, n-y^{*}\\right)-u\\left(\\theta_{1}, n-y^{*}\\right)\n\\end{aligned}\n$$\n\nAdding this inequality to equation (5) shows taht the equation is true for $\\theta_{2}$ as well, so $n-y$ is non-strictly increasing in $\\theta$, and $y$ is non-strictly decreasing. Because the output of $y$ is discrete, we see that for fixed $t, y$ is piecewise constant with respect to $\\theta$. Further, equation (5) for $\\theta_{2}$ will be a strict inequality, and we conclude that for generic $\\theta$, the largest maximandcomponent will be strictly greater than the other maximand-components. Monotonicity of $y$ implies that moving right along the $\\theta$-axis causes us to transition from flatter to steeper maximand-components.\n\n[^0]\n[^0]:    ${ }^{5}$ If the pieces of $x$ are different sizes, the problem very quickly becomes NP-hard. That is a Bad Thing. See also Babaioff, et al. (2007) and Babaioff, et al. (2009) for discussion of the secretary problem where candidates have weights. See also Cacchiani, et al. (2022a) and Cacchiani, et al. (2022b) for discussion of the knapsack problem more generally.\n\nConcavity of $V$ is less obvious than in the previous section because the decreasing $V(t, i)$ values change the vertical intercepts of the maximand-components and may have complicated effects on the region they cover. Differentiating equation (3) gives us\n\n$$\n\\left.\\frac{d^{2} V}{d t^{2}}\\right|_{(t, x)}=\\lambda\\left[V_{t}(t, x)-\\mathbb{E} V_{t}\\left(t, y^{*}\\right)\\right]\n$$\n\nwhere $V_{t}$ is the partial derivative of $V$ with respect to $t$, and $y^{*}$ is the agent's choice of $y$ at $t$. The expected value is with respect to $\\theta$ and is important because $y^{*}$ is a function of $\\theta$. At $T, y^{*}=0$, so\n\n$$\n\\left.\\frac{d^{2} V}{d t^{2}}\\right|_{(T, x)}=\\lambda\\left[V_{t}(T, x)-V_{t}(T, 0)\\right]=-\\lambda^{2} \\mathbb{E} u(\\theta, x)<0\n$$\n\nConcavity of $\\mu$ means that $V_{t}(T, x)$ is convex in $x$. It follows that there exists a neighborhood of $T$ where $V$ is concave in $x$, and we can again extend to all $t<T$ through continuous induction. Concavity with respect to $x$ allows us to establish concavity in $t$ and a negative cross-partial derivative. We have the following three lemmas and theorem on the structure of $V$. Lemma 7 is closely related to the envelope theorem and functions analogously in the proof of Theorem 10 .\n\nLemma 7. Let $D$ be a discrete set, and let $I$ be an interval. Suppose that $f$ is a function defined on $[0,1] \\times I \\times D$ that is continuously differentiable in its first two arguments. Let $\\beta:[0,1] \\times I \\rightarrow D$ be well behaved in the following sense: for any number $p$ in the interval $I$, the restriction $\\left.\\beta\\right|_{p}$ is piecewise constant on $[0,1]$, and for any point $(s, p)$ such that $\\left.\\beta\\right|_{p}$ is locally constant at $s, \\beta$ is locally constant at $(s, p)$. Then\n\n$$\n\\frac{d}{d p} \\int_{0}^{1} f(s, p, \\beta(s, p)) d s=\\int_{0}^{1} \\frac{\\partial f}{\\partial p}\\left|{ }_{s, p, \\beta(s, p)}\\right| d s\n$$\n\nLemma 8. Let $f$ and $g$ be strictly increasing and strictly concave functions defined on the natural numbers with $f(0)=g(0)=0$. Then $h(x)=\\max _{y}\\{f(x-y)+g(y)\\}$ is also strictly increasing and, assuming generic $f$ and $g$, strictly concave. Further, $\\max \\{\\Delta f(x), \\Delta g(x)\\} \\leq$ $\\max \\left\\{\\Delta f\\left(x-y^{*}\\right), \\Delta g\\left(y^{*}\\right)\\right\\}=\\Delta h(x)$, where $y^{*}$ is the optimum for $h(x)$. If $y^{*}$ satisfies $0<y^{*}<x$, then the inequality is strict.\n\nLemma 9. If $\\left\\{f_{i}\\right\\}$ is a family of positive, increasing, discrete, and strictly concave functions indexed by $i \\in[0,1]$, then\n\n$$\n\\int_{0}^{1} f_{i} d i\n$$\n\nis also positive, increasing, discrete, and concave.\nTheorem 10. Assume the agent's resources are divisible as described in this section. Then $V$ is concave in both arguments, and $\\Delta V_{t}<0$. Here $V_{t}$ is the partial derivative of $V$ with respect to $t$, and $\\Delta$ means discrete derivative with respect to $x$.\n\nCorollary 11. The saving rule $y$ is non-strictly decreasing with respect to $t$. (Equivalently, $x-y$ is increasing in t.) Both $y$ and $x-y$ are non-strictly increasing with respect to $x$.\n\nRecall that in the case of a single resource, equation (4) has a nullcline at $u(1)$. The intuition is straightforward: if $t$ gets big negative, the agent has more time to find an opportunity with $\\theta$ very close to 1 . The same idea applies when the agent has a divisible resource stock. Because $\\mu$ is concave, the agent most wants to spend each unit of $x$ separately, and if they have a large time window to find opportunities, the agent attempts to spend these individual units when $\\theta$ is near 1. Formalizing this intuition through induction on $x$ gives us the following theorem.\n\nTheorem 12. For an agent with a divisible resource, $\\lim _{t \\rightarrow-\\infty} V(t, x)=x \\mu(1)$.\nA corollary of Theorem 12 is that the agent exhibits static preference reversals. A static preference reversal means that the agent currently prefers $x_{1}$ over $x_{2}$ but believes that at some point in the future, they will switch to $x_{2}$. The agent of my model is time-consistent, so when the agent reaches the time where the expect to switch to $x_{2}$, their preference do in fact switch to $x_{2}$. The picture is more complicated in time-inconsistent preferences such as hyperbolic discounting. Let $\\bar{t}$ and $\\bar{x}$ be (positive) time and resource amounts, and consider the difference\n\n$$\nV(t, x)-V(t+\\bar{t}, x+\\bar{x})\n$$\n\nWe can think of both terms as comparing the value for an agent of getting paid $x$ resources at time $t$ versus getting paid $x+\\bar{x}$ resources at $t+\\bar{t}$. Equation (7) is positive when the agent would rather have a smaller resource stock at a sooner time and negative otherwise. At time $t=T-\\bar{t}$, equation (7) is positive. ${ }^{6}$ For $t$-values far enough away from the deadline, the picture is reversed because equation (7) approaches $-\\bar{x} \\mu(1)<0$ as $t$ approaches $-\\infty$. At some point, the expression changes sign, and differentiating shows the sign change happens at a unique time.\n\nTheorem 13. An agent with a divisible resource exhibits static preference reversal, and the time when the preference reversal happens is unique.\n\nWith a divisible resource, the agent behaves reasonably. As the quality of a given opportunity increases, the marginal utility of consumption also rises, so the agent spends more and saves less. The agent also spends more as they get closer to the deadline because the marginal value of saving another resource gets smaller at later times. Concavity with respect to $x$ arises means the agent experiences diminishing marginal value of their resource stock, and concavity with respect to $t$ means that the resource stock loses value increasingly fast as the deadline approaches. The agent's preference reversal occurs in the opposite manner from what we often see in experimental subjects, who are more likely to choose a larger delayed payment if they imagine making the choice in the future. I interpret the agent's behavior as analogous to a time crunch. Away from the deadline, the rational agent is happy to be patient and wait for a larger resource stock, but close to the deadline, the agent is willing to sacrifice resources for more time.", "tables": {}, "images": {}}, {"section_id": 5, "text": "# 5. Multiple Payments \n\nI considered an agent in previous sections of this paper who moves through time with a single\n\n[^0]\n[^0]:    ${ }^{6}$ This point is obvious because any amount of resources at $T$ are not useful to the agent.\n\nTable 3: Probabilities of Outcomes for Correlated Bernoulli Distributions\n\n![table_0](table_0)\n\npool of resources, but we can modify the model to describe an agent who receives multiple payments at different times. Suppose the agent has $x$ resources at time $t$, and at some fixed future time $\\bar{t}<T$, the agent will receive an additional $\\bar{x}$ resources. After $\\bar{t}$, the agent has received all their resources and uses the same value function we've been considering, but before $\\bar{t}$, the value function must account for the upcoming extra resources. It follows that the agent's value function $\\tilde{V}$ satisfies\n\n$$\n\\begin{array}{ll}\nt \\geq \\bar{t}: & \\tilde{V}(t, x)=\\int_{t}^{T} \\mathbb{E} \\max \\{u(\\theta, x-y)+\\tilde{V}(s, y)\\} \\lambda e^{\\lambda(t-s)} d s \\\\\nt<\\bar{t}: & \\tilde{V}(t, x)=\\int_{t}^{\\bar{t}} \\mathbb{E} \\max \\{u(\\theta, x-y)+\\tilde{V}(s, y)\\} \\lambda e^{\\lambda(t-s)} d s+e^{\\lambda(t-\\bar{t})} \\tilde{V}(\\bar{t}, x+\\bar{x})\n\\end{array}\n$$\n\nThe term $\\tilde{V}(\\bar{t}, x+\\bar{x})$ is a continuation payoff in the situation where the agent moves forward in time until $\\bar{t}$ without encountering an opportunity, and $e^{\\lambda(t-\\bar{t})}$ is the chance of no opportunities arising between $t$ and $\\bar{t}$. Notice that when $t \\geq \\bar{t}, \\tilde{V}$ satisfies the same recursion relation as equation (2), so past $\\bar{t}, \\tilde{V}=V$.\n\nWe can use $\\tilde{V}$ to establish properties such as correlation aversion. Suppose an agent randomly receives a payment of $x$ at some time $t$ and then randomly receives a payment of $\\bar{x}$ at $\\bar{t}>t$. Let $X_{1}$ and $X_{2}$ be Bernoulli random variables that encode the agent's probability of getting paid at $t$ and $\\bar{t}$ respectively. Here is how to construct $X_{1}$ and $X_{2}$ to account for correlations in their outcomes: let $X$ be uniform on $[0,1]$, and define $X_{1}=\\chi_{\\left[0, p_{1}\\right]}(X)$, where $p_{1}$ is the success probability for $X_{1}$ and $\\chi$ is an indicator function. Then we define $X_{2}=\\chi_{\\left[0, p_{2}\\right]}(X-c)$. Larger $c$ means less correlation. Not all $c$-values make sense, but there will always be some value of $c$ that makes $X_{1}$ and $X_{2}$ independent. Table 3 shows the joint probability distribution of $X_{1}$ and $X_{2}$ conditional on $c$.\n\nThe expected value $E$ of the random payout under an early resolution of uncertainty is\n\n$$\n\\begin{aligned}\nE=\\left(\\min \\left\\{p_{1}, p_{2}\\right\\}-c\\right) \\tilde{V}(t, x)+ & \\left(\\max \\left\\{p_{1}-p_{2}, 0\\right\\}+c\\right) V(t, x) \\\\\n& +\\left(\\max \\left\\{p_{2}-p_{1}, 0\\right\\}+c\\right) V(\\bar{t}, \\bar{x})\n\\end{aligned}\n$$\n\nso\n\n$$\n\\frac{d E}{d c}=-\\tilde{V}(t, x)+V(t, x)+V(\\bar{t}, \\bar{x})\n$$\n\nCorrelation aversion means that $E$ is increasing, which is equivalent to the condition $\\tilde{V}(t, x)<$ $V(t, x)+V(\\bar{t}, \\bar{x})$. We know that\n\n$$\n\\lim _{t \\uparrow \\bar{t}} \\tilde{V}(t, x)=V(\\bar{t}, x+\\bar{x})\n$$\n\nso near $\\bar{t}$, correlation aversion holds from concavity of $V$. We can extend this result to all $t<\\bar{t}$ through continuous induction, and we have the following theorem.\n\nTheorem 14. With two random payments, the agent's expected value is strictly decreasing in the amount of correlation between the payments.\n\nWe can also establish monotonicity with respect to payment timing, which means that $\\tilde{V}$ decreases as $\\bar{t}$ gets larger. Suppose the agent receives a payment of $x$ at $t$ and a payment of $\\bar{x}$ at $\\bar{t}$. Then $\\tilde{V}$ captures the value of the agent's current resources plus payment at $\\bar{t}$, and we can show that increasing $\\bar{t}$ lowers $\\tilde{V}$. The value function $\\tilde{V}$ is discontinuous at $\\bar{t}$ as written because we designed $\\tilde{V}$ to encode the value of a resource stock that jumps discontinuously at $\\bar{t}$. We consider the composite $\\tilde{V}\\left(t, x+\\bar{x} \\chi_{[\\bar{t}, T]}(t)\\right)$, which is the value of the agent's resource stock when they get paid at $\\bar{t}$, and this composite is continuous in $t$. Differentiating with respect to $\\bar{t}$ gives us\n\n$$\n\\begin{aligned}\n\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, x}=\\int_{t}^{\\bar{t}} \\mathbb{E}\\left[\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{s, y^{*}}\\right] \\lambda e^{\\lambda(t-s)} d s & +\\mathbb{E} \\max _{0 \\leq y \\leq x}\\{u(\\theta, x-y)+V(\\bar{t}, \\bar{x}+y)\\} \\lambda e^{\\lambda(t-\\bar{t})} \\\\\n& -\\mathbb{E} \\max _{0 \\leq y \\leq x+\\bar{x}}\\{u(\\theta, x+\\bar{x}-y)+V(\\bar{t}, y)\\} \\lambda e^{\\lambda(t-\\bar{t})}\n\\end{aligned}\n$$\n\nwhere $y^{*}$ maximizes $u(\\theta, x-y)+\\tilde{V}(s, y)$. This expression is intractable, and differentiating with respect to $t$ results in a slightly nicer differential equation for $d \\tilde{V} / d \\bar{t}$ given by\n\n$$\n\\left.\\frac{d}{d t}\\left(\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, x}\\right)=\\left.\\lambda \\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, x}-\\lambda \\mathbb{E}\\left[\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, y^{*}}\\right] e^{\\lambda(t-\\bar{t})}\n$$\n\nWe show through induction on $x$ that the solution is always negative when $\\bar{x}>0$, and we end up with the following theorem.\n\nTheorem 15. At time $t$, the valuation of the agent's current resource stock plus a future payment at $\\bar{t}$ strictly decreases as $\\bar{t}$ gets larger starting from $\\bar{t}=t$.", "tables": {"table_0": "|  | $X_{2}=0$ | $X_{2}=1$ |\n| :--: | :--: | :--: |\n| $X_{1}=0$ | $\\min \\left\\{1-p_{1}, 1-p_{2}\\right\\}-c$ | $\\max \\left\\{p_{2}-p_{1}, 0\\right\\}+c$ |\n| $X_{1}=1$ | $\\max \\left\\{p_{1}-p_{2}, 0\\right\\}+c$ | $\\min \\left\\{p_{1}, p_{2}\\right\\}-c$ |"}, "images": {}}, {"section_id": 6, "text": "# 6. Risk and Time \n\nThe agent of this paper exhibits an intuitive connection between risk and time, and I investigate the relationship in this section. For notational convenience in this section, we define $V_{i}(t)=V(t, i)$. The subscript is an identifier, not a partial derivative like when we previously wrote $V_{t}$. Recall that for fixed $t$, the saving rule is piecewise constant and decreasing with respect to $\\theta$, so $y$ exhibits well-defined cutoffs between the $\\theta$-values that correspond to different outputs. The cutoffs are important for understanding risk and time. Let $\\phi_{i, j}(t)$ be the maximum $\\theta$ such that an agent with $i$ resources saves $j$ of them if they reach an opportunity at $t$. Formally,\n\n$$\n\\phi_{i, j}(t)=\\max \\{\\theta: y(\\theta, t, i)=j\\}\n$$\n\nEquivalently, we may define $\\phi_{i, j}$ as the solution to\n\n$$\nu\\left(\\phi_{i, j}(t), i-j\\right)+V_{j}(t)=u\\left(\\phi_{i, j}(t), i-j+1\\right)+V_{j-1}(t)\n$$\n\nand it follows that\n\n$$\n\\phi_{i, j}=\\zeta^{-1}\\left(\\frac{V_{j}-V_{j-1}}{\\mu(i-j+1)-\\mu(i-j)}\\right)\n$$\n\nBecause $V_{j}-V_{j-1}$ is decreasing and continuous, $\\phi_{i, j}$ is also decreasing and continuous in $t$. Concavity of $V$ with respect to $x$ means that $\\phi_{i+1, j+1}<\\phi_{i, j}$, and concavity of $\\mu$ means that $\\phi_{i, j}<\\phi_{i+1, j}$. We see that $\\phi_{i, j}$ is increasing in $i$ and decreasing in $j$. At the deadline $\\phi_{i, j}(T)=0$, so the agent eventually tries to spend all their resources if they encounter an opportunity close enough to $T$.\n\nThe domain of $\\phi_{i, j}$ depends on $i$ and $j$. When $i=j$,\n\n$$\n\\phi_{i, i}=\\zeta^{-1}\\left(\\frac{V_{i}-V_{i-1}}{\\mu(1)}\\right)\n$$\n\nTheorem (12) implies that as $t$ gets big negative, the argument of $\\zeta^{-1}$ approaches 1 , so $\\phi_{i, i}$ is always well-defined. This result means that the agent always maintains a cutoff between spending nothing and spending a single unit from their resource stock. For $i<j$, the agent does not always maintain this cutoff. In the argument of $\\zeta^{-1}$ from equation (10), the numerator approaches $\\mu(1)$ away from $T$, so concavity of $\\mu$ means the argument of $\\zeta^{-1}$ eventually exceeds 1 , which makes $\\phi_{i, j}$ undefined. When I write $\\phi_{i, j}^{-1}(1)$, I refer to the minimum time $t$ where $\\phi_{i, j}$ is defined. From properties of $\\phi_{i, j}$, we see that $\\phi_{i, j}^{-1}(1)$ is increasing in $i$ and decreasing in $j$. When $t \\geq \\phi_{i+1, j}^{-1}(1)$, it is possible to compare the dynamics of $\\phi_{i, j}$ and $\\phi_{i+1, j}$. Unfortunately, there is no straightforward way to compare the dynamics of $\\phi_{i, j}$ and $\\phi_{i, j+1}$.\n\nLemma 16. Let $f$ be a smooth and strictly increasing function with $f(0)=0$. If $f$ is logconcave, then for any a such that $0<a<1$, af $\\left(f^{-1}(x)\\right)<f^{\\prime}\\left(f^{-1}(a x)\\right)$.\n\nTheorem 17. If $\\zeta$ is log-concave, then $\\phi_{i+1, j}-\\phi_{i, j}$ is strictly decreasing for all times after $\\phi_{i+1, j}^{-1}(1)$.\n\nWe can make statements about concavity if we decompose the time-derivatives $V_{i}^{\\prime}$ into a formulation that is easier to work with. Recall that $V_{i}^{\\prime}$ is the negative of the area below all maximand-components and above $V_{i}$ when we graph everything on the probability space $[0,1]$. We decompose this area into separate contributions from each maximand-component. When $\\theta$ falls between $\\phi_{i, j+1}$ and $\\phi_{i, j}$, the agent elects to save $j$ resources, and the region corresponding to $V_{i}^{\\prime}$ has height $u(\\theta, i-j)+V_{j}-V_{i}$. By adding and subtracting different $\\Delta u$ and $\\Delta V$ terms, we can write $V_{i}^{\\prime}$ as a sum of integrals that telescope a varying number of times on each region between consecutive cutpoints. We have\n\n$$\n\\begin{aligned}\nV_{i}^{\\prime} & =-\\sum_{k=0}^{i-1} \\int_{\\phi_{i, i-k}}^{1}\\left[u(\\theta, k+1)+V_{i-k-1}-u(\\theta, k)-V_{i-k}\\right] d \\theta \\\\\n& =-\\sum_{k=0}^{i-1}[\\mu(k+1)-\\mu(k)] \\int_{\\phi_{i, i-k}}^{1}\\left[\\zeta(\\theta)-\\frac{V_{i-k}-V_{i-k-1}}{\\mu(k+1)-\\mu(k)}\\right] d \\theta\n\\end{aligned}\n$$\n\nI am implicitly assuming that we evaluate only the terms of the sum where $\\phi_{i, i-k}$ is defined. Where it is defined, $\\phi_{i, i-k}$ satisfies\n\n$$\n\\zeta\\left(\\phi_{i, i-k}\\right)=\\frac{V_{i-k}-V_{i-k-1}}{\\mu(k+1)-\\mu(k)}\n$$\n\nso the integral measures the area under $\\zeta$ above $\\zeta\\left(\\phi_{i, i-k}\\right)$.\nIf we integrate along the vertical axis instead of the horizontal axis, $V_{i}^{\\prime}$ becomes simpler, and we end up with\n\n$$\nV_{i}^{\\prime}=-\\sum_{k=0}^{i-1}[\\mu(k+1)-\\mu(k)] \\int_{\\min \\left\\{\\frac{V_{i-k}-V_{i-k-1}}{\\mu(k+1)-\\mu(k)}, 1\\right\\}}^{1}\\left(1-\\zeta^{-1}(y)\\right) d y\n$$\n\nSubtracting consecutive $V_{i}^{\\prime}$ values gives us a differential equation for $\\Delta V_{t}$.\n\n$$\n\\begin{gathered}\nV_{i+1}^{\\prime}-V_{i}^{\\prime}=-\\sum_{k=0}^{i-1}[\\mu(k+1)-\\mu(k)] \\int_{\\min \\left\\{\\frac{V_{i-k}-V_{i-k-1}}{\\mu(k+1)-\\mu(k)}, 1\\right\\}}^{\\min \\left\\{\\frac{V_{i+1-k}-V_{i-k}}{\\mu(k+1)-\\mu(k)}, 1\\right\\}}\\left(1-\\zeta^{-1}(y)\\right) d y \\\\\n-\\left[\\mu(i+1)-\\mu(i)\\right] \\int_{\\min \\left\\{\\frac{V_{i}}{\\mu(i+1)-\\mu(i)}, 1\\right\\}}^{1}\\left(1-\\zeta^{-1}(y)\\right) d y\n\\end{gathered}\n$$\n\nEquation (11) allows us to easily compare marginal valuations under more or less concave utility functions.\n\nTheorem 18. Consider an agent with a divisible resource. If $w$ is more concave than $u$ with respect to $\\theta$, then for any $i, V_{i+1}-V_{i}<W_{i+1}-W_{i}$, where $W$ is the valuation that corresponds to $w$.\n\nTheorem 18 means that the agent's marginal value of an extra resource is greater when the agent has more concave utility with respect to $\\theta$. Greater marginal value translates to an agent who is less responsive to high-quality opportunities and more responsive to low quality opportunities. Let $\\psi_{i, j}$ be the $(i, j)$-cutoff corresponding to $W$. Lemma 5 implies that in a neighborhood of $T, \\psi_{i, j}<\\phi_{i, j}$. However, suppose $j<i$, and consider the time $t=\\psi_{i, j}^{-1}(1)>-\\infty$. We know that\n\n$$\n\\begin{aligned}\n\\phi_{i, j}(t) & =\\zeta^{-1}\\left(\\frac{V_{j}-V_{j-1}}{\\mu(i-j+1)-\\mu(i-j)}\\right) \\\\\n& <\\zeta^{-1}\\left(\\frac{W_{j}-W_{j-1}}{\\mu(i-j+1)-\\mu(i-j)}\\right)=\\zeta^{-1}(1)=1=\\psi_{i, j}(t)\n\\end{aligned}\n$$\n\nso the cutoffs cross over. The less risk-averse agent is willing to spend more resources sooner but only at high-quality opportunities, and this agent is more responsive to large $\\theta$-values.\n\nThis setup lends itself to a model of procrastination where the agent misperceives their instantaneous utility function and overestimates their eagerness to spend resources. The agent correctly sees the output value of $u(\\theta, x-y)$ after spending $x-y$ resources, but I assume the agent does not have other information about their own utility function or the realized $\\theta$. Suppose that instead of $\\zeta$, the agent believes their instantaneous utility function is $\\tilde{\\zeta}$, where $\\tilde{\\zeta}$ is more concave than $\\zeta$. Whenever the agent reaches an opportunity with quality $\\theta$, they believe it has quality $\\tilde{\\theta}=\\tilde{\\zeta}^{-1}(\\zeta(\\theta))$. If they spend $x-y$ resources, the agent believes they are receiving $\\tilde{\\zeta}(\\tilde{\\theta}) \\mu(x-y)=u(\\theta, x-y)$ instantaneous utility. The agent decides to spend resources according to the solution for $\\tilde{\\zeta}$, so they save $j$ resources if $\\tilde{\\theta}<\\tilde{\\phi}_{i, j}$, where $\\tilde{\\phi}_{i, j}$ is the $(i, j)$-cutoff under $\\tilde{\\zeta}$.\n\nIn terms of $\\theta$ rather than $\\tilde{\\theta}$, this cutoff is\n\n$$\n\\begin{aligned}\n\\tilde{\\zeta}^{-1}(\\zeta(\\theta))=\\tilde{\\theta}<\\tilde{\\phi}_{i, j} & =\\tilde{\\zeta}^{-1}\\left(\\frac{\\tilde{V}_{j}-\\tilde{V}_{j-1}}{\\mu(i-j+1)-\\mu(i-j)}\\right) \\\\\n\\zeta(\\theta) & <\\frac{\\tilde{V}_{j}-\\tilde{V}_{j-1}}{\\mu(i-j+1)-\\mu(i-j)} \\\\\n\\theta & <\\zeta^{-1}\\left(\\frac{\\tilde{V}_{j}-\\tilde{V}_{j-1}}{\\mu(i-j+1)-\\mu(i-j)}\\right)\n\\end{aligned}\n$$\n\nAs we saw in equation (10), a fully informed agent saves $j$ resources when\n\n$$\n\\theta<\\zeta^{-1}\\left(\\frac{V_{j}-V_{j-1}}{\\mu(i-j+1)-\\mu(i-j)}\\right)\n$$\n\nBecause $\\tilde{\\zeta}$ is more concave than $\\zeta$, the marginal value $\\tilde{V}_{j}-\\tilde{V}_{j-1}$ is greater than $V_{j}-V_{j-1}$, so the procrastinating agent uses a saving rule that is too high. The agent always spends less than they would if they perceived their utility function correctly, which delays spending.", "tables": {}, "images": {}}, {"section_id": 7, "text": "# 7. Conclusion \n\nI constructed a rational agent who spends resources at random opportunities between current time $t$ and some future deadline $T$. The agent's value function is relatively simple, but the agent exhibits intuitive and interesting properties. The agent's valuation $V$ is positive, decreasing in $t$, and increasing in $x$, and the same is true of the saving rule $y$. Further, $V$ is concave in both variables, and the marginal value with respect to time gets more negative as $x$ increases. In the limit away from the deadline, the agent plans to spend each unit of $x$ separately at an opportunity with large $\\theta$, so $V(t, x)$ has a horizontal asymptote at $x \\mu(1)$. Because the agent feels less time pressure away from the deadline, they will pick a later-larger reward over a smaller-sooner reward, but the agent reverses this choice near $T$, which constitutes a static preference reversal. The agent exhibits both correlation aversion and monotonicity with respect to payment timing. Connecting risk and time is sensible, and doing so produces a model of an agent who procrastinates because they misperceive their own utility function. These solution properties describe an agent who is very aware of the passage of time and plans accordingly to meet deadline pressure. More research is needed to test these ideas empirically and to determine whether they lead to a more general model of time preference, apart from deadlines.", "tables": {}, "images": {}}, {"section_id": 8, "text": "# References \n\nAase, Knut K. 2021. \"Elements of Economics of Uncertainty and Time with Recursive Utility.\" NHH Dept. of Business and Management Science Discussion Paper No. 2020/13.\n\nAlbers, Susanne and Leon Ladewig. 2021. \"New Results for the $k$-Secretary Problem.\" Theoretical Computer Science 863: 102-119.\n\nAndersen, Steffen, Glenn W. Harrison, Morten I. Lau, and E. Elisabet Rutstrom. 2008. \"Eliciting Risk and Time Preferences.\" Econometrica 76: 583-618.\n\nAndersen, Steffen, Glenn W. Harrison, Morten I. Lau, and Elisabet Rutstr\u00f6m. 2018. \"Multiattribute Utility Theory, Intertemporal Utility, and Correlation Aversion.\" International Economic Review 59: 537-555.\n\nAndreoni, James and Charles Sprenger. 2012. \"Estimating Time Preferences from Convex Budgets.\" American Economic Review 102: 3333-3356.\n\nApestegu\u00eda, Jose, Miguel A. Ballester, and Angelo Guti\u00e9rrez. 2019. \"Random Models for the Joint Treatment of Risk and Time Preferences.\" Economics Working Paper Series, No. 1671.\n\nArefeva, Alina and Delong Meng. 2017. \"How to Set a Deadline for Auctioning a House?\" Working Paper.\n\nAugenblick, Ned and Matthew Rabin. 2019. \"An Experiment on Time Preference and Misprediction in Unpleasant Tasks.\" Review of Economic Studies 86: 941-975.\n\nBabaioff, Moche, et al. 2009. \"Secretary Problems: Weights and Discounts.\" In Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms, 1245-1254.\n\nBabaioff, Moshe, Nicole Immorlica, David Kempe, and Robert Kleinberg. 2007. \"A Knapsack Secretary Problem with Applications.\" In Approximation, Randomization, and Combinatorial Optimization: Algorithms and Techniques, 16-28. 10th International Workshop, APPROX 2007 and 11th International Workshop, RANDOM 2007. Berlin: Springer.\n\nBalakrishnan, Uttara, Johannes Haushofer, and Pamela Jakiela. 2020. \"How Soon Is Now? Evidence of Present Bias from Convex Time Budget Experiments.\" Experimental Economics 23: 294-321.\n\nBearden, J. Neil. 2006. \"A New Secretary Problem with Rank-Based Selection and Cardinal Payoffs.\" Journal of Mathematical Psychology 50: 58-59.\n\nBernedo Del Carpio, Mar\u00eda, Francisco Alpizar, and Paul J. Ferraro. 2022. \"Time and Risk Preferences of Individuals, Married Couples and Unrelated Pairs.\" Journal of Behavioral and Experimental Economics 97: 101794.\n\nBisin, Alberto and Kyle Hyndman. 2020. \"Present-Bias, Procrastination, and Deadlines in a Field Experiment.\" Games and Economic Behavior 119: 339-357.\n\nBizzotto, Jacopo, Jesper R\u00fcdiger, and Adrien Vigier. 2021. \"Dynamic Persuasion with Outside Information.\" American Economic Journal: Microeconomics 13: 179-194.\n\nBlavatskyy, Pavlo R. 2016. \"A Monotone Model of Intertemporal Choice.\" Economic Theory 62: 785-812.\n\nBlavatskyy, Pavlo R. and Hela Maafi. 2020. \"A New Test of Convexity-Concavity of Discount Function.\" Theory and Decision 89: 121-136.\n\nBommier, Antoine, Asen Kochov, and Fran\u00e7ois Le Grand. 2017. \"On Monotone Recursive Preferences.\" Econometrica 85: 1433-1466.\n\nBreig, Zachary, Matthew Gibson, and Jeffrey G. Shrader. 2020. \"Why Do We Procrastinate? Present Bias and Optimism.\" Working Paper.\n\nBrown, Alexander L., Yuiyi Gui, and Hyundam Je. 2022. \"Preferences for the Resolution of Risk and Ambiguity.\"\n\nBrunnemeier, Markus K., Filippos Papakonstantinou, and Jonathan A. Parker. 2017. \"Optimal Time-Inconsistent Beliefs: Misplanning, Procrastination, and Commitment.\" Management Science 63: 1318-1340.\n\nCacchiani, Valentina, Manuel Iori, Alberto Locatelli, and Silvano Martello. 2022a. \"Knapsack Problems-An Overview of Recent Advances. Part I: Single Knapsack Problems.\" Computers 8 Operations Research 143: 105692.\n\u2014_. 2022b. \"Knapsack Problems-An Overview of Recent Advances. Part II: Multiple, Multidimensional, and Quadratic Knapsack Problems.\" Computers 8 Operations Research 143: 105693 .\n\nChakraborty, Anjuit, Yoram Halevy, and Kota Saito. 2020. \"The Relation between Behavior under Risk and over Time.\" American Economic Review: Insights 2: 1-16.\n\nChen, Shou, Richard Fu, Lei Wedge, and Ziran Zou. 2019. \"Non-Hyperbolic Discounting and Dynamic Preference Reversal.\" Theory and Decision 86: 183-302.\n\nCheung, Stephen L. 2020. \"Eliciting Utility Curvature in Time Preference.\" Experimental Economics 23: 493-525.\n\nCoey, Dominic, Bradley J. Larsen, and Brennan C. Platt. 2020. \"Discounts and Deadlines in Consumer Search.\" American Economic Review 110: 3748-3785.\n\nCohen, John, Keith Marzilli Ericson, Daivd Laibson, and John Myles White. 2020. \"Measuring Time Preferences.\" Journal of Economic Literature 58: 299-347.\n\nCordes, Charlotte, Jana Friedrichsen, and Simeon Shudy. 2024. \"Motivated Procrastination.\" CESifo Working Paper No. 11072.\nde Castro, Luciano, Antonio F. Galvao, Montes-Rojas, and Jose Olmo. 2023. \"Joint Elicitation of Elasticity of Intertemporal Substitution, Risk and Time Preferences.\" International Journal of Finance 8 Economics 29: 1-22.\n\nDemers, Simon. 2019. \"The Duration of Optimal Stopping Probabilities.\" ArXiv:1810.11557.\n\nDiecidue, Enrico, Hj\u00f6rdis HardardotTir, and Marco Islam. 2023. \"Why Do People Discount? The Role of Impatience and Future Uncertainty.\" INSEAD Working Paper No. 2023/08/DSC.\n\nEmanuel, Aviv, Maayan Katzir, and Nira Liberman. 2022. \"Why Do People Increase Effort Near a Deadline? An Opportunity-Cost Model of Goal Gradients.\" Journal of Experimental Psychology: General 151: 2910-2926.\n\nEpper, Thomas F. and Helga Fehr-Duda. 2024. \"Risk in Time: The Intertwined Nature of Risk Taking and Time Discounting.\" Journal of the European Economic Association 22: $310-354$.\n\nEpstein, Larry G. and Stanley E. Zin. 1989. \"Substitution, Risk Aversion, and the Temporal Behavior of Consumption and Asset Returns: A Theoretical Framework.\" Econometrica 57: 937-969.\n\nEricson, Keith Marzilli and David Laibson. 2019. \"Intertemporal Choice.\" In Handbook of Behavioral Economics-Foundations and Applications 2, edited by B. Douglas Bernheim, Stefano DellaVigna, and David Laibson, 1-67. Amsterdam: North-Holland.\n\nEvren, \u00d6zg\u00fcr. 2019. \"Recursive Non-Expected Utility: Connecting Ambiguity Attitudes to Risk Preferences and the Level of Ambiguity.\" Games and Economic Behavior 114: 285307 .\n\nFahrenwaldt, Matthias Albrecht, Ninna Reitzel Jensen, and Mogens Steffensen. 2020. \"Nonrecursive Separation of Risk and Time Preferences.\" Journal of Mathematical Economics 90: 95-108.\n\nFalk, Armin and Florian Zimmermann. 2016. \"Beliefs and Utility: Experimental Evidence on Preferences for Information.\" CESifo Working Paper No. 6061.\n\nFedyk, Anastassia. 2024. \"Asymmetric Naivete: Beliefs about Self-Control.\" Working Paper.\n\nGnedin, Alexander. 2022. \"The Best Choice Problem with Random Arrivals: How to Beat the 1/e-Strategy.\" Stochastic Processes and Their Applications 145: 226-140.\n\nGreen, Brett and Curtis R. Taylor. 2016. \"Breakthroughs, Deadlines and Self-Reported Progress: Contracting for Multistage Projects.\" American Economic Review 106: 3660-3699.\n\nGul, Faruk, Paulo Natenzon, and Wolfgang Pesendorfer. 2021. \"Random Evolving Lotteries and Instrinsic Preference for Information.\" Econometrica 89: 2225-2259.\n\nHalevy, Yoram. 2015. \"Time Consistency: Stationarity and Time Invariance.\" Econometrica 83: $335-352$.\n\nHeidhues, Paul, Botond K\u00f6szegi, and Philipp Strack. 2024. \"Misinterpreting Yourself.\" Working Paper.\n\nHeidhues, Paul and Philipp Strack. 2021. \"Identifying Present Bias from the Timing of Choices.\" American Economic Review 111: 2594-2622.\n\nHoefer, Martin and Bojana Kodric. 2017. \"Combinatorial Secretary Problems with Ordinal Information.\" ArXiv:1702.01290.\n\nHolden, Stein T., Mesfin Tilahun, and Dag E. Sommervoll. 2022. \"Is Diminishing Impatience in Time-Dated Risky Prospects Explained by Probability Weighting?\" Centre for Land Tenure Studies Working Paper, No. 03/22.\n\nHyndman, Kyle and Alberto Bisin. 2022. \"Procrastination, Self-Inposed Deadlines, and Other Commitment Devices.\" Economic Theory 74: 871-897.\n\nJagga, Shobhit, Narayanan Srinivasan, and Nisheeth Srivastava. 2021. \"Modeling Procrastination as Rational Metareasoning about Task Effort.\" Proceedings of the Annual Meeting of the Cognitive Science Society 43: 2004-2009.\n\nJones, Brant. 2020. \"Weighted Games of Best Choice.\" SIAM Journal on Discrete Mathematics 34: 399-414.\n\nKarag\u00f6zo\u011flu, Emin and Martin G. Kocher. 2019. \"Bargaining under Time Pressure from Deadlines.\" Experimental Economics 22: 419-440.\n\nKaufmann, Marc. 2022. \"Projection Bias in Effort Choices.\" Games and Economic Behavior 135: 368-393.\n\nKemel, Emmanuel and Corina Paraschiv. 2023. \"Risking the Future? Measuring Risk Attitudes towards Delayed Consequences.\" Journal of Economic Behavior and Organization 208: 325-344.\n\nKochov, Asen and Yangwei Song. 2023. \"Intertemporal Hedging and Trade in Repeated Games with Recursive Utility.\" Econometrica 91: 2333-2369.\n\nKoopmans, Tjalling C. 1960. \"Stationary Ordinal Utility and Impatience.\" Econometrica 28: 287-309.\n\nKreps, David M. and Evan L. Porteus. 1978. \"Temporal Resolution of Uncertainty and Dynamic Choice Theory.\" Econometrica 46: 185-200.\n\nKuutila, Miikka, Mika M\u00c4ntyl\u00e4, Umar Farooq, and Ma\u00eblick Claes. 2020. \"Time Pressure in Software Engineering: A Systematic Review.\" Information and Software Technology 121: 106257.\n\nLambert, Tamara, Keith L. Jones, Joseph F. Brazel, and D. Scott Showalter. 2017. \"Audit Time Pressure and Earnings Quality: An Examination of Accelerated Filings.\" Accounting, Organizations and Society 58: 50-66.\n\nLampe, Immanuel and Matthias Weber. 2021. \"Intertemporal Propsect Theory.\" Working Papers on Finance No. 2021/09.\n\nLaU, C. Oscar. 2019. \"Disentangling Intertemporal Substitution and Risk Aversion Under the Expected Utility Theorem.\" The B.E. Journal of Theoretical Economics, 20160150.\n\nLi, Jian. 2020. \"Preference for Partial Information and Ambiguity.\" Theoretical Economics 15: $1059-1094$.\n\nLiu, Xujun and OlgiCA Milenkovic. 2022. \"Finding the Second-Best Candidate under the Mallows Model.\" Theoretical Computer Science 929: 39-68.\n\nLiu, Xujun, OlgiCA Milenkovic, and George V. Moustakides. 2023. \"Query-Based Selection of Optimal Candidates under the Mallows Model.\" Theoretical Computer Science 979: 104206 .\n\nMadsen, Eric. 2022. \"Designing Deadlines.\" American Economic Review 112: 963-997.\nMeissner, Thomas and Philipp Pfeiffer. 2022. \"Measuring Preferences over the Temporal Resolution of Consumption Uncertainty.\" Journal of Economic Theory 200: 105379.\n\nMierendorff, Konrad. 2016. \"Optimal Dynamic Mechanism Design with Deadlines.\" Journal of Economic Theory 161: 190-222.\n\nAl-Najjar, Nabil I. and Eran Shmaya. 2019. \"Recursive Utility and Parameter Uncertainty.\" Journal of Economic Theory 181: 274-288.\n\nNielsen, Kirby. 2020. \"Preferences for the Resolution of Uncertainty and the Timing of Information.\" Journal of Economic Theory 189: 105090.\n\nNiU, MingZI. 2023. \"Procrastination and Commitment.\" Working Paper.\nRohde, Kirsten I. M. and Xiao Yu. 2024. \"Intertemporal Correlation Aversion-A Model-Free Measurement.\" Management Science 70: 3493-3509.\n\nSaito, Kota. 2015. \"A Relationship between Risk and Time Preferences.\" Working Paper.\nSamuelson, Paul A. 1937. \"A Note on Measurement of Utility.\" The Review of Economic Studies 4: $155-161$.\n\nSornasundaram, Jeeva and Vincent Eli. 2022. \"Risk and Time Preferences Interaction: An Experimental Measurement.\" Journal of Risk and Uncertainty 65: 215-238.\n\nStanca, Lorenzo. 2023. \"Recursive Preferences, Correlation Aversion, and the Temporal Resolution of Uncertainty.\" ArXiv:2304.04599.\n\nSun, Chen and Jan Potters. 2022. \"Magnitude Effect in Intertemporal Allocation Tasks.\" Experimental Economics 25: 593-623.\n\nThimme, Julian. 2017. \"Intemporal Substitution in Consumption: A Literature Review.\" Journal of Economic Surveys 31: 226-257.\n\nZhang, Shunmin and Tingyong Feng. 2020. \"Modeling Procrastination: Asymmetric Decisions to Act Between the Present and the Future.\" Journal of Experimental Psychology: General 149: 311-322.\n\nZhang, Sili. 2021. \"Times Are Changing: Projective Misperceptions and Misinferred Time Preferences.\" Working Paper.", "tables": {}, "images": {}}, {"section_id": 9, "text": "# Mathematical Appendix \n\nThis section contains proofs of the theorems and lemmas in the paper.\nTheorem 1. Suppose $k>0$, and let $V$ be the value function for an agent with instantaneous utility $u$. For an agent with utility ku, the value function is $k V$, and the spending rule remains unchanged.\n\nProof. Suppose $V$ solves the Bellman equation with instantaneous utility $u$. Integrals are linear operators, and maximization commutes with multiplication by a positive constant. If we multiply equation (2) by $k$, we get\n\n$$\nk V(t, x)=\\int_{t}^{T} \\mathbb{E} \\max \\{k u(\\theta, x-y)+k V(s, y)\\} \\lambda e^{\\lambda(t-s)} d s\n$$\n\nso it follows that $k V$ solves the Bellman equation with instantaneous utility $k u$.\nTheorem 2. When $t<T$ and $x>0, V$ is positive, strictly decreasing in $t$, and strictly increasing in $x$.\n\nProof. It is clear from equation (3) that $V$ is non-strictly decreasing. Let $y^{*}(\\theta, t, x)$ be the saving rule. It follows that\n\n$$\n\\begin{aligned}\nV(t, x) & =\\int_{t}^{T} \\mathbb{E}\\left\\{u\\left(\\theta, x-y^{*}(\\theta, s, x)\\right)+V\\left(s, y^{*}(\\theta, s, x)\\right)\\right\\} \\lambda e^{\\lambda(t-s)} d s \\\\\n& \\leq \\int_{t}^{T} \\mathbb{E}\\left\\{u\\left(\\theta, x-y^{*}(\\theta, s, x)\\right)+V\\left(t, y^{*}(\\theta, s, x)\\right)\\right\\} \\lambda e^{\\lambda(t-s)} d s \\\\\n& \\leq \\int_{t}^{T} \\mathbb{E} \\max \\{u(\\theta, x-y)+V(t, y)\\} \\lambda e^{\\lambda(t-s)} d s \\\\\n& =\\mathbb{E} \\max \\{u(\\theta, x-y)+V(t, y)\\} \\int_{t}^{T} \\lambda e^{\\lambda(t-s)} d s \\\\\n& <\\mathbb{E} \\max \\{u(\\theta, x-y)+V(t, y)\\}\n\\end{aligned}\n$$\n\nso $V$ is strictly decreasing in time, assuming $x>0$. Positivity follows. To show increasing in $x$, let $\\Delta x>0$. Then\n\n$$\n\\begin{aligned}\nV(t, x) & =\\int_{t}^{T} \\mathbb{E}\\left\\{u\\left(\\theta, x-y^{*}(\\theta, s, x)\\right)+V\\left(s, y^{*}(\\theta, s, x)\\right)\\right\\} \\lambda e^{\\lambda(t-s)} d s \\\\\n& <\\int_{t}^{T} \\mathbb{E}\\left\\{u\\left(\\theta, x+\\Delta x-y^{*}(\\theta, s, x)\\right)+V\\left(s, y^{*}(\\theta, s, x)\\right)\\right\\} \\lambda e^{\\lambda(t-s)} d s \\\\\n& \\leq \\int_{t}^{T} \\mathbb{E} \\max _{0 \\leq y \\leq x+\\Delta x}\\{u(\\theta, x+\\Delta x-y)+V(s, y)\\} \\lambda e^{\\lambda(t-s)} d s=V(t, x+\\Delta x)\n\\end{aligned}\n$$\n\nWhen $t=T$ or $x=0, V$ is identically 0 .\nTheorem 3. When the agent has a single resource, $V$ is concave.\n\nProof. If $t_{1}<t_{2}$, then $V\\left(t_{1}\\right)>V\\left(t_{2}\\right)$. This means $\\phi\\left(t_{1}\\right)=u^{-1}\\left(V\\left(t_{1}\\right)\\right)>u^{-1}\\left(V\\left(t_{2}\\right)\\right)=\\phi\\left(t_{2}\\right)$, so we have\n\n$$\nV^{\\prime}\\left(t_{1}\\right)=-\\int_{\\phi\\left(t_{1}\\right)}^{1} u(\\theta)-\\phi\\left(t_{1}\\right) d \\theta>-\\int_{\\phi\\left(t_{1}\\right)}^{1} u(\\theta)-\\phi\\left(t_{2}\\right) d \\theta\n$$\n\nThe integrand is positive, so reducing the lower bound makes the integral greater. The minus sign reverses this change, and we have\n\n$$\nV^{\\prime}\\left(t_{1}\\right)>-\\int_{\\phi\\left(t_{2}\\right)}^{1} u(\\theta)-\\phi\\left(t_{2}\\right) d \\theta=V^{\\prime}\\left(t_{2}\\right)\n$$\n\nThis means the derivative is decreasing in $t$, so $V$ is concave.\nLemma 4. Let $y$ and $z$ satisfy differential equations $y^{\\prime}=f(t, y)$ and $z^{\\prime}=g(t, z)$ with $f$ and $g$ negative, and suppose $y(T)=z(T)=0$. If $f<g<0$, then for $t<T, y(t)>z(t)$.\nProof. There exists a neighborhood of $T$ where $z<y$. Suppose $z<y$ on the interval $(t, T)$. We will show that for some $\\epsilon>0$, the inequality holds on $(t-\\epsilon, T)$, and we will use this fact to show that the inequality holds everywhere. We know that $z(t) \\leq y(t)$ by assumption. If the inequality is strict, we're done. Otherwise, assume that $z(t)=y(t)$. From the mean value theorem, we know that for any $\\delta>0$, there exists a $c$ such that\n\n$$\n\\frac{z(t+\\delta)-z(t)}{y(t+\\delta)-y(t)}=\\frac{z^{\\prime}(c)}{y^{\\prime}(c)}\n$$\n\nWe assumed that $z(t+\\delta)<y(t+\\delta)$, so the quotient must be greater than 1 . It follows that\n\n$$\n\\lim _{\\delta \\rightarrow 0} \\frac{z^{\\prime}(c)}{y^{\\prime}(c)}=\\frac{z^{\\prime}(t)}{y^{\\prime}(t)} \\geq 1\n$$\n\nso $z^{\\prime}(t) \\leq y^{\\prime}(t)$. (We switch the inequality sign because $y^{\\prime}<0$.) But if $z(t)=y(t)$, then $y^{\\prime}(t)=f(t, y(t))<g(t, z(t))=z^{\\prime}(t)$. By contrapositive, we cannot have $y(t)=z(t)$.\n\nNow let $E$ be the set of points in $(-\\infty, T)$ where $z \\geq y$. We know that $E$ is bounded above by $T$, so let $c=\\sup E$. We know that $c<T$, so $z<y$ on $(c, T)$. However, we also know that for any interval $(t, T)$ where $z<y$, the inequality holds on a larger interval containing $(t, T)$. It follows that $c$ can't exist, and $z<y$ everywhere.\nLemma 5. Let $f$ and $g$ be increasing functions defined on the interval $[a, b]$. If $f$ is more concave than $g$, than for any $x$,\n\n$$\n\\int_{x}^{b} \\frac{f(s)-f(x)}{f^{\\prime}(x)} d s<\\int_{x}^{b} \\frac{g(s)-g(x)}{g^{\\prime}(x)} d s\n$$\n\nProof. From properties of concavity, we know that $g^{\\prime}(x) / f^{\\prime}(x)$ is increasing in $x$. This means that for any $r>x$,\n\n$$\n\\frac{g^{\\prime}(x)}{f^{\\prime}(x)}<\\frac{g^{\\prime}(r)}{f^{\\prime}(r)} \\quad \\Rightarrow \\quad \\frac{f^{\\prime}(r)}{f^{\\prime}(x)}<\\frac{g^{\\prime}(r)}{g^{\\prime}(x)}\n$$\n\nWe have\n\n$$\n\\int_{x}^{b} \\frac{f(s)-f(x)}{f^{\\prime}(x)} d s=\\int_{x}^{b} \\int_{x}^{s} \\frac{f^{\\prime}(r)}{f^{\\prime}(x)} d r d s<\\int_{x}^{b} \\int_{x}^{s} \\frac{g^{\\prime}(r)}{g^{\\prime}(x)} d r d s=\\int_{x}^{b} \\frac{g(s)-g(x)}{g^{\\prime}(x)} d s\n$$\n\nTheorem 6. Consider an agent with a single resource. If $w$ is more concave than $u$, then $V(t)<W(t)$ and $\\psi(t)<\\phi(t)$.\n\nProof. We begin by comparing value functions. Consider $t_{1}$ and $t_{2}$ such that $V\\left(t_{1}\\right)=W\\left(t_{2}\\right)$. By assumption, $u<v$, so\n\n$$\n\\begin{aligned}\nV^{\\prime}\\left(t_{1}\\right) & =-\\int_{u^{-1}\\left(V\\left(t_{1}\\right)\\right)}^{1} u(\\theta)-V\\left(t_{1}\\right) d \\theta \\\\\n& >-\\int_{u^{-1}\\left(V\\left(t_{1}\\right)\\right)}^{1} v(\\theta)-V\\left(t_{1}\\right) d \\theta \\\\\n& >-\\int_{v^{-1}\\left(V\\left(t_{1}\\right)\\right)}^{1} v(\\theta)-V\\left(t_{1}\\right) d \\theta \\\\\n& =-\\int_{v^{-1}\\left(W\\left(t_{2}\\right)\\right)}^{1} v(\\theta)-W\\left(t_{2}\\right) d \\theta=W^{\\prime}\\left(t_{2}\\right)\n\\end{aligned}\n$$\n\nLemma 4 implies that $V<W$.\nFor cutpoints, recall that $\\phi=u^{-1}(V)$ and $\\psi=v^{-1}(W)$. We have\n\n$$\n\\phi^{\\prime}=\\frac{V^{\\prime}}{u^{\\prime} \\circ u^{-1}(V)}=\\frac{V^{\\prime}}{u^{\\prime}(\\phi)} \\quad \\psi^{\\prime}=\\frac{W^{\\prime}}{v^{\\prime} \\circ v^{-1}(W)}=\\frac{W^{\\prime}}{v^{\\prime}(\\psi)}\n$$\n\nNow consider $t_{1}$ an $t_{2}$ such that $\\phi\\left(t_{1}\\right)=\\psi\\left(t_{2}\\right)$. We see that\n\n$$\n\\begin{aligned}\n\\phi^{\\prime}\\left(t_{1}\\right) & =\\frac{V^{\\prime}\\left(t_{1}\\right)}{u^{\\prime}\\left(\\phi\\left(t_{1}\\right)\\right)} & \\psi^{\\prime}\\left(t_{2}\\right) & =\\frac{W^{\\prime}\\left(t_{2}\\right)}{v^{\\prime}\\left(\\psi\\left(t_{2}\\right)\\right)} \\\\\n& =-\\frac{1}{u^{\\prime}\\left(\\phi\\left(t_{1}\\right)\\right)} \\int_{\\phi\\left(t_{1}\\right)}^{1} u(\\theta)-u\\left(\\phi\\left(t_{1}\\right)\\right) & =-\\frac{1}{v^{\\prime}\\left(\\psi\\left(t_{2}\\right)\\right)} \\int_{\\psi\\left(t_{2}\\right)}^{1} v(\\theta)-v\\left(\\psi\\left(t_{2}\\right)\\right)\n\\end{aligned}\n$$\n\nLemma 5 implies that $\\phi^{\\prime}\\left(t_{1}\\right)<\\psi^{\\prime}\\left(t_{2}\\right)$, and applying Lemma 4 gives us $\\psi<\\phi$.\nLemma 7. Let $D$ be a discrete set, and let $I$ be an interval. Suppose that $f$ is a function defined on $[0,1] \\times I \\times D$ that is continuously differentiable in its first two arguments. Let $\\beta:[0,1] \\times I \\rightarrow D$ be well behaved in the following sense: for any number $p$ in the interval $I$, the restriction $\\left.\\beta\\right|_{p}$ is piecewise constant on $[0,1]$, and for any point $(s, p)$ such that $\\left.\\beta\\right|_{p}$ is locally constant at $s, \\beta$ is locally constant at $(s, p)$. Then\n\n$$\n\\frac{d}{d p} \\int_{0}^{1} f(s, p, \\beta(s, p)) d s=\\left.\\int_{0}^{1} \\frac{\\partial f}{\\partial p}\\right|_{s, p, \\beta(s, p)} d s\n$$\n\nProof. Fix $p$, and let $E$ be the set of points where $\\left.\\beta\\right|_{p}$ jumps. By assumption, $E$ is finite and therefore measure 0 . Therefore\n\n$$\n\\begin{aligned}\n\\frac{d}{d p} \\int_{0}^{1} f(s, p, \\beta(s, p)) d s & =\\frac{d}{d p} \\int_{E^{c}} f(s, p, \\beta(s, p)) d s \\\\\n& =\\int_{E^{c}} \\frac{d}{d p} f(s, p, \\beta(s, p)) d s\n\\end{aligned}\n$$\n\n$$\n=\\int_{E^{c}} \\lim _{h \\rightarrow 0} \\frac{f(s, p+h, \\beta(s, p+h))-f(s, p, \\beta(s, p))}{h} d s\n$$\n\nBy definition of $E^{c}$, for any $s$ in the region of integration, $\\beta$ is locally constant at $(s, p)$. This means that for purposes of calculating the limit, we can replace $\\beta(s, p+h)$ with $\\beta(s, p)$, and we end up with\n\n$$\n\\begin{aligned}\n\\frac{d}{d p} \\int_{0}^{1} f(s, p, \\beta(s, p)) d s & =\\int_{E^{c}} \\lim _{h \\rightarrow 0} \\frac{f(s, p+h, \\beta(s, p))-f(s, p, \\beta(s, p))}{h} d s \\\\\n& =\\left.\\int_{E^{c}} \\frac{\\partial f}{\\partial p}\\right|_{s, p, \\beta(s, p)} d s=\\left.\\int_{0}^{1} \\frac{\\partial f}{\\partial p}\\right|_{s, p, \\beta(s, p)} d s\n\\end{aligned}\n$$\n\nwhere we freely add $E$ back into the domain of integration because $E$ has measure 0 .\nLemma 8. Let $f$ and $g$ be strictly increasing and strictly concave functions defined on the natural numbers with $f(0)=g(0)=0$. Then $h(x)=\\max _{y}\\{f(x-y)+g(y)\\}$ is also strictly increasing and, assuming generic $f$ and $g$, strictly concave. Further, $\\max \\{\\Delta f(x), \\Delta g(x)\\} \\leq$ $\\max \\left\\{\\Delta f\\left(x-y^{*}\\right), \\Delta g\\left(y^{*}\\right)\\right\\}=\\Delta h(x)$, where $y^{*}$ is the optimum for $h(x)$. If $y^{*}$ satisfies $0<y^{*}<x$, then the inequality is strict.\n\nProof. We take it as obvious that $h(0)=0$. Consider the sequences of discrete derivatives $F=(\\Delta f(i))_{i}$ and $G=(\\Delta g(i))_{i}$. From concavity of $f$ and $g$, these sequences are strictly decreasing, and for generic $f$ and $g$, no two elements from different sequences are equal. It follows that we can interlace $F$ and $G$ to create a new sequence $A$ of differences that is strictly decreasing, and the value of $h(x)$ will be the sum of the first $x$ elements of $A$. If $A_{i}$ is the $i$ th element of $A$, then $\\Delta h(x)=A_{x}>0$, so $h$ is strictly decreasing. Because $A$ is strictly decreasing, $h$ is strictly concave. The differences $\\Delta f(x)$ and $\\Delta g(x)$ are the $x$ th elements of $F$ and $G$ respectively. Because $A$ contains exactly the elements of $F$ and $G$ in descending order, it must be the case that $F_{x}$ and $G_{x}$ appear in $A$ on or after position $x$. This means $\\max \\{\\Delta f(x), \\Delta g(x)\\}=\\max \\left\\{F_{x}, G_{x}\\right\\} \\leq A_{x}=\\max \\left\\{\\Delta f\\left(x-y^{*}\\right), \\Delta g\\left(y^{*}\\right)\\right\\}=\\Delta h(x)$. When $0<y^{*}<x$, the first $x$ elements of $A$ contain elements from both $F$ and $G$, so $F_{x}$ and $G_{x}$ appear in $A$ after position $x$. Strictness of the inequality follows in that case.\n\nLemma 9. If $\\left\\{f_{i}\\right\\}$ is a family of positive, increasing, discrete, and strictly concave functions indexed by $i \\in[0,1]$, then\n\n$$\n\\int_{0}^{1} f_{i} d i\n$$\n\nis also positive, increasing, discrete, and concave.\nProof. Discreteness is obvious. Positivity and increasing follow from monotonicity of the integral. To show concavity, let $x_{1}<x_{2}$. Then for any $i, \\Delta f\\left(x_{2}\\right)<\\Delta f\\left(x_{1}\\right)$, and\n\n$$\n\\left.\\left(\\Delta \\int_{0}^{1} f_{i} d i\\right)\\right|_{x_{2}}=\\int_{0}^{1} \\Delta f_{i}\\left(x_{2}\\right) d i<\\int_{0}^{1} \\Delta f_{i}\\left(x_{1}\\right) d i=\\left.\\left(\\Delta \\int_{0}^{1} f_{i} d i\\right)\\right|_{x_{1}}\n$$\n\nTheorem 10. Assume the agent's resources are divisible as described in this section. Then $V$ is concave in both arguments, and $\\Delta V_{t}<0$. Here $V_{t}$ is the partial derivative of $V$ with respect to $t$, and $\\Delta$ means discrete derivative with respect to $x$.\n\nProof. We know that $V_{t}(T)=-\\lambda \\mathbb{E} u(\\theta, x)$, so strict concavity of $\\mu$ means that $V$ is strictly concave with respect to $x$ in a neighborhood of $T$. Suppose that $V$ is strictly concave with respect to $x$ on the interval $(t, T)$. Consider some time $s$ satisfying $t<s<T$. For all but at most a countable number of quality values $\\theta$, the functions $u(\\theta, x)$ and $V(s, x)$ will satisfy the assumptions of Lemma 8 , and Lemma 9 means that $\\mathbb{E} \\max \\{u(\\theta, x-y)+V(s, y)\\}$ is strictly concave. If $x_{1}<x_{2}$, we have\n\n$$\n\\begin{aligned}\n\\Delta V\\left(t, x_{1}\\right) & =\\int_{t}^{T} \\Delta \\mathbb{E} \\max \\left\\{u\\left(\\theta, x_{1}-y\\right)+V(s, y)\\right\\} \\lambda e^{\\lambda(t-s)} d s \\\\\n& >\\int_{t}^{T} \\Delta \\mathbb{E} \\max \\left\\{u\\left(\\theta, x_{2}-y\\right)+V(s, y)\\right\\} \\lambda e^{\\lambda(t-s)} d s=\\Delta V\\left(t, x_{2}\\right)\n\\end{aligned}\n$$\n\nso $V$ is also strictly concave at $t$. This means there exists an interval $(t-\\epsilon, T)$ where $V$ is strictly concave with respect to $x$, and the result follows for the same reasoning as in the proof of Lemma 4.\n\nNow consider $\\Delta V_{t}(t, x)=\\lambda(\\Delta V(t, x)-\\mathbb{E} \\Delta \\max \\{u(\\theta, x-y)+V(t, y)\\})$. From Lemma 8 , we know that $\\Delta V_{t} \\leq 0$. If $0<y^{*}<x$ with positive probability, where $y^{*}$ is the saving rule, then the inequality will be strict. Let $\\underline{\\phi}$ be the cutoff between spending nothing and spending one resource, and let $\\bar{\\phi}$ be the cutoff between spending $n-1$ and $n$ resources. From equation (10), we have\n\n$$\n\\underline{\\phi}=\\zeta^{-1}\\left(\\frac{V(t, n)-V(t, n-1)}{\\mu(1)}\\right) \\quad \\bar{\\phi}=\\zeta^{-1}\\left(\\frac{V(t, 1)}{\\mu(n)-\\mu(n-1)}\\right)\n$$\n\nConcavity of $V$ means the numerator of $\\underline{\\phi}$ is less than the numerator of $\\bar{\\phi}$, and concavity of $\\mu$ means the denominator is greater. It follows that $\\underline{\\phi}<\\bar{\\phi}$, so $\\Delta V_{t}<0$.\n\nLet $y^{*}$ be the saving rule. We can write equation (3) as\n\n$$\n\\left.\\frac{d V}{d t}\\right|_{(t, x)}=\\lambda\\left(V(t, x)-\\mathbb{E} u\\left(\\theta, x-y^{*}\\right)-V\\left(t, y^{*}\\right)\\right)\n$$\n\nDifferentiating with respect to $t$ and applying Lemma 7 gives us equation (6). Because $\\bar{\\phi}>0$, $y^{*}<x$ with positive probability, so $\\Delta V_{t}<0$ implies $V_{t}(t, x)<\\mathbb{E} V_{t}\\left(t, y^{*}\\right)$. It follows that $V$ is concave in $t$.\n\nCorollary 11. The saving rule $y$ is non-strictly decreasing with respect to $t$. (Equivalently, $x-y$ is increasing in t.) Both $y$ and $x-y$ are non-strictly increasing with respect to $x$.\n\nProof. Let $y^{*}$ be the output of the spending rule for $t_{1}, \\theta$, and $x$. Consider $t_{2}>t_{1}$, and suppose $y^{*}<i$. By assumption, we have\n\n$$\nu(\\theta, x-i)+V\\left(t_{1}, i\\right) \\leq u\\left(\\theta, x-y^{*}\\right)+V\\left(t_{1}, y^{*}\\right)\n$$\n\nand from Theorem 10, we know\n\n$$\nV\\left(t_{2}, i\\right)-V\\left(t_{1}, i\\right)<V\\left(t_{2}, y^{*}\\right)-V\\left(t_{2}, y^{*}\\right)\n$$\n\nIf we add these inequalities together, it follows that\n\n$$\nu(\\theta, x-i)+V\\left(t_{2}, i\\right)<u\\left(\\theta, x-y^{*}\\right)+V\\left(t_{2}, y^{*}\\right)\n$$\n\nso $y^{*}$ cannot be increasing in $t$.\nThe second part of this corollary is equivalent to the statement that when $x$ increases by $1, y$ increases by 0 or 1 . This result follows from the same reasoning as in the proof of Lemma 8. Suppose that $y^{*}$ is the saving rule for $t, \\theta$, and $x$, and we increase $x$ by 1 resource. Then we have\n\n$$\n\\Delta \\max _{y}\\{u(\\theta, x-y)+V(t, y)\\}=\\max \\left\\{\\Delta u\\left(\\theta, x-y^{*}\\right), \\Delta V\\left(t, y^{*}\\right)\\right\\}\n$$\n\nwhere $\\Delta$ means discrete derivative in $x$ as usual. Consider the right side of equation (12). If the first element of the maximand is larger, then increasing $x$ by 1 resource leaves $y$ unchanged, so $y(\\theta, t, x+1)=y^{*}$. If the second element of the maximand is larger, increasing $x$ also increases $y$, and we get $y(\\theta, t, x+1)=y^{*}+1$.\n\nTheorem 12. For an agent with a divisible resource, $\\lim _{t \\rightarrow-\\infty} V(t, x)=x \\mu(1)$.\nProof. We know this property is true for $x=1$ because $\\mu(1)$ is the smallest nullcline of equation (3) in this case. Suppose the result holds for $x-1$ or fewer resources, and we will show it must hold for $x$. We have by assumption that for any $y<x, u(\\theta, x-y)+V(t, y)<x \\mu(1)$, and it follows that $V(t, x)=x \\mu(1)$ is a nullcline of equation (3). Now consider any $k<x \\mu(1)$. By assumption, when $t$ is far away from $T, V(t, x-1) \\approx(x-1) \\mu(1)$, and when $\\theta$ is close to 1 , $u(\\theta, 1) \\approx \\mu(1)$. It follows that there must exist some $t$ such that $u(\\theta, 1)+V(t, x-1)>k$ on a set of $\\theta$-values with positive measure, so $k$ cannot be a nullcline for $V(t, x)$. This means $x \\mu(1)$ is the smallest possible nullcline for $V(t, x)$, so $V(t, x)$ must be asymptotic to $x \\mu(1)$.\n\nTheorem 13. An agent with a divisible resource exhibits static preference reversal, and the time when the preference reversal happens is unique.\n\nProof. Consider the difference $V(t, x)-V(t+\\bar{t}, x+\\bar{x})$. When the expression is positive, the agent prefers to receive $x$ resources now, and when the expression is negative, the agent prefers to receive $x+\\bar{x}$ resources at $\\bar{t}$ time into the future. For $t=T-\\bar{t}$, the difference is clearly positive because $V((T-\\bar{t})+\\bar{t}, x+\\bar{x})=V(T, x+\\bar{x})=0$. When $t$ gets big negative, the expression is eventually negative from Theorem 12. It follows from continuity of $V$ that the agent's preference switches at some point in time. Now differentiate with respect to t . We have\n\n$$\n\\begin{aligned}\n\\frac{d}{d t} V(t, x)-V(t+\\bar{t}, x+\\bar{x}) & =V_{t}(t, x)-V_{t}(t+\\bar{t}, x+\\bar{x}) \\\\\n& =V_{t}(t, x)-V_{t}(t+\\bar{t}, x)+V_{t}(t+\\bar{t}, x)-V_{t}(t+\\bar{t}, x+\\bar{x})\n\\end{aligned}\n$$\n\nConcavity of $V$ in $t$ means $V_{t}(t, x)-V_{t}(t+\\bar{t}, x)>0$, and $\\Delta V_{t}<0$ implies that $V_{t}(t+\\bar{t}, x)-$ $V_{t}(t+\\bar{t}, x+\\bar{x})>0$. It follows that $V(t, x)-V(t+\\bar{t}, x+\\bar{x})$ is strictly increasing in $t$, so the sign change happens at a unique point in time.\n\nTheorem 14. With two random payments, the agent's expected value is strictly decreasing in the amount of correlation between the payments.\n\nProof. Correlation aversion at time $s$ is equivalent to the condition $\\tilde{V}(s, x)<V(s, x)+V(\\bar{t}, \\bar{x})$. As mentioned previously, we know that\n\n$$\n\\lim _{s \\uparrow \\bar{t}} \\tilde{V}(s, x)=V(\\bar{t}, x+\\bar{x})\n$$\n\nso near $\\bar{t}$, correlation aversion holds from strict concavity of $V$. Let $\\tilde{y}^{*}$ be the saving rule for $\\tilde{V}$ at $\\theta, s$, and $x$, and assume correlation aversion holds on the interval $(t, \\bar{t})$. Then\n\n$$\n\\begin{aligned}\n\\tilde{V}(t, x)= & \\int_{t}^{\\bar{t}} \\mathbb{E} \\max \\{u(\\theta, x-y)+V(s, y)\\} \\lambda e^{\\lambda(t-s)} d s+e^{\\lambda(t-\\bar{t})} \\tilde{V}(\\bar{t}, x+\\bar{x}) \\\\\n= & \\int_{t}^{\\bar{t}} \\mathbb{E}\\left[u\\left(\\theta, x-\\tilde{y}^{*}\\right)+\\tilde{V}\\left(s, \\tilde{y}^{*}\\right)\\right] \\lambda e^{\\lambda(t-s)} d s \\\\\n& \\quad+e^{\\lambda(t-\\bar{t})} \\tilde{V}(\\bar{t}, x+\\bar{x}) \\\\\n< & \\int_{t}^{\\bar{t}} \\mathbb{E}\\left[u\\left(\\theta, x-\\tilde{y}^{*}\\right)+V\\left(s, \\tilde{y}^{*}\\right)+V(\\bar{t}, \\bar{x})\\right] \\lambda e^{\\lambda(t-s)} d s \\\\\n& \\quad+e^{\\lambda(t-\\bar{t})} \\tilde{V}(\\bar{t}, x+\\bar{x}) \\\\\n= & \\int_{t}^{\\bar{t}} \\mathbb{E}\\left[u\\left(\\theta, x-\\tilde{y}^{*}\\right)+V\\left(s, \\tilde{y}^{*}\\right)\\right] \\lambda e^{\\lambda(t-s)} d s+\\left(1-e^{\\lambda(t-\\bar{t})}\\right) V(\\bar{t}, \\bar{x}) \\\\\n& \\quad+e^{\\lambda(t-\\bar{t})}[V(\\bar{t}, x)+V(\\bar{t}, \\bar{x})] \\\\\n= & \\int_{t}^{\\bar{t}} \\mathbb{E}\\left[u\\left(\\theta, x-\\tilde{y}^{*}\\right)+V\\left(s, \\tilde{y}^{*}\\right)\\right] \\lambda e^{\\lambda(t-s)} d s+V(\\bar{t}, \\bar{x})+e^{\\lambda(t-\\bar{t})} V(\\bar{t}, x) \\\\\n= & \\int_{t}^{\\bar{t}} \\mathbb{E}\\left[u\\left(\\theta, x-\\tilde{y}^{*}\\right)+V\\left(s, \\tilde{y}^{*}\\right)\\right] \\lambda e^{\\lambda(t-s)} d s+V(\\bar{t}, \\bar{x}) \\\\\n& +\\int_{\\bar{t}}^{T} \\mathbb{E} \\max \\{u(\\theta, x-y)+V(s, \\tilde{y})\\} \\lambda e^{\\lambda(t-s)} d s \\\\\n\\leq & V(t, x)+V(\\bar{t}, \\bar{x})\n\\end{aligned}\n$$\n\nThis means that there exists some $\\epsilon>0$ such that correlation aversion holds on $(t-\\epsilon, \\bar{t})$. For the same reasoning from the end of the proof of Lemma 4 , we see that correlation aversion holds for all $t<\\bar{t}$.\n\nTheorem 15. At time $t$, the valuation of the agent's current resource stock plus a future payment at $\\bar{t}$ strictly decreases as $\\bar{t}$ gets larger starting from $\\bar{t}=t$.\n\nProof. The value of the agent's resource stock is given by $\\tilde{V}\\left(t, x+\\bar{x} \\chi_{[\\bar{t}, T]}(t)\\right)$, where $\\chi$ is an indicator function. Changing $\\bar{t}$ means that we change not only when the agent receives an extra $\\bar{x}$ resources but also when the agent expects to receive these resources, so for notational clarity, we add a third argument $\\bar{t}$ to $\\tilde{V}$. The third argument tracks when the agent expects the additional payment to happen. If we differentiate $\\tilde{V}$ with respect to $\\bar{t}$, we have\n\n$$\n\\frac{d}{d \\bar{t}} \\tilde{V}\\left(t, x+\\bar{x} \\chi_{[\\bar{t}, T]}(t), \\bar{t}\\right)=\\lim _{h \\rightarrow 0} \\frac{V\\left(t, x+\\bar{x} \\chi_{[\\bar{t}+h, T]}(t), \\bar{t}+h\\right)-V\\left(t, x+\\bar{x} \\chi_{[\\bar{t}, T]}(t), \\bar{t}\\right)}{h}\n$$\n\n$$\n\\begin{aligned}\n= & \\lim _{h \\rightarrow 0} \\frac{1}{h}\\left[\\int_{t}^{\\bar{t}} \\mathbb{E} \\max \\{u(\\theta, x-y)+\\tilde{V}(s, y, \\bar{t}+h)\\} \\lambda e^{\\lambda(t-s)} d s\\right. \\\\\n& +\\int_{\\bar{t}}^{\\bar{t}+h} \\mathbb{E} \\max \\{u(\\theta, x-y)+\\tilde{V}(s, y, \\bar{t}+h)\\} \\lambda e^{\\lambda(t-s)} d s \\\\\n& -\\int_{t}^{\\bar{t}} \\mathbb{E} \\max \\{u(\\theta, x-y)+\\tilde{V}(s, y, \\bar{t})\\} \\lambda e^{\\lambda(t-s)} d s \\\\\n& \\left.-\\int_{t}^{\\bar{t}} \\mathbb{E} \\max \\{u(\\theta, x+\\bar{x}-y)+\\tilde{V}(s, y, \\bar{t})\\} \\lambda e^{\\lambda(t-s)} d s\\right] \\\\\n= & \\int_{t}^{\\bar{t}} \\mathbb{E} \\lim _{t \\rightarrow 0} \\frac{1}{h}[\\max \\{u(\\theta, x-y)+\\tilde{V}(s, y, \\bar{t}+h)\\} \\\\\n& -\\max \\{u(\\theta, x-y)+\\tilde{V}(s, y, \\bar{t})\\}] \\lambda e^{\\lambda(t-s)} d s \\\\\n& +\\lim _{h \\rightarrow 0} \\frac{1}{h} \\int_{\\bar{t}}^{\\bar{t}+h} \\mathbb{E} \\max \\{u(\\theta, x-y)+\\tilde{V}(s, y, \\bar{t}+h)\\} \\lambda e^{\\lambda(t-s)} d s \\\\\n& -\\lim _{h \\rightarrow 0} \\frac{1}{h} \\int_{\\bar{t}}^{\\bar{t}+h} \\mathbb{E} \\max \\{u(\\theta, x+\\bar{x}-y)+\\tilde{V}(s, y, \\bar{t})\\} \\lambda e^{\\lambda(t-s)} d s \\\\\n= & \\int_{t}^{\\bar{t}} \\mathbb{E}\\left[\\frac{d}{d t} \\max \\{u(\\theta, x-y)+\\tilde{V}(s, y, \\bar{t})\\}\\right] \\lambda e^{\\lambda(t-s)} d s \\\\\n& +\\mathbb{E} \\max _{0 \\leq y \\leq x}\\{u(\\theta, x-y)+V(\\bar{t}, \\bar{x}+y)\\} \\lambda e^{\\lambda(t-\\bar{t})} \\\\\n& -\\mathbb{E} \\max _{0 \\leq y \\leq x+\\bar{x}}\\{u(\\theta, x+\\bar{x}-y)+V(\\bar{t}, y)\\} \\lambda e^{\\lambda(t-\\bar{t})}\n\\end{aligned}\n$$\n\nApplying Lemma 7 gives us\n\n$$\n\\begin{aligned}\n\\frac{d}{d \\bar{t}} \\tilde{V}(t, x+\\bar{x} \\chi_{[\\bar{t}, T]}(t))= & \\int_{t}^{\\bar{t}} \\mathbb{E}\\left[\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{s, y^{*}}\\right] \\lambda e^{\\lambda(t-s)} d s \\\\\n& +\\mathbb{E} \\max _{0 \\leq y \\leq x}\\{u(\\theta, x-y)+V(\\bar{t}, \\bar{x}+y)\\} \\lambda e^{\\lambda(t-\\bar{t})} \\\\\n& -\\mathbb{E} \\max _{0 \\leq y \\leq x+\\bar{x}}\\{u(\\theta, x+\\bar{x}-y)+V(\\bar{t}, y)\\} \\lambda e^{\\lambda(t-\\bar{t})}\n\\end{aligned}\n$$\n\nDifferentiating both sides with respect to $t$ gives us equation (8). For reference, that equation is\n\n$$\n\\left.\\frac{d}{d t}\\left(\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, x}\\right)=\\left.\\lambda \\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, x}-\\lambda \\mathbb{E}\\left[\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, y^{*}}\\right] e^{\\lambda(t-\\bar{t})}\n$$\n\nwith initial condition\n\n$$\n\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{\\bar{t}, x}=\\lambda \\mathbb{E} \\max _{0 \\leq y \\leq x}\\{u(\\theta, x-y)+V(\\bar{t}, \\bar{x}+y)\\}-\\lambda \\mathbb{E} \\max _{0 \\leq y \\leq x+\\bar{x}}\\{u(\\theta, x+\\bar{x}-y)+V(\\bar{t}, y)\\}\n$$\n\nConsider first the case where $x=0$. Then $y^{*}=0$, and\n\n$$\n\\frac{d}{d t}\\left(\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, 0}\\right)=\\left.\\lambda \\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, 0}-\\left.\\lambda \\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, 0} e^{\\lambda(t-\\bar{t})}=\\lambda\\left(1-e^{\\lambda(t-\\bar{t})} \\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, 0}\n$$\n\nIn this case, $d \\tilde{V} / d \\bar{t}=0$ is a nullcline of the differential equation, so $d \\tilde{V} / d \\bar{t}$ never changes sign. The inital condition is\n\n$$\n\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{\\bar{t}, 0}=\\lambda V(\\bar{t}, \\bar{x})-\\lambda \\mathbb{E} \\max _{0 \\leq y \\leq \\bar{x}}\\{u(\\theta, \\bar{x}-y)+V(\\bar{t}, y)\\}=V_{t}(\\bar{t}, \\bar{x})<0\n$$\n\nso $d \\tilde{V} / d \\bar{t}$ is always negative when $x=0$.\nNow we induct on $x$. Assume $d \\tilde{V} / d \\bar{t}$ is always negative when the agent starts with $x-1$ or fewer resources. Consider the situation where $d \\tilde{V} / d \\bar{t}=0$. Then\n\n$$\n\\frac{d}{d t}\\left(\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, x}\\right)=-\\lambda \\mathbb{E}\\left[\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{t, y^{*}}\\right] e^{\\lambda(t-\\bar{t})}\n$$\n\nwhich is positive by the induction hypothesis since $y^{*}<x$ with positive probability. It follows that the positive real numbers is an attracting region for $d \\tilde{V} / d \\bar{t}$. On the other hand, suppose $y^{*}$ maximizes $u(\\theta, x-y)+V(\\bar{t}, \\bar{x}+y)$. Then the initial condition becomes\n\n$$\n\\begin{aligned}\n\\left.\\frac{d \\tilde{V}}{d \\bar{t}}\\right|_{\\bar{t}, x}= & \\lambda \\mathbb{E}\\left[u\\left(\\theta, x-y^{*}\\right)+V\\left(\\bar{t}, \\bar{x}+y^{*}\\right)\\right] \\\\\n& -\\lambda \\mathbb{E} \\max _{0 \\leq y \\leq x+\\bar{x}}\\{u(\\theta, x+\\bar{x}-y)+V(\\bar{t}, y)\\} \\\\\n\\leq & \\lambda \\mathbb{E}\\left[u\\left(\\theta, x-y^{*}\\right)+V\\left(\\bar{t}, \\bar{x}+y^{*}\\right)\\right] \\\\\n& -\\lambda \\mathbb{E}\\left[u\\left(\\theta, x+\\bar{x}-\\left[y^{*}+\\bar{x}\\right]\\right)+V\\left(\\bar{t}, y^{*}+\\bar{x}\\right)\\right]=0\n\\end{aligned}\n$$\n\nIt follows that when the agent has $x$ resources and when $t<\\bar{t}$, we have $d \\tilde{V} / d \\bar{t}<0$. So the result holds for all $x$.\n\nLemma 16. Let $f$ be a smooth and strictly increasing function with $f(0)=0$. If $f$ is logconcave, then for any a such that $0<a<1$, $a f^{\\prime}\\left(f^{-1}(x)\\right)<f^{\\prime}\\left(f^{-1}(a x)\\right)$.\n\nProof. By definition, a function $f$ is log-concave if $\\log f$ is concave. We have\n\n$$\n\\frac{d^{2}}{d x^{2}} \\log f=\\frac{d}{d x}\\left(\\frac{f^{\\prime}}{f}\\right)=\\frac{f^{\\prime \\prime} f-\\left(f^{\\prime}\\right)^{2}}{f^{2}}<0\n$$\n\nThis means $f^{\\prime \\prime} f<\\left(f^{\\prime}\\right)^{2}$, and composing both sides with $f^{-1}$ on the right gives us\n\n$$\n\\begin{gathered}\nx f^{\\prime \\prime} \\circ f^{-1}(x)<\\left[f^{\\prime} \\circ f^{-1}(x)\\right]^{2} \\\\\n\\frac{d}{d x} f^{\\prime} \\circ f^{-1}(x)=\\frac{f^{\\prime \\prime} \\circ f^{-1}(x)}{f^{\\prime} \\circ f^{-1}(x)}<\\frac{f^{\\prime} \\circ f^{-1}(x)}{x}\n\\end{gathered}\n$$\n\nIt follows that at any point $x$, the derivative of $f^{\\prime} \\circ f^{-1}$ is smaller than the slope of the segment from the origin to $\\left(x, f^{\\prime} \\circ f^{-1}(x)\\right)$. I claim this means that the graph of $f^{\\prime} \\circ f^{-1}$ lies above every segment from the origin to a point on the graph of $f^{\\prime} \\circ f^{-1}$. Suppose we have points $x$ and $y$ such that $0<y<x$, and $f^{\\prime} \\circ f^{-1}(y)$ is below the segment between the origin and $f^{\\prime} \\circ f^{-1}(x)$. Define\n\n$$\nz=\\sup \\left\\{p: 0<p<x \\text { and } f^{\\prime} \\circ f^{-1}(p)<\\frac{p}{x} f^{\\prime} \\circ f^{-1}(x)\\right\\}\n$$\n\nThis set is nonempty (because of $y$ ) and bounded above by $x$, so $z$ exists. It must be the case that\n\n$$\nf^{\\prime} \\circ f^{-1}(z)=\\frac{z}{x} f^{\\prime} \\circ f^{-1}(x)\n$$\n\nIf $z=x$, this equation is true trivially. For $z<x$, if $f^{\\prime} \\circ f^{-1}(z)<(z / x) f^{\\prime} \\circ f^{-1}(x)$, then this inequality holds in a neighborhood of $z$, so $z$ cannot be the supremum. It follows that we have equality at $z$. At the same time, there exists a sequence $\\left(p_{i}\\right)$ that converges to $z$ such that this inequality holds at each $p_{i}$. This means that\n\n$$\n\\begin{aligned}\n\\frac{d}{d z} f^{\\prime} \\circ f^{-1}(z) & =\\lim _{i \\rightarrow \\infty} \\frac{f^{\\prime} \\circ f^{-1}(z)-f^{\\prime} \\circ f^{-1}\\left(p_{i}\\right)}{z-p_{i}} \\\\\n& \\geq \\lim _{i \\rightarrow \\infty} \\frac{f^{\\prime} \\circ f^{-1}(z)-\\left(p_{i} / x\\right) f^{\\prime} \\circ f^{-1}(x)}{z-p_{i}} \\\\\n& =\\lim _{i \\rightarrow \\infty} \\frac{(z / x) f^{\\prime} \\circ f^{-1}(x)-\\left(p_{i} / x\\right) f^{\\prime} \\circ f^{-1}(x)}{z-p_{i}} \\\\\n& =\\frac{f^{\\prime} \\circ f^{-1}(x)}{x}=\\frac{f^{\\prime} \\circ f^{-1}(z)}{z}\n\\end{aligned}\n$$\n\nLog-concavity implies the opposite inequality is true, so by contrapositive, $y$ cannot exist. We conclude that the graph of $f^{\\prime} \\circ f^{-1}$ does in fact lie above every segment between the origin and any point on the graph of $f^{\\prime} \\circ f^{-1}$. In mathematical symbols, we write that property as $a f^{\\prime} \\circ f^{-1}(x)<f^{\\prime} \\circ f^{-1}(a x)$, which is exactly what we want to prove.\n\nTheorem 17. If $\\zeta$ is log-concave, then $\\phi_{i+1, j}-\\phi_{i, j}$ is strictly decreasing for all times after $\\phi_{i+1, j}^{-1}(1)$.\n\nProof. We know that\n\n$$\n\\begin{aligned}\n\\zeta\\left(\\phi_{i, j}\\right)[\\mu(i-j+1)-\\mu(i-j)] & =\\zeta\\left(\\phi_{i+1, j}\\right)[\\mu(i-j+2)-\\mu(i-j+1)] \\\\\n\\zeta\\left(\\phi_{i, j}\\right) & =\\zeta\\left(\\phi_{i+1, j}\\right) \\frac{\\mu(i-j+2)-\\mu(i-j+1)}{\\mu(i-j+1)-\\mu(i-j)} \\\\\n\\phi_{i, j} & =\\zeta^{-1}\\left(\\zeta\\left(\\phi_{i+1, j}\\right) \\frac{\\mu(i-j+2)-\\mu(i-j+1)}{\\mu(i-j+1)-\\mu(i-j)}\\right)\n\\end{aligned}\n$$\n\nIf we write $a=\\Delta \\mu(i-j+1) / \\Delta \\mu(i-j)$, then $0<a<1$, and we have $\\phi_{i, j}=\\zeta^{-1}\\left(a \\zeta\\left(\\phi_{i+1, j}\\right)\\right)$. Now consider $\\phi_{i+1, j}-\\phi_{i, j}$. Differentiating gives us\n\n$$\n\\frac{d}{d t} \\phi_{i+1, j}-\\phi_{i, j}=\\frac{d}{d t} \\phi_{i+1, j}-\\zeta^{-1}\\left(a \\zeta\\left(\\phi_{i+1, j}\\right)\\right)\n$$\n\n$$\n\\begin{aligned}\n& =\\phi_{i+1, j}^{\\prime}-\\frac{a \\zeta^{\\prime}\\left(\\phi_{i+1, j}\\right)}{\\zeta^{\\prime} \\circ \\zeta^{-1}\\left(a \\zeta\\left(\\phi_{i+1, j}\\right)\\right)} \\phi_{i+1, j}^{\\prime} \\\\\n& =\\phi_{i+1, j}^{\\prime}\\left[1-\\frac{a \\zeta^{\\prime}\\left(\\phi_{i+1, j}\\right)}{\\zeta^{\\prime} \\circ \\zeta^{-1}\\left(a \\zeta\\left(\\phi_{i+1, j}\\right)\\right)}\\right]\n\\end{aligned}\n$$\n\nFrom Lemma 16, the term inside brackets is positive if $\\zeta$ is log-concave. Because $\\phi_{i+1, j}$ is decreasing, its derivative is negative, so the product must be negative. It follows that $\\phi_{i+1, j}-\\phi_{i, j}$ is strictly decreasing.\n\nTheorem 18. Consider an agent with a divisible resource. If $w$ is more concave than $u$ with respect to $\\theta$, then for any $i, V_{i+1}-V_{i}<W_{i+1}-W_{i}$, where $W$ is the valuation that corresponds to $w$.\n\nProof. Theorem 6 establishes this result for the case $i=0$. We establish the general case by induction. Suppose the result is true up to $i-1$. By performing a variable substitution on each integral, we can rewrite equation (11) as\n\n$$\n\\begin{aligned}\nV_{i+1}^{\\prime}-V_{i}^{\\prime}= & -\\sum_{k=0}^{i-1} \\int_{\\min \\left\\{V_{i-k}+V_{i-k-1}, \\mu(k+1)-\\mu(k)\\right\\}}^{\\min \\{V_{i-k}-V_{i-k}, \\mu(k+1)-\\mu(k)\\}}\\left[1-\\zeta^{-1}\\left(\\frac{y}{\\mu(k+1)-\\mu(k)}\\right)\\right] d y \\\\\n& -\\int_{\\min \\{V_{1}, \\mu(i+1)-\\mu(i)\\}}^{\\mu(i+1)-\\mu(i)\\}[1-\\zeta^{-1}\\left(\\frac{y}{\\mu(i+1)-\\mu(i)}\\right)] d y\n\\end{aligned}\n$$\n\nSuppose $k_{1}<k_{2}$. Then\n\n$$\n\\begin{aligned}\n\\Delta \\mu\\left(k_{1}\\right) & >\\Delta \\mu\\left(k_{2}\\right) \\\\\n\\frac{y}{\\Delta \\mu\\left(k_{1}\\right)} & <\\frac{y}{\\Delta \\mu\\left(k_{2}\\right)} \\\\\n1-\\zeta^{-1}\\left(\\frac{y}{\\Delta \\mu\\left(k_{1}\\right)}\\right) & >1-\\zeta^{-1}\\left(\\frac{y}{\\Delta \\mu\\left(k_{2}\\right)}\\right)\n\\end{aligned}\n$$\n\nThis means that in each successive addend from equation (13), the integrand gets smaller. At the same time, in each successive addend, the bounds $\\mu(k+1)-\\mu(k)$ in the limits of integration get smaller. It follows that for $k>0$, increasing $V_{i-k}-V_{i-k-1}$ makes the right side of equation (13) stay the same or become more negative. At the same time, replacing $\\zeta$ with a more concave function $\\xi$ also makes the right side of equation (13) more negative because\n\n$$\n\\begin{aligned}\n\\zeta & <\\xi \\\\\n\\zeta^{-1} & >\\xi^{-1} \\\\\n1-\\zeta^{-1} & <1-\\xi^{-1}\n\\end{aligned}\n$$\n\nNow consider equation (13) to be a differential equation for $V_{i+1}^{\\prime}-V_{i}^{\\prime}$. We also have an analogous differential equation for $W_{i+1}^{\\prime}-W_{i}^{\\prime}$, and by the inductive hypothesis, when $k>0$, $V_{i-k+1}-V_{i-k}<W_{i-k+1}-W_{i-k}$. Suppose at time $t, V_{i+1}-V_{i}=W_{i+1}-W_{i}$. Then\n\n$$\nV_{i+1}^{\\prime}-V_{i}^{\\prime}=-\\sum_{k=0}^{i-1} \\int_{\\min \\left\\{V_{i-k}+V_{i-k-1}, \\mu(k+1)-\\mu(k)\\right\\}}^{\\min \\{V_{i-k}-V_{i-k}, \\mu(k+1)-\\mu(k)\\}}\\left[1-\\zeta^{-1}\\left(\\frac{y}{\\mu(k+1)-\\mu(k)}\\right)\\right] d y\n$$\n\n$$\n\\begin{aligned}\n& -\\int_{\\min \\left\\{V_{1}, \\mu(i+1)-\\mu(i)\\right\\}}^{\\mu(i+1)-\\mu(i)}\\left[1-\\zeta^{-1}\\left(\\frac{y}{\\mu(i+1)-\\mu(i)}\\right)\\right] d y \\\\\n\\geq & -\\sum_{k=0}^{i-1} \\int_{\\min \\left\\{W_{i-k}-W_{i-k-1}, \\mu(k+1)-\\mu(k)\\right\\}}^{\\min \\{W_{i-k}-W_{i-k-1}, \\mu(k+1)-\\mu(k)\\}}\\left[1-\\zeta^{-1}\\left(\\frac{y}{\\mu(k+1)-\\mu(k)}\\right)\\right] d y \\\\\n& -\\int_{\\min \\{W_{1}, \\mu(i+1)-\\mu(i)\\}}^{\\mu(i+1)-\\mu(i)\\}[1-\\zeta^{-1}\\left(\\frac{y}{\\mu(i+1)-\\mu(i)}\\right)\\right] d y \\\\\n> & -\\sum_{k=0}^{i-1} \\int_{\\min \\left\\{W_{i-k+1}-W_{i-k}, \\mu(k+1)-\\mu(k)\\right\\}}^{\\min \\{W_{i-k}-W_{i-k-1}, \\mu(k+1)-\\mu(k)\\}}\\left[1-\\xi^{-1}\\left(\\frac{y}{\\mu(k+1)-\\mu(k)}\\right)\\right] d y \\\\\n& -\\int_{\\min \\{W_{1}, \\mu(i+1)-\\mu(i)\\}}^{\\mu(i+1)-\\mu(i)\\}[1-\\xi^{-1}\\left(\\frac{y}{\\mu(i+1)-\\mu(i)}\\right)\\right] d y=W_{i+1}^{\\prime}-W_{i}^{\\prime}\n\\end{aligned}\n$$\n\nThe result follows from Lemma 4.", "tables": {}, "images": {}}], "id": "2411.11828v1", "authors": ["Conrad Kosowsky"], "categories": ["econ.TH"], "abstract": "I model a rational agent who spends resources between the current time and\nsome fixed future deadline. Opportunities to spend resources arise randomly\naccording to a Poisson process, and the quality of each opportunity follows a\nuniform distribution. The agent values their current resource stock at exactly\nthe sum of expected utility from all future spending opportunities. Unlike in\ntraditional discounted expected utility models, the agent exhibits correlation\naversion, static (but not dynamic) preference reversals, and monotonicity with\nrespect to payment timing. Connecting the agent's risk and time preference is\nintuitive, and doing so leads to a new model of procrastination where the agent\nmisperceives their general attitude toward spending resources.", "updated": "2024-11-18T18:47:56Z", "published": "2024-11-18T18:47:56Z"}