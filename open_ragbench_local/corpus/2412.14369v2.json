{
  "title": "Uncertainty Awareness in Wireless Communications and Sensing",
  "sections": [
    {
      "section_id": 0,
      "text": "#### Abstract\n\nWireless communications and sensing (WCS) establish the backbone of modern information exchange and environment perception. Typical applications range from mobile networks and the Internet of Things to radar and sensor grids. Despite transformative capabilities, wireless systems often face diverse uncertainties in design and operation, such as modeling errors due to incomplete physical knowledge, statistical errors arising from data scarcity, measurement errors caused by sensor imperfections, computational errors owing to resource limitation, and unpredictability of environmental evolution. Once ignored, these uncertainties can lead to severe outcomes, e.g., performance degradation, system untrustworthiness, inefficient resource utilization, and security vulnerabilities. As such, this article reviews mature and emerging architectural, computational, and operational countermeasures, encompassing uncertainty-aware designs of signals and systems (e.g., diversity, adaptivity, modularity), as well as uncertainty-aware modeling and computational frameworks (e.g., risk-informed optimization, robust signal processing, and trustworthy machine learning). Trade-offs to employ these methods, e.g., robustness vs optimality, are also highlighted.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 1,
      "text": "## I. INTRODUCTION\n\nTHE 20th and 21st centuries have witnessed the advent, development, and maturation of wireless systems that play key roles in communications and sensing. Representative examples include cellular networks, satellite systems, Bluetooth meshes, wireless fidelity (Wi-Fi) systems, the Internet of Things (IoT), autonomous swarms, radar, and sensor networks, to name a few. These wireless systems have greatly revolutionized human society by enabling the intelligent acquisition and exchange of information, for example, high-speed data transfer, ubiquitous connectivity, environmental understanding, medical microwave imaging, and remote healthcare. The incorporation of advanced analysis and processing techniques, such as artificial intelligence and machine learning, further pushes the boundaries of wireless communications and sensing, enabling automated and high-quality data analytics, and supporting sensible and efficient decision-making [1].\n\nAlthough significant functions and capabilities have been shown, wireless systems often face numerous modeling, experimental, computational, operational, and environmental uncertainties that threaten their trustworthiness, efficiency, and security. Here, uncertainties refer to discrepancies between\n\n[^0]our knowledge and the underlying truths. These uncertainties can arise from diverse sources, for instance, channel modeling errors, sensor measurement errors, algorithmic truncation errors, network interferences and attacks, and environmental evolutions and fluctuations, respectively. In the design and operation of wireless systems, if uncertainties are ignored, the consequences can be severe in the sense of conspicuous performance degradation, system untrustworthiness, inefficient resource utilization, and security vulnerabilities. To be specific, for example, wireless signals inevitably undergo nonstationary random channel fading (e.g., time-varying Rayleigh or Rician), hardware imperfections (e.g., nonlinearities in power amplifiers, in-phase--quadrature imbalances, and phase noises), and interferences from other devices (e.g., co-channel, jamming, and network attacks), which can cause unpredictable variations in signal quality and uncontrollable errors in signal detection, estimation, and analysis, if these uncertainties are not sufficiently handled. For another example, when external environments evolve or fluctuate, the performance of employed signal processing and machine learning methods for communications and sensing may seriously degrade, if the adaptation or robustification of these methods is not addressed. Therefore, uncertainty awareness comprises a critical aspect of intelligent transmission and processing; see [2, Fig. 10].\n\nTo enhance and ensure the trustworthiness, efficiency, and security of wireless systems, great efforts have been made in the design and operation processes by both academia and industry. Aiming to illuminate the path to uncertainty-aware (UA) transmission and processing, this article reviews mature and emerging architectural, computational, and operational mitigation strategies in response to different types of uncertainties in wireless communications and sensing. We categorize the existing and developing UA treatments into two primary streams. The first stream works on reforms of UA wireless signals and systems, considering the following key factors:\n\n- Redundancy, Diversity, and Margin;\n- Feedback and Adaptivity;\n- Anomaly Detection and Handling;\n- Modularization;\n- Decentralization;\n- and Prediction and Prescription.\n\nThese solutions emphasize modifying signal characteristics (e.g., structures, parameters), system architectures, and operational strategies to enhance uncertainty awareness. The second stream focuses on enriching UA modeling and computational frameworks, emphasizing the following aspects:\n\n- Uncertainty Quantification;\n\n\n[^0]:    S. Wang, W. Dai, and G. Li are with the Department of Electrical and Electronic Engineering, Imperial College London, London SW7 2AZ, United Kingdom (E-mail: s.wang@u.nus.edu; wei.dai1@imperial.ac.uk; geoffrey.li@imperial.ac.uk); J. Sun and Z. Xu are with the School of Mathematics and Statistics, Xi'an Jiaotong University, Xi'an 710049, China. (E-mail: jy.sun@xjtu.edu.cn; zbxu@xjtu.edu.cn). (Corresponding Author: S. Wang.)\n    This work is supported by the UK Department for Science, Innovation and Technology under the Future Open Networks Research Challenge project TUDOR (Towards Ubiquitous 3D Open Resilient Network).\n\n- UA Optimization;\n- Adaptive and Robust Signal Processing;\n- and Trustworthy Machine Learning.\n\nThese solutions are particularly useful when a wireless communication or sensing problem can be formulated as an optimization, signal processing, or machine learning model.\n\nHowever, advanced system characteristics, such as adaptivity and robustness, always come with additional prices, e.g., higher design expenses, resource idling for overengineering, loss of performance optimality under ideal conditions, and extra computational burdens. Hence, in practice, balances among conflicting system features must be carefully planned. To this end, we also summarize potential trade-offs in UA wireless systems engineering.\n\nThis article is organized as follows. Section II identifies diverse sources of uncertainties in wireless communications and sensing, and highlights the necessity of uncertainty awareness. Section III outlines architectural, computational, and operational approaches to address these uncertainties. Tradeoffs in UA wireless engineering are discussed in Section IV, while concrete examples of uncertainty awareness are given in Section V. Conclusions in Section VI complete the article.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 2,
      "text": "## II. SOURCES OF UNCERTAINTIES AND NECESSITY OF UNCERTAINTY AWARENESS\n\nUncertainties arise when our knowledge deviates from the underlying truths, for example, discrepancies between modeling assumptions and physical mechanisms, between observations and actual values, between found local optimality and unknown global optimality, and between limited history data and population distribution. The more complex and dynamic a system, model, process, or population is, the more uncertainties may appear. Based on their origins, uncertainties in wireless systems can be exemplified as follows, along with the potential consequences if not properly handled.\n\nChannel Uncertainties: Channel uncertainties can be caused by modeling errors (e.g., mismatched modeling assumptions), moving objects, environmental evolutions and fluctuations, and estimation errors due to data scarcity and limited computing resources. Ignoring channel uncertainties may lead to severe repercussions, such as dead zones in mobile networks, weak connectivity, reduced or unstable signal-to-noise ratio (SNR), inter-symbol interference, frequency offsets (i.e., Doppler), and inefficient resource utilization (e.g., high spectrum and power consumption with limited performance gains).\n\nNoises, Interferences, and Attacks: In wireless systems design and operation, thermal noises, quantization noises, phase noises, co-channel interference, adjacent-channel interference, inter-system (e.g., between Bluetooth and Zigbee) interference, self-interference (e.g., in full-duplex systems), jamming, eavesdropping, spoofing, etc., are common. If unaddressed, these impairments can cause serious consequences, such as connectivity loss, SNR deterioration, increased bit-error rates, reduced target detection probability, privacy and confidentiality leakage, systemic disruption, and dropped sensing accuracy.\n\nHardware Imperfections: Despite great advances in design and manufacturing, hardware devices are unavoidably subject\nto imperfections and non-idealities that can significantly impact system performance. Aging and environmental variations are typical non-anthropogenic driving forces for hardware imperfections. Representatives include power amplifier nonlinearities, in-phase-quadrature (I/Q) imbalances, phase noises, array calibration errors, limited resolutions of converters, clock drifts, etc. Severe issues resulting from hardware imperfections encompass constellation shift and distortion, SNR reduction, system disruption, sensing inaccuracy, etc.\n\nDeployment and Configuration Uncertainties: Uncertainties in deployment arise when real-world devices and components do not exactly reach the positions for which they are planned; e.g., placement errors of base stations and access points, deployment errors of sensor nodes, array calibration errors, and swarm formation errors (e.g., in highly-maneuvering unmanned aerial vehicle networks). Uncertainties in configuration arise when operating values of parameters or inputs do not exactly match their optimal values, for example, suboptimal or improper resource allocation of spectra and power. Deployment and configuration uncertainties can lead to significant and widespread outcomes, such as coverage gaps, interference, signal degradation, suboptimal or poor quality of service, inefficient resource management, and inaccurate environmental measurements (e.g., low resolution in multitarget direction-of-arrival estimation).\n\nTiming Errors: Timing errors occur when synchronization between devices (e.g., between transmitters and receivers) is inaccurate. Such errors can arise from factors like clock drifts in oscillators, clock skews between different devices or systems, and time-quantization errors. If not properly addressed, timing errors can lead to severe cascading effects, for example, inter-symbol interference, inter-carrier interference (e.g., in orthogonal frequency-division multiplexing), synchronization failures in time-division multiple access (TDMA) or distributed networks, and poor sensing quality in time-difference-of-arrival (TDoA) and time-of-arrival (ToA) methods.\n\nVariability of Network Topology: Wireless systems are inherently dynamic, with frequently changing network topologies due to, e.g., node mobility, node availability (i.e., joining and quitting), and networking protocols. The variability of network topology poses significant challenges in maintaining stable, efficient, and reliable communication connections, further leading to deficient service quality, such as message latency and dropout. Moreover, the variability can greatly impact the accuracy of networked sensing systems because, for example, the nominal topology assumed in signal processing algorithms may deviate from the underlying actual one.\n\nVariability of Available Resources: Resource allocation for wireless communications and sensing focuses on optimizing the utilization of critical resources in time, space, spectrum, power, and computing. However, in real-world operations, accessible resources may be inexactly known. For example, devices relying on solar, wind, or radio energy harvesting can face power variability due to environmental factors such as weather or disasters. For another example, in spectra-sharing systems, such as cognitive radio and integrated sensing and communications (ISAC), the accessibility of spectral resources is highly variable due to, e.g., spectrum sensing inaccuracies,\n\nprimary user activities, interference from coexisting functions, and environmental conditions. For the third example, insufficient computing power and memory can lead to delays and denial-of-service in executing signal processing and machine learning tasks. The variability of available resources may cause significant performance degradation in wireless systems, including decreased data throughput, increased latency, unstable connection, lower reliability (e.g., frequent system disruption), deteriorated detection and estimation accuracy, etc.\n\nEnvironmental Uncertainties: Environmental uncertainties mean that the operating environment of a system is not completely known to model designers, algorithm developers, and decision makers, due to the inherent variability, uncontrollability, and unpredictability of environments. Environmental uncertainties act as causing factors of many other uncertainties, such as channel uncertainties, noises and interferences, variability of network topology, and variability of available resources. Rain, snow, humidity and temperature fluctuations, natural disasters, solar activities, space radiations, industrial electromagnetic interference (e.g., when machines start), vehicle moving, and human activities (e.g., gatherings, scatterings) are typical reasons for environmental uncertainties.\n\nAlgorithmic and Computational Errors: Algorithmic and computational errors can originate from model surrogate errors (e.g., sample-average approximation of mathematical expectation), local optimality in optimization (e.g., alternating direction method of multipliers), empirical (thus suboptimal) specifications of initial and termination conditions of iterative algorithms, numerical errors (e.g., in rounding, truncation, matrix inversion, quantization, discretization), and computational resource constraints (e.g., incomplete or delayed computations). These errors can lead to critical issues, such as unreliable predictions and decisions, inaccurate communication and sensing, system instabilities, safety risks, and insufficient management of power and spectral resources, to name a few; specific examples include localization and positioning errors, sub-optimality in resource allocation, etc. In the era of intelligent transmission and processing, as wireless systems evolve to incorporate advanced technologies like machine learning and edge computing, the risks associated with algorithmic and computational errors become progressively critical.\n\nData Scarcity: The availability of sufficient and high-quality data is essential for optimal performance in tasks such as system modeling, parameter (e.g., channel) estimation, and decision-making (e.g., pattern recognition). The scarcity of data can result from inherent system limitations (e.g., sparse sensor deployments and limited sampling rates), environmental constraints (e.g., harsh or dynamic environments), privacy and security concerns (e.g., data restriction), data aging, or high cost of data acquisition. If data scarcity is not addressed, it can lead to a range of severe consequences that undermine the effectiveness of wireless systems, including inaccurate channel estimation, unreliable signal detection and estimation (e.g., in target positioning and tracking), insufficient model calibration, limited generalization ability of decisions (e.g., in data-driven machine learning), and inadequate identification and counter ability against cyberattacks.\n\nIn summary, neglecting uncertainties in wireless systems\ncan cause significant losses of trustworthiness in terms of four critical aspects:\n\n1) Reliability: The ability to meet performance targets despite given uncertainties. For example, high reliability can mean that the likelihood of failure is below a specified threshold. In wireless communications, minimizing the outage probability is a typical example of achieving system reliability [3].\n2) Resilience: The ability to return to normal states or recover expected functionality after disruptions. In wireless communications, an excellent example is as follows: a base station can hand over connections to neighboring stations when it fails or is overloaded.\n3) Adaptivity: The ability to maintain performance by adjusting decisions, behaviors, configurations, or functionalities in response to changes in environments or conditions. In wireless communications, adaptive precoding and combining using real-time channel state information is a representative example [4], [5].\n4) Robustness: The ability to sustain performance by tolerating uncertainties; that is, the performance or output is insensitive to perturbations in parameter or input. In wireless communications and sensing, robust Capon beamforming against pointing errors and array calibration errors is a notable example [6], [7].\nTherefore, UA wireless systems engineering seeks to ensure the trustworthiness of wireless systems, including reliability, resilience, adaptivity, and robustness.\n\nThe demonstrated types of uncertainties and their corresponding hazards commonly arise, either individually or concurrently, in diverse wireless systems, such as IoT, wireless sensor networks (WSNs), mobile ad hoc networks (MANETs), and vehicular ad hoc networks (VANETs); see [8]-[10]. In practice, different uncertainties are often independently addressed. Although the taxonomy and examples above cover a broad range of wireless engineering, they are not necessarily exhaustive. Researchers and practitioners should be aware of other types of uncertainties.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 3,
      "text": "## III. Technical Treatments Against Uncertainties\n\nThis section summarizes representative strategies to combat uncertainties in wireless systems. As per the characteristics of these approaches, we group them into two categories: UA designs of signals and systems, and UA modeling and computational frameworks. Some of these methods are invented from the perspective of systems structuring and design, while others are from that of systems control and operation.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 4,
      "text": "## A. UA Designs of Signals and Systems\n\nIn wireless communications and sensing, signal characteristics (e.g., structures, parameters), system architectures, and operational strategies play a key role in uncertainty awareness. This subsection discusses the efforts in this direction.\n\n1) Redundancy, Diversity, and Margin: Redundancy and diversity are two specific approaches of overengineering, where a system or solution is designed in a more complex\n\nand resource-consuming way than minimally required. Redundancy means adding homogeneous components or parallel systems to maintain functionality in case one fails, while diversity involves using heterogeneous components or methods to mitigate the risk of common-mode failures. In cellular networks, deploying dense homogeneous base stations and employing intelligent reflective surfaces can mitigate dead-zone and shadowing effects. In wireless sensing, applying information fusion on heterogeneous sensor grids can reduce target detection, positioning, and tracking errors under various types of interference such as jamming. Channel coding methods, e.g., Hamming codes, are excellent examples of redundancy. Temporal diversity such as interleaving, spatial diversity such as multi-input multi-output (MIMO), and frequency diversity such as orthogonal frequency-division multiplexing (OFDM) are remarkable examples of diversity. Redundancy and diversity schemes can also be jointly used. For example, time redundancy (i.e., cyclic prefixes) in OFDM further enhances the reliability of information transmission. On the other hand, margin entails introducing buffering regions to the design of signals, systems, methods, etc., to suppress uncertainties. Unlike redundancy and diversity, margin does not necessarily add complexities, although it consumes additional time, spectral, or power resources as well. When transmit power is fixed, lower-order modulation schemes, e.g., quadrature phase shift keying (QPSK), have larger I/Q margins than higher-order quadrature amplitude modulation (QAM) to combat noises and interference. Guard intervals in the time domain and guard bands in the frequency domain can add margins (i.e., buffers) to account for channel uncertainties. As illustrated, redundancy, diversity, and margin in signals and systems are natural ways to ensure reliability, resilience, and robustness.\n2) Feedback and Adaptivity: Adaptivity means that a system or method can monitor its running environment or conditions, learn from shifts in the environment or changes in the conditions, and adjust its structure or operation in a real-time manner. Feedback is a key component of the adaptivity loop since it informs performance or environmental changes and guides subsequent adjustments. In wireless communications, adaptive modulation and coding leveraging channel feedback, and cognitive radio for real-time spectral sensing and allocation, are two typical examples. In wireless sensing, adaptive beamforming for target tracking exemplifies the power of adaptivity and feedback; to be specific, the beamformer can steer the main lobe toward the real-time location of the target. Fast adaptation to evolving channel states (e.g., due to changing environments) is also a trending consideration in emerging machine-learning (ML) techniques for wireless communications and signal processing [5].\n3) Anomaly Detection and Handling: Anomaly detection and handling is a mainstream approach to addressing uncertainties in the operation of a system, algorithm, or process. Specific examples include the following: a) error detection and correction codes in channel coding; b) error monitoring (using pilots) and reduction in signal detection, through techniques such as channel equalization and Doppler compensation (if large errors occur); c) intrusion detection and access control (e.g., intruder quarantining) in wireless networks; d) abnormal\nsensor detection and data imputation in sensor grids. Feedback and adaptivity represent a special case of anomaly detection and handling. Unlike feedback and adaptivity, anomaly detection and handling do not necessarily involve a feedback loop to dynamically influence the sources of errors. Instead, they may simply provide remedial solutions, such as robust methods [7], [8], [11], to mitigate or tolerate these faults.\n4) Modularization: Modularization entails breaking down a complex system into structurally smaller, functionally independent, and operationally more manageable self-contained modules. This approach can isolate issues and failures to specific modules, so it becomes easier to locate and fix problems. In addition, replacing damaged individual parts is operationally more convenient. Moreover, modularized systems are flexible for topological reconfiguration and upgrading. Therefore, modularization can naturally benefit the improvement of the system's flexibility, scalability, and resilience. Under the modularization scheme, reliability, adaptivity, and robustness can also be enhanced in the sense that UA technical treatments for an individual module are more manageable than those for the whole system. In this sense, a highly integrated information transmission and processing (ITP) system is not necessarily preferable over its modularized counterpart; the former refers to an ML-based black-box ITP system, while the latter means a canonical communications system [2, Figs. 2, 5].\n5) Decentralization: Decentralization means distributing the computing power and data storage of a network over multiple independent nodes, rather than relying on a single central node. Decentralization can improve the network's reliability, resilience, and robustness against failures and attacks because disruptions at a subgroup of nodes may not necessarily obliterate the functionality of the entire network. Moreover, decentralization can enhance the network's scalability because joining or exiting nodes may not significantly impact the workload and strategy of a single member. In centralized networks, however, the central coordinator or controller is highly influenced by topological variability. Edge computing and federated learning are typical examples of decentralization in wireless communications. In wireless sensing, decentralization can be exemplified by distributed sensor networks. To sum up, in terms of reliability, resilience, adaptivity, and robustness, the decentralized system architecture is beneficial compared to its centralized counterpart.\n6) Prediction and Prescription: Prediction and prescription is a strategy to forecast future events or behaviors and take proactive actions in advance to prevent or reduce adverse impacts. This strategy helps to maintain smooth functionality and reduce disruptions of a system or method, thus improving its reliability and robustness. For example, in ISAC systems, the incorporation of sensing functions enables base stations to forecast the positions of users, and therefore, generate predictive beams for smoother and robust quality of communications services. For another example, machine learning in network management can predict the traffic patterns in cellular networks (e.g., user demand spikes and traffic density in specific cells) using historical data, and therefore, enable proactive load balancing for better user experience in the future. For the third example, machine learning models (e.g.,\n\nTABLE I\nUnCERTainty-AwARE Optimizations\n\n![table_0](table_0)\n\nrecurrent neural networks, long short-term memory networks) can predict future channel conditions based on historical channel state information, and therefore, empower proactive resource allocation (e.g., adaptive modulation and coding, beamforming) for smoother and robust quality of communications and sensing service in the time ahead.",
      "tables": {
        "table_0": "| Name | Formulation | Remarks |\n| :--: | :--: | :--: |\n| Original Optimization | $\\min _{\\boldsymbol{x} \\in \\mathcal{X}} \\quad f(\\boldsymbol{x}, \\boldsymbol{\\xi})$ | $\\boldsymbol{x}$ : decision, $\\mathcal{X}$ : domain, $\\boldsymbol{\\xi}$ : parameter, $f$ : cost function (mostly nonnegative), $g$ : constraint function (possibly multi-output). |\n|  | s.t. $\\quad \\boldsymbol{g}(\\boldsymbol{x}, \\boldsymbol{\\xi}) \\leq \\mathbf{0}$ |  |\n| Robust Optimization | $\\min _{\\boldsymbol{x} \\in \\mathcal{X}} \\max _{\\boldsymbol{\\xi} \\in \\Xi} \\quad f(\\boldsymbol{x}, \\boldsymbol{\\xi})$ | $\\Xi$ : uncertainty set of $\\boldsymbol{\\xi}$. |\n|  | s.t. $\\quad \\max _{\\boldsymbol{\\xi} \\in \\Xi} g(\\boldsymbol{x}, \\boldsymbol{\\xi}) \\leq \\mathbf{0}$ | Philosophy: minimize worst-case cost (i.e., avoid significant performance degradation) \\& guarantee worst-case feasibility. |\n| Stochastic Optimization | $\\min _{\\boldsymbol{x} \\in \\mathcal{X}} \\quad \\mathbb{E}_{\\boldsymbol{\\xi} \\sim \\mathcal{F}_{\\boldsymbol{\\xi}}} f(\\boldsymbol{x}, \\boldsymbol{\\xi})$ | $\\mathbb{E}:$ expectation operator. |\n|  | s.t. $\\quad \\mathbb{E}_{\\boldsymbol{\\xi} \\sim \\mathcal{F}_{\\boldsymbol{\\xi}}} g(\\boldsymbol{x}, \\boldsymbol{\\xi}) \\leq \\mathbf{0}$ | Philosophy: minimize expected cost \\& guarantee expected feasibility. |\n|  |  | Sample-Average Approx. (SAA) $\\min _{\\boldsymbol{x} \\in \\mathcal{X}} \\quad \\frac{1}{n} \\sum_{i=1}^{n} f\\left(\\boldsymbol{x}, \\boldsymbol{\\xi}_{i}\\right)$ |\n|  |  | Using Samples $\\left\\{\\boldsymbol{\\xi}_{1}, \\boldsymbol{\\xi}_{2}, \\ldots, \\boldsymbol{\\xi}_{n}\\right\\} \\quad$ s.t. $\\quad \\frac{1}{n} \\sum_{i=1}^{n} g\\left(\\boldsymbol{x}, \\boldsymbol{\\xi}_{i}\\right) \\leq \\mathbf{0}$. |\n| Chance-Constrained Optimization | $\\min _{\\boldsymbol{x} \\in \\mathcal{X}} \\quad \\mathbb{E}_{\\boldsymbol{\\xi} \\sim \\mathcal{F}_{\\boldsymbol{\\xi}}} f(\\boldsymbol{x}, \\boldsymbol{\\xi})$ | $\\operatorname{Pr}_{\\boldsymbol{\\xi}}[\\cdot]$ : probability of argument event induced by random vector $\\boldsymbol{\\xi}$. |\n|  | s.t. $\\quad \\operatorname{Pr}_{\\boldsymbol{\\xi} \\sim \\mathcal{F}_{\\boldsymbol{\\xi}}}[g(\\boldsymbol{x}, \\boldsymbol{\\xi}) \\leq \\mathbf{0}] \\geq \\alpha$ | Philosophy: require the probability of feasibility to be no less than a pre-specified level $\\alpha$ (e.g., 0.95 ). |\n| Mean-Variance Optimization | $\\min _{\\boldsymbol{x} \\in \\mathcal{X}} \\quad \\mathbb{E}_{\\boldsymbol{\\xi} \\sim \\mathcal{F}_{\\boldsymbol{\\xi}}} f(\\boldsymbol{x}, \\boldsymbol{\\xi})+\\lambda_{1} \\mathbb{D}_{\\boldsymbol{\\xi} \\sim \\mathcal{F}_{\\boldsymbol{\\xi}}} f(\\boldsymbol{x}, \\boldsymbol{\\xi})$ | $\\mathbb{D}:$ variance operator, $\\lambda_{1}, \\lambda_{2}:$ trade-off parameters. |\n|  | s.t. $\\quad \\mathbb{E}_{\\boldsymbol{\\xi} \\sim \\mathcal{F}_{\\boldsymbol{\\xi}}} g(\\boldsymbol{x}, \\boldsymbol{\\xi})+\\lambda_{2} \\mathbb{D}_{\\boldsymbol{\\xi} \\sim \\mathcal{F}_{\\boldsymbol{\\xi}}} g(\\boldsymbol{x}, \\boldsymbol{\\xi}) \\leq \\mathbf{0}$ | Philosophy: minimize variances for smaller variability (i.e., higher robustness). |\n| Mean-VaR Optimization | $\\min _{\\boldsymbol{x} \\in \\mathcal{X}} \\max _{\\boldsymbol{\\xi} \\in \\mathcal{U}} f(\\boldsymbol{x}, \\boldsymbol{\\xi})+\\lambda \\operatorname{VaR}_{\\alpha}[f(\\boldsymbol{x}, \\boldsymbol{\\xi})]$ | Value-at-Risk (VaR): $\\operatorname{VaR}_{\\alpha}[h(\\eta)]:=\\inf _{\\eta} \\operatorname{Pr}_{\\eta \\sim \\mathcal{F}_{\\eta}}[h(\\eta) \\leq \\epsilon] \\geq \\alpha$. |\n|  | s.t. $\\quad$ considerations of $\\boldsymbol{g}(\\boldsymbol{x}, \\boldsymbol{\\xi})$ under $\\mathbb{P}_{\\boldsymbol{\\xi}}$ | Philosophy: minimize VaR for smaller variability (higher robustness). Considerations of $\\boldsymbol{g}(\\boldsymbol{x}, \\boldsymbol{\\xi})$ under $\\mathbb{P}_{\\boldsymbol{\\xi}}$ can be mean, variance, VaR, probability (i.e., chance-constraint), etc. |\n| Distributionally Robust Optimization | $\\min _{\\boldsymbol{x} \\in \\mathcal{X}} \\max _{\\boldsymbol{\\xi} \\in \\mathcal{U}} \\mathbb{E}_{\\boldsymbol{\\xi} \\sim \\mathcal{P}} f(\\boldsymbol{x}, \\boldsymbol{\\xi})$ | Philosophy: $\\mathbb{P}_{\\boldsymbol{\\xi}}$ is not exactly known (e.g., SAA), but included in $\\mathcal{U}$. $\\mathcal{U}:=\\{\\mathbb{P}: d(\\mathbb{P}, \\mathbb{P}) \\leq \\epsilon\\}$ : uncertainty set for $\\mathbb{P}_{\\boldsymbol{\\xi}}$, a ball centered at $\\mathbb{P}$. $\\mathbb{P}:$ a reference distribution, serving as an estimate of $\\mathbb{P}_{\\boldsymbol{\\xi}}$. |"
      },
      "images": {}
    },
    {
      "section_id": 5,
      "text": "## B. UA Modeling and Computational Frameworks\n\nWhen a wireless communication or sensing problem can be formulated as an optimization, signal processing, or machine learning model, existing analytical and computational frameworks in these domains become particularly applicable. This subsection discusses the efforts in this direction.\n\n1) Uncertainty Quantification: Let $\\boldsymbol{\\xi}$ denote a quantity of interest that takes values on real or complex coordinate spaces; for example, locations of users, channel matrices, channel noise powers, budgets of transmit power, and predicted future loads of base stations or access points. From the perspective of mathematical modeling and algorithmic computation, the initiative step of uncertainty awareness in $\\boldsymbol{\\xi}$ is to quantify uncertainties. Most prevalent treatments in this regard include the following: a) region analysis, e.g., specifying the practically smallest region $\\Xi$ on which $\\boldsymbol{\\xi}$ tasks its values; b) probability method, e.g., modeling $\\boldsymbol{\\xi}$ as a random vector or matrix that has distribution $\\mathbb{P}_{\\boldsymbol{\\xi}}$. Note that $\\Xi$ and $\\mathbb{P}_{\\boldsymbol{\\xi}}$ can also be specific to extra conditions such as time, space, and frequency; that is, $\\Xi$ and $\\mathbb{P}_{\\boldsymbol{\\xi}}$ can be time-, position-, and frequency-selective. Other less-trending uncertainty-quantification approaches encompass fuzzy logic, Dempster-Shafer evidence theory, etc. After quantifying uncertainties, handling methods such as UA optimization, adaptive and robust signal processing, and trustworthy machine learning are the next consideration.\n2) UA Optimization: Numerous communications and sensing problems can be formulated as an optimization model\n[12]; see Original Optimization in Table I. For example, $\\boldsymbol{x}$ can be a symbol vector in signal detection, a direction-of-arrival (DoA) vector in multi-target sensing, a beamformer vector in beamforming, a power control vector in resource allocation, a position vector in base-station and sensor deployment, and so on; $\\boldsymbol{\\xi}$ can denote power budgets, array steering vectors, channel matrices, constellation points, and reflection coefficients of relays or intelligent surfaces, among others.\n\nAdaptive Optimization: When the value of $\\boldsymbol{\\xi}$ is not exactly known, solving Original Optimization is not practically accessible. In this case, a natural way is to estimate its real-time value and solve the problem repeatedly whenever the value of $\\boldsymbol{\\xi}$ is updated. The estimation of $\\boldsymbol{\\xi}$ can be based on collecting more data, incorporating more expert knowledge, etc. In wireless communications, a typical example is to refine the channel state information frequently using new-coming pilots. In wireless sensing, DoA tracking is a representative instance to account for dynamic targets. In the practice of wireless engineering, the primary challenge, however, is to obtain the real-time information of $\\boldsymbol{\\xi}$ in a satisfactorily accurate manner.\n\nRobust Optimization: When the real-time value of $\\boldsymbol{\\xi}$ is difficult to be accurately estimated, another popular technical treatment is to study Robust Counterpart [7], [8], [13]; see Table I. To clarify, for all possible values of $\\boldsymbol{\\xi}$, the cost of decision $\\boldsymbol{x}$ is no larger than $\\max _{\\boldsymbol{\\xi} \\in \\Xi} f(\\boldsymbol{x}, \\boldsymbol{\\xi})$, and the feasibility of $\\boldsymbol{x}$ is always ensured. Note that $f$ and $g$ may only depend on part of $\\boldsymbol{\\xi}$; e.g., $f\\left(\\boldsymbol{x}, \\boldsymbol{\\xi}_{1}\\right)$ and $g\\left(\\boldsymbol{x}, \\boldsymbol{\\xi}_{2}\\right)$ where $\\boldsymbol{\\xi}_{1} \\in \\Xi_{1}, \\boldsymbol{\\xi}_{2} \\in \\Xi_{2}$, and $\\boldsymbol{\\xi}:=\\left[\\boldsymbol{\\xi}_{1} ; \\boldsymbol{\\xi}_{2}\\right]$. Note also that adaptivity and robustness principles can be jointly used in practice [7] because adaptive estimation can be inexact as well.\n\nStochastic Optimization: Stochastic optimization, instead of considering only the domain $\\Xi$, takes into account distribution $\\mathbb{P}_{\\boldsymbol{\\xi}}$ of $\\boldsymbol{\\xi}$ and studies expectations of random quantities $f(\\boldsymbol{x}, \\boldsymbol{\\xi})$ and $\\boldsymbol{g}(\\boldsymbol{x}, \\boldsymbol{\\xi})$; see Table I. Chance-Constrained Optimization\n\n(CCO), in contrast, requires the probability of feasibility to be no less than a pre-specified level $0 \\leq \\alpha \\leq 1$ [3], [6], [14]; see Table I. In wireless communications, studying outage probability is a particularization of CCO ; see, e.g., [3]. Since $f$ and $g$ may only depend on part of $\\boldsymbol{\\xi}$, the expectation operator $\\mathbb{E}$ or the probability operator $\\operatorname{Pr}$ can be accordingly dropped if no uncertainty is present. In addition to CCO, other variants of stochastic optimization include MeanVariance Optimization and Mean-VaR Optimization [14]; see Table I. The value-at-risk (VaR) of a random quantity $h(\\eta)$, induced by a deterministic function $h$ and another random quantity $\\eta$, at confidence level $\\alpha$, is the lower $\\alpha$-quantile of $h(\\eta)$. Minimizing VaR of $f(\\boldsymbol{x}, \\boldsymbol{\\xi})$ implies reducing its variability (i.e., increasing robustness) because cost function $f$ is nonnegative in most wireless design and operation problems; cf. minimizing variance in mean-variance optimization. Yet another variant of stochastic optimization takes into account conditional VaR (CVaR) as a risk measure where CVaR is the mean of tail values larger than VaR of $h(\\eta)$ [14]: i.e., $\\mathrm{CVaR}_{\\alpha}[h(\\eta)]:=\\mathbb{E}\\{h(\\eta)[h(\\eta) \\geq \\mathrm{VaR}_{\\alpha}[h(\\eta)]\\}$. Minimizing the CVaR of $f(\\boldsymbol{x}, \\boldsymbol{\\xi})$ can also reduce its variability, which, however, brings additional technical benefits than minimizing VaR, for example, capturing tail risk. In real-world applications, if we only have access to $n$ samples $\\left\\{\\boldsymbol{\\xi}_{1}, \\boldsymbol{\\xi}_{2}, \\ldots, \\boldsymbol{\\xi}_{n}\\right\\}$ drawn from $\\mathbb{P}_{\\boldsymbol{\\xi}}$, rather than the full knowledge $\\mathbb{P}_{\\boldsymbol{\\xi}}$ itself, the stochastic-optimization counterpart can be estimated using the sample-average approximation (SAA). Stochastic-optimization variants based on other $\\mathbb{P}_{\\boldsymbol{\\xi}}$-involved quantities, such as chanceconstraint, variance, VaR, and CVaR, can be approximated using samples similarly.\n\nDistributionally Robust Optimization: In stochastic optimization and its variants, we have assumed that the distribution $\\mathbb{P}_{\\boldsymbol{\\xi}}$ of $\\boldsymbol{\\xi}$ is exactly known. In practice, however, this assumption can be highly untenable, and only a prior guess $\\overline{\\mathbb{P}}$ of $\\mathbb{P}_{\\boldsymbol{\\xi}}$ is available. For example, $\\overline{\\mathbb{P}}$ can be the empirical distribution constructed using samples $\\left\\{\\boldsymbol{\\xi}_{1}, \\boldsymbol{\\xi}_{2}, \\ldots, \\boldsymbol{\\xi}_{n}\\right\\}$. As a result, we can consider an uncertainty set $\\mathcal{U}$ for distribution $\\mathbb{P}_{\\boldsymbol{\\xi}}$ and formulate Distributionally Robust Counterpart [11], [14]; see Table I. The uncertainty set $\\mathcal{U}$ is usually constructed using a distributional ball where $d$ is a similarity measure between two distributions $\\mathbb{P}$ and $\\overline{\\mathbb{P}}$, and $\\epsilon \\geq 0$ is the radius. Intuitively, although we do not exactly know $\\mathbb{P}_{\\boldsymbol{\\xi}}$, we assume that $\\mathbb{P}_{\\boldsymbol{\\xi}}$ is included in $\\mathcal{U}$; the more trustable the prior $\\overline{\\mathbb{P}}$ is, that is, the closer $\\overline{\\mathbb{P}}$ is to true distribution $\\mathbb{P}_{\\boldsymbol{\\xi}}$, the smaller the value of $\\epsilon$ should be. The distributionally robust counterpart for other $\\mathbb{P}_{\\boldsymbol{\\xi}}$-involved quantities, such as chance-constraint, variance, VaR, CVaR, etc., can be similarly obtained, for instance, $\\min _{\\mathbb{P} \\in \\mathcal{U}} \\operatorname{Pr}_{\\boldsymbol{\\xi} \\sim \\mathbb{P}}[\\boldsymbol{g}(\\boldsymbol{x}, \\boldsymbol{\\xi}) \\leq \\mathbf{0}] \\geq \\alpha$.\n\nObjective Deliberation: As illustrated by UA optimization techniques, such as stochastic optimization and its variants, as well as (distributionally) robust optimization, the key to uncertainty awareness is to modify the objective and constraint functions. To this end, uncertainty awareness can also be pursued from the very beginning of an optimization task, that is, to deliberate the design of objective and constraint functions. For example, in regression analysis, we can replace the mean-squared-error cost function with the Huber cost function to achieve robustness against outliers [15]. In wireless communications and sensing, the Huber cost is particularly useful in outlier-aware signal processing and machine learning for, e.g., wireless signal estimation.\n3) Adaptive and Robust Signal Processing: Typical roles of signal processing in wireless communications and sensing include data compression (e.g., source coding and decoding, rate-distortion analysis), modulation and demodulation, channel estimation and equalization, error detection and correction (e.g., channel coding and decoding), spectrum analysis (e.g., in cognitive radio), transmit beamforming (e.g., for resource allocation), receive beamforming and spatial filtering (e.g., for waveform, power, or DoA estimation), time synchronization, frequency alignment, noise and interference suppression (e.g., digital filtering), signal detection and estimation (e.g., in MIMO), waveform design, pattern recognition and target detection, information fusion (e.g., in sensor network), user behavior and station load forecasting, and target localization and tracking, among many others. A signal-processing process can be seen as a computational system or method with explicit input and output. As such, general UA principles in systems design can be used to improve the reliability, resilience, adaptivity, and robustness of a signal processing approach; specifically, these principles include the following: a) redundancy, diversity, and margin; b) feedback and adaptivity; c) anomaly detection and handling; d) modularization; e) decentralization; and f) prediction and prescription. When a signal processing problem is cast into an optimization formulation, UA optimization methods can also be considered; these methods encompass a) adaptive optimization, b) robust optimization, c) stochastic optimization and its variants, d) distributionally robust optimization, and e) objective deliberation. For concrete examples, see, e.g., [4], [7], [11], [15], [16].\n4) Trustworthy Machine Learning: Typical roles of machine learning in wireless communications and sensing can be largely covered by optimization and signal processing; for example, resource allocation, dynamic network management, beamforming, modulation, coding, signal detection and estimation, user behavior and station load prediction, target positioning and tracking, and channel estimation, compression, and feedback. The main difference is that machine learning heavily depends on historical observation data rather than physical mechanism modeling [1]. The benefit of this datadriven nature is to free scientists and engineers from frustrating modeling of a complex and dynamic physical process, real-world phenomenon, or data-generating mechanism. The drawback arises, nevertheless, when the data set is scarce (e.g., due to the fast variability of wireless environments) and the computational resources are limited (e.g., in IoT devices); the less data and computational resources that we have, the less trustable a machine learning method is. Trustworthiness in machine learning for wireless communications and sensing includes, but is beyond, reliability, resilience, adaptivity, and robustness; cf. [2, Fig. 10]. In this sense, general UA principles in systems design, optimization, and signal processing can be resorted to for trustworthy machine learning, such as redundancy, diversity, modularization, decentralization, prediction and prescription, adaptivity, robustness, objective deliberation, etc. Other trustworthiness considerations encompass explain-\n\nability (e.g., transparency, fairness) and sustainability (e.g., power efficiency, ethics), which, however, require additional technical elaborations and exceed the scope of this article.\nAd hoc technical treatments are also widely reported for trustworthy machine learning to accommodate uncertain factors; see, e.g., [17]. Typical examples include the following.\n\n- Data Engineering: to transform and augment data set. Excellent examples encompass noise injection, synonym replacement and paraphrasing of texts, rotating and flipping of images, cropping and splitting of audios, artifact interference in wireless engineering, etc.\n- Hypothesis Engineering: to choose a suitable hypothesis space to avoid overfitting. For example, for Gaussiandistributed data, linear models are optimal and therefore sufficient. The employment of highly-nonlinear neural networks, on the contrary, tends to overfit the data. In this sense, tailoring a suitable function space (e.g., a neutral network architecture) for a specific problem is crucial.\n- Algorithm Engineering: to opt for a suitable computational approach and control its execution. For example, adaptive learning (e.g., few-shot, transfer, continual), adversarial training, regularization, ensemble learning (e.g., bagging, boosting), dropout in neural network training, and tricks in stochastic gradient descent (e.g., momentum, gradient clipping, and early stopping) are typical choices.\nThe three techniques above, however, can also be incorporated into signal processing methods, e.g., [18] for noise injection.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 6,
      "text": "## IV. Prices of Uncertainty Awareness\n\nThe law of \"no free lunch\" is philosophically and technically applicable to the systems engineering of almost all real-world designs, productions, and applications. Uncertainty awareness in wireless communications and sensing is no exception. Addressing uncertainties such as noise, interference, hardware imperfections, dynamic environments, data scarcity, and computational errors often requires balancing conflicting performance metrics. To be specific, optimizing for reliability, resilience, adaptability, and robustness often comes at the expense of other critical factors like computational complexity, resource efficiency, or nominal optimality. For example, some typical trade-offs can be highlighted as follows:\n\n- Robustness vs Efficiency: Robust strategies that prioritize robustness to uncertainties, such as redundancy, diversity, and margin through employing conservative resource allocations, spectra spread, guard times, errorcorrection mechanisms, etc., often sacrifice resource efficiency because extra resources, which may remain idle, are occupied.\n- Robustness vs Complexity: By introducing overengineering techniques (e.g., redundancy and diversity) and complicated optimization formulations (e.g., Table I), the structural and computational complexities of the system, model, or method are largely increased; see [13], [14].\n- Robustness vs Optimality: Robustness against uncertainties loses nominal optimality under ideal or near-ideal conditions. To be specific, when significant uncertainties do not actually occur in practice since they are random,\nthe optimality cannot be reached by a robust solution because it pursues optimality under the worst case, not under the nominal situation.\n- Modularization vs Integration: To isolate faults and facilitate maintenance, we prefer the modularization scheme. Yet, for the purposes of resource sharing and overall optimality, e.g., in ISAC and ML-based ITP systems, we may resort to integration.\n- Centralization vs Decentralization: Centralized systems enable efficient global optimality of resource use and node interaction, but are prone to central-node failure and network attacks. Decentralized systems enhance robustness and scalability by distributing data storage and computation, but may face node-coordination challenges and suboptimal global performance.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 7,
      "text": "## V. Examples of Uncertainty Handling\n\nIn Subsection III-A, concrete examples of UA designs of signals and systems are provided. This section presents additional examples that leverage UA modeling and computational frameworks in Subsection III-B.\n\nFast Adaptations for Wireless Communications: In wireless communications, channel conditions vary over time due to environmental fluctuations and user mobility. Consequently, the entire wireless transmission process must adapt to realtime channel conditions, including channel estimation, transmit precoding, receive combining, and resource allocation, among others [4], [5]. Two immediate challenges arise: first, acquiring sufficient new pilot data to estimate updated channel state information; second, ensuring adequate computing power for adaptive operations. However, in practice, both pilot data and computing resources are limited, especially for highly dynamic channels and resource-constrained edge devices. Hence, computationally-lightweight and data-efficient methods in wireless transmission must be developed to handle channel evolution. In signal processing for wireless communications, typical examples include adaptive modulation and coding, adaptive beamforming, and adaptive receivers, among others [4]. In machine learning for wireless communications, few-shot learning has emerged as a promising approach. By leveraging meta-learning techniques, multi-task learning, and domain knowledge, few-shot learning enables computationand data-efficient wireless solutions such as channel estimation, precoding, and signal detection [5].\n\nRobust Adaptive Beamforming: Adaptive beamforming plays a key role in wireless communications and sensing to enhance signal-to-interference-plus-noise ratios (SINRs); Capon beamforming is a typical approach in this domain, which is formulated as $\\min _{\\boldsymbol{w}} \\boldsymbol{w}^{\\mathrm{H}} \\hat{\\boldsymbol{R}} \\boldsymbol{w}$, s.t. $\\hat{\\boldsymbol{a}}^{\\mathrm{H}} \\boldsymbol{w}=1$, where $\\hat{\\boldsymbol{R}}$ denotes the estimated covariance matrix of array snapshots, $\\boldsymbol{w}$ a beamformer, and $\\hat{\\boldsymbol{a}}$ the assumed steering vector of the signal of interest [7]. In practice, $\\hat{\\boldsymbol{R}}$ and $\\hat{\\boldsymbol{a}}$ can be inaccurate. As such, robust Capon beamforming is formulated as\n\n$$\n\\min _{\\boldsymbol{w}} \\max _{\\boldsymbol{R} \\in \\mathcal{U}_{R}} \\quad \\boldsymbol{w}^{\\mathrm{H}} \\boldsymbol{R} \\boldsymbol{w}\n$$\n\n$\\min _{\\boldsymbol{a} \\in \\mathcal{U}_{n}} \\boldsymbol{w}^{\\mathrm{H}} \\boldsymbol{a} \\boldsymbol{a}^{\\mathrm{H}} \\boldsymbol{w} \\geq 1$,\n\nto optimize the worst-case performance and ensure worstcase feasibility [7], where $\\mathcal{U}_{R}$ and $\\mathcal{U}_{a}$ are the uncertainty sets (i.e., uncertainty quantifications) of $\\boldsymbol{R}$ and $\\boldsymbol{a}$, respectively; for example, $\\mathcal{U}_{R}:=\\left\\{\\boldsymbol{R}: \\|\\boldsymbol{R}-\\hat{\\boldsymbol{R}}\\|_{F} \\leq \\epsilon_{1}\\right\\}$ and $\\mathcal{U}_{a}:=$ $\\left\\{\\boldsymbol{a}: \\|\\boldsymbol{a}-\\hat{\\boldsymbol{a}}\\|_{2} \\leq \\epsilon_{2}\\right\\}$ for some uncertainty levels $\\epsilon_{1}, \\epsilon_{2} \\geq 0$ where $\\|\\cdot\\|_{F}$ and $\\|\\cdot\\|_{2}$ denote the matrix Frobenius norm and the vector 2 -norm, respectively. A chance-constraint alternative is proposed in [6], where $\\operatorname{Pr}_{\\boldsymbol{a} \\sim \\mathbb{P}_{\\boldsymbol{a}}}\\left[\\boldsymbol{w}^{\\mathrm{H}} \\boldsymbol{a} \\boldsymbol{a}^{\\mathrm{H}} \\boldsymbol{w} \\geq 1\\right] \\geq \\alpha$ is employed with an uncertainty-quantification distribution $\\mathbb{P}_{\\boldsymbol{a}}$ and a pre-specified level $\\alpha$. It is reported that such UA formulations can greatly enhance beamforming performance when uncertainties are present in the estimated snapshot covariance $\\hat{\\boldsymbol{R}}$ and assumed steering vector $\\hat{\\boldsymbol{a}}$ [6], [7]. However, this benefit comes with extra prices, such as computational burden, because solving (1) requires additional efforts [7]. To sum up, through this example, the concepts of uncertainty quantification, robust optimization, chance-constrained optimization, and robustness-complexity trade-off have been illustrated.\n\nDistributionally Robust Localization: Wireless localization is a fundamental technique in IoT and WSNs. A wireless localization problem can be formulated as $\\min _{\\boldsymbol{r}} \\mathbb{E}_{\\boldsymbol{r}_{0} \\sim \\bar{\\nabla}_{\\boldsymbol{r}_{0}}}\\left[g\\left(\\boldsymbol{r}, \\boldsymbol{r}_{0}\\right)\\right]$, where $\\boldsymbol{r}$ is an estimated location of a target, $\\boldsymbol{r}_{0}$ is the actual but unknown location of this target, $g$ is a cost function such as the mean-squared error, and $\\overline{\\mathbb{P}}_{\\boldsymbol{r}_{0}}$ is an assumed uncertaintyquantification distribution of $\\boldsymbol{r}_{0}$ [11]. In practice, the assumed distribution $\\overline{\\mathbb{P}}_{\\boldsymbol{r}_{0}}$ can be inaccurate. As such, the distributionally robust localization problem can be formulated as\n\n$$\n\\min _{\\boldsymbol{r}} \\max _{\\bar{\\nabla}_{\\boldsymbol{r}_{0}} \\in \\mathcal{U}} \\mathbb{E}_{\\boldsymbol{r}_{0} \\sim \\bar{\\nabla}_{\\boldsymbol{r}_{0}}}\\left[g\\left(\\boldsymbol{r}, \\boldsymbol{r}_{0}\\right)\\right]\n$$\n\nwhere $\\mathcal{U}:=\\left\\{\\bar{\\nabla}_{\\boldsymbol{r}_{0}}: d\\left(\\mathbb{P}_{\\boldsymbol{r}_{0}}, \\overline{\\mathbb{P}}_{\\boldsymbol{r}_{0}}\\right) \\leq \\epsilon\\right\\}$ is the uncertainty set (i.e., uncertainty quantification) of $\\mathbb{P}_{\\boldsymbol{r}_{0}}, d$ is a metric between distributions, and $\\epsilon \\geq 0$ is the uncertainty level. It is reported that such a UA formulation can significantly reduce localization errors when distributional uncertainties are present in the assumed distribution $\\overline{\\mathbb{P}}_{\\boldsymbol{r}_{0}}$ [11]. However, if the assumed $\\overline{\\mathbb{P}}_{\\boldsymbol{r}_{0}}$ is accurate, solving (2) may sacrifice the performance optimality because the solution to the robust counterpart (2) does not necessarily solve the original problem $\\min _{\\boldsymbol{r}} \\mathbb{E}_{\\boldsymbol{r}_{0} \\sim \\bar{\\nabla}_{\\boldsymbol{r}_{0}}}\\left[g\\left(\\boldsymbol{r}, \\boldsymbol{r}_{0}\\right)\\right]$, leading to a conflict between robustness and optimality [11, Fig. 5]. In summary, through this example, the concepts of uncertainty quantification, distributionally robust optimization, and robustness-optimality trade-off have been illustrated.\n\nIn real-world systems such as IoT, WSNs, MANETs, and VANETs, the demonstrated uncertainties and countermeasures are applicable because signal detection, precoding and beamforming, and localization are key enabling techniques.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 8,
      "text": "## VI. CONCLUSIONS\n\nThis article focuses on uncertainty awareness in wireless communications and sensing. First, the sources and complications of uncertainties are identified, for example, the reliability, resilience, adaptivity, and robustness issues resulting from channel uncertainties, interferences, cyberattacks, hardware imperfections, dynamic environments, data scarcity, and computational errors. Second, existing and developing UA technical treatments are highlighted, including UA designs of signals and systems (i.e., redundancy, diversity, and margin,\nfeedback and adaptivity, anomaly detection and handling, modularization, decentralization, and prediction and prescription), as well as UA modeling and computational frameworks (i.e., uncertainty quantification, UA optimization, adaptive and robust signal processing, and trustworthy machine learning). Third, trade-offs that balance conflicting performance metrics in using UA strategies are exemplified, encompassing robustness vs efficiency, robustness vs complexity, robustness vs optimality, modularization vs integration, and centralization vs decentralization, among others. Fourth, motivating examples of how to apply these UA strategies are provided. Through the above efforts, we deliver the following message to the community: uncertainty awareness is an enabling and pivotal aspect of intelligent transmission and processing.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 9,
      "text": "## REFERENCES\n\n[1] J. Wang, C. Jiang, H. Zhang, Y. Ren, K.-C. Chen, and L. Hanzo, \"Thirty years of machine learning: The road to pareto-optimal wireless networks,\" IEEE Commun. Surveys Tuts., vol. 22, no. 3, pp. 1472-1514, 2020.\n[2] S. Wang and G. Y. Li, \"Machine learning in communications: A road to intelligent transmission and processing,\" Commun. of Huawei Res., vol. 7, pp. 2-20, November 2024.\n[3] G. Classen, A. M. Koster, D. Coudert, and N. Nepomuceno, \"Chanceconstrained optimization of reliable fixed broadband wireless networks,\" INFORMS J. on Comput., vol. 26, no. 4, pp. 893-909, 2014.\n[4] M. Ibukahla, Adaptive Signal Processing in Wireless Communications. CRC Press, 2009.\n[5] O. Wang, H. He, S. Zhou, Z. Ding, S. Jin, K. B. Letaief, and G. Y. Li, \"Fast adaptation for deep learning-based wireless communications,\" arXiv preprint arXiv:2409.04302, 2024.\n[6] S. A. Vorobyov, H. Chen, and A. B. Gershman, \"On the relationship between robust minimum variance beamformers with probabilistic and worst-case distortionless response constraints,\" IEEE Trans. on Signal Process., vol. 56, no. 11, pp. 5719-5724, 2008.\n[7] Y. Huang, H. Fu, S. A. Vorobyov, and Z. Luo, \"Robust adaptive beamforming via worst-case SINR maximization with nonconvex uncertainty sets,\" IEEE Trans. on Signal Process., vol. 71, pp. 218-232, 2023.\n[8] W. Ye and F. Ordonez, \"Robust optimization models for energy-limited wireless sensor networks under distance uncertainty,\" IEEE Trans. on Wireless Commun., vol. 7, no. 6, pp. 2161-2169, 2008.\n[9] Y. Li, Y. Zhuang, X. Hu, Z. Gao, J. Hu, L. Chen, Z. He, L. Pei, K. Chen, M. Wang et al., \"Toward location-enabled IoT (LE-IoT): IoT positioning techniques, error sources, and error mitigation,\" IEEE Internet Things J., vol. 8, no. 6, pp. 4035-4062, 2020.\n[10] A. Cika, \"On the modeling of mobile ad hoc networks,\" Ph.D. dissertation, University of Oxford, 2020.\n[11] N. A. Jagadeesan and B. Krishnamachari, \"Distributionally robust radio frequency localization,\" IEEE Trans. Signal Inf. Process. Netw., vol. 5, no. 2, pp. 390-403, 2018.\n[12] Y.-F. Liu, T.-H. Chang, M. Hong, Z. Wu, A. M.-C. So, E. A. Jorswieck, and W. Yu, \"A survey of recent advances in optimization methods for wireless communications,\" IEEE J. Select. Areas Commun., 2024.\n[13] A. Ben-Tal, A. Nemirovski, and L. El Ghaoui, Robust Optimization. Princeton University Press, 2009.\n[14] D. Kuhn, S. Shafine, and W. Wiesemann, \"Distributionally robust optimization,\" Acta Numerica, 2024.\n[15] A. M. Zoubir, V. Koivunen, Y. Chakhchoukh, and M. Muma, \"Robust estimation in signal processing: A tutorial-style treatment of fundamental concepts,\" IEEE Signal Process. Mag., vol. 29, no. 4, pp. 61-80, 2012.\n[16] F. Dietrich, Robust Signal Processing for Wireless Communications. Springer Science \\& Business Media, 2007.\n[17] J. Gawlikowski, C. R. N. Tassi, M. Ali, J. Lee, M. Hunn, J. Feng, A. Kruspe, R. Triebel, P. Jung, R. Roscher et al., \"A survey of uncertainty in deep neural networks,\" Artif. Intell. Rev., vol. 56, pp. 1513-1589, 2023.\n[18] Y. Pan, F. Duan, F. Chapeau-Blondeau, and D. Abbott, \"Noise enhancement in robust estimation of location,\" IEEE Trans. on Signal Process., vol. 66, no. 8, pp. 1953-1966, 2018.",
      "tables": {},
      "images": {}
    }
  ],
  "id": "2412.14369v2",
  "authors": [
    "Shixiong Wang",
    "Wei Dai",
    "Jianyong Sun",
    "Zongben Xu",
    "Geoffrey Ye Li"
  ],
  "categories": [
    "eess.SP"
  ],
  "abstract": "Wireless communications and sensing (WCS) establish the backbone of modern\ninformation exchange and environment perception. Typical applications range\nfrom mobile networks and the Internet of Things to radar and sensor grids.\nDespite transformative capabilities, wireless systems often face diverse\nuncertainties in design and operation, such as modeling errors due to\nincomplete physical knowledge, statistical errors arising from data scarcity,\nmeasurement errors caused by sensor imperfections, computational errors owing\nto resource limitation, and unpredictability of environmental evolution. Once\nignored, these uncertainties can lead to severe outcomes, e.g., performance\ndegradation, system untrustworthiness, inefficient resource utilization, and\nsecurity vulnerabilities. As such, this article reviews mature and emerging\narchitectural, computational, and operational countermeasures, encompassing\nuncertainty-aware designs of signals and systems (e.g., diversity, adaptivity,\nmodularity), as well as uncertainty-aware modeling and computational frameworks\n(e.g., risk-informed optimization, robust signal processing, and trustworthy\nmachine learning). Trade-offs to employ these methods, e.g., robustness vs\noptimality, are also highlighted.",
  "updated": "2025-04-07T19:16:27Z",
  "published": "2024-12-18T22:08:17Z"
}