{
  "title": "On classical solutions and canonical transformations for\n  Hamilton--Jacobi--Bellman equations",
  "sections": [
    {
      "section_id": 0,
      "text": "#### Abstract\n\nIn this note we show how canonical transformations reveal hidden convexity properties for deterministic optimal control problems, which in turn result in global existence of $C_{t o c}^{1,1}$ solutions to first order Hamilton-Jacobi-Bellman equations.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 1,
      "text": "## 1. InTRODUCTION\n\nFor given data $H: \\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ and $G: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ and time horizon $T>0$ let us consider the following Cauchy problem associated with the Hamilton-Jacobi-Bellman (HJB) equation\n\n$$\n\\begin{cases}\\partial_{t} u(t, x)+H\\left(x, \\partial_{x} u\\right)=0, & (t, x) \\in(0, T) \\times \\mathbb{R}^{d} \\\\ u(T, x)=G(x), & x \\in \\mathbb{R}^{d}\\end{cases}\n$$\n\nFor convenience we will assume that $H \\in C^{2}\\left(\\mathbb{R}^{d} \\times \\mathbb{R}^{d}\\right)$ and $G \\in C^{2}\\left(\\mathbb{R}^{d}\\right)$, and the second derivatives of these functions are uniformly bounded. Suppose that $H$ is convex in its second variable, so that this can be seen as the Legendre-Fenchel transform of a Lagrangian function, i.e. we have\n\n$$\nH(x, p)=\\sup _{v \\in \\mathbb{R}^{d}}\\{p \\cdot v-L(x,-v)\\}\n$$\n\nfor some $L \\in C^{2}\\left(\\mathbb{R}^{d} \\times \\mathbb{R}^{d}\\right)$ given. For convenience, we also assume that $L$ is convex in its second variable. In this case (1.1) corresponds to a variational problem. Indeed, it is well-known that under suitable assumptions we have that the value function\n\n$$\nu(t, x):=\\inf _{\\gamma:[t, T] \\rightarrow \\mathbb{R}^{d}, \\gamma(t)=x} \\int_{t}^{T} L(\\gamma(s), \\dot{\\gamma}(s)) \\mathrm{d} s+G(\\gamma(T))\n$$\n\nis the unique viscosity solution to (1.1). This solution is locally Lipschitz continuous and locally semi-concave with a linear modulus of continuity (cf. [CS04, Theorem 7.4.12, Theorem 7.4.14]).\nIt is well-known, however, that the unique viscosity solution $u$ in general develops singularities in finite time, even if $H$ and $G$ are smooth. Examples of finite time singularity formations can be constructed in a relatively straightforward way, see for instance [CS04, Example 1.3.4, Example 6.3.5] or [GM22, Appendix B.4]. More particularly, one can show that for instance for purely quadratic Hamiltonians $H(x, p)=\\frac{1}{2}|p|^{2}$ a singularity of $u$ must form in finite time, for any non-convex (and non-constant) $G$. This fact is documented in [GM23, Theorem 3.1].\nFine properties of sets of singularities of viscosity solutions have been studied extensively in the literature. Probably the first results on this topic were obtained in [CS87]. For a non-exhaustive list of further works dealing with singularities of solutions we refer the reader to [CS89, AC99, AC99, Yu06, CMS97, CY09, CF91, CF14] and to the review paper [CC21]. Singularity formation is equivalent to the non-uniqueness of optimal trajectories in the variational problem (1.3) (cf. [CS04]).\nTherefore, if one is able to ensure uniqueness of optimizers in (1.3), this results in the differentiability of the value function, hence in the existence of a unique classical solution to (1.1). This is precisely the case if $L$ is jointly convex and $G$ is convex, when the dynamics in the control problem is linear. This implies that $u(t, \\cdot)$ inherits the convexity and thus it becomes a $C_{t o c}^{1,1}$ classical solution for arbitrary\n\ntime horizon. This fact and related properties are classical and well documented in the literature, see for instance [CS04, Corollary 7.2.12] and [BE84, GR02, Goe05a, Goe05b, Roc70c, Roc70a].\nAs evidenced by the aforementioned works, the global existence of classical solutions is more of an exception than the rule in the theory of HJB equations. To the best of our knowledge, beyond the fully convex regime described above, there are no alternative sufficient conditions on the data $(H, G)$ (or $(L, G)$ ) which would result in global in time classical well-posedness theory for (1.1) in the class $C_{l o c}^{1,1}$. Both of the concrete situations of singularity formations mentioned above ([GM22, Appendix B.4] and [GM23, Theorem 3.1]) show precisely how semi-convexity estimates fail in general in finite time, hence this is a particular source of the failure of the global in time well-posedness in the class $C_{l o c}^{1,1}$.\nIn this manuscript we show that a special class of linear canonical transformations can reveal new global well-posedness theories. Let us describe the philosophy behind our approach. Let $\\alpha \\in \\mathbb{R}$ be given. Then the transformation\n\n$$\n\\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\ni(x, p) \\mapsto(x, p-\\alpha x)\n$$\n\nis a so-called canonical transformation on the phase space, which preserves the structure of Hamilton's equations. Such transformations are well-known in classical mechanics (cf. [Arn89]). We will make use of the following definitions.\n\n$$\nH_{\\alpha}(x, p):=H(x, p-\\alpha x)\n$$\n\nand\n\n$$\nG_{\\alpha}(x):=G(x)+\\frac{\\alpha}{2}|x|^{2}\n$$\n\nBecause of the nature of this transformation, we can state the first result of the paper.\nTheorem 1.1. Let $\\alpha \\in \\mathbb{R}$. Then $u$ is a classical solution to (1.1) with data $(H, G)$ in $(0, T) \\times \\mathbb{R}^{d}$, if and only if $u_{\\alpha}:(0, T) \\times \\mathbb{R}^{d}$, defined as\n\n$$\nu_{\\alpha}(t, x):=u(t, x)+\\frac{\\alpha}{2}|x|^{2}\n$$\n\nis a classical solution to $(1.1)$ on $(0, T) \\times \\mathbb{R}^{d}$ with data $\\left(H_{\\alpha}, G_{\\alpha}\\right)$.\nThis theorem has two immediate consequences. First, if we have a global well-posedness theory for (1.1) in the class $C_{l o c}^{1,1}$ with data $(H, G)$, we obtain a whole one-parameter family of global well-posedness theories in $C_{l o c}^{1,1}$ with data $\\left(H_{\\alpha}, G_{\\alpha}\\right)_{\\alpha \\in \\mathbb{R}}$. Second, if we are able to find one real number $\\alpha \\in \\mathbb{R}$ such that (1.1) is globally well-posed for the data $\\left(H_{\\alpha}, G_{\\alpha}\\right)$, then the original problem with data $(H, G)$ must also be globally well-posed.\nIt turns out that this second consequence will be the one revealing genuine new global in time wellposedness theories for (1.1) in the class $C_{l o c}^{1,1}$. Therefore, as our second main result (formulated in Theorem 3.4 below), we have identified sufficient conditions on $(H, G)$ which imply that for some precise $\\alpha \\in \\mathbb{R}$, the transformed data $\\left(H_{\\alpha}, G_{\\alpha}\\right)$ (or the corresponding $\\left.\\left(L_{\\alpha}, G_{\\alpha}\\right)\\right)$ fall into the well-known fully convex regime, and therefore this gives the global well-posedness of (1.1) in $C_{l o c}^{1,1}$ with the original data $(H, G)$. A direct corollary of our main results can be summarized as follows.\nCorollary 1.2. Let $H: \\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ and $G: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ be $C^{2}$ functions with uniformly bounded second order derivatives. Suppose furthermore that $H(x, \\cdot)$ is strongly convex, uniformly in $x$.\nThen, we have the following.\n(1) There exist a constant $C>0$ depending only on $\\left\\|D^{2} G\\right\\|_{\\infty},\\left\\|D^{2} H\\right\\|_{\\infty}$, and the lower bound on $\\partial_{p p} H$ such that (1.1) with data $(\\tilde{H}, G)$, where\n\n$$\n\\tilde{H}(x, p):=H(x, p)+\\alpha x \\cdot p\n$$\n\nis globally well-posed in the class $C_{\\text {loc }}^{1,1}\\left([0, T] \\times \\mathbb{R}^{d}\\right)$, for any $T>0$, whenever $\\alpha>C$.\n\n(2) There exist a constant $C>0$ depending only on $\\left\\|D^{2} G\\right\\|_{\\infty},\\left\\|D^{2} H\\right\\|_{\\infty}$, and the lower bound on $\\partial_{p p} H$ such that (1.1) with data $(\\tilde{H}, G)$, where\n\n$$\n\\tilde{H}(x, p):=H(x, p)-\\alpha \\frac{|x|^{2}}{2}\n$$\n\nis globally well-posed in the class $C_{\\mathrm{loc}}^{1,1}\\left([0, T] \\times \\mathbb{R}^{d}\\right)$, for any $T>0$, whenever $\\alpha>C$.\nRemark 1.3. We see that suitably modifying the existing data of a Hamilton-Jacobi-Bellman equation can 'convexify' the problem, and in turn this leads to a global in time classical well-posedness theory. Corollary 1.2 shows that this procedure can be done not only by adding the term $(x, p) \\mapsto-\\alpha \\frac{|x|^{2}}{2}$ to the Hamiltonian, but also by adding $(x, p) \\mapsto \\alpha x \\cdot p$ to $H$, for a suitably chosen $\\alpha$.\n\nRemark 1.4. The attentive reader will notice that we are only using 'upper triangular' canonical transformations, i.e. transformations of the form $(x, p) \\mapsto(x, p-\\alpha x)$. The reason for this is that in order for a system of ODEs (in the $\\left(X_{s}, P_{s}\\right)$ unknowns) to be the characteristic equations of a HJB equation not only do they need to have a Hamiltonian system structure but the boundary conditions must be of a particular form. Specifically to preserve the structure of boundary condition $X_{0}=x_{0}$ we need to have the transformation to be upper triangular. From here one could imagine taking a transform $(x, p) \\mapsto(x, p-A x)$ for some constant matrix $A$. In order to preserve the structure of the condition $P_{T}=\\nabla G\\left(X_{T}\\right)$ (specifically that the right-hand side is the gradient of a function) we need that $A$ is symmetric. The choice of $A=\\alpha I$ is taken for simplicity and the same arguments should work with any symmetric matrix $A$.\n\nRemark 1.5. Although we illustrate this canonical transformation technique to obtain a classical global well-posedness theory for the HJB equation, the approach works exactly the same for any other features of HJB equations. For example, if one had a result on the structure of the shocks for a HJB equation with data $(H, G)$ (e.g. for instance, the points of non-differentiability lie on a smooth curve) then the same result would hold for the transformed data $\\left(H_{\\alpha}, G_{\\alpha}\\right)$ (in fact the non-differentiability points would be the exact same).\n\nWe finish this introduction with some concluding remarks.\n\n- In this manuscript, for the simplicity of the exposition, we choose to consider only a simple class of linear canonical transformations of the form $\\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\ni(x, p) \\mapsto(x, p-\\alpha x)$. However, our approach would potentially work for a class of more general nonlinear transformations of the form\n\n$$\n\\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\ni(x, p) \\mapsto(x, p-\\nabla \\varphi(x))\n$$\n\nfor suitable potential functions $\\varphi: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$. While these extensions would not pose conceptual difficulties in our analysis, they would introduce heavy technical computations. Thus, we decided not to pursue these in this manuscript.\n\n- Our approach works using only a Hamiltonian perspective, therefore, in particular by working purely with Hamiltonian systems, we believe that similar results could be proven in the case of Hamiltonians which are not necessarily convex in the momentum variable. Again, for simplicity of the exposition, we do not pursue this direction here.\n- Canonical transformations are well understood in the case of more general Hamiltonian systems on symplectic manifolds, as these are symplectomorphisms on the cotangent bundle (cf. [Arn89]). Although we consider only a simple Euclidean setting here, we suspect that our ideas could be potentially useful to study solutions of Hamilton-Jacobi-Bellman equations in more general geometric frameworks as well. Such studies would fall outside of the scope of the present manuscript.\n- It turns out that the canonical transformations considered in this manuscript reveal new deep well-posedness theories in a particular infinite dimensional setting, namely for the master equation in Mean Field Games. These results are detailed in our companion paper [BM24].\n\nThe rest of the paper contains two short sections. In Section 2, for pedagogical reasons, we detail the role of the specific canonical transformations from the Lagrangian perspective. Section 3 contains our main results, and this is written purely from the Hamiltonian perspective.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 2,
      "text": "# 2. Canonical transformations and classical solutions from the Lagrangian PERSPECTIVE \n\nFor $t \\in(0, T)$, consider the functional $\\mathcal{F}_{t}: C^{1}\\left((t, T) ; \\mathbb{R}^{d}\\right) \\rightarrow \\mathbb{R}$ defined as\n\n$$\n\\mathcal{F}_{t}(\\gamma):=\\int_{t}^{T} L(\\gamma(x), \\dot{\\gamma}(s)) \\mathrm{d} s+G(\\gamma(T))\n$$\n\nFurthermore, we define the set of admissible curves as\n\n$$\n\\operatorname{Adm}_{t, x}:=\\left\\{\\gamma \\in C^{1}\\left((t, T) ; \\mathbb{R}^{d}\\right): \\gamma(t)=x\\right\\}\n$$\n\nUsing this functional, one has\n\n$$\nu(t, x):=\\inf _{\\gamma \\in \\operatorname{Adm}_{t, x}} \\mathcal{F}_{t}(\\gamma)\n$$\n\nDifferentiability of solutions to (1.1) is deeply linked to the uniqueness of minimizers in the optimal control problem (1.3) (see for instance the discussions in [CS04, Example 1.3.4, Example 6.3.5] or [GM22, Appendix B.4]). In particular, it is well-known that the convexity of the functional $\\gamma \\mapsto \\mathcal{F}(\\gamma)$ would imply that $u(t, \\cdot)$ is convex, which in turn would further implies that $u$ is a classical solution to (1.1) in the class $C_{\\mathrm{loc}}^{1,1}\\left([0, T] \\times \\mathbb{R}^{d}\\right)$ (see [CS04, Theorem 7.4.13]). The convexity of $\\gamma \\mapsto \\mathcal{F}(\\gamma)$ can be guaranteed by the joint convexity of $L$ and the convexity of $G$.\nHowever since the endpoint in the optimization problem, i.e. $\\gamma(t)=x$, was fixed we could have just as well considered the functional\n\n$$\n\\mathcal{F}_{t, \\alpha}(\\gamma):=\\mathcal{F}_{t}(\\gamma)+\\frac{\\alpha}{2}|x|^{2}=\\mathcal{F}_{t}(\\gamma)+\\frac{\\alpha}{2}|\\gamma(t)|^{2}\n$$\n\nfor any $\\alpha \\in \\mathbb{R}$. In this case, one would simply have\n\n$$\nu(t, x)+\\frac{\\alpha}{2}|x|^{2}:=\\inf _{\\gamma \\in \\operatorname{Adm}_{t, x}} \\mathcal{F}_{t, \\alpha}(\\gamma)\n$$\n\nFollowing a standard idea in classical mechanics we rewrite this new term as the integral of its time derivative and an initial term to get\n\n$$\n\\begin{aligned}\n\\mathcal{F}_{t, \\alpha}(\\gamma) & =\\int_{t}^{T} L(\\gamma(x), \\dot{\\gamma}(s))-\\frac{\\mathrm{d}}{\\mathrm{~d} s}\\left(\\frac{\\alpha}{2}|\\gamma(s)|^{2}\\right) \\mathrm{d} s+\\frac{\\alpha}{2}|\\gamma(T)|^{2}+G(\\gamma(T)) \\\\\n& =\\int_{t}^{T} L(\\gamma(x), \\dot{\\gamma}(s))-\\alpha\\langle\\gamma(s), \\dot{\\gamma}(s)\\rangle \\mathrm{d} s+G(\\gamma(T))+\\frac{\\alpha}{2}|\\gamma(T)|^{2}\n\\end{aligned}\n$$\n\nNotice now that it is possible to not have convexity of\n\n$$\n\\gamma \\mapsto \\mathcal{F}_{t}(\\gamma)\n$$\n\nbut have convexity of\n\n$$\n\\gamma \\mapsto \\mathcal{F}_{t, \\alpha}(\\gamma)\n$$\n\nfor some $\\alpha \\in \\mathbb{R}$, even though\n\n$$\n\\inf _{\\gamma \\in \\operatorname{Adm}_{t, x}} \\mathcal{F}_{t}(\\gamma) \\text { and } \\inf _{\\gamma \\in \\operatorname{Adm}_{t, x}} \\mathcal{F}_{t, \\alpha}(\\gamma)\n$$\n\nare the same problems, in that the optimal values differ by the constant $\\frac{\\alpha}{2}|x|^{2}$ and in particular they have the same minimizers.\nTherefore, it turns out that such transformations could reveal hidden convexity structures on the data, which were not straightforward in the original setting of the problem, and in particular (1.1) would be well-posed in the class $C_{\\mathrm{loc}}^{1,1}\\left([0, T] \\times \\mathbb{R}^{d}\\right)$, if $\\gamma \\mapsto \\mathcal{F}_{t, \\alpha}$ is convex even if we did not have convexity of $\\gamma \\mapsto \\mathcal{F}_{t}$.\n\nWe also have the opposite situation, i.e. when $\\gamma \\mapsto \\mathcal{F}_{t}$ is convex, yet $\\gamma \\mapsto \\mathcal{F}_{t, \\alpha}$ is not convex. As the convexity properties of the functionals can be characterized by the convexity of the Lagrangian and final data, it is natural to define the following quantities. For $\\alpha \\in \\mathbb{R}$, let $L_{\\alpha}: \\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ be defined as\n\n$$\nL_{\\alpha}(x, v):=L(x, v)-\\alpha x \\cdot v\n$$\n\nand $G_{\\alpha}: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$, defined as\n\n$$\nG_{\\alpha}(x):=G(x)+\\frac{\\alpha}{2}|x|^{2}\n$$\n\nBased on the previous discussion, we can formulate the following proposition.\nProposition 2.1. We have the following.\n(i) Let $G: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ be convex and let $L: \\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ be jointly convex, and suppose furthermore that both $G$ and $L$ have bounded second derivatives. Then, there exists $\\alpha_{0} \\in \\mathbb{R}$ such that $L_{\\alpha}$ is not jointly convex and $G_{\\alpha}$ is not convex for any $\\alpha<\\alpha_{0}$.\n(ii) There exist $L: \\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ not jointly convex and $G: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ non-convex, such that there for a suitable $\\alpha \\in \\mathbb{R}, L_{\\alpha}$ becomes jointly convex and $G_{\\alpha}$ becomes convex.\n\nProof. (i) Let $f: \\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ defined as $f(v, x)=v \\cdot x$. Direct computation yields that -1 is an eigenvalue of $D^{2} f$ (the eigenvector is the $(1, \\ldots, 1,-1, \\ldots,-1)$ ). Indeed, we see that $D^{2} f(x, y)=$ $\\left[\\begin{array}{cc}0_{d} & I_{d} \\\\ I_{d} & 0_{d}\\end{array}\\right]$, where $0_{d}$ and $I_{d}$ stand for the zero matrix and the identity matrix in $\\mathbb{R}^{d \\times d}$, respectively. From here the claim follows. Hence for $\\alpha<\\dot{\\alpha_{0}}:=-\\left\\|D^{2} L\\right\\|_{\\infty}$ we have that $L_{\\alpha}$ is not jointly convex. Now let $\\alpha_{0}:=\\min \\left\\{\\dot{\\alpha}_{0},-\\left\\|\\partial_{x x} G\\right\\|_{L^{\\infty}}\\right\\}$, and then the result follows.\n(ii) In the previous point we have constructed $L_{\\alpha}$ and $G_{\\alpha}$ that are non-convex, but $L$ and $G$ were convex. Now if we apply the same transformation on these new functions with constant $-\\alpha$, i.e. $\\left(L_{\\alpha}\\right)_{-\\alpha}$ and $\\left(G_{\\alpha}\\right)_{-\\alpha}$ we get back to the original functions which were convex. The statement follows.\n\nThe transformations on $L$, as describe above, translate naturally to the Hamiltonian $H$. Indeed, we can see that $H_{\\alpha}$ corresponding to $L_{\\alpha}$ is defined as in 1.4.\nIt is important to notice that the previous transformation preserves the Hamiltonian structure and the HJB equation. This is what leads precisely to Theorem 1.1, whose proof is straightforward and we present it below.\n\nProof of Theorem 1.1. This result readily follows from the representation formula (2.1). Alternatively, direct computation yields\n\n$$\n\\partial_{t} u_{\\alpha}(t, x)=\\partial_{t} u(t, x) \\text { and } \\partial_{x} u_{\\alpha}(t, x)=\\partial_{x} u(t, x)+\\alpha x\n$$\n\nand so\n\n$$\n-\\partial_{t} u_{\\alpha}(t, x)+H_{\\alpha}\\left(x, \\partial_{x} u_{\\alpha}(t, x)\\right)=-\\partial_{t} u(t, x)+H\\left(x, \\partial_{x} u(t, x)+\\alpha x-\\alpha x\\right)=0\n$$\n\nand\n\n$$\nu_{\\alpha}(T, x)=G_{\\alpha}(x)\n$$\n\nThe result follows.\nRemark 2.2. Because of the representation formula (2.1), the previous result clearly holds true for viscosity solutions as well (cf. [CS04, Theorem 7.4.14]).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 3,
      "text": "# 3. Canonical transformations and Classical SOlutions from the Perspective of HAMILTONIAN SYSTEMS \n\nBased on [Roc70b, Theorem 33.1], we can formulate the following result.\nLemma 3.1. $H: \\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$, defined in (1.2) is concave-convex (i.e. $H(\\cdot, p)$ is convex for all $p \\in \\mathbb{R}^{d}$ and $H(x, \\cdot)$ is convex for all $x \\in \\mathbb{R}^{d}$ ) if and only $L$ is jointly convex.\n\nFrom this lemma we see that the global existence of classical solutions to the Hamilton-Jacobi equation (1.1) in the class $C_{\\mathrm{loc}}^{1,1}$, from the Hamiltonian point of view, is intimately linked to the concave-convex properties of $H$ and convexity of the final condition $G$.\n\nDefinition 3.2. For a square matrix $A \\in \\mathbb{R}^{m \\times m}$, we define the symmetric matrix\n\n$$\n\\operatorname{Re} A:=\\frac{1}{2}\\left(A+A^{\\top}\\right)\n$$\n\nFor a symmetric matrix $A \\in \\mathbb{R}^{m \\times m}$, we denote by $\\lambda_{\\min }(A)$ and $\\lambda_{\\max }(A)$ its smallest and largest eigenvalues, respectively.\n\nLemma 3.3. Suppose that\n\n$$\n\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w\\right)^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right) \\geq 0, \\quad \\forall w \\in \\mathbb{R}^{d}, \\quad \\forall x, p \\in \\mathbb{R}^{d} \\times \\mathbb{R}^{d}\n$$\n\nDefine\n\n$$\n\\alpha:=\\inf _{\\substack{(x, p, w) \\in \\mathbb{R}^{3 d} \\\\\\|w\\|=1}} \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w+\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, y) w\\right)^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}{\\left.\\|w\\|=1\\right.} \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w+\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w\\right)^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}}{w^{\\top} \\partial_{p p} H(x, p) w}\n$$\n\nSuppose that $x \\mapsto G(x)+\\alpha \\frac{|x|^{2}}{2}$ is convex and\n\n$$\n\\alpha \\geq \\sup _{\\substack{(x, p, w) \\in \\mathbb{R}^{3 d} \\\\\\|w\\|=1}} \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w-\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w\\right)^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}{\\left.\\|w\\|=1\\right.} \\frac{w^{\\top} \\partial_{p p} H(x, p) w}{w}\n$$\n\nThen the Hamilton-Jacobi equation (1.1) with data $(H, G)$ is globally well-posed in the class $C_{\\mathrm{loc}}^{1,1}([0, T] \\times$ $\\left.\\mathbb{R}^{d}\\right)$.\n\nProof. Using (1.4) and (2.2) we define $H_{\\alpha}$ and $G_{\\alpha}$ with the particular choice of $\\alpha$ given in the statement. We see that $G_{\\alpha}$ is convex. Also, we compute for any $w \\in \\mathbb{R}^{d}$ and any $(x, p) \\in \\mathbb{R}^{d} \\times \\mathbb{R}^{d}$\n\n$$\nw^{\\top} \\partial_{x x} H_{\\alpha}(x, p) w=w^{\\top} \\partial_{x x} H(x, p-\\alpha x) w-2 \\alpha w^{\\top} \\operatorname{Re}\\left(\\partial_{x p} H(x, p-\\alpha x)\\right) w+\\alpha^{2} w^{\\top} \\partial_{p p} H(x, p-\\alpha x) w\n$$\n\nThis expression is a quadratic polynomial in $\\alpha$ with positive leading coefficient. The conditions of the theorem assure that this polynomial is non-positive at $\\alpha$, i.e.\n\n$$\n\\begin{aligned}\n& \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w-\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w\\right)^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}{w^{\\top} \\partial_{p p} H(x, p) w} \\\\\n& \\leq \\alpha \\\\\n& \\leq \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w+\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w\\right)^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}}{w^{\\top} \\partial_{p p} H(x, p) w}\n\\end{aligned}\n$$\n\nfor all $(x, p) \\in \\mathbb{R}^{d} \\times \\mathbb{R}^{d}$ and for all $w \\in \\mathbb{R}^{d}$.\nIn particular $H_{\\alpha}$ is concave in $x$. Furthermore, this particular transformation does not change the convexity of $H_{\\alpha}$ in the $p$-variable, as $\\partial_{p p} H_{\\alpha}(x, p)=\\partial_{p p} H(x, p-\\alpha x)$. The thesis of the lemma follows by Lemma 3.1 and [CS04, Theorem 7.4.13].\n\nAs a consequence of this lemma, we can formulate the following result.\nTheorem 3.4. We define the following quantities\n\n$$\n\\begin{gathered}\n\\lambda_{0}:=\\inf _{(x, p) \\in \\mathbb{R}^{d} \\times \\mathbb{R}^{d}} \\lambda_{\\min }\\left(\\operatorname{Re} \\partial_{x p} H(x, p)\\right) \\\\\n\\lambda_{H}:=\\sup _{(x, p) \\in \\mathbb{R}^{d} \\times \\mathbb{R}^{d}} \\lambda_{\\max }\\left(\\partial_{x x} H(x, p)\\right)\n\\end{gathered}\n$$\n\nand\n\n$$\n\\lambda_{G}:=\\inf _{x \\in \\mathbb{R}^{d}} \\lambda_{\\min }\\left(\\partial_{x x} G(x)\\right)\n$$\n\nSuppose that\n\n$$\n\\lambda_{0}^{2} \\geq\\left\\|\\partial_{p p} H\\right\\|_{\\infty} \\lambda_{H} \\text { and that } \\lambda_{0}+\\sqrt{\\lambda_{0}^{2}-\\left\\|\\partial_{p p} H\\right\\|_{\\infty} \\lambda_{H}}+\\left\\|\\partial_{p p} H\\right\\|_{\\infty} \\lambda_{G} \\geq 0\n$$\n\nFurthermore assume that either $\\lambda_{H} \\leq 0$ or $\\lambda_{0} \\geq 0$. Then the Hamilton-Jacobi equation (1.1) is globally well-posed, for any $T>0$, in the class $C_{\\mathrm{loc}}^{1,1}\\left([0, T] \\times \\mathbb{R}^{d}\\right)$.\n\nProof. We verify the assumptions of Lemma 3.3. First, let us consider the inequality (3.1).\nIf $\\lambda_{H} \\leq 0$ then (3.1) is fulfilled immediately.\nIf $\\lambda_{H}>0$, but $\\lambda_{0} \\geq 0$ we have the following. By definition of $\\lambda_{0}, w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w \\geq \\lambda_{0}$, for all $(x, p) \\in \\mathbb{R}^{d} \\times \\mathbb{R}^{d}$ and for all $w \\in \\mathbb{R}^{d}$. Since the right-hand side is non-negative we can square to obtain\n\n$$\n\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w\\right)^{2} \\geq \\lambda_{0}^{2} \\geq\\left\\|\\partial_{p p} H\\right\\|_{\\infty} \\lambda_{H}\n$$\n\nwhich implies that\n\n$$\n\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w\\right)^{2} \\geq\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)\n$$\n\nThus, (3.1) follows.\nWe verify the other assumptions in the statement of Lemma 3.3. Let $\\alpha$ be defined as in (3.2). Just as before, we distinguish two cases.\nCase 1. $\\lambda_{H} \\leq 0$.\nIn this case we have that $\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right) \\leq 0$, for all $(x, p) \\in \\mathbb{R}^{d} \\times \\mathbb{R}^{d}$ and for all $w \\in \\mathbb{R}^{d}$. Therefore\n\n$$\n\\alpha \\geq 0 \\geq \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w-\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w\\right)^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}{w^{\\top} \\partial_{p p} H(x, p) w}\n$$\n\nfor all $(x, p) \\in \\mathbb{R}^{d} \\times \\mathbb{R}^{d}$ and for all $w \\in \\mathbb{R}^{d}$. This implies (3.3).\nFurthermore, we have\n\n$$\n\\begin{aligned}\n\\alpha= & \\inf _{\\substack{(x, p, w) \\in \\mathbb{R}^{3 d} \\\\\n\\|w\\|=1}} \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w+\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, y) w\\right)^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}{w^{\\top} \\partial_{p p} H(x, p) w} \\\\\n\\geq & \\inf _{\\substack{(x, p, w) \\in \\mathbb{R}^{3 d} \\\\\n\\|w\\|=1}} \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w+\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, y) w\\right)^{2}-\\left\\|\\partial_{p p} H\\right\\|_{\\infty}\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}{\\left\\|\\partial_{p p} H\\right\\|_{\\infty}}\n\\end{aligned}\n$$\n\nwhere in the last inequality we have used that the function $f:\\left\\{(a, b, c): c \\geq 0, b \\leq 0, a^{2} \\geq b c\\right\\} \\rightarrow \\mathbb{R}$ defined as $f(a, b, c)=\\frac{a+\\sqrt{a^{2}-b c}}{c}$ is decreasing in $c$.\nContinuing we have\n\n$$\n\\begin{aligned}\n\\alpha & \\geq \\inf _{\\substack{(x, p, w) \\in \\mathbb{R}^{3 d} \\\\\n\\|w\\|=1}} \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w+\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, y) w\\right)^{2}-\\left\\|\\partial_{p p} H\\right\\|_{\\infty}\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}{\\left\\|\\partial_{p p} H\\right\\|_{\\infty}} \\\\\n& \\geq \\inf _{\\substack{(x, p, w) \\in \\mathbb{R}^{3 d} \\\\\n\\|w\\|=1}} \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w+\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, y) w\\right)^{2}-\\left\\|\\partial_{p p} H\\right\\|_{\\infty} \\lambda_{H}}}{\\left\\|\\partial_{p p} H\\right\\|_{\\infty}} \\\\\n& \\geq \\frac{\\lambda_{0}+\\sqrt{\\lambda_{0}^{2}-\\left\\|\\partial_{p p} H\\right\\|_{\\infty} \\lambda_{H}}}{\\left\\|\\partial_{p p} H\\right\\|_{\\infty}}\n\\end{aligned}\n$$\n\nwhere the last inequality is because the function $f:\\{(a, b): b \\leq 0\\} \\rightarrow \\mathbb{R}$ defined as $f(a, b)=$ $a+\\sqrt{a^{2}-b}$ is increasing in $a$. From this, by the assumptions of this theorem it follows that $x \\mapsto$ $G(x)+\\alpha \\frac{|x|^{2}}{2}$ is convex.\nCase 2. $\\lambda_{0} \\geq 0$. We notice that without loss of generality, we may assume also that the inequality $\\lambda_{H} \\geq 0$ takes place.\nWe have\n\n$$\n\\begin{aligned}\n& \\alpha=\\inf _{\\substack{(x, p, w) \\in \\mathbb{R}^{3 d} \\\\\n\\|w\\|=1}} \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w+\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, y) w\\right)^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}{w^{\\top} \\partial_{p p} H(x, p) w} \\\\\n& \\geq \\inf _{\\substack{(x, p, w) \\in \\mathbb{R}^{3 d} \\\\\n\\|w\\|=1}} \\frac{\\lambda_{0}+\\sqrt{\\lambda_{0}^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right) \\lambda_{H}}}{w^{\\top} \\partial_{p p} H(x, p) w} \\\\\n& \\geq \\inf _{\\substack{(x, p, w) \\in \\mathbb{R}^{3 d} \\\\\n\\|w\\|=1}} \\frac{\\lambda_{0}+\\sqrt{\\lambda_{0}^{2}-\\left\\|\\partial_{p p} H\\right\\|_{\\infty} \\lambda_{H}}}{w^{\\top} \\partial_{p p} H(x, p) w} \\\\\n& \\geq \\frac{\\lambda_{0}+\\sqrt{\\lambda_{0}^{2}-\\left\\|\\partial_{p p} H\\right\\|_{\\infty} \\lambda_{H}}}{\\left\\|\\partial_{p p} H\\right\\|_{\\infty}}\n\\end{aligned}\n$$\n\nwhere the last two inequalities follow from $\\lambda_{H} \\geq 0$ and $\\lambda_{0} \\geq 0$ respectively. We notice also that in the previous chain of inequalities all the quantities under the square root are non-negative.\nFurthermore, we see that $\\lambda_{0}+\\sqrt{\\lambda_{0}^{2}-\\left\\|\\partial_{p p} H\\right\\|_{\\infty} \\lambda_{H}}+\\left\\|\\partial_{p p} H\\right\\|_{\\infty} \\lambda_{G} \\geq 0$ implies that $\\alpha+\\lambda_{G} \\geq 0$ and so $x \\mapsto G(x)+\\alpha \\frac{|x|^{2}}{2}$ is convex.\nNext note that the function $f:\\left\\{(a, b): a, b \\geq 0, a^{2} \\geq b\\right\\} \\rightarrow \\mathbb{R}$ defined as $f(a, b)=a-\\sqrt{a^{2}-b}$ is decreasing in $a$. Hence\n\n$$\n\\begin{aligned}\n& \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w-\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w\\right)^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}{w^{\\top} \\partial_{p p} H(x, p) w} \\\\\n& \\leq \\frac{\\lambda_{0}-\\sqrt{\\lambda_{0}^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}{w^{\\top} \\partial_{p p} H(x, p) w} \\\\\n& \\leq \\frac{\\lambda_{0}-\\sqrt{\\lambda_{0}^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right) \\lambda_{H}}}{w^{\\top} \\partial_{p p} H(x, p) w} \\\\\n& \\leq \\frac{\\lambda_{0}-\\sqrt{\\lambda_{0}^{2}-\\left\\|\\partial_{p p} H\\right\\|_{\\infty} \\lambda_{H}}}{\\left\\|\\partial_{p p} H\\right\\|_{\\infty}}\n\\end{aligned}\n$$\n\nwhere the last inequality follows from the fact that the function $f:\\left\\{(a, b, c): a, b, c \\geq 0, a^{2} \\geq b c\\right\\} \\rightarrow \\mathbb{R}$, defined as $f(a, b, c)=\\frac{a-\\sqrt{a^{2}-b c}}{c}$ is increasing in $c$. Combining (3.4) and (3.5) we can conclude that\n\n$$\n\\alpha \\geq \\sup _{\\substack{(x, p, w) \\in \\mathbb{R}^{3 d} \\\\\\|w\\|=1}} \\frac{w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, p) w-\\sqrt{\\left(w^{\\top} \\operatorname{Re} \\partial_{x p} H(x, y) w\\right)^{2}-\\left(w^{\\top} \\partial_{p p} H(x, p) w\\right)\\left(w^{\\top} \\partial_{x x} H(x, p) w\\right)}}{w^{\\top} \\partial_{p p} H(x, p) w}\n$$\n\nwhich completes the proof in this case.\n\nFrom this theorem the proof of Corollary 1.2 is immediate.\nProof of Corollary 1.2. We see that if $\\alpha$ is large enough then the assumptions of Theorem 3.4 are satisfied.\n\nAcknowledgements. The authors are grateful to Wilfrid Gangbo for valuable remarks and constructive comments. MB's work was supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-1650604 and by the Air Force Office of Scientific Research under Award No. FA9550-18-1-0502. ARM has been partially supported by the EPSRC New Investigator Award \"Mean Field Games and Master equations\" under award no. EP/X020320/1 and by the King Abdullah University of Science and Technology Research Funding (KRF) under award no. ORA-2021-CRG10-4674.2. Both authors acknowledge the partial support of the Heilbronn Institute for Mathematical Research and the UKRI/EPSRC Additional Funding Programme for Mathematical Sciences through the focused research grant \"The master equation in Mean Field Games\".\n\nData Availability. We did not make use of or did not generate data sets.\nConflict of interest. The authors declare that they do not have any conflict of interest.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 4,
      "text": "# REFERENCES \n\n[AC99] P. Albano and P. Cannarsa. Structural properties of singularities of semiconcave functions. Ann. Scuola Norm. Sup. Pisa Cl. Sci. (4), 28(4):719-740, 1999.\n[Arn89] V. I. Arnol'd. Mathematical methods of classical mechanics, volume 60 of Graduate Texts in Mathematics. Springer-Verlag, New York, second edition, 1989. Translated from the Russian by K. Vogtmann and A. Weinstein.\n[BE84] M. Bardi and L. C. Evans. On Hopf's formulas for solutions of Hamilton-Jacobi equations. Nonlinear Anal., $8(11): 1373-1381,1984$.\n[BM24] M. Bansil and A.R. M\u00e9sz\u00e1ros. Hidden monotonicity and canonical transformations for mean field games and master equations. preprint, 2024.\n[CC21] P. Cannarsa and W. Cheng. Singularities of solutions of Hamilton-Jacobi equations. Milan J. Math., 89(1):187215, 2021.\n[CF91] P. Cannarsa and H. Frankowska. Some characterizations of optimal trajectories in control theory. SIAM J. Control Optim., 29(6):1322-1347, 1991.\n[CF14] P. Cannarsa and H. Frankowska. From pointwise to local regularity for solutions of Hamilton-Jacobi equations. Calc. Var. Partial Differential Equations, 49(3-4):1061-1074, 2014.\n[CMS97] P. Cannarsa, A. Mennucci, and C. Sinestrari. Regularity results for solutions of a class of Hamilton-Jacobi equations. Arch. Rational Mech. Anal., 140(3):197-223, 1997.\n[CS87] P. Cannarsa and H.M. Soner. On the singularities of the viscosity solutions to Hamilton-Jacobi-Bellman equations. Indiana Univ. Math. J., 36(3):501-524, 1987.\n[CS89] P. Cannarsa and H.M. Soner. Generalized one-sided estimates for solutions of Hamilton-Jacobi equations and applications. Nonlinear Anal., 13(3):305-323, 1989.\n[CS04] P. Cannarsa and C. Sinestrari. Semiconcave functions, Hamilton-Jacobi equations, and optimal control, volume 58 of Progress in Nonlinear Differential Equations and their Applications. Birkh\u00e4user Boston, Inc., Boston, MA, 2004.\n[CY09] P. Cannarsa and Y. Yu. Singular dynamics for semiconcave functions. J. Eur. Math. Soc. (JEMS), 11(5):9991024, 2009.\n[GM22] W. Gangbo and A.R. M\u00e9sz\u00e1ros. Global well-posedness of master equations for deterministic displacement convex potential mean field games. Comm. Pure Appl. Math., 75(12):2685-2801, 2022.\n[GM23] P.J. Graber and A.R. M\u00e9sz\u00e1ros. On monotonicity conditions for mean field games. J. Funct. Anal., 285(9):110095, 2023.\n[Goe05a] R. Goebel. Convex optimal control problems with smooth Hamiltonians. SIAM J. Control Optim., 43(5):17871811, 2005.\n[Goe05b] R. Goebel. Duality and uniqueness of convex solutions to stationary Hamilton-Jacobi equations. Trans. Amer. Math. Soc., 357(6):2187-2203, 2005.\n[GR02] R. Goebel and R. T. Rockafellar. Generalized conjugacy in Hamiltonian-Jacobi theory for fully convex Lagrangians. volume 9, pages 463-473. 2002. Special issue on optimization (Montpellier, 2000).\n[Roc70a] R. T. Rockafellar. Conjugate convex functions in optimal control and the calculus of variations. J. Math. Anal. Appl., 32:174-222, 1970.\n[Roc70b] R.T. Rockafellar. Convex analysis. Princeton Mathematical Series. Princeton University Press, Princeton, N. J., 1970.\n[Roc70c] R.T. Rockafellar. Generalized Hamiltonian equations for convex problems of Lagrange. Pacific J. Math., 33:411$427,1970$.\n\n[Yu06] Y. Yu. A simple proof of the propagation of singularities for solutions of Hamilton-Jacobi equations. Ann. Sc. Norm. Super. Pisa Cl. Sci. (5), 5(4):439-444, 2006.\n\nDepartment of Mathematics, University of California, Los Angeles, CA 90095-1555, USA Email address: mbansil@math.ucla.edu\n\nDepartment of Mathematical Sciences, University of Durham, Durham DH1 3LE, UK Email address: alpar.r.meszaros@durham.ac.uk",
      "tables": {},
      "images": {}
    }
  ],
  "id": "2403.05412v2",
  "authors": [
    "Mohit Bansil",
    "Alp\u00e1r R. M\u00e9sz\u00e1ros"
  ],
  "categories": [
    "math.OC",
    "math.AP"
  ],
  "abstract": "In this note we show how canonical transformations reveal hidden convexity\nproperties for deterministic optimal control problems, which in turn result in\nglobal existence of $C^{1,1}_{loc}$ solutions to first order\nHamilton--Jacobi--Bellman equations.",
  "updated": "2025-04-09T09:24:25Z",
  "published": "2024-03-08T16:11:03Z"
}