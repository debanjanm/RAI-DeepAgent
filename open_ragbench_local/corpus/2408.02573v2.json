{"title": "Testing identifying assumptions in Tobit Models", "sections": [{"section_id": 0, "text": "#### Abstract\n\nThis paper develops sharp testable implications for Tobit and IV-Tobit models' identifying assumptions: linear index specification, (joint) normality of latent errors, and treatment (instrument) exogeneity and relevance. The new sharp testable equalities can detect all possible observable violations of the identifying conditions. We propose a testing procedure for the model's validity using existing inference methods for intersection bounds. Simulation results suggest adequate test size for large samples and reasonable power in detecting violations of the exogeneity assumption and error structure. We review and propose new alternative paths to partially identify the parameters of interest under less restrictive assumptions. We revisit a study of married women's labor supply in Lee (1995) to demonstrate the practical implementation and usefulness of the test.\n\n\nKeywords: Tobit models, hypothesis testing, Testable Implications, Instrumental variables.\nJEL subject classification: C12, C24, C26, C34.", "tables": {}, "images": {}}, {"section_id": 1, "text": "## 1. Introduction\n\nSince the seminal work of Tobin (1958), Tobit models have earned attention in economics, business and social sciences. ${ }^{1}$ Tobin (1958) analyzed household expenditure on durable goods using a regression model that specifically incorporated that expenditure (the dependent variable) cannot be negative. This approach is related to a broader class of censored or truncated regression models, depending on whether observations outside a specified range are lost or censored. When applied researchers are interested in modelling limited dependent variables, potentially with mass accumulation points, the Tobit family of models provides\n\n[^0]\n[^0]:    The present version is as of January 20, 2025, the first version is from December 2022. All errors are ours. Email address: otavio.bartalotti@monash.edu. We want to thank participants at seminars in the 2024 Jornadas Anuales de Econom\u00eda del Banco Central del Uruguay and RMIT University, the 2024 IAAE and Southern Economic Association meetings.\n    ${ }^{1}$ According to Google Scholar Tobin's original paper has more than 10000 citations.\n\nstructure to identify parameters of interest, such as the average treatment effect (ATE). Identification relies on three primary sources: (i) instrument exogeneity (or exogeneity of the variable of interest itself), (ii) normality of the model's latent variables, and in the case of an instrumental variable approach to endogeneity, (iii) the relevance condition for the instrument. While researchers recognize the model's restrictive nature, it remains a valuable tool in the empirical literature.\n\nIn this paper, we develop a test for the validity of the Tobit model's structure and assumptions, providing three main contributions to the literature. The first is to provide sharp testable equalities that can detect all possible observable violations of the Tobit model. Second, we propose a test for the validity of the Tobit model's identifying assumptions using the sharp equalities that characterize the model to check its falsifiability. Following recent literature, we convert the equalities into conditional moment inequalities and implement the test by existing inferential methods from Chernozhukov, Lee, and Rosen (2013). The Tobit family of models involves continuous outcomes with accumulation points and potentially continuous treatment, implying a large number of moment equalities to be tested. This creates significant challenges to test implementation. We propose a discretization of the space of the treatment and the outcome that balances the computational requirements and data availability for different parts of their joint support. This simplifies the implementation, making it easy to compute and providing an asymptotically valid testing procedure.\n\nThe third contribution is to review and propose alternative approaches that can be used when the model is rejected. We explore an alternative path to partially identify the parameter of interest by assuming the monotonicity of selection into treatment. Finally, we provide an empirical example illustrating the methodology's practical relevance. More generally, the current paper contributes to the growing literature on testing identifying assumptions of econometric models.\n\nWe focus on two main models: (i) the \"classic Tobit\" model in which the main variable of interest is assumed to be exogenous and (ii) the instrumental variable (IV) Tobit model. In both cases, the proposed test considers all observable violations of the model structure, such as linear index, normality of the latent errors, independence of the treatment, and homoskedasticity; with the addition of the validity of the instrument for the IV-Tobit. Additional results for variants of the Tobit family of models are presented in the Appendix.\n1.1. Previous Literature. There is a vast literature related to testing the validity of Tobit models and their assumptions, which we contribute to. Most of the preceding work focuses\n\non testing a particular assumption or feature of the model while maintaining other assumptions and structures as valid. Nelson (1981) constructs a Hausman-type test for misspecification of the classic Tobit model (that is, normality, linear index, and homoskedasticity) where the maximum likelihood estimates are compared with method of moment estimates. Nelson's test compares the sample proportion of non-censored observations with the hypothesized probability of being non-censored in the Tobit model. Bera, Jarque, and Lee (1984) state that the test is equivalent to the Lagrange multiplier (LM) test of the Tobit model against Cragg's model (Lin and Schmidt, 1984) and propose an alternative LM test for the normality assumption against other distributions of the Pearson family of distributions while the remaining assumptions are maintained. Newey (1987b) considers both exogenous and endogenous explanatory variables cases using symmetrically censored least squares estimators to construct specification tests of normality and homoskedasticity assumptions via a Hausman-type specification test. Holden (2004) examines several statistics proposed to test the normality assumption in the Tobit (censored regression) model and reinterpreted them as a version of the LM (score) test for a common null hypothesis. Reynolds and Shonkwiler (1991) use an information matrix misspecification test to detect violations of the distributional assumptions of the Tobit model.\n\nOther tests include Drukker (2002), which operationalized conditional moment tests developed by Newey (1985) and Tauchen (1985) to the case of misspecification of the distribution of the classic Tobit model. With a similar intuition to our framework, their test writes down conditional moment restrictions, which should have zero conditional expected values under the null. Since the model was estimated by maximum likelihood, the assumed data-generating process specifies the moments of disturbances conditional on the covariates to be the ones of a normal distribution. Drukker (2002) use these moment-based methods based on the third and fourth moments of the normal distribution. While intuitively similar, our procedure detects all possible violations of the model, not only those evident from deviations in the third and fourth moments. Smith and Blundell (1986) propose a test of the treatment variable's exogeneity in the IV-Tobit Model by a control function approach exploiting the joint normality of the latent variables. Most of these approaches focus on testing a particular subset of assumptions or a specific class of alternatives to consider.\n\nThe developments proposed in this paper consider all observable violations of the general Tobit model structure and its assumptions, serving as a useful test for empirical researchers constructing models for censored/truncated data. This work contributes to the growing literature on the testability of the identifying assumptions in various econometric models.\n\nThose include tests for the validity of assumptions in instrumental variable models, local average treatment effects, regression discontinuity designs, bivariate probit, encouragement designs, among others. (Mourifi\u00e9 and Wan, 2017; Kitagawa, 2015; Huber and Mellace, 2015; Gunsilius, 2021; Arai et al., 2022; Acerenza, Bartalotti, and K\u00e9dagni, 2023; Bai and Tabord-Meehan, 2024). Our testing procedures are connected to K\u00e9dagni and Mourifi\u00e9 (2020), which provides tests for assumptions related to the instrumental variables in the model, while we also consider the implications of the parametric structure on the outcome and latent error structure, which are inherent to Tobit models.\n\nThe two papers closest to ours are Acerenza, Bartalotti, and K\u00e9dagni (2023) and Goff, K\u00e9dagni, and Wu (2024). The first focuses on bivariate probit models, leading to a finite set of moment equalities as testable restrictions. As mentioned above, this study builds upon their work by tackling the case of the Tobit family of estimators, which provides additional technical and practical challenges given the continuous nature of outcome and treatment, including accumulation points. Goff, K\u00e9dagni, and Wu (2024) considers separable parametric instrumental variable models that induce a different set of moment equalities to be tested while our approach focuses on Tobit and IV-Tobit models, which can potentially be non-separable. ${ }^{2}$\n\nThe remainder of the paper is organized as follows. Section 2 presents the model and identifying assumptions. Section 3 derives the sharp testable implications. Section 4 discusses heuristically the identification of the model's parameters. Section 5 outlines the testing procedure. Section 6 include simulation evidence about the test's size while discussions about power are relegated to the Appendix. Section 7 discusses how to relax the assumptions in case of rejection. Section 8 provides an empirical illustration revisiting the study of married women's labor supply from Lee (1995) to demonstrate the practical implementation and usefulness of the test. Finally, Section 9 concludes. Additional results and details are collected in Appendices A-F.", "tables": {}, "images": {}}, {"section_id": 2, "text": "# 2. MODELS \n\nThis section describes two popular \"two-part\" models for truncated data for which we derive testable implications in Section 3: the classic Tobit, and the IV-Tobit. ${ }^{3}$\n\n[^0]\n[^0]:    ${ }^{2}$ While Goff, K\u00e9dagni, and Wu (2024) briefly mention the possibility of extending their results to nonseparable models, they obtain different equalities from ours and do not discuss identification or sharpness. Implementation would also differ from our approach.\n    ${ }^{3}$ We omit conditioning on other exogenous covariates $(X)$ for simplicity of exposition. The results including covariates are presented in Section 5.\n\nLet $Y=\\max \\left(0, Y^{*}\\right)$ be the observed outcome taking values in $\\mathcal{Y} \\subset \\mathbb{R}^{+}$with $Y^{*}$ a latent continuous dependent variable taking values in $\\mathcal{Y}^{*} \\subset \\mathbb{R}$. Both the treatment of interest, $D$, and the instrumental variable, $Z$, can be discrete or continuous and take values in $\\mathcal{D} \\subset \\mathbb{R}$ and $\\mathcal{Z} \\subset \\mathbb{R}$, respectively. We normalize the coefficients by the standard deviation of the convenient unobservable structure for the exposition. ${ }^{4}$\n2.1. Classic Tobit model. The classic Tobit model considers the case in which the researcher is interested in the effect of an exogenous treatment on a non-negative outcome that has a mass point at zero:\n\n$$\n\\left\\{\\begin{array}{l}\nY=\\max \\left(0, Y^{*}\\right) \\\\\nY^{*}=\\alpha_{0}+\\alpha_{1} D+U\n\\end{array}\\right.\n$$\n\nwhere $U$ is an unobservable (latent) error. In addition to the model structure in system 2.1, the classic Tobit restricts the distribution of the error term and its relationship to the treatment.\n\nAssumption 1. $D$ is independent of $U$.\nAssumption 2. $U$ is distributed as $N(0,1)$.\n\nAssumption 1 states that the treatment of interest is independent of the model's unobservables. Assumption 2 imposes that the latent error has a standard normal distribution. ${ }^{5}$\n\nDespite its simplicity, the classic Tobit model can accommodate continuous or discrete treatment, and the normality assumption for the latent error could be replaced by other distributional assumptions that preserve the identification of the parameters.\n2.2. IV Tobit model. The IV Tobit considers the case in which the treatment of interest is endogenous, but an instrumental variable is available to identify its effect. Let the IV Tobit model be: ${ }^{6}$\n\n$$\n\\left\\{\\begin{aligned}\nY & =\\max \\left(0, Y^{*}\\right) \\\\\nY^{*} & =\\alpha_{0}+\\alpha_{1} D+U \\\\\nD & =\\gamma_{0}+\\gamma_{1} Z+V\n\\end{aligned}\\right.\n$$\n\n[^0]\n[^0]:    ${ }^{4}$ Identification for the normalized and non-normalized parameters is discussed in section 4.\n    ${ }^{5}$ The error could take $N\\left(0, \\sigma^{2}\\right)$ but after scale normalizations we can model it as $N(0,1)$.\n    ${ }^{6}$ Results for the IV-Tobit model are presented for continuous $D$ but hold for a binary treatment, $D=$ $1\\left\\{\\gamma_{0}+\\gamma_{1} Z-V>0\\right\\}$. In that case, the parameters are identified only up to scale.\n\nAlternatively, in its reduced form representation:\n\n$$\n\\left\\{\\begin{aligned}\nY & =\\max \\left(0, Y^{*}\\right) \\\\\nY^{*} & =\\beta_{0}+\\beta_{1} Z+W \\\\\nD & =\\gamma_{0}+\\gamma_{1} Z+V\n\\end{aligned}\\right.\n$$\n\nWhere $U, V$ are the latent structural error terms. To that model structure, restrictions on the joint distribution of the latent variables and their relationship to the instrumental variable are added.\n\nAssumption 3. $Z$ is independent of $(U, V)$ and $\\gamma_{1} \\neq 0$.\nAssumption 4. Let $U, V$ follow a bivariate normal distribution with covariance $\\rho$, i.e., $\\binom{U}{V} \\sim \\mathcal{N}(\\mu, \\Sigma)$, where $\\mu=\\binom{0}{0}$, and $\\Sigma=\\left(\\begin{array}{cc}\\sigma_{U}^{2} & \\rho_{U V} \\\\ \\rho_{U V} & \\sigma_{V}^{2}\\end{array}\\right)$.\n\nAssumption 3(i) states that the instrumental variable is independent of the model's structural latent variables. The second part of Assumption 3 is the usual instrument relevance in determining the treatment. This assumption also implies that $Z$ is independent of $W, V$, since $W=\\alpha_{1} V+U$.\n\nAssumption 4 characterizes the distribution of the latent vector of error terms as bivariate normal. Then, $W, V$ also follows a bivariate normal distribution and $\\alpha_{0}, \\alpha_{1}, \\gamma_{0}, \\gamma_{1}$ could be scale normalized so $(W, V)^{\\prime}$ follows the standard bivariate normal distribution with covariance $\\rho$, i.e., $\\binom{W}{V} \\sim \\mathcal{N}(\\mu, \\Sigma)$, where $\\mu=\\binom{0}{0}$, and $\\Sigma=\\left(\\begin{array}{cc}1 & \\rho \\\\ \\rho & 1\\end{array}\\right) .{ }^{7}$ The latter characterization aids the development of the sharp testable implications.", "tables": {}, "images": {}}, {"section_id": 3, "text": "# 3. SHARP TESTABLE EQUALITIES \n\nThis section presents the sharp testable equalities for the models described in Section 2. Deviations from these equalities imply violations of the \"null hypothesis\" that the Tobit model (linear latent index, independence, instrument validity, and normality) is valid. The\n\n[^0]\n[^0]:    ${ }^{7}$ Note that if $U, V$ follow a bivariate normal distribution, $\\binom{U}{V} \\sim \\mathcal{N}(\\mu, \\Sigma)$, where $\\mu=\\binom{0}{0}$, and $\\Sigma=$ $\\left(\\begin{array}{cc}\\sigma_{U}^{2} & \\rho_{U V} \\\\ \\rho_{U V} & \\sigma_{V}^{2}\\end{array}\\right)$, then $W, V$ follow a bivariate normal distribution, $\\binom{W}{V} \\sim \\mathcal{N}\\left(\\mu_{1}, \\Sigma_{1}\\right)$, where $\\mu_{1}=\\binom{0}{0}$, and $\\Sigma_{1}=\\left(\\begin{array}{cc}\\alpha_{1}^{2} \\sigma_{V}^{2}+\\sigma_{U}^{2}+2 \\rho_{U V} \\alpha_{1} \\sigma_{V} \\sigma_{U} & \\alpha_{1} \\sigma_{V}^{2}+\\rho_{U V} \\\\ \\alpha_{1} \\sigma_{V}^{2}+\\rho_{U V} & \\sigma_{V}^{2}\\end{array}\\right)$. Then the reduced form system can be scale normalized.\n\nequalities are conditional on parameters being identified under the model's assumptions, and a discussion on identification is postponed to Section 4.\n3.1. Classic Tobit model. A defining characteristic of Tobit and similar models is the mass accumulation at zero for the distribution of the non-negative outcome, $Y$. Thus, the model's testable implications require characterizing the distribution at both the mass point and beyond it.\n\nStarting at the continuous part of the distribution of $Y$, the conditional probabilities of $c_{0} \\leq Y \\leq c_{1}$ are observed for $c_{1}, c_{0}>0$. For any value of the treatment variables $d \\in \\mathcal{D}$ :\n\n$$\n\\begin{aligned}\nP\\left(c_{0} \\leq Y \\leq c_{1} \\mid D=d\\right) & =P\\left(c_{0} \\leq Y \\leq c_{1}, Y^{*} \\geq 0 \\mid D=d\\right) \\\\\n& +P\\left(c_{0} \\leq Y \\leq c_{1}, Y^{*}<0 \\mid D=d\\right) \\\\\n& =P\\left(c_{0} \\leq Y \\leq c_{1}, Y^{*} \\geq 0 \\mid D=d\\right) \\\\\n& =P\\left(c_{0} \\leq Y^{*} \\leq c_{1}, Y^{*} \\geq 0 \\mid D=d\\right) \\\\\n& =P\\left(c_{0} \\leq Y^{*} \\leq c_{1} \\mid D=d\\right) \\\\\n& =P\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d \\leq U \\leq c_{1}-\\alpha_{0}-\\alpha_{1} d \\mid D=d\\right) \\\\\n& =\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d\\right)-\\Phi\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d\\right)\n\\end{aligned}\n$$\n\nwhere $\\Phi($.$) is the standard normal CDF. The first equality follows from the law of total$ probability. The second through fourth equalities follow from the model's structure described in Equation 2.1, namely $P\\left(Y>0, Y^{*}<0 \\mid D=d\\right)=0$ and $Y^{*}=Y$ for $Y^{*}>0$. The fifth one is given by the latent linear model structure of $Y^{*}$, and finally, the last step follows from assumptions 1 and 2 . To cover all possible cases of positive outcomes, note that for any $c_{1}>0$ :\n\n$$\nP\\left(c_{1} \\leq Y \\mid D=d\\right)=1-\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d\\right)\n$$\n\nTurning to the accumulation point, the observed event of $Y=0$ has probability,\n\n$$\nP(Y=0 \\mid D=d)=P\\left(Y^{*} \\leq 0 \\mid D=d\\right)=\\Phi\\left(-\\alpha_{0}-\\alpha_{1} d\\right)\n$$\n\nThe first equality follows from the model's structure in Equation 2.1, and the second one applies assumptions 1 and 2 . The equalities described in equations 3.1-3.3 fully characterize the distribution of $Y$ conditional on $D$, connecting the probabilities in the observed data to those implied by the Tobit model.\n\nRemark 1 (Sharpness). In the context of model 2.1, equalities 3.1-3.3 are sharp in the sense that whenever they hold, it is possible to construct a vector of $(\\tilde{Y}, D, \\tilde{U})$ that satisfies\n\nmodel 2.1, Assumptions 1 and 2, and induces the observed distribution on the data $(Y, D)$. For the proof, see Appendix A.\n\nThen, the equalities 3.1-3.3 are sharp testable implications for the validity of the classic Tobit Model in 2.1 coupled with assumptions 1-2. They serve as the basis for the test procedure described in Section 5.\n\nRemark 2 (Non-learnability). The testable implications and sharpness discussed above show that the classic Tobit model is generally refutable. However, the model is non-verifiable in the sense that we can always construct a joint probability law of $(\\bar{Y}, D, \\bar{U})$ that violates the Tobit model validity but satisfies equalities 3.1-3.3. See Appendix E for the proof.\n\nRemark 3 (Extensions). The previous derivation can be adjusted for different variations of Tobit models, such as generalizations of the distributional assumptions (Barros et al., 2018), different thresholds (Carson and Sun, 2007), dynamic Tobit models, or including individual specific effects (Wooldridge, 2005; Honore, Kyriazidou, and Powell, 2000; Honor\u00e9, 1993). In appendix $C$, we derive the equalities for the type 2 Tobit model, and similar logic can be applied to other two-part models. Additional testable results for the aforementioned models are discussed in Appendix D.\n3.2. IV Tobit model. We turn our attention to the instrumental variable Tobit case and propose testable implications that can be used to test the model described in 2.2 and the associated assumptions 3 and 4 .\n\nThe observed data includes $(Y, D, Z)$, and we characterize the joint distribution of $(Y, D) \\in$ $\\mathcal{Y} \\times \\mathcal{D}$ conditional on the instrument, $Z$, to obtain the model's testable implications. The mapping from observed probabilities to their corresponding quantities implied by the IV Tobit model requires jointly evaluating the continuous (interior) support for the outcome and treatment variables, as well as the accumulation points and distribution tails conditional\n\non $Z$. Consider any $0<c_{0}<c_{1}, d_{0}<d_{1}$, and $z \\in \\mathcal{Y} \\times \\mathcal{D} \\times \\mathcal{Z}$,\n\n$$\n\\begin{aligned}\nP\\left(c_{0} \\leq Y \\leq c_{1}, d_{0} \\leq D \\leq d_{1} \\mid Z=z\\right) & =\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& +\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& \\equiv \\Phi_{c_{1}, c_{0}, d_{1}, d_{0}}^{1} \\\\\nP\\left(c_{0} \\leq Y \\leq c_{1}, D \\leq d_{0} \\mid Z=z\\right) & =\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& \\equiv \\Phi_{c_{1}, c_{0}, d_{0}}^{1} \\\\\nP\\left(c_{0} \\leq Y \\leq c_{1}, D \\geq d_{1} \\mid Z=z\\right) & =\\Phi_{W}\\left(c_{1}-\\beta_{0}-\\beta_{1} z\\right)-\\Phi_{W}\\left(c_{0}-\\beta_{0}-\\beta_{1} z\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& +\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& \\equiv \\Phi_{c_{1}, c_{0}, d_{1}}^{1} \\\\\nP\\left(c_{1} \\leq Y, d_{0} \\leq D \\leq d_{1} \\mid Z=z\\right) & =\\Phi_{V}\\left(d_{1}-\\gamma_{0}-\\gamma_{1} z\\right)-\\Phi_{V}\\left(d_{0}-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& +\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& \\equiv \\Phi_{c_{1}, d_{1}, d_{0}}^{1} \\\\\nP\\left(c_{1} \\leq Y, D \\leq d_{0} \\mid Z=z\\right) & =\\Phi_{V}\\left(d_{0}-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& \\equiv \\Phi_{c_{1}, d_{0}}^{1} \\\\\nP\\left(c_{1} \\leq Y, D \\geq d_{1} \\mid Z=z\\right) & =1-\\Phi_{W}\\left(c_{1}-\\beta_{0}-\\beta_{1} z\\right)-\\Phi_{V}\\left(d_{1}-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n& +\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& \\equiv \\Phi_{c_{1}, d_{1}}^{1}\n\\end{aligned}\n$$\n\nwhere $\\Phi_{W, V}(w, v ; \\rho)$ denotes the joint c.d.f. of $(W, V)$, a standard bivariate normal with coefficient of correlation $\\rho$. Similarly, considering the case that the observed $Y$ equals zero,\n\n$$\n\\begin{aligned}\nP\\left(Y=0, d_{0} \\leq D \\leq d_{1} \\mid Z=z\\right) & =\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\equiv \\Phi_{d_{1}, d_{0}}^{2} \\\\\nP\\left(Y=0, D \\leq d_{0} \\mid Z=z\\right) & =\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\equiv \\Phi_{d_{0}}^{2} \\\\\nP\\left(Y=0, D \\geq d_{1} \\mid Z=z\\right) & =\\Phi_{W}\\left(-\\beta_{0}-\\beta_{1} z\\right)-\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& \\equiv \\Phi_{d_{1}}^{2}\n\\end{aligned}\n$$\n\nRemark 4 (Sharpness). In the context of model 2.2 or 2.3, equalities 3.4-3.12 for all $c, d, z \\in \\mathcal{Y} \\times \\mathcal{D} \\times \\mathcal{Z}$ are sharp in the sense that whenever they hold, it is possible to construct a vector of $(\\tilde{Y}, \\tilde{D}, \\tilde{U}, \\tilde{V}, Z)$ or equivalently $(\\tilde{Y}, \\tilde{D}, \\tilde{W}, \\tilde{V}, Z)$ that satisfies model 2.2 and 2.3, Assumptions 3 and 4, and induces the observed distribution on the data $(Y, D, Z)$. See Appendix B for the proof.\n\nRemark 5 (Non-learnability). The testable implications and sharpness discussed above show that the IV-Tobit model is generally refutable. However, the model is non-verifiable. The demonstration follows a similar logic as in the classic Tobit case. See Appendix E for the proof.\n\nThen, the equalities 3.4-3.12 are sharp testable implications for the validity of the instrumental variable Tobit Model in 2.2 coupled with assumptions 3-4. They serve as the basis for the test procedure described in Section 5.", "tables": {}, "images": {}}, {"section_id": 4, "text": "# 4. IDENTIFICATION \n\nIn this section, we provide heuristic arguments for the identification of the parameters of the respective models, expanding on Han and Vytlacil (2017) and Acerenza, Bartalotti, and K\u00e9dagni (2023).\n4.1. Classic Tobit model. Equation (3.3) established that in the classic Tobit model,\n\n$$\n1-P(Y=0 \\mid D)=\\Phi\\left(\\alpha_{0}+\\alpha_{1} D\\right)\n$$\n\nSince the standard normal CDF, $\\Phi($.$) , is monotonic, we use its inverse to obtain:$\n\n$$\n\\Phi^{-1}(1-P(Y=0 \\mid D))=\\alpha_{0}+\\alpha_{1} D\n$$\n\nThus, $\\alpha_{1}=\\frac{\\operatorname{Cov}\\left(\\Phi^{-1}(1-P(Y=0 \\mid D)), D\\right)}{\\operatorname{Var}(D)}$, and $\\alpha_{0}=E\\left(\\Phi^{-1}(1-P(Y=0 \\mid D))\\right)-\\alpha_{1} E(D)$.\n\nThe coefficients have been normalized by dividing by the latent variable's $(U)$ square root of the variance, denoted by $\\sigma$. Naturally, this implies that the ratio of the original parameters is identified since $P(Y=0 \\mid D=d)=\\Phi\\left(\\alpha_{0}+\\alpha_{1} D\\right)=\\Phi\\left(\\tilde{\\alpha}_{0} / \\sigma+\\tilde{\\alpha}_{1} / \\sigma D\\right)$. This allows the identification of the inverse mills ratio, which is a known function of the standard normal density, $\\lambda\\left(\\tilde{\\alpha}_{0} / \\sigma+\\tilde{\\alpha}_{1} / \\sigma D\\right)$ ). Then,\n\n$$\nE(Y \\mid D, Y>0)=\\tilde{\\alpha}_{0} / \\sigma+\\tilde{\\alpha}_{1} / \\sigma D+\\sigma \\lambda\\left(\\tilde{\\alpha}_{0} / \\sigma+\\tilde{\\alpha}_{1} / \\sigma D\\right))\n$$\n\nWhich in turn implies:\n\n$$\nY=\\tilde{\\alpha}_{0} / \\sigma+\\tilde{\\alpha}_{1} / \\sigma D+\\sigma \\lambda\\left(\\tilde{\\alpha}_{0} / \\sigma+\\tilde{\\alpha}_{1} / \\sigma D\\right))+e\n$$\n\nwith $e$ mean independent of $D, \\lambda(\\cdot)$. Since $D$ is known and $\\lambda(\\cdot)$ was already identified then by considering the moment conditions for $\\operatorname{Cov}(., D), \\operatorname{Cov}(., \\lambda(\\cdot))$ and $E($.$) we get a three$ by three linear system with a unique solution for $\\tilde{\\alpha}_{0}, \\tilde{\\alpha}_{1}, \\sigma$. In other words, the normality assumption allows identification by leveraging the relationship of the variable of interest and the outcome at the accumulation point $(Y=0)$ to obtain the scaled parameters, and the same relationship when $Y>0$ to overcome the normalization. However, the reliance on the normality and linearity assumptions underlines the importance of adequately testing the model's structure and assumptions in empirical applications.\n4.2. IV Tobit model. Turning the focus to the IV-Tobit model, the first stage is readily identified from the linear structure, $\\gamma_{1}=\\frac{\\operatorname{Cov}(Z, D)}{\\operatorname{Var}(Z)}, \\gamma_{0}=E(D)-\\gamma_{1} E(Z)$. Now note that calculating $P(Y=0 \\mid Z)$ :\n\n$$\n1-P(Y=0 \\mid Z)=\\Phi\\left(-\\beta_{0}-\\beta_{1} Z\\right)\n$$\n\nSimilarly to subsection 4.1, by inverting the normal CDF we obtain $-\\beta_{1}=\\frac{\\operatorname{Cov}\\left(\\Phi^{-1}(1-P(Y=0 \\mid Z)), Z\\right)}{\\operatorname{Var}(Z)}$, $-\\beta_{0}=E\\left(\\Phi^{-1}(1-P(Y=0 \\mid Z))\\right)+\\beta_{1} E(Z)$. The relationship between $\\beta_{0}, \\beta_{1}, \\gamma_{0}, \\gamma_{1}$ identifies $\\left(\\alpha_{0}, \\alpha_{1}\\right)$. Finally, to identify $\\rho$, let $s=c-\\beta_{0}-\\beta_{1} z$ and $t=d-\\gamma_{0}-\\gamma_{1} z$. Then, by using equation 3.7:\n\n$$\nP(Y \\leq c, D \\leq d \\mid Z=z)=\\Phi_{W, V}(s, t ; \\rho)\n$$\n\nWhich by classic results of bivariate normal random variables if we differentiate with respect to $\\rho$ is:\n\n$$\n\\frac{\\partial P(Y \\leq c, D \\leq d \\mid Z=z)}{\\partial \\rho}=\\phi_{W, V}(s, t ; \\rho)\n$$\n\nWhere $\\phi_{a, b}$ is the bivariate normal probability density, which is positive for any $s, t$. Hence, $\\Phi_{W, V}(., . ; \\rho)$ is monotonic in $\\rho$ and thus invertible. So $\\rho$ can be identified.\n\nRecall the previous coefficients are normalized, a two-step procedure can be followed to identify the full original covariance matrix and the reduced form covariance matrix (Wooldridge, 2010, p. 683-84).", "tables": {}, "images": {}}, {"section_id": 5, "text": "# 5. TESTING PROCEDURE \n\nTo test the sharp equalities, we rewrite each of these equalities as two inequalities (Mourifi\u00e9 and Wan, 2017; Acerenza, Bartalotti, and K\u00e9dagni, 2023). For a concrete example, we first note that\n$P\\left(c_{1} \\leq Y \\mid D=d\\right)=1-\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d\\right) \\Longleftrightarrow E\\left[1\\left\\{c_{1} \\leq Y\\right\\}-1+\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} D\\right) \\mid D\\right]=0$.\nWe rewrite each of these moment equalities implied by the restrictions on the empirical distribution as moment inequalities\n$E\\left[1\\left\\{c_{1} \\leq Y\\right\\}-1+\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} D\\right) \\mid D\\right] \\leq 0, E\\left[-1\\left\\{c_{1} \\leq Y\\right\\}+1-\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} D\\right) \\mid D\\right] \\leq 0$.\nIn doing this for all the restrictions on the empirical distribution, we can implement a test relying on existing intersection bounds inferential methods such as Chernozhukov, Lee, and Rosen (2013), which is specifically suited to test conditional moment inequalities.\n\nNote that the equalities for the classic Tobit hold for any pair of constants $\\left(c_{0}, c_{1}\\right)$, and the ones from the IV Tobit hold for pairs of $\\left(c_{0}, c_{1}\\right)$ and $\\left(d_{0}, d_{1}\\right)$. We propose a partition of $\\mathcal{Y} \\times \\mathcal{D}$ to test sufficient conditions of these sharp equalities. Rejection of any of the null hypotheses that the equalities hold at these particular levels implies violations of the model.\n\nClassic Tobit model. The sharp testable equalities for every $c_{0}, c_{1} \\in \\mathcal{Y}$ are given by equations 3.1 and 3.3. For a partition of the support of $Y$ into $K$ arbitrary chosen sets $C_{k}=\\left(0, c_{k}\\right)$ such that $C_{k} \\in C_{k+1}$, the following set of sufficient inequalities are, for some chosen values of $c_{k}, c_{k+1} \\in \\mathcal{Y}$, related to the components of 3.1-3.3.\n\nThe formulation of the inequalities considered will depend on each partition's location on the support of the outcome variable $Y$. Let $c_{1}=0$ and $W_{k}$ be\n$W_{k}=\\left\\{\\begin{array}{cl}1\\{Y=0\\}-\\left(1-\\Phi\\left(\\alpha_{0}+\\alpha_{1} D\\right)\\right), & \\text { if } k=0 \\\\ 1\\left\\{c_{k}<Y \\leq c_{k+1}\\right\\}-\\Phi\\left(c_{k+1}-\\alpha_{0}-\\alpha_{1} D\\right)+\\Phi\\left(c_{k}-\\alpha_{0}-\\alpha_{1} D\\right), & \\text { if } 1 \\leq k<K \\\\ 1\\left\\{c_{K}<Y\\right\\}-\\left(1-\\Phi\\left(c_{K}-\\alpha_{0}-\\alpha_{1} D\\right)\\right), & \\text { if } k=K\\end{array}\\right.$\n\nThe intersection bounds framework considers the following $2(K+1)$ inequalities\n\n$$\n\\begin{aligned}\n\\sup _{d} E\\left[W_{k} \\mid D=d\\right] & \\leq 0 \\\\\n\\sup _{d} E\\left[-W_{k} \\mid D=d\\right] & \\leq 0, \\text { for } k=0, \\ldots, K\n\\end{aligned}\n$$\n\nWe can write more compactly as\n\n$$\n\\max _{k} \\sup _{D} \\theta_{k}(D) \\leq 0\n$$\n\nwhere $\\theta_{k}(D)$ collects all the inequalities being tested. The decision rule for the test is given by Chernozhukov, Lee, and Rosen (2013), we reject $H_{0}$ if\n\n$$\n\\hat{\\theta}_{1-\\alpha} \\equiv \\max _{k} \\sup _{D}\\left\\{\\hat{\\theta}(D, k)-\\kappa_{1-\\alpha} \\hat{s}(D, k)\\right\\}>0\n$$\n\nwhere $\\hat{\\theta}(D, k)$ is a nonparametric estimator for $\\theta_{k}(D), \\hat{s}(D, k)$ its standard error, and $\\kappa_{1-\\alpha}$ is a critical value at the significance level $\\alpha$.\n\nIV Tobit model. For the instrumental variable Tobit model, the continuous support for both the outcome and treatment poses challenges to the implementation of the test. ${ }^{8}$ The sharp testable equalities for every $c_{0}, c_{1} \\in \\mathcal{Y}$ and $d_{0}, d_{1} \\in \\mathcal{D}$ are given by equations 3.4-3.12.\n\nConsider a partition of the support of $Y$ into $K$ arbitrary chosen sets $C_{k}=\\left(0, c_{k}\\right)$ such that $C_{k} \\in C_{k+1}$ and of the support of $D$ into $Q$ arbitrary chosen sets $D_{q}=\\left(0, d_{q}\\right)$ such that $D_{q} \\in D_{q+1}$, the following set of sufficient inequalities are related to the components of (3.4)(3.12). Analogous to the classic Tobit case, the formulation of the inequalities considered will depend on each partition's location on the joint support of the outcome and treatment variables. Let $W_{k q}$ be given by,\n\n$$\nW_{k q}=\\left\\{\\begin{array}{cl}\n1\\{Y=0\\} 1\\left\\{D \\leq d_{0}\\right\\}-\\Phi_{d_{0}}^{2}, & \\text { if } k=0, q=0 \\\\\n1\\{Y=0\\} 1\\left\\{d_{q} \\leq D \\leq d_{q+1}\\right\\}-\\Phi_{d_{q}, d_{q+1}}^{2}, & \\text { if } k=0,1 \\leq q<Q \\\\\n1\\{Y=0\\} 1\\left\\{D \\geq d_{Q}\\right\\}-\\Phi_{d_{Q}}^{2}, & \\text { if } k=0, q=Q \\\\\n1\\left\\{c_{k} \\leq Y \\leq c_{k+1}\\right\\} 1\\left\\{D \\leq d_{0}\\right\\}-\\Phi_{c_{k+1}, c_{k}, d_{0}}^{1}, & \\text { if } 1 \\leq k<K, q=0 \\\\\n1\\left\\{c_{k} \\leq Y \\leq c_{k+1}\\right\\} 1\\left\\{d_{q} \\leq D \\leq d_{q+1}\\right\\}-\\Phi_{c_{k+1}, c_{k}, d_{q+1}, d_{q}}^{1}, & \\text { if } 1 \\leq k<K, 1 \\leq q<Q \\\\\n1\\left\\{c_{k} \\leq Y \\leq c_{k+1}\\right\\} 1\\left\\{D \\geq d_{Q}\\right\\}-\\Phi_{c_{k+1}, c_{k}, d_{Q}}^{1}, & \\text { if } 1 \\leq k<K, q=Q \\\\\n1\\left\\{Y \\geq c_{K}\\right\\} 1\\left\\{D \\leq d_{0}\\right\\}-\\Phi_{c_{K}, d_{0}}^{1}, & \\text { if } k=K, q=0 \\\\\n1\\left\\{Y \\geq c_{K}\\right\\} 1\\left\\{d_{q} \\leq D \\leq d_{q+1}\\right\\}-\\Phi_{c_{K}, d_{q+1}, d_{q}}^{1}, & \\text { if } k=K, 1 \\leq q<Q \\\\\n1\\left\\{Y \\geq c_{K}\\right\\} 1\\left\\{D \\geq d_{Q}\\right\\}-\\Phi_{c_{K}, d_{Q}}^{1}, & \\text { if } k=K, q=Q\n\\end{array}\\right.\n$$\n\n[^0]\n[^0]:    ${ }^{8}$ Note that a discrete treatment can also be accommodated as an intermediate step between the current derivation and the derivations from Acerenza, Bartalotti, and K\u00e9dagni (2023).\n\nWhere we used the simplifying notation defined in equations (3.4)-(3.12) for each partition of the support for $Y$ and $D$. The intersection bounds framework considers the following $2(K+1)(Q+1)$ inequalities\n\n$$\n\\begin{aligned}\n\\sup _{z} E\\left[W_{k q}[Z=z]\\right. & \\leq 0 \\\\\n\\sup _{z} E\\left[-W_{k q}[Z=z]\\right. & \\leq 0, \\text { for } k=0, \\ldots, K ; q=0, \\ldots, Q\n\\end{aligned}\n$$\n\nWe can write more compactly as\n\n$$\n\\max _{k, q} \\sup _{Z} \\theta_{k} q(Z) \\leq 0\n$$\n\nwhere $\\theta_{k} q(Z)$ collects all the inequalities being tested. The decision rule for the test is given by Chernozhukov, Lee, and Rosen (2013), we reject $H_{0}$ if\n\n$$\n\\hat{\\theta}_{1-\\alpha} \\equiv \\max _{k, q} \\sup _{Z}\\left\\{\\hat{\\theta}(Z, k, q)-\\kappa_{1-\\alpha} \\hat{s}(D, k, q)\\right\\}>0\n$$\n\nwhere $\\hat{\\theta}(Z, k, q)$ is a nonparametric estimator for $\\theta_{k q}(Z), \\hat{s}(D, k, q)$ its standard error, and $\\kappa_{1-\\alpha}$ is a critical value at the significance level $\\alpha$.\n\nTo implement the test within the Chernozhukov, Lee, and Rosen (2013) intersection bounds inferential method, we use the CLR Stata package described in Chernozhukov et al. (2015). The parameters in the relevant model, for example, $\\beta_{0}, \\beta_{1}, \\gamma_{0}, \\gamma_{1}, \\rho$, are replaced by their maximum likelihood estimators (MLE), and asymptotic validity of this \"plug-in\" test follows from the argument described by (Acerenza, Bartalotti, and K\u00e9dagni, 2023, Appendix B). Some additional details on the test implementation are discussed in Section 6 .\n\nRemark 6. Intuitively, the testable conditions derived above consider whether the empirical conditional distribution of the observed outcome variable - in both the mass accumulation and non-truncated parts of the support of $Y$ - is consistent with a random variable(s) following the (bivariate) normal distribution for different sections of the distribution and values of the independent instrument, $Z$.\n\nThe proposed test procedures are intended to detect violations of the model due to:\n\n1. Misspecification of the latent structure that makes the coefficient estimates biased as estimates of the true coefficients of $Y^{*}$;\n2. Violations arising from the empirical distribution of $Y$ being inconsistent with the implied distributions from the parametric structure (that is if the proportion of residuals in different parts of its support deviate from the normality assumptions);\n\n3. Violations due to the empirical distributions of the residuals differing from the implied distributions in certain values of the treatment (Classic Tobit) or instrument (IV Tobit), which indicate violations of the exogeneity of treatment or instrument (K\u00e9dagni and Mourifi\u00e9, 2020).\n\nIncluding Covariates. The proposed procedure can be extended to include exogenous covariates, $X$, within the linear index model in 2.2. Then, the testable equalities for classic and IV Tobit models can be derived with the additional conditioning on $X$. The test with covariates could be implemented by generating a partition of the covariate space, say in $J$ grids, similar to the partition of the exogenous variable used in Section 5. For every grid in the partition, one computes the test statistic 5.2 or 5.4 for the classic or the IV-tobit, respectively. Then obtain critical values that account for multiple testing via a Bonferroni correction. In particular, for every grid, set the critical value at the significance level $\\frac{\\alpha}{J}$, namely $\\kappa_{1-\\frac{\\alpha}{J}} \\cdot{ }^{9}$ This procedure can be cumbersome when there are many covariates or when they are continuous.\n\nAnother route that is less computationally intensive follows Acerenza, Bartalotti, and K\u00e9dagni (2023). We illustrate it for the $I V$-tobit case, and a similar logic could be applied to the classic Tobit case. Thus, with covariates added to the linear index function, we have,\n\n$$\n\\left\\{\\begin{array}{l}\nY=\\max \\left(0, Y^{*}\\right) \\\\\nY^{*}=\\beta_{0}+\\beta_{1} Z+\\beta_{2} X+W \\\\\nD=\\gamma_{0}+\\gamma_{1} Z+\\gamma_{2} X+V\n\\end{array}\\right.\n$$\n\nWe extend Assumption 3 to formalize covariates' exogeneity:\n\nAssumption 5 (full independence). $(Z, X) \\Perp(W, V)$.\n\n[^0]\n[^0]:    ${ }^{9} \\mathrm{~A}$ theoretically interesting approach would partition the joint support of all the exogenous variables and compute the test statistics across all parts of the grid. However, this approach would entail significant implementation challenges since the statistical package for Chernozhukov et al. (2015) allows for only one exogenous covariate.\n\nUnder Assumptions 4-5, by a similar argument to that used in Section 3, any given generic testable implication becomes\n\n$$\n\\begin{aligned}\nP\\left(c_{0} \\leq Y \\leq c_{1}, d_{0} \\leq D \\leq d_{1} \\mid Z=z, X=x\\right) & =\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z-\\beta_{2} x, d_{1}-\\gamma_{0}-\\gamma_{1} z-\\gamma_{2} x ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z-\\beta_{2} x, d_{1}-\\gamma_{0}-\\gamma_{1} z-\\gamma_{2} x ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z-\\beta_{2} x, d_{0}-\\gamma_{0}-\\gamma_{1} z-\\gamma_{2} x ; \\rho\\right) \\\\\n& +\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z-\\beta_{2} x, d_{0}-\\gamma_{0}-\\gamma_{1} z-\\gamma_{2} x ; \\rho\\right)\n\\end{aligned}\n$$\n\nfor all $z \\in \\mathcal{Z}$ and $x \\in \\mathcal{X}$, where $x$ can be a vector. Equivalent conditions for the case that $Y=0$ and other parts of the support of $Y$ and $D$ can be similarly obtained.\n\nImplementation. Since the test is carried out nonparametrically, we face challenges when the dimension of $X$ is large, especially with continuous covariates. Another operational limitation is that the Stata's clrbound package only allows for one conditioning variable at a time. For those practical reasons, we propose implementing a weaker, non-sharp, version of the testable equalities. Continuing with the example of Equality 5.6, we can integrate over the covariates $X$ (or alternatively, $Z$ ), taking advantage of the fact that $\\mathbb{E}[W \\mid Z=z, X=x]=0$ implies $\\mathbb{E}[W \\mid Z=z]=0$ and $\\mathbb{E}[W \\mid X=x]=0$ for all random variables $W$.\n\nImplementation becomes very similar to the IV-Tobit discussed above by redefining the simplifying notation in equations (3.4)-(3.12), with the only difference being the inclusion of $X$ on the linear indexes in $\\Phi_{W}(\\cdot)$ and $\\Phi_{W, V}(\\cdot, \\cdot, \\cdot)$. For example,\n\n$$\n\\begin{aligned}\n\\Phi_{c_{1}, c_{0}, d_{1}, d_{0}}^{1} & \\equiv \\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z-\\beta_{2} x, d_{1}-\\gamma_{0}-\\gamma_{1} z-\\gamma_{2} x ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z-\\beta_{2} x, d_{1}-\\gamma_{0}-\\gamma_{1} z-\\gamma_{2} x ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z-\\beta_{2} x, d_{0}-\\gamma_{0}-\\gamma_{1} z-\\gamma_{2} x ; \\rho\\right) \\\\\n& +\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z-\\beta_{2} x, d_{0}-\\gamma_{0}-\\gamma_{1} z-\\gamma_{2} x ; \\rho\\right)\n\\end{aligned}\n$$\n\nand similarly for the other terms. Then, compute the new $W_{k q}$ in the same manner as in Section 5, and the intersection bounds framework considers the similar $2(K+1)(Q+1)$ inequalities, based on the partition of the support of $Y$ and $D$.\n\n$$\n\\begin{aligned}\n\\sup _{z} E\\left[W_{k q} \\mid Z=z\\right] & \\leq 0 \\\\\n\\sup _{z} E\\left[-W_{k q} \\mid Z=z\\right] & \\leq 0, \\text { for } k=0, \\ldots, K ; q=0, \\ldots, Q\n\\end{aligned}\n$$\n\nThis is the test procedure that we implement for the empirical application in Section 8.\nUnder Assumption 5, one could base the test in conditioning on a particular covariate $X_{C}$ instead of $Z$ by integrating the sharp Equality 5.6 over $Z$ and then implementing the intersection bounds procedure using $X_{C}$ as the sole conditioning variable. ${ }^{10}$", "tables": {}, "images": {}}, {"section_id": 6, "text": "# 6. Simulations \n\nIn this section, we provide simulation exercises for the proposed tests. The testing procedure described relies on testing sharp equalities that should hold for any arbitrary partition of the outcome, treatment and instrument support. When both the outcome and treatment are continuous, evaluating all possible equalities is technically challenging. We focus on a non-sharp set of the equalities by evaluating them at different grid partitions of their support, in a similar spirit to Honor\u00e9 and Hu (2020) which is particularly well suited for continuous supports. Naturally, this choice makes the test less powerful as we don't consider the continuum of equalities derived in Section 4, but is justified by the ease of implementation of the procedure based on intersection bounds and the performance of the test on the simulations below.\n\nFor the simulations related to the classic Tobit, we partition the support of the observed outcome variable into the accumulation point $(Y=0)$ and four quartiles on the (untruncated) positive range, while for the IV-Tobit case we also partition the support of the treatment variable $(D)$ to create a grid based on both the outcome and treatment. ${ }^{11}$ The choice of the number and location of the partitions/evaluation points balances the implementation computational requirements, data availability for different parts of the joint support of the outcome, treatment and exogenous instrumental variable. For the procedure in Section 5 to be feasible, we must have data on both the outcome and the exogenous variables within each partition. Using the empirical quantiles of the non-truncated outcomes to determine the partitions guarantees a reasonable number of observations for each grid part. Larger sample sizes might allow finer partitions for the outcome support. Still, the added\n\n[^0]\n[^0]:    ${ }^{10}$ Assumption 5 constraints the relationship between the covariates and the latent error terms in such a way that one could combine the information on all $X$ and $Z$ in an index and construct non-sharp testable equalities that would hold conditional on this index. For example, having $\\sup _{t} E\\left[W_{k q} \\mid Z+X_{1}+\\ldots+X_{C}=\\right.$ $t]=0$, for $k=0, \\ldots, K ; q=0, \\ldots, Q$.\n    ${ }^{11}$ Note that if the treatment variable was discrete, the respective grid points could be set naturally to the possible countable values $D$ takes.\n\ncomputational requirements created by an increased number of equalities being checked, coupled with the larger datasets, can substantially increase computing time. ${ }^{12}$\n\nWhen implementing the intersection bounds in STATA using the package clrbound Chernozhukov et al. (2015), the researcher must determine the range of values of the exogenous variable for which each equality will be evaluated. To guarantee the feasibility of the procedure, we adjust the evaluation points for $D(Z)$ to the first and $99^{\\text {th }}$ percentiles of the exogenous variable in each partition of the support for the outcome $Y .{ }^{13}$\n\nIn evaluating the finite sample performance of the proposed tests, we consider a continuous treatment $D$ following the data generating process described in Equation 6.1.\n\n$$\n\\left\\{\\begin{aligned}\nY & =\\max \\left\\{Y^{*}, 0\\right\\} \\\\\nY^{*} & =D+U \\\\\nD & =2 Z-V \\\\\n\\left(\\begin{array}{l}\nU \\\\\nV \\\\\nZ\n\\end{array}\\right) & \\sim \\mathcal{N}\\left(\\mathbf{0}_{3}, \\boldsymbol{\\Sigma}\\right) \\\\\n\\boldsymbol{\\Sigma} & =\\left(\\begin{array}{ccc}\n1 & \\rho_{u v} & \\rho_{u z} \\\\\n\\rho_{u v} & 1 & \\rho_{v z} \\\\\n\\rho_{u z} & \\rho_{v z} & 1\n\\end{array}\\right) \\\\\n\\rho_{u z} & =\\rho_{v z}=0 \\\\\n\\rho_{u v} & =\\rho\n\\end{aligned}\\right.\n$$\n\nWhere $\\mathbf{0}_{p}$ is a $p \\times 1$ vector of zeroes. The parameter $\\rho$ determines the intensity of dependence between the latent variables jointly determining the treatment and outcome. Under the treatment exogeneity condition described in Assumption 1, $\\rho=0$. Table 1 presents the empirical test sizes for the Classic Tobit test this scenario, for different significance levels $\\alpha$. The results indicate that while the test over rejects the null hypothesis for small to mid-sized samples, the test's empirical coverage approaches its desired nominal benchmark as samples larger than 5,000 are used.\n\nTo consider the test's performance under violations of the exogeneity assumption, we modify the DGP in Equation 6.1 with different values for $\\rho$, reflecting various degrees of treatment endogeneity. Larger values of $\\rho$ produce more acute violations of the null\n\n[^0]\n[^0]:    ${ }^{12}$ The simulations presented in Section 6 have limited sample sizes and a relatively small number of equalities being tested due to the long-running time and computational constraints when repeating the test procedure thousands of times.\n    ${ }^{13}$ See details on implementation on the simulation replication STATA code.\n\nTable 1. Classic Tobit Test Size\n\n![table_0](table_0)\n\nBased on 500 replications.\nhypothesis. Table 2 presents the results for the Classic Tobit test: columns 3-4 report the MSE, while the remaining columns show empirical rejection rates. As expected, the power of the test increases with larger $\\rho$ and bigger sample sizes. ${ }^{14}$\n\nNaturally, researchers concerned about treatment endogeneity should consider the IVTobit model and implement the test of its identifying assumptions proposed in Section 5. Table 3 presents the empirical coverage for the test of the IV-Tobit model for different levels of treatment endogeneity $(\\rho=\\{0,0.5,0.8\\})$ for sample sizes 5,000 and 8,000 . The test produces adequate empirical coverage, in line with the results for the classic Tobit test.", "tables": {"table_0": "| N | $\\alpha=10 \\%$ | $\\alpha=5 \\%$ | $\\alpha=1 \\%$ |\n| :--: | :--: | :--: | :--: |\n| 1000 | $18.84 \\%$ | $14.23 \\%$ | $9.62 \\%$ |\n| 2000 | $16.00 \\%$ | $11.00 \\%$ | $5.00 \\%$ |\n| 5000 | $10.82 \\%$ | $6.21 \\%$ | $3.01 \\%$ |\n| 8000 | $10.00 \\%$ | $6.40 \\%$ | $3.20 \\%$ |\n| 10000 | $8.80 \\%$ | $5.40 \\%$ | $1.80 \\%$ |"}, "images": {}}, {"section_id": 7, "text": "# 7. RELAXATION OF THE ASSUMPTIONS \n\nWhen the test proposed in Section 5 rejects the null hypothesis of the model's validity, researchers must pursue alternative models and less restrictive assumptions to learn confidently about the parameters of interest.\n7.1. Alternative Approaches. There is a vast literature on alternatives to the Tobit Model that can be implemented in the presence of censored dependent variables. Most approaches consider changes or relaxations of one of the two main assumptions associated with the model. The first assumption is the parametric distribution of the error terms and latent index form connecting treatment (and covariates) to the outcome. The second assumption is the exogeneity of the treatment or potential instrument. Here, we provide a non-exhausting survey of existing work.\n\n[^0]\n[^0]:    ${ }^{14}$ Simulations for test performance when violations of normality of the latent errors occur are presented in Appendix F.\n\nTable 2. Classic Tobit test power for violations in exogeneity\n\n![table_1](table_1)\n\nBased on 500 replications.\nTable 3. IV Tobit - Test Size\n\n![table_2](table_2)\n\nBased on 500 replications.\n\nCragg (1971) maintains the normality of the errors, linearity of the index and exogeneity but relaxes the way censoring occurs in comparison to the latent structure of the censored outcome. Specifically, while the latent outcome is still modelled by $Y^{*}=\\alpha_{0}+\\alpha_{1} D+U$, they\n\nallow for the censoring to depend on a different linear index, $P\\left(Y^{*}>0\\right)=P\\left(\\gamma_{0}+\\gamma_{1} D+e\\right)$, increasing the model's flexibility.\n\nPowell (1984) relaxes the parametric structure of the errors while maintaining the latent linear index and treatment exogeneity, and estimates the parameters of interest by least absolute deviations. Powell (1986) also maintains linearity of the latent index and treatment exogeneity, but relaxes normality by imposing symmetrical distributions to the latent errors, which leads to estimation by symmetrically censored least squares. Newey (1987a) relaxes exogeneity of the treatment, relying on normality and an instrumental variable to identify the model, which is estimated by generalized least squares.\n\nHonor\u00e9 and Powell (1994) relax linearity and mean independence of the unobservable with respect to the treatment to exploit the idea that, although $Y_{i}^{*}-\\alpha_{0}-\\alpha_{1} D_{i}$ is not meanindependent of $D_{i}$, one can trim any pair of residuals $Y_{i}^{*}-\\alpha_{0}-\\alpha_{1} D_{i}$ and $Y_{j}^{*}-\\alpha_{0}-\\alpha_{1} D_{j}$, and the trimmed residuals are independent and identically distributed conditional on $D_{i}, D_{j}$. They estimate the model by identically censored least absolute deviations and identically censored least squares (ICLS). Das (2002) estimates a model using symmetrically censored least squares that relaxes exogeneity of the treatment and normality of the errors. To achieve that they rely on instrumental variables, linearity of the mean of the structural error conditional on the reduced form error, and mean independence of the reduced form error.\n\nBlundell and Powell (2007) proposes a control variable approach that relaxes exogeneity and normality but maintains the latent linear structure $\\left(\\alpha_{0}+\\alpha_{1} D+U\\right)$. Crucially, they impose that the distribution (or quantiles) of the latent error conditional on the treatment and instrument is only a function of the control variable $V=D-\\pi(Z)$, which isolates the endogenous variation on the treatment. ${ }^{15}$ This allows them to estimate the effect of the treatment by censored quantile instrumental variable regression augmented by a control variable given by the quantiles of $U$ conditional on $V$ at the quantile of interest. In a similar spirit, Chernozhukov, Fern\u00e1ndez-Val, and Kowalski (2015) focuses on conditional quantile functions and flexible approaches to estimate the control variable in the first stage.\n\nFinally, Chesher, Kim, and Rosen (2023) provides partial identification results for a general alternative by relaxing the exogeneity of the treatment and instrument, linearity of the latent index and imposing no parametric structure of the error term. They characterize the\n\n[^0]\n[^0]:    ${ }^{15}$ This assumption is weaker than independence of all errors and instruments since it does not impose $V$ independent of $Z$ but is neither stronger nor weaker than independence of $U$ and $Z$, since it permits $Z$ to affect $U$ through $V$.\n\nidentified set for the parameters of interest following the Generalized Instrumental Variables framework (Chesher and Rosen, 2017), relying on the assumption that the relationship of $Y^{*}$ to treatment and errors is continuous and monotonic in the errors. Their approach uses the residual sets associated with the structure of the latent function and conditional probability of the error term given potential instruments.\n7.2. Partial identification under monotonicity. In this subsection, we present an approach that partially identifies the effect of an endogenous treatment variable by replacing the normality and exogeneity assumptions with a monotonicity in treatment selection constraint. While less general than Chesher, Kim, and Rosen (2023), this approach is easy to implement and could be useful to empirical researchers.\n\nConsider the model that maintains linearity (or a known structure of $Y^{*}$ up to a finite number of parameters),\n\n$$\n\\left\\{\\begin{array}{l}\nY=\\max \\left(0, Y^{*}\\right) \\\\\nY^{*}=\\alpha_{0}+\\alpha_{1} D+U\n\\end{array}\\right.\n$$\n\nAs an alternative to treatment exogeneity and normality, consider a constraint on the direction of the endogenous relationship between the treatment and the unobservables that affect the outcome.\n\nAssumption 6 (Monotone Treatment Selection - MTS). Let $E(U \\mid D=d, Y>0) \\equiv \\Gamma(d)$. Then, for any $d>d^{*}$ we either have $\\Gamma(d)<\\Gamma\\left(d^{*}\\right)$ or $\\Gamma(d)>\\Gamma\\left(d^{*}\\right)$.\n\nAssumption 6 is common in the partial identification literature (Jiang, Chiba, and VanderWeele, 2014; Manski, 1997; Manski and Pepper, 2000; Okumura and Usui, 2014). In this context, we restrict the latent selection to be monotonic with respect to the treatment. This assumption is embedded in the classic Tobit model since the inverse mills ratio, $\\lambda(\\cdot)$, is monotonic (and decreasing) in the treatment variable. Furthermore, independence between $D$ and $U$ restricts the sign of the coefficient of the selection term directly, as the derivative of the inverse mills-ratio is $\\lambda^{\\prime}\\left(\\alpha_{0}+\\alpha_{1} D\\right) \\alpha_{1}$. Thus, without imposing independence or a parametric latent structure, we maintain a relevant property of the Tobit model that aids identification. Since it is not as restrictive as imposing a parametric structure and independence, we can only partially identify the parameter of interest.\n\nUnder Assumption 6 and the model described in 7.1, treatment and outcome are not independent. Note that,\n\n$$\n\\begin{aligned}\n& E(Y \\mid D=d, Y>0)=\\alpha_{0}+\\alpha_{1} d+\\Gamma(d) \\\\\n& E(Y \\mid D=d, Y>0)-\\alpha_{0}-\\alpha_{1} d=\\Gamma(d)\n\\end{aligned}\n$$\n\nThen, for any two $d>d^{*}$ we have, by Assumption 6:\n\n$$\n\\begin{aligned}\n& \\Gamma(d) \\quad<\\Gamma\\left(d^{*}\\right) \\\\\n& \\Leftrightarrow \\\\\n& E(Y \\mid D=d, Y>0)-\\alpha_{0}-\\alpha_{1} d<E\\left(Y \\mid D=d^{*}, Y>0\\right)-\\alpha_{0}-\\alpha_{1} d^{*} \\\\\n& \\text { \u314a } \\\\\n& \\alpha_{1}>\\frac{E\\left(Y \\mid D=d^{*}, Y>0\\right)-E(Y \\mid D=d, Y>0)}{d^{*}-d}\n\\end{aligned}\n$$\n\nwhich implies a lower bound on the parameter interest.\nFor a binary treatment $D \\in\\{0,1\\}$ the lower bound is, intuitively, the difference in average outcomes between treated and untreated individuals away from the mass point at zero:\n\n$$\n\\alpha_{1}>E(Y \\mid D=1, Y>0)-E(Y \\mid D=0, Y>0)\n$$\n\nThe bound can be more informative in the case of a continuous or multi-valued treatment. If $\\Gamma(D)$ is differentiable we have:\n\n$$\n\\alpha_{1}>\\frac{\\partial E(Y \\mid D=d, Y>0)}{\\partial d} \\text {, for all d. }\n$$\n\nSince the inequality holds for any $d$ in the continuous case or for any $d, d^{*}$ for multi-valued discrete treatment, the linear index structure with constant parameters implies that tighter bounds for $\\alpha_{1}$ are given by the maximum value of $\\frac{\\partial E(Y \\mid D=d, Y>0)}{\\partial d}$ across all possible points in the support for $D$. Analogous results with the inequalities reverted can be derived for any $d>d^{*}$, as we have $\\Gamma(d)>\\Gamma\\left(d^{*}\\right)$.\n\nOne-sided simple confidence regions can be computed based on these outer sets of the treatment effect. One can estimate $E(Y \\mid D=d, Y>0)$ using its sample analogs and rely on their asymptotic normality. For example, let the estimators be given by $\\widehat{E}(Y \\mid D=d, Y>0)$. By the continuous mapping theorem, $\\frac{\\widehat{E}\\left(Y \\mid D=d^{*}, Y>0\\right)-\\widehat{E}(Y \\mid D=d, Y>0)}{d^{*}-d}$ is asymptotically normal. Thus, a one-sided confidence interval for $\\frac{E(Y \\mid D=d^{*}, Y>0)-E(Y \\mid D=d, Y>0)}{d^{*}-d}$ can be computed via bootstrap, which implies a conservative estimate for the lower bound for $\\alpha_{1}$.\n\nA bootstrap procedure could be used for a nonparametric estimator of $\\frac{\\partial E(Y \\mid D=d, Y>0)}{\\partial d}$ using a local polynomial regression. In this case, the estimator is asymptotically normal\n\nand converges at a nonparametric rate that depends on the bandwidth $h$. Recent developments in Calonico, Cattaneo, and Farrell $(2018,2022)$ for estimation and optimal coverage error bandwidth and kernel selection methods that are nonparametric robust bias-corrected (RBC) can be used through their convenient implementation using the package nprobust (Calonico, Cattaneo, and Farrell, 2019).\n\nRemark 7 (On including covariates). If we impose that $Y^{*}=\\alpha_{0}+\\alpha_{1} D+\\alpha_{2} X+U$ the procedure can include exogenous covariates by modifying Assumption 6 to hold conditional on $X$. Then,\n\n$$\n\\begin{aligned}\n\\Gamma(d, X) & <\\Gamma\\left(d^{*}, X\\right) \\\\\n\\Leftrightarrow & \\\\\nE(Y \\mid D=d, X, Y>0)-\\alpha_{0}-\\alpha_{1} d-\\alpha_{2} X & <E(Y \\mid D=d^{*}, X, Y>0)-\\alpha_{0}-\\alpha_{1} d^{*}-\\alpha_{2} X \\\\\n& \\Leftrightarrow \\\\\n\\alpha_{1} & >\\frac{E(Y \\mid D=d^{*}, X, Y>0)-E(Y \\mid D=d, X, Y>0)}{d^{*}-d}\n\\end{aligned}\n$$\n\nA similar argument holds when the treatment variable is continuous. Tighter bounds are achieved by considering the maximum value of $\\frac{\\partial E(Y \\mid D=d, X=x, Y>0)}{\\partial d}$ across all possible points in the support for $D$ and $X$.", "tables": {"table_1": "| $N$ | $\\rho$ | $\\operatorname{MSE}\\left(\\beta_{0}\\right)$ | $\\operatorname{MSE}\\left(\\beta_{1}\\right)$ | $\\alpha=10 \\%$ | $\\alpha=5 \\%$ | $\\alpha=1 \\%$ |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n| 5000 | 0.10 | 0.0005 | 0.0005 | $8.60 \\%$ | $6.00 \\%$ | $3.20 \\%$ |\n|  | 0.50 | 0.0005 | 0.0104 | $16.03 \\%$ | $10.82 \\%$ | $5.21 \\%$ |\n|  | 0.75 | 0.0005 | 0.0227 | $36.00 \\%$ | $27.80 \\%$ | $14.20 \\%$ |\n|  | 0.80 | 0.0005 | 0.0259 | $42.00 \\%$ | $30.60 \\%$ | $16.80 \\%$ |\n|  | 0.90 | 0.0004 | 0.0326 | $62.40 \\%$ | $48.40 \\%$ | $27.60 \\%$ |\n|  | 0.95 | 0.0004 | 0.0360 | $71.34 \\%$ | $59.32 \\%$ | $35.87 \\%$ |\n| 8000 | 0.10 | 0.0003 | 0.0005 | $8.40 \\%$ | $5.00 \\%$ | $2.00 \\%$ |\n|  | 0.50 | 0.0003 | 0.0102 | $17.43 \\%$ | $12.22 \\%$ | $5.61 \\%$ |\n|  | 0.75 | 0.0003 | 0.0225 | $45.58 \\%$ | $36.14 \\%$ | $20.08 \\%$ |\n|  | 0.80 | 0.0003 | 0.0256 | $53.80 \\%$ | $39.80 \\%$ | $18.00 \\%$ |\n|  | 0.90 | 0.0003 | 0.0323 | $79.00 \\%$ | $65.40 \\%$ | $36.40 \\%$ |\n|  | 0.95 | 0.0002 | 0.0363 | $85.57 \\%$ | $75.15 \\%$ | $49.70 \\%$ |\n| 10000 | 0.10 | 0.0003 | 0.0005 | $10.04 \\%$ | $7.43 \\%$ | $2.41 \\%$ |\n|  | 0.50 | 0.0002 | 0.0101 | $15.80 \\%$ | $10.00 \\%$ | $3.80 \\%$ |\n|  | 0.75 | 0.0002 | 0.0226 | $44.80 \\%$ | $32.80 \\%$ | $16.00 \\%$ |\n|  | 0.80 | 0.0002 | 0.0256 | $56.60 \\%$ | $41.00 \\%$ | $21.60 \\%$ |\n|  | 0.90 | 0.0002 | 0.0326 | $79.60 \\%$ | $66.60 \\%$ | $36.60 \\%$ |\n|  | 0.95 | 0.0002 | 0.0361 | $90.56 \\%$ | $79.52 \\%$ | $51.61 \\%$ |", "table_2": "| N | $\\rho_{u v}$ | $\\alpha=10 \\%$ | $\\alpha=5 \\%$ | $\\alpha=1 \\%$ |\n| :--: | :--: | :--: | :--: | :--: |\n| 5000 | 0.0 | $10.8 \\%$ | $7.0 \\%$ | $3.2 \\%$ |\n| 5000 | 0.5 | $11.2 \\%$ | $9.0 \\%$ | $3.2 \\%$ |\n| 5000 | 0.8 | $15.9 \\%$ | $7.9 \\%$ | $4.0 \\%$ |\n| 8000 | 0.0 | $7.4 \\%$ | $3.8 \\%$ | $1.8 \\%$ |\n| 8000 | 0.5 | $9.2 \\%$ | $5.6 \\%$ | $1.8 \\%$ |\n| 8000 | 0.8 | $17.8 \\%$ | $11.1 \\%$ | $2.9 \\%$ |"}, "images": {}}, {"section_id": 8, "text": "# 8. Empirical Illustration: Lee (1995) \n\nIn this section, we implement the proposed test to the data from Lee (1995). Using the 1987 cross-section of the Michigan Panel Study of Income Dynamics, the authors study the responses of married women's labor supply $(Y)$ - measured in hours per year - to hundreds of dollars in \"other\" household income $(D)$, which is endogenous. The instrumental variables explored are dummy variables for the husband's occupation $(Z)$, which implies the restrictive identifying assumption that the wife's labor supply is affected by the husband's occupation only through their income. Following the original study, we add other covariates $(X)$ in the linear index for both the outcome and treatment equations, controlling for factors that could impact women's labor supply. Those include a quadratic on the person's age, their years of completed education, the number of children coded in three categories (children up to 5 years old, ages 6 to 13, ages 14 to 17), the local unemployment rate in percentage points, and indicators for race ( 0 if white, 1 otherwise), homeownership ( 1 if owner, 0 otherwise) and if the couple has a mortgage on their home ( 1 if yes, 0 otherwise).\n\nOur empirical illustration considers as an instrument the binary variable indicating if the husband's occupation is classified as manager or professional. ${ }^{16}$\n\nFollowing Lee (1995), we proceed with the analysis focusing on the data for married couples with non-negative family total income or \"other\" household income and where the wife was of working age (18-64) and not self-employed. These selections results in 3,277 observations, for which 26 percent of wage observations are censored. Table 4 presents the estimates obtained using the IV Tobit model.\n\nThe first column presents the first-stage estimates indicating the relevance of the potential $I V$. The second column presents the structural equation reflecting the effect the treatment variable has on the outcome equation. The parameter $\\rho$ shows evidence of no correlation between the unobservables driving the \"other\" household income and hours worked after controlling for covariates. The estimated coefficient of interest indicates that other household income negatively affects the wife's labor supply after conditional on the household characteristics. In particular, for women working positive hours, an increase of one thousand dollars in household income from other sources is estimated to reduce hours worked by 9.7 hours per year. The direction of the impacts at the intensive margin of hours worked follow intuitive patterns and are qualitative similar to those in Lee (1995). However, the model is rejected at conventional significance levels when we test for the IV-Tobit model's validity, $\\left(\\hat{\\theta}_{0.99}=0.1335>0, \\hat{\\theta}_{0.95}=0.1368>0\\right.$, and $\\left.\\hat{\\theta}_{0.90}=0.1385>0\\right)$. This indicates that the assumptions underlying the IV-Tobit model are not compatible with the empirical distribution of the data, and caution is needed when relying on the results.\n\nBounds under Assumption 6 and latent linear index. Given the rejection of the IV-Tobit model in this case, we relax the distributional and exogeneity of treatment assumptions, and construct lower bounds on the treatment effect under the MTS assumption and latent linear index only. Assumption 6 imposes that average unobservables affecting women's preferences related to hours worked away from home, are monotonically decreasing in characteristics leading to higher income of other sources in the household, such as husband's income. In other words, households that prefer flexible schedules for women might similarly prioritize partner jobs that provide higher income.\n\n[^0]\n[^0]:    ${ }^{16}$ The 1987 PSID uses 3-digit occupation codes from the 1970 U.S. Census, and this dummy variable seems to include workers listed in the categories \"1-195 Professional, Technical, and Kindred Workers,\" and \"201-245 Managers and Administrators, except Farm.\"\n\nTable 4. IV Tobit specification for Lee (1995)\n\n![table_3](table_3)\n\nStandard errors (in parentheses); ${ }^{* * *}$ : significant at $1 \\%$ level; *significant at $10 \\%$ level\n\nTABLE 5. Confidence sets for parameter of interest\n\n![table_4](table_4)\n\nThe first column of Table 5 repeats the estimate for $\\alpha_{1}$ from Table 4. The second column reports the estimated lower bound for $\\alpha_{1}$, obtained under Assumption 6 and latent linear index only based on the nonparametric estimate of the average derivative of the conditional expectation for yearly hours worked with respect to the household income from other sources, as described in Remark 7. Even after relaxing the normality of errors and treatment exogeneity, the lower bound for the size of the effect of having higher household income from sources other than the wife's labor on their labor supply indicates an effect larger than -4.19 hours worked per year for married women. Hence, we can rule out annual reductions of more than 4.2 hours in female labor supply for every one thousand dollars in other household income, but cannot reject that the effect is zero or positive.", "tables": {"table_3": "|  | MLE <br> Other household income Hours per year worked |  |\n| :--: | :--: | :--: |\n| Husband's occupation: manager or professional | $\\begin{gathered} 120.802^{* * *} \\\\ (10.813) \\end{gathered}$ |  |\n| Other household income |  | $\\begin{gathered} -0.973^{* * *} \\\\ (0.373) \\end{gathered}$ |\n| Age | $13.686^{* * *}$ | $72.414^{* * *}$ |\n|  | (3.251) | (15.249) |\n| Age squared | $\\begin{gathered} -0.105^{* * *} \\\\ (0.039) \\end{gathered}$ | $\\begin{gathered} -1.221^{* * *} \\\\ (0.178) \\end{gathered}$ |\n| Education | $20.281^{* * *}$ | $92.107^{* * *}$ |\n|  | (2.071) | (13.231) |\n| Children under 5 | 9.448 | $-500.332^{* * *}$ |\n|  | (6.482) | (28.163) |\n| Children between 6 and 13 | 3.204 | $-211.687^{* * *}$ |\n|  | (5.601) | (23.737) |\n| Children between 14 and 17 | 12.881 | $-16.878$ |\n|  | (9.342) | (39.152) |\n| Nonwhite | $\\begin{gathered} -59.550^{* * *} \\\\ (10.210) \\end{gathered}$ | $\\begin{gathered} 146.336^{* * *} \\\\ (51.105) \\end{gathered}$ |\n| Homeowner | $60.591^{* * *}$ | 13.830 |\n|  | (15.461) | (69.142) |\n| Has mortgage | $24.192^{*}$ | $254.660^{* * *}$ |\n|  | (13.954) | (61.036) |\n| Local Unemployment | $\\begin{gathered} -8.165^{* * *} \\\\ (1.941) \\end{gathered}$ | $\\begin{gathered} -41.979^{* * *} \\\\ (8.966) \\end{gathered}$ |\n| Constant | $\\begin{gathered} -339.059^{* * *} \\\\ (63.387) \\end{gathered}$ | $\\begin{gathered} -337.347 \\\\ (314.207) \\end{gathered}$ |\n| $\\rho$ |  | 0.042 |\n|  |  | $(0.094)$ |\n| $n$ | 3,377 | 3,377 |", "table_4": "| Parameter | IV-Tobit estimates | $\\alpha_{1}$ 's Lower Bound |\n| :--: | :--: | :--: |\n| $\\alpha_{1}$ | -0.973 | -0.419 |\n| conf.: confidence; LB: lower bound |  |  |"}, "images": {}}, {"section_id": 9, "text": "# 9. CONCLUSION \n\nIn this paper, we develop sharp testable equalities for the classic Tobit and IV-Tobit models that can detect all observable violations of the model's assumptions. The results are shown to extend to many other popular Tobit-type \"two-part\" models. By converting these sharp equalities into conditional moment inequalities, we propose a testing procedure that detects violations of the Tobit model assumptions on a grid on the joint support of the outcome (and treatment) variables leveraging inference results from Chernozhukov, Lee, and Rosen (2013) and the implementation from Chernozhukov et al. (2015).\n\nSimulation results suggest the test performs well for reasonably sized samples (larger than 5000 observations). The test is conservative for smaller samples, overejecting the null hypothesis of model validity. Simulations indicate that the test is powerful to detect violations of the exogeneity assumption for the treatment/instrument that affect the point estimates and inference. Finally, the proposed test exhibits good performance for violations of the distributional assumptions about the error structure.\n\nWe provide a brief review of existing models that could be implemented under weak/alternative assumptions when the Tobit model is rejected. Furthermore, we propose a simple\n\nmodel that partially identifies the parameter of interest by relying solely on linear index and monotone treatment selection restrictions, a standard assumption from the partial identification literature (Manski and Pepper, 2000).\n\nWe illustrate our methods on data from Lee (1995). We replicate qualitatively the results in the original paper and the proposed test for validity of the IV-Tobit model rejects the null hypothesis in this empirical application. We estimate our proposed lower bound for the effect of household income from sources other than the wife's labor on their labor supply, which does not rely on the normality of latent errors or treatment exogeneity. While we can rule out that an extra 1,000 dollars in other household income reduce female labor supply by more than 4.2 hours per year, we cannot rule out that the effect is zero.", "tables": {}, "images": {}}, {"section_id": 10, "text": "# REFERENCES \n\nAcerenza, Santiago, Ot\u00e1vio Bartalotti, and D\u00e9sir\u00e9 K\u00e9dagni. 2023. \"Testing identifying assumptions in bivariate probit models.\" Journal of Applied Econometrics 38 (3):407422. URL https://onlinelibrary.wiley.com/doi/10.1002/jae. 2956.\n\nArai, Yoichi, Yu-Chin Hsu, Toru Kitagawa, Ismael Mourifi\u00e9, and Yuanyuan Wan. 2022. \"Testing identifying assumptions in fuzzy regression discontinuity designs.\" Quantitative Economics 13 (1):1-28. URL http://qeconomics.org/ojs/index.php/qe/article/view/GE1367.\nBai, Yuehao and Max Tabord-Meehan. 2024. \"Sharp Testable Implications of Encouragement Designs.\" URL https://arxiv.org/abs/2411.09808.\nBarros, Michelli, Manuel Galea, V\u00edctor Leiva, and Manoel Santos-Neto. 2018. \"Generalized Tobit models: Diagnostics and application in econometrics.\" Journal of Applied Statistics 45 (1):145-167.\nBera, Anil K., Carlos M. Jarque, and Lung-Fei Lee. 1984. \"Testing the Normality Assumption in Limited Dependent Variable Models.\" International Economic Review 25 (3):563. URL https://www.jstor.org/stable/2526219?origin=crossref.\nBlundell, Richard and James L Powell. 2007. \"Censored regression quantiles with endogenous regressors.\" Journal of Econometrics 141 (1):65-83.\nCalonico, Sebastian, Matias D Cattaneo, and Max H Farrell. 2018. \"On the effect of bias estimation on coverage accuracy in nonparametric inference.\" Journal of the American Statistical Association 113 (522):767-779.\n\u2014_. 2019. \"nprobust: Nonparametric Kernel-Based Estimation and Robust BiasCorrected Inference.\" Journal of statistical software 91 (8):1-33.\n\n\u2014_. 2022. \"Coverage error optimal confidence intervals for local polynomial regression.\" Bernoulli 28 (4).\nCarson, Richard T and Yixiao Sun. 2007. \"The Tobit model with a non-zero threshold.\" The Econometrics Journal 10 (3):488-502.\nChernozhukov, Victor, Iv\u00e1n Fern\u00e1ndez-Val, and Amanda E Kowalski. 2015. \"Quantile regression with censoring and endogeneity.\" Journal of Econometrics 186 (1):201-221.\nChernozhukov, Victor, Wooyoung Kim, Sokbae Lee, and Adam M. Rosen. 2015. \"Implementing Intersection Bounds in Stata.\" The Stata Journal: Promoting communications on statistics and Stata 15 (1):21-44. URL http://journals.sagepub.com/doi/10.1177/1536867X1501500103.\nChernozhukov, Victor, Sokbae Lee, and Adam M. Rosen. 2013. \"Intersection Bounds: Estimation and Inference.\" Econometrica 81 (2):667-737. URL http://doi.wiley.com/10.3982/ECTA8718.\nChesher, Andrew, Dongwoo Kim, and Adam M Rosen. 2023. \"IV methods for Tobit models.\" Journal of Econometrics 235 (2):1700-1724.\nChesher, Andrew and Adam M Rosen. 2017. \"Generalized instrumental variable models.\" Econometrica 85 (3):959-989.\nCragg, John G. 1971. \"Some statistical models for limited dependent variables with application to the demand for durable goods.\" Econometrica: journal of the Econometric Society :829-844.\nDas, Mitali. 2002. \"Estimators and inference in a censored regression model with endogenous covariates.\" .\nDrukker, David M. 2002. \"Bootstrapping a Conditional Moments Test for Normality after Tobit Estimation.\" The Stata Journal: Promoting communications on statistics and Stata 2 (2):125-139. URL http://journals.sagepub.com/doi/10.1177/1536867X0200200202.\nGoff, Leonard, D\u00e9sir\u00e9 K\u00e9dagni, and Huan Wu. 2024. \"Testing Identifying Assumptions in Parametric Separable Models: A Conditional Moment Inequality Approach.\" arXiv preprint arXiv:2410.12098 .\nGunsilius, F F. 2021. \"Nontestability of instrument validity under continuous treatments.\" Biometrika 108 (4):989-995. URL https://academic.oup.com/biomet/article/108/4/989/6035117.\nHan, Sukjin and Edward J. Vytlacil. 2017. \"Identification in a generalization of bivariate probit models with dummy endogenous regressors.\" Journal of Econometrics 199 (1):6373. URL https://linkinghub.elsevier.com/retrieve/pii/S0304407617300465.\n\nHeckman, James J. 1979. \"Sample selection bias as a specification error.\" Econometrica: Journal of the econometric society :153-161.\nHolden, Darryl. 2004. \"Testing the Normality Assumption in the Tobit Model.\" Journal of Applied Statistics 31 (5):521-532. URL http://www.tandfonline.com/doi/abs/10.1080/02664760410001681783.\nHonor\u00e9, Bo E. 1993. \"Orthogonality conditions for Tobit models with fixed effects and lagged dependent variables.\" Journal of econometrics 59 (1-2):35-61.\nHonor\u00e9, Bo E and Luojia Hu. 2020. \"Selection without exclusion.\" Econometrica 88 (3):1007-1029.\nHonore, Bo E, Ekaterini Kyriazidou, and JL Powell. 2000. \"Estimation of Tobit-type models with individual specific effects.\" Econometric reviews 19 (3):341-366.\nHonor\u00e9, Bo E and James L Powell. 1994. \"Pairwise difference estimators of censored and truncated regression models.\" Journal of Econometrics 64 (1-2):241-278.\nHuber, Martin and Giovanni Mellace. 2015. \"Testing Instrument Validity for LATE Identification Based on Inequality Moment Constraints.\" Review of Economics and Statistics 97 (2):398-411. URL https://direct.mit.edu/rest/article/97/2/398-411/58220.\nJiang, Zhichao, Yasutaka Chiba, and Tyler J VanderWeele. 2014. \"Monotone confounding, monotone treatment selection and monotone treatment response.\" Journal of causal inference $2(1): 1-12$.\nK\u00e9dagni, D\u00e9sir\u00e9 and Ismael Mourifi\u00e9. 2020. \"Generalized instrumental inequalities: testing the instrumental variable independence assumption.\" Biometrika 107 (3):661-675.\nKitagawa, Toru. 2015. \"A Test for Instrument Validity.\" Econometrica 83 (5):2043-2063. URL https://www.econometricsociety.org/doi/10.3982/ECTA11974.\nK\u00e9dagni, D\u00e9sir\u00e9 and Ismael Mourifi\u00e9. 2020. \"Generalized instrumental inequalities: testing the instrumental variable independence assumption.\" Biometrika 107 (3):661-675. URL https://academic.oup.com/biomet/article/107/3/661/5767137.\nLee, Myoung-Jae. 1995. \"Semi-parametric estimation of simultaneous equations with limited dependent variables: a case study of female labour supply.\" Journal of Applied Econometrics 10 (2):187-200.\nLin, Tsai-Fen and Peter Schmidt. 1984. \"A Test of the Tobit Specification Against an Alternative Suggested by Cragg.\" The Review of Economics and Statistics 66 (1):174. URL https://www.jstor.org/stable/1924712?origin=crossref.\nManski, Charles F. 1997. \"Monotone treatment response.\" Econometrica: Journal of the Econometric Society :1311-1334.\n\nManski, Charles F. and John V. Pepper. 2000. \"Monotone Instrumental Variables: With an Application to the Returns to Schooling.\" Econometrica 68 (4):997-1010. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-0262.t01-1-00144a.\nMourifi\u00e9, Ismael and Yuanyuan Wan. 2017. \"Testing Local Average Treatment Effect Assumptions.\" The Review of Economics and Statistics 99 (2):305-313. URL https://direct.mit.edu/rest/article/99/2/305-313/58389.\nNelson, Forrest D. 1981. \"A Test for Misspecification in the Censored Normal Model.\" Econometrica 49 (5):1317. URL https://www.jstor.org/stable/1912756?origin=crossref.\nNewey, Whitney K. 1985. \"Maximum Likelihood Specification Testing and Conditional Moment Tests.\" Econometrica 53 (5):1047. URL https://www.jstor.org/stable/1911011?origin=crossref.\nNewey, Whitney K. 1987a. \"Efficient estimation of limited dependent variable models with endogenous explanatory variables.\" Journal of econometrics 36 (3):231-250.\nNewey, Whitney K. 1987b. \"Specification tests for distributional assumptions in the Tobit model.\" Journal of Econometrics 34 (1-2):125-145. URL https://linkinghub.elsevier.com/retrieve/pii/0304407687900704.\nOkumura, Tsunao and Emiko Usui. 2014. \"Concave-monotone treatment response and monotone treatment selection: With an application to the returns to schooling.\" Quantitative Economics 5 (1):175-194.\nPowell, James L. 1984. \"Least absolute deviations estimation for the censored regression model.\" Journal of Econometrics 25 (3):303-325. URL https://www.sciencedirect.com/science/article/pii/0304407684900046.\n-1. 1986. \"Symmetrically trimmed least squares estimation for Tobit models.\" Econometrica: journal of the Econometric Society :1435-1460.\nReynolds, A. and J. S. Shonkwiler. 1991. \"Testing and correcting for distributional misspecifications in the Tobit model: An application of the Information Matrix test.\" Empirical Economics 16 (3):313-323. URL http://link.springer.com/10.1007/BF01206278.\nSmith, Richard J. and Richard W. Blundell. 1986. \"An Exogeneity Test for a Simultaneous Equation Tobit Model with an Application to Labor Supply.\" Econometrica 54 (3):679. URL https://www.jstor.org/stable/1911314?origin=crossref.\nTauchen, George. 1985. \"Diagnostic testing and evaluation of maximum likelihood models.\" Journal of Econometrics 30 (1-2):415-443. URL https://linkinghub.elsevier.com/retrieve/pii/0304407685901496.\n\nTobin, James. 1958. \"Estimation of Relationships for Limited Dependent Variables.\" Econometrica 26 (1):24. URL https://www.jstor.org/stable/1907382?origin=crossref.\nWooldridge, Jeffrey M. 2005. \"Simple solutions to the initial conditions problem in dynamic, nonlinear panel data models with unobserved heterogeneity.\" Journal of applied econometrics $20(1): 39-54$.\nWooldridge, Jeffrey M. 2010. Econometric analysis of cross section and panel data. Cambridge, Mass: MIT Press, 2nd ed ed. OCLC: ocn627701062.", "tables": {}, "images": {}}, {"section_id": 11, "text": "# Appendix A. Sharpness for the classic Tobit case \n\nLet $\\alpha_{1}, \\alpha_{0}$ be identified. Suppose 3.1- 3.3 hold. Let $f_{\\tilde{U} \\mid D}=\\frac{1}{\\sqrt{2 \\pi}} e^{-1 / 2 \\tilde{U}^{2}}$. Let $\\tilde{Y}^{*}=$ $\\alpha_{0}+\\alpha_{1} D+\\tilde{U}$ and $\\tilde{Y}=\\max \\left(0, \\tilde{Y}^{*}\\right)$. From $f_{\\tilde{U} \\mid D}$ we can see assumption 1 holds, since $f_{\\tilde{U} \\mid D}=f_{\\tilde{U}}$. Also note $f_{\\tilde{U}}$ is the $N(0,1)$ density, thus assumption 2 holds. Considering the positive values for $\\tilde{Y}$, for any constants $c_{0}, c_{1}$ such that $0<c_{0}<c_{1}$, then,\n\n$$\n\\begin{aligned}\nP\\left(c_{0} \\leq \\tilde{Y} \\leq c_{1} \\mid D=d\\right) & =P\\left(c_{0} \\leq \\tilde{Y}^{*} \\leq c_{1} \\mid D=d\\right) \\\\\n& =P\\left(c_{0} \\leq \\alpha_{0}+\\alpha_{1} d+\\tilde{U} \\leq c_{1} \\mid D=d\\right) \\\\\n& =P\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d \\leq \\tilde{U} \\leq c_{1}-\\alpha_{0}-\\alpha_{1} d \\mid D=d\\right) \\\\\n& =P\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d \\leq \\tilde{U} \\leq c_{1}-\\alpha_{0}-\\alpha_{1} d\\right) \\\\\n& =\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d\\right)-\\Phi\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d\\right) \\\\\n& =P\\left(c_{0} \\leq Y \\leq c_{1} \\mid D=d\\right)\n\\end{aligned}\n$$\n\nThe first three equalities follow from the definitions of $\\tilde{Y}^{*}$ and $\\tilde{Y}$. The fourth and fifth steps use the specific choice for the probability density of $\\tilde{U}$, which implies independence from $D$ and normality respectively. The last step uses the relationship between the observed data and the model, established in 3.1. Similar reasoning applies for $P\\left(c_{1} \\leq \\tilde{Y} \\mid D=d\\right)=P\\left(c_{1} \\leq\\right.$ $\\alpha_{0}+\\alpha_{1} d+\\tilde{U} \\mid D=d)=1-\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d\\right)=P\\left(c_{1} \\leq Y \\mid D=d\\right)$.\n\nFurthermore, for $P(\\tilde{Y}=0 \\mid D=d)$ :\n\n$$\n\\begin{aligned}\nP(\\tilde{Y}=0 \\mid D=d) & =P\\left(\\tilde{Y}^{*} \\leq 0 \\mid D=d\\right)=P\\left(\\alpha_{0}+\\alpha_{1} d+\\tilde{U} \\leq 0 \\mid D=d\\right) \\\\\n& =P\\left(\\tilde{U} \\leq-\\alpha_{0}-\\alpha_{1} d \\mid D=d\\right)=P\\left(\\tilde{U} \\leq-\\alpha_{0}-\\alpha_{1} d\\right) \\\\\n& =\\Phi\\left(-\\alpha_{0}-\\alpha_{1} d\\right)=1-\\Phi\\left(\\alpha_{0}+\\alpha_{1} d\\right)=P(Y=0 \\mid D=d)\n\\end{aligned}\n$$\n\nThe last step uses the equality established in 3.3. Thus, we characterized the distribution of $\\tilde{Y} \\mid D$, which is equal to the one of $Y \\mid D$, with $D$ given. Thus, we can induce the observed distribution $Y, D$.", "tables": {}, "images": {}}, {"section_id": 12, "text": "# Appendix B. Details of the IV-Tobit case\n## B.1. Derivation of equation 3.4.\n\n$$\n\\begin{aligned}\n& P\\left(c_{0} \\leq Y \\leq c_{1}, d_{0} \\leq D \\leq d_{1} \\mid Z=z\\right) \\\\\n= & P\\left(c_{0} \\leq Y \\leq c_{1}, d_{0} \\leq D \\leq d_{1}, Y^{*} \\geq 0 \\mid Z=z\\right)+P\\left(c_{0} \\leq Y \\leq c_{1}, d_{0} \\leq D \\leq d_{1}, Y^{*}<0 \\mid Z=z\\right) \\\\\n= & P\\left(c_{0} \\leq Y^{*} \\leq c_{1}, d_{0} \\leq D \\leq d_{1}, Y^{*} \\geq 0 \\mid Z=z\\right) \\\\\n= & P\\left(c_{0} \\leq \\beta_{0}+\\beta_{1} z+W \\leq c_{1}, d_{0} \\leq \\gamma_{0}+\\gamma_{1} z+V \\leq d_{1}, Y^{*} \\geq 0 \\mid Z=z\\right) \\\\\n= & P\\left(c_{0}-\\beta_{0}-\\beta_{1} z \\leq W \\leq c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z \\leq V \\leq d_{1}-\\gamma_{0}-\\gamma_{1} z, Y^{*} \\geq 0 \\mid Z=z\\right) \\\\\n= & P\\left(c_{0}-\\beta_{0}-\\beta_{1} z \\leq W \\leq c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z \\leq V \\leq d_{1}-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n= & \\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right)-\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n- & \\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right)+\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right)\n\\end{aligned}\n$$\n\nThe first equality follows from the law of total probability. The second through fourth equalities are in consequence of the model structure in 2.3. The fifth step uses Assumption 3 and $c_{0} \\geq 0$. The final equality is by the properties of probabilities and the joint normality for $W, V$ (Assumption 4).\nB.2. Derivation of equation 3.10. By a similar approach to the derivation of 3.4:\n\n$$\n\\begin{aligned}\nP\\left(Y=0, d_{0} \\leq D \\leq d_{1} \\mid Z=z\\right) & =P\\left(Y^{*} \\leq 0, d_{0} \\leq D \\leq d_{1} \\mid Z=z\\right) \\\\\n& =P\\left(W \\leq-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} \\leq V \\leq d_{1}-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n& =\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right)\n\\end{aligned}\n$$\n\nB.3. Proof of Sharpness. Let $\\beta_{0}, \\beta_{1}, \\gamma_{0}, \\gamma_{1}, \\rho$ be identified and equalities 3.4-3.12 hold. Define the joint density of $(\\bar{W}, \\bar{V})$ conditional on $Z$ as\n\n$$\nf_{(\\bar{W}, \\bar{V} \\mid Z)}(w, v \\mid z)=\\frac{1}{\\sqrt{1-\\rho^{2}}} \\phi\\left(\\frac{w-\\rho v}{\\sqrt{1-\\rho^{2}}}\\right) \\phi(v)\n$$\n\nwhere $\\phi(t)=\\exp \\left(-t^{2} / 2\\right)$, and define\n\n$$\n\\left\\{\\begin{aligned}\n\\tilde{Y} & =\\max \\left(0, \\tilde{Y}^{*}\\right) \\\\\n\\tilde{Y}^{*} & =\\beta_{0}+\\beta_{1} Z+\\tilde{W} \\\\\n\\tilde{D} & =\\gamma_{0}+\\gamma_{1} Z+\\tilde{V}\n\\end{aligned}\\right.\n$$\n\nNote that $f_{\\left(\\tilde{W}, \\tilde{V} \\mid Z\\right)}=f_{\\left(\\tilde{W}, \\tilde{V}\\right)}$, thus assumption 3 holds. Similarly, $(\\tilde{W}, \\tilde{V})$ follow a bivariate normal distribution as $\\binom{\\tilde{W}}{\\tilde{V}} \\sim \\mathcal{N}(\\mu, \\Sigma)$, where $\\mu=\\binom{0}{0}$, and $\\Sigma=\\left(\\begin{array}{ll}1 & \\rho \\\\ \\rho & 1\\end{array}\\right)$. Let $\\tilde{U}=$ $\\tilde{W}-\\alpha_{1} \\tilde{V}$, which implies $\\tilde{U}, \\tilde{V}$ satisfies assumption 4 , given the scale-location normalizations.\n\nThen, for any constants $0<c_{0} \\leq c_{1}$ and $d_{0}<d_{1}$ :\n\n$$\n\\begin{aligned}\n& P\\left(c_{0} \\leq \\tilde{Y} \\leq c_{1}, d_{0} \\leq \\tilde{D} \\leq d_{1} \\mid Z=z\\right)=P\\left(c_{0} \\leq \\tilde{Y}^{*} \\leq c_{1}, d_{0} \\leq \\tilde{D} \\leq d_{1} \\mid Z=z\\right) \\\\\n& =P\\left(c_{0} \\leq \\beta_{0}+\\beta_{1} z+\\tilde{W} \\leq c_{1}, d_{0} \\leq \\gamma_{0}+\\gamma_{1} z+\\tilde{V} \\leq d_{1} \\mid Z=z\\right) \\\\\n& =P\\left(c_{0}-\\beta_{0}-\\beta_{1} z \\leq \\tilde{W} \\leq c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z \\leq \\tilde{V} \\leq d_{1}-\\gamma_{0}-\\gamma_{1} z \\mid Z=z\\right) \\\\\n& =P\\left(c_{0}-\\beta_{0}-\\beta_{1} z \\leq \\tilde{W} \\leq c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z \\leq \\tilde{V} \\leq d_{1}-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n& =\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right)-\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right)+\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& =P\\left(c_{0} \\leq Y \\leq c_{1}, d_{0} \\leq D \\leq d_{1} \\mid Z=z\\right)\n\\end{aligned}\n$$\n\nThe first through third equalities follow from the definitions of $\\tilde{Y}, \\tilde{Y}^{*}$ and $\\tilde{D}$. The fourth and fifth steps are consequences of the particular choice for joint density for $(\\tilde{W}, \\tilde{V})$ conditional on $Z$. The final equality is given by the relationship between observable data and the latent model structure in Equation 3.4. Similar derivations hold for 3.5-3.9.\n\nFor the accumulation point, at $Y=0$ :\n\n$$\n\\begin{aligned}\n& P\\left(\\tilde{Y}=0, d_{0} \\leq \\tilde{D} \\leq d_{1} \\mid Z=z\\right)=P\\left(\\tilde{Y}^{*} \\leq 0, d_{0} \\leq \\tilde{D} \\leq d_{1} \\mid Z=z\\right) \\\\\n& =P\\left(\\beta_{0}+\\beta_{1} z+\\tilde{W} \\leq 0, d_{0} \\leq \\gamma_{0}+\\gamma_{1} z+\\tilde{V} \\leq d_{1} \\mid Z=z\\right) \\\\\n& =P\\left(\\tilde{W} \\leq-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z \\leq \\tilde{V} \\leq d_{1}-\\gamma_{0}-\\gamma_{1} z \\mid Z=z\\right) \\\\\n& =P\\left(\\tilde{W} \\leq-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z \\leq \\tilde{V} \\leq d_{1}-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n& =\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right)-\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& =P\\left(Y=0, d_{0} \\leq D \\leq d_{1} \\mid Z=z\\right)\n\\end{aligned}\n$$\n\nThe steps of the proof are similar to previous cases and the last equality is given by the relationship between observable data and the latent model structure in Equation 3.10. Similar derivations hold for equalities 3.11-3.12.\n\nThus, we characterized the distribution of $(\\tilde{Y}, \\tilde{D}) \\mid Z$, which coincides with the joint distribution of $(Y, D) \\mid Z$, for given $Z$. Thus, we induced the observed distribution of the data $Y, D, Z$.", "tables": {}, "images": {}}, {"section_id": 13, "text": "# Appendix C. Type 2 Tobit testable implications \n\nIn this section we derive the results of the Type 2 tobit model also known as selection models or Heckman selection type of models (Heckman, 1979). The basic setup with no covariates (which can be extended in several directions and with different distributional assumptions as well as to incorporate treatment endogeneity, as we pointed out for the classic Tobit model in remark 3) is:\n\n$$\n\\left\\{\\begin{aligned}\nY & =Y^{*} \\quad \\text { if } \\quad S=1 \\\\\nY & =\\text { missing if } \\quad S=0 \\\\\nY^{*} & =\\alpha_{0}+\\alpha_{1} D+U \\\\\nS & =1\\left\\{\\gamma_{0}+\\gamma_{1} Z+V \\geq 0\\right\\}\n\\end{aligned}\\right.\n$$\n\nWhere $U, V$ are the latent structural error terms.\n\nAssumption 7. $D, Z$ be independent of $U, V$. Furthermore, let $\\gamma_{1} \\neq 0$\n\nAssumption 8. Let $U, V$ follow a bivariate normal distribution with covariance $\\rho$, i.e., $\\binom{U}{V} \\sim \\mathcal{N}(\\mu, \\Sigma)$, where $\\mu=\\binom{0}{0}$, and $\\Sigma=\\left(\\begin{array}{cc}\\sigma_{U}^{2} & \\rho_{U V} \\\\ \\rho_{U V} & \\sigma_{V}^{2}\\end{array}\\right)$.\n\nNote that $Y$ is missing at $S=0$. Thus, fully characterizing the distribution implies observing the behaviour at the missing point and beyond it.\n\nFrom the observed data the conditional probabilities of $c_{0} \\leq Y \\leq c_{1}$ for an $c_{1}, c_{0}$ can be computed. Then note for any $d \\in \\mathcal{D}$ and $z \\in \\mathcal{Z}$ :\n\n$$\n\\begin{aligned}\nP(Y=\\text { missing } \\quad \\mid D=d, Z=z) & =P(S=0 \\mid D=d, Z=z) \\\\\n& =P\\left(\\gamma_{0}+\\gamma_{1} Z+V<0 \\mid D=d, Z=z\\right) \\\\\n& =P\\left(\\gamma_{0}+\\gamma_{1} z+V<0\\right) \\\\\n& =P\\left(V<-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n& =\\Phi_{v}\\left(\\frac{-\\gamma_{0}-\\gamma_{1} z}{\\sigma_{V}}\\right)\n\\end{aligned}\n$$\n\nWhere the first and the second equalities are due to the structure of the model described in equation C.1. The third step is due to Assumption 7 and the last one follows from the normalization for normal random variables and Assumption 8.\n\nAdditionally,\n\n$$\n\\begin{aligned}\nP\\left(c_{0} \\leq Y \\leq c_{1} \\mid D=d, Z=z\\right) & =P\\left(c_{0} \\leq Y \\leq c_{1}, S=0 \\mid D=d, Z=z\\right) \\\\\n& +P\\left(c_{0} \\leq Y \\leq c_{1}, S=1 \\mid D=d, Z=z\\right) \\\\\n& =P\\left(c_{0} \\leq Y^{*} \\leq c_{1}, S=1 \\mid D=d, Z=z\\right) \\\\\n& =P\\left(c_{0} \\leq \\alpha_{0}+\\alpha_{1} D+U \\leq c_{1}, \\gamma_{0}+\\gamma_{1} Z+V \\geq 0 \\mid D=d, Z=z\\right) \\\\\n& =P\\left(c_{0} \\leq \\alpha_{0}+\\alpha_{1} d+U \\leq c_{1}, \\gamma_{0}+\\gamma_{1} z+V \\geq 0 \\mid D=d, Z=z\\right) \\\\\n& =P\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d \\leq U \\leq c_{1}-\\alpha_{0}-\\alpha_{1} d, V \\geq-\\gamma_{0}-\\gamma_{1} z \\mid D=d, Z=z\\right) \\\\\n& =P\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d \\leq U \\leq c_{1}-\\alpha_{0}-\\alpha_{1} d, V \\geq-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n& =\\Phi_{U}\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d\\right)-\\Phi_{U}\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d\\right) \\\\\n& -\\Phi_{U, V}\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d,-\\gamma_{0}-\\gamma_{1} z, \\rho_{U V}\\right) \\\\\n& +\\Phi_{U, V}\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d,-\\gamma_{0}-\\gamma_{1} z, \\rho_{U V}\\right)\n\\end{aligned}\n$$\n\nThe first equality follows from the law of total probability. The second through fifth equalities follow from the model's structure described in Equation C.1, namely $P\\left(Y>0, Y^{*}<\\right.$ $0 \\mid D=d)=0$ and $Y^{*}=Y$, not missing for $S=1$, the structure of $S$, and the latent linear model. The sixth step is due to Assumption 7. The last equality uses Assumption 8 as well as properties of normal random variables. Thus, we can construct a test similarly to the one in the main text, using these equalities in addition to the ones of the form $P\\left(Y \\geq c_{2} \\mid D=d, Z=z\\right)$.", "tables": {}, "images": {}}, {"section_id": 14, "text": "# Appendix D. Results from Remark 3 \n\nIn this appendix we derive the testable implications of the extensions to the classic Tobit and IV-Tobit discussed in Remark 3. We discuss testable implications assuming the identification of the relevant parameters or distributions.\nD.1. Barros et al. (2018) and Carson and Sun (2007). Barros et al. (2007) proposes a variant of the tobit model with elliptically contoured distributions and a non-zero threshold. At the same time Carson and Sun (2007) proposes a Tobit model with a non-zero threshold. In this section we combine both types of results and report the testable implications with a generic non-zero threshold and a generic known or identifiable parametric distribution function. In addition, extend the latent structure to be also known or an identifiable function up to a vector of parameters but invertible in $U$. In this context, let:\n\n$$\n\\left\\{\\begin{aligned}\nY & =\\max \\left(\\tau, Y^{*}\\right) \\\\\nY^{*} & =g(\\alpha, D, U)\n\\end{aligned}\\right.\n$$\n\nAssumption 9. $D$ is independent of $U$.\nAssumption 10. $U$ is distributed according to distribution $F_{H}($.$) with parameters \\omega$.\n\nIn this context, the testable implications are, starting at the continuous part of the distribution of $Y$, the conditional probabilities of $c_{0} \\leq Y \\leq c_{1}$ for a $c_{1}, c_{0}>\\tau$ are observed. For any value of the treatment variables $d \\in \\mathcal{D}$ :\n\n$$\n\\begin{aligned}\nP\\left(c_{0} \\leq Y \\leq c_{1} \\mid D=d\\right) & =P\\left(c_{0} \\leq Y \\leq c_{1}, Y^{*} \\geq \\tau \\mid D=d\\right)+P\\left(c_{0} \\leq Y \\leq c_{1}, Y^{*}<\\tau \\mid D=d\\right) \\\\\n& =P\\left(c_{0} \\leq Y \\leq c_{1}, Y^{*} \\geq \\tau \\mid D=d\\right) \\\\\n& =P\\left(c_{0} \\leq Y^{*} \\leq c_{1}, Y^{*} \\geq \\tau \\mid D=d\\right) \\\\\n& =P\\left(c_{0} \\leq Y^{*} \\leq c_{1} \\mid D=d\\right) \\\\\n& =P\\left(c_{0} \\leq g(\\alpha, D, U) \\leq c_{1} \\mid D=d\\right) \\\\\n& =P\\left(g^{-1}\\left(\\alpha, d, c_{0}\\right) \\leq U \\leq g^{-1}\\left(\\alpha, d, c_{1}\\right) \\mid D=d\\right) \\\\\n& =F_{H}\\left(g^{-1}\\left(\\alpha, d, c_{1}\\right) ; \\omega\\right)-F_{H}\\left(g^{-1}\\left(\\alpha, d, c_{0}\\right) ; \\omega\\right)\n\\end{aligned}\n$$\n\nTurning to the accumulation point, the observed event of $Y=0$,\n\n$$\nP(Y=0 \\mid D=d)=P\\left(Y^{*} \\leq \\tau \\mid D=d\\right)=F_{H}\\left(g^{-1}(\\alpha, d, \\tau) ; \\omega\\right)\n$$\n\nThese equalities can be used to construct a test in a similar way as did for the classic Tobit and IV-Tobit by adding the type of equalities $P\\left(Y \\geq c_{2} \\mid D=d\\right)$ which can be derived in a similar fashion. Also, note it is possible to extend the previous development to cases where the truncation takes the form $Y=Y^{*}$ if $\\tau_{0} \\leq Y^{*} \\leq \\tau_{1}, Y=\\tau_{0}$ if $\\tau_{0} \\geq Y^{*}$ and $Y=\\tau_{1}$ if $Y^{*} \\geq \\tau_{1}$.", "tables": {}, "images": {}}, {"section_id": 15, "text": "# D.2. Wooldridge (2005); Honore, Kyriazidou, and Powell (2000); Honor\u00e9 (1993). \n\nConsider the following dynamic version of the Tobit model, which is related to Wooldridge (2005); Honore, Kyriazidou, and Powell (2000); Honor\u00e9 (1993). Here, we specify the conditional behaviour of $c_{i}$ in the spirit of Wooldridge (2005) and others.\n\n$$\n\\left\\{\\begin{aligned}\nY_{i, t} & =\\max \\left(0, Y_{i, t}^{*}\\right) \\\\\nY_{i, t}^{*} & =\\alpha_{0}+\\alpha_{1} D_{i, t}+\\alpha_{2} g\\left(Y_{i, t-1}\\right)+c_{i}+U_{i, t}\n\\end{aligned}\\right.\n$$\n\nAssumption 11. $D_{i, t}$ is independent of $U_{i, t}$ given $Y_{i, t-1}, c_{i}$.\nAssumption 12. $U_{i, t} \\mid Y_{i, t-1}, c_{i}$ follows a $N(0,1)$ distribution.\nAssumption 13. $c_{i} \\mid Y_{i, t-1}, D_{i, t-1}$ has a known distribution such as $N(0,1)$.\n\nThen, starting at the continuous part of the distribution of $Y$, the conditional probabilities of $c_{0} \\leq Y \\leq c_{1}$ for a $c_{1}, c_{0}>0$ are observed. For any value of the treatment variables $d \\in \\mathcal{D}$, $P\\left(c_{0} \\leq Y_{i, t} \\leq c_{1} \\mid D_{i, t}=d, Y_{i, t-1}=y\\right)$ :\n\n$$\n\\begin{aligned}\n& =\\int P\\left(c_{0} \\leq Y_{i, t} \\leq c_{1} \\mid D_{i, t}=d, Y_{i, t-1}=y, c_{i}\\right) f\\left(c_{i} \\mid D_{i, t}=d, Y_{i, t-1}=y\\right) d c_{i} \\\\\n& =\\int P\\left(c_{0} \\leq Y_{i, t} \\leq c_{1} \\mid Y_{i, t-1}=y, c_{i}\\right) f\\left(c_{i} \\mid D_{i, t}=d, Y_{i, t-1}=y\\right) d c_{i} \\\\\n& =\\int P\\left(c_{0} \\leq Y_{i, t}^{*} \\leq c_{1} \\mid Y_{i, t-1}=y, c_{i}\\right) f\\left(c_{i} \\mid D_{i, t}=d, Y_{i, t-1}=y\\right) d c_{i} \\\\\n& =\\int P\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d-\\alpha_{2} g(y)-c_{i} \\leq U_{i, t} \\leq c_{1}-\\alpha_{0}-\\alpha_{1} d-\\alpha_{2} g(y)-c_{i} \\mid Y_{i, t-1}=y, c_{i}\\right) f\\left(c_{i} \\mid d, y\\right) d c_{i} \\\\\n& =\\int\\left[\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d-\\alpha_{2} g(y)-c_{i}\\right)-\\Phi\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d-\\alpha_{2} g(y)-c_{i}\\right)\\right] \\phi\\left(c_{i}\\right) d c_{i}\n\\end{aligned}\n$$\n\nSimilarly,\n\n$$\n\\begin{aligned}\nP\\left(Y_{i, t}=0 \\mid D_{i, t}=d, Y_{i, t-1}=y\\right) & =\\int P\\left(Y_{i, t}=0 \\mid D_{i, t}=d, Y_{i, t-1}=y, c_{i}\\right) f\\left(c_{i} \\mid D_{i, t}=d, Y_{i, t-1}=y\\right) d c_{i} \\\\\n& =\\int P\\left(Y_{i, t}=0 \\mid Y_{i, t-1}=y, c_{i}\\right) f\\left(c_{i} \\mid D_{i, t}=d, Y_{i, t-1}=y\\right) d c_{i} \\\\\n& =\\int P\\left(Y_{i, t}^{*} \\leq 0 \\mid Y_{i, t-1}=y, c_{i}\\right) f\\left(c_{i} \\mid D_{i, t}=d, Y_{i, t-1}=y\\right) d c_{i} \\\\\n& =\\int P\\left(U_{i, t} \\leq-\\alpha_{0}-\\alpha_{1} d-\\alpha_{2} g(y)-c_{i} \\mid Y_{i, t-1}=y, c_{i}\\right) f\\left(c_{i} \\mid d, y\\right) d c_{i} \\\\\n& =\\int\\left[\\Phi\\left(-\\alpha_{0}-\\alpha_{1} d-\\alpha_{2} g(y)-c_{i}\\right) \\mid \\phi\\left(c_{i}\\right) d c_{i}\\right.\n\\end{aligned}\n$$\n\nWhich can then be used to construct a test in a similar way as presented in the main text by adding the type of equalities $P\\left(Y_{i, t} \\geq c_{2} \\mid D_{i, t}=d, Y_{i, t-1}=y\\right)$, with the caveat that the right-hand side requires numerical integration or an approximation by an estimator when no closed form is available. Such estimator should ensure that the left-hand side of the equality converges at root- $N$ in order for the estimation step of the null model to be asymptotically negligible (Acerenza, Bartalotti, and K\u00e9dagni, 2023, Appendix B).", "tables": {}, "images": {}}, {"section_id": 16, "text": "# Appendix E. Non-learnability \n\nE.1. Non-Learnability for the classic Tobit model. As mentioned in Remark 2, the standard Tobit model is non-verifiable, that is, we cannot learn if the maintained Tobit model is the true data generating process based on the sharp equalities proposed in Section 3.1. One can show that by finding an alternative model that is compatible with the equalities (3.1)-(3.3) in all cases in which the Tobit model could not be disregarded. Suppose that,\n\n$$\n\\left\\{\\begin{aligned}\n\\bar{Y} & =\\max \\left(0, \\bar{Y}^{*}\\right) \\\\\n\\bar{Y}^{*} & =G\\left(\\alpha_{0}+\\alpha_{1} D+\\bar{U}\\right)\n\\end{aligned}\\right.\n$$\n\nWhere $G($.$) is some continuous and strictly increasing function such that G^{-1}(0)=0$ and $\\bar{U}$ is a random variable that is $N(0,1)$.\n\nFor $c_{0} \\leq Y \\leq c_{1}$ for a $c_{1}, c_{0}>0$ and for any value of the treatment variables $d \\in \\mathcal{D}$, assume that the equalities (3.1)-(3.3) hold:\n\n$$\n\\begin{aligned}\nP\\left(c_{0} \\leq Y \\leq c_{1} \\mid D=d\\right) & =\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d\\right)-\\Phi\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d\\right) \\\\\nP\\left(c_{1} \\leq Y \\mid D=d\\right) & =1-\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d\\right) \\\\\nP(Y=0 \\mid D=d) & =1-\\Phi\\left(\\alpha_{0}+\\alpha_{1} d\\right)\n\\end{aligned}\n$$\n\nNow define $\\bar{Y}_{d}=G\\left(\\alpha_{0}+\\alpha_{1} d+\\bar{U}\\right)$ and define the following distribution function:\n\n$$\nP\\left(\\bar{Y}_{d} \\leq c_{1}, \\bar{U} \\leq u \\mid D=d\\right)=\\Phi\\left(\\min \\left\\{\\left(G^{-1}\\left(c_{1}\\right)-\\alpha_{0}-\\alpha_{1} d\\right), u\\right\\}\\right)\n$$\n\nIn the above proposed DGP, the latent model is not linear. However, the DGP is compatible with the data since,\n\n$$\n\\begin{aligned}\nP\\left(\\bar{Y}_{d} \\leq 0\\right) & =P\\left(\\bar{U} \\leq-\\alpha_{0}-\\alpha_{1} d\\right)=\\Phi\\left(-\\alpha_{0}-\\alpha_{1} d\\right) \\\\\n& =1-\\Phi\\left(\\alpha_{0}+\\alpha_{1} d\\right)=P(Y=0 \\mid D=d)\n\\end{aligned}\n$$\n\nThe last equality is due to the testable equalities holding. Similarly, for any $c_{1}>0$, we can get that\n\n$$\nP\\left(G\\left(c_{1}\\right)<\\bar{Y}_{d}\\right)=1-\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d\\right)=P\\left(c_{1}<Y \\mid D=d\\right)\n$$\n\nAnd,\n\n$$\n\\begin{aligned}\nP\\left(G\\left(c_{0}\\right) \\leq \\bar{Y}_{d} \\leq G\\left(c_{1}\\right)\\right) & =\\Phi\\left(c_{1}-\\alpha_{0}-\\alpha_{1} d\\right)-\\Phi\\left(c_{0}-\\alpha_{0}-\\alpha_{1} d\\right) \\\\\n& =P\\left(c_{0} \\leq Y \\leq c_{1} \\mid D=d\\right)\n\\end{aligned}\n$$\n\nHence, when the sharp equalities hold, there exists an alternative observationally equivalent model, to the classic tobit that can induce the observed data distribution. Indeed, the observed distribution of $Y$ and the non refuted marginal distribution of $U$, do not imply that we can learn the true distribution of $Y_{1}, Y_{0}, U$.\nE.2. Non-Learnability for the IV- Tobit model. As mentioned in Remark 5, the IVTobit model is non-verifiable, that is, we cannot learn if the maintained model is the true data generating process based on the sharp equalities proposed in Section 3.2. One can show that by finding an alternative model that is compatible with the equalities (3.4)-(3.12) in all cases in which the IV-Tobit model could not be disregarded. Suppose that,\n\n$$\n\\left\\{\\begin{array}{l}\n\\tilde{Y}=\\max \\left(0, \\tilde{Y}^{*}\\right) \\\\\n\\tilde{Y}^{*}=G\\left(\\beta_{0}+\\beta_{1} Z+\\tilde{W}\\right) \\\\\n\\tilde{D}=\\gamma_{0}+\\gamma_{1} Z+\\tilde{V}\n\\end{array}\\right.\n$$\n\nWhere $G$ is the same function as in the previous subsection. Assume that equations 3.4-3.12 hold:\n\n$$\n\\begin{aligned}\nP\\left(c_{0} \\leq Y \\leq c_{1}, d_{0} \\leq D \\leq d_{1} \\mid Z=z\\right) & =\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& +\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\nP\\left(c_{0} \\leq Y \\leq c_{1}, D \\leq d_{0} \\mid Z=z\\right) & =\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\nP\\left(c_{0} \\leq Y \\leq c_{1}, D \\geq d_{1} \\mid Z=z\\right) & =\\Phi_{W}\\left(c_{1}-\\beta_{0}-\\beta_{1} z\\right)-\\Phi_{W}\\left(c_{0}-\\beta_{0}-\\beta_{1} z\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& +\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\nP\\left(c_{1} \\leq Y, d_{0} \\leq D \\leq d_{1} \\mid Z=z\\right) & =\\Phi_{V}\\left(d_{1}-\\gamma_{0}-\\gamma_{1} z\\right)-\\Phi_{V}\\left(d_{0}-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& +\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\nP\\left(c_{1} \\leq Y, D \\leq d_{0} \\mid Z=z\\right) & =\\Phi_{V}\\left(d_{0}-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\nP\\left(c_{1} \\leq Y, D \\geq d_{1} \\mid Z=z\\right) & =1-\\Phi_{W}\\left(c_{1}-\\beta_{0}-\\beta_{1} z\\right)-\\Phi_{V}\\left(d_{1}-\\gamma_{0}-\\gamma_{1} z\\right) \\\\\n& +\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\nP(Y=0, d_{0} \\leq D \\leq d_{1} \\mid Z=z) & =\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\nP(Y=0, D \\leq d_{0} \\mid Z=z) & =\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\nP(Y=0, D \\geq d_{1} \\mid Z=z) & =\\Phi_{W}\\left(-\\beta_{0}-\\beta_{1} z\\right)-\\Phi_{W, V}\\left(-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right)\n\\end{aligned}\n$$\n\nDefine $\\bar{Y}_{z}=G\\left(\\beta_{0}+\\beta_{1} z+\\tilde{W}\\right), \\tilde{D}_{z}=\\gamma_{0}+\\gamma_{1} z+\\tilde{V}$ and define the following distribution function:\n\n$$\nP\\left(\\bar{Y}_{d} \\leq c_{1}, \\tilde{D}_{z} \\leq d_{1}, \\bar{U} \\leq u, \\bar{V} \\leq v \\mid D=d\\right)=\\Phi\\left(\\min \\left\\{\\left(G^{-1}\\left(c_{1}\\right)-\\beta_{0}-\\beta_{1} z\\right), u\\right\\}, \\min \\left\\{d_{1}-\\gamma_{0}-\\gamma_{1} z, v\\right\\} ; \\rho\\right)\\right.\n$$\n\nNow note that, for example,\n\n$$\n\\begin{aligned}\nP\\left(G\\left(c_{0}\\right) \\leq \\tilde{Y}_{z} \\leq G\\left(c_{1}\\right), d_{0} \\leq \\tilde{D}_{z} \\leq d_{1}\\right) & =\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{1}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& -\\Phi_{W, V}\\left(c_{1}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& +\\Phi_{W, V}\\left(c_{0}-\\beta_{0}-\\beta_{1} z, d_{0}-\\gamma_{0}-\\gamma_{1} z ; \\rho\\right) \\\\\n& =P\\left(c_{0} \\leq Y \\leq c_{1}, d_{0} \\leq D \\leq d_{1} \\mid Z=z\\right)\n\\end{aligned}\n$$\n\nA similar logic holds for the other equalities. But the model is not the IV-tobit model.", "tables": {}, "images": {}}, {"section_id": 17, "text": "# APPENDix F. Simulations FOR TEST's POWER UNDER VIOLATIONS OF NORMALITY \n\nTurning our attention to the test's power under violations of normality of the latent error, we consider the modified DGP in Equation F.1. In this DGP, $F(\\cdot)$ denotes an alternative density for the latent error $U$, which we vary across scenarios. Table 6 present the test's empirical coverage when $F(\\cdot)$ is uniform, lognormal and t-student distributions.\n\n$$\n\\left\\{\\begin{array}{ll}\nY & =\\max \\left\\{Y^{*}, 0\\right\\} \\\\\nY^{*} & =D+U \\\\\nD & =2 Z-V \\\\\n\\binom{V}{Z} & \\sim \\mathcal{N}\\left(\\mathbf{0}_{2}, \\boldsymbol{\\Sigma}\\right) \\\\\n\\boldsymbol{\\Sigma} & =\\left(\\begin{array}{ll}\n1 & 0 \\\\\n0 & 1\n\\end{array}\\right) \\\\\nU \\sim F(\\cdot)\n\\end{array}\\right.\n$$\n\nAs expected, the rejection rate for the case of the t-student with 80 degrees of freedom is close to the nominal size of the test, since it represents a very mild violation of the normality assumption. In the other three cases, which deviate significantly from the normality assumption, the test rejects the null hypothesis in most instances. This example indicates that the proposed test is useful in detecting violations of the distributional assumptions in the classic Tobit model.\n\nTable 6. Test power for violations in error structure\n\n![table_5](table_5)\n\nBased on 500 replications.", "tables": {"table_5": "| $N$ | $U$ | $\\operatorname{MSE}\\left(\\beta_{0}\\right)$ | $\\operatorname{MSE}\\left(\\beta_{1}\\right)$ | $\\alpha=10 \\%$ | $\\alpha=5 \\%$ | $\\alpha=1 \\%$ |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n| 5000 | t-student (df=80) | 0.9987 | 1.0018 | $7.21 \\%$ | $4.01 \\%$ | $1.40 \\%$ |\n|  | t-student (df=5) | 1.027 | 1.0624 | $92.20 \\%$ | $81.80 \\%$ | $48.80 \\%$ |\n|  | LogNormal | 1.3336 | 0.0896 | $100.00 \\%$ | $100.00 \\%$ | $100.00 \\%$ |\n|  | Uniform | 0.892 | 0.785 | $100.00 \\%$ | $100.00 \\%$ | $100.00 \\%$ |\n| 8000 | t-student (df=80) | 0.9999 | 1.0034 | $7.00 \\%$ | $4.80 \\%$ | $1.20 \\%$ |\n|  | t-student (df=5) | 1.0251 | 1.0653 | $99.20 \\%$ | $97.80 \\%$ | $87.58 \\%$ |\n|  | LogNormal | 1.3385 | 0.0866 | $100.00 \\%$ | $100.00 \\%$ | $100.00 \\%$ |\n|  | Uniform | 0.8932 | 0.7896 | $100.00 \\%$ | $100.00 \\%$ | $100.00 \\%$ |\n| 10000 | t-student (df=80) | 1.0016 | 1.0059 | $5.42 \\%$ | $2.41 \\%$ | $1.00 \\%$ |\n|  | t-student (df=5) | 1.0241 | 1.0642 | $99.20 \\%$ | $98.40 \\%$ | $90.58 \\%$ |\n|  | LogNormal | 1.3348 | 0.0868 | $100.00 \\%$ | $100.00 \\%$ | $100.00 \\%$ |\n|  | Uniform | 0.8908 | 0.7862 | $100.00 \\%$ | $100.00 \\%$ | $100.00 \\%$ |"}, "images": {}}], "id": "2408.02573v2", "authors": ["Santiago Acerenza", "Ot\u00e1vio Bartalotti", "Federico Veneri"], "categories": ["econ.EM"], "abstract": "This paper develops sharp testable implications for Tobit and IV-Tobit\nmodels' identifying assumptions: linear index specification, (joint) normality\nof latent errors, and treatment (instrument) exogeneity and relevance. The new\nsharp testable equalities can detect all possible observable violations of the\nidentifying conditions. We propose a testing procedure for the model's validity\nusing existing inference methods for intersection bounds. Simulation results\nsuggests proper size for large samples and that the test is powerful to detect\nlarge violation of the exogeneity assumption and violations in the error\nstructure. Finally, we review and propose new alternative paths to partially\nidentify the parameters of interest under less restrictive assumptions.", "updated": "2025-01-17T13:48:15Z", "published": "2024-08-05T15:48:14Z"}