{"title": "A Subquadratic Time Approximation Algorithm for Individually Fair\n  k-Center", "sections": [{"section_id": 0, "text": "## 1 INTRODUCTION\n\nClustering is the process of partitioning a given data set into subsets such that, ideally, the elements in each subset are similar to each other and elements in different subsets are less similar. It is a basic approach in unsupervised learning with applications in, for example, signal processing [1], community detection in networks [2][3], outlier detection [4] and data summarization [5].\n\nFor many clustering problems each cluster has a corresponding center that can be viewed as a representative of all points contained in the given cluster. Data points closer to the center are naturally better represented than those that are far away. Ideally, we would like every data point to be close to its representative center, but this is usually impossible to realize. One way to mitigate this is to use clustering objectives such as $k$-median or $k$-means clustering that optimize the average (squared) distance to the cluster center. But optimizing the average distance will often lead to some data points being less well represented than they could be. In applications where data points model humans, such a behaviour may be undesirable and raises the question how to obtain a clustering that is acceptable for everyone. This problem is addressed in a recent paper by Jung et al. [6] that introduced the notion of individual fairness in the context of clustering.\n\nIndividual fairness can be thought of as a clustering constraint that ensures that every data point is assigned to a center that is not much worse than what one could hope for in a certain average-type setting: If one partitions a data set with $n$ points in $k$ clusters then on average a cluster has $n / k$ data points [6]. Thus, individual fairness is defined to be the constraint that every data point has a center among its $\\lceil n / k\\rceil$-th nearest neighbors.\n\nIndividually fair clustering was mainly studied for $k$-median and $k$-means clustering in metric spaces and generalizations to $l_{p}$-norm type distance functions [7] [8] [9] [10]. This also led to results on the individually fair $k$-center problem, which we will call the $\\alpha$-fair $k$-center problem.\n\nIn this paper, we show that the properties of the $\\alpha$-fair $k$-center problem can be exploited to achieve a simple algorithm that improves upon the current state of the art. We then give another algorithm that achieves a randomized constant bicriteria approximation in $O(k n \\log (n / \\delta))$ time where $\\delta>0$ is a parameter that bounds the failure probability. To do so, we develop a procedure to approximate the\n\n[^0]\n[^0]:    *Department of Mathematics and Computer Science, University of Cologne, Germany. Email: ymebbens@gmail.com.\n    ${ }^{\\dagger}$ Department of Mathematics and Computer Science, University of Cologne, Germany. Email: funk@cs.uni-koeln.de.\n    $\\ddagger$ Department of Mathematics and Computer Science, University of Cologne, Germany. Email: hoeckendorff@cs.uni-koeln.de. Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - Project Number 459420781.\n    $\\S$ Department of Mathematics and Computer Science, University of Cologne, Germany. Email: sohler@cs.uni-koeln.de.\n    $\\cdot$Department of Mathematics and Computer Science, University of Cologne, Germany. Email: weil@cs.uni-koeln.de.\n\ndistances to the $\\lceil n / k\\rceil$-th nearest neighbors of each data point in that running time. We believe that this procedure may find further applications in the context of individual fairness.", "tables": {}, "images": {}}, {"section_id": 1, "text": "# 2 OUR CONTRIBUTIONS \n\nIn this work, we give a $O\\left(n^{2}+k n \\log n\\right)$ time (2,2)-bicriteria approximation algorithm for the individually $\\alpha$-fair metric $k$-center problem, improving upon the current state of the art $(3,3)$-approximation algorithm by Vakilian and Yal\u00e7iner [9].\n\nResult 1 (Simplified restatement of Theorem 8). Algorithm (2,2)-ApproxFairCenter is a (2,2)-bicriteria approximation algorithm for the individually $\\alpha$-fair (discrete) metric $k$-center problem with $O\\left(n^{2}+\\right.$ $k n \\log n$ ) running time, where $n$ is the number of input points.\n\nAs the running time of this algorithm is dominated by the computation of the $\\lceil n / k\\rceil$-th nearest neighbors of each data point, we develop a randomized approximation algorithm for these distances under the assumption that $k$ is smaller than $n / 6$ (if this is not the case we can compute all distances to the $\\lceil n / k\\rceil$-th nearest neighbors exactly in $O(n k)$ time).\n\nResult 2 (Simplified restatement of Lemma 11). Let $(P, d)$ be a finite metric space. Algorithm ApproxFairRadii computes with probability at least $1-\\delta$ for all $p \\in P$ a 5 -approximation to the distance of the $\\lceil n / k\\rceil$-th nearest neighbor. The running time of the algorithm is $O(n k \\log (n / \\delta))$.\n\nUsing the approximated distances, we modify the (2,2)-approximation algorithm to obtain a randomized approximation algorithm with subquadratic running time if $k$ is asymptotically smaller than $n$.\n\nResult 3 (Simplified restatement of Theorem 13). Let $\\delta, \\varepsilon>0$. Algorithm (10, 2+ $\\epsilon$ )-ApproxFairCenter is a randomized algorithm that computes with probability at least $1-\\delta$ a $(10,2+\\epsilon)$-bicriteria approximation for the individually $\\alpha$-fair (discrete) metric $k$-center problem. The running time of the algorithm is $O\\left(n k(\\log (n / \\delta))+k^{2} / \\varepsilon\\right)$, where $n$ is the number of input points.", "tables": {}, "images": {}}, {"section_id": 2, "text": "## 3 RELATED WORK\n\nFor the $k$-center problem there is a $O(n k)$ time 2-approximation by Gonzalez [11] and it is known that the problem is NP-complete to approximate with a factor less than 2 [12].\n\nThe notion of individual fairness we consider in this paper was introduced by Jung et al. [6] for $k$-clustering in general, but also studied previously in other contexts such as priority clustering [13] and metric embedding [14][15]. In fact, individually fair clustering is a special case of priority clustering [16]. In the context of individual fairness, a clustering of size $k$ is $\\alpha$-fair for a set of points $P$ and some $\\alpha>0$ if for each point $p$ in $P$ there is a center within $\\alpha$ times the distance to its $\\lceil|P| / k\\rceil$-th nearest neighbor in $P$. Jung et al. [6] showed that solving $k$-clustering under individual fairness with $\\alpha=1$ is NP-hard in any metric space. They additionally designed an algorithm that computes a $k$-center clustering that is 2 -fair but lacks any guarantee on the cost. In the context of individually fair $k$-clustering, previous work studied algorithms for arbitrary $\\ell_{p}$ norm cost functions including $k$-center, $k$-median and $k$-means as special cases [7] [8] [9] [10]. We start by stating the results for the case of $k$-center. The first result with guarantees on both cost and fairness was by Mahabadi and Vakilian [7], who developed a $\\tilde{O}\\left(k^{5} n^{5}\\right)$ time local search $(O(\\log n), 7)$-approximation algorithm that computes a $7 \\alpha$-fair solution with cost at most $O(\\log n)$ times the optimal cost, for the case $\\alpha \\geq 1$. Further work was made by Negahbani and Chakrabarty [8] utilizing LP rounding to develop a $\\tilde{O}\\left(k n^{4}\\right)$-time $(2+\\varepsilon, 8)$-approximation for $\\alpha=1$ and $\\varepsilon>0$. The most recent result with respect to bicriteria approximation is by Vakilian and Yal\u00e7iner [9], who proposed a $\\tilde{O}\\left(n^{2}\\right)$-time $(3+\\varepsilon, 3)$-approximation for any $\\alpha \\geq 1$ and $\\varepsilon>0$. Han et al. [17] consider a relaxed version of individual fair $k$-center by allowing outliers and propose a 4-approximation for this variant. Next we discuss the results for other $\\ell_{p}$-norms. The algorithm of Mahabadi and Vakilian [7] achieves a (84, 7)-approximation algorithm for $\\alpha$-fair $k$-median. Negahbani and Chakrabarty [8] designed a $\\left(2^{p+2}, 8\\right)$-approximation, which yields cost approximations 8 for $k$-median $(p=1)$ and 16 for $k$-means $(p=2)$ objective functions. Further results by Vakilian and Yal\u00e7iner [9] are a polynomial time $\\left(16^{p}+\\varepsilon, 3\\right)$-approximation for general $p$ and a $(7.081+\\varepsilon, 3)$-approximation for $k$-median. Finally, for $\\alpha=1$, Bateni et al. [10] proposed an $\\tilde{O}\\left(n k^{2}\\right)$ time $(O(1), 6)$-approximation algorithm for $k$-median and $k$-means. Additional studies include coresets for individually fair $k$-clustering by Chhaya et al. [18]\n\nand alternative notions to individual fairness like a feature based approach by Kar et al. [19] and an approach through similarity sets by Chakrabarti et al. [20].", "tables": {}, "images": {}}, {"section_id": 3, "text": "# 4 PRELIMINARIES \n\nIn this section, we will establish the necessary notation and introduce the $k$-center problem with individual fairness. Throughout this work $(P, d)$ will denote an arbitrary discrete metric space with $n=|P|$. $P$ will be given as input and we assume that one can compute $d(x, y)$ in constant time for any $x, y \\in P$. For a set $C \\subseteq P$ and some point $p \\in P$ we write $d(p, C):=\\min _{c \\in C} d(p, c)$ and set $d(p, \\emptyset):=\\infty$. We denote the cost of a set $C \\subseteq P$ by $\\operatorname{cost}(P, C):=\\max _{p \\in P} d(p, C)$. The definition of the unconstrained $k$-center problem is then as follows.\n\nDefinition 1 (discrete metric $k$-center problem). Given a discrete metric space $(P, d)$ and a target number of clusters $k \\in \\mathbb{N}$, find a set $C \\subseteq P$ of size $k$ such that $\\operatorname{cost}(P, C)$ is minimized.\n\nThe individual fairness constraint is modelled in the following way [6].\nDefinition 2. (fairness radius) Let $k \\in \\mathbb{N}, p \\in P$ and let $B(p, r):=\\{q \\in P \\mid d(p, q) \\leq r\\}$ be the ball centered at $p$ with radius $r \\in \\mathbb{R}_{\\geq 0}$. The $k$-fair radius of $p$ is defined as\n\n$$\nr_{k}(p):=\\inf \\left\\{r \\in \\mathbb{R}_{\\geq 0}| | B(p, r) \\mid \\geq n / k\\right\\}\n$$\n\nDefinition 3. (individually fair centers) For $\\alpha \\in \\mathbb{R}_{>0}$ and $k \\in \\mathbb{N}$, a set $C \\subseteq P$ of centers is called $(\\alpha, k)$-fair, if $d(p, C) \\leq \\alpha r_{k}(p)$ for all $p \\in P$. If in addition $|C| \\leq k$, then $C$ is called a feasible solution for the $\\alpha$-fair $k$-center problem.\n\nWhen the parameters $\\alpha$ and $k$ are clear from the context we call a feasible solution to the $\\alpha$-fair $k$-center problem also simply a feasible solution.\n\nDefinition 4 ( $\\alpha$-fair $k$-center problem). Given a discrete metric space $(P, d)$, a target number of clusters $k \\in \\mathbb{N}$, and a fairness parameter $\\alpha \\in \\mathbb{R}_{>0}$, find an $(\\alpha, k)$-fair set $C \\subseteq P$ of size $k$ that minimizes $\\operatorname{cost}(P, C)$.\n\nNote that there does not necessarily exist a feasible solution for all choices of $\\alpha>0$ in the $\\alpha$-fair $k$-center problem [6]. In this case, we define the cost of an optimal solution as infinity. However, it is known that for $\\alpha \\geq 2$ there is always a feasible solution [6]. We will consider the following bi-criteria approximation.\n\nDefinition 5 ( $(\\beta, \\gamma)$-approximation for $\\alpha$-fair $k$-center). Given $k \\in \\mathbb{N}, \\alpha \\in \\mathbb{R}_{>0}$ and let $\\Delta^{*}$ be the cost of an optimal solution for the $\\alpha$-fair $k$-center problem. A set $C \\subseteq P$ of size $k$ is a $(\\beta, \\gamma)$-approximation for the $\\alpha$-fair $k$-center problem, if the following two conditions hold:\n\n1. $\\operatorname{cost}(P, C) \\leq \\beta \\Delta^{*}$,\n2. $C$ is $(\\gamma \\alpha, k)$-fair.\n\nNote that, since $\\alpha$ is part of the input, one can reduce the $k$-center problem to the $\\alpha$-fair $k$-center problem, by choosing a suitable $\\alpha$ for given input points s.t. any set of $k$ centers is $(\\alpha, k)$-fair. By the hardness results on individual fairness [6] and approximability of $k$-center [12], a (2,2)-approximation algorithm for $\\alpha$-fair $k$-center is the best one can hope for in polynomial time unless P equals NP.", "tables": {}, "images": {}}, {"section_id": 4, "text": "## $5(2,2)$-APPROXIMATION ALGORITHM\n\nIn this section, we present and analyze our deterministic bicriteria approximation algorithm for the $\\alpha$-fair $k$-center problem. The first algorithm for individually fair clustering by Jung et al. [6] computes a $(2, k)$ fair solution by considering points $p \\in P$ in order, non-decreasingly sorted by their fairness radii $r_{k}(p)$, and choosing $p$ as center, if $B\\left(p, r_{k}(p)\\right)$ does not intersect the ball $B\\left(q, r_{k}(q)\\right)$, i.e $d(p, q)>r_{k}(p)+r_{k}(q)$, for all previously chosen centers $q \\in P$.\n\nThis approach is equivalent to the algorithm for finding a $(k / n)$-density net by Chan et al. [14], the metric embedding algorithm of Charikar et al. [15] and the 2-approximation algorithm for priority $k$-center by Plesnik [13][16]. Vakilian and Yal\u00e7iner [9] later changed the condition of choosing $p$ as a center to $d(p, q)$ having to be at least $2 \\alpha r_{k}(p) \\geq 2 \\alpha\\left(r_{k}(p)+r_{k}(q)\\right)$ for all previously chosen centers $q \\in P$.\n\nWe adapt this approach by guessing an upper bound $\\Delta$ on the cost of an optimal solution and modify the condition to $d(p, q) \\geq 2 \\min \\left\\{\\alpha r_{k}(p), \\Delta\\right\\}$, as done in Algorithm 1.\n\nBesides the fairness parameter $\\alpha>0$ and the number of centers $k$, Algorithm 1 also receives a cost value $\\Delta \\in \\mathbb{R}$ and function $r: P \\rightarrow \\mathbb{R}_{\\geq 0}$ as input. The algorithm is guaranteed to always compute a $(2 \\alpha, k)$-fair set $C \\subseteq P$ with cost at most $2 \\Delta$ if $r=r_{k}$. If there exists a feasible solution for $\\alpha$-fair $k$-center with cost at most $\\Delta$, then it additionally holds that $|C| \\leq k$. Assume that we know the optimal value $\\Delta^{*}$ for the $\\alpha$-fair $k$-center problem, then we can apply Algorithm 1 to obtain a (2, 2)-approximation. To find the value $\\Delta^{*}$ we exploit the fact that there always exist two input points $p, q \\in P$ with $d(p, q)=\\Delta^{*}$.\n\n```\nAlgorithm 1: FairCenter\n    Input: Number of centers \\(k \\in \\mathbb{N}\\), fairness parameter \\(\\alpha \\in \\mathbb{R}_{>0}\\), cost value \\(\\Delta \\in \\mathbb{R}\\), function\n        \\(r: P \\rightarrow \\mathbb{R}_{\\geq 0}\\)\n    Output: Set \\(C \\subseteq P\\)\n1 Let \\(P=\\left\\{p_{1}, \\ldots, p_{n}\\right\\}\\) be sorted s.t. \\(r\\left(p_{1}\\right) \\leq r\\left(p_{2}\\right) \\leq \\cdots \\leq r\\left(p_{n}\\right)\\)\n    \\(C:=\\emptyset\\)\n    for \\(i:=1\\) to \\(n\\) do\n        if \\(d\\left(p_{i}, C\\right)>2 \\min \\left\\{\\alpha r\\left(p_{i}\\right), \\Delta\\right\\}\\) then\n            \\(\\mid C:=C \\cup\\left\\{p_{i}\\right\\}\\)\n    return \\(C\\)\n```\n\nLemma 6. Let $k \\in \\mathbb{N}, \\alpha \\in \\mathbb{R}_{>0}, \\Delta \\in \\mathbb{R}_{>0}$ and $r: P \\rightarrow \\mathbb{R}$ s.t. $r(p) \\geq r_{k}(p)$ for all $p \\in P$. If there exists a feasible solution for $\\alpha$-fair $k$-center with cost at most $\\Delta$, then FairCenter $(k, \\alpha, \\Delta, r)$ returns a set $C$ of size at most $k$.\n\nProof. Let $(P, d)$ be the input instance and assume that there exists a feasible solution $C^{*}$ for the $\\alpha$-fair $k$ center problem with cost at most $\\Delta$ and let $C=\\left\\{c_{1}, \\ldots, c_{\\ell}\\right\\}$ be the set returned by FairCenter $(k, \\alpha, \\Delta, r)$. In order to prove the lemma, we will construct a set of $\\ell$ disjoint balls (one for each center) such that every ball contains at least one center from $C^{*}$. Since $\\left|C^{*}\\right| \\leq k$ this will imply the result.\n\nAssume that the centers $c_{1}, \\ldots, c_{\\ell}$ are ordered increasingly by the time at which they were included in $C$. Note that, since $\\alpha>0$ and $P$ is sorted non-decreasingly with respect to $r$, for $1 \\leq i \\leq j \\leq \\ell$, $\\alpha r\\left(c_{i}\\right) \\leq \\alpha r\\left(c_{j}\\right)$ holds. Now define $r^{\\prime}\\left(c_{i}\\right):=\\min \\left\\{\\alpha r\\left(c_{i}\\right), \\Delta\\right\\}$. Since $c_{1}, \\ldots, c_{\\ell}$ were included in $C$ by Line 4 of Algorithm 1, they satisfy\n\n$$\nd\\left(c_{j}, c_{i}\\right)>2 r^{\\prime}\\left(c_{j}\\right) \\geq r^{\\prime}\\left(c_{i}\\right)+r^{\\prime}\\left(c_{j}\\right)\n$$\n\nfor $1 \\leq i<j \\leq \\ell$, which implies that\n\n$$\nB\\left(c_{i}, r^{\\prime}\\left(c_{i}\\right)\\right) \\cap B\\left(c_{j}, r^{\\prime}\\left(c_{j}\\right)\\right)=\\emptyset\n$$\n\nWe now observe that $C^{*}$ must have at least one center in each of these balls. Indeed, assume that $B\\left(c_{i}, r^{\\prime}\\left(c_{i}\\right)\\right) \\cap C^{*}$ is empty for some $c_{i} \\in C$. Then $d\\left(c_{i}, C^{*}\\right)>r^{\\prime}\\left(c_{i}\\right)=\\min \\left\\{\\alpha r\\left(c_{i}\\right), \\Delta\\right\\} \\geq \\min \\left\\{\\alpha r_{k}\\left(c_{i}\\right), \\Delta\\right\\}$. Thus, $c_{i}$ either violates the fairness constraint of $C^{*}$ or the solution $C^{*}$ has cost more than $\\Delta$, which is a contradiction. Since the balls are disjoint and each ball contains at least one point of $C^{*}$, we conclude that $|C| \\leq k$.\n\nLemma 7. Let $k \\in \\mathbb{N}, \\alpha \\in \\mathbb{R}_{>0}$ and $\\Delta \\in \\mathbb{R}_{>0}$. If there exists a feasible solution for $\\alpha$-fair $k$-center with cost at most $\\Delta$, then $\\operatorname{FairCenter}\\left(k, \\alpha, \\Delta, r_{k}\\right)$ returns a $(2 \\alpha, k)$-fair set of at most $k$ points with cost at most $2 \\Delta$.\n\nProof. Let $C$ be the set returned by $\\operatorname{FairCenter}\\left(k, \\alpha, \\Delta, r_{k}\\right)$. By Lemma 6 we know that $|C| \\leq k$. The if-clause in Line 4 ensures that $d(p, C) \\leq 2 \\min \\left\\{\\alpha r_{k}(p), \\Delta\\right\\} \\leq 2 \\Delta$ for all $p \\in P$, which concludes the proof.\n\nTheorem 8. Let $k \\in \\mathbb{N}$ and $\\alpha \\in \\mathbb{R}_{>0}$. If there exists a feasible solution for $\\alpha$-fair $k$-center, Algorithm 2 computes a (2, 2)-approximation for $\\alpha$-fair $k$-center in time $O\\left(n^{2}+k n \\log n\\right)$.\n\nProof. Observe that the cost of an optimal solution for $\\alpha$-fair $k$-center is defined by the distance of two points in $P$. Let $\\Delta^{*}$ be the cost of an optimal solution, then by Lemma 7 the set $C$ returned by FairCenter $\\left(k, \\alpha, \\Delta^{*}, r_{k}\\right)$ is a (2,2)-approximation for $\\alpha$-fair $k$-center (note that we can include arbitrary additional points in $C$ until $|C|=k$, if $|C|<k$ ). To find the distance $\\Delta^{*}$ that is passed to Algorithm 1,\n\n```\n    Input: Number of centers \\(k \\in \\mathbb{N}\\), fairness parameter \\(\\alpha \\in \\mathbb{R}_{>0}\\)\n    Output: Subset of \\(P\\) of size at most \\(k\\), or failure message\n1 Let \\(D\\) be set of pairwise distances in \\(P\\)\n2 Compute \\(r_{k}(p)\\) for \\(p \\in P\\)\n    Do a binary search over \\(D\\) to find smallest \\(\\Delta\\) s.t. \\(\\left|\\operatorname{FairCenter}\\left(k, \\alpha, \\Delta, r_{k}\\right)\\right| \\leq k\\)\n    if \\(\\Delta\\) does not exist then\n        return no feasible solution exists\n    else\n        return \\(\\operatorname{FairCenter}\\left(k, \\alpha, \\Delta, r_{k}\\right)\\)\n```\n\nwe first compute in $O\\left(n^{2}\\right)$ time for all points $p, q \\in P$ their distances $d(p, q)$. For each input point we can then compute its $k$-fair radii $r_{k}(p)$ in $O(n)$ time (e.g. Theorem 9.3 in [21]). Additionally we sort $P$ in non-decreasing order with respect to the $k$-fair radii, which takes $O(n \\log n)$ time. We apply a binary search on the pairwise distances to find the optimal $\\Delta^{*}$ and keep track of the subset of $D$ that can contain the optimal solution. In each recursion step the median can be computed in linear time (e.g. Theorem 9.3 in [21]) without sorting the values a priori. We invoke $O(\\log n)$ queries to Algorithm 1 by doing so, where we increase the cost value if $|C|>k$ and decrease otherwise. If the binary search terminates without finding a cost value such that $|C| \\leq k$ then no feasible solution exists. A call of Algorithm 1 takes $O(n k)$ time, since we computed the $k$-fair radii and sorted $P$ beforehand. The running time of the binary search on $1 \\leq t \\leq n^{2}$ elements is $T(t)=O(t)+O(n k)+T(t / 2) \\in O\\left(n^{2}+k n \\log n\\right)$. This results in a total running time of $O\\left(n^{2}+k n \\log n\\right)$, which concludes the proof.\n\nNotice that all results in this section are under the assumption that a feasible solution exists. We now remark what happens if this is not the case. From Lemma 1 we can derive that if FairCenter $\\left(k, \\alpha, \\Delta, r_{k}\\right)$ returns a set of size larger than $k$ then there does not exist a feasible solution for $\\alpha$-fair $k$-center clustering with cost at most $\\Delta$. On the other hand, it may be the case that there does not exist a feasible solution but a set $C$ of size at most $k$ is returned. Since for all $p \\in P, d(p, C) \\leq 2 \\min \\left\\{\\alpha r_{k}(p), \\Delta\\right\\}, C$ is then a feasible solution for $2 \\alpha$-fair $k$-center with cost at most $2 \\Delta$.", "tables": {}, "images": {}}, {"section_id": 5, "text": "# 6 FAST $(10,2+\\varepsilon)$-APPROXIMATION \n\nNext, we give a subquadratic time $(10,2+\\varepsilon)$-approximation algorithm. The running time bottleneck of the procedure discussed in Theorem 8 is the computation of the candidate cost values and the fair radii, both of which take $\\Theta\\left(n^{2}\\right)$ time. To overcome this, we show in Section 6.1 that a small set containing a good approximation of the optimal cost can be obtained using Gonzalez's algorithm [11] and we approximate the fair radii using uniform sampling in Section 6.2.\n\nSince the randomized algorithm presented in this section has a running time in $\\tilde{O}(k n)$, we get subquadratic time under the natural assumption that $k$ is asymptotically smaller then $n$. Furthermore, in this section we assume the pairwise distances between points in $P$ to be distinct, which can be achieved by an arbitrarily small perturbation of the input points.", "tables": {}, "images": {}}, {"section_id": 6, "text": "### 6.1 COST VALUE CANDIDATES\n\nWe start by discussing how to efficiently compute a small set of candidate values that contains a good approximation for the optimal cost of the given $\\alpha$-fair $k$-center instance. To do so, we compute $k$ centers that are a constant approximation for the unconstrained $k$-center problem and show that the optimal cost of $\\alpha$-fair $k$-center either relates to the cost of unconstrained $k$-center, or to the distance between two of our computed centers. We use the algorithm by Gonzalez for this procedure [11]. This algorithm finds a 2-approximation for the optimal $k$-center cost by starting with an arbitrary point as first center and then greedily selecting the point as new center, which is furthest away from all previously chosen centers.\n\nAlgorithm 3 describes our procedure to find a list of cost value candidates.\nLemma 9. Let $k \\in \\mathbb{N}$ and $\\alpha, \\varepsilon \\in \\mathbb{R}_{>0}$. Assume that there exists a solution for the $\\alpha$-fair $k$-center problem and let $\\Delta_{\\alpha}^{*}$ be the cost of an optimal solution. CostCandidates $(k, \\varepsilon)$ computes in $O\\left(k n+k^{2} / \\varepsilon\\right)$ time a set $L$ of size $O\\left(k^{2} / \\varepsilon\\right)$ such that there exists $\\ell \\in L$ with $\\Delta_{\\alpha}^{*} \\leq \\ell \\leq(1+\\varepsilon) \\Delta_{\\alpha}^{*}$.", "tables": {}, "images": {}}, {"section_id": 7, "text": "# Algorithm 3: CostCandidates \n\nInput: Number of centers $k \\in \\mathbb{N}$, precision parameter $\\varepsilon \\in \\mathbb{R}_{>0}$\nOutput: Set $L \\subset \\mathbb{R}$\n1 Let $C_{G}$ be the set of points returned by Gonzalez's algorithm\n$2 L:=\\left\\{\\frac{1}{2}(1+\\varepsilon)^{j} \\max _{p \\in P} d\\left(p, C_{G}\\right) \\mid j \\in\\left\\{1, \\ldots,\\left\\lceil\\log _{1+\\varepsilon}(16)\\right\\rceil\\right\\}\\right\\}$\n3 for $\\left.\\left(g_{1}, g_{2}\\right) \\in C_{G}^{2}\\right.$ with $g_{1} \\neq g_{2}$ do\n$4 \\quad \\mid L:=L \\cup\\left\\{\\frac{1}{2}(1+\\varepsilon)^{j} d\\left(g_{1}, g_{2}\\right) \\mid j \\in\\left\\{1, \\ldots,\\left\\lceil\\log _{1+\\varepsilon}(4)\\right\\rceil\\right\\}\\right\\}$\n5 return $L$\n\nProof. Let OPT be an optimal set of centers for $k$-center (without fairness constraints) and $\\Delta^{*}:=$ $\\max _{p \\in P} d(p, \\mathrm{OPT})$. Let $C_{G}$ be the set of centers found by Gonzalez's algorithm and $\\Delta:=\\max _{p \\in P} d\\left(p, C_{G}\\right)$. It holds that $\\Delta^{*} \\leq \\Delta \\leq 2 \\Delta^{*}$ and that $C_{G}$ can be computed in $O(k n)$ time as shown by Gonzalez [11].\n\nFor each pair of distinct centers $g_{1}, g_{2} \\in C_{G}$, let\n\n$$\n\\begin{aligned}\nL\\left(g_{1}, g_{2}\\right):= & \\left\\{\\frac{1}{2}(1+\\varepsilon)^{j} d\\left(g_{1}, g_{2}\\right) \\mid\\right. \\\\\n& \\left.j \\in\\left\\{1, \\ldots,\\left\\lceil\\log _{1+\\varepsilon}(4)\\right\\rceil\\right\\}\\right\\}\n\\end{aligned}\n$$\n\nObserve that the union of the intervals $\\left[(1+\\varepsilon)^{-1} \\ell, \\ell\\right]$ over all $\\ell \\in L\\left(g_{1}, g_{2}\\right)$ completely covers the interval $\\left[\\frac{1}{2} d\\left(g_{1}, g_{2}\\right), 2 d\\left(g_{1}, g_{2}\\right)\\right]$.\n\nFurthermore, let\n\n$$\nL_{0}:=\\left\\{\\frac{1}{2}(1+\\varepsilon)^{j} \\Delta \\mid j \\in\\left\\{1, \\ldots,\\left\\lceil\\log _{1+\\varepsilon}(16)\\right\\rceil\\right\\}\\right\\}\n$$\n\nSimilarly, the union of the intervals $\\left[(1+\\varepsilon)^{-1} \\ell, \\ell\\right]$ over all $\\ell \\in L_{0}$ completely covers the interval $\\left[\\frac{1}{2} \\Delta, 8 \\Delta\\right]$. Finally, let\n\n$$\nL:=L_{0} \\cup \\bigcup_{g_{1}, g_{2} \\in C_{G}, g_{1} \\neq g_{2}} L\\left(g_{1}, g_{2}\\right)\n$$\n\nas it is constructed in Algorithm 3.\nWe will show that $L$ has the desired properties. The bounds on running time and size are clear from the construction. To prove that there exists $\\ell \\in L$ satisfying $\\Delta_{\\alpha}^{*} \\leq \\ell \\leq(1+\\varepsilon) \\Delta_{\\alpha}^{*}$, we consider two cases.\n\nFirst, assume that\n\n$$\n\\Delta^{*} \\leq \\Delta_{\\alpha}^{*} \\leq 8 \\Delta^{*}\n$$\n\nSince\n\n$$\n\\frac{1}{2} \\Delta \\leq \\Delta^{*} \\leq \\Delta\n$$\n\nit follows that\n\n$$\n\\frac{1}{2} \\Delta \\leq \\Delta_{\\alpha}^{*} \\leq 8 \\Delta\n$$\n\nThen there exists $j \\in\\left\\{1, \\ldots,\\left\\lceil\\log _{1+\\varepsilon}(16)\\right\\rceil\\right\\}$ such that\n\n$$\n\\frac{1}{2}(1+\\varepsilon)^{j-1} \\Delta \\leq \\Delta_{\\alpha}^{*} \\leq \\frac{1}{2}(1+\\varepsilon)^{j} \\Delta\n$$\n\nthus,\n\n$$\n\\Delta_{\\alpha}^{*} \\leq \\frac{1}{2}(1+\\varepsilon)^{j} \\Delta \\leq(1+\\varepsilon) \\Delta_{\\alpha}^{*}\n$$\n\nSince $\\frac{1}{2}(1+\\varepsilon)^{j} \\Delta \\in L$, this proves the claim.\nSecond, assume that $\\Delta_{\\alpha}^{*}>8 \\Delta^{*}$. Let $\\mathrm{OPT}_{\\alpha}$ be an optimal solution for $\\alpha$-fair $k$-center and consider $p \\in P, c_{\\alpha} \\in \\mathrm{OPT}_{\\alpha}$ that realize $\\Delta_{\\alpha}^{*}$, i.e., $d\\left(p, c_{\\alpha}\\right)=\\Delta_{\\alpha}^{*}$. Furthermore, let $g(p)$ and $g\\left(c_{\\alpha}\\right)$ be the centers in $C_{G}$ closest to $p$ and $c_{\\alpha}$, respectively. We have $d(p, g(p)) \\leq 2 \\Delta^{*}$ and $d\\left(c_{\\alpha}, g\\left(c_{\\alpha}\\right)\\right) \\leq 2 \\Delta^{*}$, so by the triangle inequality\n\n$$\n\\begin{aligned}\nd\\left(g(p), g\\left(c_{\\alpha}\\right)\\right) & \\leq d(g(p), p)+d\\left(p, c_{\\alpha}\\right)+d\\left(c_{\\alpha}, g\\left(c_{\\alpha}\\right)\\right) \\\\\n& \\leq \\Delta_{\\alpha}^{*}+4 \\Delta^{*} \\\\\n& \\leq 2 \\Delta_{\\alpha}^{*}\n\\end{aligned}\n$$\n\nwhere the last inequality follows from $\\Delta_{\\alpha}^{*}>8 \\Delta^{*}$. On the other hand,\n\n$$\n\\begin{aligned}\nd\\left(g(p), g\\left(c_{\\alpha}\\right)\\right) & \\geq d\\left(p, c_{\\alpha}\\right)-d(p, g(p))-d\\left(c_{\\alpha}, g\\left(c_{\\alpha}\\right)\\right) \\\\\n& \\geq \\Delta_{\\alpha}^{*}-4 \\Delta^{*} \\\\\n& \\geq \\frac{1}{2} \\Delta_{\\alpha}^{*}\n\\end{aligned}\n$$\n\nwhere the last inequality again follows from $\\Delta_{\\alpha}^{*}>8 \\Delta^{*}$. Hence,\n\n$$\n\\frac{1}{2} d\\left(g(p), g\\left(c_{\\alpha}\\right)\\right) \\leq \\Delta_{\\alpha}^{*} \\leq 2 d\\left(g(p), g\\left(c_{\\alpha}\\right)\\right)\n$$\n\nThen there exists $j \\in\\left\\{1, \\ldots,\\left\\lceil\\log _{1+\\varepsilon}(4)\\right\\rceil\\right\\}$ such that\n\n$$\n\\frac{1}{2}(1+\\varepsilon)^{j-1} d\\left(g(p), g\\left(c_{\\alpha}\\right)\\right) \\leq \\Delta_{\\alpha}^{*} \\leq \\frac{1}{2}(1+\\varepsilon)^{j} d\\left(g(p), g\\left(c_{\\alpha}\\right)\\right)\n$$\n\nthus,\n\n$$\n\\Delta_{\\alpha}^{*} \\leq \\frac{1}{2}(1+\\varepsilon)^{j} d\\left(g(p), g\\left(c_{\\alpha}\\right)\\right) \\leq(1+\\varepsilon) \\Delta_{\\alpha}^{*}\n$$\n\nSince\n\n$$\n\\frac{1}{2}(1+\\varepsilon)^{j} d\\left(g(p), g\\left(c_{\\alpha}\\right)\\right) \\in L\\left(g(p), g\\left(c_{\\alpha}\\right)\\right) \\subseteq L\n$$\n\nthis proves the claim in the second case, which concludes the proof.", "tables": {}, "images": {}}, {"section_id": 8, "text": "# 6.2 APPROXIMATING FAIR RADII \n\nNext we discuss how to efficiently compute good approximations for the $k$-fair radii of the points in $P$. The procedure first samples a small subset of the input $S$ such that with constant probability it holds that for every point $p \\in P$ there exists a point $q \\in S$ with $d(p, q) \\in\\left(r_{3 k}(p), r_{k}(p)\\right]$. The pseudocode of this subprocedure is stated in Algorithm 4. Note that a similiar result was proven by Czumaj and Sohler in the context of approximating the cost of $k$-nearest neighbor graphs (See lemma 3.1 in [22]).\n\n```\nAlgorithm 4: FairSampling\n    Input: Number of centers \\(k \\in \\mathbb{N}\\) with \\(k \\leq n / 6\\), failure probability \\(\\delta \\in(0,1)\\)\n    Output: Function \\(r^{\\prime}: P \\rightarrow \\mathbb{R}\\)\n\\(s:=36 k\\lceil\\ln (2 n / \\delta)\\rceil\\)\n\\(t:=27\\lceil\\ln (2 n / \\delta)\\rceil\\)\n    3 Let \\(S\\) be a subset of size \\(s\\) drawn uniformly at random with replacement from \\(P\\)\n    4 for \\(p \\in P\\) do\n        Let \\(x\\) be \\(t\\)-nearest neighbor of \\(p\\) in \\(S\\)\n        \\(r^{\\prime}(p):=d(p, x)\\)\n    7}\\mathrm{ return \\(r^{\\prime}\\)\n```\n\nLemma 10. Given $k \\in \\mathbb{N}$ such that $k \\leq n / 6$ and $\\delta \\in(0,1)$. Algorithm 4 returns in time $O(n k \\log (n / \\delta))$ with probability at least $1-\\delta$ for all $p \\in P$ a value $r^{\\prime}(p) \\in\\left(r_{3 k}(p), r_{k}(p)\\right]$.\nProof. Let $S$ be a sample taken uniformly at random (with replacement) from $P$ of size $s=36 k\\lceil\\ln (2 n / \\delta)\\rceil$ as in Algorithm 4. We start by showing that $r^{\\prime}(p) \\in\\left(r_{3 k}(p), r_{k}(p)\\right]$ for all $p \\in P$ with probability at least $1-\\delta$. For $p \\in P$ and $q \\in S$ let $X_{p q}^{k}$ be the indicator random variable that is 1 if the sample $q$ is in $B\\left(p, r_{k}(p)\\right)$ and 0 otherwise. Furthermore, let $X_{p}^{k}=\\sum_{q \\in S} X_{p q}^{k}$ be the random variable indicating the number of points of $S$ in $B\\left(p, r_{k}(p)\\right)$. We define $X_{p q}^{3 k}$ and $X_{p}^{3 k}$ similarly by replacing $r_{k}(p)$ by $r_{3 k}(p)$.\n\nObserve that $r^{\\prime}(p) \\in\\left(r_{3 k}(p), r_{k}(p)\\right]$ if and only if $X_{p}^{3 k}<t$ and $X_{p}^{k} \\geq t$, since $r^{\\prime}(p)$ is defined as the distance from $p$ to its $t$-nearest neighbor. Therefore, $r^{\\prime}(p) \\in\\left(r_{3 k}(p), r_{k}(p)\\right]$ does not hold only if $X_{p}^{3 k} \\geq t$ or $X_{p}^{k}<t$.\n\nFirst, we give an upper bound for $\\operatorname{Pr}\\left(X_{p}^{3 k} \\geq t\\right)$. By definition, $\\left|B\\left(p, r_{3 k}(p)\\right)\\right|=\\left\\lceil\\frac{n}{3 k}\\right\\rceil$, so\n\n$$\n\\frac{n}{3 k} \\leq\\left|B\\left(p, r_{3 k}(p)\\right)\\right| \\leq \\frac{n}{3 k}+1 \\leq \\frac{n}{2 k}\n$$\n\nsince $k \\leq n / 6$. Each $q \\in S$ is sampled uniformly at random from $P$, so $\\frac{1}{3 k} \\leq \\operatorname{Pr}\\left(X_{p q}^{3 k}=1\\right) \\leq \\frac{1}{2 k}$. By linearity of expectation, $E\\left[X_{p}^{3 k}\\right]=s \\operatorname{Pr}\\left(X_{p q}^{3 k}=1\\right)$, so $12\\lceil\\ln (2 n / \\delta)\\rceil \\leq E\\left[X_{p}^{3 k}\\right] \\leq 18\\lceil\\ln (2 n / \\delta)\\rceil$. Then\n\n$$\n\\begin{aligned}\n\\operatorname{Pr}\\left(X_{p}^{3 k} \\geq t\\right) & =\\operatorname{Pr}\\left(X_{p}^{3 k} \\geq 27\\lceil\\ln (2 n / \\delta)\\rceil\\right) \\\\\n& \\leq \\operatorname{Pr}\\left(X_{p}^{3 k} \\geq \\frac{1}{2} E\\left[X_{p}^{3 k}\\right]\\right)\n\\end{aligned}\n$$\n\nfrom which it follows by a Chernoff bound (e.g. Theorem 4.4 in [23]) that\n\n$$\n\\operatorname{Pr}\\left(X_{p}^{3 k} \\geq t\\right) \\leq e^{-E\\left[X_{p}^{3 k}\\right] / 12}\n$$\n\nSince $E\\left[X_{p}^{3 k}\\right] \\geq 12\\lceil\\ln (2 n / \\delta)\\rceil$, we conclude that\n\n$$\n\\operatorname{Pr}\\left(X_{p}^{3 k} \\geq t\\right) \\leq e^{-\\lceil\\ln (2 n / \\delta)\\rceil)} \\leq \\frac{\\delta}{2 n}\n$$\n\nSecond, we give an upper bound for $\\operatorname{Pr}\\left(X_{p}^{k}<t\\right)$. By a similar reasoning as before, we see that $\\frac{1}{k} \\leq \\operatorname{Pr}\\left(X_{p q}^{k}=1\\right) \\leq \\frac{3}{2 k}$ and $36\\lceil\\ln (2 n / \\delta)\\rceil \\leq E\\left[X_{p}^{k}\\right] \\leq 54\\lceil\\ln (2 n / \\delta)\\rceil$. Then\n\n$$\n\\begin{aligned}\n\\operatorname{Pr}\\left(X_{p}^{k}<t\\right) & =\\operatorname{Pr}\\left(X_{p}^{k}<27\\lceil\\ln (2 n / \\delta)\\rceil\\right) \\\\\n& \\leq \\operatorname{Pr}\\left(X_{p}^{k}<\\frac{3}{4} E\\left[X_{p}^{k}\\right]\\right)\n\\end{aligned}\n$$\n\nso it follows by a Chernoff bound (e.g. Theorem 4.5 in [23]) that\n\n$$\n\\operatorname{Pr}\\left(X_{p}^{k}<t\\right) \\leq e^{-E\\left[X_{p}^{k}\\right] / 32}\n$$\n\nSince $E\\left[X_{p}^{k}\\right] \\geq 36\\lceil\\ln (2 n / \\delta)\\rceil$, we conclude that\n\n$$\n\\operatorname{Pr}\\left(X_{p}^{k}<t\\right) \\leq e^{-\\lceil\\ln (2 n / \\delta)\\rceil)} \\leq \\frac{\\delta}{2 n}\n$$\n\nCombining both upper bounds, we see that $\\operatorname{Pr}\\left(r^{\\prime}(p) \\notin\\left(r_{3 k}(p), r_{k}(p)\\right]\\right) \\leq \\delta / n$. It follows from a union bound over all $p \\in P$ that the probability that $r^{\\prime}(p) \\notin\\left(r_{3 k}(p), r_{k}(p)\\right]$ for at least one $p \\in P$ is at most $\\delta$, which proves the desired claim.\n\nAs for the running time, drawing the sample set $S$ takes $O(k \\log (n / \\delta))$ time. Finding the $t$-nearest neighbor of $p \\in P$ in $S$ can be done in $O(k \\log (n / \\delta))$ time (e.g. Theorem 9.3 in [21]), yielding a total running time of $O(n k \\log (n / \\delta))$.\n\nNotice that the radii computed by Algorithm 4 are not necessarily constant factor approximations of the fairness radii. We can however use them to compute 3 -approximations of the actual $k$-fair radii as described in Algorithm 5. Algorithm 5 considers the input points in non-decreasing order with respect to the corresponding values $r^{\\prime}$ computed by Algorithm 4. Assuming Algorithm 4 to be successful, we argue that the following yields approximate fairness radii efficiently: The algorithm maintains a set $C$ of points for which we compute the fairness radii exactly. Initially $C$ is empty. Whenever a new point $p$ is considered, we check whether $B\\left(p, r^{\\prime}(p)\\right)$ intersects any of the balls $B\\left(q, r^{\\prime}(q)\\right)$ defined by the points $q \\in C$. If this is not the case, we add $p$ to $C$. Otherwise, we set the radius value of $p$ to $d(p, q)+r_{k}(q)$. Since the balls defined by the $r^{\\prime}$ values contain sufficiently many points and are disjoint, we can argue that the case of computing the $k$-fair radii explicitly does not happen too often.\n\n```\nAlgorithm 5: ApproxFairRadii\n    Input: Number of centers \\(k \\in \\mathbb{N}\\) with \\(k \\leq n / 6\\), failure probability \\(\\delta \\in(0,1)\\)\n    Output: Function \\(\\tilde{r}: P \\rightarrow \\mathbb{R}\\), or a failure message\n    1 Let \\(r^{\\prime}\\) be the function returned by FairSampling \\((k, \\delta)\\)\n    2 Organize \\(P\\) in a min-heap \\(H\\) with respect to \\(r^{\\prime}\\)\n    \\(p:=\\operatorname{extractMin}(H)\\)\n    4 Compute \\(r_{k}(p)\\) exactly and set \\(\\tilde{r}(p):=r_{k}(p)\\)\n    \\(C:=\\{p\\}\\)\n    6 while \\(H \\neq \\emptyset\\) do\n        \\(p:=\\operatorname{extractMin}(H)\\)\n        if \\(\\exists q \\in C: r^{\\prime}(p)+r^{\\prime}(q) \\geq d(p, q)\\) then\n            \\(\\tilde{r}(p):=d(p, q)+\\tilde{r}(q)\\)\n        else\n            Compute \\(r_{k}(p)\\) exactly and set \\(\\tilde{r}(p):=r_{k}(p)\\)\n            \\(C:=C \\cup\\{p\\}\\)\n            if \\(\\|C\\|>3 k\\) then\n                return Fail\n    15}\\mathrm{ return \\(\\tilde{r}\\)\n```\n\nLemma 11. Given $k \\in \\mathbb{N}$ with $k \\leq n / 6$ and $\\delta \\in(0,1)$. Then Algorithm 5 computes in $O(k n \\log (n / \\delta))$ time with probability at least $1-\\delta$ for all $p \\in P$ a value $\\tilde{r}(p)$ s.t. $r_{k}(p) \\leq \\tilde{r}(p) \\leq 5 r_{k}(p)$.\n\nProof. By Lemma 10, $r^{\\prime}(p) \\in\\left(r_{3 k}(p), r_{k}(p)\\right]$ for all $p \\in P$ with probability at least $1-\\delta$, so assume that this is the case for the proof of correctness. The definition of $k$-fair radius implies the following claim.\nClaim 12. For all $p, q \\in P, r_{k}(p) \\leq d(p, q)+r_{k}(q)$.\nConsider an arbitrary iteration of the algorithm and let $p$ be the point extracted from the min-heap. Note that for all $q \\in C, \\tilde{r}(q)=r_{k}(q)$. Let $(i)$ be the case that there exists a point $q \\in C$ such that $d(p, q) \\leq r^{\\prime}(p)+r^{\\prime}(q)$. This corresponds to Line 8 of the algorithm. Note that $r^{\\prime}(q) \\leq r^{\\prime}(p)$ for all $q \\in C$, since these points were considered before $p$. Then\n\n$$\n\\begin{aligned}\n\\tilde{r}(p) & =d(p, q)+\\tilde{r}(q) \\\\\n& =d(p, q)+r_{k}(q) \\\\\n& \\leq 2 d(p, q)+r_{k}(p) \\\\\n& \\leq 2\\left(r^{\\prime}(p)+r^{\\prime}(q)\\right)+r_{k}(p) \\\\\n& \\leq 4 r^{\\prime}(p)+r_{k}(p) \\\\\n& \\leq 5 r_{k}(p)\n\\end{aligned}\n$$\n\nwhere the first inequality holds by Claim 12. Let (ii) be the other case when there is no such point in $C$. This corresponds to Line 10 of the algorithm. Here, we trivially get $\\tilde{r}(p)=r_{k}(p)$.\n\nLet us consider the running time. By Lemma 10, the procedure $\\operatorname{FairSampling}(k, \\delta)$ takes $O(n k \\log (n / \\delta))$ time. Setting up the min-heap takes $O(n)$ time and extracting a point takes $O(\\log n)$ time. Consider an arbitrary iteration of the algorithm. Observe that the running time of Case $(i)$ is $O(|C|)$, since we search $C$ for an intersection. Case (ii) takes $O(n \\log (n))$ time, since we compute the $k$-fair radius exactly. Note that the number of iterations where Case (ii) happens corresponds directly to the size of $C$. It therefore remains to bound the size of $C$.\n\nAssume that FairSampling $(k, \\delta)$ is successful, i.e., that $r^{\\prime}(p) \\in\\left(r_{3 k}(p), r_{k}(p)\\right]$ for all $p \\in P$. Then the ball $B\\left(p, r^{\\prime}(p)\\right)$ contains at least $n / 3 k$ points for all $p \\in P$, which implies that for all $p \\in P$ there are at least $n / 3 k$ points $q$ in $P$ such that $r^{\\prime}(p)+r^{\\prime}(q) \\geq d(p, q)$. Since the Balls $B\\left(q, r^{\\prime}(q)\\right)$ of points $q \\in C$ are pairwise disjoint by definition of $C$, we get that whenever a point $p$ is included to $C$ through Case (ii) there exist at least $n / 3 k$ points for which Case (i) happens. This implies that Case (ii) can only happen up to $3 k$ times, so $|C| \\leq 3 k$. In total, we therefore incur a running time of $O(n k \\log (n / \\delta))$.\n\nNow consider the case that the procedure FairSampling failed, i.e., there exists $p \\in P$ such that $r^{\\prime}(p) \\notin\\left(r_{3 k}(p), r_{k}(p)\\right]$. If $r^{\\prime}(p) \\leq r_{3 k}(p)$, we cannot argue that Case (ii) happens at most $3 k$ times during the algorithm. It is therefore checked in Line 13 if $|C|>3 k$, which implies that FairSampling failed and the algorithm terminates after only executing $O(k)$ iterations of Case $(i)$. The running time is therefore also $O(n k \\log (n / \\delta))$ for the failure case.", "tables": {}, "images": {}}, {"section_id": 9, "text": "# 6.3 SUBQUADRATIC TIME APPROXIMATION ALGORITHM \n\nWe can now state and prove the main result of this work.\n\n```\nAlgorithm 6: \\((10,2+\\varepsilon)\\)-ApproxFairCenter\n    Input: Number of centers \\(k \\in \\mathbb{N}\\), fairness parameter \\(\\alpha \\in \\mathbb{R}_{>0}\\), failure probability \\(\\delta \\in(0,1)\\)\n    Output: Subset of \\(P\\) of size at most \\(k\\), or failure message\n    if \\(k>n / 6\\) or \\(k^{2} / \\varepsilon>n^{2} \\log n\\) then\n    2 return \\((2,2)\\)-ApproxFairCenter \\((P, k, \\alpha)\\)\n    \\(i \\leftarrow \\operatorname{ApproxFairRadii}(k, \\delta)\\)\n    if \\(\\tilde{r}=\\) Fail then\n    return Fail\n    \\(L \\leftarrow \\operatorname{CostCandidate}(k, \\varepsilon / 2)\\)\n    Binary search over \\(L\\) to find smallest \\(\\Delta\\) s.t. |FairCenter \\((k, \\alpha, \\Delta, \\tilde{r})| \\leq k\\)\n    if \\(\\Delta\\) does not exist then\n        return no feasible solution exists\n    else\n        return \\(\\operatorname{FairCenter}\\left(k, \\alpha, \\Delta, r_{k}\\right)\\)\n```\n\nTheorem 13. Given parameters $k \\in \\mathbb{N}, \\alpha, \\varepsilon \\in \\mathbb{R}_{>0}$ and $\\delta \\in(0,1)$. If there exists a feasible solution for $\\alpha$-fair $k$-center Algorithm 6 computes with probability at least $1-\\delta a(10,2+\\varepsilon)$-approximation for the $\\alpha$-fair $k$-center problem. The running time of the algorithm is in $O\\left(\\operatorname{kn} \\log (n / \\delta)+k^{2} / \\varepsilon\\right)$ time.\n\nProof. Assume that $k \\leq n / 6$ and $k^{2} / \\varepsilon \\leq n^{2} \\log n$, otherwise the proof follows from Theorem 8.\nWe first execute ApproxFairRadii $(k, \\delta)$. By Lemma 11, ApproxFairRadii $(k, \\delta)$ outputs values $\\tilde{r}(p)$ such that $r_{k}(p) \\leq \\tilde{r}(p) \\leq 5 r_{k}(p)$ for all $p \\in P$ with probability at least $1-\\delta$.\n\nNext we execute CostCandidate $(k, \\varepsilon / 2)$. By Lemma 9 , the set $L$ computed by CostCandidates $(k, \\varepsilon / 2)$ contains $\\Delta \\in L$ with $\\operatorname{cost}\\left(P, C^{*}\\right) \\leq \\Delta \\leq(1+\\varepsilon / 2) \\operatorname{cost}\\left(P, C^{*}\\right)$, where $C^{*}$ is an optimal solution for $\\alpha$-fair $k$-center.\n\nLet $C$ be the solution returned by FairCenter $\\left(k, \\alpha, \\Delta^{\\prime}, \\tilde{r}\\right)$ for an arbitrary $\\Delta^{\\prime} \\geq \\Delta$. By Lemma 6 , we know that in this case $|C| \\leq k$. Thus, the binary search stops with a value $\\Delta^{\\prime} \\leq \\Delta$. The if-clause in Line 4 of Algorithm FairCenter ensures that\n\n$$\n\\begin{aligned}\nd(p, C) & \\leq 2 \\min \\left\\{\\alpha \\tilde{r}(p), \\Delta^{\\prime}\\right\\} \\\\\n& \\leq 2 \\min \\left\\{\\alpha 5 r_{k}(p),(1+\\varepsilon / 2) \\operatorname{cost}\\left(P, C^{*}\\right)\\right\\}\n\\end{aligned}\n$$\n\nThis implies that $C$ is a $(10,2+\\varepsilon)$-approximation for $\\alpha$-fair $k$-center.\nFinally, we analyze the running time of this procedure. By Lemma 10, ApproxFairRadii $(k, \\delta)$ takes $O(k n \\log (n / \\delta))$ time. By Lemma 9, CostCandidates $(k, \\varepsilon / 2)$ requires $O\\left(k n+k^{2} / \\varepsilon\\right)$ time. Sorting $P$ takes $O(n \\log n)$ time. Analogous to Algorithm 2 one can implement the binary search to have running time $O\\left(k^{2} / \\varepsilon+k n \\log (k / \\varepsilon)\\right)$. Under our assumptions the procedure takes $O\\left(k n \\log (n / \\delta)+k^{2} / \\varepsilon\\right)$ time in total.", "tables": {}, "images": {}}, {"section_id": 10, "text": "# References \n\n[1] S. Lloyd, Least squares quantization in pcm, IEEE Transactions on Information Theory 28 (2) (1982) $129-137$.\n[2] S. Zhang, R.-S. Wang, X.-S. Zhang, Identification of overlapping community structure in complex networks using fun Physica A: Statistical Mechanics and its Applications 374 (1) (2007) 483-490. doi:https://doi.org/10.1016/j.physa.2006.07.023.\nURL https://www.sciencedirect.com/science/article/pii/S0378437106008119\n[3] A. Bota, M. Kresz, B. Zavalnij, Adaptations of the k-means algorithm to community detection in parallel environments, International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC) (2015) 299-302.\n[4] S. Chawla, A. Gionis, $k$-means: A unified approach to clustering and outlier detection, in: Proceedings of the 2013 SIAM International Conference on Data Mining (SDM 2013), 2013, pp. 189-197. doi:10.1137/1.9781611972832.21.\nURL https://epubs.siam.org/doi/abs/10.1137/1.9781611972832.21\n[5] M. Kleindessner, P. Awasthi, J. Morgenstern, Fair k-center clustering for data summarization, in: International Conference on Machine Learning (ICML 2019), PMLR, 2019, pp. 3448-3457.\n[6] C. Jung, S. Kannan, N. Lutz, Service in Your Neighborhood: Fairness in Center Location, in: 1st Symposium on Foundations of Responsible Computing (FORC 2020), Vol. 156 of Leibniz International Proceedings in Informatics (LIPIcs), Schloss Dagstuhl - Leibniz-Zentrum f\u00fcr Informatik, 2020, pp. 5:1-5:15.\n[7] S. Mahabadi, A. Vakilian, Individual fairness for k-clustering, in: International conference on machine learning (ICLM 2020), PMLR, 2020, pp. 6586-6596.\n[8] M. Negahbani, D. Chakrabarty, Better algorithms for individually fair $k$-clustering, Advances in Neural Information Processing Systems (NeurIPS 2021) 34 (2021) 13340-13351.\n[9] A. Vakilian, M. Yal\u00e7iner, Improved approximation algorithms for individually fair clustering, in: International conference on artificial intelligence and statistics (AISTATS 2022), PMLR, 2022, pp. $8758-8779$.\n\n[10] M. Bateni, V. Cohen-Addad, A. Epasto, S. Lattanzi, A scalable algorithm for individually fair kmeans clustering, in: International Conference on Artificial Intelligence and Statistics, PMLR, 2024, pp. 3151-3159.\n[11] T. F. Gonzalez, Clustering to minimize the maximum intercluster distance, Theoretical computer science 38 (1985) 293-306.\n[12] D. S. Hochbaum, D. B. Shmoys, A best possible heuristic for the k-center problem, Mathematics of operations research 10 (2) (1985) 180-184.\n[13] J. Plesn\u00edk, A heuristic for the p-center problems in graphs, Discrete Applied Mathematics 17 (3) (1987) $263-268$.\n[14] T.-H. H. Chan, M. Dinitz, A. Gupta, Spanners with slack, in: European Symposium on Algorithms (ESA 2006), Springer, 2006, pp. 196-207.\n[15] M. Charikar, K. Makarychev, Y. Makarychev, Local global tradeoffs in metric embeddings, SIAM Journal on Computing 39 (6) (2010) 2487-2512.\n[16] T. Bajpai, D. Chakrabarty, C. Chekuri, M. Negahbani, Revisiting priority $k$-center: Fairness and outliers, in: 48th International Colloquium on Automata, Languages, and Programming (ICALP 2021), Vol. 198 of Leibniz International Proceedings in Informatics (LIPIcs), 2021, pp. 21:1-21:20.\n[17] L. Han, D. Xu, Y. Xu, P. Yang, Approximation algorithms for the individually fair k-center with outliers, Journal of Global Optimization 87 (2) (2023) 603-618.\n[18] R. Chhaya, A. Dasgupta, J. Choudhari, S. Shit, On coresets for fair regression and individually fair clustering., in: Proceedings of The 25th International Conference on Artificial Intelligence and Statistics (AISTATS 2022), Vol. 151 of Proceedings of Machine Learning Research, 2022, pp. 96039625 .\n[19] D. Kar, M. Kosan, D. Mandal, S. Medya, A. Silva, P. Dey, S. Sanyal, Feature-based individual fairness in k-clustering, arXiv preprint arXiv:2109.04554 (2021).\n[20] D. Chakrabarti, J. P. Dickerson, S. A. Esmaeili, A. Srinivasan, L. Tsepenekas, A new notion of individually fair clustering: $\\alpha$-equitable $k$-center, in: 25 th International conference on artificial intelligence and statistics (AISTATS 2022), PMLR, 2022, pp. 6387-6408.\n[21] T. H. Cormen, C. E. Leiserson, R. L. Rivest, C. Stein, Introduction to algorithms, MIT press, 2022.\n[22] A. Czumaj, C. Sohler, Sublinear time approximation of the cost of a metric-nearest neighbor graph, SIAM Journal on Computing 53 (2) (2024) 524-571.\n[23] M. Mitzenmacher, E. Upfal, Probability and computing: Randomization and probabilistic techniques in algorithms and data analysis, Cambridge university press, 2017.", "tables": {}, "images": {}}], "id": "2412.04943v2", "authors": ["Matthijs Ebbens", "Nicole Funk", "Jan H\u00f6ckendorff", "Christian Sohler", "Vera Weil"], "categories": ["cs.DS", "cs.CG"], "abstract": "We study the $k$-center problem in the context of individual fairness. Let\n$P$ be a set of $n$ points in a metric space and $r_x$ be the distance between\n$x \\in P$ and its $\\lceil n/k \\rceil$-th nearest neighbor. The problem asks to\noptimize the $k$-center objective under the constraint that, for every point\n$x$, there is a center within distance $r_x$. We give bicriteria\n$(\\beta,\\gamma)$-approximation algorithms that compute clusterings such that\nevery point $x \\in P$ has a center within distance $\\beta r_x$ and the\nclustering cost is at most $\\gamma$ times the optimal cost. Our main\ncontributions are a deterministic $O(n^2+ kn \\log n)$ time\n$(2,2)$-approximation algorithm and a randomized\n$O(nk\\log(n/\\delta)+k^2/\\varepsilon)$ time $(10,2+\\varepsilon)$-approximation\nalgorithm, where $\\delta$ denotes the failure probability. For the latter, we\ndevelop a randomized sampling procedure to compute constant factor\napproximations for the values $r_x$ for all $x\\in P$ in subquadratic time; we\nbelieve this procedure to be of independent interest within the context of\nindividual fairness.", "updated": "2025-03-25T10:34:02Z", "published": "2024-12-06T11:00:16Z"}