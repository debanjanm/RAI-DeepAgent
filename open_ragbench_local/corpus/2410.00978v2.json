{"title": "Uncovering the Viral Nature of Toxicity in Competitive Online Video\n  Games", "sections": [{"section_id": 0, "text": "#### Abstract\n\nToxicity is a widespread phenomenon in competitive online video games. In addition to its direct undesirable effects, there is a concern that toxicity can spread to others, amplifying the harm caused by a single player's misbehavior. In this study, we estimate whether and to what extent a player's toxic speech spreads, causing their teammates to behave similarly. To this end, we analyze proprietary data from the free-to-play firstperson action game Call of Duty\u00ae: Warzone ${ }^{\\mathrm{TM}}$. We formulate and implement an instrumental variable identification strategy that leverages the network of interactions among players across matches. Our analysis reveals that all else equal, all of a player's teammates engaging in toxic speech increases their probability of engaging in similar behavior by 26.1 to 30.3 times the average player's likelihood of engaging in toxic speech. These findings confirm the viral nature of toxicity, especially toxic speech, in competitive online video games.\n\n\nIndex Terms-competitive online video games, peer effects, virality, toxicity.", "tables": {}, "images": {}}, {"section_id": 1, "text": "## I. INTRODUCTION\n\nCOMPETITIVE online video games are a popular form of entertainment. They allow players to immerse themselves in virtual environments and interact with other players. While these games offer a positive experience to many, they can also expose players to disruptive behavior, including bullying, cheating, trolling, and toxicity.\nPrevious research suggests toxicity is so deeply ingrained in competitive online video games that it has become normalized, with some players rationalizing it as an inherent part of the game culture [1], [2]. For instance, a recent study found that $86 \\%$ of players aged 18 to 45 report having experienced harassment while playing [3]. The incidence of toxic behavior in competitive online video games can be accounted for by their inherently competitive nature, amplified by the anonymity of online interactions [4]-[6]. Given these games' massive player bases, even a low rate of toxic behavior translates into thousands of daily incidents, exposing an even higher number of players to such behavior.\nThe undesirable effects of toxicity on player performance, psychological well-being, satisfaction, and retention are welldocumented [7]. For example, players who are frequently targeted by toxic behavior tend to report more symptoms of depression and problematic gaming habits [8], [9]. Furthermore, both victims and perpetrators tend to report heightened levels of anxiety and anger rumination. Marginalized groups, such as LGBTQ+ individuals, people of color, and women,\n\n[^0]are disproportionately affected by toxicity and its detrimental effects [10]-[16]. In esports, toxic behavior has been found to disrupt team coordination and morale, ultimately hindering players' in-game performance [1]. Lastly, it has been shown that toxicity contributes to player churn and deters new players from joining, suggesting that video game publishers have a vested interest in mitigating toxicity [17].\nIn addition to these first-order effects, there is a concern that toxic behavior can spread to other players, amplifying the consequences of a single player's misbehavior. Countless empirical studies, experimental and observational, have documented strong correlations and causal relationships between an individual's behavior and outcomes and those of their peers, a phenomenon known as \"peer effects\" [18]-[24]. This is equally true of virtuous and reprehensible behavior, including academic dishonesty, bullying, and delinquency. Some studies have specially considered peer effects in online interactions, including how a player's social network influences their performance in multiplayer video games [25]-[27].\nPeer effects can be theoretically justified through several mechanisms, one of which is conformity to social norms [28]. As inherently social beings, humans tend to avoid deviating from social norms. Accordingly, if toxicity is perceived as consistent with these norms, as suggested by its frequency and players' stated perceptions, players may feel compelled or encouraged to engage in such behavior. In this context, the actions of a single individual have the transformative power to redefine the norm, making behavior once considered unacceptable seem acceptable [29]. Therefore, it is plausible to expect toxicity to propagate, with one player's toxic behavior causing the exposed players to engage in similar behavior. Previous research has already provided correlational evidence in support of this conjecture [30], [31]. Relatedly, conformity (or lack thereof) has previously been recognized as a factor in why female and other \"out-group\" players may be targeted by toxic behavior [7], [13].\nUnderstanding how toxicity presumedly spreads is crucial for accurately appreciating its impact, as this impact mechanically grows with the extent to which it spreads to other players. This information is also valuable for developing effective strategies to address toxicity. To our knowledge, no study has yet quantified the causal relationship between a player's toxic behavior and that of their teammates. In this context, this paper seeks to assess whether and, if so, to what extent toxic behavior, specifically toxic speech, by a player causes their teammates to engage in similar behavior in competitive online video games.\nWe analyze proprietary data from the first-person action video game franchise Call of Duty\u00ae, published since 2003 by\n\n\n[^0]:    I. Morrier and R. M. Alvarez are with the Division of the Humanities and Social Sciences, California Institute of Technology, Mail Code 228-77, Pasadena, CA, 91125, USA (e-mail: jmorrier@caltech.edu; rma@hss.caltech.edu).\n    A. Mahmassani is with Activision\u00ae.\n\nActivision\u00ae. We focus on the free-to-play first-person action video game Call of Duty: Warzone ${ }^{\\mathrm{TM}}$ [32]. In its primary game mode, Battle Royale (BR), players compete to be the last player or team standing by eliminating all their opponents. Players can play alone, in pairs, or in squads of three or four players. Matches begin with players skydiving from an aircraft and landing on a large map within a limited time frame. Players start with minimal equipment and must search the map for weapons and gear scattered throughout, all while avoiding being eliminated by enemies. Players can also loot equipment from eliminated players. As the game progresses and more players are eliminated, the playable area shrinks, forcing survivors into smaller zones.\n\nSince 2023, Activision has partnered with Modulate ${ }^{\\mathrm{TM}}$, a start-up developing advanced voice technology to detect and mitigate online toxicity [33]. Activision has integrated Modulate's voice chat moderation technology, ToxMod ${ }^{\\mathrm{TM}}$, into its gaming platforms. ToxMod uses artificial intelligence and machine learning to detect toxic speech, including harassment, hate speech, and discriminatory remarks, in real-time [34]. This technology was rolled out in North America on August 30, 2023, within the games Call of Duty: Modern Warfare\u00aeII [35] and Call of Duty: Warzone ${ }^{\\mathrm{TM}}$, with initial support in English and plans to extend to additional languages. Our analysis is based on the data generated by ToxMod for all matches monitored between September 1 and October 31, 2023. A player is classified as having engaged in toxic speech in a game if ToxMod detected at least one instance of toxicity during it.\n\nEven with a large amount of high-quality data, analysts seeking to estimate the causal effect of toxic speech by a player on their teammates' probability of employing similar language face considerable statistical challenges. The reason is that some variables not controlled for in our regression modelsbecause they are unmeasured, for instance-may simultaneously influence whether players and their teammates engage in toxic speech. For example, teammates might concomitantly use toxic language in reaction to a random event occurring in a match. More fundamentally, players mutually influence each other. Consequently, whether a player and their teammates engage in toxicity is jointly determined. This obscures the cause-to-effect relationship of exposure to toxic speech and introduces biases in standard ordinary least squares (OLS) estimates.\n\nTo address this causal identification problem, we propose a novel identification strategy that takes advantage of the fact that we observe players in multiple matches with different teammates and the resulting network of interactions. By implementing an instrumental variable or two-stage least squares (2SLS) estimation strategy, we isolate variations in players' probability of engaging in toxic speech caused by interactions with teammates who, in other matches with other players, have employed toxic language more frequently and are therefore more likely to do so in the current game. This approach allows us to rigorously determine whether, and to what extent, a player's use of toxic speech causes variations in their teammates' probability of doing so. In and of itself, our identification strategy represents a significant contribution\nto the methodological literature on the causal identification of peer effects.\n\nWe perform our analysis on four sets of observations: (i) all observations from the BR Duos game mode, in which players compete in pairs; (ii) algorithmically matched pairs in BR Duos games; (iii) all observations in the BR Quads mode, in which players compete in four-member squads; and (iv) all observations from the BR Duos, Trios and Quads modes. Our findings confirm that toxicity is viral, with players having a significant causal effect on their teammates' likelihood of using toxic language. When all of a player's teammates engage in toxic speech, their probability of engaging in similar behavior rises by 2.91 to 7.57 percentage points (pp.). Depending on the context, this effect represents 26.1 to 30.3 times the average probability of a player using toxic language. These findings confirm the viral nature of toxicity, especially toxic speech, in competitive online video games.", "tables": {}, "images": {}}, {"section_id": 2, "text": "## II. Methodology\n\nThe following methodological explanation focuses on the BR Duos game mode, in which players compete in pairs. We then discuss extending this methodology to the BR Trios and Quads games modes, in which players participate in three- and four-member squads, respectively.\n\nFor reference, Table I contains the number of unique matches, unique players, and observations, along with the average probability that a player engages in toxic speech, for each of the four sets of observations on which we conduct our analysis. Our dataset does not contain personally identifiable information permitting the individual to whom the information applies to be reasonably inferred, nor any data on players' sex, gender, race, ethnicity, or other socially relevant groups. Caltech's Committee for the Protection of Human Subjects reviewed and approved our research design.", "tables": {}, "images": {}}, {"section_id": 3, "text": "## A. Model Specification\n\nWe wish to estimate the causal effect of a player employing toxic speech on their teammate's likelihood of exhibiting similar behavior. We define this effect as the change in a player's probability of engaging in toxic speech in the current match induced by their teammate engaging in toxic speech, holding all other factors constant.\n\nTo this end, we formulate the following structural model of players' behavior:\n\n$$\nY_{i j}=\\alpha_{j}+\\beta \\times Y_{i k}+\\varepsilon_{i j}\n$$\n\nIn this model, $Y_{i j}$ is a binary variable denoting whether player $j$ has engaged in toxic speech in match $i, \\alpha_{j}$ a playerspecific intercept reflecting player $j$ 's natural tendency to employ toxic language, and $\\varepsilon_{i j}$ an error term. We classify a player as having engaged in toxic speech during a match if ToxMod ${ }^{\\text {TM }}$ labeled at least one of their statements as toxic.\n\nThis model postulates that whether a player engages in toxic speech is determined by two factors: (i) their inherent predisposition toward such behavior, and (ii) whether their teammate engages in it. The coefficient $\\beta$ reflects the causal effect of a teammate engaging in toxic speech on a player's\n\nTABLE I\nDESCRIPTIVE STATISTICS\n\n![table_0](table_0)\n\nlikelihood of exhibiting similar behavior. This coefficient is our estimand.", "tables": {"table_0": "|  | Duos Mode | Duos Mode <br> Algorithmic Pairs | Quads Mode | All Modes |\n| :-- | :--: | :--: | :--: | :--: |\n| Number of Unique Matches | 244,182 | 240,367 | 303,360 | 605,664 |\n| Number of Unique Players | $1,038,893$ | 339,820 | $1,166,445$ | $1,963,084$ |\n| Number of Observations | $11,958,686$ | $2,264,728$ | $9,381,343$ | $19,131,444$ |\n| Average Probability of Toxic Speech (\\%) | 0.264 | 0.102 | 0.249 | 0.249 |"}, "images": {}}, {"section_id": 4, "text": "## B. Causal Identification Problem\n\nNaturally, one might contemplate estimating the coefficient $\\beta$ through OLS. However, contrary to standard assumptions in linear regression models, the model's equations are not exclusively linked through their error terms. The reason is that the dependent variable in some equations appears on the right-hand side of others. This entails that a player and their teammate mutually influence each other, and whether they each employ toxic speech is jointly determined. Consequently, the variable indicating whether one's teammate engages in toxic speech is endogenous, resulting in a causal identification problem.\n\nTo demonstrate this formally, we consider the pair formed by players $j$ and $k$ in match $i$. The two equations governing whether these players engage in toxic speech are defined as follows:\n\n$$\n\\begin{aligned}\n& Y_{i j}=\\alpha_{j}+\\beta \\times Y_{i k}+\\varepsilon_{i j} \\\\\n& Y_{i k}=\\alpha_{k}+\\beta \\times Y_{i j}+\\varepsilon_{i k}\n\\end{aligned}\n$$\n\nTo show that $Y_{i k}$ is correlated with $\\varepsilon_{i j}$, it suffices to incorporate the first equation into the second and isolate $Y_{i k}$ on the left-hand side:\n\n$$\n\\begin{aligned}\nY_{i k} & =\\alpha_{k}+\\beta \\times\\left(\\alpha_{j}+\\beta \\times Y_{i k}+\\varepsilon_{i j}\\right)+\\varepsilon_{i k} \\\\\n\\Leftrightarrow & \\left(1-\\beta^{2}\\right) \\times Y_{i k}=\\alpha_{k}+\\beta \\times\\left(\\alpha_{j}+\\varepsilon_{i j}\\right)+\\varepsilon_{i k} \\\\\n\\Leftrightarrow & Y_{i k}=\\frac{\\beta}{1-\\beta^{2}} \\times\\left(\\alpha_{j}+\\varepsilon_{i j}\\right)+\\frac{1}{1-\\beta^{2}} \\times\\left(\\alpha_{k}+\\varepsilon_{i k}\\right)\n\\end{aligned}\n$$\n\nThe last equation implies that the error term $\\varepsilon_{i j}$ implicitly enters the value of $Y_{i k}$, such that they are correlated. This means that OLS estimates do not only capture the effect of the teammate's toxic speech on a player's probability of engaging in such behavior but also its \"reflection,\" that is, the effect that player has on their teammate.\n\nOther challenges to the causal identification of peer effects include misspecification and self-selection. We discuss each in turn. First, our model may be incorrectly specified, as it may not contain variables governing players' probability of engaging in toxic speech. Some of these factors may equally influence whether a player and their teammate engage in toxicity. For example, two players in a team might engage in toxic behavior after observing one of their opponents doing so or in reaction to their actions. Formally, this may introduce a correlation between the error terms of two players, say,\nplayers $j$ and $k$, in the same team within a particular match, say, match $i$ :\n\n$$\n\\operatorname{corr}\\left(\\varepsilon_{i j}, \\varepsilon_{i k}\\right) \\neq 0\n$$\n\nSecond, players can endogenously choose their teammates by forming \"parties.\" Players may form parties for various reasons, including to engage intentionally in toxicity or in anticipation that their teammate will engage in such behavior. Also, when two players decide to play as a pair, it suggests a certain degree of familiarity between them. This familiarity can affect social dynamics between them. Formally, this may introduce a correlation between the error terms of two players across all matches in which they are paired:\n\n$$\n\\operatorname{corr}\\left(\\varepsilon_{i j}, \\varepsilon_{\\ell k}\\right) \\neq 0 \\text { for all matches } i, \\ell \\text { in which }\n$$\n\nplayers $j$ and $k$ are paired.", "tables": {}, "images": {}}, {"section_id": 5, "text": "## C. Identification Strategy\n\nTo address the causal identification problem described above, we formulate an identification strategy that leverages the fact that we observe players in multiple matches with different teammates. We propose to implement an instrumental variable or 2SLS estimation strategy. Concretely, we will use as an instrument of the variable indicating whether a player's teammate engaged in toxic speech the probability that they engage in such behavior in other matches in which they are teamed up with other players.\n\nFormally, our identification strategy consists of adding the following equation to our structural model of players' behavior:\n\n$$\nY_{i k}=\\delta_{j}+\\gamma \\times \\hat{Y}_{k,-j}+u_{i k}\n$$\n\nwhere $\\hat{Y}_{k,-j}$ equals the probability that player $k$ engages in toxic speech in all matches in which they are not paired with player $j$. This instrumental variable belongs to the general class of spatial or \"leave-one-out\" instruments used in empirical industrial organization for demand and supply estimation [36], [37]. In short, our identification strategy isolates variations in a player's probability of engaging in toxic speech resulting from being paired with a teammate who, in other matches played with other players, has a greater inclination to engage in such behavior.\n\nIn general, for an instrumental variable to be valid, it must satisfy two conditions: (i) relevance, meaning that the instrumental variables must be strongly correlated with the endogenous explanatory variables, and (ii) exclusion, meaning that the instrumental variables must be independent of the structural equation's error term. The validity of the first\n\nTABLE II\nFirst-Stage Estimation Results\n\n![table_1](table_1)\n\ncondition can be verified empirically by examining the firststage regression. As a rule of thumb, the $F$ statistic against the null hypothesis that the instrument is irrelevant in the firststage regressions should have a value greater than ten. Table II presents the coefficient associated with the instrumental variable, the $F$ statistic, and the number of observations for all first-stage regressions in our analysis. In each case, the $F$ statistic is substantially greater than ten, suggesting that we undoubtedly have a \"strong first stage.\"\n\nOn the other hand, the validity of the exclusion restriction cannot be empirically tested. Instead, it hinges on the assumptions we are willing to make regarding the relationship between the instrumental variables and the structural equation's error term. To show this, we consider the equation governing whether player $j$ engages in toxic behavior in match $i$, in which they are paired with player $k$ :\n\n$$\nY_{i j}=\\alpha_{j}+\\beta \\times Y_{i k}+\\varepsilon_{i j}\n$$\n\nThe corresponding first-stage equation is defined as follows:\n\n$$\nY_{i k}=\\delta_{j}+\\gamma \\times \\bar{Y}_{k,-j}+u_{i k}\n$$\n\nThe exclusion restriction demands that $\\bar{Y}_{k,-j}$ and $\\varepsilon_{i j}$ be independent of each other. The instrument $\\bar{Y}_{k,-j}$ equals the average value of the dependent variable in some of the other structural equations: those governing whether player $k$ engages in toxic speech in the matches in which they were not paired with player $j$. It follows that the corresponding error terms enter the value of our instrumental variable. Therefore, for our instrumental variable to satisfy the exclusion restriction, we must assume that these error terms are independent of $\\varepsilon_{i j}$. A sufficient condition for this is to presume that the error terms for two players in two matches in which they were not paired together are independent:\n\n$$\n\\begin{aligned}\n& \\varepsilon_{i j} \\Perp \\varepsilon_{\\ell k} \\text { for all matches } i, \\ell \\text { in which } \\\\\n& \\text { players } j \\text { and } k \\text { are paired. }\n\\end{aligned}\n$$\n\nIn interpreting our findings, we must recognize that our identification strategy yields an estimate of the local average treatment effect (LATE) for \"compliers\" [38]. Therefore, our estimates reflect the effect of teammates' toxic behavior on these specific players. In our context, the compliers are players whose teammates engaged in toxic behavior because they were more likely to behave that way in matches with others and, consequently, exogenously more likely to do so in the current game. This definition excludes players who intentionally use toxic language to provoke reactions from their teammates,\nfor example. If the effect of exposure to toxic language were heterogeneous, the LATE may not accurately reflect the average treatment effect for the entire player population.", "tables": {"table_1": "|  | Duos Mode | Duos Mode <br> Algorithmic Pairs | Quads Mode | All Modes |\n| :-- | :--: | :--: | :--: | :--: |\n| Estimate | 0.2200 | 0.2044 | 0.2575 | 0.1693 |\n| Standard Error | $(0.005)$ | $(0.009)$ | $(0.003)$ | $(0.003)$ |\n| $F$ Statistic | 1937.6 | 497.6 | 6855.3 | 1485.4 |\n| Number of Observations | $11,958,686$ | $2,264,728$ | $9,381,343$ | $19,131,444$ |"}, "images": {}}, {"section_id": 6, "text": "## D. Generalization to Battle Royale Trios and Quads Game Modes\n\nSo far, our description of the methodology has focused on the BR Duos game mode, in which each player has a single teammate. We now explain how to generalize this approach to game modes in which players have more than one teammate, specifically, the Trios and Quads game modes. In this case, our structural model of players' behavior is defined as follows:\n\n$$\nY_{i j}=\\alpha_{j}+\\beta \\times \\frac{\\sum_{k=1}^{K} Y_{i k}}{K}+\\varepsilon_{i j}\n$$\n\nIn this equation, $K$ represents the number of teammates player $j$ has. This model is a straightforward extension of the structural model defined above, in which the right-hand-side variable is the share of teammates who engage in toxic speech. In this equation, the coefficient $\\beta$ reflects the effect of all of a player's teammates using toxic language on their probability of engaging in similar behavior.\n\nThe generalized model suffers from a causal identification problem analogous to the one described above, requiring a similar identification strategy. We instrument the variable representing the share of a player's teammates who use toxic speech with the average probability that each engages in such behavior in other matches in which they are not paired with the player but may still be matched with each other. This instrument satisfies the exclusion restriction. We only consider observations for which we can compute the instrument's value for all a player's teammates since the model would be underspecified if we lacked the value of the instrumental variable for some teammates.", "tables": {}, "images": {}}, {"section_id": 7, "text": "## E. Estimation\n\nOur regression models include player-specific intercepts, formally called fixed effects, capturing the innate tendency of players to exhibit outcomes of interest. Estimation of these fixed effects is computationally expensive. Therefore, analysts frequently resort to \"down-sampling,\" which consists of sampling a computationally convenient number of observations and estimating the model with fixed effects only for those. This leads to a lower statistical accuracy. However, we do not need to compute them explicitly, especially since these fixed effects are not of primary interest to our analysis. The\n\nreason for including them in our model is to absorb timeinvariant variables that affect individual players' propensity to display the outcomes of interest. This is particularly important if there is a correlation between a player's inherent tendency to engage in toxic speech and their teammates'. Instead of explicitly estimating fixed effects, we can achieve the same end by demeaning the values of the dependent, independent, and instrumental variables for all players at the individual level [39]. After doing so, we can estimate the coefficients $\\beta$ through the standard 2SLS estimation procedure.\n\nWe restrict our analysis to observations for which the following two conditions are met: (i) we observe the teammate play at least one match with another player so that we can compute the instrument's value, and (ii) we observe the player participate in at least two matches so that we can demean the values of the dependent, independent, and instrumental variables for that player. These restrictions lead to some minor attrition.", "tables": {}, "images": {}}, {"section_id": 8, "text": "## III. RESULTS\n\nTable III presents estimation results for all four sets of observations described above. The table presents the estimated values of the coefficients reflecting the causal effect of all a player's teammates engaging in toxic speech on that player's probability of engaging in such behavior, along with their heteroskedasticity-robust standard errors. To provide readers with a sense of this effect's relative magnitude, we also express the value of the coefficients as a multiple of the average probability that players use toxic speech. Finally, for comparison, we present OLS estimates, which lack a causal interpretation, along with those of our 2SLS estimation strategy, to which we ascribe a causal interpretation.\n\nIn the BR Duos mode, our analysis reveals that when a player's teammate engages in toxic speech, it causes a 7.37 pp. increase in the probability that the player also exhibits such behavior. This effect equals 29.6 times the average likelihood of a player engaging in toxic speech. This means that, all else equal, a player whose teammate engages in toxic speech is 29.6 more likely to engage in such behavior than the average player. This effect is statistically significant at the $99 \\%$ confidence level. OLS estimates suggest that the probability of a player engaging in toxic speech is 3.75 pp . higher when their teammate does, a magnitude roughly half that of the estimated causal effect.\n\nFor the algorithmically matched pairs in the BR Duos game mode, our analysis indicates that when their teammate engages in toxic speech, it causes a 2.91 pp . increase in the probability that a player exhibits such behavior. This effect equals 28.6 times the average likelihood of a player engaging in toxic speech. This effect is statistically significant at the $95 \\%$ confidence level. In comparison, OLS estimates suggest that the probability of a player engaging in toxic speech is 1.85 pp. higher when their teammate does, a magnitude roughly half that of the estimated causal effect.\n\nIn the BR Quads mode, our analysis indicates that all their teammates indulging in toxic speech causes a 6.5 pp . increase\nin the probability that a player engages in such behavior. ${ }^{1}$ This effect equals 26.1 times the average likelihood of a player engaging in toxic speech. This effect is statistically significant at the $99 \\%$ confidence level. In comparison, OLS estimates suggest that the probability of a player engaging in toxic speech is 5.96 pp . higher when all their teammate does, which is close but still lower than the estimated causal effect.\n\nFor all BR game modes pooled together, our findings indicate that when all their teammates engage in toxic speech, it causally increases by 7.57 pp . the probability that a player participates in such behavior. This effect equals 30.3 times the average likelihood of a player engaging in toxic speech. This effect is statistically significant at the $99 \\%$ confidence level. OLS estimates suggest that the probability of a player engaging in toxic speech is 4.20 pp . higher when all their teammate does, which is slightly more than half the magnitude of the causal effect.", "tables": {}, "images": {}}, {"section_id": 9, "text": "## IV. DiscuSSION AND CONCLUSION\n\nOur analysis reveals that all else equal when a player's teammates engage in toxic speech, it increases the player's probability of exhibiting similar behavior by 26.1 to 30.3 times the average player's likelihood of engaging in toxic speech. This implies that toxic behavior spreads among teammates, amplifying the effects of a single player's misconduct. These findings underscore the viral nature of toxicity, particularly toxic speech, in competitive online video games.\n\nThe overall effect exerted by a player's teammates on their probability of engaging in toxic speech is consistent across the BR Duos and Quads game modes. This implies that the causal effect of a single teammate engaging in toxic speech is lower in the Quads game mode compared to the Duos mode. In other words, the presence of more teammates diminishes the influence of a single teammate engaging in toxic speech. This is plausible since a player has an inherently lower probability of interacting with any specific teammate when they have many, as in the Quads game mode, compared to when they only have one, as in the Duos game mode.\n\nOur findings also suggest that the endogeneity induced by the reflection problem is less pronounced in the Quads game mode, as evidenced by the smaller gap between OLS and 2SLS estimates compared to the Duos mode. This is also sensible, considering that the effect of a single teammate participating in toxic speech is lower in the Quads game mode, and the likelihood of any two teammates interacting decreases as team size grows. As a result, the \"reflection\" of one teammate's effect on a player's likelihood of engaging in toxic speech is lower, resulting in less endogeneity.\n\nWhile we cited conformity as the primary justification for peer effects, they may also be driven by homophily. Homophily is characterized by players' tendency to assemble teams with others sharing a similar inclination for engaging in toxic speech or with whom they intend to engage in such behavior [40]. Similar to how the reflection problem makes it\n\n[^0]\n[^0]:    ${ }^{1}$ The causal effect of a single teammate using toxic language can be computed by multiplying the coefficient by the portion of teammates it represents, that is, by one-third.\n\nTABLE III\nEstimates of the Effect of Teammates' Toxic Speech on a Player's Probability of Employing Similar Language\n\n![table_2](table_2)\n\nmore likely that players engage concurrently in toxic behavior, homophily increases the probability of players concurrently engaging in toxicity.\n\nOur model includes fixed effects to control for the innate inclination of players and their teammates towards toxic speech. Therefore, our estimates reflect how much more likely than average a player is to use toxic language when paired with teammates who are exogenously more prone to such behavior than their average teammate. Additionally, our instrumental variable estimation strategy is designed to neutralize the effect of players intentionally forming teams to engage in toxic behavior. Nonetheless, to address potential apprehensions about our estimates being inadvertently influenced by the endogenous formation of teams, we can leverage the distinction between players who joined a match in endogenously formed \"parties\" and those who joined alone and were algorithmically matched with a teammate. Specifically, we estimated peer effects using the subset of algorithmically matched pairs in the Duos game mode. While the absolute magnitude of peer effects in algorithmically matched pairs is lower compared to that of all Duos, these effects' magnitude relative to the average probability that a player in an algorithmically matched pair engages in toxic speech is the same as that observed across all observations in the Duos game mode. This implies that the magnitude of estimated peer effects is unaltered by homophily.\n\nOur work expands on and contributes to the literature on toxicity in competitive online video games by uncovering its viral nature. Rather than relying on survey data, as many studies have done, we take a distinct yet complementary approach, focusing on observational causal inference with gameplay data. This approach mitigates the various biases associated with players' self-reported behavior and perceptions, though it introduces greater analytical complexity. We formulate an estimation strategy to measure the causal effects of exposure to toxicity. This approach could be applied to further document the effects of toxicity on player performance [1], retention [17], and other key outcomes, thereby strengthening previous research in this area.\n\nAdmittedly, our analysis does not account for whether players were exposed to toxic speech. Instead, we consider how teammates engaging in toxic speech affects a player's behavior, irrespective of whether that player was exposed to that speech. However, if a player's audio chat is disabled, they cannot hear their teammates' toxic speech. In this case, it cannot plausibly affect their behavior. On the whole, this results in conservative estimates because the effect of direct\nexposure to toxic speech is necessarily greater than the effect of teammates simply engaging in toxic speech, as the latter is a prerequisite for the former. In econometric terms, our estimates can be interpreted as reflecting the effect of the \"intent to treat,\" where the treatment is exposure to toxicity, rather than the effect of the treatment itself.\n\nIn conclusion, we suggest that future research investigate in priority how the spread of toxic speech to a player's teammates varies across different contexts. Understanding these differences would be invaluable, as it would allow resources to be allocated to the contexts where the virality of toxicity and, by extension, its adverse effects are the most pronounced. Exploring forms of toxicity beyond language and speech also offers a compelling direction for future research.", "tables": {"table_2": "|  | Duos Mode |  | Duos Mode <br> Algorithmic Pairs |  | Quads Mode |  | All Modes |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  | OLS | 2SLS | OLS | 2SLS | OLS | 2SLS | OLS | 2SLS |\n| Estimate <br> Standard Error | $\\begin{gathered} 0.0375 \\\\ (0.001) \\end{gathered}$ | $\\begin{gathered} 0.0737 \\\\ (0.0211) \\end{gathered}$ | $\\begin{gathered} 0.0185 \\\\ (0.003) \\end{gathered}$ | $\\begin{gathered} 0.0291 \\\\ (0.0118) \\end{gathered}$ | $\\begin{gathered} 0.0596 \\\\ (0.002) \\end{gathered}$ | $\\begin{gathered} 0.0650 \\\\ (0.0091) \\end{gathered}$ | $\\begin{gathered} 0.0420 \\\\ (0.001) \\end{gathered}$ | $\\begin{gathered} 0.0757 \\\\ (0.0088) \\end{gathered}$ |\n| Multiple of Average Probability of Toxic Speech | 14.2 | 29.6 | 18.2 | 28.6 | 23.9 | 26.1 | 16.9 | 30.3 |"}, "images": {}}, {"section_id": 10, "text": "## ACKNOWLEDGMENT\n\nThe authors thank Andrea Boonyarungsrit, Grant Cahill, MJ Kim, Rafal Kocielnik, Jonathan Lane, Zhuofang Li, Gary Quan, Deshawn Sambrano, Feri Soltani, Carly Taylor, and Michael Vance for their assistance and support in preparing this article. The opinions expressed by the authors do not represent the views of Activision\u00ae.", "tables": {}, "images": {}}, {"section_id": 11, "text": "## REFERENCES\n\n[1] S. T\u00fcrkay, J. Formosa, S. Adinolf, R. Cathbert, and R. Altizer, \"See No Evil, Hear No Evil, Speak No Evil: How Collegiate Players Define, Experience and Cope with Toxicity,\" in Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 2020, pp. 1-13.\n[2] N. A. Beres, J. Frommel, E. Reid, R. L. Mandryk, and M. Klarkowski, \"Don't You Know That You're Toxic: Normalization of Toxicity in Online Gaming,\" in Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, 2021, pp. 1-15.\n[3] ADL Center for Technology and Society, \"Hate Is No Game: Hate and Harassment in Online Games,\" 2022. [Online]. Available: https://www.adl.org/sites/default/files/documents/ 2022-12/Hate-and-Harassment-in-Online-Games-120622-v2.pdf\n[4] N. Lapidot-Leffer and A. Barak, \"Effects of anonymity, invisibility, and lack of eye-contact on toxic online disinhibition,\" Computers in Human Behavior, vol. 28, no. 2, pp. 434-443, 2012.\n[5] S. Adinolf and S. Turkay, \"Toxic Behaviors in Exports Games: Player Perceptions and Coping Strategies,\" in Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts, 2018, pp. 365-372.\n[6] S. J. Lee, E. J. Jeong, and J. H. Jeon, \"Disruptive behaviors in online games: Effects of moral positioning, competitive motivation, and aggression in League of Legends,\" Social Behavior and Personality: an international journal, vol. 47, no. 2, pp. 1-9, 2019.\n[7] H. Kwak, J. Blackburn, and S. Han, \"Exploring Cyberbullying and Other Toxic Behavior in Team Competition Online Games,\" in Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, 2015, pp. 3739-3748.\n\n[8] S. Caplan, D. Williams, and N. Yee, \"Problematic Internet use and psychosocial well-being among MMO players,\" Computers in Human Behavior, vol. 25, no. 6, pp. 1312-1319, 2009.\n[9] A. Zsila, R. Shabahang, M. S. Araguete, and G. Orosz, \"Toxic behaviors in online multiplayer games: Prevalence, perception, risk factors of victimization, and psychological consequences,\" Aggressive Behavior, vol. 48, no. 3, pp. 356-364, 2022.\n[10] K. L. Gray, \"Deviant bodies, stigmatized identities, and racist acts: examining the experiences of African-American gamers in Xbox Live,\" New Review of Hypermedia and Multimedia, vol. 18, no. 4, pp. 261-276, 2012.\n[11] A. Salter and B. Blodgett, \"Hypermasculinity \\& Dickwolves: The Contentious Role of Women in the New Gaming Public,\" Journal of Broadcasting \\& Electronic Media, vol. 56, no. 3, pp. 401-416, 2012.\n[12] J. H. Kuznekoff and L. M. Rose, \"Communication in multiplayer gaming: Examining player responses to gender cues,\" New Media \\& Society, vol. 15, no. 4, pp. 541-556, 2013.\n[13] J. Fox and W. Y. Tang, \"Sexism in online video games: The role of conformity to masculine norms and social dominance orientation,\" Computers in Human Behavior, vol. 33, pp. 314-320, 2014.\n[14] S. Chess and A. Shaw, \"A Conspiracy of Fishes, or, How We Learned to Stop Worrying About \\#GamerGate and Embrace Hegemonic Masculinity,\" Journal of Broadcasting \\& Electronic Media, vol. 59, no. 1, pp. 208-220, 2015.\n[15] M. E. Ballard and K. M. Welch, \"Virtual Warfare: Cyberbullying and Cyber-Victimization in MMOG Play,\" Games and Culture, vol. 12, no. 5, pp. 466-491, 2017.\n[16] D. Madden, Y. Liu, H. Yu, M. F. Sonbudak, G. M. Troiano, and C. Harteveld, \"\"Why Are You Playing Games? You Are a Girl!: Exploring Gender Biases in Esports,\" in Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, 2021.\n[17] R. Kowert and E. Kilmer, \"Toxic Gamers are Alienating Your Core Demographic: The Business Case for Community Management,\" 2023. [Online]. Available: https://www.takethis.org/wp-content/uploads/2023/ 08/ToxicGamersBottomLineReport_TakeThis.pdf\n[18] C. F. Manski, \"Economic Analysis of Social Interactions,\" Journal of Economic Perspectives, vol. 14, no. 3, pp. 115-136, 2000.\n[19] C. Alexander, M. Piazza, D. Mekos, and T. Valente, \"Peers, schools, and adolescent cigarette smoking,\" Journal of Adolescent Health, vol. 29, no. 1, pp. 22-30, 2001.\n[20] C. Salmivalli, \"Bullying and the peer group: A review,\" Aggression and Violent Behavior, vol. 15, no. 2, pp. 112-120, 2010.\n[21] D. Epple and R. E. Romano, \"Peer Effects in Education: A Survey of the Theory and Evidence,\" in Handbook of Social Economics, J. Benhabib, A. Bisin, and M. O. Jackson, Eds., 2011, vol. 1, pp. 1053-1163.\n[22] D. A. Kreager, K. Rulison, and J. Moody, \"Delinquency and the Structure of Adolescent Peer Groups,\" Criminology, vol. 49, no. 1, pp. 95-127, 2011.\n[23] B. Sacerdote, \"Peer Effects in Education: How Might They Work, How Big Are They and How Much Do We Know Thus Far?\" in Handbook of the Economics of Education, E. A. Hanushek, S. Machin, and L. Woessmann, Eds., 2011, vol. 3, pp. 249-277.\n[24] B. S. Graham, \"Identifying and Estimating Neighborhood Effects,\" Journal of Economic Literature, vol. 56, no. 2, pp. 450-500, 2018.\n[25] C. Shen, P. Monge, and D. Williams, \"Virtual Brokerage and Closure: Network Structure and Social Capital in a Massively Multiplayer Online Game,\" Communication Research, vol. 41, no. 4, pp. 459-480, 2014.\n[26] Y. Wang, P. Goes, Z. Wei, and D. Zeng, \"Production of Online Word-of-Mouth: Peer Effects and the Moderation of User Characteristics,\" Production and Operations Management, vol. 28, no. 7, pp. 1621-1640, 2019.\n[27] D. Goetz and W. Lu, \"Peer Effects from Friends and Strangers: Evidence from Random Matchmaking in an Online Game,\" in Proceedings of the 23rd ACM Conference on Economics and Computation, 2022.\n[28] J. Henrich and R. Boyd, \"The Evolution of Conformist Transmission and the Emergence of Between-Group Differences,\" Evolution and Human Behavior, vol. 19, no. 4, pp. 215-241, 1998.\n[29] N. A. Beres, J. Frommel, E. Reid, R. L. Mandryk, and M. Klarkowski, \"Don't You Know That You're Toxic: Normalization of Toxicity in Online Gaming,\" in Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, 2021.\n[30] C. Shen, Q. Sun, T. Kim, G. Wolff, R. Ratan, and D. Williams, \"Viral vitriol: Predictors and contagion of online toxicity in World of Tanks,\" Computers in Human Behavior, vol. 108, pp. 1-9, 2020.\n[31] B. Kordyaka, S. Laato, K. Jahn, J. Hamari, and B. Niehaves, \"The Cycle of Toxicity: Exploring Relationships between Personality and Player Roles in Toxic Behavior in Multiplayer Online Battle Arena Games,\"\n\nProceedings of the ACM on Human-Computer Interaction, vol. 7, no. CHI PLAY, pp. 611-641, 2023.\n[32] Infinity Ward and Raven Software, \"Call of Duty\u00ae: Warzone ${ }^{\\text {TM }}$,\" Game, 2022, Activision.\n[33] Activision Publishing, \"Call of Duty Takes Aim at Voice Chat Toxicity, Details Year-to-Date Moderation Progress,\" 2023. [Online]. Available: https://www.callofduty.com/blog/2023/08/call-of-duty-modern-warfare-warzone-anti-toxicity-progress-report\n[34] R. Kowert and L. Woodwell, \"Moderation challenges in digital gaming spaces: Prevalence of offensive behaviors in voice chat,\" 2022. [Online]. Available: https://www.takethis.org/wp-content/uploads/2022/ 12/takethismodulatereport.pdf\n[35] Infinity Ward, \"Call of Duty\u00ae: Modern Warfare\u00aeII,\" Game, 2022, Activision.\n[36] J. A. Hausman, \"Valuation of New Goods under Perfect and Imperfect Competition,\" in The Economics of New Goods, T. F. Bresnahan and R. J. Gordon, Eds. University of Chicago Press, 1996, pp. 207-248.\n[37] A. Nevo, \"Measuring Market Power in the Ready-to-Eat Cereal Industry,\" Econometrica, vol. 69, no. 2, pp. 307-342, 2001.\n[38] J. M. Wooldridge, Econometric Analysis of Cross Section and Panel Data, 2nd ed. The MIT Press, 2010.\n[39] W. H. Greene, Econometric Analysis, 8th ed. Prentice Hall, 2018.\n[40] L. Charroin, B. Fortin, and M. C. Villeval, \"Peer effects, self-selection and dishonesty,\" Journal of Economic Behavior and Organization, vol. 200, pp. 618-637, 2022.", "tables": {}, "images": {}}], "id": "2410.00978v2", "authors": ["Jacob Morrier", "Amine Mahmassani", "R. Michael Alvarez"], "categories": ["cs.HC", "econ.GN", "q-fin.EC"], "abstract": "Toxicity is a widespread phenomenon in competitive online video games. In\naddition to its direct undesirable effects, there is a concern that toxicity\ncan spread to others, amplifying the harm caused by a single player's\nmisbehavior. In this study, we estimate whether and to what extent a player's\ntoxic speech spreads, causing their teammates to behave similarly. To this end,\nwe analyze proprietary data from the free-to-play first-person action game Call\nof Duty: Warzone. We formulate and implement an instrumental variable\nidentification strategy that leverages the network of interactions among\nplayers across matches. Our analysis reveals that all else equal, all of a\nplayer's teammates engaging in toxic speech increases their probability of\nengaging in similar behavior by 26.1 to 30.3 times the average player's\nlikelihood of engaging in toxic speech. These findings confirm the viral nature\nof toxicity, especially toxic speech, in competitive online video games.", "updated": "2025-01-31T23:38:29Z", "published": "2024-10-01T18:07:06Z"}