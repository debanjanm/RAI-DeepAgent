{"title": "Large Deviations for Stochastic Evolution Equations in the Critical\n  Variational Setting", "sections": [{"section_id": 0, "text": "#### Abstract\n\nUsing the weak convergence approach, we prove the large deviation principle (LDP) for solutions to quasilinear stochastic evolution equations with small Gaussian noise in the critical variational setting, a recently developed general variational framework. No additional assumptions are made apart from those required for well-posedness. In particular, no monotonicity is required, nor a compact embedding in the Gelfand triple. Moreover, we allow for flexible growth of the diffusion coefficient, including gradient noise. This leads to numerous applications for which the LDP was not established yet, in particular equations on unbounded domains with gradient noise. Since our framework includes the 2D Navier-Stokes and Boussinesq equations with gradient noise and unbounded domains, our results resolve an open problem that has remained unsolved for over 15 years.", "tables": {}, "images": {}}, {"section_id": 1, "text": "## CONTENTS\n\n1. Introduction ..... 1\nNotation ..... 3\n2. Main result ..... 4\n2.1. The critical variational setting ..... 4\n2.2. Statement of the main result ..... 6\n3. Well-posedness of the skeleton equation ..... 7\n3.1. Linearized skeleton equation ..... 7\n3.2. Local well-posedness ..... 11\n3.3. Global well-posedness ..... 18\n4. Proof of the large deviation principle ..... 20\n4.1. Weak convergence approach ..... 20\n4.2. Weakly continuous dependence in the skeleton equation ..... 23\n4.3. Stochastic continuity criterion ..... 28\n4.4. Proof of Theorem 2.6 ..... 32\n5. Application to fluid dynamics ..... 33\n5.1. Abstract model ..... 33\n5.2. LDP for Navier-Stokes equations with gradient noise ..... 34\nAppendix A. ..... 35\nReferences ..... 36", "tables": {}, "images": {}}, {"section_id": 2, "text": "## 1. InTRODUCTION\n\nIn this paper we study large deviations for solutions to small-noise stochastic evolution equations of the form\n\n$$\n\\mathrm{d} Y^{\\varepsilon}(t)=-A\\left(t, Y^{\\varepsilon}(t)\\right) \\mathrm{d} t+\\sqrt{\\varepsilon} B\\left(t, Y^{\\varepsilon}(t)\\right) \\mathrm{d} W(t)\n$$\n\n[^0]\n[^0]:    Date: April 18, 2025.\n    2010 Mathematics Subject Classification. Primary: 60H15, Secondary: 60F10, 35K59, 35K90, 35R60, 47J35.\n    Key words and phrases. Large deviation principle, variational methods, stochastic evolution equations, stochastic partial differential equations, quasi- and semilinear, critical nonlinearities.\n\n    The authors are supported by the VICI subsidy VLC.212.027 of the Netherlands Organisation for Scientific Research (NWO).\n\nin the new variational framework of [6] by Agresti and the second author. This framework, the critical variational setting, has been developed to extend the classical variational approach to stochastic evolution equations originating from [8], [34], [26]. In the classical variational approach, the drift and diffusion coefficients $A$ and $B$ need to satisfy several conditions to ensure wellposedness of (1.1). The usual weak monotonicity condition is especially restrictive. It is therefore no surprise that efforts have been made to weaken the monotonicity condition, e.g. in [29, \u00a75.2] and very recently [41] with a much weaker local monotonicity condition. One of the advantages of the critical variational setting of [6] used in this paper, is that no form of monotonicity is assumed. In return, $A$ and $B$ are of a slightly less (but still very) general form:\n\n$$\nA(t, v)=A_{0}(t, v) v-F(t, v)+f(t), \\quad B(t, v)=B_{0}(t, v) v+G(t, v)+g(t)\n$$\n\nfor $t \\in \\mathbb{R}_{+}$and $v \\in V$, where $\\left(V, H, V^{*}\\right)$ is a Gelfand triple belonging to the stochastic evolution equation. That is, $(A, B)$ contains a quasilinear part $\\left(A_{0}, B_{0}\\right)$ and a semilinear part $(F, G)$ and it is assumed that both parts satisfy certain critical local Lipschitz conditions, where the Lipschitz constant may depend arbitrarily on $\\|v\\|_{H}$ and, allowing even more flexibility, polynomially on interpolation norms $\\|v\\|_{V_{\\beta}}$, where $V_{\\beta}=\\left[V^{*}, V\\right]_{\\beta}$ denotes the complex interpolation space. Besides the absence of any monotonicity assumption, another major improvement of the critical variational setting is the weakening of the usual growth conditions on the diffusion coefficient $B$, allowing e.g. for gradient noise. Lastly, a special feature is that critical nonlinearities are allowed (see (2.6)), which is not the case in other settings. The critical variational setting covers many semilinear and some quasilinear equations that were not covered by more classical variational settings. In particular, this holds for many equations that require an (analytically) strong setting, in which monotonicity often fails, for example the Cahn-Hilliard equation, the tamed Navier-Stokes equations and the Allen-Cahn equation. See $[6, \\S 5]$ for details. The exact assumptions in the critical variational setting can be found in Section 2. Finally, it should be stressed that unlike the settings in [41], the critical variational setting does not require a compact (Sobolev) embedding $V \\hookrightarrow H$ and is thus suited to treat equations on unbounded spatial domains.\n\nThe goal of this paper is to establish the LDP for solutions to small-noise stochastic evolution equations in the critical variational setting. Large deviations have been studied for SPDEs in many different frameworks. The first results for SPDEs were inspired by the pioneering paper for SDEs by Freidlin and Wentzell [18] (see also [14, \u00a75.6]), relying on discretizations and the contraction principle. These techniques were extended to several SPDE settings with Gaussian noise, notably in [13], [35], [10] (stochastic reaction-diffusion equations), [11] (semilinear parabolic equations) and [42] (stochastic porous media equations). However, for less regular $A$ and $B$ such techniques are difficult to use in general settings. In 2001, Budhiraja and Dupuis proved a substantially generalized contraction principle, the so-called weak convergence approach to large deviations [9]. This approach turned out to be extremely powerful for SPDEs and subsequently, it was applied to many SPDEs with less regular coefficients, e.g. in [45], [12] (2D Navier-Stokes and hydrodynamical models), [15] (Boussinesq equations), as well as [39] and [28] (general classical variational settings). A more detailed discussion on applications to fluid dynamics can be found below.\n\nAlso for the recent variational settings with even weaker conditions on the coefficients $A$ and $B$, the weak convergence approach has led to new LDP proofs. In [20] the LDP is obtained for McKean-Vlasov quasilinear stochastic evolution equations, in [32] for a setting from [41], in [27] for the same setting extended to L\u00e9vy noise, and most recently, [33] obtained the LDP for the strongest setting of [41]. The latter allows flexible growth bounds on $B$, including gradient noise. Still, the combination of flexible growth of $B$ and unbounded spatial domains (that is, no compact embedding $V \\hookrightarrow H$ ) has not been covered in any of the papers so far. The main improvement of our work is that we allow for both. In fact, no additional bounds on $A$ and $B$ are assumed for the LDP apart from those in [6] required for well-posedness, nor do we assume a compact embedding in the Gelfand triple. New techniques are used to replace the usual compactness arguments. The paper contains new approaches for\n\n- well-posedness of the skeleton equation and compact sublevel sets of the rate function in the LDP, by means of maximal regularity theory and a strong approximation argument,\n\n- the stochastic continuity criterion from the weak convergence approach, using critical estimates for the nonlinearities and an effective combination of deterministic and stochastic Gronwall inequalities.\nThe LDP result in this paper opens up many new applications. In particular, the following examples are included on bounded and unbounded domains in $\\mathbb{R}^{d}$ and with gradient noise:\n- Navier-Stokes equations for $d=2$ [5, App. A],\n- tamed Navier-Stokes equations for $d=3$ [6, \u00a75.2],\n- Cahn-Hilliard equation for $d=1,2[6, \\S 5.1]$,\n- Swift-Hohenberg equations for $d=1,2,3[6, \\S 5.6]$,\n- many reaction-diffusion equations, e.g. for $d \\leq 4$ :\n- Allen-Cahn equations [6, \u00a75.4],\n- symbiotic Lotka-Volterra equations [4, Th. 3.11],\n- coagulation equations [4, Th. 3.9].\n\nThis list is far from extensive.\nTo make our results concrete for some of the models discussed above, we present a detailed application to fluid dynamics in Subsection 5. We focus on models with gradient noise and do not assume that the underlying domain is bounded; consequently, compactness results based on Sobolev embeddings are not available. In $[12,15]$, an abstract framework is introduced that encompasses, in particular, the 2D Navier-Stokes and Boussinesq equations. Within this framework, well-posedness is established in full generality. To prove the large deviation principle, the authors adopt the weak convergence method. They identify a gap in earlier papers on large deviations for the 2D Navier-Stokes equations - specifically, in the compactness argument for the sublevel sets of the associated skeleton equations. The authors resolve this gap under the assumption that the gradient noise vanishes, but the general gradient noise case has remained open since then. We solve this problem in Theorems 5.2 and 5.4.\n\nAnother application that we would like to highlight are the 3D tamed Navier-Stokes equations, for which a large deviation principle was established in [43]. However, gradient noise was not considered in that work, and it is far from straightforward to extend their approach to settings where such noise is present. Our main result, Theorem 2.6, now covers the gradient noise case and also applies to a broad class of other models (see the list above).\n\nClosing the above indicated gap requires several intricate approximation techniques, which are detailed in Subsection 4.2. Furthermore, in the full abstract setting, the stochastic continuity criterion also necessitates new ideas, which we develop in Subsection 4.3.\n\nAcknowledgement. The authors thank Antonio Agresti and Sebastian Bechtel for their helpful comments.\n\nNotation. We let $\\mathbb{R}_{+}:=[0, \\infty)$. For $T>0$ and a normed space $X$ we let $C([0, T] ; X)$ denote the space of continuous functions from $[0, T]$ to $X$ equipped with supremum norm $\\|f\\|_{C([0, T] ; X)}:=$ $\\sup _{t \\in[0, T]}\\|f(t)\\|_{X}$. For $(S, \\mathcal{A}, \\mu)$ a measure space, we denote by $L^{0}(S ; X)$ the space of strongly measurable functions $f: S \\rightarrow X$, with identification of a.e. equal functions. For $p \\in(0, \\infty]$, we let $L^{p}(S ; X)$ denote the subset consisting of all $f \\in L^{0}(S ; X)$ for which $\\|f\\|_{L^{p}(S ; X)}<\\infty$, where\n\n$$\n\\|f\\|_{L^{p}(S ; X)}:= \\begin{cases}\\left(\\int_{S}\\|f(s)\\|_{X}^{p} \\mathrm{~d} \\mu(s)\\right)^{\\frac{1}{p}}, & p<\\infty \\\\ \\operatorname{csssup}_{s \\in S}\\|f(s)\\|_{X}, & p=\\infty\\end{cases}\n$$\n\nWe write $L^{p}(S):=L^{p}(S ; \\mathbb{R})$ and if $S=[0, T] \\subset \\mathbb{R}$, we write $L^{p}(0, T ; X):=L^{p}(S ; X)$. Moreover, we let $L_{\\text {loc }}^{p}\\left(\\mathbb{R}_{+} ; X\\right):=\\left\\{u: \\mathbb{R}_{+} \\rightarrow X: u \\mid[0, T] \\in L^{2}(0, T ; X)\\right.$ for all $\\left.T \\in \\mathbb{R}_{+}\\right\\}$.\n\nFor Hilbert spaces $U$ and $H$ we let $\\mathcal{L}(U, H)$ and $\\mathcal{L}_{2}(U, H)$ denote the continuous linear operators and Hilbert-Schmidt operators from $U$ to $H$, respectively. For brevity, we write\n\n$$\n\\|\\cdot\\|_{H}:=\\|\\cdot\\|_{\\mathcal{L}_{2}(U, H)}\n$$\n\nFurthermore, we denote the dual of a Hilbert space $V$ by $V^{*}$ and for $\\beta \\in(0,1)$, we denote the complex interpolation space at $\\beta$ by\n\n$$\nV_{\\beta}:=\\left[V^{*}, V\\right]_{\\beta}, \\quad\\|\\cdot\\|_{\\beta}:=\\|\\cdot\\|_{V_{\\beta}}\n$$\n\nFor a metric space $M$ we denote its Borel $\\sigma$-algebra by $\\mathcal{B}(M)$. The unique product measure space of two $\\sigma$-finite measure spaces $\\left(S_{1}, \\mathcal{A}_{1}, \\mu_{1}\\right)$ and $\\left(S_{2}, \\mathcal{A}_{2}, \\mu_{2}\\right)$ is denoted by $\\left(S_{1} \\times S_{2}, \\mathcal{A}_{1} \\otimes\\right.$ $\\left.\\mathcal{A}_{2}, \\mu_{1} \\otimes \\mu_{2}\\right)$. Let $I=[0, T]$ or $I=\\mathbb{R}_{+}$and let $X$ be a Banach space. A process $(\\Phi(t))_{t \\in I}$ is a strongly measurable function $\\Phi: I \\times \\Omega \\rightarrow X$. It is called strongly progressively measurable if for every $t \\in I, \\Phi \\mid_{[0, t] \\times \\Omega}$ is strongly $\\mathcal{B}([0, t]) \\otimes \\mathcal{F}_{t}$-measurable. For $I=\\mathbb{R}_{+}$, we denote the $\\sigma$-algebra generated by the strongly progressively measurable processes by $\\mathcal{P}$.\n\nWe write $a \\vee b:=\\max (a, b)$ and $a \\wedge b:=\\min (a, b)$ for $a, b \\in \\mathbb{R}$.", "tables": {}, "images": {}}, {"section_id": 3, "text": "# 2. Main Result \n\nWe specify our setting for stochastic evolution equations and recall the definition of the large deviation principle before we state our main result, Theorem 2.6.\n2.1. The critical variational setting. We let $\\left(V, H, V^{*}\\right)$ be a Gelfand triple of real Hilbert spaces. That is, $\\left(V,(\\cdot, \\cdot)_{V}\\right)$ and $\\left(H,(\\cdot, \\cdot)_{H}\\right)$ are real Hilbert spaces such that there exists a continuous and dense embedding $\\iota: V \\hookrightarrow H$. Then, $j: H \\hookrightarrow V^{*}: x \\mapsto(x, \\iota(\\cdot))_{H}$ is a continuous embedding and $j(H)$ is dense in $V^{*}$ by reflexivity of $V\\left(j=\\iota^{*}\\right.$ under Riesz' identification $\\left.H \\cong H^{*}\\right)$. From now on we identify $x \\in V$ with $\\iota(x) \\in H$ and $x \\in H$ with $j(x) \\in V^{*}$. Then, if $\\langle\\cdot, \\cdot\\rangle$ denotes the duality pairing between the abstract dual $V^{*}$ and $V$, one has\n\n$$\n\\langle x, v\\rangle=(v, x)_{H} \\quad \\text { for all } x \\in H, v \\in V\n$$\n\nFor convenience of the reader, we recall that in applications, one does not work with the abstract dual $V^{*}$ but with a space $V^{\\prime}$ which, under some assumptions and with the correct duality pairing, is isomorphic to $V^{*}$, see also [26, p. 1244]. One starts with reflexive Banach (or Hilbert) (sub)spaces $V \\subset H \\subset V^{\\prime}$, where each inclusion is dense and continuous and one defines $j: H \\hookrightarrow V^{*}: x \\mapsto$ $(x, \\cdot)_{H}$. Then, provided that\n\n$$\n\\left|(x, v)_{H}\\right| \\leq\\|x\\|_{V^{\\prime}}\\|v\\|_{V} \\quad \\text { for all } x \\in H, v \\in V\n$$\n\nthere exists a unique continuous extension to a map $j_{1}: V^{\\prime} \\rightarrow V^{*}$. Furthermore, if $j_{1}$ is bijective, then it follows that $j_{1}: V^{\\prime} \\cong V^{*}$ as normed spaces, although not necessarily isometrically. The duality pairing is then given by $\\left\\langle v^{\\prime}, v\\right\\rangle:=j_{1}\\left(v^{\\prime}\\right)(v)$ and for $x \\in H, v \\in V$ we have $\\langle x, v\\rangle=(x, v)_{H}$ since $j_{1}$ is the extension of $j$. The triple $\\left(V, H, V^{\\prime}\\right)$ is also called a Gelfand triple and simply denoted by $\\left(V, H, V^{*}\\right)$, where as explained, the correct duality pairing $\\langle\\cdot, \\cdot\\rangle: V^{\\prime} \\times V \\rightarrow \\mathbb{R}$ is given by $\\left\\langle v^{\\prime}, v\\right\\rangle:=j_{1}\\left(v^{\\prime}\\right)(v)$.\n\nIn fact, bijectivity of $j_{1}$ holds if and only if there exists $\\alpha>0$ such that\n\n$$\n\\alpha\\|x\\|_{V^{\\prime}} \\leq \\sup _{v \\in V,\\|v\\|_{V} \\leq 1}\\left|(x, v)_{H}\\right|=\\left\\|j_{1}(x)\\right\\|_{V^{*}} \\quad \\text { for all } x \\in H\n$$\n\nThe equivalence follows from [44, Th. 4.48], density of $H \\subset V^{\\prime}$ and continuity of $j_{1}$, and density of $\\operatorname{Im}\\left(j_{1}\\right) \\subset V^{*}$. The latter holds since $j_{1}\\left(V^{\\prime}\\right) \\supset j_{1}(H)=j(H)$ and one can verify that $j(H)$ is dense in $V^{*}$ using reflexivity of $V$. In conclusion, provided that $V \\subset H \\subset V^{\\prime}$ continuously and densely, one only has to verify (2.1) and (2.2) to have $j_{1}: V^{\\prime} \\cong V^{*}$.\n\nPopular choices for the Gelfand triple are the weak and strong setting for a given differential operator. For example, if $A(t, u):=\\Delta u$ on $\\mathbb{R}^{d}$, then one can use\n\n$$\n\\begin{array}{ll}\nV=H^{1}\\left(\\mathbb{R}^{d}\\right), H=L^{2}\\left(\\mathbb{R}^{d}\\right), V^{\\prime}=H^{-1}\\left(\\mathbb{R}^{d}\\right)=V^{*} & \\text { (weak setting) } \\\\\nV=H^{2}\\left(\\mathbb{R}^{d}\\right), H=H^{1}\\left(\\mathbb{R}^{d}\\right), V^{\\prime}=L^{2}\\left(\\mathbb{R}^{d}\\right) \\cong V^{*} & \\text { (strong setting) }\n\\end{array}\n$$\n\nSee also [6, Ex. 2.1, Ex. 2.2].\nRecall that $H=\\left[V^{*}, V\\right]_{\\frac{1}{2}}[7, \\S 5.5 .2]$ and the following interpolation estimate holds for $\\beta \\in\\left(\\frac{1}{2}, 1\\right)$ :\n\n$$\n\\|v\\|_{\\beta} \\leq K\\|v\\|_{H}^{2-2 \\beta}\\|v\\|_{V}^{2 \\beta-1}, \\quad v \\in V\n$$\n\nSince strong solutions are required to be strongly measurable, see Definition 2.1 below, one can assume without loss of generality that $V$ and $H$ are separable, see also [26, p. 1244]. Thus, from now on we assume that $V$ and $H$ are separable.\n\nAs mentioned in the introduction, we work with the critical variational setting from [6]. We consider stochastic evolution equations of the form\n\n$$\n\\left\\{\\begin{array}{l}\n\\mathrm{d} u(t)=-A(t, u(t)) \\mathrm{d} t+B(t, u(t)) \\mathrm{d} W(t), \\quad t \\in[0, T] \\\\\nu(0)=x\n\\end{array}\\right.\n$$\n\nwhere $x \\in H, T>0$ and $W$ is a $U$-cylindrical Brownian motion (see Definition 4.1).\nIf $\\Phi:[0, T] \\times \\Omega \\rightarrow \\mathcal{L}_{2}(U, H)$ is strongly progressively measurable and $\\Phi \\in L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)$ a.s., then one can define the stochastic integral $\\int_{0}^{t} \\Phi(s) \\mathrm{d} W(s)$ for $t \\in[0, T]$, see [31, $\\S 5.4(p=0)]$.\n\nWe now specify what we mean by a strong solution to (2.4). In our definition we also allow for $L^{1}(0, T ; H)$-valued integrands, which is only needed to treat the skeleton equation associated to (2.4), see Definition 2.5 below.\n\nDefinition 2.1. For $T>0$, we define the maximal regularity space by\n\n$$\n\\operatorname{MR}(0, T):=C([0, T] ; H) \\cap L^{2}(0, T ; V), \\quad\\|\\cdot\\|_{\\operatorname{MR}(0, T)}:=\\|\\cdot\\|_{C([0, T] ; H)}+\\|\\cdot\\|_{L^{2}(0, T ; V)}\n$$\n\nLet $A: \\mathbb{R}_{+} \\times V \\rightarrow V^{*}, B: \\mathbb{R}_{+} \\times V \\rightarrow \\mathcal{L}_{2}(U, H)$ and let $x \\in H$. Let $W$ be a $U$-cylindrical Brownian motion on a filtered probability space $\\left(\\Omega, \\mathcal{F},\\left(\\mathcal{F}_{t}\\right)_{t \\geq 0}, \\mathbb{P}\\right)$ and let $T>0$. We say that a strongly progressively measurable process $u:[0, T] \\times \\Omega \\rightarrow V$ is a strong solution to (2.4) if a.s.\n\n$$\nu \\in \\operatorname{MR}(0, T), A(\\cdot, u(\\cdot)) \\in L^{2}\\left(0, T ; V^{*}\\right)+L^{1}(0, T ; H), B(\\cdot, u(\\cdot)) \\in L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)\n$$\n\nand a.s.\n\n$$\nu(t)=x-\\int_{0}^{t} A(s, u(s)) \\mathrm{d} s+\\int_{0}^{t} B(s, u(s)) \\mathrm{d} W(s) \\text { in } V^{*} \\text { for all } t \\in[0, T]\n$$\n\nA strong solution $u$ is unique if for any other strong solution $v$ we have a.s. $u=v$ in $\\operatorname{MR}(0, T)$.\nIf $B=0$, we write $u^{\\prime}(t)=-A(t, u(t))$ instead of $\\mathrm{d} u(t)=-A(t, u(t)) \\mathrm{d} t$ in (2.4) and we call $u \\in \\operatorname{MR}(0, T)$ a strong solution if $A(\\cdot, u(\\cdot)) \\in L^{2}\\left(0, T ; V^{*}\\right)+L^{1}(0, T ; H)$ and (2.5) holds.\n\nFor the weak convergence approach to large deviations it is necessary to let $A$ and $B$ be defined on $\\mathbb{R}_{+} \\times V$ rather than $\\mathbb{R}_{+} \\times \\Omega \\times V$, meaning that stochasticity enters $A$ and $B$ through the solution $u$ in (2.4) and not separately. Also, the initial value $x$ in (1.1) has to be deterministic. Other than that, we make exactly the same assumptions as those required for global well-posedness [6, Th. 3.5]. Let us introduce these assumptions.\n\nAssumption 2.2. We assume that:\n(1) $A(t, v)=A_{0}(t, v) v-F(t, v)-f$ and $B(t, v)=B_{0}(t, v) v+G(t, v)+g$, where\n\n$$\nA_{0}: \\mathbb{R}_{+} \\times H \\rightarrow \\mathcal{L}\\left(V, V^{*}\\right) \\text { and } B_{0}: \\mathbb{R}_{+} \\times H \\rightarrow \\mathcal{L}\\left(V, \\mathcal{L}_{2}(U, H)\\right)\n$$\n\nare $\\mathcal{B}\\left(\\mathbb{R}_{+}\\right) \\otimes \\mathcal{B}(H)$-measurable, and\n\n$$\nF: \\mathbb{R}_{+} \\times V \\rightarrow V^{*} \\text { and } G: \\mathbb{R}_{+} \\times V \\rightarrow \\mathcal{L}_{2}(U, H)\n$$\n\nare $\\mathcal{B}\\left(\\mathbb{R}_{+}\\right) \\otimes \\mathcal{B}(V)$-measurable, and $f: \\mathbb{R}_{+} \\rightarrow V^{*}$ and $g: \\mathbb{R}_{+} \\rightarrow \\mathcal{L}_{2}(U, H)$ are $\\mathcal{B}\\left(\\mathbb{R}_{+}\\right)$ measurable maps with\n\n$$\nf \\in L_{\\mathrm{loc}}^{2}\\left(\\mathbb{R}_{+} ; V^{*}\\right) \\text { and } g \\in L_{\\mathrm{loc}}^{2}\\left(\\mathbb{R}_{+} ; \\mathcal{L}_{2}(U, H)\\right)\n$$\n\n(2) For all $T>0$ and $n \\in \\mathbb{R}_{+}$, there exist $\\theta_{n, T}, M_{n, T}>0$ such that for any $t \\in[0, T], u \\in H$, $v \\in V$ with $\\|u\\|_{H} \\leq n$, we have\n\n$$\n\\left\\langle A_{0}(t, u) v, v\\right\\rangle-\\frac{1}{2}\\left\\|B_{0}(t, u) v\\right\\|_{H}^{2} \\geq \\theta_{n, T}\\|v\\|_{V}^{2}-M_{n, T}\\|v\\|_{H}^{2}\n$$\n\n(3) There exist $\\rho_{j} \\geq 0$ and $\\beta_{j} \\in\\left(\\frac{1}{2}, 1\\right)$ such that\n\n$$\n2 \\beta_{j} \\leq 1+\\frac{1}{1+\\rho_{j}}, \\quad j \\in\\left\\{1, \\ldots, m_{F}+m_{G}\\right\\}\n$$\n\nfor some $m_{F}, m_{G} \\in \\mathbb{N}$ and for all $T>0, n \\in \\mathbb{R}_{+}$there exists a constant $C_{n, T}$ such that for all $t \\in[0, T]$ and $u, v, w \\in V$ with $\\|u\\|_{H},\\|v\\|_{H} \\leq n$, we have\n\n$$\n\\begin{gathered}\n\\left\\|A_{0}(t, u) w\\right\\|_{V^{*}} \\leq C_{n, T}\\left(1+\\|u\\|_{H}\\right)\\|w\\|_{V} \\\\\n\\left\\|A_{0}(t, u) w-A_{0}(t, v) w\\right\\|_{V^{*}} \\leq C_{n, T}\\|u-v\\|_{H}\\|w\\|_{V} \\\\\n\\left\\|B_{0}(t, u) w\\right\\|_{H} \\leq C_{n, T}\\left(1+\\|u\\|_{H}\\right)\\|w\\|_{V} \\\\\n\\left\\|B_{0}(t, u) w-B_{0}(t, v) w\\right\\|_{H} \\leq C_{n, T}\\|u-v\\|_{H}\\|w\\|_{V} \\\\\n\\|F(t, u)\\|_{V^{*}} \\leq C_{n, T} \\sum_{j=1}^{m_{F}}\\left(1+\\|u\\|_{\\beta_{j}}^{\\rho_{j}+1}\\right) \\\\\n\\|F(t, u)-F(t, v)\\|_{V^{*}} \\leq C_{n, T} \\sum_{j=1}^{m_{F}}\\left(1+\\|u\\|_{\\beta_{j}}^{\\rho_{j}}+\\|v\\|_{\\beta_{j}}^{\\rho_{j}}\\right)\\|u-v\\|_{\\beta_{j}} \\\\\n\\|G(t, u)\\|_{H} \\leq C_{n, T} \\sum_{j=m_{F}+1}^{m_{F}+m_{G}}\\left(1+\\|u\\|_{\\beta_{j}}^{\\rho_{j}+1}\\right) \\\\\n\\|G(t, u)-G(t, v)\\|_{H} \\leq C_{n, T} \\sum_{j=m_{F}+1}^{m_{F}+m_{G}}(1+\\|u\\|_{\\beta_{j}}^{\\rho_{j}}+\\|v\\|_{\\beta_{j}}^{\\rho_{j}} \\|\\|u-v\\|_{\\beta_{j}}\n\\end{gathered}\n$$\n\nWithout loss of generality, we assume that the constants $C_{n, T}$ are non-decreasing in $n$ and $T$.\nBecause the coefficients are defined on $\\mathbb{R}_{+} \\times V$ instead of $\\mathbb{R}_{+} \\times \\Omega \\times V$, the measurability in Assumption 2.2(1) is different than in [6, Assumption 3.1]. However, $(A, B)$ satisfies our assumption if and only if $(\\bar{A}, \\bar{B})$ satisfies [6, Assumption 3.1], where $\\bar{A}(t, \\omega, v):=A(t, v)$ and $\\bar{B}(t, \\omega, v):=B(t, v)$ are trivial extensions.\n\nThe operators $A_{0}$ and $B_{0}$ are of leading (differential) order and of quasilinear form. In the semilinear case, they are linear in the sense that $A_{0}(t, u)$ and $B_{0}(t, u)$ do not depend on $u$.\n\nCondition (2.6) describes a balance between the growth rate $\\rho_{j}+1$ of the nonlinearities $F$ and $G$ and the regularity coefficient $\\beta_{j}$ (whose value is usually determined by Sobolev embeddings). In case of equality in (2.6) for some $j$, the nonlinearity is called critical.\n\nFrom (2.3) and Assumption 2.2(3), it is clear that $\\|F(t, v)\\|_{V^{*}}+\\|G(t, v)\\|_{H} \\leq \\tilde{C}_{\\|v\\|_{H}, T}\\left(1+\\|v\\|_{V}\\right)$ for all $t \\in[0, T]$ if $\\|v\\|_{H} \\leq n$, where $\\tilde{C}_{\\|v\\|_{H}, T}$ is a constant. Thus we have integrability of $F(\\cdot, u(\\cdot))$ and $G(\\cdot, u(\\cdot))$ if $u \\in \\operatorname{MR}(0, T)$.\n\nIn [6, Th. 3.3] it is shown that under Assumption 2.2, there exists a unique local solution to (2.4). In [6, Th. 3.5], this is extended to a global well-posedness result under a coercivity condition on $(A, B)$. The next result follows from $[6$, Th. 3.5].\n\nTheorem 2.3. Let $(A, B)$ satisfy Assumption 2.2 and suppose that $(A, B)$ is coercive in the following sense: for all $T>0$, there exist $\\theta, M>0$ and $\\phi \\in L^{2}(0, T)$ such that for all $v \\in V$ and $t \\in[0, T]$,\n\n$$\n\\langle A(t, v), v\\rangle-\\frac{1}{2}\\|B(t, v)\\|_{H}^{2} \\geq \\theta\\|v\\|_{V}^{2}-M\\|v\\|_{H}^{2}-|\\phi(t)|^{2}\n$$\n\nThen, for any $x \\in H$ and $T>0$, there exists a unique strong solution $u$ to (2.4) on $[0, T]$.\nEnergy estimates can also be found in [6, Th. 3.5], but these will not be used. More general theory in an $L^{p}$-setting was developed in [1] and [2].", "tables": {}, "images": {}}, {"section_id": 4, "text": "# 2.2. Statement of the main result. \n\nDefinition 2.4. Let $\\mathcal{E}$ be a Polish space, let $(\\Omega, \\mathcal{F}, \\mathbb{P})$ be a probability space and let $\\left(Y^{\\varepsilon}\\right)_{\\varepsilon>0}$ be a collection of $\\mathcal{E}$-valued random variables on $(\\Omega, \\mathcal{F}, \\mathbb{P})$. Let $I: \\mathcal{E} \\rightarrow[0, \\infty]$ be a function. Then $\\left(Y^{\\varepsilon}\\right)$ satisfies the large deviation principle (LDP) on $\\mathcal{E}$ with rate function $I: S \\rightarrow[0, \\infty]$ if\n(i) I has compact sublevel sets,\n(ii) for all open $E \\subset \\mathcal{E}: \\liminf _{\\varepsilon \\downarrow 0} \\varepsilon \\log \\mathbb{P}\\left(Y^{\\varepsilon} \\in E\\right) \\geq-\\inf _{z \\in E} I(z)$,\n(iii) for all closed $E \\subset \\mathcal{E}: \\lim \\sup _{\\varepsilon \\downarrow 0} \\varepsilon \\log \\mathbb{P}\\left(Y^{\\varepsilon} \\in E\\right) \\leq-\\inf _{z \\in E} I(z)$.\n\nBefore we formulate our LDP result, we define the skeleton equation, which appears in the rate function of our LDP.\n\nDefinition 2.5. Let $x \\in H$ be fixed. For $\\psi \\in L^{2}(0, T ; U)$, the skeleton equation associated to the stochastic evolution equation (2.4) is given by\n\n$$\n\\left\\{\\begin{array}{l}\n\\left(u^{\\psi}\\right)^{\\prime}(t)=-A\\left(t, u^{\\psi}(t)\\right)+B\\left(t, u^{\\psi}(t)\\right) \\psi(t), \\quad t \\in[0, T] \\\\\nu^{\\psi}(0)=x\n\\end{array}\\right.\n$$\n\nThe main theorem of this paper is as follows.\nTheorem 2.6. Suppose that $(A, B)$ satisfies Assumption 2.2 and coercivity (2.7). Let $x \\in H$. For $\\varepsilon \\in(0,1]$, let $Y^{\\varepsilon}$ be the strong solution to\n\n$$\n\\left\\{\\begin{array}{l}\n\\mathrm{d} Y^{\\varepsilon}(t)=-A\\left(t, Y^{\\varepsilon}(t)\\right) \\mathrm{d} t+\\sqrt{\\varepsilon} B\\left(t, Y^{\\varepsilon}(t)\\right) \\mathrm{d} W(t), \\quad t \\in[0, T] \\\\\nu(0)=x\n\\end{array}\\right.\n$$\n\nThen $\\left(Y^{\\varepsilon}\\right)$ satisfies the $L D P$ on $\\operatorname{MR}(0, T)$ with rate function $I: \\operatorname{MR}(0, T) \\rightarrow[0,+\\infty]$ given by\n\n$$\nI(z)=\\frac{1}{2} \\inf \\left\\{\\int_{0}^{T}\\|\\psi(s)\\|_{U}^{2} \\mathrm{~d} s: \\psi \\in L^{2}(0, T ; U), z=u^{\\psi}\\right\\}\n$$\n\nwhere $\\inf \\varnothing:=+\\infty$ and $u^{\\psi}$ is the strong solution to (2.8).\nWe have taken $\\varepsilon \\in(0,1]$ to ensure that $(A, \\sqrt{\\varepsilon} B)$ satisfies coercivity (2.7), so that the equation for $Y^{\\varepsilon}$ is well-posed by Theorem 2.3.\n\nTo have $u^{\\psi}$ appearing in (2.9) well-defined, (2.8) needs to be (globally) well-posed. In Section 3, we prove that this is the case. Finally, we recall that the LDP is equivalent to the Laplace principle [16, Def. 1.2.2, Th. 1.2.1, Th. 1.2.3]. The weak convergence approach from [9] offers sufficient conditions for the latter, hence for the LDP. The approach is stated in Subsection 4.1, after which we apply it to prove Theorem 2.6 in the remainder of Section 4.", "tables": {}, "images": {}}, {"section_id": 5, "text": "# 3. WELL-POSEDNESS OF THE SKELETON EQUATION \n\nBefore we turn to large deviations, we prove global well-posedness of the skeleton equation (2.8) under Assumption 2.2 and coercivity (2.7). This is needed, since the solution to (2.8) appears in the rate function (2.9) of the LDP.\n\nUnfortunately, well-posedness cannot be proved at once. Instead, we first achieve well-posedness of an appropriate linearized version of the skeleton equation in Corollary 3.5, together with a maximal regularity estimate. Then, we can borrow the strategies from [22, Chap. 18], [38], [37], [36]. That is, we use the maximal regularity estimate of Corollary 3.5 for the linearized equation in a fixed point argument, yielding existence of a local solution to the skeleton equation in Theorem 3.7. Finally, we extend to a global solution in Theorem 3.16, making use of a blow-up criterion. Uniqueness will be obtained along the way.\n3.1. Linearized skeleton equation. We consider the following linearization of (2.8). We discard the non-linearities $F$ and $G$ and for fixed $w \\in L^{\\infty}(0, T ; H)$, we consider\n\n$$\n\\left\\{\\begin{array}{l}\nu^{\\prime}(t)+A_{0}(t, w(t)) u(t)-B_{0}(t, w(t)) u(t) \\psi(t)=\\bar{f}(t)+\\bar{g}(t) \\psi(t) \\\\\nu(0)=x\n\\end{array}\\right.\n$$\n\nwhere $A_{0}$ and $B_{0}$ are as in Assumption 2.2 and $\\bar{f} \\in L^{2}\\left(0, T ; V^{*}\\right), \\bar{g} \\in L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)$. In this subsection we prove well-posedness of (3.1) using the method of continuity [22, Lem. 16.2.2], together with a suitable maximal regularity estimate. We prove it for more general equations as this does not require any more effort and makes the exposition more transparent. Let us introduce spaces $S$ and $E$ that will be used in the method of continuity.\nDefinition 3.1. For $T>0$, we let\n\n$$\nS:=L^{2}\\left(0, T ; V^{*}\\right)+L^{1}(0, T ; H)\n$$\n\nbe the sum space of the interpolation couple $\\left(L^{2}\\left(0, T ; V^{*}\\right), L^{1}(0, T ; H)\\right)$, where we note that both components embed continuously into the Hausdorff topological vector space $L^{1}\\left(0, T ; V^{*}\\right)$. The norm on $S$ is given by\n\n$$\n\\|h\\|_{S}:=\\inf \\left\\{\\|f\\|_{L^{2}\\left(0, T ; V^{*}\\right)}+\\|g\\|_{L^{1}(0, T ; H)}: h=f+g, f \\in L^{2}\\left(0, T ; V^{*}\\right), g \\in L^{1}(0, T ; H\\}\\right\\}\n$$\n\nNote that $S$ is a Banach space [21, Prop. C.1.3] and $S \\hookrightarrow L^{1}\\left(0, T ; V^{*}\\right)$. Moreover, we define\n\n$$\nE:=\\left\\{u \\in \\operatorname{MR}(0, T): u \\text { is weakly differentiable, } u^{\\prime} \\in S\\right\\}, \\quad\\|u\\|_{E}:=\\|u\\|_{\\mathrm{MR}(0, T)}+\\left\\|u^{\\prime}\\right\\|_{S}\n$$\n\nNote that trivially, $E \\hookrightarrow \\operatorname{MR}(0, T)$.\nDealing with the sum space $S$ is not standard in part of the literature. However, it is covered excellently in Pardoux' thesis [34].\n\nThe following proposition is a direct consequence of [34, Th. 2.1].\nProposition 3.2. Let $\\bar{A}:[0, T] \\rightarrow \\mathcal{L}\\left(V, V^{*}\\right)$ be such that $[0, T] \\rightarrow V^{*}: t \\mapsto \\bar{A}(t) v$ is strongly Borel measurable for all $v \\in V$ and suppose that $\\alpha_{T}:=\\sup _{t \\in[0, T]}\\|\\bar{A}(t)\\|_{\\mathcal{L}\\left(V, V^{*}\\right)}<\\infty$. Suppose that there exists $\\theta>0$ such that for all $t \\in[0, T]$ and $v \\in V$ :\n\n$$\n\\langle\\bar{A}(t) v, v\\rangle \\geq \\theta\\|v\\|_{V}^{2}\n$$\n\nThen, for any $h \\in S$ and $x \\in H$, there exists a unique $u \\in E$ satisfying\n\n$$\n\\left\\{\\begin{array}{l}\nu^{\\prime}(t)+\\bar{A}(t) u(t)=h(t), \\quad t \\in[0, T] \\\\\nu(0)=x\n\\end{array}\\right.\n$$\n\nWe will need an extension of Proposition 3.2 with the coercivity condition replaced by the weaker condition (3.3) below. As a preparation, we first prove a maximal regularity estimate.\nLemma 3.3. Let $\\bar{A}:[0, T] \\rightarrow \\mathcal{L}\\left(V, V^{*}\\right)$ be such that $\\bar{A}(\\cdot) u(\\cdot) \\in S$ for any $u \\in \\operatorname{MR}(0, T)$. Suppose that there exist $\\theta>0$ and $M \\in L^{1}(0, T), M \\geq 0$ such that for all $t \\in[0, T]$ and $v \\in V$ :\n\n$$\n\\langle\\bar{A}(t) v, v\\rangle \\geq \\theta\\|v\\|_{V}^{2}-M(t)\\|v\\|_{H}^{2}\n$$\n\nLet $h \\in S$ and $x \\in H$ and suppose that $u \\in \\operatorname{MR}(0, T)$ is a strong solution to (3.2). Then\n\n$$\n\\|u\\|_{\\operatorname{MR}(0, T)} \\leq C_{\\theta} \\exp \\left(2\\|M\\|_{L^{1}(0, T)}\\right)\\left(\\|h\\|_{S}+\\|x\\|_{H}\\right)\n$$\n\nfor a constant $C_{\\theta}>0$ depending only on $\\theta$.\nProof. Write $h=f+g$ with $f \\in L^{2}\\left(0, T ; V^{*}\\right), g \\in L^{1}(0, T ; H)$. We apply [34, Th. 2.2]. Since $u \\in \\operatorname{MR}(0, T)$ is a strong solution, we have $u(t)=x+\\int_{0}^{t} v(s) \\mathrm{d} s$ with $v:=h(\\cdot)-\\bar{A}(\\cdot) u(\\cdot) \\in S=$ $L^{2}\\left(0, T ; V^{*}\\right)+L^{1}(0, T ; H)$. Hence, the chain rule (A.2) and (3.3) yield for all $t \\in[0, T]$ :\n\n$$\n\\begin{aligned}\n\\|u(t)\\|_{H}^{2} & =\\|x\\|_{H}^{2}+2 \\int_{0}^{t}\\langle h(s), u(s)\\rangle \\mathrm{d} s-2 \\int_{0}^{t}\\langle\\bar{A}(s) u(s), u(s)\\rangle \\mathrm{d} s \\\\\n& \\leq\\|x\\|_{H}^{2}+2 \\int_{0}^{t}\\langle h(s), u(s)\\rangle \\mathrm{d} s-2 \\theta\\|u\\|_{L^{2}(0, t ; V)}^{2}+2 \\int_{0}^{t} M(s)\\|u(s)\\|_{H}^{2} \\mathrm{~d} s\n\\end{aligned}\n$$\n\nNote that by Young's inequality, we have for all $s \\in[0, t]$ :\n\n$$\n\\begin{aligned}\n\\langle h(s), u(s)\\rangle=\\langle f(s), u(s)\\rangle+\\langle g(s), u(s)\\rangle & \\leq\\|u(s)\\|_{V}\\|f(s)\\|_{V^{*}}+\\|u(s)\\|_{H}\\|g(s)\\|_{H} \\\\\n& \\leq \\frac{\\theta}{2}\\|u(s)\\|_{V}^{2}+\\frac{1}{2 \\theta}\\|f(s)\\|_{V^{*}}^{2}+\\sup _{r \\in[0, t]}\\|u(r)\\|_{H}\\|g(s)\\|_{H}\n\\end{aligned}\n$$\n\nEntering this into (3.5) we obtain for all $0 \\leq t \\leq t_{1} \\leq T$ :\n\n$$\n\\begin{aligned}\n\\|u(t)\\|_{H}^{2}+\\theta\\|u\\|_{L^{2}(0, t ; V)}^{2} \\leq\\|x\\|_{H}^{2}+\\frac{1}{\\theta}\\|f\\|_{L^{2}\\left(0, T ; V^{*}\\right)}^{2}+2 \\sup _{r \\in\\left[0, t_{1}\\right]}\\|u(r)\\|_{H}\\|g\\|_{L^{1}(0, T ; H)} \\\\\n+\\int_{0}^{t_{1}} 2 M(s)\\|u(s)\\|_{H}^{2} \\mathrm{~d} s \\\\\n\\leq\\|x\\|_{H}^{2}+\\frac{1}{\\theta}\\|f\\|_{L^{2}\\left(0, T ; V^{*}\\right)}^{2}+\\frac{1}{2} \\sup _{r \\in\\left[0, t_{1}\\right]}\\|u(r)\\|_{H}^{2}+2\\|g\\|_{L^{1}(0, T ; H)}^{2}+\\int_{0}^{t} 2 M(s)\\|u(s)\\|_{H}^{2} \\mathrm{~d} s\n\\end{aligned}\n$$\n\nHence, taking $\\sup _{t \\in\\left[0, t_{1}\\right]}$ in the above and writing $F\\left(t_{1}\\right):=\\frac{1}{2} \\sup _{t \\in\\left[0, t_{1}\\right]}\\left(\\|u(t)\\|_{H}^{2}+\\theta\\|u\\|_{L^{2}(0, t ; V)}\\right)$ gives for all $0 \\leq t_{1} \\leq T$ :\n\n$$\n\\begin{aligned}\nF\\left(t_{1}\\right) & \\leq 2 F\\left(t_{1}\\right)-\\frac{1}{2} \\sup _{r \\in\\left[0, t_{1}\\right]}\\|u(r)\\|_{H}^{2} \\\\\n& \\leq\\|x\\|_{H}^{2}+\\frac{1}{\\theta}\\|f\\|_{L^{2}\\left(0, T ; V^{*}\\right)}^{2}+2\\|g\\|_{L^{1}\\left(0, T ; H\\right)}^{2}+\\int_{0}^{t_{1}} 2 M(s)\\|u(s)\\|_{H}^{2} \\mathrm{~d} s \\\\\n& \\leq\\|x\\|_{H}^{2}+\\frac{1}{\\theta}\\|f\\|_{L^{2}\\left(0, T ; V^{*}\\right)}^{2}+2\\|g\\|_{L^{1}\\left(0, T ; H\\right)}^{2}+\\int_{0}^{t_{1}} 4 M(s) F(s) \\mathrm{d} s\n\\end{aligned}\n$$\n\nso by Gronwall's inequality, we obtain\n\n$$\n\\|u\\|_{C([0, T] ; H)}^{2}+\\theta\\|u\\|_{L^{2}\\left(0, T ; V\\right)}^{2} \\leq 4 F(T) \\leq 4\\left(\\|x\\|_{H}^{2}+\\frac{1}{\\theta}\\|f\\|_{L^{2}\\left(0, T ; V^{*}\\right)}^{2}+2\\|g\\|_{L^{1}\\left(0, T ; H\\right)}^{2}\\right) \\exp \\left(4\\|M\\|_{L^{1}(0, T)}\\right)\n$$\n\nThus\n\n$$\n\\|u\\|_{\\mathrm{MR}(0, T)}^{2} \\leq\\left(1 \\vee \\theta^{-1}\\right) 4\\left(\\|x\\|_{H}^{2}+\\left(\\theta^{-1} \\vee 2\\right)\\left(\\|f\\|_{L^{2}\\left(0, T ; V^{*}\\right)}+\\|g\\|_{L^{1}\\left(0, T ; H\\right)}\\right)^{2}\\right) \\exp \\left(4\\|M\\|_{L^{1}(0, T)}\\right)\n$$\n\nSince $f$ and $g$ with $h=f+g$ were arbitrary, taking the infimum over $\\left\\{(f, g) \\in L^{2}\\left(0, T ; V^{*}\\right) \\times\\right.$ $L^{1}(0, T ; H): h=f+g\\}$ gives\n\n$$\n\\|u\\|_{\\mathrm{MR}(0, T)}^{2} \\leq C_{\\theta}^{2}\\left(\\|x\\|_{H}^{2}+\\|h\\|_{S}^{2}\\right) \\exp \\left(4\\|M\\|_{L^{1}(0, T)}\\right)\n$$\n\nwhere $C_{\\theta}:=\\left(4\\left(1 \\vee \\theta^{-1}\\right)\\left(\\theta^{-1} \\vee 2\\right)\\right)^{\\frac{1}{2}}$. Taking square roots on both sides yields (3.4).\nWe now prove Proposition 3.2 under the weaker coercivity (3.3).\nTheorem 3.4. Let $\\bar{A}:[0, T] \\rightarrow \\mathcal{L}\\left(V, V^{*}\\right)$ and suppose that for all $u \\in \\operatorname{MR}(0, T)$ :\n\n$$\n\\bar{A}(\\cdot) u(\\cdot) \\in S, \\quad\\|\\bar{A}(\\cdot) u(\\cdot)\\|_{S} \\leq \\alpha\\|u\\|_{\\mathrm{MR}(0, T)}\n$$\n\nfor some constant $\\alpha>0$ independent of $u$. Suppose that coercivity (3.3) is satisfied for some $\\theta>0$ and $M \\in L^{1}(0, T)$. Then for any $h \\in S$, there exists a unique strong solution $u \\in \\operatorname{MR}(0, T)$ to (3.2). Moreover, the estimate (3.4) holds.\n\nProof. We use the method of continuity [22, Lem. 16.2.2]. Define $A_{0} \\in \\mathcal{L}\\left(V, V^{*}\\right)$ by $A_{0} v:=$ $\\theta(\\cdot, v)_{V}$. For $\\lambda \\in[0,1]$, put\n\n$$\n\\begin{aligned}\n& A_{\\lambda}:[0, T] \\rightarrow \\mathcal{L}\\left(V, V^{*}\\right): t \\mapsto(1-\\lambda) A_{0}+\\lambda \\bar{A}(t) \\\\\n& L_{\\lambda}: E \\rightarrow S \\times H:\\left(L_{\\lambda} u\\right):=\\left(u^{\\prime}(\\cdot)+A_{\\lambda}(\\cdot)(u(\\cdot)), u(0)\\right)\n\\end{aligned}\n$$\n\nClearly, $L_{\\lambda}$ is linear. We show that $L_{\\lambda} \\in \\mathcal{L}(E, S \\times H)$ and that $[0,1] \\rightarrow \\mathcal{L}(E, S \\times H): \\lambda \\mapsto L_{\\lambda}$ is continuous.\n\nLet $u \\in E$ be arbitrary. For all $t \\in[0, T]$ we have $A_{0} u(t)=\\theta(\\cdot, u(t)) \\in V^{*}$, so by the Riesz isomorphism, $\\left\\|A_{0} u(t)\\right\\|_{V^{*}}=\\theta\\|u(t)\\|_{V}$. Since $u \\in L^{2}(0, T ; V)$, it follows that $A_{0} u(\\cdot) \\in$ $L^{2}\\left(0, T ; V^{*}\\right) \\subset S$ and\n\n$$\n\\left\\|A_{0} u(\\cdot)\\right\\|_{S} \\leq\\left\\|A_{0} u(\\cdot)\\right\\|_{L^{2}\\left(0, T ; V^{*}\\right)}=\\theta\\|u\\|_{L^{2}\\left(0, T ; V\\right)} \\leq \\theta\\|u\\|_{\\mathrm{MR}(0, T)}\n$$\n\nCombining with (3.6) gives $A_{\\lambda}(\\cdot) u(\\cdot) \\in S$ and\n\n$$\n\\left\\|A_{\\lambda}(\\cdot) u(\\cdot)\\right\\|_{S} \\leq(1-\\lambda)\\left\\|A_{0} u(\\cdot)\\right\\|_{S}+\\lambda\\|\\bar{A}(\\cdot) u(\\cdot)\\|_{S} \\leq(\\theta+\\alpha)\\|u\\|_{\\mathrm{MR}(0, T)}\n$$\n\nNote that $u^{\\prime} \\in S$ and $\\left\\|u^{\\prime}\\right\\|_{S} \\leq\\|u\\|_{E}$ by definition of $E$. Moreover, $E \\hookrightarrow \\operatorname{MR}(0, T)$, thus\n\n$$\n\\begin{aligned}\n\\left\\|L_{\\lambda} u\\right\\|_{S \\times H} & \\leq\\left\\|u^{\\prime}\\right\\|_{S}+\\left\\|A_{\\lambda}(\\cdot) u(\\cdot)\\right\\|_{S}+\\|u(0)\\|_{H} \\\\\n& \\leq\\|u\\|_{E}+(\\theta+\\alpha)\\|u\\|_{\\mathrm{MR}(0, T)}+\\|u\\|_{C([0, T] ; H)} \\\\\n& \\leq(2+\\theta+\\alpha)\\|u\\|_{E}\n\\end{aligned}\n$$\n\nproving $L_{\\lambda} \\in \\mathcal{L}(E, S \\times H)$. Moreover, we have for any $\\lambda, \\mu \\in[0,1]$ and $u \\in E$ :\n\n$$\n\\begin{aligned}\n\\left\\|\\left(L_{\\lambda}-L_{\\mu}\\right) u\\right\\|_{S \\times H} & =\\|\\left((\\mu-\\lambda) A_{0} u(\\cdot)+(\\lambda-\\mu) \\bar{A}(\\cdot) u(\\cdot), 0\\right)\\|_{S \\times H} \\\\\n& \\leq|\\mu-\\lambda|\\left\\|A_{0} u(\\cdot)\\right\\|_{S}+|\\lambda-\\mu|\\|\\bar{A}(\\cdot) u(\\cdot)\\|_{S} \\\\\n& \\leq|\\mu-\\lambda|(\\theta+\\alpha)\\|u\\|_{\\mathrm{MR}(0, T)}\n\\end{aligned}\n$$\n\n$$\n\\leq|\\mu-\\lambda|(\\theta+\\alpha)\\|u\\|_{E}\n$$\n\ni.e. $\\left\\|L_{\\lambda}-L_{\\mu}\\right\\|_{\\mathcal{L}(E, S \\times H)} \\leq|\\mu-\\lambda|(\\theta+\\alpha)$. Thus $\\lambda \\mapsto L_{\\lambda}$ is (Lipschitz) continuous.\n\nNext, we verify that $\\|u\\|_{E} \\leq K\\left\\|L_{\\lambda} u\\right\\|_{S \\times H}$ for some $K>0$ independent of $\\lambda$. Note that $A_{\\lambda}$ satisfies all conditions of Lemma 3.3. Coercivity (3.3) holds since\n\n$$\n\\begin{aligned}\n\\left\\langle v, A_{\\lambda}(t) v\\right\\rangle=(1-\\lambda)\\left\\langle v, A_{0} v\\right\\rangle+\\lambda\\langle v, \\bar{A}(t) v\\rangle & \\geq(1-\\lambda) \\theta\\|v\\|_{V}^{2}+\\lambda(\\theta\\|v\\|_{V}^{2}-|M(t)|\\|v\\|_{H}^{2}) \\\\\n& \\geq \\theta\\|v\\|_{V}^{2}-|M(t)|\\|v\\|_{H}^{2}\n\\end{aligned}\n$$\n\nThus, by (3.4) applied to $h:=u^{\\prime}+A_{\\lambda} u \\in S$ and $x:=u(0)$ :\n\n$$\n\\|u\\|_{\\operatorname{MR}(0, T)} \\leq C_{\\theta} \\exp \\left(2\\|M\\|_{L^{1}(0, T)}\\right)\\left(\\|h\\|_{S}+\\|u(0)\\|_{H}\\right)=C\\left\\|L_{\\lambda} u\\right\\|_{S \\times H}\n$$\n\nwith $C:=C_{\\theta} \\exp \\left(2\\|M\\|_{L^{1}(0, T)}\\right)$. Together with (3.7) this gives for all $u \\in E$ :\n\n$$\n\\begin{aligned}\n\\|u\\|_{E}=\\|u\\|_{\\operatorname{MR}(0, T)}+\\left\\|u^{\\prime}\\right\\|_{S} & =\\|u\\|_{\\operatorname{MR}(0, T)}+\\left\\|h(\\cdot)-A_{\\lambda}(\\cdot) u(\\cdot)\\right\\|_{S} \\\\\n& \\leq\\|u\\|_{\\operatorname{MR}(0, T)}+\\left\\|L_{\\lambda} u\\right\\|_{S \\times H}+\\left\\|A_{\\lambda}(\\cdot) u(\\cdot)\\right\\|_{S} \\\\\n& \\leq(1+\\theta+\\alpha)\\|u\\|_{\\operatorname{MR}(0, T)}+\\left\\|L_{\\lambda} u\\right\\|_{S \\times H} \\\\\n& \\leq(1+C(1+\\theta+\\alpha))\\left\\|L_{\\lambda} u\\right\\|_{S \\times H}\n\\end{aligned}\n$$\n\nFinally, note that $L_{0}: E \\rightarrow S \\times H:\\left(L_{0} u\\right)=\\left(u^{\\prime}(\\cdot)+A_{0} u(\\cdot), u(0)\\right)$ is surjective. This follows from Proposition 3.2 applied to $\\bar{A}_{0}:[0, T] \\rightarrow \\mathcal{L}\\left(V, V^{*}\\right)$ given by $\\bar{A}_{0}(t) v:=A_{0} v=\\theta(\\cdot, v)_{V}$.\n\nAll requirements for the method of continuity are fulfilled and we conclude that $L_{1}$ is surjective, giving existence of strong solutions. The a priori estimate (3.4) now follows from Lemma 3.3 and proves uniqueness of strong solutions at once, since $\\bar{A}(t)$ is linear.\n\nAs promised, a mere application of Theorem 3.4 now gives us the desired well-posedness and maximal regularity estimate for (3.1).\n\nCorollary 3.5. Let $A_{0}$ and $B_{0}$ satisfy the conditions concerning $A_{0}, B_{0}$ in Assumption 2.2 and let $\\psi \\in L^{2}(0, T ; U)$. Let $T>0$ and $w \\in L^{\\infty}(0, T ; H)$. Define $\\bar{A}:[0, T] \\rightarrow \\mathcal{L}\\left(V, V^{*}\\right)$ by $\\bar{A}(t) v:=$ $A_{0}(t, w(t)) v-B_{0}(t, w(t)) v \\psi(t)$. Then $\\bar{A}$ satisfies all conditions of Theorem 3.4. Consequently, for any $\\bar{f} \\in L^{2}\\left(0, T ; V^{*}\\right)$ and $\\bar{g} \\in L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)$, there exists a unique strong solution $u \\in$ $\\operatorname{MR}(0, T)$ to\n\n$$\n\\left\\{\\begin{aligned}\nu^{\\prime}(t) & +A_{0}(t, w(t)) u(t)-B_{0}(t, w(t)) u(t) \\psi(t)=\\bar{f}(t)+\\bar{g}(t) \\psi(t) \\\\\nu(0) & =x\n\\end{aligned}\\right.\n$$\n\nMoreover, for any $\\tilde{T} \\in[0, T]$ there exists a constant $K_{\\tilde{T}}>0$ such that\n\n$$\n\\|u\\|_{\\operatorname{MR}(0, \\tilde{T})} \\leq K_{\\tilde{T}}\\left(\\|x\\|_{H}+\\|\\bar{f}\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)}+\\|\\bar{g}\\|_{L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)}\\right)\n$$\n\nand $K_{\\tilde{T}}$ is non-decreasing in $\\tilde{T}$ and depends further only on $T,\\|w\\|_{L^{\\infty}(0, T ; H)}$ and $\\|\\psi\\|_{L^{2}\\left(0, \\tilde{T} ; U\\right)}$.\nProof. Put $n:=\\|w\\|_{L^{\\infty}(0, T ; H)}$. Since strong solutions only depend on $\\bar{A}$ through an integral, we can fix a strongly measurable, pointwise defined measurable version of $w$ which satisfies $\\|w(t)\\|_{H} \\leq$ $n$ for all $t \\in[0, T]$. Strong measurability of $\\bar{A}(\\cdot) u(\\cdot)$ is then satisfied if $u \\in \\operatorname{MR}(0, T)$, see Remark 3.6. Moreover, Assumption 2.2(3) gives for all $u \\in \\operatorname{MR}(0, T)$ :\n\n$$\n\\left\\|A_{0}(\\cdot, w(\\cdot)) u(\\cdot)\\right\\|_{L^{2}\\left(0, T ; V^{*}\\right)} \\leq C_{n, T}(1+n)\\|u\\|_{L^{2}\\left(0, T ; V\\right)}<\\infty\n$$\n\nand by the Cauchy-Schwarz inequality,\n\n$$\n\\begin{aligned}\n\\left\\|B_{0}(\\cdot, w(\\cdot)) u(\\cdot) \\psi(\\cdot)\\right\\|_{L^{1}(0, T ; H)} & \\leq\\left\\|B_{0}(\\cdot, w(\\cdot)) u(\\cdot)\\right\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)}\\|\\psi\\|_{L^{2}\\left(0, T ; U\\right)} \\\\\n& \\leq C_{n, T}(1+n)\\|u\\|_{L^{2}\\left(0, T ; V\\right)}\\|\\psi\\|_{L^{2}\\left(0, T ; U\\right)}<\\infty\n\\end{aligned}\n$$\n\nHence, $\\bar{A}(\\cdot) u(\\cdot) \\in S$ and we have\n\n$$\n\\begin{aligned}\n\\|\\bar{A}(\\cdot) u(\\cdot)\\|_{S} & \\leq\\left\\|A_{0}(\\cdot, w(\\cdot)) u(\\cdot)\\right\\|_{L^{2}\\left(0, T ; V^{*}\\right)}+\\left\\|B_{0}(\\cdot, w(\\cdot)) u(\\cdot) \\psi(\\cdot)\\right\\|_{L^{1}(0, T ; H)} \\\\\n& \\leq C_{n, T}(1+n)\\left(1+\\|\\psi\\|_{L^{2}\\left(0, T ; U\\right)}\\right)\\|u\\|_{L^{2}\\left(0, T ; V\\right)} \\\\\n& \\leq \\alpha\\|u\\|_{\\operatorname{MR}(0, T)}\n\\end{aligned}\n$$\n\nwhere $\\alpha:=C_{n, T}(1+n)\\left(1+\\|\\psi\\|_{L^{2}(0, T ; U))}\\right)$.\nFurthermore, by Assumption 2.2(2), we have for all $v \\in V$ and $t \\in[0, T]$ :\n\n$$\n\\begin{aligned}\n\\langle\\bar{A}(t) v, v\\rangle & =\\left\\langle A_{0}(t, w(t)) v, v\\right\\rangle-\\left\\langle B_{0}(t, w(t)) \\psi(t) v, v\\right\\rangle \\\\\n& \\geq\\left\\langle A_{0}(t, w(t)) v, v\\right\\rangle-\\frac{1}{2}\\left\\|B_{0}(t, w(t)) v\\right\\|_{H}^{2}-\\frac{1}{2}\\|\\psi(t)\\|_{U}^{2}\\|v\\|_{H}^{2} \\\\\n& \\geq \\theta_{n, T}\\|v\\|_{V}^{2}-\\left(M_{n, T}+\\frac{1}{2}\\|\\psi(t)\\|_{U}^{2}\\right)\\|v\\|_{H}^{2}\n\\end{aligned}\n$$\n\nso coercivity (3.3) is satisfied with $\\theta:=\\theta_{n, T}$ and $M(\\cdot):=M_{n, T}+\\frac{1}{2}\\|\\psi(\\cdot)\\|_{U}^{2} \\in L^{1}(0, T)$.\nAs before by the Cauchy-Schwarz inequality, $h:=\\bar{f}+\\bar{g} \\psi \\in S$. Now Theorem 3.4 yields existence of a unique strong solution $u \\in \\operatorname{MR}(0, T)$ to (3.1). Finally, let $\\tilde{T} \\in(0, T]$ be arbitrary and put $\\tilde{S}:=L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)+L^{1}(0, \\tilde{T} ; H)$. We have\n\n$$\n\\|h\\|_{\\tilde{S}} \\leq\\|\\bar{f}\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)}+\\|\\bar{g} \\psi\\|_{L^{1}(0, \\tilde{T} ; H)} \\leq\\|\\bar{f}\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)}+\\|\\bar{g}\\|_{L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)}\\|\\psi\\|_{L^{2}\\left(0, \\tilde{T} ; U\\right)}\n$$\n\nAs $\\left.u\\right|_{[0, \\tilde{T}]}$ is a strong solution to (3.1) on $[0, \\tilde{T}],(3.4)$ and (3.9) yield\n\n$$\n\\begin{aligned}\n\\|u\\|_{\\operatorname{MR}(0, \\tilde{T})} & \\leq C_{\\theta} \\exp \\left(2\\|M\\|_{L^{1}(0, \\tilde{T})}\\right)\\left(\\|h\\|_{\\tilde{S}}+\\|x\\|_{H}\\right) \\\\\n& \\leq K_{\\tilde{T}}\\left(\\|x\\|_{H}+\\|\\bar{f}\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)}+\\|\\bar{g}\\|_{L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)}\\right)\n\\end{aligned}\n$$\n\nwhere $K_{\\tilde{T}}:=C_{\\theta} \\exp \\left(2\\|M\\|_{L^{1}(0, \\tilde{T})}\\right)\\left(1 \\vee\\|\\psi\\|_{L^{2}\\left(0, \\tilde{T} ; U\\right)}\\right)$ is non-decreasing in $\\tilde{T}$. Note that apart from $\\tilde{T}, K_{\\tilde{T}}$ only depends on $T, n$ and $\\|\\psi\\|_{L^{2}\\left(0, \\tilde{T} ; U\\right)}$, since these determine $\\theta$ and $\\|M\\|_{L^{1}(0, \\tilde{T})}$.\n\nRemark 3.6. In Corollary 3.5, the map $t \\mapsto \\bar{A}(t) v$ is strongly Borel measurable for any $v \\in$ $V$, and even more is true. Assumption 2.2 assures that we have strong Borel measurability of $A_{0}(\\cdot, w(\\cdot)) u(\\cdot), F(\\cdot, u(\\cdot)):[0, T] \\rightarrow V^{*}$ and $B_{0}(\\cdot, w(\\cdot)) u(\\cdot), G(\\cdot, u(\\cdot)):[0, T] \\rightarrow \\mathcal{L}_{2}(U, H)$, for any $u \\in L^{0}(0, T ; V)$ and $w \\in L^{0}(0, T ; H)$. This follows from strong measurability of $u:[0, T] \\rightarrow V$ and $w:[0, T] \\rightarrow H$ and the fact that by Assumption 2.2(3), $F(t, \\cdot), G(t, \\cdot)$ are continuous on $V$ and $A_{0}(t, \\cdot) \\cdot, B_{0}(t, \\cdot) \\cdot$ are continuous on $H \\times V$. Moreover, one uses the measurability of Assumption 2.2(1), separability of $V, H, V^{*}, \\mathcal{L}_{2}(U, H)$ and continuity of $V \\hookrightarrow H \\hookrightarrow V^{*}$.\n3.2. Local well-posedness. From now on, we let $\\psi \\in L^{2}(0, T ; U)$ be arbitrary but fixed. Using Corollary 3.5, we will prove local well-posedness of the actual skeleton equation (2.8). Local wellposedness is established in Theorem 3.7. Its proof and preparatory lemma's are analogous to [22, \u00a718.2], which was inspired by [38] and [37].\n\nThe skeleton equation does not fit in the setting of [22], [38] or [37], for the reason that we only have $L^{1}$-( instead of $L^{2}$-)integrability of the term $\\left.B(\\cdot, u^{\\psi}(\\cdot))\\right) \\psi(\\cdot)$ in (2.8). Besides that, our maximal regularity space $\\operatorname{MR}(0, T)=C([0, T] ; H) \\cap L^{2}(0, T ; V)$ is different.\n\nWhen no confusion can arise, we omit the time input in our notations for brevity. For example, for $u, v \\in \\operatorname{MR}(0, T)$ we denote by $A_{0}(u) v$ and $B_{0}(u) v \\psi$ the maps $t \\mapsto A_{0}(t, u(t)) v(t)$ and $t \\mapsto$ $B_{0}\\left(t, u_{0}\\right) v(t) \\psi(t)$ respectively and similarly for $F(u)$ and $G(u) \\psi$. We define the following $V^{*}$ valued mappings:\n\n$$\n\\bar{A}(u) v:=A_{0}(u) v-B_{0}(u) v \\psi, \\quad \\tilde{F}(u)=F(u)+f+(G(u)+g) \\psi\n$$\n\nTheorem 3.7 (Local well-posedness of the skeleton equation). Suppose that $(A, B)$ satisfies Assumption 2.2. Let $u_{0} \\in H$ be fixed. Then there exist $\\tilde{T}, \\varepsilon>0$ such that for each $v_{0} \\in B_{H}\\left(u_{0}, \\varepsilon\\right)$, there exists a unique strong solution $u_{v_{0}} \\in \\operatorname{MR}(0, \\tilde{T})$ to\n\n$$\n\\begin{cases}u^{\\prime}+\\tilde{A}(u) u=\\tilde{F}(u) & \\text { on }[0, \\tilde{T}] \\\\ u(0)=v_{0}\\end{cases}\n$$\n\nMoreover, there exists a constant $C>0$ such that for all $v_{0}, w_{0} \\in B_{H}\\left(u_{0}, \\varepsilon\\right)$ :\n\n$$\n\\left\\|u_{v_{0}}-u_{w_{0}}\\right\\|_{\\mathrm{MR}(0, \\tilde{T})} \\leq C\\left\\|v_{0}-w_{0}\\right\\|_{H}\n$$\n\nTheorem 3.7 will be proved using the Banach fixed point theorem, applied to the map $\\Psi_{v_{0}}: \\operatorname{MR}(0, \\tilde{T}) \\rightarrow$ $\\operatorname{MR}(0, \\tilde{T})$ defined by $\\Psi_{v_{0}}(v):=u$, where $u$ is the unique strong solution to\n\n$$\n\\left\\{\\begin{array}{l}\nu^{\\prime}+\\tilde{A}\\left(u_{0}\\right) u=\\left(\\tilde{A}\\left(u_{0}\\right)-\\tilde{A}(v)\\right) v+\\tilde{F}(v) \\quad \\text { on }[0, \\tilde{T}] \\\\\nu(0)=v_{0}\n\\end{array}\\right.\n$$\n\nNote that $u \\in \\operatorname{MR}(0, \\tilde{T})$ is a strong solution to (3.10) if and only if $\\Psi_{v_{0}}(u)=u$.\nOur first task is to prove that $\\Psi_{v_{0}}$ is well-defined, i.e. (3.12) is well-posed. By Corollary 3.5 $\\left(w(t):=u_{0}\\right)$ it suffices to show that\n\n$$\n\\tilde{f}:=\\left(A_{0}\\left(u_{0}\\right)-A_{0}(v)\\right) v+F(v)+f, \\quad \\tilde{g}:=\\left(B_{0}\\left(u_{0}\\right)-B_{0}(v)\\right) v+G(v)+g\n$$\n\nsatisfy $\\tilde{f} \\in L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)$ and $\\tilde{g} \\in L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)$. The latter will be ascertained by the following lemma, which will also be used later on in Section 4.\nLemma 3.8. Let $\\rho_{j}>0, \\beta_{j} \\in\\left(\\frac{1}{2}, 1\\right)$ be such that $\\left(2 \\beta_{j}-1\\right)\\left(\\rho_{j}+1\\right) \\leq 1$. Let $V_{\\beta_{j}}=\\left[V^{*}, V\\right]_{\\beta_{j}}$ be the complex interpolation space with norm $\\|\\cdot\\|_{\\beta_{j}}:=\\|\\cdot\\|_{V_{\\beta_{j}}}$. Then, for any $T>0$ :\n(i) $\\iota_{j, T}: \\operatorname{MR}(0, T) \\hookrightarrow L^{2\\left(\\rho_{j}+1\\right)}\\left(0, T ; V_{\\beta_{j}}\\right)$. The embedding satisfies $\\left\\|\\iota_{j, T}\\right\\| \\leq M_{T}^{j}$ with $M_{T}^{j} \\in \\mathbb{R}_{+}$ non-decreasing in $T$.\nSuppose that $(A, B)$ satisfies Assumption 2.2. Let $n \\in \\mathbb{R}_{+}$and $T>0$. For $C_{n, T}$ the constant from Assumption 2.2(3) (non-decreasing in $n$ and $T$ ), it holds that\n(ii) for all $u \\in C([0, T] ; H), w \\in L^{2}(0, T ; V)$ with $\\|u\\|_{C([0, T] ; H)} \\leq n$ :\n\n$$\n\\left\\|A_{0}(u) w\\right\\|_{L^{2}\\left(0, T ; V^{*}\\right)} \\vee\\left\\|B_{0}(u) w\\right\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)} \\leq C_{n, T}(1+n)\\|w\\|_{L^{2}\\left(0, T ; V\\right)}\n$$\n\n(iii) for all $u, v \\in C([0, T] ; H), w \\in L^{2}(0, T ; V)$ with $\\|u\\|_{C([0, T] ; H)},\\|v\\|_{C([0, T] ; H)} \\leq n$ :\n\n$$\n\\begin{aligned}\n& \\left\\|\\left(A_{0}(u)-A_{0}(v)\\right) w\\right\\|_{L^{2}\\left(0, T ; V^{*}\\right)} \\vee\\left\\|\\left(B_{0}(u)-B_{0}(v)\\right) w\\right\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)} \\\\\n& \\leq C_{n, T}\\left(\\int_{0}^{T}\\|u(s)-v(s)\\|_{H}^{2}\\|w(s)\\|_{V}^{2} \\mathrm{~d} s\\right)^{\\frac{1}{2}} \\leq C_{n, T}\\left\\|u-v\\right\\|_{C([0, T] ; H)}\\|w\\|_{L^{2}\\left(0, T ; V\\right)}\n\\end{aligned}\n$$\n\nMoreover, there exists a constant $\\tilde{C}_{n, T}$ non-decreasing in $T$ such that\n(iv) for all $u \\in \\operatorname{MR}(0, T)$ with $\\|u\\|_{C([0, T] ; H)} \\leq n$ :\n\n$$\n\\|F(u)\\|_{L^{2}\\left(0, T ; V^{*}\\right)} \\vee\\|G(u)\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)} \\leq \\tilde{C}_{n, T}\\left(1+\\|u\\|_{L^{2}\\left(0, T ; V\\right)}\\right)\n$$\n\nLastly, for each $\\sigma>0$ there exists a constant $C_{n, T, \\sigma}$ non-decreasing in $T$ such that\n(v) for all $u, v \\in \\operatorname{MR}(0, T)$ with $\\|u\\|_{C([0, T] ; H)},\\|v\\|_{C([0, T] ; H)} \\leq n$ :\n\n$$\n\\begin{aligned}\n& \\|F(u)-F(v)\\|_{L^{2}\\left(0, T ; V^{*}\\right)}^{2} \\vee\\|G(u)-G(v)\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)}^{2} \\\\\n& \\quad \\leq C_{n, T, \\sigma} \\int_{0}^{t}\\left(1+\\|u(s)\\|_{V}^{2}+\\|v(s)\\|_{V}^{2}\\right)\\|u(s)-v(s)\\|_{H}^{2} \\mathrm{~d} s+\\sigma C_{n, T}^{2}\\|u-v\\|_{L^{2}\\left(0, T ; V\\right)}^{2}\n\\end{aligned}\n$$\n\nProof. (i): By the interpolation estimate (2.3), we have for any $u \\in \\operatorname{MR}(0, T)$ :\n\n$$\n\\begin{aligned}\n\\int_{0}^{T}\\|u(t)\\|_{\\beta_{j}}^{2\\left(\\rho_{j}+1\\right)} \\mathrm{d} t & \\leq K \\int_{0}^{T}\\|u(t)\\|_{H}^{2\\left(\\rho_{j}+1\\right)\\left(2-2 \\beta_{j}\\right)}\\|u(t)\\|_{V}^{2\\left(\\rho_{j}+1\\right)\\left(2 \\beta_{j}-1\\right)} \\mathrm{d} t \\\\\n& \\leq K\\|u\\|_{C\\left([0, T] ; H)}^{2\\left(\\rho_{j}+1\\right)\\left(2-2 \\beta_{j}\\right)} \\int_{0}^{T}\\|u(t)\\|_{V}^{2\\left(\\rho_{j}+1\\right)\\left(2 \\beta_{j}-1\\right)} \\mathrm{d} t \\\\\n& \\leq K\\|u\\|_{C\\left([0, T] ; H)}^{2\\left(\\rho_{j}+1\\right)\\left(2-2 \\beta_{j}\\right)}\\|1\\|_{L^{p_{j}^{\\prime}}\\left(0, T\\right)}^{2\\left(\\rho_{j}+1\\right)\\left(2 \\beta_{j}-1\\right)}\\|_{L^{p_{j}}\\left(0, T\\right)} \\\\\n& \\leq K\\|u\\|_{C\\left([0, T] ; H)}^{2\\left(\\rho_{j}+1\\right)\\left(2-2 \\beta_{j}\\right)}(1 \\vee T)^{\\frac{p_{j}-1}{p_{j}}}\\|u\\|_{L^{2}\\left(0, T ; V\\right)}^{2\\left(\\rho_{j}+1\\right)\\left(2 \\beta_{j}-1\\right)}\n\\end{aligned}\n$$\n\nwhere we applied H\u00f6lder's inequality for each $j$ with $p_{j}:=\\frac{1}{\\left(\\rho_{j}+1\\right)\\left(2 \\beta_{j}-1\\right)} \\in[1, \\infty), p_{j}^{\\prime}:=\\frac{p_{j}}{p_{j}-1} \\in$ $[1, \\infty]$ and included the maximum with 1 to cover the case $p_{j}^{\\prime}=\\infty$. We conclude that\n\n$$\n\\|u\\|_{L^{2\\left(\\rho_{j}+1\\right)}\\left(0, T ; V_{\\beta_{j}}\\right)} \\leq M_{T}^{j}\\|u\\|_{C\\left([0, T] ; H)}^{(2-2 \\beta_{j})}\\|u\\|_{L^{2}\\left(0, T ; V\\right)}^{(2 \\beta_{j}-1)}\n$$\n\n$$\n\\begin{aligned}\n& \\leq M_{T}^{j}\\left(\\left(2-2 \\beta_{j}\\right)\\|u\\|_{C([0, T] ; H)}+\\left(2 \\beta_{j}-1\\right)\\|u\\|_{L^{2}(0, T ; V)}\\right) \\\\\n& \\leq M_{T}^{j}\\|u\\|_{\\operatorname{MR}(0, T)}\n\\end{aligned}\n$$\n\nwhere $M_{T}^{j} \\in \\mathbb{R}_{+}$is non-decreasing in $T$. We used Young's inequality and the fact that $\\beta_{j} \\in\\left(\\frac{1}{2}, 1\\right)$.\nIn (ii)-(v), note that strong measurability of $A_{0}(\\cdot, u(\\cdot)) w(\\cdot), F(\\cdot, u(\\cdot)), B_{0}(\\cdot, u(\\cdot)) w(\\cdot)$ and $G(\\cdot, u(\\cdot))$ holds, as was mentioned in Remark 3.6. Moreover, by symmetry in Assumption 2.2, $B_{0}$ and $G$ can be estimated in the same way as $A_{0}$ and $F$. We provide the estimates for the latter. Assumption 2.2(3) immediately yields (ii) and (iii).\n\nFor (iv): by Assumption 2.2(3) and (2.3), we have pointwise in $t \\in[0, T]$ :\n\n$$\n\\begin{aligned}\n\\|F(u)\\|_{V^{*}} \\leq C_{n, T} \\sum_{j=1}^{m_{F}}\\left(1+\\|u\\|_{\\beta_{j}}^{\\rho_{j}+1}\\right) & \\leq C_{n, T} \\sum_{j=1}^{m_{F}}\\left(1+\\left(K n^{2-2 \\beta_{j}}\\right)^{\\rho_{j}+1}\\|u\\|_{V}^{\\left(2 \\beta_{j}-1\\right)\\left(\\rho_{j}+1\\right)}\\right) \\\\\n& \\leq C_{n, T} \\sum_{j=1}^{m_{F}}\\left(1+C_{n}\\left(1+\\|u\\|_{V}\\right)\\right) \\\\\n& \\leq \\bar{C}_{n, T}\\left(1+\\|u\\|_{V}\\right)\n\\end{aligned}\n$$\n\nwhere we used that $\\left(2 \\beta_{j}-1\\right)\\left(\\rho_{j}+1\\right) \\leq 1$ and put $C_{n}:=\\max _{j=1, \\ldots, m_{F}}\\left(K n^{2-2 \\beta_{j}}\\right)^{\\rho_{j}+1}<\\infty$ and $\\bar{C}_{n, T}:=m_{F} C_{n, T}\\left(1+C_{n}\\right)$. Thus\n\n$$\n\\|F(u)\\|_{L^{2}\\left(0, T ; V^{*}\\right)} \\leq \\bar{C}_{n, T}\\left(T^{\\frac{1}{2}}+\\|u\\|_{L^{2}(0, T ; V)}\\right) \\leq \\bar{C}_{n, T}\\left(1+\\|u\\|_{L^{2}(0, T ; V)}\\right)\n$$\n\nwith $\\bar{C}_{n, T}=\\bar{C}_{n, T}\\left(T^{\\frac{1}{2}} \\vee 1\\right)$. Since $C_{n, T}$ is non-decreasing in $T$, the same holds for $\\bar{C}_{n, T}$ and $\\bar{C}_{n, T}$.\nFor (v): the following estimates can be found in the proof of [6, Prop. 4.5]. By Assumption 2.2(3) we have pointwise in $t \\in[0, T]$ :\n\n$$\n\\|F(u)-F(v)\\|_{V^{*}} \\leq C_{n, T} \\sum_{j=1}^{m_{F}}\\left(1+\\|u\\|_{\\beta_{j}}^{\\rho_{j}}+\\|v\\|_{\\beta_{j}}^{\\rho_{j}}\\right)\\|u-v\\|_{\\beta_{j}}\n$$\n\nBy the interpolation estimate (2.3) and Young's inequality (with powers $\\frac{1}{2-2 \\beta}$ and $\\frac{1}{2 \\beta-1}$ ), we have for all $y, z \\in V, \\beta \\in\\left(\\frac{1}{2}, 1\\right), \\rho \\geq 0$ with $(2 \\beta-1)(\\rho+1) \\leq 1$ and for all $\\sigma>0$ :\n\n$$\n\\begin{aligned}\n\\|y\\|_{\\beta}^{\\rho}\\|z\\|_{\\beta} & \\leq\\left(K^{\\rho+1}\\|y\\|_{H}^{(2-2 \\beta) \\rho}\\|y\\|_{V}^{(2 \\beta-1) \\rho}\\|z\\|_{H}^{2-2 \\beta}\\right)\\|z\\|_{V}^{2 \\beta-1} \\\\\n& \\leq \\sigma^{-\\frac{5 \\beta-1}{2-2 \\beta}}(2-2 \\beta) K^{\\frac{\\rho+1}{2-2 \\beta}}\\|y\\|_{H}^{\\rho}\\|y\\|_{V}^{\\frac{(2 \\beta-1) \\rho}{2-2 \\beta}}\\|z\\|_{H}+\\sigma(2 \\beta-1)\\|z\\|_{V} \\\\\n& \\leq \\sigma^{-\\frac{5 \\beta-1}{2-2 \\beta}} K^{\\frac{\\rho+1}{2-2 \\beta}}\\|y\\|_{H}^{\\rho}\\left(1+\\|y\\|_{V}\\right)\\|z\\|_{H}+\\sigma\\|z\\|_{V} \\\\\n& \\leq M_{\\sigma, \\beta, \\rho}\\|y\\|_{H}^{\\rho}\\left(1+\\|y\\|_{V}\\right)\\|z\\|_{H}+\\sigma\\|z\\|_{V}\n\\end{aligned}\n$$\n\nwhere $M_{\\sigma, \\beta, \\rho}>0$ is a constant depending only on $\\sigma, \\beta$ and $\\rho$ and we let $0^{0}=1$. In the above we used that $a:=\\frac{(2 \\beta-1) \\rho}{2-2 \\beta} \\in[0,1]$, hence $x^{a} \\leq 1+x$ for $x \\geq 0$. For $j \\in\\left\\{1, \\ldots, m_{F}\\right\\}$, application of (3.15) gives pointwise in $t \\in[0, T]$ :\n\n$$\n\\begin{aligned}\n& \\left(1+\\|u\\|_{\\beta_{j}}^{\\rho_{j}}+\\|v\\|_{\\beta_{j}}^{\\rho_{j}}\\right)\\|u-v\\|_{\\beta_{j}} \\\\\n& \\quad \\leq\\left(M_{\\sigma, \\beta_{j}, 0}+M_{\\sigma, \\beta_{j}, \\rho_{j}}\\|u\\|_{H}^{\\rho_{j}}\\left(1+\\|u\\|_{V}\\right)+M_{\\sigma, \\beta_{j}, \\rho_{j}}\\|v\\|_{H}^{\\rho_{j}}\\left(1+\\|v\\|_{V}\\right)\\right)\\|u-v\\|_{H}+3 \\sigma\\|u-v\\|_{V} \\\\\n& \\quad \\leq M_{\\sigma}\\left(1+\\|u\\|_{V}+\\|v\\|_{V}\\right)\\|u-v\\|_{H}+3 \\sigma\\|u-v\\|_{V}\n\\end{aligned}\n$$\n\nwith $M_{\\sigma}:=\\max _{j=1, \\ldots, m_{F}}\\left(M_{\\sigma, \\beta_{j}, 0}+2 M_{\\sigma, \\beta_{j}, \\rho_{j}} N^{\\rho_{j}}\\right)<\\infty$. Now, (3.14) and (3.16) imply\n\n$$\n\\|F(u)-F(v)\\|_{V^{*}} \\leq C_{n, T} m_{F} M_{\\sigma}\\left(1+\\|u\\|_{V}+\\|v\\|_{V}\\right)\\|u-v\\|_{H}+3 \\sigma C_{n, T} m_{F}\\|u-v\\|_{V}\n$$\n\nand hence, applying $\\left(x_{1}+\\ldots+x_{d}\\right)^{2} \\leq 2^{d-1}\\left(x_{1}^{2}+\\ldots+x_{d}^{2}\\right)$ with $d=2,3$ :\n\n$$\n\\begin{aligned}\n\\|F(u)-F(v)\\|_{L^{2}\\left(0, T ; V^{*}\\right)}^{2} \\leq \\bar{C}_{n, T, \\sigma} & \\int_{0}^{T}(1+\\|u(t)\\|_{V}^{2}+\\|v(t)\\|_{V}^{2})\\|u(t)-v(t)\\|_{H}^{2} \\mathrm{~d} t \\\\\n& +2\\left(3 \\sigma C_{n, T} m_{F}\\right)^{2} \\int_{0}^{T}\\|u(t)-v(t)\\|_{V}^{2} \\mathrm{~d} t\n\\end{aligned}\n$$\n\nwith $\\bar{C}_{N, T, \\sigma}=8\\left(C_{n, T} m_{F} M_{\\sigma}\\right)^{2}$. Since $C_{n, T}$ is non-decreasing in $T$, the same holds for $\\bar{C}_{n, T, \\sigma}$. Substituting $\\sigma=18 \\bar{\\sigma}^{2} m_{F}^{2}, C_{n, T, \\sigma}:=\\bar{C}_{n, T, \\bar{\\sigma}}$ now yields (v).\n\nRemark 3.9. Lemma 3.8 yields $A(\\cdot, u(\\cdot)) \\in L^{2}\\left(0, T ; V^{*}\\right)$ and $B(\\cdot, u(\\cdot)) \\in L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)$ a.s. if $u \\in \\operatorname{MR}(0, T)$ a.s. Hence, under Assumption 2.2, this condition is redundant in the definition of a strong solution (Definition 2.1).\n\nFrom Lemma 3.8, we see that $\\tilde{f}$ and $\\tilde{g}$ defined by (3.13) lie in $L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)$ and $L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)$ respectively, for any $\\tilde{T}>0$ and $v \\in \\operatorname{MR}(0, \\tilde{T})$ (put $n=\\left\\|u_{0}\\right\\|_{H} \\vee\\|v\\|_{C([0, \\tilde{T} \\mid ; H)}$ and apply (iii) and (v)). Thus Corollary 3.5 gives that (3.12) is well-posed, i.e. $\\Psi_{v_{0}}$ is well-defined.\n\nOur next concern is to prove that $\\Psi_{v_{0}}$ is contractive on a suitable smaller subspace of $\\operatorname{MR}(0, T)$. To define this subspace, let us introduce some notations. For what follows, we fix an arbitrary $u_{0} \\in H$ and $T>0$. For $v_{0} \\in H$, we let $z_{v_{0}} \\in \\operatorname{MR}(0, T)$ be the reference solution, defined as the unique strong solution to the linear problem\n\n$$\n\\begin{cases}z^{\\prime}+\\tilde{A}\\left(u_{0}\\right) z=0 & \\text { on }[0, T] \\\\ z(0)=v_{0} . & \\end{cases}\n$$\n\nWell-posedness holds by Corollary 3.5. Note that $z_{u_{0}}(0)=u_{0}$ and $z_{u_{0}} \\in \\operatorname{MR}(0, T)$, so there exists a $T_{1} \\in(0, T]$ such that\n\n$$\n\\left\\|z_{u_{0}}-u_{0}\\right\\|_{C\\left(\\left[0, T_{1}\\right] ; H\\right)} \\leq \\frac{1}{3}\n$$\n\nWe fix such a $T_{1}$. Finally, for $v_{0} \\in H, r>0$ and $\\tilde{T} \\in[0, T]$, we define\n\n$$\nZ_{r, \\tilde{T}}\\left(v_{0}\\right):=\\left\\{v \\in \\operatorname{MR}(0, \\tilde{T}): v(0)=v_{0},\\left\\|v-z_{u_{0}}\\right\\|_{\\operatorname{MR}(0, \\tilde{T})} \\leq r\\right\\}\n$$\n\nNote that $Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ is closed in $\\operatorname{MR}(0, \\tilde{T})$, hence complete. Eventually, we will find that $\\Psi_{v_{0}}$ is contractive on some $Z_{r, \\tilde{T}}\\left(v_{0}\\right)$. Several crucial estimates will be gathered in the next lemma's.\n\nLemma 3.10. There exist $\\varepsilon_{1}, r_{1}>0$ such that for all $\\varepsilon \\in\\left(0, \\varepsilon_{1}\\right], r \\in\\left(0, r_{1}\\right], \\tilde{T} \\in\\left(0, T_{1}\\right]$, $v_{0} \\in B_{H}\\left(u_{0}, \\varepsilon\\right)$ and $v \\in Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ it holds that $\\left\\|v-u_{0}\\right\\|_{C\\left([0, \\tilde{T} \\mid ; H\\right)} \\leq 1$.\n\nProof. Let $\\varepsilon, r>0, \\tilde{T} \\in\\left(0, T_{1}\\right]$ and let $v \\in Z_{r, \\tilde{T}}\\left(v_{0}\\right)$. We have\n\n$$\n\\begin{aligned}\n\\left\\|v-z_{v_{0}}\\right\\|_{\\operatorname{MR}(0, \\tilde{T})} & \\leq\\left\\|v-z_{u_{0}}\\right\\|_{\\operatorname{MR}(0, \\tilde{T})}+\\left\\|z_{u_{0}}-z_{v_{0}}\\right\\|_{\\operatorname{MR}\\left(0, T_{1}\\right)} \\\\\n& =\\left\\|v-z_{u_{0}}\\right\\|_{\\operatorname{MR}(0, \\tilde{T})}+\\left\\|z_{u_{0}-v_{0}}\\right\\|_{\\operatorname{MR}\\left(0, T_{1}\\right)} \\\\\n& \\leq r+K_{T_{1}}\\left\\|u_{0}-v_{0}\\right\\|_{H}\n\\end{aligned}\n$$\n\nwhere the last inequality follows from the definition of $Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ and (3.8). Therefore,\n\n$$\n\\begin{aligned}\n\\left\\|v-u_{0}\\right\\|_{C\\left([0, \\tilde{T} \\mid ; H\\right)} & \\leq\\left\\|v-z_{v_{0}}\\right\\|_{\\operatorname{MR}\\left(0, \\tilde{T}\\right)}+\\left\\|z_{v_{0}}-z_{u_{0}}\\right\\|_{\\operatorname{MR}\\left(0, T_{1}\\right)}+\\left\\|z_{u_{0}}-u_{0}\\right\\|_{C\\left(\\left[0, T_{1}\\right] ; H\\right)} \\\\\n& \\leq\\left(r+K_{T_{1}}\\left\\|u_{0}-v_{0}\\right\\|_{H}\\right)+K_{T_{1}}\\left\\|u_{0}-v_{0}\\right\\|_{H}+\\frac{1}{3} \\\\\n& \\leq r+2 K_{T_{1}} \\varepsilon+\\frac{1}{3}\n\\end{aligned}\n$$\n\nwhenever $v_{0} \\in B_{H}\\left(u_{0}, \\varepsilon\\right)$. Taking $r_{1}=\\frac{1}{3}$ and $\\varepsilon_{1}=\\left(6 K_{T_{1}}\\right)^{-1}$, the claim is proved.\nThe next lemma is analogous to [22, Lem. 18.2.10].\nLemma 3.11. Let $u_{0} \\in H$ and suppose that $(A, B)$ satisfies Assumption 2.2. Let $\\tilde{f} \\in L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)$ and $\\tilde{g} \\in L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)$ be defined by (3.13). For $\\varepsilon_{1}$ and $r_{1}$ from Lemma 3.10, the following estimates hold for any $\\tilde{T} \\in\\left(0, T_{1}\\right], \\varepsilon \\in\\left(0, \\varepsilon_{1}\\right], r \\in\\left(0, r_{1}\\right], v_{0} \\in B_{H}\\left(u_{0}, \\varepsilon\\right), v \\in Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ and $\\sigma>0$ :\n\n$$\n\\|\\tilde{f}\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\vee\\|\\tilde{g}\\|_{L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)} \\leq \\alpha_{T_{1}}(\\tilde{T})+\\beta_{T_{1}, r_{1}, \\sigma}(\\tilde{T}, r) r+\\sigma C_{T_{1}} r\n$$\n\nwhere $C_{T_{1}}$ is a constant and $\\alpha_{T_{1}}(\\tilde{T}), \\beta_{T_{1}, r_{1}, \\sigma}(\\tilde{T}, r) \\downarrow 0$ as $\\tilde{T}, r \\downarrow 0$. Moreover, $C_{T_{1}}, \\alpha_{T_{1}}(\\tilde{T})$ and $\\beta_{T_{1}, r_{1}, \\sigma}(\\tilde{T}, r)$ are independent of $v_{0}$ and $v$.\n\nProof. Let $v_{0} \\in B_{H}\\left(u_{0}, \\varepsilon\\right), \\tilde{T} \\in\\left(0, T_{1}\\right]$ and $v \\in Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ be arbitrary. We estimate each term appearing in the definition of $\\tilde{f}$. By Lemma 3.10,\n\n$$\n\\|v\\|_{C([0, \\tilde{T} ; H)} \\leq\\left\\|v-u_{0}\\right\\|_{C([0, T_{1} ; H)}+\\left\\|u_{0}\\right\\|_{H} \\leq\\left\\|u_{0}\\right\\|_{H}+1\n$$\n\nPutting $C_{T_{1}}:=C_{\\left\\|u_{0}\\right\\|_{H}+1, T_{1}}$, Lemma 3.8(iii) gives\n\n$$\n\\begin{aligned}\n& \\left\\|A_{0}\\left(u_{0}\\right) v-A_{0}(v) v\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\leq C_{T_{1}}\\left\\|u_{0}-v\\right\\|_{C([0, \\tilde{T} ; H)}\\|v\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)} \\\\\n& \\leq C_{T_{1}}\\left(\\left\\|u_{0}-z_{u_{0}}\\right\\|_{C([0, \\tilde{T} ; H)}+\\left\\|z_{u_{0}}-v\\right\\|_{C([0, \\tilde{T} ; H)}\\right)\\left(\\left\\|v-z_{u_{0}}\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)}+\\left\\|z_{u_{0}}\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)}\\right) \\\\\n& \\leq C_{T_{1}}(\\alpha(\\tilde{T})+r)^{2} \\leq 2 C_{T_{1}}\\left(\\alpha(\\tilde{T})^{2}+r^{2}\\right)\n\\end{aligned}\n$$\n\nwith\n\n$$\n\\alpha(\\tilde{T}):=\\left\\|u_{0}-z_{u_{0}}\\right\\|_{C([0, \\tilde{T} ; H)} \\vee\\left\\|z_{u_{0}}\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)}\n$$\n\nNote that $\\alpha(\\tilde{T}) \\downarrow 0$ as $\\tilde{T} \\downarrow 0$, since $z_{u_{0}} \\in C\\left(\\left[0, T_{1}\\right] ; H\\right) \\cap L^{2}\\left(0, T_{1} ; V\\right)$ and $z_{u_{0}}(0)=u_{0}$.\nWe turn to the term $F(v)$ appearing in $\\tilde{f}$. By (3.18),\n\n$$\n\\left\\|z_{u_{0}}\\right\\|_{C([0, \\tilde{T} ; H)} \\leq\\left\\|z_{u_{0}}-u_{0}\\right\\|_{C\\left(\\left[0, T_{1}\\right] ; H\\right)}+\\left\\|u_{0}\\right\\|_{H}<1+\\left\\|u_{0}\\right\\|_{H}\n$$\n\nNow we apply Lemma 3.8(v) and write $\\tilde{C}_{T_{1}, \\sigma}:=C_{\\left\\|u_{0}\\right\\|_{H}+1, T_{1}, \\sigma}$ and $C_{T_{1}}=C_{\\left\\|u_{0}\\right\\|_{H}+1, T_{1}}$ for the constants therein. Recalling (3.23) and (3.21), we obtain\n\n$$\n\\begin{aligned}\n& \\left\\|F(v)\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\leq\\left\\|F(v)-F\\left(z_{u_{0}}\\right)\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)}+\\left\\|F\\left(z_{u_{0}}\\right)\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\\\\n& \\leq\\left(\\tilde{C}_{T_{1}, \\sigma} \\int_{0}^{\\tilde{T}}\\left(1+\\|v\\|_{V}^{2}+\\left\\|z_{u_{0}}\\right\\|_{V}^{2}\\right)\\left\\|v-z_{u_{0}}\\right\\|_{H}^{2} \\mathrm{~d} s\\right)^{\\frac{1}{2}}+\\sigma C_{T_{1}}\\left\\|v-z_{u_{0}}\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)} \\\\\n& +\\left\\|F\\left(z_{u_{0}}\\right)\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\\\\n& \\leq\\left(\\tilde{C}_{T_{1}, \\sigma} \\int_{0}^{\\tilde{T}}\\left(1+\\|v\\|_{V}^{2}+\\left\\|z_{u_{0}}\\right\\|_{V}^{2}\\right) r^{2} \\mathrm{~d} s\\right)^{\\frac{1}{2}}+\\sigma C_{T_{1}} r+\\left\\|F\\left(z_{u_{0}}\\right)\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\\\\n& \\leq r \\tilde{C}_{T_{1}, \\sigma}^{\\frac{1}{2}}\\left(\\tilde{T}^{\\frac{1}{2}}+\\|v\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)}+\\left\\|z_{u_{0}}\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)}\\right)+\\sigma C_{T_{1}} r+\\left\\|F\\left(z_{u_{0}}\\right)\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\\\\n& \\leq r \\tilde{C}_{T_{1}, \\sigma}^{\\frac{1}{2}}\\left(\\tilde{T}^{\\frac{1}{2}}+\\|v-z_{u_{0}}\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)}+2\\left\\|z_{u_{0}}\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)}\\right)+\\sigma C_{T_{1}} r+\\left\\|F\\left(z_{u_{0}}\\right)\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\\\\n& \\leq r \\tilde{C}_{T_{1}, \\sigma}^{\\frac{1}{2}}\\left(\\tilde{T}^{\\frac{1}{2}}+r+2\\left\\|z_{u_{0}}\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)}\\right)+\\sigma C_{T_{1}} r+\\left\\|F\\left(z_{u_{0}}\\right)\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} .\n\\end{aligned}\n$$\n\nIt follows that\n\n$$\n\\|F(v)\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)}+\\|f\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\leq \\tilde{\\beta}_{T_{1}, r_{1}, \\sigma}(\\tilde{T}, r) r+\\sigma C_{T_{1}} r+\\gamma(\\tilde{T})\n$$\n\nwith\n\n$$\n\\begin{aligned}\n& \\tilde{\\beta}_{T_{1}, r_{1}, \\sigma}(\\tilde{T}, r):=\\tilde{C}_{\\tilde{T}_{1}, \\sigma}^{\\frac{1}{2}}\\left(\\tilde{T}^{\\frac{1}{2}}+r+2\\left\\|z_{u_{0}}\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)}\\right)+\\|f\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\\\\n& \\gamma(\\tilde{T}):=\\left(\\|f\\|_{L^{2}\\left(0, \\tilde{T} ; H\\right)} \\vee\\|g\\|_{L^{2}\\left(0, \\tilde{T} ; H\\right)}\\right)+\\left\\|F\\left(z_{u_{0}}\\right)\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)}\n\\end{aligned}\n$$\n\nRecall that $z_{u_{0}} \\in \\operatorname{MR}\\left(0, T_{1}\\right) \\subset L^{2}\\left(0, T_{1} ; V\\right)$ and by Lemma 3.8(iv), $F\\left(z_{u_{0}}\\right) \\in L^{2}\\left(0, T_{1} ; V^{*}\\right)$. So $\\tilde{\\beta}_{T_{1}, r_{1}, \\sigma}(\\tilde{T}, r) \\downarrow 0$ as $\\tilde{T}, r \\downarrow 0$ and $\\gamma(\\tilde{T}) \\downarrow 0$ as $\\tilde{T} \\downarrow 0$ by the Dominated Convergence Theorem. Combining (3.24) and (3.22) and putting\n\n$$\n\\begin{aligned}\n& \\beta_{T_{1}, r_{1}, \\sigma}(\\tilde{T}, r):=\\tilde{\\beta}_{T_{1}, r_{1}, \\sigma}(\\tilde{T}, r)+2 C_{T_{1}} r \\\\\n& \\alpha_{T_{1}}(\\tilde{T}):=2 C_{T_{1}} \\alpha(\\tilde{T})^{2}+\\gamma(\\tilde{T})\n\\end{aligned}\n$$\n\nproves (3.20) for $\\tilde{f}$. By symmetry in Lemma 3.8, the estimate for $\\hat{g}$ follows similarly.\nBefore we prove Theorem 3.7, we need one more lemma, a modification of [22, Lemma 18.2.12].\n\nLemma 3.12. Let $u_{0} \\in H$ and suppose that $(A, B)$ satisfies Assumption 2.2. For $\\varepsilon_{1}$ and $r_{1}$ from Lemma 3.10, the following estimates hold for any $\\tilde{T} \\in\\left(0, T_{1}\\right], v_{0}, w_{0} \\in B_{H}\\left(u_{0}, \\varepsilon\\right), v \\in Z_{r, \\tilde{T}}\\left(v_{0}\\right)$, $w \\in Z_{r, \\tilde{T}}\\left(w_{0}\\right)$ and $u \\in \\operatorname{MR}(0, \\tilde{T})$ :\n\n$$\n\\begin{aligned}\n& \\left\\|\\left(A_{0}(v)-A_{0}(w)\\right) v\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\vee\\left\\|\\left(B_{0}(v)-B_{0}(w)\\right) v\\right\\|_{L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)} \\\\\n& \\leq c_{T_{1}}(r+\\alpha(\\tilde{T}))\\|v-w\\|_{\\mathrm{MR}(0, \\tilde{T})} \\\\\n& \\left\\|\\left(A_{0}\\left(u_{0}\\right)-A_{0}(w)\\right) u\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\vee\\left\\|\\left(B_{0}\\left(u_{0}\\right)-B_{0}(w)\\right) u\\right\\|_{L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)} \\\\\n& \\leq c_{T_{1}}(r+\\beta(\\tilde{T}))\\|u\\|_{\\mathrm{MR}(0, \\tilde{T})} \\\\\n& \\|F(v)-F(w)\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\vee\\|G(v)-G(w)\\|_{L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)} \\leq \\gamma_{T_{1}}(\\tilde{T}, r)\\|v-w\\|_{\\mathrm{MR}(0, \\tilde{T})}\n\\end{aligned}\n$$\n\nwhere $c_{T_{1}}$ is a constant and $\\alpha(\\tilde{T}), \\beta(\\tilde{T}), \\gamma_{T_{1}}(\\tilde{T}, r) \\downarrow 0$ as $\\tilde{T}, r \\downarrow 0$. Moreover, $c_{T_{1}}, \\alpha(\\tilde{T}), \\beta(\\tilde{T})$ and $\\gamma_{T_{1}}(\\tilde{T}, r)$ are independent of $v_{0}, w_{0}, v$ and $w$.\nProof. Fix $n:=2\\left\\|u_{0}\\right\\|_{H}+2, c_{T_{1}}:=C_{n, T_{1}}$ and note that $\\|v\\|_{C(\\left[0, \\tilde{T} ; H\\right)}+\\|w\\|_{C(\\left[0, \\tilde{T} ; H\\right)} \\leq n$ by Lemma 3.10. By Lemma 3.8(iii), we have\n\n$$\n\\begin{aligned}\n\\left\\|\\left(A_{0}(v)-A_{0}(w)\\right) v\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} & \\leq c_{T_{1}}\\|v-w\\|_{C(\\left[0, \\tilde{T} ; H\\right)}\\|v\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)} \\\\\n& \\leq c_{T_{1}}\\|v-w\\|_{\\mathrm{MR}(0, \\tilde{T})}\\left(\\left\\|v-z_{u_{0}}\\right\\|_{\\mathrm{MR}(0, \\tilde{T})}+\\left\\|z_{u_{0}}\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)}\\right) \\\\\n& \\leq c_{T_{1}}\\|v-w\\|_{\\mathrm{MR}(0, \\tilde{T})}(r+\\alpha(\\tilde{T}))\n\\end{aligned}\n$$\n\nwhere $\\alpha(\\tilde{T}):=\\left\\|z_{u_{0}}\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)} \\downarrow 0$ as $\\tilde{T} \\downarrow 0$. Similarly,\n\n$$\n\\begin{aligned}\n\\left\\|\\left(A_{0}\\left(u_{0}\\right)-A_{0}(w)\\right) u\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} & \\leq c_{T_{1}}\\left\\|u_{0}-w\\right\\|_{C(\\left[0, \\tilde{T} ; H\\right)}\\|u\\|_{L^{2}\\left(0, \\tilde{T} ; V\\right)} \\\\\n& \\leq c_{T_{1}}\\left(\\left\\|u_{0}-z_{u_{0}}\\right\\|_{C(\\left[0, \\tilde{T} ; H\\right)}+\\left\\|z_{u_{0}}-w\\right\\|_{\\mathrm{MR}(0, \\tilde{T})}\\right)\\|u\\|_{\\mathrm{MR}(0, \\tilde{T})} \\\\\n& \\leq c_{T_{1}}(\\beta(\\tilde{T})+r)\\|u\\|_{\\mathrm{MR}(0, \\tilde{T})}\n\\end{aligned}\n$$\n\nwhere $\\beta(\\tilde{T}):=\\left\\|u_{0}-z_{u_{0}}\\right\\|_{C(\\left[0, \\tilde{T} ; H\\right)} \\downarrow 0$ as $\\tilde{T} \\downarrow 0$ since $z_{u_{0}}(0)=u_{0}$.\nNow we turn to $F$. Let $p_{j}:=\\frac{2\\left(\\rho_{j}+1\\right)}{\\rho_{j}}$ and $q_{j}:=2\\left(\\rho_{j}+1\\right)$. Since $\\frac{1}{p_{j}}+\\frac{1}{q_{j}}=\\frac{1}{2}$, we have\n\n$$\n\\begin{aligned}\n& \\|F(v)-F(w)\\|_{L^{2}\\left(0, \\tilde{T}, V^{*}\\right)} \\leq c_{T_{1}} \\sum_{j=1}^{m_{F}}\\left\\|\\left(1+\\|v\\|_{\\beta_{j}}^{\\rho_{j}}+\\|w\\|_{\\beta_{j}}^{\\rho_{j}}\\right)\\|v-w\\|_{\\beta_{j}}\\right\\|_{L^{2}(0, \\tilde{T})} \\\\\n& \\quad \\leq c_{T_{1}} \\sum_{j=1}^{m_{F}}\\|1+\\|v\\|_{\\beta_{j}}^{\\rho_{j}}+\\|w\\|_{\\beta_{j}}^{\\rho_{j}}\\left\\|_{L^{p_{j}}(0, \\tilde{T})}\\right\\|\\|v-w\\|_{\\beta_{j}}\\left\\|_{L^{q_{j}}(0, \\tilde{T})}\\right. \\\\\n& \\quad \\leq c_{T_{1}} \\sum_{j=1}^{m_{F}}\\left(\\tilde{T}^{\\frac{1}{\\rho_{j}}}+\\|v\\|_{L^{p_{j} p_{j}}\\left(0, \\tilde{T} ; V_{\\beta_{j}}\\right)}^{\\rho_{j}}+\\|w\\|_{L^{p_{j}} p_{j}}^{\\rho_{j}}\\left(0, \\tilde{T} ; V_{\\beta_{j}}\\right)}^{\\rho_{j}}\\right)\\|v-w\\|_{L^{q_{j}}\\left(0, \\tilde{T} ; V_{\\beta_{j}}\\right)} \\\\\n& \\quad(3.25)=c_{T_{1}} \\sum_{j=1}^{m_{F}}\\left(\\tilde{T}^{\\frac{\\rho_{j}}{\\beta\\left(\\rho_{j}+1\\right)}}+\\|v\\|_{L^{2}\\left(\\rho_{j}+1\\right)}^{\\rho_{j}}\\left(0, \\tilde{T} ; V_{\\beta_{j}}\\right)}+\\|w\\|_{L^{2}\\left(\\rho_{j}+1\\right)\\left(0, \\tilde{T} ; V_{\\beta_{j}}\\right)}^{\\rho_{j}}\\right)\\|v-w\\|_{L^{2\\left(\\rho_{j}+1\\right)}\\left(0, \\tilde{T} ; V_{\\beta_{j}}\\right)}\n\\end{aligned}\n$$\n\nMoreover, by Lemma 3.8(i):\n\n$$\n\\begin{aligned}\n& \\|v\\|_{L^{2\\left(\\rho_{j}+1\\right)}\\left(0, \\tilde{T} ; V_{\\beta_{j}}\\right)} \\leq\\left\\|v-z_{u_{0}}\\right\\|_{L^{2\\left(\\rho_{j}+1\\right)}\\left(0, \\tilde{T} ; V_{\\beta_{j}}\\right)}+\\left\\|z_{u_{0}}\\right\\|_{L^{2\\left(\\rho_{j}+1\\right)}\\left(0, \\tilde{T} ; V_{\\beta_{j}}\\right)} \\\\\n& \\leq M_{T_{1}}^{j}\\left\\|v-z_{u_{0}}\\right\\|_{\\mathrm{MR}(0, \\tilde{T})}+\\left\\|z_{u_{0}}\\right\\|_{L^{2\\left(\\rho_{j}+1\\right)}\\left(0, \\tilde{T} ; V_{\\beta_{j}}\\right)} \\\\\n& \\leq M_{T_{1}}^{j}\\left(r+\\alpha_{j}(\\tilde{T})\\right)\n\\end{aligned}\n$$\n\nwith $\\alpha_{j}(\\tilde{T}):=\\left\\|z_{u_{0}}\\right\\|_{L^{2\\left(\\rho_{j}+1\\right)}\\left(0, \\tilde{T} ; V_{\\beta_{j}}\\right)} \\downarrow 0$ as $\\tilde{T} \\downarrow 0$ by the Dominated Convergence Theorem. Similarly, (3.26) holds with $v$ replaced by $w$. Combining (3.25), (3.26) and Lemma 3.8(i) gives\n\n$$\n\\|F(v)-F(w)\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\leq c_{T_{1}} \\sum_{j=1}^{m_{F}} \\gamma_{T_{1}}^{j}(\\tilde{T}, r) M_{T_{1}}^{j}\\|v-w\\|_{\\mathrm{MR}(0, \\tilde{T})}\n$$\n\nwhere\n\n$$\n\\gamma_{T_{1}}^{j}(\\tilde{T}, r):=\\left(\\tilde{T}^{\\frac{\\rho_{j}}{2\\left(\\rho_{j}+1\\right)}}+2\\left(M_{T_{1}}^{j}\\left(r+\\alpha_{j}(\\tilde{T})\\right)\\right)^{\\rho_{j}}\\right)\n$$\n\nNote that for each $j \\in\\left\\{1, \\ldots, m_{F}\\right\\}$ we have $\\gamma_{T_{1}}^{j}(\\tilde{T}, r) \\downarrow 0$ as $\\tilde{T}, r \\downarrow 0$. Thus, putting $\\gamma_{T_{1}}(\\tilde{T}, r):=$ $c_{T_{1}} \\sum_{j=1}^{m_{F}} \\gamma_{T_{1}}^{j}(\\tilde{T}, r) M_{T_{1}}^{j}$, we have proved the desired estimate for $F(v)-F(w)$.\n\nBy symmetry in Assumption 2.2(3), $B_{0}$ and $G$ can be estimated similarly.\nWe are now ready to prove Theorem 3.7. The proof is adapted from [22, Th. 18.2.6].\nProof of Theorem 3.7. Let $\\varepsilon_{1}, r_{1}>0$ be as in Lemma 3.10 and let $\\tilde{T} \\in\\left(0, T_{1}\\right], \\varepsilon \\in\\left(0, \\varepsilon_{1}\\right], r \\in$ $\\left(0, r_{1}\\right]$. As above, define $\\Psi_{v_{0}}: \\operatorname{MR}(0, \\tilde{T}) \\rightarrow \\operatorname{MR}(0, \\tilde{T})$ by $\\Psi_{v_{0}}(v):=u$, where $u$ is the unique strong solution to (3.12). Recall that $u$ solves (3.10) if and only if $\\Psi_{v_{0}}(u)=u$ and recall that $Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ defined by (3.19) is closed in $\\operatorname{MR}(0, \\tilde{T})$, hence complete. We show that for $\\tilde{T}, \\varepsilon, r$ small enough, the mapping $\\Psi_{v_{0}}$ maps $Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ to itself and is contractive. The Banach fixed point theorem then gives existence of a unique fixed point in $Z_{r, \\tilde{T}}\\left(v_{0}\\right)$, hence existence of a solution to (3.10). We will extend the uniqueness within $Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ to uniqueness in $\\operatorname{MR}(0, \\tilde{T})$.\n\nLet $v \\in Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ and let $u:=\\Psi_{v_{0}}(v)$. Let $z_{u_{0}}$ be defined as in (3.17) and define $\\tilde{f}, \\tilde{g}$ by (3.13). Note that $u-z_{u_{0}}=\\Psi_{v_{0}-u_{0}}(v)$, so by (3.8) and (3.20), we have for any $\\sigma>0$ :\n\n$$\n\\begin{aligned}\n\\left\\|u-z_{u_{0}}\\right\\|_{\\mathrm{MR}(0, \\tilde{T})} \\leq\\left\\|u-z_{u_{0}}\\right\\|_{\\mathrm{MR}\\left(0, T_{1}\\right)} & \\leq K_{T_{1}}\\left(\\left\\|v_{0}-u_{0}\\right\\|_{H}+\\|\\tilde{f}\\|_{L^{2}\\left(0, T_{1} ; V^{*}\\right)}+\\|\\tilde{g}\\|_{L^{2}\\left(0, T_{1} ; \\mathcal{L}_{2}(U, H)\\right)}\\right) \\\\\n& \\leq K_{T_{1}}\\left(\\varepsilon+2 \\alpha_{T_{1}}(\\tilde{T})+2 \\beta_{T_{1}, r_{1}, \\sigma}(\\tilde{T}, r) r+2 \\sigma C_{T_{1}} r\\right)\n\\end{aligned}\n$$\n\nwith $\\alpha_{T_{1}}(\\tilde{T}), \\beta_{T_{1}, r_{1}, \\sigma}(\\tilde{T}, r) \\downarrow 0$ as $\\tilde{T}, r \\downarrow 0$. Recall that $K_{T_{1}}$ from (3.8) only depends on $T_{1}, T$, $\\left\\|u_{0}\\right\\|_{H}$ and $\\psi$, not on $v_{0}$ or $v$. Fixing first $\\sigma:=\\left(4 K_{T_{1}} C_{T_{1}}\\right)^{-1}$, we find\n\n$$\n\\left\\|u-z_{u_{0}}\\right\\|_{\\mathrm{MR}(0, \\tilde{T})} \\leq \\frac{r}{2}+K_{T_{1}}\\left(\\varepsilon+2 \\alpha_{T_{1}}(\\tilde{T})+2 \\beta_{\\sigma, T_{1}, r_{1}}(\\tilde{T}, r) r\\right)\n$$\n\nFor all small enough $r$ and all small enough $\\tilde{T}, \\varepsilon$ (dependent on $r$ ), one thus has $\\left\\|u-z_{u_{0}}\\right\\|_{\\mathrm{MR}(0, \\tilde{T})} \\leq$ $r$, i.e. $\\Psi_{v_{0}}(v)=u \\in Z_{r, \\tilde{T}}\\left(v_{0}\\right)$. In particular, for all such $r, \\tilde{T}, \\varepsilon$ and for all $v_{0} \\in B_{H}\\left(u_{0}, \\varepsilon\\right), \\Psi_{v_{0}}$ maps $Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ to itself.\n\nNow we show that for some (even smaller) $r, \\tilde{T}, \\varepsilon>0$, the map $\\Psi_{v_{0}}: Z_{r, \\tilde{T}}\\left(v_{0}\\right) \\rightarrow Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ is contractive for all $v_{0} \\in B_{H}\\left(u_{0}, \\varepsilon\\right)$ and we prove continuous dependence on the initial value $v_{0}$. Let $v_{0}, w_{0} \\in B_{H}\\left(u_{0}, \\varepsilon\\right), v \\in Z_{r, \\tilde{T}}\\left(v_{0}\\right), w \\in Z_{r, \\tilde{T}}\\left(w_{0}\\right)$ and note that $u:=\\Psi_{v_{0}}(v)-\\Psi_{w_{0}}(w)$ is a strong solution to\n\n$$\n\\left\\{\\begin{aligned}\nu^{\\prime}+\\tilde{A}\\left(u_{0}\\right) u=\\left(\\tilde{A}\\left(u_{0}\\right)-\\tilde{A}(v)\\right) v-\\left(\\tilde{A}\\left(u_{0}\\right)-\\tilde{A}(w)\\right) w+\\tilde{F}(v)-\\tilde{F}(w) & \\text { on }[0, \\tilde{T}] \\\\\nu(0)=v_{0}-w_{0} &\n\\end{aligned}\\right.\n$$\n\nHence, by (3.8):\n\n$$\n\\|u\\|_{\\mathrm{MR}(0, \\tilde{T})} \\leq K_{T_{1}}\\left(\\left\\|v_{0}-w_{0}\\right\\|_{H}+\\|\\tilde{f}\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)}+\\|\\tilde{g}\\|_{L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)}\\right)\n$$\n\nwith $\\bar{f}:=\\left(A_{0}\\left(u_{0}\\right)-A_{0}(v)\\right) v-\\left(A_{0}\\left(u_{0}\\right)-A_{0}(w)\\right) w+F(v)-F(w)$ and $\\bar{g}:=\\left(B_{0}\\left(u_{0}\\right)-B_{0}(v)\\right) v-$ $\\left(B_{0}\\left(u_{0}\\right)-B_{0}(w)\\right) w+G(v)-G(w)$. We have by Lemma 3.12:\n\n$$\n\\begin{aligned}\n\\|\\tilde{f}\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\leq\\left\\|\\left(A_{0}(v)-A_{0}(w)\\right) v\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)}+\\left\\|\\left(A\\left(u_{0}\\right)-A(w)\\right)(v-w)\\right\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\\\\n+\\|F(v)-F(w)\\|_{L^{2}\\left(0, \\tilde{T} ; V^{*}\\right)} \\\\\n\\leq\\left(c_{T_{1}}(2 r+\\alpha(\\tilde{T})+\\beta(\\tilde{T}))+\\gamma_{T_{1}}(\\tilde{T}, r)\\right)\\|v-w\\|_{\\mathrm{MR}(0, \\tilde{T})}\n\\end{aligned}\n$$\n\nwith $\\alpha(\\tilde{T}), \\beta(\\tilde{T}), \\gamma_{T_{1}}(\\tilde{T}, r) \\downarrow 0$ as $\\tilde{T}, r \\downarrow 0$. The same estimate applies to $\\|\\tilde{g}\\|_{L^{2}\\left(0, \\tilde{T} ; \\mathcal{L}_{2}(U, H)\\right)}$ by symmetry. Putting $C(\\tilde{T}, r):=2\\left(c_{T_{1}}(2 r+\\alpha(\\tilde{T})+\\beta(\\tilde{T}))+\\gamma_{T_{1}}(\\tilde{T}, r)\\right)$, we conclude that\n\n$$\n\\|u\\|_{\\mathrm{MR}(0, \\tilde{T})} \\leq K_{T_{1}}\\left(\\left\\|v_{0}-w_{0}\\right\\|_{H}+C(\\tilde{T}, r)\\|v-w\\|_{\\mathrm{MR}(0, \\tilde{T})}\\right)\n$$\n\nwith $C(\\tilde{T}, r) \\downarrow 0$ as $\\tilde{T}, r \\downarrow 0$. For all small enough $r, \\tilde{T}, \\varepsilon$ we thus have $K_{T_{1}} C(\\tilde{T}, r) \\leq \\frac{1}{2}$ and\n\n$$\n\\left\\|\\Psi_{v_{0}}(v)-\\Psi_{w_{0}}(w)\\right\\|_{\\mathrm{MR}(0, \\tilde{T})}=\\|u\\|_{\\mathrm{MR}(0, \\tilde{T})} \\leq K_{T_{1}}\\left\\|v_{0}-w_{0}\\right\\|_{H}+\\frac{1}{2}\\|v-w\\|_{\\mathrm{MR}(0, \\tilde{T})}\n$$\n\nApplication to $w_{0}=v_{0}$ shows that $\\Psi_{v_{0}}: Z_{r, \\tilde{T}}\\left(v_{0}\\right) \\rightarrow Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ is a strict contraction. A unique fixed point is thus guaranteed by the Banach fixed point theorem. Now let $u_{v_{0}} \\in Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ and $u_{w_{0}} \\in Z_{r, \\tilde{T}}\\left(w_{0}\\right)$ be fixed points of $\\Psi_{v_{0}}$ and $\\Psi_{w_{0}}$, respectively. Then (3.27) yields\n\n$$\n\\left\\|u_{v_{0}}-u_{w_{0}}\\right\\|_{\\mathrm{MR}(0, \\tilde{T})}=\\left\\|\\Psi_{v_{0}}\\left(u_{v_{0}}\\right)-\\Psi_{w_{0}}\\left(u_{w_{0}}\\right)\\right\\|_{\\mathrm{MR}(0, \\tilde{T})} \\leq K_{T_{1}}\\left\\|v_{0}-w_{0}\\right\\|_{H}+\\frac{1}{2}\\left\\|u_{v_{0}}-u_{w_{0}}\\right\\|_{\\mathrm{MR}(0, \\tilde{T})}\n$$\n\nConsequently, (3.11) holds with $C:=2 K_{T_{1}}>0$.\nIt remains to show that uniqueness not only holds within $Z_{r, \\tilde{T}}\\left(v_{0}\\right)$ but also within the larger space $\\operatorname{MR}(0, \\tilde{T})$. Let $v, \\tilde{v} \\in \\operatorname{MR}(0, \\tilde{T})$ be strong solutions to (3.10) and suppose that $v \\neq \\tilde{v}$. Then we have $s:=\\inf \\{t \\in[0, \\tilde{T}]: v(t) \\neq \\tilde{v}$ in $H\\} \\in[0, \\tilde{T})$ since $\\operatorname{MR}(0, \\tilde{T})=C([0, \\tilde{T} ; H) \\cap L^{2}(0, \\tilde{T} ; V)$ and $V \\hookrightarrow H$ is injective. Moreover, $v(s)=\\tilde{v}(s)=: w_{0}$ as $v, \\tilde{v} \\in C([0, \\tilde{T} ; H)$ and $v(\\cdot+s)$ and $\\tilde{v}(\\cdot+s)$ are strong solutions to\n\n$$\n\\begin{cases}u^{\\prime}+\\tilde{A}(u) u=\\tilde{F}(u) & \\text { on }[0, \\tilde{T}-s] \\\\ u(0)=w_{0}\\end{cases}\n$$\n\nNow, by the first part of the proof, there exist $r_{0}, T_{0}>0$ such that (3.28) has a unique solution in $Z_{r, \\delta}\\left(w_{0}\\right)$ for all $r \\in\\left(0, r_{0}\\right]$ and $\\delta \\in\\left(0, T_{0}\\right]$ (take $u_{0}=v_{0}=w_{0}$ ). Fix\n\n$$\n\\delta:=\\sup \\left\\{t \\in\\left[0, \\min \\left\\{T_{0}, \\tilde{T}-s\\right\\}\\right):\\left\\|v(\\cdot+s)-z_{w_{0}}\\right\\|_{\\mathrm{MR}(0, t)} \\vee\\left\\|\\tilde{v}(\\cdot+s)-z_{w_{0}}\\right\\|_{\\mathrm{MR}(0, t)}<r_{0}\\right\\}\n$$\n\nand note that $\\delta \\in\\left(0, \\min \\left\\{T_{0}, \\tilde{T}-s\\right\\}\\right]$ since $v(0+s)=\\tilde{v}(0+s)=w_{0}=z_{w_{0}}(0)$. In particular, $\\delta \\in\\left(0, T_{0}\\right]$ and $v(\\cdot+s), \\tilde{v}(\\cdot+s) \\in Z_{r_{0}, T}\\left(w_{0}\\right)$ by definition of $\\delta$. Uniqueness of solutions in $Z_{r_{0}, \\delta}\\left(w_{0}\\right)$ implies that $v(\\cdot+s)=\\tilde{v}(\\cdot+s)$ on $[0, \\delta]$. Therefore $v=\\tilde{v}$ on $[0, s+\\delta]$, contradicting the definition of $s$. We conclude that $v=\\tilde{v}$.\n\nRemark 3.13. Observe that the local well-posedness could also have been proved under mere coercivity of $A_{0}$ instead of coercivity of $\\left(A_{0}, B_{0}\\right)$ (Assumption 2.2(2)). Indeed, in the current section, we have only used Corollary 3.5 and the estimates from Assumption 2.2(3). Now, the proof of Corollary 3.5 continues when we only assume $\\left\\langle A_{0}(t, u) v, v\\right\\rangle \\geq \\theta_{n, T}\\|v\\|_{V}^{2}-M_{n, T}\\|v\\|_{H}^{2}$, since then, combined with Assumption 2.2(3) and Young's inequality:\n\n$$\n\\begin{aligned}\n\\langle\\tilde{A}(t) v, v\\rangle & \\geq\\left\\langle A_{0}(t, w(t)) v, v\\right\\rangle-\\sigma\\left\\|B_{0}(t, w(t)) v\\right\\|_{H}^{2}-C_{\\sigma}\\|\\psi(t)\\|_{U}^{2}\\|v\\|_{H}^{2} \\\\\n& \\geq \\theta_{n, T}\\|v\\|_{V}^{2}-\\left(M_{n, T}+C_{\\sigma}\\|\\psi(t)\\|_{U}^{2}\\right)\\|v\\|_{H}^{2}-\\sigma C_{n, T}^{2}(1+n)^{2}\\|v\\|_{V}^{2}\n\\end{aligned}\n$$\n\nPutting $\\sigma:=\\theta_{n, T}\\left(2 C_{n, T}^{2}(1+n)^{2}\\right)^{-1}$, the required coercivity (3.3) for $\\tilde{A}$ follows.\n3.3. Global well-posedness. Similar to [36, Chap. 5] and [22, \u00a718.2], we will extend Theorem 3.7 to a global well-posedness result by means of maximal solutions and a blow-up criterion.\n\nDefinition 3.14. For $T \\in(0, \\infty]$, we define\n\n$$\n\\operatorname{MR}_{\\text {loc }}(0, T):=\\{u:[0, T) \\rightarrow H: u|_{\\left[0, \\tilde{T}\\right]} \\in \\operatorname{MR}(0, \\tilde{T}) \\text { for all } \\tilde{T} \\in[0, T)\\}\n$$\n\n$A$ maximal solution to (2.8) is a pair $\\left(u_{*}, T_{*}\\right) \\in \\operatorname{MR}_{\\text {loc }}\\left(0, T_{*}\\right) \\times(0, \\infty]$ such that\n(i) for all $T \\in\\left(0, T_{*}\\right)$, $\\left.u_{*}\\right|_{[0, T]}$ is a strong solution to (2.8),\n(ii) for any $T>0$ and for any strong solution $u \\in \\operatorname{MR}(0, T)$ to (2.8) it holds that $T \\leq T_{*}$ and $u=u_{*}$ on $[0, T]$.\n\nNote that maximal solutions are unique by definition. The proof of the next proposition is adapted from [22, Th. 18.2.14, Th. 18.2.15] and [36].\n\nProposition 3.15 (Blow-up criterion). Let $x \\in H$ and $\\psi \\in L_{\\mathrm{loc}}^{2}\\left(\\mathbb{R}_{+} ; U\\right)$. Suppose that $(A, B)$ satisfies Assumption 2.2. Then equation (2.8) has a maximal solution $\\left(u_{*}, T_{*}\\right)$. Moreover, if $T_{*}<\\infty$ and $\\sup _{T \\in\\left[0, T_{*}\\right)}\\left\\|u_{*}\\right\\|_{L^{2}\\left(0, T ; V\\right)}<\\infty$, then $\\lim _{t \\uparrow T_{*}} u_{*}(t)$ does not exist in $H$.\n\nProof. The proof of Theorem 3.7 (with $u_{0}=v_{0}=x$ ) shows that there exists a local solution and that any strong solution on any finite time interval is unique. Hence, there exists a maximal solution $\\left(u_{*}, T_{*}\\right)$ for some $T_{*} \\in(0, \\infty]$ and $u_{*} \\in \\operatorname{MR}_{\\mathrm{loc}}\\left(0, T_{*}\\right)$.\n\nSuppose that $T_{*}<\\infty, \\sup _{T \\in\\left[0, T_{*}\\right)}\\left\\|u_{*}\\right\\|_{L^{2}(0, T ; V)}<\\infty$ and $u^{*} \\vDash \\lim _{t \\uparrow T_{*}} u_{*}(t)$ does exist in $H$. We will derive a contradiction. Note that the second assumption implies $u_{*} \\in L^{2}\\left(0, T_{*} ; V\\right)$.\n\nBy Theorem 3.7, there exists $\\delta>0$ and a strong solution $u \\in \\operatorname{MR}\\left(T_{*}, T_{*}+\\delta\\right)$ to\n\n$$\n\\begin{cases}u^{\\prime}+\\tilde{A}(u) u=\\tilde{F}(u) & \\text { on }\\left[T_{*}, T_{*}+\\delta\\right] \\\\ u\\left(T_{*}\\right)=u^{*} & \\end{cases}\n$$\n\nwhere we use that the translated pair $\\left(A\\left(T_{*}+\\cdot, \\cdot\\right), B\\left(T_{*}+\\cdot, \\cdot\\right)\\right)$ also satisfies Assumption 2.2. Then\n\n$$\n\\bar{u}(t) \\vDash \\begin{cases}u_{*}(t), & t \\in\\left[0, T_{*}\\right) \\\\ u(t), & t \\in\\left[T_{*}, T_{*}+\\delta\\right]\\end{cases}\n$$\n\nsatisfies $\\bar{u} \\in \\operatorname{MR}\\left(0, T_{*}+\\delta\\right)$ and $\\bar{u}$ is a strong solution to (3.10) on $\\left[0, T_{*}+\\delta\\right]$, contradicting maximality of $\\left(u_{*}, T_{*}\\right)$.\n\nUsing the blow-up criterion, we finally prove global well-posedness for the skeleton equation. Besides Assumption 2.2, we now also assume the coercivity condition (2.7) for the pair $(A, B)$. This condition has not been used so far, but it is also needed for the global well-posedness result for the stochastic evolution equation [6, Th. 3.5], see Theorem 2.3.\nTheorem 3.16 (Global well-posedness skeleton equation). Suppose that $(A, B)$ satisfies Assumption 2.2 and coercivity (2.7). Then for any $\\psi \\in L_{\\mathrm{loc}}^{2}\\left(\\mathbb{R}_{+} ; U\\right), x \\in H$ and $T>0$, there exists a unique strong solution $u \\in \\operatorname{MR}(0, T)$ to (2.8). Moreover,\n\n$$\n\\|u\\|_{\\operatorname{MR}(0, T)} \\leq\\left(2+\\frac{1}{\\theta}\\right)^{\\frac{1}{2}}\\left(\\|x\\|_{H}+\\sqrt{2}\\|\\phi\\|_{L^{2}(0, T)}\\right) \\exp \\left[M T+\\frac{1}{2}\\|\\psi\\|_{L^{2}(0, T ; U)}^{2}\\right]\n$$\n\nwhere $\\theta, M>0$ and $\\phi \\in L^{2}(0, T)$ are such that (2.7) holds for $t \\in[0, T]$.\nProof. By Proposition 3.15 we have a maximal solution $\\left(u_{*}, T_{*}\\right)$ to (2.8). If $T_{*}=\\infty$, then wellposedness for every $T>0$ follows. Suppose that $T_{*}<\\infty$. We will derive a contradiction. Let $\\theta, M>0$ and $\\phi \\in L^{2}\\left(0, T_{*}\\right)$ be such that the coercivity condition (2.7) holds with $T=T^{*}$. By definition of the maximal solution, $\\left.u_{*}\\right|_{[0, T]}$ is a strong solution to (2.8) on $[0, T]$ for all $T \\in\\left[0, T_{*}\\right)$. The chain rule (A.2) thus gives for all $t \\in\\left[0, T_{*}\\right)$ :\n\n$$\n\\begin{aligned}\n\\left\\|u_{*}(t)\\right\\|_{H}^{2}=\\|x\\|_{H}^{2}+2 \\int_{0}^{t}\\left\\langle-A\\left(s, u_{*}(s)\\right), u_{*}(s)\\right\\rangle+\\left\\langle B\\left(s, u_{*}(s)\\right) \\psi(s), u_{*}(s)\\right\\rangle \\mathrm{d} s \\\\\n\\leq\\|x\\|_{H}^{2}+2 \\int_{0}^{t}-\\frac{1}{2}\\left\\|B\\left(s, u_{*}(s)\\right)\\right\\|_{H}^{2}-\\theta\\left\\|u_{*}(s)\\right\\|_{V}^{2}+M\\left\\|u_{*}(s)\\right\\|_{H}^{2}+|\\phi(s)|^{2} \\\\\n+\\left\\|B\\left(s, u_{*}(s)\\right)\\right\\|_{H}\\|\\psi(s)\\|_{U}\\left\\|u_{*}(s)\\right\\|_{H} \\mathrm{~d} s \\\\\n\\leq\\|x\\|_{H}^{2}+2 \\int_{0}^{t}-\\frac{1}{2}\\left\\|B\\left(s, u_{*}(s)\\right)\\right\\|_{H}^{2}-\\theta\\left\\|u_{*}(s)\\right\\|_{V}^{2}+M\\left\\|u_{*}(s)\\right\\|_{H}^{2}+|\\phi(s)|^{2} \\\\\n+\\frac{1}{2}\\left\\|B\\left(s, u_{*}(s)\\right)\\right\\|_{H}^{2}+\\frac{1}{2}\\|\\psi(s)\\|_{U}^{2}\\left\\|u_{*}(s)\\right\\|_{H}^{2} \\mathrm{~d} s \\\\\n=-2 \\theta\\left\\|u_{*}\\right\\|_{L^{2}(0, t ; V)}^{2}+\\|x\\|_{H}^{2}+2\\|\\phi\\|_{L^{2}(0, t)}^{2}+\\int_{0}^{t}\\left(2 M+\\|\\psi(s)\\|_{U}^{2}\\right)\\left\\|u_{*}(s)\\right\\|_{H}^{2} \\mathrm{~d} s\n\\end{aligned}\n$$\n\nBy Lemma A.1(Gronwall), we obtain for all $T \\in\\left(0, T_{*}\\right)$ :\n\n$$\n\\left\\|u_{*}\\right\\|_{C([0, T] ; H)}^{2}+\\left\\|u_{*}\\right\\|_{L^{2}(0, T ; V)}^{2} \\leq\\left(1+\\frac{1}{2 \\theta}\\right)\\left(\\|x\\|_{H}^{2}+2\\|\\phi\\|_{L^{2}(0, T)}^{2}\\right) \\exp \\left[2 M T+\\|\\psi\\|_{L^{2}(0, T ; U)}^{2}\\right]\n$$\n\nhence\n\n$$\n\\left\\|u_{*}\\right\\|_{\\operatorname{MR}(0, T)} \\leq\\left(2+\\frac{1}{\\theta}\\right)^{\\frac{1}{2}}\\left(\\|x\\|_{H}+\\sqrt{2}\\|\\phi\\|_{L^{2}(0, T)}\\right) \\exp \\left[M T+\\frac{1}{2}\\|\\psi\\|_{L^{2}(0, T ; U)}^{2}\\right] \\Leftarrow K(T)\n$$\n\nwhere $K:\\left[0, T_{*}\\right] \\rightarrow \\mathbb{R}_{+}$is increasing. Applying Lemma 3.8(iv) with $n=K\\left(T_{*}\\right)<\\infty$ we find that $F\\left(u_{*}\\right) \\in L^{2}\\left(0, t ; V^{*}\\right)$ for all $t \\in\\left(0, T_{*}\\right)$ and $L:=\\sup _{t \\in\\left[0, T_{*}\\right)}\\left\\|F\\left(u_{*}\\right)\\right\\|_{L^{2}\\left(0, t ; V^{*}\\right)}<\\infty$. Thus,\n\nby the Monotone Convergence Theorem, $\\left\\|F\\left(u_{*}\\right)\\right\\|_{L^{2}\\left(0, T_{*} ; V^{*}\\right)} \\leq L<\\infty$. Similarly, $G\\left(u_{*}\\right) \\in$ $L^{2}\\left(0, T_{*} ; \\mathcal{L}_{2}(U, H)\\right)$. Now we apply Corollary 3.5 with $T:=T^{*}, w:=u_{*} \\in C\\left(\\left[0, T_{*}\\right) ; H\\right) \\subset$ $L^{\\infty}(0, T ; H)$ (extend by $w(T):=u_{*}(0)$ on the Lebesgue null set $\\{T\\}), n:=K\\left(T_{*}\\right)$ and $\\bar{f}:=$ $F\\left(u_{*}\\right)+f \\in L^{2}\\left(0, T_{*} ; V^{*}\\right), \\bar{g}:=G\\left(u_{*}\\right)+g \\in L^{2}\\left(0, T_{*} ; \\mathcal{L}_{2}(U, H)\\right)$. Corollary 3.5 gives existence of a strong solution $\\bar{u} \\in \\operatorname{MR}\\left(0, T_{*}\\right)$ to (2.8) on $\\left[0, T_{*}\\right]$. By uniqueness of the maximal solution, it follows that $\\left.u_{*}\\right|_{[0, T]}=\\left.\\bar{u}\\right|_{[0, T]}$ for all $T \\in\\left[0, T_{*}\\right)$. Hence $\\lim _{t \\uparrow T_{*}} u_{*}(t)=\\lim _{t \\uparrow T_{*}} \\bar{u}(t)=\\bar{u}\\left(T_{*}\\right) \\in H$, contradicting Proposition 3.15.\n\nWe conclude that the assumption $T_{*}<\\infty$ was false, i.e. $T_{*}=\\infty$ and for any $T>0, u:=$ $\\left.u_{*}\\right|_{[0, T]} \\in \\operatorname{MR}(0, T)$ is the desired strong solution on $[0, T]$. Finally, note that the estimates leading to (3.31) can be repeated with $\\theta, M, \\phi$ of the coercivity condition belonging to $T$ instead of $T_{*}$, proving (3.30).", "tables": {}, "images": {}}, {"section_id": 6, "text": "# 4. Proof of the large Deviation Principle \n\n4.1. Weak convergence approach. We return to our original setting of Section 2 and start with the proof of the LDP of Theorem 2.6. From now on, assume that $U$ is a real separable Hilbert space and $\\left(\\Omega, \\mathcal{F}, \\mathbb{P},\\left(\\mathcal{F}_{t}\\right)_{t \\geq 0}\\right)$ is a filtered probability space. For $\\varepsilon>0$, we let $Y^{\\varepsilon}$ be the unique strong solution to\n\n$$\n\\left\\{\\begin{array}{l}\n\\mathrm{d} Y^{\\varepsilon}(t)=-A\\left(t, Y^{\\varepsilon}(t)\\right)+\\sqrt{\\varepsilon} B\\left(t, Y^{\\varepsilon}(t)\\right) \\mathrm{d} W(t), \\quad t \\in[0, T] \\\\\nY^{\\varepsilon}(0)=x\n\\end{array}\\right.\n$$\n\nHere, $W$ is a $U$-cylindrical Brownian motion, which is defined as follows.\nDefinition 4.1. Let $W \\in \\mathcal{L}\\left(L^{2}\\left(\\mathbb{R}_{+} ; U\\right), L^{2}(\\Omega)\\right)$. Then $W$ is called a $U$-cylindrical Brownian motion with respect to $\\left(\\Omega, \\mathcal{F}, \\mathbb{P},\\left(\\mathcal{F}_{t}\\right)_{t \\geq 0}\\right)$ if for all $f, g \\in L^{2}\\left(\\mathbb{R}_{+} ; U\\right)$ and $t \\in \\mathbb{R}_{+}$:\n(i) $W f$ is normally distributed with mean zero and $\\mathbb{E}[W f W g]=\\langle f, g\\rangle_{L^{2}\\left(\\mathbb{R}_{+}\\right ; U)}$,\n(ii) if $\\operatorname{supp}(f) \\subset[0, t]$, then $W f$ is $\\mathcal{F}_{t}$-measurable,\n(iii) if $\\operatorname{supp}(f) \\subset[t, \\infty)$, then $W f$ is independent of $\\mathcal{F}_{t}$.\n\nThere exist several different definitions of a cylindrical Brownian motion or cylindrical Wiener process in the literature. Some references in our proof of the LDP use (an equivalent of) an $\\mathbb{R}^{\\infty}$-Brownian motion, defined below.\nDefinition 4.2. An $\\mathbb{R}^{\\infty}$-Brownian motion (in $U$ ) is a pair $\\tilde{W}:=\\left(\\left(\\beta_{k}\\right)_{k \\in \\mathbb{N}},\\left(e_{k}\\right)_{k \\in \\mathbb{N}}\\right)$, with $\\left(\\beta_{k}\\right)_{k \\in \\mathbb{N}}$ a sequence of independent standard real-valued $\\left(\\mathcal{F}_{t}\\right)$-Brownian motions and $\\left(e_{k}\\right)_{k \\in \\mathbb{N}}$ an orthonormal basis for $U$.\n\nIn Proposition A. 4 of Appendix A, the connection between the $U$-cylindrical Brownian motion and the $\\mathbb{R}^{\\infty}$-Brownian motion is summarized, as well as their equivalent, but differently constructed stochastic integrals. The $\\mathbb{R}^{\\infty}$-Brownian motion of Definition 4.2 is e.g. used in [29], where it is called a cylindrical $Q$-Wiener process (with $Q:=I \\in \\mathcal{L}(U ; U)$ the identity operator). Often, the notation $\\tilde{W}(t)=\\sum_{k \\in \\mathbb{N}} \\beta_{k}(t) e_{k}$ is also used, which is only formal as the series does not converge in $L^{2}(\\Omega ; U)$. However, we will write $\\tilde{W}=\\left(\\left(\\beta_{k}\\right)_{k \\in \\mathbb{N}},\\left(e_{k}\\right)_{k \\in \\mathbb{N}}\\right)$.\nRemark 4.3. For the proof of the LDP for $\\left(Y^{\\varepsilon}\\right)$, without loss of generality, we can assume that the filtration $\\left(\\mathcal{F}_{t}\\right)_{t \\geq 0}$ is right-continuous and complete. Indeed, one can fix any orthonormal basis $\\left(e_{k}\\right)_{k \\in \\mathbb{N}}$ of $U$ and put $\\mathcal{H}_{t}^{k}:=\\sigma\\left(W\\left(\\mathbb{1}_{(0, s]} \\otimes e_{k}\\right): s \\in[0, t]\\right)$ for $k \\in \\mathbb{N}$ and\n\n$$\n\\mathcal{F}_{t}^{0}:=\\sigma\\left(\\bigcup_{k \\in \\mathbb{N}} \\mathcal{H}_{t}^{k}\\right), \\quad \\mathcal{H}_{t}^{0}:=\\sigma\\left(\\bigcup_{k \\in \\mathbb{N}} \\mathcal{H}_{t}^{k} \\cup \\mathcal{N}\\right), \\quad \\mathcal{H}_{t}:=\\mathcal{H}_{t^{+}}^{0}:=\\bigcap_{h>0} \\mathcal{H}_{t+h}^{0}\n$$\n\nwhere $\\mathcal{N}$ is the collection of all $\\left(\\Omega, \\mathcal{F}, \\mathbb{P}\\right)$-null sets. Then $\\left(\\mathcal{H}_{t}\\right)_{t \\geq 0}$ is a complete, right-continuous filtration on $\\left(\\Omega, \\overline{\\mathcal{F}}, \\overline{\\mathbb{P}}\\right)$. Moreover, one can show that $W$ is a $U$-cylindrical Brownian motion with respect to $\\left(\\Omega, \\overline{\\mathcal{F}}, \\overline{\\mathbb{P}},\\left(\\mathcal{H}_{t}\\right)_{t \\geq 0}\\right)$ and with respect to $\\left(\\Omega, \\mathcal{F}, \\mathbb{P},\\left(\\mathcal{F}_{t}^{0}\\right)_{t \\geq 0}\\right)$. Let $Y_{0}^{\\varepsilon}$ and $\\bar{Y}^{\\varepsilon}$ be the unique strong solution to (4.1) on $\\left(\\Omega, \\mathcal{F}, \\mathbb{P},\\left(\\mathcal{F}_{t}^{0}\\right)_{t \\geq 0}\\right)$ and $\\left(\\Omega, \\overline{\\mathcal{F}}, \\overline{\\mathbb{P}},\\left(\\mathcal{H}_{t}\\right)_{t \\geq 0}\\right)$, respectively. Since $\\mathcal{F}_{t}^{0} \\subset$ $\\mathcal{F}_{t} \\cap \\mathcal{H}_{t}, Y_{0}^{\\varepsilon}$ is also a strong solution to (4.1) on $\\left(\\Omega, \\mathcal{F}, \\mathbb{P},\\left(\\mathcal{F}_{t}\\right)_{t \\geq 0}\\right)$ and on $\\left(\\Omega, \\overline{\\mathcal{F}}, \\overline{\\mathbb{P}},\\left(\\mathcal{H}_{t}\\right)_{t \\geq 0}\\right)$. Pathwise uniqueness gives $Y^{\\varepsilon}=Y_{0}^{\\varepsilon}=\\bar{Y}^{\\varepsilon} \\mathbb{P}$-a.s. Now trivially from Definition 2.4, if we prove the LDP for $\\left(\\bar{Y}^{\\varepsilon}\\right)$, then the LDP carries over to $\\left(Y^{\\varepsilon}\\right)$.\n\nIn view of the above remark, we assume that the filtration $\\left(\\mathcal{F}_{t}\\right)_{t \\geq 0}$ is right-continuous and complete from now on, and we assume that $W$ is a $U$-cylindrical Brownian motion with respect to $\\left(\\mathcal{F}_{t}\\right)_{t \\geq 0}$. Moreover, we fix any orthonormal basis $\\left(e_{k}\\right)_{k \\in \\mathbb{N}}$ for $U$. We let $\\tilde{W}=\\left(\\beta_{k}\\right)_{k \\in \\mathbb{N}},\\left(e_{k}\\right)_{k \\in \\mathbb{N}}$ denote the unique $\\mathbb{R}^{\\infty}$-Brownian motion associated to $W$ from Proposition A.4, i.e. satisfying (A.6). In the upcoming proofs $\\tilde{W}$ will be useful, since we will be applying the Yamada-Watanabe theorem and Girsanov's theorem for $\\mathbb{R}^{\\infty}$-Brownian motions. Finally, from now on we fix a separable Hilbert space $U_{1}$ and a Hilbert-Schmidt inclusion $J: U \\hookrightarrow U_{1}$. This is always possible: let $\\langle u, v\\rangle_{1}:=\\sum_{k=1}^{\\infty} \\frac{1}{k}\\left\\langle u, e_{k}\\right\\rangle_{U}\\left\\langle e_{k}, v\\right\\rangle_{U}$ for $u, v \\in U$ and let $U_{1}:=$ completion $\\left(U,\\langle\\cdot, \\cdot\\rangle_{1}\\right)$. We associate to $\\tilde{W}$ the following $U_{1}$-valued process:\n\n$$\n\\tilde{W}_{1}(t):=\\sum_{k=1}^{\\infty} \\beta_{k}(t) J e_{k}, \\quad t \\in[0, T]\n$$\n\nBy [29, Prop. 2.5.2], $\\tilde{W}_{1}$ is a $Q_{1}$-Wiener process on $U_{1}$, with $Q_{1}:=J J^{*}$. In what follows, $\\tilde{W}_{1}$ denotes this $Q_{1}$-Wiener process defined by (4.2). We note that the paths of $\\tilde{W}_{1}$ are in $C\\left([0, T] ; U_{1}\\right)$.\n\nDefinition 4.4. We define\n\n$$\n\\mathcal{A}:=\\left\\{\\Psi:[0, T] \\times \\Omega \\rightarrow U: \\Psi \\text { is an }\\left(\\mathcal{F}_{t}\\right) \\text {-predictable process, }\\|\\Psi\\|_{L^{2}(0, T ; U)}<\\infty \\mathbb{P} \\text {-a.s. }\\right\\}\n$$\n\nand for $K>0$,\n\n$$\nS_{K}:=\\left\\{\\psi \\in L^{2}(0, T ; U):\\|\\psi\\|_{L^{2}(0, T ; U)} \\leq K\\right\\}, \\quad \\mathcal{A}_{K}:=\\left\\{\\Psi \\in \\mathcal{A}: \\Psi \\in S_{K} \\mathbb{P} \\text {-a.s. }\\right\\}\n$$\n\nWe write ( $S_{K}$, weak) for the topological space consisting of $S_{K}$, equipped with the weak topology inherited from $L^{2}(0, T ; U)$.\n\nThe next theorem gives sufficient conditions for the LDP and is known as the weak convergence approach, which originates from [9, Th. 4.4]. In [30], a useful adaptation was proved. The following version is immediately derived from [30, Th. 3.2]. We will use it to prove Theorem 2.6.\nTheorem 4.5. Let $\\mathcal{E}$ be a Polish space and let $\\left(Y^{\\varepsilon}\\right)_{\\varepsilon>0}$ be a collection of $\\mathcal{E}$-valued random variables on $(\\Omega, \\mathcal{F}, \\mathbb{P})$. Let $\\tilde{W}=\\left(\\left(\\beta_{k}\\right)_{k \\in \\mathbb{N}},\\left(e_{k}\\right)_{k \\in \\mathbb{N}}\\right)$ be an $\\mathbb{R}^{\\infty}$-Brownian motion. Let $\\tilde{W}_{1}: \\Omega \\rightarrow C\\left([0, T] ; U_{1}\\right)$ be the associated $Q_{1}$-Wiener process on $U_{1}$ defined by (4.2). Suppose that for $\\varepsilon \\geq 0$, there exist measurable maps $\\mathcal{G}^{\\varepsilon}: C\\left([0, T] ; U_{1}\\right) \\rightarrow \\mathcal{E}$ such that\n(i) $Y^{\\varepsilon}=\\mathcal{G}^{\\varepsilon}\\left(\\tilde{W}_{1}(\\cdot)\\right)$ a.s. for all $\\varepsilon>0$,\n(ii) for any $K<\\infty,\\left(\\psi_{n}\\right) \\subset S_{K}$ and $\\psi \\in S_{K}$ with $\\psi_{n} \\rightarrow \\psi$ weakly in $L^{2}(0, T ; U)$, it holds that\n\n$$\n\\mathcal{G}^{0}\\left(\\int_{0} \\psi_{n}(s) \\mathrm{d} s\\right) \\rightarrow \\mathcal{G}^{0}\\left(\\int_{0} \\psi(s) \\mathrm{d} s\\right) \\text { in } \\mathcal{E}\n$$\n\n(iii) for any $K<\\infty$ and $\\left(\\Psi^{\\varepsilon}\\right) \\subset \\mathcal{A}_{K}$, it holds that\n\n$$\n\\mathcal{G}^{\\varepsilon}\\left(\\tilde{W}_{1}(\\cdot)+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0} \\Psi^{\\varepsilon}(s) \\mathrm{d} s\\right)-\\mathcal{G}^{0}\\left(\\int_{0} \\Psi^{\\varepsilon}(s) \\mathrm{d} s\\right) \\rightarrow 0 \\text { in probability }\n$$\n\nas $\\mathcal{E}$-valued random variables.\nThen $\\left(Y^{\\varepsilon}\\right)_{\\varepsilon>0}$ satisfies the LDP on $\\mathcal{E}$ with good rate function\n\n$$\nI(z):=\\frac{1}{2} \\inf \\left\\{\\int_{0}^{T}\\|\\psi(s)\\|_{U}^{2} \\mathrm{~d} s: \\psi \\in L^{2}(0, T ; U), z=\\mathcal{G}^{0}\\left(\\int_{0} \\psi(s) \\mathrm{d} s\\right)\\right\\}\n$$\n\nConditions (ii) and (iii) imply the conditions of the original weak convergence approach of [9]. For the latter, instead of (ii) and (iii), one would require\n(II) for any $K<\\infty,\\left\\{\\mathcal{G}^{0}\\left(\\int_{0} \\psi(s) \\mathrm{d} s\\right): \\psi \\in S_{K}\\right\\}$ is a compact subset of $\\mathcal{E}$,\n(III) for any $K<\\infty$, if $\\left(\\Psi^{\\varepsilon}\\right) \\subset \\mathcal{A}_{K}$ with $\\Psi^{\\varepsilon} \\rightarrow \\Psi$ in distribution with respect to the weak topology on $L^{2}(0, T ; U)$, then $\\mathcal{G}^{\\varepsilon}\\left(\\tilde{W}_{1}(\\cdot)+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0} \\Psi^{\\varepsilon}(s) \\mathrm{d} s\\right) \\rightarrow \\mathcal{G}^{0}\\left(\\int_{0} \\Psi(s) \\mathrm{d} s\\right)$ in distribution.\n\nHere, $[9, \\mathrm{Th} .4 .4]$ is applied with $Q_{1}$-Wiener process $\\tilde{W}_{1}, H:=U_{1}, H_{0}:=Q_{1}^{\\frac{1}{2}}\\left(U_{1}\\right)$ and one uses that $Q_{1}^{\\frac{1}{2}}\\left(U_{1}\\right)=J(U)=U$ as a subspace of $U_{1}$, see [29, Prop. 2.5.2] (with $Q:=I, U_{0}:=I^{\\frac{1}{2}}(U)=U$ ).\n\nNote that (II) means that the sublevel sets of the rate function $I$ defined by (4.3) are compact, as is also required in Definition 2.4. On the other hand, (ii) means that the map $\\tau:\\left(S_{K}\\right.$, weak) $\\rightarrow$ $\\mathcal{E}: \\psi \\mapsto \\mathcal{G}^{0}\\left(\\int_{0} \\psi \\mathrm{~d} s\\right)=u^{\\psi}$ is continuous ( $S_{K}$ is weakly metrizable as opposed to $L^{2}(0, T ; U)$, thus sequential continuity suffices). In particular, this implies (II). Indeed, $S_{K} \\subset L^{2}(0, T ; U)$ is weakly compact by the Banach-Alaoglu theorem and reflexivity of $L^{2}(0, T ; U)$, so $\\left\\{\\mathcal{G}^{0}\\left(\\int_{0} \\psi(s) \\mathrm{d} s\\right): \\psi \\in\\right.$ $\\left.S_{K}\\right\\}=\\tau\\left(S_{K}\\right)$ is the continuous image of a compact set, hence it is compact.\n\nWe will apply Theorem 4.5 with the map $\\mathcal{G}^{0}: C\\left([0, T] ; U_{1}\\right) \\rightarrow \\operatorname{MR}(0, T)$ given by\n\n$$\n\\mathcal{G}^{0}(\\gamma):= \\begin{cases}u^{\\psi}, & \\text { if } \\gamma=\\int_{0} \\psi(s) \\mathrm{d} s, \\psi \\in L^{2}(0, T ; U) \\\\ 0, & \\text { otherwise }\\end{cases}\n$$\n\nwhere $u^{\\psi}$ is the strong solution to (2.8). Note that the rate function $I$ defined by (2.9) is then precisely equal to the rate function given by (4.3).\n\nWe will verify that all conditions in Theorem 4.5 are satisfied for $Y^{\\varepsilon}$ defined as the strong solution to (4.1). Condition (i) follows from the Yamada-Watanabe theorem in [40]. The details are given in Lemma 4.6, as well as a preparation for the proof of condition (iii).\n\nLemma 4.6. Suppose that Assumption 2.2 holds and suppose that $(A, B)$ satisfies (2.7). Let $x \\in H$. Then for each $\\varepsilon>0$, there exists a measurable map $\\mathcal{G}^{\\varepsilon}: C\\left([0, T] ; U_{1}\\right) \\rightarrow \\operatorname{MR}(0, T)$ such that the unique strong solution $Y^{\\varepsilon}$ to (4.1) satisfies $Y^{\\varepsilon}=\\mathcal{G}^{\\varepsilon}\\left(\\tilde{W}_{1}\\right)$ a.s., where $\\tilde{W}_{1}$ is given by (4.2). Moreover, for any $\\Psi^{\\varepsilon} \\in \\mathcal{A}_{K}, X^{\\varepsilon}:=\\mathcal{G}^{\\varepsilon}\\left(\\tilde{W}_{1}(\\cdot)+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0} \\Psi^{\\varepsilon}(s) \\mathrm{d} s\\right)$ is a strong solution to\n\n$$\n\\left\\{\\begin{array}{l}\n\\mathrm{d} X^{\\varepsilon}(t)=-A\\left(t, X^{\\varepsilon}(t)\\right)+B\\left(t, X^{\\varepsilon}(t)\\right) \\Psi^{\\varepsilon}(t)+\\sqrt{\\varepsilon} B\\left(t, X^{\\varepsilon}(t)\\right) \\mathrm{d} W(t), \\quad t \\in[0, T] \\\\\nX^{\\varepsilon}(0)=x\n\\end{array}\\right.\n$$\n\nProof. To prove the first statement, we use the Yamada-Watanabe theorem from [40, Th. 2.1] on $[0, T]$ with $L^{1}(0, T ; V)$ replaced by $L^{2}(0, T ; V)$. Let $\\varepsilon>0$. For any $Y^{\\varepsilon}$ with $Y^{\\varepsilon} \\in \\operatorname{MR}(0, T)$ a.s. and for any $\\xi \\in L^{0}\\left(\\left(\\Omega, \\mathcal{F}_{0}\\right) ; H\\right)$, we have that $\\left(Y^{\\varepsilon}, \\tilde{W}\\right)$ is a weak solution in the sense of [40, Def. $1.4]$ to\n\n$$\n\\left\\{\\begin{array}{l}\n\\mathrm{d} \\tilde{Y}^{\\varepsilon}(t)=-A\\left(t, \\tilde{Y}^{\\varepsilon}(t)\\right)+\\sqrt{\\varepsilon} B\\left(t, \\tilde{Y}^{\\varepsilon}(t)\\right) \\mathrm{d} \\tilde{W}(t) \\\\\n\\tilde{Y}^{\\varepsilon}(0)=\\xi\n\\end{array}\\right.\n$$\n\nif and only if $Y^{\\varepsilon}$ is a strong solution in the sense of $[6$, Def. 3.2] to (4.1) with $x$ replaced by $\\xi$. This is a mere consequence of (A.7) and the fact that $B(\\cdot, Y(\\cdot)) \\in L^{2}\\left(([0, T] \\times \\Omega, \\mathcal{P}, \\lambda \\times \\mathbb{P}) ; \\mathcal{L}_{2}(U, H)\\right) \\subset$ $\\mathcal{N}(0, T)$ for any $Y \\in \\operatorname{MR}(0, T)$. By [6, Th. 3.5], (4.1) has a unique strong solution $Y^{\\varepsilon}$, also when $x$ is replaced by random initial data $\\xi$. Thus we have pathwise uniqueness in the sense of [40, Def. 1.7] and we have existence of a.s. $\\operatorname{MR}(0, T)$-valued weak solutions. Now fix $x \\in H$ and $\\varepsilon>0$ and let $Y^{\\varepsilon}$ be the unique strong solution to (4.1). By [40, Th. 2.1, Def. 1.9(2), Def. 1.8] there exists a measurable map $\\mathcal{G}^{\\varepsilon}: C\\left([0, T] ; U_{1}\\right) \\rightarrow \\operatorname{MR}(0, T)$ such that a.s. $Y^{\\varepsilon}=\\mathcal{G}^{\\varepsilon}\\left(\\tilde{W}_{1}(\\cdot)\\right)$.\n\nNext, let $X^{\\varepsilon}:=\\mathcal{G}^{\\varepsilon}\\left(\\tilde{W}_{1}(\\cdot)+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0} \\Psi^{\\varepsilon}(s) \\mathrm{d} s\\right)$. We prove that $X^{\\varepsilon}$ solves (4.5). Define\n\n$$\n\\tilde{W}:=\\tilde{W}+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0} \\Psi^{\\varepsilon}(s) \\mathrm{d} s:=\\left(\\left(\\hat{\\beta}_{k}\\right)_{k \\in \\mathbb{N}},\\left(e_{k}\\right)_{k \\in \\mathbb{N}}\\right), \\quad \\hat{\\beta}_{k}:=\\beta_{k}+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0}\\left\\langle\\Psi^{\\varepsilon}(s), e_{k}\\right\\rangle_{U} \\mathrm{~d} s\n$$\n\nWe have $\\mathbb{E}\\left[\\exp \\left(\\frac{1}{2}\\left\\|-\\frac{1}{\\sqrt{\\varepsilon}} \\Psi^{\\varepsilon}\\right\\|_{L^{2}(0, T ; U)}^{2}\\right)\\right] \\leq \\exp \\left(\\frac{K^{2}}{2 \\varepsilon}\\right)<\\infty$, so by Novikov's condition [24, Prop. 5.12],\n\n$$\n\\mathbb{E}\\left[\\exp \\left(\\int_{0}^{T}\\left\\langle-\\frac{1}{\\sqrt{\\varepsilon}} \\Psi^{\\varepsilon}(s), \\mathrm{d} \\tilde{W}(s)\\right\\rangle_{U}-\\frac{1}{2}\\left\\|\\frac{1}{\\sqrt{\\varepsilon}} \\Psi^{\\varepsilon}\\right\\|_{L^{2}(0, T ; U)}^{2}\\right)\\right]=1\n$$\n\nNow Girsanov's theorem [29, Proposition I.0.6], [17, Th. 2.3] yields that $\\tilde{W}$ is an $\\mathbb{R}^{\\infty}$-Brownian motion on $\\left(\\Omega, \\mathcal{F}, \\dot{\\mathbb{P}},\\left(\\mathcal{F}_{t}\\right)_{t \\geq 0}\\right)$, where\n\n$$\n\\dot{\\mathbb{P}}:=\\exp \\left(-\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0}^{T}\\left\\langle\\Psi^{\\varepsilon}(s), \\mathrm{d} \\tilde{W}(s)\\right\\rangle_{U}-\\frac{1}{2 \\varepsilon}\\left\\|\\Psi^{\\varepsilon}\\right\\|_{L^{2}(0, T ; U)}^{2}\\right) \\mathrm{d} \\mathbb{P}\n$$\n\nMoreover, $\\hat{W}$ induces a $U_{1}$-valued $Q_{1}$-Wiener process $\\hat{W}_{1}$ on $\\left(\\Omega, \\mathcal{F}, \\hat{\\mathbb{P}},\\left(\\mathcal{F}_{t}\\right)_{t \\geq 0}\\right)$ using the same Hilbert-Schmidt inclusion $J: U \\hookrightarrow U_{1}$ as we used for $\\hat{W}_{1}$ in (4.2), resulting in:\n\n$$\n\\begin{aligned}\n\\hat{W}_{1}(t):=\\sum_{k \\in \\mathbb{N}} \\hat{\\beta}_{k}(t) J e_{k} & =\\sum_{k \\in \\mathbb{N}} \\beta_{k}(t) J e_{k}+\\frac{1}{\\sqrt{\\varepsilon}} \\sum_{k \\in \\mathbb{N}}\\left(\\int_{0}^{t}\\left\\langle\\Psi^{\\varepsilon}(s), e_{k}\\right\\rangle_{U} \\mathrm{~d} s\\right) J e_{k} \\\\\n& =\\hat{W}_{1}(t)+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0}^{t} \\sum_{k \\in \\mathbb{N}}\\left\\langle\\Psi^{\\varepsilon}(s), e_{k}\\right\\rangle_{U} e_{k} \\mathrm{~d} s \\\\\n& =\\hat{W}_{1}(t)+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0}^{t} \\Psi^{\\varepsilon}(s) \\mathrm{d} s\n\\end{aligned}\n$$\n\n$\\mathbb{P}$-a.s. in $U_{1}$, where we used that $\\Psi^{\\varepsilon} \\in \\mathcal{A}_{K}$ to apply Fubini's theorem in the second line. Thus, recalling the definition of $X^{\\varepsilon}$ and noting that $\\hat{\\mathbb{P}} \\ll \\mathbb{P} \\ll \\hat{\\mathbb{P}}$, we have $\\hat{\\mathbb{P}}$-a.s. $X^{\\varepsilon}=\\mathcal{G}^{\\varepsilon}\\left(\\hat{W}_{1}(\\cdot)\\right)$. By the Yamada-Watanabe theorem [40, Th. 2.1, Def. 1.9], for $X^{\\varepsilon}=\\mathcal{G}^{\\varepsilon}\\left(\\hat{W}_{1}(\\cdot)\\right)$ we have that $\\left(X^{\\varepsilon}, \\hat{W}\\right)$ is a weak solution to (4.1). That is, $X^{\\varepsilon}$ satisfies $\\hat{\\mathbb{P}}$-a.s. in $V^{*}$ :\n\n$$\nX^{\\varepsilon}(t)=x+\\int_{0}^{t}-A\\left(s, X^{\\varepsilon}(s)\\right) \\mathrm{d} s+\\int_{0}^{t} \\sqrt{\\varepsilon} B\\left(s, X^{\\varepsilon}(s)\\right) \\mathrm{d} \\hat{W}(s)\n$$\n\nBy Proposition A.4, there exists a unique $U$-cylindrical Brownian motion $\\hat{\\mathcal{W}} \\in \\mathcal{L}\\left(L^{2}\\left(\\mathbb{R}_{+} ; U\\right) ; L^{2}(\\Omega)\\right)$ with respect to $\\left(\\Omega, \\mathcal{F}, \\hat{\\mathbb{P}},\\left(\\mathcal{F}_{t}\\right)_{t \\geq 0}\\right)$, satisfying for all $u \\in U$ and $t \\in[0, T]$ :\n\n$$\n\\hat{\\mathcal{W}}\\left(\\mathbb{1}_{(0, t]} \\otimes u\\right)=\\sum_{k=1}^{\\infty} \\hat{\\beta}_{k}(t)\\left\\langle u, e_{k}\\right\\rangle_{U}=W\\left(\\mathbb{1}_{(0, t]} \\otimes u\\right)+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0}^{t}\\left\\langle\\Psi^{\\varepsilon}(s), u\\right\\rangle_{U} \\mathrm{~d} s\n$$\n\nwhere the last equality follows from the definition of $\\hat{\\beta}_{k}$ and (A.6). Let $\\hat{\\mathcal{N}}(0, T)$ denote the stochastically integrable processes with respect to $\\hat{\\mathcal{W}}$ and $\\hat{W}$ on $\\left(\\Omega, \\mathcal{F}, \\hat{\\mathbb{P}},\\left(\\mathcal{F}_{t}\\right)_{t \\geq 0}\\right)$, i.e. (A.3) with $\\mathbb{P}$ replaced by $\\hat{\\mathbb{P}}$. Note that $\\hat{\\mathcal{N}}(0, T)=\\mathcal{N}(0, T)$, since $\\mathbb{P} \\ll \\hat{\\mathbb{P}} \\ll \\mathbb{P}$. Thus, Proposition A. 4 gives $\\int_{0}^{t} \\Phi(s) \\mathrm{d} \\hat{\\mathcal{W}}(s)=\\int_{0}^{t} \\Phi(s) \\mathrm{d} \\hat{W}(s) \\hat{\\mathbb{P}}$-a.s. for all $\\Phi \\in \\mathcal{N}(0, T)$ and $t \\in[0, T]$. Therefore, combined with (4.6), $X^{\\varepsilon}$ satisfies $\\hat{\\mathbb{P}}$-a.s. (hence $\\mathbb{P}$-a.s.) in $V^{*}$ :\n\n$$\n\\begin{aligned}\nX^{\\varepsilon}(t) & =x+\\int_{0}^{t}-A\\left(s, X^{\\varepsilon}(s)\\right) \\mathrm{d} s+\\int_{0}^{t} \\sqrt{\\varepsilon} B\\left(s, X^{\\varepsilon}(s)\\right) \\mathrm{d} \\hat{\\mathcal{W}}(s) \\\\\n& =x+\\int_{0}^{t}-A\\left(s, X^{\\varepsilon}(s)\\right) \\mathrm{d} s+\\int_{0}^{t} \\sqrt{\\varepsilon} B\\left(s, X^{\\varepsilon}(s)\\right) \\mathrm{d} W(s)+\\int_{0}^{t} B\\left(s, X^{\\varepsilon}(s)\\right) \\Psi^{\\varepsilon}(s) \\mathrm{d} s\n\\end{aligned}\n$$\n\nIn the last line we used that $\\int_{0}^{t} \\Phi(s) \\mathrm{d} \\hat{\\mathcal{W}}(s)=\\int_{0}^{t} \\Phi(s) \\mathrm{d} W(s)+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0}^{t} \\Phi(s) \\Psi^{\\varepsilon}(s) \\mathrm{d} s$ for $\\Phi \\in \\mathcal{N}(0, T)$ and $t \\in[0, T]$. For $\\Phi=\\mathbb{1}_{A \\times\\left(t_{1}, t_{2}\\right]} \\otimes(u \\otimes x)$ with $0 \\leq t_{1}<t_{2} \\leq T, A \\in \\mathcal{F}_{t_{1}}, u \\in U, x \\in H$, the identity follows from (4.7) and the definition of the stochastic integral for elementary processes [31, p. 305]. By linearity and continuity of the integrals and by a density argument and localization, the identity extends for $\\Phi \\in \\mathcal{N}(0, T)$. This finishes the proof of the last claim of the lemma.\n\nRemark 4.7. The above proof also yields existence and uniqueness of strong solutions to (4.5), since it was actually shown that $X^{\\varepsilon}$ is a strong solution to (4.5) if and only if it is a strong solution to (4.1) with $W$ replaced by the $U$-cylindrical Brownian motion $\\hat{\\mathcal{W}}$. The latter was already considered in Theorem 2.3.\n4.2. Weakly continuous dependence in the skeleton equation. In this subsection we prove that condition (ii) of Theorem 4.5 is satisfied. This will be achieved in the upcoming Proposition 4.9. Its proof was inspired by [20, Th. 3.2]. Using an additional approximation by Bochner-simple functions, we can omit the time(-H\u00f6lder) regularity assumptions on $B$ of [20, (H5)].\n\nLemma 4.8. Let $\\left(w_{n}\\right) \\subset C([0, T] ; H),\\left(\\alpha_{n}\\right) \\subset L^{1}\\left(0, T ; V^{*}\\right)$ and $\\left(\\psi_{n}\\right) \\subset L^{2}(0, T ; U)$ be such that\n\n$$\nw_{n}(t)=\\int_{0}^{t} \\alpha_{n}(s) \\mathrm{d} s\n$$\n\nand such that $C_{\\alpha}:=\\sup _{n \\in \\mathbb{N}}\\left\\|\\alpha_{n}\\right\\|_{L^{1}\\left(0, T ; V^{*}\\right)}<\\infty, C_{w}:=\\sup _{n \\in \\mathbb{N}}\\left\\|w_{n}\\right\\|_{C([0, T] ; H)}<\\infty$ and $\\psi_{n} \\rightarrow \\psi$ weakly in $L^{2}(0, T ; U)$. Let $b \\in L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)$. Then,\n\n$$\n\\lim _{n \\rightarrow \\infty} \\sup _{t \\in[0, T]}\\left|\\int_{0}^{t}\\left\\langle b(s)\\left(\\psi_{n}(s)-\\psi(s)\\right), w_{n}(s)\\right\\rangle \\mathrm{d} s\\right|=0\n$$\n\nProof. Without loss of generality, we can assume $\\psi=0$, i.e. $\\psi_{n} \\rightarrow 0$ weakly in $L^{2}(0, T ; U)$ (apply to $\\left.\\psi_{n}-\\psi\\right)$. Since $\\left(\\psi_{n}\\right)$ is weakly convergent, it is bounded. Throughout the proof we let\n\n$$\nC_{\\psi}:=\\sup _{n \\in \\mathbb{N}}\\left\\|\\psi_{n}\\right\\|_{L^{2}(0, T ; U)}<\\infty\n$$\n\nFirst, let us observe that it suffices to prove (4.8) for all $b$ in the collection\n\n$$\n\\mathcal{S}:=\\left\\{\\mathbb{1}_{D} \\otimes u \\otimes v: D \\in \\mathcal{B}([0, T]), u \\in U, v \\in V\\right\\} \\subset L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)\n$$\n\nwhere $\\left(\\mathbb{1}_{D} \\otimes u \\otimes v\\right)(t) x:=\\mathbb{1}_{D}(t)(u, x)_{U} v \\in H$ for $t \\in[0, T]$ and $x \\in U$. Note that $\\operatorname{span}(\\mathcal{S})$ is dense in $L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)$, using consecutively density of Bochner-simple functions, density of finite rank operators in $\\mathcal{L}_{2}(U, H)$ and density of $V$ in $H$. Define for $n \\in \\mathbb{N}$ :\n\n$$\nI_{n}: L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right) \\rightarrow C([0, T] ; \\mathbb{R}), I_{n}(b):=\\int_{0}\\left\\langle b(s) \\psi_{n}(s), w_{n}(s)\\right\\rangle \\mathrm{d} s\n$$\n\nEach $I_{n}$ is linear and continuous with $\\left\\|I_{n}\\right\\| \\leq C_{\\psi} C_{w}$, independent of $n$ :\n(4.9) $\\left\\|I_{n}(b)\\right\\|_{C([0, T] ; \\mathbb{R})} \\leq\\|b\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)}\\left\\|\\psi_{n}\\right\\|_{L^{2}\\left(0, T ; U\\right)}\\left\\|w_{n}\\right\\|_{C(0, T ; H)} \\leq\\|b\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)} C_{\\psi} C_{w}$.\n\nIf (4.8) holds for all $b \\in \\mathcal{S}$, i.e. $\\lim _{n \\rightarrow \\infty}\\left\\|I_{n}(b)\\right\\|_{C([0, T] ; \\mathbb{R})}=0$, then it also holds for all $b \\in \\operatorname{span}(\\mathcal{S})$, by the triangle inequality in $C([0, T] ; \\mathbb{R})$. Moreover, for $b \\in L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)$, we find $\\left(b_{k}\\right) \\subset$ $\\operatorname{span}(\\mathcal{S})$ with $b_{k} \\rightarrow b$ in $L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)$ by density. Now (4.9) and a standard $2 \\varepsilon$-argument yield (4.8) for $b$.\n\nIt remains to prove (4.8) for $b=\\mathbb{1}_{D} \\otimes u \\otimes v$ with $D \\in \\mathcal{B}([0, T]), u \\in U$ and $v \\in V$. Note that in this case,\n\n$$\nI_{n}(b)=\\int_{0} \\mathbb{1}_{D}(s)\\left(u, \\psi_{n}(s)\\right)_{U}\\left\\langle v, w_{n}(s)\\right\\rangle \\mathrm{d} s\n$$\n\nand we have\n\n$$\n\\left(v, w_{n}(s)\\right)_{H}=\\left\\langle v, w_{n}(s)\\right\\rangle=\\int_{0}^{t}\\left\\langle\\alpha_{n}(s), v\\right\\rangle \\mathrm{d} s\n$$\n\nSince $u$ and $v$ are fixed, we have $\\left(v, w_{n}(\\cdot)\\right)_{H} \\in C([0, T] ; \\mathbb{R})$ and $\\left\\langle\\alpha_{n}(\\cdot), v\\right\\rangle \\in L^{1}(0, T)$ with norms uniformly bounded in $n$. Moreover, $\\left(u, \\psi_{n}(\\cdot)\\right)_{U} \\in L^{2}(0, T)$ and $\\psi_{n} \\rightarrow 0$ weakly in $L^{2}(0, T ; U)$ implies $\\left(u, \\psi_{n}(\\cdot)\\right)_{U} \\rightarrow 0$ weakly in $L^{2}(0, T)$. Combined with (4.10), we conclude that it suffices to prove the lemma for $U=V=H=V^{*}=\\mathbb{R}$ and $b=\\mathbb{1}_{D} \\in L^{2}(0, T)=L^{2}\\left(0, T ; \\mathcal{L}_{2}(\\mathbb{R} ; \\mathbb{R})\\right)$.\n\nLet $\\left(w_{n}\\right),\\left(\\alpha_{n}\\right),\\left(\\psi_{n}\\right)$ be as in the statement, now real-valued, and with $\\psi=0$. Define $I^{n}(t):=$ $\\int_{0}^{t} \\mathbb{1}_{D}(s) \\psi_{n}(s) w_{n}(s) \\mathrm{d} s$. We have to show that $\\lim _{n \\rightarrow \\infty} \\sup _{t \\in[0, T]}\\left|I^{n}(t)\\right|=0$.\n\nWe use an equidistant time discretization to approximate $w_{n}$. For $\\delta>0$ and $t \\in[0, T]$, put $t_{\\delta}:=\\left\\lfloor\\frac{1}{\\delta}\\right\\rfloor \\delta$. We have for all $n \\in \\mathbb{N}$ and $\\delta>0$ :\n\n$$\n\\begin{aligned}\n\\left|I^{n}(t)\\right| \\leq & \\left|\\int_{0}^{t} \\mathbb{1}_{D}(s) \\psi_{n}(s)\\left(w_{n}(s)-w_{n}\\left(s_{\\delta}\\right)\\right) \\mathrm{d} s\\right|+\\left|\\int_{0}^{t} \\mathbb{1}_{D}(s) \\psi_{n}(s)\\left(w_{n}\\left(s_{\\delta}\\right)\\right) \\mathrm{d} s\\right| \\\\\n\\leq & \\left|\\int_{0}^{t} \\mathbb{1}_{D}(s) \\psi_{n}(s)\\left(w_{n}(s)-w_{n}\\left(s_{\\delta}\\right)\\right) \\mathrm{d} s\\right| \\\\\n& +\\sum_{l=0}^{\\left\\lfloor\\frac{\\delta}{2}\\right\\rfloor-1}\\left|\\int_{l \\delta}^{(l+1) \\delta} \\mathbb{1}_{D}(s) \\psi_{n}(s) w_{n}\\left(s_{\\delta}\\right) \\mathrm{d} s\\right|+\\left|\\int_{t_{\\delta}}^{t} \\mathbb{1}_{D}(s) \\psi_{n}(s) w_{n}\\left(s_{\\delta}\\right) \\mathrm{d} s\\right| \\\\\n= & J_{1}^{n, \\delta}(t)+\\sum_{l=0}^{\\left\\lfloor\\frac{\\delta}{2}\\right\\rfloor-1} J_{2}^{n, \\delta, l}+J_{3}^{n, \\delta}(t)\n\\end{aligned}\n$$\n\nWe estimate each term. Since $\\psi_{n} \\rightarrow 0$ weakly in $L^{2}(0, T)$, we have for all $\\delta>0$ and $l \\in \\mathbb{N}$ :\n\n$$\nJ_{2}^{n, \\delta, l}=\\left|w_{n}(l \\delta)\\right|\\left|\\int_{l \\delta}^{(l+1) \\delta} \\mathbb{1}_{D}(s) \\psi_{n}(s) \\mathrm{d} s\\right| \\leq C_{w}\\left|\\int_{l \\delta}^{(l+1) \\delta} \\mathbb{1}_{D}(s) \\psi_{n}(s) \\mathrm{d} s\\right| \\rightarrow 0 \\quad \\text { as } n \\rightarrow \\infty\n$$\n\nFurthermore, we have for all $n \\in \\mathbb{N}$ :\n\n$$\n\\sup _{t \\in[0, T]} J_{3}^{n, \\delta}(t) \\leq C_{w} \\sup _{t \\in[0, T]} \\int_{t_{\\delta}}^{t}\\left|\\psi_{n}(s)\\right| \\mathrm{d} s \\leq C_{w} C_{\\psi} \\delta^{\\frac{1}{\\delta}} \\rightarrow 0 \\quad \\text { as } \\delta \\downarrow 0\n$$\n\nwhere we used that $\\left|t-t_{\\delta}\\right|<\\delta$ for all $t \\in[0, T]$. Note that the convergence is uniform in $n$.\nFinally, we estimate $J_{1}^{n, \\delta}(t)$ uniformly in $n$ and $t$. By the Cauchy-Schwarz inequality, we have for all $n \\in \\mathbb{N}$ and $\\delta>0$ :\n\n$$\n\\sup _{t \\in[0, T]} J_{1}^{n, \\delta}(t) \\leq \\int_{0}^{T}\\left|\\psi_{n}(s)\\right|\\left|w_{n}(s)-w_{n}\\left(s_{\\delta}\\right)\\right| \\mathrm{d} s \\leq C_{\\psi}\\left\\|w_{n}(\\cdot)-w_{n}(\\cdot)_{\\delta}\\right\\|_{L^{2}(0, T)}\n$$\n\nTo estimate further, we use an argument inspired by [20, Lem. 3.3]. Note that $w_{n}(0)=0$ and\n\n$$\n\\begin{aligned}\n\\int_{0}^{T}\\left|w_{n}(t)-w_{n}\\left(t_{\\delta}\\right)\\right|^{2} \\mathrm{~d} t & =\\int_{0}^{\\delta}\\left|w_{n}(t)\\right|^{2} \\mathrm{~d} t+\\int_{\\delta}^{T}\\left|w_{n}(t)-w_{n}\\left(t_{\\delta}\\right)\\right|^{2} \\mathrm{~d} t \\\\\n& \\leq \\delta C_{w}^{2}+\\int_{\\delta}^{T}\\left|w_{n}(t)-w_{n}\\left(t_{\\delta}\\right)\\right|^{2} \\mathrm{~d} t\n\\end{aligned}\n$$\n\nFor any $t \\in[\\delta, T]$, we can apply the chain rule (A.2) to $v_{n}^{t, \\delta}(\\cdot):=w_{n}(\\cdot)-w_{n}\\left(t_{\\delta}\\right)=\\int_{t_{\\delta}} \\alpha_{n}(s) \\mathrm{d} s$ on $\\left[t_{\\delta}, T\\right]$ and obtain for all $\\tilde{t} \\in\\left[t_{\\delta}, T\\right]$ :\n\n$$\n\\left|w_{n}(\\tilde{t})-w_{n}\\left(t_{\\delta}\\right)\\right|^{2}=2 \\int_{\\tilde{t}_{\\delta}}^{\\tilde{t}} \\alpha_{n}(s)\\left(w_{n}(s)-w_{n}\\left(t_{\\delta}\\right)\\right) \\mathrm{d} s\n$$\n\nApplying the above expression with $\\tilde{t}=t$ we estimate the second term from (4.15):\n\n$$\n\\begin{aligned}\n\\int_{\\delta}^{T}\\left|w_{n}(t)-w_{n}\\left(t_{\\delta}\\right)\\right|^{2} \\mathrm{~d} t & =2 \\int_{\\delta}^{T} \\int_{t_{\\delta}}^{t} \\alpha_{n}(s)\\left(w_{n}(s)-w_{n}\\left(t_{\\delta}\\right)\\right) \\mathrm{d} s \\mathrm{~d} t \\\\\n& \\leq 4 C_{w} \\int_{\\delta}^{T} \\int_{t-\\delta}^{t}\\left|\\alpha_{n}(s)\\right| \\mathrm{d} s \\mathrm{~d} t \\\\\n& \\leq 4 C_{w} \\int_{0}^{T} \\int_{\\delta}^{T} \\mathbb{1}_{\\left[s,(s+\\delta) \\wedge T\\right]}(t) \\mathrm{d} t\\left|\\alpha_{n}(s)\\right| \\mathrm{d} s \\\\\n& \\leq 4 \\delta C_{w} C_{\\alpha}\n\\end{aligned}\n$$\n\nwhere we used that $\\mathbb{1}_{[t-\\delta, t]}(s) \\leq \\mathbb{1}_{[s,(s+\\delta) \\wedge T]}(t)$ for all $(s, t) \\in[0, T] \\times[\\delta, T]$. Combining (4.14), (4.15) and (4.16) we conclude that for all $\\delta>0$ :\n\n$$\n\\sup _{n \\in \\mathbb{N}} \\sup _{t \\in[0, T]} J_{1}^{n, \\delta}(t) \\leq C_{\\psi}\\left(\\delta C_{w}^{2}+4 \\delta C_{w} C_{\\alpha}\\right)^{\\frac{1}{\\delta}}\n$$\n\nNow let $\\varepsilon>0$. According to (4.17) and (4.13), fix $\\delta>0$ sufficiently small such that we have $\\sup _{n \\in \\mathbb{N}} \\sup _{t \\in[0, T]} J_{1}^{n, \\delta}(t)<\\frac{\\varepsilon}{3}$ and $\\sup _{n \\in \\mathbb{N}} \\sup _{t \\in[0, T]} J_{3}^{n, \\delta}(t)<\\frac{\\varepsilon}{3}$. Then, according to (4.12), pick $N \\in \\mathbb{N}$ such that for all $n \\geq N: J_{2}^{n, \\delta, l}<\\frac{\\varepsilon}{3\\left\\lfloor\\frac{\\varepsilon}{3}\\right\\rfloor}$. By (4.11), we obtain $\\sup _{t \\in[0, T]}\\left|I^{n}(t)\\right|<\\varepsilon$ for all $n \\geq N$. Thus $\\lim _{n \\rightarrow \\infty} \\sup _{t \\in[0, T]}\\left|I^{n}(t)\\right|=0$.\n\nEquipped with the lemma above, we now prove that condition (ii) of Theorem 4.5 is satisfied. Note that the growth bounds on $B$ in Assumption 2.2 contain $V$-norms (instead of merely $H$ norms), making it more difficult to apply Gronwall inequalities. To deal with this, the estimates from Lemma 3.8 will be used.\n\nProposition 4.9. Suppose that Assumption 2.2 holds and suppose that $(A, B)$ satisfies (2.7). For $\\psi \\in L^{2}(0, T ; U)$ let $u^{\\psi}$ be the unique strong solution to (2.8). Then for any $K \\geq 0$, the map $\\left(S_{K}\\right.$, weak $) \\rightarrow \\operatorname{MR}(0, T): \\psi \\mapsto u^{\\psi}$ is continuous.\n\nProof. Note that $S_{K}$ is weakly metrizable (as opposed to $L^{2}(0, T ; U)$ ), so we may verify sequential continuity. Suppose that $\\psi_{n} \\rightarrow \\psi$ weakly in $L^{2}(0, T ; U)$ and write $w_{n}:=u^{\\psi_{n}}-u^{\\psi}$. We show that $w_{n} \\rightarrow 0$ in $\\operatorname{MR}(0, T)$. For each $n \\in \\mathbb{N}, w_{n}$ is a strong solution to\n\n$$\n\\begin{cases}w_{n}^{\\prime}+\\bar{A}_{0} w_{n}=f_{n}+\\left(\\bar{B}_{0} w_{n}+g_{n}\\right) \\psi_{n}+b\\left(\\psi_{n}-\\psi\\right) \\\\ w_{n}(0)=0\\end{cases}\n$$\n\nwhere $\\bar{A}_{0}:=A_{0}\\left(u^{\\psi}\\right), \\bar{B}_{0}:=B_{0}\\left(u^{\\psi}\\right)$ and\n\n$$\n\\begin{aligned}\nf_{n} & :=\\left(A_{0}\\left(u^{\\psi}\\right)-A_{0}\\left(u^{\\psi_{n}}\\right)\\right) u^{\\psi_{n}}+F\\left(u^{\\psi_{n}}\\right)-F\\left(u^{\\psi}\\right) \\in L^{2}\\left(0, T ; V^{*}\\right) \\\\\ng_{n} & :=-\\left(B_{0}\\left(u^{\\psi}\\right)-B_{0}\\left(u^{\\psi_{n}}\\right)\\right) u^{\\psi_{n}}+G\\left(u^{\\psi_{n}}\\right)-G\\left(u^{\\psi}\\right) \\in L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right) \\\\\nb & :=B\\left(u^{\\psi}\\right)=B_{0}\\left(u^{\\psi}\\right) u^{\\psi}+G\\left(u^{\\psi}\\right)+g \\in L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)\n\\end{aligned}\n$$\n\nBy the chain rule (A.2), we have for all $t \\in[0, T]$ :\n\n$$\n\\begin{gathered}\n\\frac{1}{2}\\left\\|w_{n}(t)\\right\\|_{H}^{2}=\\int_{0}^{t}-\\left\\langle\\bar{A}_{0} w_{n}(s), w_{n}(s)\\right\\rangle+\\left\\langle\\bar{B}_{0} w_{n}(s) \\psi_{n}(s), w_{n}(s)\\right\\rangle \\mathrm{d} s \\\\\n+\\int_{0}^{t}\\left\\langle f_{n}(s), w_{n}(s)\\right\\rangle+\\left\\langle g_{n}(s) \\psi_{n}(s), w_{n}(s)\\right\\rangle \\mathrm{d} s \\\\\n+\\int_{0}^{t}\\left\\langle b(s)\\left(\\psi_{n}(s)-\\psi(s)\\right), w_{n}(s)\\right\\rangle \\mathrm{d} s \\\\\n=: I_{1}^{n}(t)+I_{2}^{n}(t)+I_{3}^{n}(t)\n\\end{gathered}\n$$\n\nThe strategy is now to use Lemma A. 1 (Gronwall) for deriving an estimate of the form\n\n$$\n\\left\\|w_{n}\\right\\|_{\\operatorname{MR}(0, T)}^{2} \\leq C \\sup _{t \\in[0, T]}\\left|I_{3}^{n}(t)\\right|\n$$\n\nafter which we will apply Lemma 4.8 to $I_{3}^{n}$ and obtain $w_{n} \\rightarrow 0$ in $\\operatorname{MR}(0, T)$. Using the maximal regularity estimate (3.30) and boundedness of $\\left(\\psi_{n}\\right)$ in $L^{2}(0, T ; U)$, we put\n\n$$\nN:=\\left\\|u^{\\psi}\\right\\|_{\\mathrm{MR}(0, T)}+\\sup _{n \\in \\mathbb{N}}\\left\\|u^{\\psi_{n}}\\right\\|_{\\mathrm{MR}(0, T)}<\\infty\n$$\n\nLet $\\theta_{N, T}, M_{N, T}$ and $C_{N, T}$ be as in Assumption 2.2. We estimate $I_{1}^{n}$ and $I_{2}^{n}$ appearing in (4.18). The coercivity of $\\left(A_{0}, B_{0}\\right)$ in Assumption 2.2(2) gives\n\n$$\n\\begin{aligned}\nI_{1}^{n}(t) & \\leq \\int_{0}^{t}-\\left\\langle\\bar{A}_{0} w_{n}(s), w_{n}(s)\\right\\rangle+\\left\\|\\bar{B}_{0} w_{n}(s)\\right\\|_{H}\\left\\|\\psi_{n}(s)\\right\\|_{U}\\left\\|w_{n}(s)\\right\\|_{H} \\mathrm{~d} s \\\\\n& \\leq \\int_{0}^{t}-\\left\\langle\\bar{A}_{0} w_{n}(s), w_{n}(s)\\right\\rangle+\\frac{1}{2}\\left\\|\\bar{B}_{0} w_{n}(s)\\right\\|_{H}^{2}+\\frac{1}{2}\\left\\|\\psi_{n}(s)\\right\\|_{U}^{2}\\left\\|w_{n}(s)\\right\\|_{H}^{2} \\mathrm{~d} s \\\\\n& \\leq \\int_{0}^{t}-\\theta_{N, T}\\left\\|w_{n}(s)\\right\\|_{V}^{2}+\\left(M_{N, T}+\\frac{1}{2}\\left\\|\\psi_{n}(s)\\right\\|_{U}^{2}\\right)\\left\\|w_{n}(s)\\right\\|_{H}^{2} \\mathrm{~d} s\n\\end{aligned}\n$$\n\nMoreover,\n\n$$\n\\begin{aligned}\nI_{2}^{n}(t) & \\leq \\int_{0}^{t}\\left\\|f_{n}(s)\\right\\|_{V^{*}}\\left\\|w_{n}(s)\\right\\|_{V}+\\llbracket g_{n}(s) \\rrbracket_{H}\\left\\|\\psi_{n}(s)\\right\\|_{U}\\left\\|w_{n}(s)\\right\\|_{H} \\mathrm{~d} s \\\\\n\\leq & \\int_{0}^{t} \\frac{1}{\\theta_{N, T}}\\left\\|f_{n}(s)\\right\\|_{V^{*}}^{2}+\\frac{\\theta_{N, T}}{4}\\left\\|w_{n}(s)\\right\\|_{V}^{2}+\\frac{1}{2} \\llbracket g_{n}(s) \\rrbracket_{H}^{2}+\\frac{1}{2}\\left\\|\\psi_{n}(s)\\right\\|_{U}^{2}\\left\\|w_{n}(s)\\right\\|_{H}^{2} \\mathrm{~d} s\n\\end{aligned}\n$$\n\nFor $f_{n}$, Lemma 3.8(iii)(v) gives for any $\\sigma>0$ :\n\n$$\n\\begin{aligned}\n\\left\\|f_{n}\\right\\|_{L^{2}\\left(0, t ; V^{*}\\right)}^{2} \\leq & 2\\left\\|\\left(A_{0}\\left(u^{\\psi}\\right)-A_{0}\\left(u^{\\psi_{n}}\\right)\\right) u^{\\psi_{n}}\\right\\|_{L^{2}\\left(0, t ; V^{*}\\right)}^{2}+2\\left\\|F\\left(u^{\\psi_{n}}\\right)-F\\left(u^{\\psi}\\right)\\right\\|_{L^{2}\\left(0, t ; V^{*}\\right)}^{2} \\\\\n\\leq & 2 C_{N, T}^{2} \\int_{0}^{t}\\left\\|u^{\\psi_{n}}\\right\\|_{V}^{2}\\left\\|w_{n}\\right\\|_{H}^{2} \\mathrm{~d} s \\\\\n& +2 C_{N, T, \\sigma} \\int_{0}^{t}\\left(1+\\left\\|u^{\\psi}\\right\\|_{V}^{2}+\\left\\|u^{\\psi_{n}}\\right\\|_{V}^{2}\\right)\\left\\|w_{n}\\right\\|_{H}^{2} \\mathrm{~d} s+2 \\sigma C_{N, T}^{2}\\left\\|w_{n}\\right\\|_{L^{2}(0, t ; V)}^{2}\n\\end{aligned}\n$$\n\nSimilarly, $\\left\\|g_{n}\\right\\|_{L^{2}\\left(0, t ; \\mathcal{L}_{2}(U, H)\\right)}^{2}$ is bounded by the right-hand side of (4.22), by Lemma 3.8(iii)(v). Fix $\\bar{\\sigma}:=\\theta_{N, T}^{2}\\left(4\\left(2+\\theta_{N, T}\\right) C_{N, T}^{2}\\right)^{-1}>0$. Combining (4.21) and (4.22) yields\n\n$$\n\\begin{aligned}\nI_{2}^{n}(t) \\leq\\left(\\frac{2}{\\theta_{N, T}}+1\\right) & \\left(C_{N, T}^{2} \\int_{0}^{t}\\left\\|u^{\\psi_{n}}\\right\\|_{V}^{2}\\left\\|w_{n}\\right\\|_{H}^{2} \\mathrm{~d} s+C_{N, T, \\bar{\\sigma}} \\int_{0}^{t}\\left(1+\\left\\|u^{\\psi}\\right\\|_{V}^{2}+\\left\\|u^{\\psi_{n}}\\right\\|_{V}^{2}\\right)\\left\\|w_{n}\\right\\|_{H}^{2} \\mathrm{~d} s\\right) \\\\\n& +\\left(\\frac{2}{\\theta_{N, T}}+1\\right) \\bar{\\sigma} C_{N, T}^{2}\\left\\|w_{n}\\right\\|_{L^{2}(0, t ; V)}^{2}+\\frac{\\theta_{N, T}}{4}\\left\\|w_{n}\\right\\|_{L^{2}(0, t ; V)}^{2}+\\int_{0}^{t} \\frac{1}{2}\\left\\|\\psi_{n}\\right\\|_{U}^{2}\\left\\|w_{n}\\right\\|_{H}^{2} \\mathrm{~d} s \\\\\n=\\int_{0}^{t} h_{n}(s)\\left\\|w_{n}(s)\\right\\|_{H}^{2} \\mathrm{~d} s+\\frac{\\theta_{N, T}}{2}\\left\\|w_{n}\\right\\|_{L^{2}(0, t ; V)}^{2}\n\\end{aligned}\n$$\n\nwhere\n\n$$\nh_{n}(s):=\\left(\\frac{2}{\\theta_{N, T}}+1\\right)\\left(C_{N, T}^{2}\\left\\|u^{\\psi_{n}}(s)\\right\\|_{V}^{2}+C_{N, T, \\bar{\\sigma}}\\left(1+\\left\\|u^{\\psi}(s)\\right\\|_{V}^{2}+\\left\\|u^{\\psi_{n}}(s)\\right\\|_{V}^{2}\\right)\\right)+\\frac{1}{2}\\left\\|\\psi_{n}(s)\\right\\|_{U}^{2}\n$$\n\nNote that $\\sup _{n \\in \\mathbb{N}}\\left\\|h_{n}\\right\\|_{L^{1}(0, T)}<\\infty$, by (4.19) and since $\\left(\\psi_{n}\\right) \\subset S_{K}$. Now (4.20) and (4.23) give\n\n$$\nI_{1}^{n}(t)+I_{2}^{n}(t) \\leq-\\frac{\\theta_{N, T}}{2}\\left\\|w_{n}\\right\\|_{L^{2}(0, t ; V)}^{2}+\\int_{0}^{t}\\left(h_{n}(s)+M_{N, T}+\\frac{1}{2}\\left\\|\\psi_{n}(s)\\right\\|_{U}^{2}\\right)\\left\\|w_{n}(s)\\right\\|_{H}^{2} \\mathrm{~d} s\n$$\n\nHence, combined with (4.18):\n$\\left\\|w_{n}(t)\\right\\|_{H}^{2} \\leq-\\theta_{N, T}\\left\\|w_{n}\\right\\|_{L^{2}(0, t ; V)}^{2}+2 \\int_{0}^{t}\\left(h_{n}(s)+M_{N, T}+\\frac{1}{2}\\left\\|\\psi_{n}(s)\\right\\|_{U}^{2}\\right)\\left\\|w_{n}(s)\\right\\|_{H}^{2} \\mathrm{~d} s+2 \\sup _{s \\in[0, t]}\\left|I_{3}^{n}(s)\\right|$.\nLemma A. 1 (Gronwall) gives for all $n \\in \\mathbb{N}$ :\n\n$$\n\\frac{1}{2}\\left\\|w_{n}\\right\\|_{\\operatorname{MR}(0, T)}^{2} \\leq \\sup _{t \\in[0, T]}\\left\\|w_{n}(t)\\right\\|_{H}^{2}+\\left\\|w_{n}\\right\\|_{L^{2}(0, T ; V)}^{2} \\leq 2\\left(1+\\frac{1}{\\theta_{N, T}}\\right) \\sup _{s \\in[0, t]}\\left|I_{3}^{n}(s)\\right| \\exp (2 \\kappa)\n$$\n\nwith constant $\\kappa:=\\sup _{n \\in \\mathbb{N}}\\left(\\left\\|h_{n}\\right\\|_{L^{1}(0, T)}+\\frac{1}{2}\\left\\|\\psi_{n}\\right\\|_{L^{2}(0, T ; U)}^{2}\\right)+M_{N, T}<\\infty$.\nBy (4.24), it remains to show that $\\lim _{n \\rightarrow \\infty} \\sup _{t \\in[0, T]}\\left|I_{3}^{n}(t)\\right|=0$. We use Lemma 4.8. Note that $\\sup _{n \\in \\mathbb{N}}\\left\\|w_{n}\\right\\|_{\\operatorname{MR}(0, T)} \\leq N$ by (4.19), so we only have to verify boundedness of $\\left(\\alpha_{n}\\right) \\subset L^{1}\\left(0, T ; V^{*}\\right)$, where $\\alpha_{n}:=-A_{0} w_{n}+f_{n}+\\left(\\bar{B}_{0} w_{n}+g_{n}\\right) \\psi_{n}+b\\left(\\psi_{n}-\\psi\\right) \\in L^{2}\\left(0, T ; V^{*}\\right)+L^{1}(0, T ; H) \\subset L^{1}\\left(0, T ; V^{*}\\right)$. The last inclusion is continuous, so it suffices to prove boundedness of $\\left(-A_{0} w_{n}+f_{n}\\right) \\subset L^{2}\\left(0, T ; V^{*}\\right)$ and $\\left(\\beta_{n}\\right):=\\left(\\left(\\bar{B}_{0} w_{n}+g_{n}\\right) \\psi_{n}+b\\left(\\psi_{n}-\\psi\\right)\\right) \\subset L^{1}(0, T ; H)$. Note that $\\left\\|\\left(\\bar{B}_{0} w_{n}+g_{n}\\right) \\psi_{n}\\right\\|_{H} \\leq$ $\\left\\|\\bar{B}_{0} w_{n}+g_{n}\\right\\|_{H}\\left\\|\\psi_{n}\\right\\|_{U}$ with $\\left(\\psi_{n}\\right)$ bounded in $L^{2}(0, T ; U)$ and similar for $b\\left(\\psi_{n}-\\psi\\right)$. Thus by the Cauchy-Schwarz inequality, if we show that $\\left(\\bar{B}_{0} w_{n}\\right)$ and $\\left(g_{n}\\right)$ are bounded in $L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)$, then boundedness of $\\left(\\beta_{n}\\right) \\subset L^{1}(0, T ; H)$ follows $\\left(b \\in L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)\\right.$ does not depend on $\\left.n\\right)$. By symmetry in Assumption 2.2(3), $\\bar{B}_{0} w_{n}$ and $g_{n}$ can be estimated in the same way as $\\bar{A}_{0} w_{n}:=$ $A_{0}\\left(u^{\\psi}\\right) w_{n}$ and $f_{n}:=\\left(A_{0}\\left(u^{\\psi}\\right)-A_{0}\\left(u^{\\psi_{n}}\\right)\\right) u^{\\psi_{n}}+F\\left(u^{\\psi_{n}}\\right)-F\\left(u^{\\psi}\\right)$, respectively. We provide the estimates for the latter here. By Lemma 3.8(ii)(iii), $\\left\\|A_{0}\\left(u^{\\psi}\\right) w_{n}\\right\\|_{L^{2}\\left(0, T ; V^{*}\\right)} \\leq C_{N, T}(1+N) N<\\infty$ and $\\left\\|\\left(A_{0}\\left(u^{\\psi}\\right)-A_{0}\\left(u^{\\psi_{n}}\\right)\\right) u^{\\psi_{n}}\\right\\|_{L^{2}\\left(0, T ; V^{*}\\right)} \\leq C_{N, T} N^{2}<\\infty$. Furthermore, Lemma 3.8(iv) gives $\\left\\|F\\left(u^{\\psi_{n}}\\right)\\right\\|_{L^{2}\\left(0, T ; V^{*}\\right)} \\leq \\tilde{C}_{N, T}(1+N)<\\infty$. Finally, $F\\left(u^{\\psi}\\right) \\in L^{2}\\left(0, T ; V^{*}\\right)$ does not depend on $n$. We conclude that $\\left(-A_{0} w_{n}+f_{n}\\right)$ is bounded in $L^{2}\\left(0, T ; V^{*}\\right)$ and by the considerations above, $\\left(\\beta_{n}\\right)$ is bounded in $L^{1}(0, T ; H)$. Lemma 4.8 thus yields $\\lim _{n \\rightarrow \\infty} \\sup _{t \\in[0, T]}\\left|I_{3}^{n}(t)\\right|=0$ and (4.24) gives $w_{n} \\rightarrow 0$ in $\\operatorname{MR}(0, T)$.\n\nRemark 4.10. Proposition 4.9 also ensures measurability of the map $\\mathcal{G}^{0}: C\\left([0, T] ; U_{1}\\right) \\rightarrow \\operatorname{MR}(0, T)$ defined by (4.4), as required in Theorem 4.5. Note that $\\left\\{\\int_{0} \\psi(s) \\mathrm{d} s: \\psi \\in L^{2}(0, T ; U)\\right\\}=\\{v \\in$ $\\left.W^{1,2}(0, T ; U): v(0)=0\\right\\}=W_{0}^{1,2}$. By Sobolev embedding [22, Corollary L.4.6], $W_{0}^{1,2}$ embeds continuously into $C\\left([0, T] ; U\\right)\\left(W_{0}^{1,2}\\right.$ is a closed subspace of $\\left.W^{1,2}(0, T ; U)\\right)$. Hence Kuratowski's theorem [25, Th. 15.1] gives $\\mathcal{B}\\left(W_{0}^{1,2}\\right) \\subset \\mathcal{B}(C([0, T] ; U))$. Moreover, $\\gamma: W_{0}^{1,2} \\rightarrow$ $\\operatorname{MR}(0, T): \\int_{0}^{1} \\psi(s) \\mathrm{d} s \\mapsto u^{\\psi}$ is continuous, since $\\int_{0}^{1} \\psi_{n}(s) \\mathrm{d} s \\rightarrow \\int_{0}^{1} \\psi(s) \\mathrm{d} s$ in $W_{0}^{1,2}$ implies $\\psi_{n} \\rightarrow \\psi$\n\nin $L^{2}(0, T ; U)$, and $L^{2}(0, T ; U) \\rightarrow \\operatorname{MR}(0, T): \\psi \\mapsto u^{\\psi}$ is norm-continuous since it is weakly sequentially continuous by Proposition 4.9. It follows that for $E \\in \\mathcal{B}(\\operatorname{MR}(0, T))$, we have\n\n$$\n\\left(\\mathcal{G}^{0}\\right)^{-1}(E)= \\begin{cases}\\gamma^{-1}(E) \\in \\mathcal{B}\\left(W_{0}^{1,2}\\right) \\subset \\mathcal{B}(C([0, T] ; U)), & 0 \\notin E \\\\ \\gamma^{-1}(E) \\cup\\left(C([0, T] ; U) \\backslash W^{1,2}(0)\\right) \\in \\mathcal{B}(C([0, T] ; U)), & 0 \\in E\\end{cases}\n$$\n\nSince $U \\hookrightarrow U_{1}$, Kuratowski's theorem yields $\\mathcal{B}(C([0, T] ; U)) \\subset \\mathcal{B}\\left(C\\left([0, T] ; U_{1}\\right)\\right)$. Thus $\\mathcal{G}^{0}$ is measurable.\n4.3. Stochastic continuity criterion. It remains to verify the stochastic continuity criterion (iii) of Theorem 4.5. Before we prove that (iii) is satisfied, we first derive some stochastic bounds which we will later apply to $X^{\\varepsilon}:=\\mathcal{G}^{\\varepsilon}\\left(\\widetilde{W}_{1}(\\cdot)+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0} \\Psi^{\\varepsilon}(s) \\mathrm{d} s\\right)$. In the next lemma we use a stochastic Gronwall lemma as in [6] to avoid further growth bound assumptions on $B$.\n\nLemma 4.11. Suppose that Assumption 2.2 holds and suppose that $(A, B)$ satisfies (2.7). Let $K>0,\\left(\\Psi^{\\varepsilon}\\right)_{0<\\varepsilon<\\frac{1}{\\varepsilon}} \\subset \\mathcal{A}_{K}$ and let $x \\in H$. For $\\varepsilon \\in\\left(0, \\frac{1}{\\varepsilon}\\right)$, let $X^{\\varepsilon}$ be a strong solution to\n\n$$\n\\left\\{\\begin{array}{l}\n\\mathrm{d} X^{\\varepsilon}(t)=\\left(-A\\left(t, X^{\\varepsilon}(t)\\right)+B\\left(t, X^{\\varepsilon}(t)\\right) \\Psi^{\\varepsilon}(t)\\right) \\mathrm{d} t+\\sqrt{\\varepsilon} B\\left(t, X^{\\varepsilon}(t)\\right) \\mathrm{d} W(t), \\quad t \\in[0, T] \\\\\nX^{\\varepsilon}(0)=x\n\\end{array}\\right.\n$$\n\nThen there exists $C>0$ such that for all $\\gamma>0$,\n\n$$\n\\left\\{\\begin{array}{l}\n\\sup _{\\varepsilon \\in\\left(0, \\frac{1}{\\varepsilon}\\right)} \\mathbb{P}\\left(\\left\\|X^{\\varepsilon}\\right\\|_{\\operatorname{MR}(0, T)}>\\gamma\\right) \\leq \\frac{C}{\\gamma^{\\varepsilon}} \\\\\n\\sup _{\\varepsilon \\in\\left(0, \\frac{1}{\\varepsilon}\\right)} \\mathbb{P}\\left(\\left\\|B\\left(\\cdot, X^{\\varepsilon}(\\cdot)\\right)\\right\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)}>\\gamma\\right)<\\frac{C}{\\gamma^{\\varepsilon}}\n\\end{array}\\right.\n$$\n\nThe constant $C$ depends only on $x, K, T$ and $\\phi, M, \\theta$ from (2.7).\nProof. By the It\u00f4 formula (A.4), by (2.7) and since $\\varepsilon<\\frac{1}{2}$, we have a.s. for all $t \\in[0, T]$ :\n\n$$\n\\begin{aligned}\n& \\left\\|X^{\\varepsilon}(t)\\right\\|_{H}^{2}-\\|x\\|_{H}^{2}=2 \\int_{0}^{t}\\left\\langle-A\\left(s, X^{\\varepsilon}(s)\\right), X^{\\varepsilon}(s)\\right\\rangle+\\left\\langle B\\left(s, X^{\\varepsilon}(s)\\right) \\Psi^{\\varepsilon}(s), X^{\\varepsilon}(s)\\right\\rangle \\mathrm{d} s \\\\\n& +2 \\sqrt{\\varepsilon} \\int_{0}^{t}\\left\\langle X^{\\varepsilon}(s), B\\left(s, X^{\\varepsilon}(s)\\right) \\mathrm{d} W(s)\\right\\rangle+\\varepsilon \\int_{0}^{t}\\left\\|B\\left(s, X^{\\varepsilon}(s)\\right)\\right\\|_{H}^{2} \\mathrm{~d} s \\\\\n& \\leq 2 \\int_{0}^{t}-\\frac{1}{2}\\left\\|B\\left(s, X^{\\varepsilon}(s)\\right)\\right\\|_{H}^{2}-\\theta\\left\\|X^{\\varepsilon}(s)\\right\\|_{V}^{2}+M\\left\\|X^{\\varepsilon}(s)\\right\\|_{H}^{2}+|\\phi(s)|^{2} \\mathrm{~d} s \\\\\n& +2 \\int_{0}^{t}\\left\\langle B\\left(s, X^{\\varepsilon}(s)\\right) \\Psi^{\\varepsilon}(s), X^{\\varepsilon}(s)\\right\\rangle \\mathrm{d} s \\\\\n& +\\varepsilon \\int_{0}^{t}\\left\\|B\\left(s, X^{\\varepsilon}(s)\\right)\\right\\|_{H}^{2} \\mathrm{~d} s+2 \\sqrt{\\varepsilon} \\int_{0}^{r}\\left\\langle X^{\\varepsilon}(s), B\\left(s, X^{\\varepsilon}(s)(\\cdot)\\right\\rangle \\mathrm{d} W(s)\\right. \\\\\n& \\leq-\\int_{0}^{t}\\left\\|B\\left(s, X^{\\varepsilon}(s)\\right)\\right\\|_{H}^{2} \\mathrm{~d} s-2 \\theta\\left\\|X^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2}+\\int_{0}^{t} 2 M\\left\\|X^{\\varepsilon}(s)\\right\\|_{H}^{2} \\mathrm{~d} s+2\\|\\phi\\|_{L^{2}(0, t)}^{2} \\\\\n& +2 \\int_{0}^{t} \\frac{1}{8}\\left\\|B\\left(s, X^{\\varepsilon}(s)\\right)\\right\\|_{H}^{2}+2\\left\\|\\Psi^{\\varepsilon}(s)\\right\\|_{U}^{2}\\left\\|X^{\\varepsilon}(s)\\right\\|_{H}^{2} \\mathrm{~d} s \\\\\n& +\\frac{1}{2} \\int_{0}^{t}\\left\\|B\\left(s, X^{\\varepsilon}(s)\\right)\\right\\|_{H}^{2} \\mathrm{~d} s+2 \\sqrt{\\varepsilon} \\int_{0}^{t}\\left\\langle X^{\\varepsilon}(s), B\\left(s, X^{\\varepsilon}(s)(\\cdot)\\right\\rangle \\mathrm{d} W(s)\\right. \\\\\n& =-\\frac{1}{4}\\left\\|B\\left(\\cdot, X^{\\varepsilon}(\\cdot)\\right)\\right\\|_{L^{2}\\left(0, t ; \\mathcal{L}_{2}(U, H)\\right)}^{2}-2 \\theta\\left\\|X^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2}+2\\|\\phi\\|_{L^{2}(0, t)}^{2} \\\\\n& +\\int_{0}^{t} 2\\left(M+2\\left\\|\\Psi^{\\varepsilon}(s)\\right\\|_{U}^{2}\\right)\\left\\|X^{\\varepsilon}(s)\\right\\|_{H}^{2} \\mathrm{~d} s+2 \\sqrt{\\varepsilon} \\int_{0}^{t}\\left\\langle X^{\\varepsilon}(s), B\\left(s, X^{\\varepsilon}(s)(\\cdot)\\right\\rangle \\mathrm{d} W(s)\\right.\n\\end{aligned}\n$$\n\nWe conclude that $y_{\\varepsilon}(t) \\leq h(t)+\\int_{0}^{t} y_{\\varepsilon}(s) a_{\\varepsilon}(s) \\mathrm{d} s+2 \\sqrt{\\varepsilon} \\int_{0}^{t}\\left\\langle X^{\\varepsilon}(s), B\\left(s, X^{\\varepsilon}(s)(\\cdot)\\right\\rangle \\mathrm{d} W(s)\\right.$, where\n\n$$\n\\begin{gathered}\ny_{\\varepsilon}(t):=\\left\\|X^{\\varepsilon}(t)\\right\\|_{H}^{2}+2 \\theta\\left\\|X^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2}+\\frac{1}{4}\\left\\|B\\left(\\cdot, X^{\\varepsilon}(\\cdot)\\right)\\right\\|_{L^{2}\\left(0, t ; \\mathcal{L}_{2}(U, H)\\right)}^{2} \\\\\nh(t):=\\|x\\|_{H}^{2}+2\\|\\phi\\|_{L^{2}(0, T)}^{2}, \\quad a_{\\varepsilon}(t):=2\\left(M+2\\left\\|\\Psi^{\\varepsilon}(t)\\right\\|_{U}^{2}\\right)\n\\end{gathered}\n$$\n\nNow the stochastic Gronwall inequality [19, Cor. 5.4b), (50)] (with $R:=2 M T+4 K^{2}$ ) gives\n\n$$\n\\mathbb{P}\\left(\\sup _{t \\in[0, T]} y_{\\varepsilon}(t)>\\gamma\\right) \\leq \\frac{\\exp \\left(2 M T+4 K^{2}\\right)}{\\gamma} \\mathbb{E}[h(T)] \\leq \\frac{\\exp \\left(2 M T+4 K^{2}\\right)}{\\gamma}\\left(\\|x\\|_{H}^{2}+2\\|\\phi\\|_{L^{2}(0, T)}^{2}\\right)\n$$\n\nfor all $\\gamma>0$, where we used that $\\left\\|\\Psi^{\\varepsilon}\\right\\|_{L^{2}(0, T ; U)} \\leq K$ a.s. since $\\left(\\Psi^{\\varepsilon}\\right) \\subset \\mathcal{A}_{K}$. Using\n\n$$\n\\begin{aligned}\n& \\left\\{\\sup _{t \\in[0, T]} y_{\\varepsilon}(t)>\\gamma\\right\\} \\\\\n& \\supset\\left\\{\\left\\|X^{\\varepsilon}\\right\\|_{C([0, T] ; H)}^{2}+2 \\theta\\left\\|X^{\\varepsilon}\\right\\|_{L^{2}(0, T ; V)}^{2}>2 \\gamma\\right\\} \\cup\\left\\{\\left\\|B\\left(\\cdot, X^{\\varepsilon}(\\cdot)\\right)\\right\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)}^{2}>4 \\gamma\\right\\} \\\\\n& \\supset\\left\\{\\left\\|X^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)}^{2}>\\frac{4 \\gamma}{1 \\wedge 2 \\theta}\\right\\} \\cup\\left\\{\\left\\|B\\left(\\cdot, X^{\\varepsilon}(\\cdot)\\right)\\right\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)}^{2}>4 \\gamma\\right\\}\n\\end{aligned}\n$$\n\nand putting $C:=\\frac{4}{1 \\wedge 2 \\theta} \\exp \\left(2 M T+4 K^{2}\\right)\\left(\\|x\\|_{H}^{2}+2\\|\\phi\\|_{L^{2}(0, T)}^{2}\\right)$, yields for all $\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)$ :\n\n$$\n\\mathbb{P}\\left(\\left\\|X^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)}^{2}>\\gamma\\right)<\\frac{C}{\\gamma}, \\quad \\mathbb{P}\\left(\\left\\|B\\left(\\cdot, X^{\\varepsilon}(\\cdot)\\right)\\right\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)}^{2}>\\gamma\\right)<\\frac{C}{\\gamma}\n$$\n\nConsequently, we have $\\mathbb{P}\\left(\\left\\|X^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)}>\\gamma\\right)=\\mathbb{P}\\left(\\left\\|X^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)}^{2}>\\gamma^{2}\\right) \\leq \\frac{C}{\\gamma^{2}}$ and in the same way, $\\mathbb{P}\\left(\\left\\|B\\left(\\cdot, X^{\\varepsilon}(\\cdot)\\right)\\right\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)}>\\gamma\\right)<\\frac{C}{\\gamma^{2}}$, uniformly in $\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)$.\n\nWe now prove that condition (iii) of Theorem 4.5 is satisfied.\nProposition 4.12. Suppose that Assumption 2.2 holds and suppose that $(A, B)$ satisfies (2.7). Let $\\left(\\Psi^{\\varepsilon}\\right)_{0<\\varepsilon<\\frac{1}{2}} \\subset \\mathcal{A}_{K}$ for some $K>0$ and let $x \\in H$. For $\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)$, let $X^{\\varepsilon}$ and $u^{\\varepsilon}$ be defined by\n\n$$\nX^{\\varepsilon}:=\\mathcal{G}^{\\varepsilon}\\left(\\widetilde{W}_{1}(\\cdot)+\\frac{1}{\\sqrt{\\varepsilon}} \\int_{0} \\Psi^{\\varepsilon}(s) \\mathrm{d} s\\right), \\quad u^{\\varepsilon}:=\\mathcal{G}^{0}\\left(\\int_{0} \\Psi^{\\varepsilon}(s) \\mathrm{d} s\\right)\n$$\n\nwhere $\\mathcal{G}^{\\varepsilon}: C\\left([0, T] ; U_{1}\\right) \\rightarrow \\operatorname{MR}(0, T)$ is the measurable map from Lemma 4.6 for $\\varepsilon>0, \\mathcal{G}^{0}$ is defined by (4.4) and $\\widetilde{W}_{1}$ by (4.2). Then $X^{\\varepsilon}-u^{\\varepsilon} \\rightarrow 0$ in probability in $\\operatorname{MR}(0, T)$ as $\\varepsilon \\downarrow 0$.\n\nProof. We will apply It\u00f4's formula and Assumption 2.2. However, because the estimates in Assumption 2.2 are $n$-dependent, below we use a cut-off argument to reduce to processes that are bounded by $n$ in $H$-norm.\n\nBy Definition 4.4, we have a.s. $\\left\\|\\Psi^{\\varepsilon}\\right\\|_{L^{2}(0, T ; U)} \\leq K<\\infty$. Thus, recalling (4.4), we have for a.e. $\\omega \\in \\Omega: u^{\\varepsilon}(\\omega)=u^{\\Psi_{\\varepsilon}(\\omega)}$, where the latter is the unique strong solution (Theorem 3.16) to (2.8) with $\\psi=\\Psi^{\\varepsilon}(\\omega) \\in S_{K}$. Furthermore, the maximal regularity estimate (3.30) gives\n\n$$\nN:=\\underset{\\omega \\in \\Omega}{\\operatorname{ess} \\sup } \\sup _{\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)}\\left\\|u^{\\varepsilon}(\\omega)\\right\\|_{\\mathrm{MR}(0, T)}<\\infty\n$$\n\nOn the other hand, for $X^{\\varepsilon}$ we do not have a.s. $\\sup _{\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)}\\left\\|X^{\\varepsilon}\\right\\|_{C([0, T] ; H)}<\\infty$, but we do have the boundedness in probability from Lemma 4.11. For $\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)$ and $n \\in \\mathbb{N}$, define\n\n$$\nE_{n, \\varepsilon}:=\\left\\{\\left\\|X^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)} \\leq n\\right\\} \\cap\\left\\{\\left\\|u^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)} \\leq N\\right\\}\n$$\n\nBy Lemma 4.6, $X^{\\varepsilon}$ is a strong solution to (4.25), so thanks to Lemma 4.11 and (4.27),\n\n$$\n\\mathbb{P}\\left(E_{n, \\varepsilon}^{\\mathrm{c}}\\right)=\\mathbb{P}\\left(\\left\\|X^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)}>n\\right) \\leq \\frac{C}{n^{2}}\n$$\n\nwhere $C$ is a constant independent of $\\varepsilon$. Hence, for all $\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)$ and $n \\in \\mathbb{N}$ :\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)}>\\gamma\\right) & \\leq \\mathbb{P}\\left(\\left\\{\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)}>\\gamma\\right\\} \\cap E_{n, \\varepsilon}\\right)+\\mathbb{P}\\left(E_{n, \\varepsilon}^{\\mathrm{c}}\\right) \\\\\n& \\leq \\mathbb{P}\\left(\\left\\{\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)}>\\gamma\\right\\} \\cap E_{n, \\varepsilon}\\right)+\\frac{C}{n^{2}}\n\\end{aligned}\n$$\n\nTherefore, to have the stated convergence in probability, it suffices to prove that for any $\\delta>0$ and any large enough $n \\in \\mathbb{N}$ :\n\n$$\n\\lim _{\\varepsilon \\downarrow 0} \\mathbb{P}\\left(\\left\\{\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)}>\\delta\\right\\} \\cap E_{n, \\varepsilon}\\right)=0\n$$\n\nLet $n \\geq N$ be arbitrary, where $N$ is given by (4.27). We prove (4.28). By the It\u00f4 formula (A.4), we have for all $t \\in[0, T]$ :\n\n$$\n\\begin{aligned}\n& \\left\\|X^{\\varepsilon}(t)-u^{\\varepsilon}(t)\\right\\|_{H}^{2}=2 \\int_{0}^{t}\\left\\langle-A\\left(s, X^{\\varepsilon}(s)\\right)+A\\left(s, u^{\\varepsilon}(s)\\right), X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\rangle \\mathrm{d} s \\\\\n& +2 \\int_{0}^{t}\\left\\langle\\left(B\\left(s, X^{\\varepsilon}(s)\\right)-B\\left(s, u^{\\varepsilon}(s)\\right)\\right) \\Psi^{\\varepsilon}(s), X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\rangle \\mathrm{d} s \\\\\n& +\\varepsilon \\int_{0}^{t} \\llbracket B\\left(s, X^{\\varepsilon}(s)\\right) \\rrbracket_{H}^{2} \\mathrm{~d} s \\\\\n& +2 \\sqrt{\\varepsilon} \\int_{0}^{t}\\left\\langle X^{\\varepsilon}(s)-u^{\\varepsilon}(s), B\\left(s, X^{\\varepsilon}(s)\\right) \\mathrm{d} W(s)\\right\\rangle \\\\\n& =: I_{1}^{\\varepsilon}(t)+I_{2}^{\\varepsilon}(t)+I_{3}^{\\varepsilon}(t)+I_{4}^{\\varepsilon}(t) .\n\\end{aligned}\n$$\n\nBelow we derive an estimate of the form\n\n$$\nI_{1}^{\\varepsilon}(t)+I_{2}^{\\varepsilon}(t) \\leq-\\theta_{n, T}\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2}+\\int_{0}^{t}\\left|h_{n, \\varepsilon}(s)\\right|\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2} \\mathrm{~d} s\n$$\n\nthat holds a.s. on the set $E_{n, \\varepsilon}$, for every $t \\in[0, T]$ and $\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)$. Here, $\\theta_{n, T}$ is a constant and a.s. $h_{n, \\varepsilon} \\in L^{1}(0, T)$, with $\\alpha_{n}:=\\sup _{\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)} \\operatorname{ess} \\sup _{\\Omega}\\left\\|h_{n, \\varepsilon} \\mathbb{1}_{E_{n, \\varepsilon}}\\right\\|_{L^{1}(0, T)}<\\infty$. Then, a.s. on $E_{n, \\varepsilon}$,\n\n$$\n\\left\\|X^{\\varepsilon}(t)-u^{\\varepsilon}(t)\\right\\|_{H}^{2} \\leq-\\theta_{n, T}\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2}+I_{3}^{\\varepsilon}(t)+\\sup _{r \\in[0, t]} I_{4}^{\\varepsilon}(r)+\\int_{0}^{t}\\left|h_{n, \\varepsilon}(s)\\right|\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2} \\mathrm{~d} s\n$$\n\nso Lemma A. 1 (Gronwall) gives pointwise in a.e. $\\omega \\in E_{n, \\varepsilon}$ :\n\n$$\n\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{C([0, T] ; H)}^{2}+\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{L^{2}(0, T ; V)}^{2} \\leq\\left(1+\\theta_{n, T}^{-1}\\right) \\exp \\left(\\alpha_{n}\\right)\\left(I_{3}^{\\varepsilon}(T)+\\sup _{t \\in[0, T]}\\left|I_{4}^{\\varepsilon}(t)\\right|\\right)\n$$\n\nPutting $c_{n}:=2\\left(1+\\theta_{n, T}^{-1}\\right) \\exp \\left(\\alpha_{n}\\right)$, we thus have $\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)}^{2} \\leq c_{n}\\left(I_{3}^{\\varepsilon}(T)+\\sup _{t \\in[0, T]}\\left|I_{4}^{\\varepsilon}(t)\\right|\\right)$ a.s. on $E_{n, \\varepsilon}$, and therefore,\n\n$$\n\\mathbb{P}\\left(\\left\\{\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{\\mathrm{MR}(0, T)}^{2}>\\delta\\right\\} \\cap E_{n, \\varepsilon}\\right) \\leq \\sum_{i=3}^{4} \\mathbb{P}\\left(\\left\\{\\sup _{t \\in[0, T]}\\left|I_{i}^{\\varepsilon}(t)\\right|>\\frac{\\delta}{2 c_{n}}\\right\\} \\cap E_{n, \\varepsilon}\\right)\n$$\n\nHence, after we have proved (4.29), for (4.28), it suffices to prove two convergences in probability:\n\n$$\n\\lim _{\\varepsilon \\downarrow 0} \\mathbb{P}\\left(I_{3}^{\\varepsilon}(T)>\\delta\\right)=0 \\text { for any } \\delta>0\n$$\n\n$$\n\\lim _{\\varepsilon \\downarrow 0} \\mathbb{P}\\left(\\sup _{t \\in[0, T]}\\left|I_{4}^{\\varepsilon}(t)\\right|>\\delta\\right)=0 \\text { for any } \\delta>0\n$$\n\nAll in all, recalling that we reduced the original problem to proving (4.28), by the reasoning above it remains to establish (4.29), (4.30) and (4.31).\n\nLet us prove (4.29). Recall that $A(t, v)=A_{0}(t, v) v-F(t, v)-f$ and $B(t, v)=B_{0}(t, v) v+$ $G(t, v)+g$, see Assumption 2.2(1). We have pointwise on $E_{n, \\varepsilon}$, for all $\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)$ :\n\n$$\n\\begin{aligned}\n& \\frac{1}{2}\\left(I_{1}^{\\varepsilon}(t)+I_{2}^{\\varepsilon}(t)\\right)=\\int_{0}^{t}\\left\\langle-A_{0}\\left(s, u^{\\varepsilon}(s)\\right)\\left(X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right), X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\rangle \\mathrm{d} s \\\\\n& +\\int_{0}^{t}\\left\\langle\\left(A_{0}\\left(s, u^{\\varepsilon}(s)\\right)-A_{0}\\left(s, X^{\\varepsilon}(s)\\right)\\right) X^{\\varepsilon}(s), X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\rangle \\mathrm{d} s \\\\\n& +\\int_{0}^{t}\\left\\langle F\\left(X^{\\varepsilon}(s)\\right)-F\\left(u^{\\varepsilon}(s)\\right), X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\rangle \\mathrm{d} s \\\\\n& +\\int_{0}^{t}\\left\\langle B_{0}\\left(s, u^{\\varepsilon}(s)\\right)\\left(X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right) \\Psi^{\\varepsilon}(s), X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\rangle \\mathrm{d} s \\\\\n& +\\int_{0}^{t}\\left\\langle\\left(B_{0}\\left(s, X^{\\varepsilon}(s)\\right)-B_{0}\\left(s, u^{\\varepsilon}(s)\\right)\\right) X^{\\varepsilon}(s) \\Psi^{\\varepsilon}(s), X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\rangle \\mathrm{d} s\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n& +\\int_{0}^{t}\\left\\langle\\left(G\\left(X^{\\varepsilon}(s)\\right)-G\\left(u^{\\varepsilon}(s)\\right)\\right) \\Psi^{\\varepsilon}(s), X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\rangle \\mathrm{d} s \\\\\n\\leq & \\int_{0}^{t}\\left\\langle-A_{0}\\left(s, u^{\\varepsilon}(s)\\right)\\left(X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right), X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right) \\mathrm{d} s \\\\\n& +\\int_{0}^{t} \\frac{1}{2}\\llbracket B_{0}\\left(s, u^{\\varepsilon}(s)\\right)\\left(X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right) \\rrbracket_{H}^{2}+\\frac{1}{2}\\left\\|\\Psi^{\\varepsilon}(s)\\right\\|_{U}^{2}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2} \\mathrm{~d} s \\\\\n& +\\int_{0}^{t}\\left\\|\\left(A_{0}\\left(s, u^{\\varepsilon}(s)\\right)-A_{0}\\left(s, X^{\\varepsilon}(s)\\right)\\right) X^{\\varepsilon}(s)\\right\\|_{V^{*}}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{V} \\mathrm{~d} s \\\\\n& +\\int_{0}^{t}\\left\\|F\\left(X^{\\varepsilon}(s)\\right)-F\\left(u^{\\varepsilon}(s)\\right)\\right\\|_{V^{*}}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{V} \\mathrm{~d} s \\\\\n& +\\int_{0}^{t} \\llbracket\\left(B_{0}\\left(s, X^{\\varepsilon}(s)\\right)-B_{0}\\left(s, u^{\\varepsilon}(s)\\right)\\right) X^{\\varepsilon}(s) \\rrbracket_{H}\\left\\|\\Psi^{\\varepsilon}(s)\\right\\|_{U}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H} \\mathrm{~d} s \\\\\n& +\\int_{0}^{t} \\llbracket G\\left(X^{\\varepsilon}(s)\\right)-G\\left(u^{\\varepsilon}(s)\\right) \\rrbracket_{H}\\left\\|\\Psi^{\\varepsilon}(s)\\right\\|_{U}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H} \\mathrm{~d} s \\\\\n\\leq & \\int_{0}^{t}-\\theta_{n, T}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{V}^{2} \\mathrm{~d} s \\\\\n& +\\int_{0}^{t}\\left(M_{n, T}+\\frac{1}{2}\\left\\|\\Psi^{\\varepsilon}(s)\\right\\|_{U}^{2}\\right)\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2} \\mathrm{~d} s \\\\\n& +\\int_{0}^{t} C_{\\sigma}\\left\\|\\left(A_{0}\\left(s, u^{\\varepsilon}(s)\\right)-A_{0}\\left(s, X^{\\varepsilon}(s)\\right)\\right) X^{\\varepsilon}(s)\\right\\|_{V^{*}}^{2}+\\sigma\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{V}^{2} \\mathrm{~d} s \\\\\n& +\\int_{0}^{t} C_{\\sigma}\\left\\|F\\left(X^{\\varepsilon}(s)\\right)-F\\left(u^{\\varepsilon}(s)\\right)\\right\\|_{V^{*}}^{2}+\\sigma\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{V}^{2} \\mathrm{~d} s \\\\\n& +\\int_{0}^{t} \\frac{1}{2} \\llbracket\\left(B_{0}\\left(s, X^{\\varepsilon}(s)\\right)-B_{0}\\left(s, u^{\\varepsilon}(s)\\right)\\right) X^{\\varepsilon}(s) \\rrbracket_{H}^{2}+\\frac{1}{2}\\left\\|\\Psi^{\\varepsilon}(s)\\right\\|_{U}^{2}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2} \\mathrm{~d} s \\\\\n& +\\frac{1}{2} \\int_{0}^{t} \\llbracket G\\left(X^{\\varepsilon}(s)\\right)-G\\left(u^{\\varepsilon}(s)\\right) \\rrbracket_{H}^{2}+\\frac{1}{2}\\left\\|\\Psi^{\\varepsilon}(s)\\right\\|_{U}^{2}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2} \\mathrm{~d} s \\\\\n= & -\\theta_{n, T}\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2}+J_{1}^{\\varepsilon}(t)+J_{2}^{\\varepsilon, \\sigma}(t)+J_{3}^{\\varepsilon, \\sigma}(t)+J_{4}^{\\varepsilon}(t)+J_{5}^{\\varepsilon}(t) \\\\\n= & -\\theta_{n, T}\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2}+J_{1}^{\\varepsilon}(t)+J_{2}^{\\varepsilon, \\sigma}(t)+J_{3}^{\\varepsilon, \\sigma}(t)+J_{4}^{\\varepsilon}(t)+J_{5}^{\\varepsilon}(t)\n\\end{aligned}\n$$\n\nfor any $\\sigma>0$, where $C_{\\sigma}:=\\frac{1}{4 \\sigma}$ from Young's inequality and $\\theta_{n, T}$ and $M_{n, T}$ are the constants from the local coercivity of $\\left(A_{0}, B_{0}\\right)$ in Assumption 2.2(2).\n\nNext, we estimate the terms of (4.32). $J_{1}^{\\varepsilon}$ is already in the desired form for application of Gronwall's inequality. Moreover, Lemma 3.8(iii) yields\n\n$$\n\\begin{aligned}\nJ_{2}^{\\varepsilon, \\sigma}(t) & \\leq C_{\\sigma} C_{n, T}^{2} \\int_{0}^{t}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2}\\left\\|X^{\\varepsilon}(s)\\right\\|_{V}^{2} \\mathrm{~d} s+\\sigma\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2} \\\\\nJ_{4}^{\\varepsilon}(t) & \\leq \\frac{1}{2} \\int_{0}^{t}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2}\\left(C_{n, T}^{2}\\left\\|X^{\\varepsilon}(s)\\right\\|_{V}^{2}+\\left\\|\\Psi^{\\varepsilon}(s)\\right\\|_{U}^{2}\\right) \\mathrm{d} s\n\\end{aligned}\n$$\n\nSimilarly, Lemma 3.8(v) gives for any $\\tilde{\\sigma}>0$ :\n\n$$\n\\begin{aligned}\nJ_{3}^{\\varepsilon, \\sigma}(t) \\leq & C_{\\sigma} C_{n, T, \\tilde{\\sigma}} \\int_{0}^{t}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2}\\left(1+\\left\\|X^{\\varepsilon}(s)\\right\\|_{V}^{2}+\\left\\|u^{\\varepsilon}(s)\\right\\|_{V}^{2}\\right) \\mathrm{d} s \\\\\n& +C_{\\sigma} \\tilde{\\sigma} C_{n, T}^{2}\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2}+\\sigma\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2}\n\\end{aligned}\n$$\n\nfor some constant $C_{n, T, \\tilde{\\sigma}}>0$, and\n\n$$\n\\begin{aligned}\nJ_{5}^{\\varepsilon}(t) \\leq & \\frac{1}{2} \\int_{0}^{t}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2}\\left(C_{n, T, \\tilde{\\sigma}}\\left(1+\\left\\|X^{\\varepsilon}(s)\\right\\|_{V}^{2}+\\left\\|u^{\\varepsilon}(s)\\right\\|_{V}^{2}\\right)+\\left\\|\\Psi^{\\varepsilon}(s)\\right\\|_{U}^{2}\\right) \\mathrm{d} s \\\\\n& +\\frac{1}{2} \\tilde{\\sigma} C_{n, T}^{2}\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2}\n\\end{aligned}\n$$\n\nNow we fix $\\sigma:=\\frac{\\theta_{n, T}}{8}$. Then we fix $\\tilde{\\sigma}:=\\frac{\\theta_{n, T}}{8 C_{n, T}^{2}\\left(C_{\\sigma}+\\frac{1}{2}\\right)}$. Combining estimates (4.33)-(4.36) with (4.32), we obtain\n\n$$\nI_{1}^{\\varepsilon}(t)+I_{2}^{\\varepsilon}(t) \\leq-\\theta_{n, T}\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{L^{2}(0, t ; V)}^{2}+\\int_{0}^{t} h_{n, \\varepsilon}(s)\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2} \\mathrm{~d} s\n$$\n\nwhere $h_{n, \\varepsilon}$ is of the form\n\n$$\nh_{n, \\varepsilon}(s)=C_{n, T, \\sigma, \\tilde{\\sigma}}\\left(1+\\left\\|\\Psi^{\\varepsilon}(s)\\right\\|_{U}^{2}+\\left\\|X^{\\varepsilon}(s)\\right\\|_{V}^{2}+\\left\\|u^{\\varepsilon}(s)\\right\\|_{V}^{2}\\right)\n$$\n\nfor a constant $C_{n, T, \\sigma, \\tilde{\\sigma}}>0$. Now, a.s. $\\Psi^{\\varepsilon} \\in L^{2}(0, T ; U)$ and a.s. $X^{\\varepsilon}, u^{\\varepsilon} \\in L^{2}(0, T ; V)$, thus a.s. $h_{n, \\varepsilon} \\in L^{1}(0, T)$. By definition of $E_{n, \\varepsilon}$, by (4.37) and since $\\left(\\Psi^{\\varepsilon}\\right) \\subset \\mathcal{A}_{K}$, we have a.s. $\\left\\|h_{n, \\varepsilon} \\mathbb{1}_{E_{n, \\varepsilon}}\\right\\|_{L^{1}(0, T)} \\leq C_{n, T, \\sigma, \\tilde{\\sigma}}\\left(T+K^{2}+2 n^{2}\\right)$ for every $\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)$. Thus, $h_{n, \\varepsilon}$ has all required properties and (4.29) is satisfied a.s. on the set $E_{n, \\varepsilon}$, for every $\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)$, as desired.\n\nRegarding (4.30), by Lemma 4.11 we have for any (fixed) $\\delta>0$ :\n\n$$\n\\lim _{\\varepsilon \\downarrow 0} \\mathbb{P}\\left(I_{3}^{\\varepsilon}(T)>\\delta\\right)=\\lim _{\\varepsilon \\downarrow 0} \\mathbb{P}\\left(\\left\\|B\\left(\\cdot, X^{\\varepsilon}(\\cdot)\\right)\\right\\|_{L^{2}(0, T ; \\mathcal{L}_{2}(U, H))}^{2}>\\delta \\varepsilon^{-1}\\right) \\leq \\lim _{\\varepsilon \\downarrow 0} C \\varepsilon \\delta^{-1}=0\n$$\n\nIt remains to prove (4.31). Note that $I_{4}^{\\varepsilon}$ is a continuous local martingale (using Lemma 4.11) starting at zero, with $\\left[I_{4}^{\\varepsilon}\\right](T)=\\int_{0}^{T} \\varepsilon\\left\\|\\left\\langle X^{\\varepsilon}(s)-u^{\\varepsilon}(s), B\\left(s, X^{\\varepsilon}(s)\\right)(\\cdot)\\right\\rangle\\right\\|_{\\mathcal{L}_{2}(U, \\mathbb{R})}^{2} \\mathrm{~d} s$, where $\\left[I_{4}^{\\varepsilon}\\right]$ denotes the quadratic variation. Thus, by [23, Prop. 18.6], (4.31) is equivalent to\n\n$$\n\\lim _{\\varepsilon \\downarrow 0} \\mathbb{P}\\left(\\varepsilon \\int_{0}^{T}\\left\\|\\left\\langle X^{\\varepsilon}(s)-u^{\\varepsilon}(s), B\\left(s, X^{\\varepsilon}(s)\\right)(\\cdot)\\right\\rangle\\right\\|_{\\mathcal{L}_{2}(U, \\mathbb{R})}^{2} \\mathrm{~d} s>\\delta\\right)=0 \\text { for all } \\delta>0\n$$\n\nWe prove the latter. We have for all $\\delta>0$ and $\\varepsilon \\in\\left(0, \\frac{1}{2}\\right)$ :\n\n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(\\varepsilon \\int_{0}^{T}\\left\\|\\left\\langle X^{\\varepsilon}(s)-u^{\\varepsilon}(s), B\\left(s, X^{\\varepsilon}(s)\\right)(\\cdot)\\right\\rangle\\right\\|_{\\mathcal{L}_{2}(U, \\mathbb{R})}^{2} \\mathrm{~d} s>\\delta\\right) \\\\\n& \\leq \\mathbb{P}\\left(\\int_{0}^{T}\\left\\|X^{\\varepsilon}(s)-u^{\\varepsilon}(s)\\right\\|_{H}^{2}\\left\\|B\\left(s, X^{\\varepsilon}(s)\\right)\\right\\|_{H}^{2} \\mathrm{~d} s>\\delta \\varepsilon^{-1}\\right) \\\\\n& \\leq \\mathbb{P}\\left(\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{C([0, T] ; H)}^{2} \\int_{0}^{T}\\left\\|B\\left(s, X^{\\varepsilon}(s)\\right)\\right\\|_{H}^{2} \\mathrm{~d} s>\\delta \\varepsilon^{-1}\\right) \\\\\n& \\leq \\mathbb{P}\\left(\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{C([0, T] ; H)}>\\left(\\delta \\varepsilon^{-1}\\right)^{\\frac{1}{4}}\\right)+\\mathbb{P}\\left(\\left\\|B\\left(\\cdot, X^{\\varepsilon}(\\cdot)\\right)\\right\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)}>\\left(\\delta \\varepsilon^{-1}\\right)^{\\frac{1}{4}}\\right) .\n\\end{aligned}\n$$\n\nDue to Lemma 4.11, we have\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(\\left\\|X^{\\varepsilon}-u^{\\varepsilon}\\right\\|_{C([0, T] ; H)}>\\left(\\delta \\varepsilon^{-1}\\right)^{\\frac{1}{4}}\\right) & \\leq \\mathbb{P}\\left(\\left\\|X^{\\varepsilon}\\right\\|_{C([0, T] ; H)}>\\frac{1}{2}\\left(\\delta \\varepsilon^{-1}\\right)^{\\frac{1}{4}}\\right)+\\mathbb{P}\\left(\\left\\|u^{\\varepsilon}\\right\\|_{C([0, T] ; H)}>\\frac{1}{2}\\left(\\delta \\varepsilon^{-1}\\right)^{\\frac{1}{4}}\\right) \\\\\n& \\leq 4 C\\left(\\varepsilon \\delta^{-1}\\right)^{\\frac{1}{2}}+\\mathbb{P}\\left(\\left\\|u^{\\varepsilon}\\right\\|_{C([0, T] ; H)}>\\frac{1}{2}\\left(\\delta \\varepsilon^{-1}\\right)^{\\frac{1}{4}}\\right)\n\\end{aligned}\n$$\n\n(4.41) $\\mathbb{P}\\left(\\left\\|B\\left(\\cdot, X^{\\varepsilon}(\\cdot)\\right)\\right\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)}>\\left(\\delta \\varepsilon^{-1}\\right)^{\\frac{1}{4}}\\right) \\leq C\\left(\\varepsilon \\delta^{-1}\\right)^{\\frac{1}{2}}$.\n\nNote that $\\mathbb{P}\\left(\\left\\|u^{\\varepsilon}\\right\\|_{C([0, T] ; H)}>\\frac{1}{2}\\left(\\delta \\varepsilon^{-1}\\right)^{\\frac{1}{4}}\\right)=0$ for all $\\varepsilon \\in\\left(0, \\frac{4}{16 N^{2}} \\wedge \\frac{1}{2}\\right)$ by (4.27). Thus, combining (4.40), (4.41) and continuing from (4.39), we see that for all $\\varepsilon \\in\\left(0, \\frac{4}{16 N^{2}} \\wedge \\frac{1}{2}\\right)$ :\n\n$$\n\\mathbb{P}\\left(\\varepsilon \\int_{0}^{T}\\left\\|\\left\\langle X^{\\varepsilon}(s)-u^{\\varepsilon}(s), B\\left(s, X^{\\varepsilon}(s)\\right)(\\cdot)\\right\\rangle\\right\\|_{\\mathcal{L}_{2}(U, \\mathbb{R})}^{2} \\mathrm{~d} s>\\delta\\right) \\leq 5 C\\left(\\varepsilon \\delta^{-1}\\right)^{\\frac{1}{2}}\n$$\n\nLetting $\\varepsilon \\downarrow 0$ we arrive at (4.38).\n4.4. Proof of Theorem 2.6. Proving Theorem 2.6 is now only a matter of combining.\n\nProof. We verify the criteria of Theorem 4.5. Note that $\\mathcal{E}:=\\operatorname{MR}(0, T)$ is Polish. Define $\\mathcal{G}^{0}$ by (4.4) and for $\\varepsilon>0$, let $\\mathcal{G}^{\\varepsilon}$ be the measurable map from Lemma 4.6. Now, (i) holds by Lemma 4.6, (ii) holds by Proposition 4.9 and (iii) holds by Proposition 4.12. The proof is complete.\n\nLastly, a small remark.\n\nRemark 4.13. The LDP of Theorem 2.6 implies the following Strong Law of Large Numbers: we have $Y^{\\varepsilon} \\rightarrow Y^{0}$ a.s. as $\\varepsilon \\downarrow 0$, where $Y^{0}$ solves (4.1) with $\\varepsilon=0$, i.e. with only the drift term. This follows from the Borel-Cantelli lemma and the fact that the rate function has a unique zero at $Y^{0}$. Indeed, $I\\left(Y^{0}\\right)=I\\left(u^{0}\\right)=0$ and if $I(z)=0$, one finds $\\left(\\psi_{n}\\right) \\subset L^{2}(0, T ; U)$ with $z=u^{\\psi_{n}}$ and $\\left\\|\\psi_{n}\\right\\|_{L^{2}(0, T ; U)} \\rightarrow 0$. Then, $u^{\\psi_{n}} \\rightarrow z$ in $\\operatorname{MR}(0, T)$ and by Proposition 4.9, $u^{\\psi_{n}} \\rightarrow u^{0}=Y^{0}$ in $\\operatorname{MR}(0, T)$, thus $\\{z \\in \\operatorname{MR}(0, T): I(z)=0\\}=\\left\\{Y^{0}\\right\\}$.", "tables": {}, "images": {}}, {"section_id": 7, "text": "# 5. APPLICATION TO FLUID DYNAMICS \n\nIn this subsection, we apply our results to an abstract fluid dynamics model considered in several earlier works. We closely follow the presentation of $[3,12]$ and focus on what the large deviation principle of Theorem 2.6 becomes in this setting. Afterwards, we specialize to the Navier-Stokes equations with gradient noise to make our results even more concrete.\n5.1. Abstract model. The abstract form of the problem we consider is as follows\n\n$$\n\\left\\{\\begin{aligned}\n\\mathrm{d} Y^{\\varepsilon}(t)+A_{0}(t) Y^{\\varepsilon} \\mathrm{d} t & =\\Phi\\left(Y^{\\varepsilon}(t), Y^{\\varepsilon}(t)\\right) \\mathrm{d} t+\\sqrt{\\varepsilon}\\left(B_{0}(t) Y^{\\varepsilon}(t)+G\\left(t, Y^{\\varepsilon}(t)\\right)\\right) \\mathrm{d} W(t) \\\\\nu(0) & =x\n\\end{aligned}\\right.\n$$\n\nHere, $\\Phi$ is supposed to take care of the typical bilinear term appearing in equations in fluid dynamics. In particular, all of the following models can be included in the abstract framework below: 2D Navier-Stokes, 2D Boussinesq equations, quasigeostrophic equations, 2D magnetohydrodynamic equations, 2D magnetic B\u00e9nard problem, 3D Leray $\\alpha$-model for Navier-Stokes equations and shell models of turbulence.\n\nTo put this problem in the setting of (2.4) and Assumption 2.2, we assume the following.", "tables": {}, "images": {}}, {"section_id": 8, "text": "## Assumption 5.1.\n\n(1) $A_{0}: \\mathbb{R}_{+} \\rightarrow \\mathcal{L}\\left(V, V^{*}\\right)$ and $B_{0}: \\mathbb{R}_{+} \\rightarrow \\mathcal{L}\\left(V, \\mathcal{L}_{2}(U, H)\\right)$ are measurable and for all $T>0$, $\\sup _{t \\in[0, T]}\\left\\|A_{0}(t)\\right\\|_{\\mathcal{L}\\left(V, V^{*}\\right)}<\\infty$ and $\\sup _{t \\in[0, T]}\\left\\|B_{0}(t)\\right\\|_{\\mathcal{L}\\left(V, \\mathcal{L}_{2}(U, H)\\right)}<\\infty$. Moreover, for all $T>0$, there exist $\\theta>0$ and $M \\geq 0$ such that for all $v \\in V$ and $t \\in[0, T]$,\n\n$$\n\\left\\langle v, A_{0}(t) v\\right\\rangle-\\frac{1}{2}\\left\\|B_{0}(t) v\\right\\|_{\\mathcal{L}_{2}(U, H)}^{2} \\geq \\theta\\|v\\|_{V}^{2}-M\\|v\\|_{H}^{2}\n$$\n\n(2) For some $\\beta_{1} \\in\\left(\\frac{1}{2}, \\frac{3}{4}\\right], \\Phi: V_{\\beta_{1}} \\times V_{\\beta_{1}} \\rightarrow V^{*}$ is bilinear and satisfies\n\n$$\n\\|\\Phi(u, v)\\|_{V^{*}} \\leq C\\|u\\|_{\\beta_{1}}\\|v\\|_{\\beta_{1}}, \\quad\\langle u, \\Phi(u, u)\\rangle=0, \\quad u, v \\in V\n$$\n\n(3) For some $\\beta_{2} \\in\\left(\\frac{1}{2}, 1\\right), G: \\mathbb{R}_{+} \\times V_{\\beta_{2}} \\rightarrow \\mathcal{L}_{2}(U, H)$ is measurable and satisfies the following Lipschitz conditions: for all $T>0$, there exists a constant $C$ such that for all $u, v \\in V_{\\beta_{2}}$ and $t \\in[0, T]$,\n\n$$\n\\|G(t, u)-G(t, v)\\|_{\\mathcal{L}_{2}(U, H)} \\leq C\\|u-v\\|_{V_{\\beta_{2}}} \\text { and }\\|G(t, u)\\|_{\\mathcal{L}_{2}(U, H)} \\leq C\\left(1+\\|u\\|_{V_{\\beta_{2}}}\\right)\n$$\n\nThe associated skeleton equation is given by\n\n$$\n\\left\\{\\begin{array}{l}\n\\left(u^{\\psi}\\right)^{\\prime}(t)+A_{0}(t) u^{\\psi}(t)=\\Phi\\left(u^{\\psi}(t), u^{\\psi}(t)\\right)+\\left(B_{0}(t) u^{\\psi}(t)+G\\left(t, u^{\\psi}(t)\\right)\\right) \\psi(t), \\quad t \\in[0, T] \\\\\nu^{\\psi}(0)=x\n\\end{array}\\right.\n$$\n\nTheorem 5.2. Suppose that Assumption 5.1 holds, Then for every $x \\in H$ and $\\varepsilon \\in(0,1]$, the problem (5.1) has a unique global solution\n\n$$\nY^{\\varepsilon} \\in L_{\\mathrm{loc}}^{2}([0, \\infty) ; V) \\cap C([0, \\infty) ; H) \\text { a.s. }\n$$\n\nMoreover, for every $T>0,\\left(Y^{\\varepsilon}\\right)$ satisfies the LDP on $L_{\\mathrm{loc}}^{2}(0, T ; V) \\cap C([0, T] ; H)$ with rate function $I: L_{\\mathrm{loc}}^{2}(0, T ; V) \\cap C([0, T] ; H) \\rightarrow[0,+\\infty]$ given by\n\n$$\nI(z)=\\frac{1}{2} \\inf \\left\\{\\int_{0}^{T}\\|\\psi(s)\\|_{U}^{2} \\mathrm{~d} s: \\psi \\in L^{2}(0, T ; U), z=u^{\\psi}\\right\\}\n$$\n\nwhere $\\inf \\varnothing:=+\\infty$ and $u^{\\psi}$ is the strong solution to (5.2).\nProof. In [3, Th. 7.10] it is shown that Assumption 5.1 is satisfied, noting that the arguments also work for the time-dependent setting. Thus well-posedness follows from Theorem 2.3 and the large deviation principle follows from Theorem 2.6.\n\n5.2. LDP for Navier-Stokes equations with gradient noise. Next we specialize the result to the 2D Navier-Stokes equations on an arbitrary open set $\\mathcal{O} \\subseteq \\mathbb{R}^{2}$ (possibly unbounded), and we let the noise term contain a transport/gradient term. The large deviation principle is new even for the case $\\mathcal{O}=\\mathbb{R}^{2}$. Indeed, as explained in the introduction, previous results in the literature either contain a gap, or do not have gradient noise, or assume boundedness of the domain $\\mathcal{O}$.\n\nFor simplicity we only consider the case of It\u00f4 noise. For details on Stratonovich noise, see [5, App. A]. We follow the presentation of $[3, \\S 7.3 .4]$.\n\nConsider the following Navier-Stokes system with no-slip condition on domain $\\mathcal{O}$ :\n\n$$\n\\left\\{\\begin{aligned}\n\\mathrm{d} Y^{\\varepsilon}= & {\\left[\\nu \\Delta Y^{\\varepsilon}-\\left(Y^{\\varepsilon} \\cdot \\nabla\\right) Y^{\\varepsilon}-\\nabla P^{\\varepsilon}\\right] \\mathrm{d} t } \\\\\n& +\\sqrt{\\varepsilon} \\sum_{n \\geq 1}\\left[\\left(b_{n} \\cdot \\nabla\\right) Y^{\\varepsilon}+g_{n}\\left(\\cdot, Y^{\\varepsilon}\\right)-\\nabla \\widetilde{P}_{n}^{\\varepsilon}\\right] \\mathrm{d} W_{t}^{n} \\\\\n\\operatorname{div} Y^{\\varepsilon}= & 0 \\\\\nY^{\\varepsilon}= & 0 \\text { on } \\partial \\mathcal{O} \\\\\nY^{\\varepsilon}(0, \\cdot)= & u_{0}\n\\end{aligned}\\right.\n$$\n\nHere, $Y^{\\varepsilon}:=\\left(Y^{\\varepsilon, 1}, Y^{\\varepsilon, 2}\\right):[0, \\infty) \\times \\Omega \\times \\mathcal{O} \\rightarrow \\mathbb{R}^{2}$ denotes the unknown velocity field, $P^{\\varepsilon}, \\widetilde{P}_{n}^{\\varepsilon}:[0, \\infty) \\times$ $\\Omega \\times \\mathcal{O} \\rightarrow \\mathbb{R}$ the unknown pressures, $\\left(W_{t}^{n}: t \\geq 0\\right)_{n \\geq 1}$ a given sequence of independent standard Brownian motions and\n\n$$\n\\left(b_{n} \\cdot \\nabla\\right) u:=\\left(\\sum_{j \\in\\{1,2\\}} b_{n}^{j} \\partial_{j} u^{k}\\right)_{k=1,2}, \\quad(u \\cdot \\nabla) u:=\\left(\\sum_{j \\in\\{1,2\\}} u^{j} \\partial_{j} u^{k}\\right)_{k=1,2}\n$$\n\nAssumption 5.3. Let $d=2$. Let $b^{j}=\\left(b_{n}^{j}\\right)_{n \\geq 1}: \\mathbb{R}_{+} \\times \\mathcal{O} \\rightarrow \\ell^{2}$ be measurable and bounded and suppose that for every $T>0$ there exists a $\\mu \\in(0, \\nu)$ such that for all $x \\in \\mathcal{O}$ and $t \\in[0, T]$,\n\n$$\n\\frac{1}{2} \\sum_{n \\geq 1} \\sum_{i, j \\in\\{1,2\\}} b_{n}^{i}(x) b_{n}^{j}(x) \\xi_{i} \\xi_{j} \\leq \\mu|\\xi|^{2} \\quad \\text { for all } \\xi \\in \\mathbb{R}^{d}\n$$\n\nMoreover, $g^{1}, g^{2}: \\mathbb{R}_{+} \\times \\mathcal{O} \\times \\mathbb{R}^{2} \\rightarrow \\ell^{2}$ and for every $T>0$ there exists a constant $L_{g}$ such that\n\n$$\n\\begin{aligned}\n& \\left\\|g^{j}(t, x, y)-g^{j}\\left(t, x, y^{\\prime}\\right)\\right\\|_{\\ell^{2}} \\leq L_{g}\\left|y-y^{\\prime}\\right| \\\\\n& \\quad\\left\\|g^{j}(t, x, y)\\right\\|_{\\ell^{2}} \\leq L_{g}(1+|y|), \\quad x \\in \\mathcal{O}, y, y^{\\prime} \\in \\mathbb{R}^{2}, t \\in[0, T], j \\in\\{1,2\\}\n\\end{aligned}\n$$\n\nAs in $[3, \\S 7.3 .4]$, we can use the Helmholtz projection $\\mathbb{P}$ to rewrite (5.3) as (5.1). To this end, let $\\mathcal{U}=\\ell^{2}$ with standard basis $\\left(e_{n}\\right)_{n \\geq 1}$ and let\n\n$$\nH=\\mathbb{L}^{2}(\\mathcal{O}), \\quad V=\\mathbb{H}_{0}^{1}(\\mathcal{O})=H_{0}^{1}\\left(\\mathcal{O} ; \\mathbb{R}^{2}\\right) \\cap \\mathbb{L}^{2}(\\mathcal{O}) \\text { and } V^{*}:=\\mathbb{H}^{-1}(\\mathcal{O})=\\left(\\mathbb{H}_{0}^{1}(\\mathcal{O})\\right)^{*}\n$$\n\nwhere $\\mathbb{L}^{2}(\\mathcal{O})$ denotes the range of the Helmholtz projection in $L^{2}\\left(\\mathcal{O} ; \\mathbb{R}^{2}\\right)$. By the divergence free condition, $(u \\cdot \\nabla) u=\\operatorname{div}(u \\otimes u)$, where $u \\otimes u$ is the matrix with components $u_{j} u_{k}$. Assuming $x \\in \\mathbb{L}^{2}(\\mathcal{O})$, after applying the Helmholtz projection $\\mathbb{P}$ to (5.3), we can write (5.3) in the form (5.1) with\n\n$$\nA_{0}=-\\nu \\mathbb{P} \\Delta, \\quad \\Phi(u, v)=-\\mathbb{P} \\operatorname{div}[u \\otimes v],\\left(B_{0} u\\right) e_{n}=\\mathbb{P}\\left[\\left(b_{n} \\cdot \\nabla\\right) u\\right], \\text { and } G(u) e_{n}=\\mathbb{P} g_{n}(\\cdot, u)\n$$\n\nFor $\\psi \\in L^{2}\\left(0, T ; \\ell^{2}\\right)$, consider the following skeleton equation on $\\mathcal{O}$ :\n\n$$\n\\left\\{\\begin{aligned}\n\\mathrm{d} u^{\\psi} & =\\left[\\nu \\Delta u^{\\psi}-\\mathbb{P} \\operatorname{div}\\left(u^{\\psi} \\otimes u^{\\psi}\\right)\\right] \\mathrm{d} t+\\sqrt{\\varepsilon} \\sum_{n \\geq 1}\\left(\\mathbb{P}\\left[\\left(b_{n} \\cdot \\nabla\\right) u^{\\psi}\\right]+\\mathbb{P} g_{n}\\left(\\cdot, u^{\\psi}\\right)\\right) \\psi_{n} \\\\\nu^{\\psi} & =0 \\text { on } \\partial \\mathcal{O} \\\\\nu^{\\psi}(0, \\cdot) & =u_{0}\n\\end{aligned}\\right.\n$$\n\nIn $[3, \\S 7.3 .4]$ it is verified that Assumption 5.1 is fulfilled for the above setting. Thus we obtain the next result immediately from Theorem 5.2.\n\nTheorem 5.4 (LDP for the 2D Navier-Stokes equations with transport noise). Let $d=2$. Suppose that Assumption 5.3 holds, Then for every $x \\in \\mathbb{L}^{2}(\\mathcal{O})$ and $\\varepsilon \\in(0,1]$, there exists a unique global solution $Y^{\\varepsilon} \\in L_{\\mathrm{loc}}^{2}\\left([0, \\infty) ; \\mathbb{H}_{0}^{1}(\\mathcal{O})\\right) \\cap C\\left([0, \\infty) ; \\mathbb{L}^{2}(\\mathcal{O})\\right)$ to (5.3). Moreover, for every $T>0$,\n\n$\\left(Y^{e}\\right)$ satisfies the $L D P$ on $\\operatorname{MR}(0, T):=L_{\\text {loc }}^{2}\\left(0, T ; \\mathbb{H}_{0}^{1}(\\mathcal{O})\\right) \\cap C\\left([0, T] ; \\mathbb{L}^{2}(\\mathcal{O})\\right)$ with rate function $I: \\operatorname{MR}(0, T) \\rightarrow[0,+\\infty]$ given by\n\n$$\nI(z)=\\frac{1}{2} \\inf \\left\\{\\int_{0}^{T}\\|\\psi(s)\\|_{\\ell^{2}}^{2} \\mathrm{~d} s: \\psi \\in L^{2}\\left(0, T ; \\ell^{2}\\right), z=u^{\\psi}\\right\\}\n$$\n\nwhere $\\inf \\varnothing:=+\\infty$ and $u^{\\psi}$ is the strong solution to (5.4).", "tables": {}, "images": {}}, {"section_id": 9, "text": "# Appendix A. \n\nFor convenience we state some tools that are used repeatedly. To begin, let us state a direct consequence of Gronwall's inequality.\nLemma A. 1 (Gronwall). Let $T>0$ and let $F, G, H, K:[0, T] \\rightarrow \\mathbb{R}_{+}$with $F$ and $G$ continuous, $K$ non-decreasing and $H \\in L^{1}(0, T)$. Suppose that $F(t) \\leq-G(t)+K(t)+\\int_{0}^{t} F(s) H(s) \\mathrm{d} s$ for all $t \\in[0, T]$. Then\n\n$$\n\\sup _{t \\in[0, T]} F(t) \\vee \\sup _{t \\in[0, T]} G(t) \\leq K(T) \\exp \\left[\\|H\\|_{L^{1}(0, T)}\\right]\n$$\n\nThe following special case of a chain rule from [34] is useful, since it applies to $L^{2}\\left(0, T ; V^{*}\\right)+$ $L^{1}(0, T ; H)$-valued integrands.\n\nLemma A.2. [34, Lem. 2.2 p. 30] Let $\\left(V, H, V^{*}\\right)$ be a Gelfand triple of Hilbert spaces. Let $x \\in H, u \\in C([0, T] ; H) \\cap L^{2}(0, T ; V)$ and $v \\in L^{2}\\left(0, T ; V^{*}\\right)+L^{1}(0, T ; H)$ be such that\n\n$$\nu(t)=x+\\int_{0}^{t} v(s) \\mathrm{d} s \\text { in } V^{*}, \\quad \\text { for all } t \\in[0, T]\n$$\n\nThen for all $t \\in[0, T]$ :\n\n$$\n\\|u(t)\\|_{H}^{2}=\\|x\\|_{H}^{2}+2 \\int_{0}^{t}\\langle v(s), u(s)\\rangle \\mathrm{d} s\n$$\n\nProof. Note that $u \\in L^{2}(0, T ; V) \\cap L^{\\infty}(0, T ; H)$ and $v \\in L^{1}\\left(0, T ; V^{*}\\right)$. Thus by (A.1), $u$ is weakly differentiable with $u^{\\prime}=v$ a.e. on $[0, T]$, see [21, Lem. 2.5.8]. Hence, $u^{\\prime}=v \\in L^{2}\\left(0, T ; V^{*}\\right)+$ $L^{1}(0, T ; H)$. Also, (A.1) implies absolute continuity of $u:[0, T] \\rightarrow V^{*}$. Now [34, Lem. 2.2 p. 30, $p=2]$ gives $\\frac{\\mathrm{d}}{\\mathrm{d} t}\\|u(t)\\|_{H}^{2}=2\\left\\langle u^{\\prime}(t), u(t)\\right\\rangle=2\\langle v(t), u(t)\\rangle$ a.e., proving (A.2).\n\nStochastic versions of the chain rule, or It\u00f4 formula, are also given in [34]. The following special case is suited for random, $L^{2}\\left(0, T ; V^{*}\\right)+L^{1}(0, T ; H)$-valued integrands. We recall that the class of integrable processes for a $U$-cylindrical Brownian motion (Definition 4.1) is given by\n\n$$\n\\mathcal{N}(0, T):=\\left\\{\\Phi:[0, T] \\times \\Omega \\rightarrow \\mathcal{L}_{2}(U, H): \\Phi \\text { strongly progressively measurable }\\right.\n$$\n\n$$\n\\mathbb{P}\\left(\\|\\Phi\\|_{L^{2}\\left(0, T ; \\mathcal{L}_{2}(U, H)\\right)}<\\infty\\right)=1\\}\n$$\n\nLemma A.3. [34, Th. 3.1 p. 57, Th. 3.3 p. 59] Let $\\left(V, H, V^{*}\\right)$ be a Gelfand triple of Hilbert spaces and let $\\left(\\Omega, \\mathcal{F}, \\mathbb{P},\\left(\\mathcal{F}_{t}\\right)_{t \\in \\mathbb{R}_{+}}\\right)$be a filtered probability space. Suppose that\n(i) $u \\in L^{0}\\left(\\Omega ; L^{2}(0, T ; V)\\right), u_{0} \\in L^{0}\\left(\\Omega, \\mathcal{F}_{0}, \\mathbb{P} ; H\\right)$,\n(ii) $v \\in L^{0}\\left(\\Omega ; L^{1}(0, T ; H)\\right)+L^{0}\\left(\\Omega ; L^{2}\\left(0, T ; V^{*}\\right)\\right), v$ is adapted,\n(iii) $\\Phi \\in \\mathcal{N}(0, T), W$ is a $U$-cylindrical Brownian motion,\n(iv) a.s. for all $t \\in[0, T]: u(t)=u_{0}+\\int_{0}^{t} v(s) \\mathrm{d} s+\\int_{0}^{t} \\Phi(s) \\mathrm{d} W(s)$.\n\nThen, $u \\in L^{0}(\\Omega ; C([0, T] ; H))$ and a.s. for all $t \\in[0, T]$ :\n\n$$\n\\|u(t)\\|_{H}^{2}=\\left\\|u_{0}\\right\\|_{H}^{2}+2 \\int_{0}^{t}\\langle v(s), u(s)\\rangle \\mathrm{d} s+2 \\int_{0}^{t}\\langle u(s), \\Phi(s) \\mathrm{d} W(s)\\rangle+\\int_{0}^{t} \\llbracket \\Phi(s) \\rrbracket_{H}^{2} \\mathrm{~d} s\n$$\n\nFinally, we relate the $U$-cylindrical Brownian motion $W$ of Definition 4.1 to the $\\mathbb{R}^{\\infty}$-Brownian motion $\\widetilde{W}$ of Definition 4.2, as well as their stochastic integrals constructed in [31] and [29], respectively.\n\nAn $\\mathbb{R}^{\\infty}$-Brownian motion $\\tilde{W}=\\left(\\left(\\beta_{k}\\right)_{k \\in \\mathbb{N}},\\left(e_{k}\\right)_{k \\in \\mathbb{N}}\\right)$ in $U$ corresponds to a Wiener process $\\tilde{W}_{1}$ in a larger space $U_{1}$, with trace class covariance. That is, for any Hilbert-Schmidt embedding $J: U \\hookrightarrow U_{1}$, the $U_{1}$-valued process given by\n\n$$\n\\tilde{W}_{1}(t):=\\sum_{k=1}^{\\infty} \\beta_{k}(t) J e_{k}, \\quad t \\in[0, T]\n$$\n\ndefines a $Q_{1}$-Wiener process on $U_{1}$, with $Q_{1}:=J J^{*} \\in \\mathcal{L}\\left(U_{1}, U_{1}\\right)$ nonnegative definite, symmetric and of trace class [29, Prop. 2.5.2].\n\nIt is well-known that $\\mathcal{N}(0, T)$ from (A.3) is the class of integrable processes for both $\\tilde{W}$ and $W$, see [29, p. 52, p. 53], [1, Prop. 2.13] and the proof in [31, p. 306, $\\S 5.4(p=0)$ ]. The next proposition relates the stochastic integrals corresponding to $\\tilde{W}$ and $W$.\n\nProposition A.4. For any $U$-cylindrical Brownian motion $W \\in \\mathcal{L}\\left(L^{2}\\left(\\mathbb{R}_{+} ; U\\right), L^{2}(\\Omega)\\right)$ and any orthonormal basis $\\left(e_{k}\\right)_{k \\in \\mathbb{N}}$ of $U$, there exists an $\\mathbb{R}^{\\infty}$-Brownian motion $\\tilde{W}=\\left(\\left(\\beta_{k}\\right)_{k \\in \\mathbb{N}},\\left(e_{k}\\right)_{k \\in \\mathbb{N}}\\right)$ with\n\n$$\nW\\left(\\mathbb{1}_{(0, t]} \\otimes e_{k}\\right)=\\beta_{k}(t) \\quad \\text { in } L^{2}(\\Omega), \\quad \\text { for all } k \\in \\mathbb{N} \\text { and } t \\in \\mathbb{R}_{+}\n$$\n\nThe sequence $\\left(\\beta_{k}\\right)_{k \\in \\mathbb{N}}$ in $\\tilde{W}$ is unique up to indistinguishability.\nReversely, given an $\\mathbb{R}^{\\infty}$-Brownian motion $\\tilde{W}=\\left(\\left(\\beta_{k}\\right)_{k \\in \\mathbb{N}},\\left(e_{k}\\right)_{k \\in \\mathbb{N}}\\right)$, there exists a unique $U$ cylindrical Brownian motion $W \\in \\mathcal{L}\\left(L^{2}\\left(\\mathbb{R}_{+} ; U\\right), L^{2}(\\Omega)\\right)$ that satisfies (A.6).\n\nIf (A.6) holds, then for any $\\Phi \\in \\mathcal{N}(0, T)$ and $t \\in[0, T]$, we have $\\mathbb{P}$-a.s. in $C([0, T] ; H)$ :\n\n$$\n\\int_{0}^{t} \\Phi(s) \\mathrm{d} W(s)=\\int_{0}^{t} \\Phi(s) \\circ J^{-1} \\mathrm{~d} \\tilde{W}_{1}(s)=: \\int_{0}^{t} \\Phi(s) \\mathrm{d} \\tilde{W}(s), \\quad t \\in[0, T]\n$$\n\nwith $\\tilde{W}_{1}$ as in (A.5). Here, the integral on the left-hand side is the one constructed in [31] and the middle and right integral are those constructed in [29, \u00a72.3, \u00a72.5].", "tables": {}, "images": {}}, {"section_id": 10, "text": "# REFERENCES \n\n[1] A. Agresti and M. Veraar. \"Nonlinear parabolic stochastic evolution equations in critical spaces part I. Stochastic maximal regularity and local existence\". In: Nonlinearity 35.8 (2022), pp. 4100-4210.\n[2] A. Agresti and M. Veraar. \"Nonlinear parabolic stochastic evolution equations in critical spaces part II. Blow-up criteria and instantaneous regularization\". In: J. Evol. Equ. 22.56 (2022).\n[3] A. Agresti and M. Veraar. Nonlinear SPDEs and maximal regularity: an extended survey. 2025. arXiv: 2501.18561.\n[4] A. Agresti and M. Veraar. \"Reaction-diffusion equations with transport noise and critical superlinear diffusion: global well-posedness of weakly dissipative systems\". In: SIAM J. Math. Anal. 56.4 (2024), pp. 4870-4927.\n[5] A. Agresti and M. Veraar. \"Stochastic Navier-Stokes equations for turbulent flows in critical spaces\". In: Commun. Math. Phys. 405.2 (2024), Paper no. 43.\n[6] A. Agresti and M. Veraar. \"The critical variational setting for stochastic evolution equations\". In: Probab. Theory Relat. Fields (2024).\n[7] W. Arendt. \"Semigroups and evolution equations: functional calculus, regularity and kernel estimates\". In: Handbook of differential equations: evolutionary equations. Vol. 1. Elsevier North Holland, 2002, pp. 1-85.\n[8] A. Bensoussan and R. Temam. \"Equations aux derivees partielles stochastiques non lineaires\". In: Isr. J. Math. 11.1 (1972), pp. 95-129.\n[9] A. Budhiraja and P. Dupuis. \"A variational representation for positive functionals of infinite dimensional Brownian motion\". In: Probab. Math. Stat. 20.1 (2001).\n[10] S. Cerrai and M. R\u00f6ckner. \"Large deviations for stochastic reaction-diffusion systems with multiplicative noise and non-Lipschitz reaction term\". In: Ann. Probab. 32.1 (2004).\n[11] P. Chow. \"Large deviation problem for some parabolic It\u00f4 equations\". In: Commun. Pure Appl. Math. 45.1 (1992), pp. 97-120.\n\n[12] I. Chueshov and A. Millet. \"Stochastic 2D hydrodynamical type systems: well posedness and large deviations\". In: Appl. Math. Optim. 61.3 (2010), pp. 379-420.\n[13] G. Da Prato and J. Zabczyk. Stochastic equations in infinite dimensions. Second edition. Cambridge: Cambridge University Press, 2014.\n[14] A. Dembo and O. Zeitouni. Large deviations techniques and applications. Second edition. Berlin, Heidelberg: Springer, 2010.\n[15] J. Duan and A. Millet. \"Large deviations for the Boussinesq equations under random influences\". In: Stoch. Process. Their Appl. 119.6 (2009), pp. 2052-2081.\n[16] P. Dupuis and R. S. Ellis. A weak convergence approach to the theory of large deviations. New York: John Wiley \\& Sons, Inc., 1997.\n[17] B. Ferrario. \"Uniqueness and absolute continuity for semilinear SPDE's\". In: Seminar on stochastic analysis, random fields and applications VII. Basel: Springer, 2013, pp. 85-94.\n[18] M. I. Freidlin, A. D. Wentzell, and J. Sz\u00fccs. Random perturbations of dynamical systems. Third edition. Berlin, Heidelberg: Springer, 2012.\n[19] S. Geiss. \"Sharp convex generalizations of stochastic Gronwall inequalities\". In: J. Differ. Equ. 392 (2024), pp. 74-127.\n[20] W. Hong, S. Li, and W. Liu. \"Large deviation principle for McKean-Vlasov quasilinear stochastic evolution equations\". In: Appl. Math. Optim. 84.1 (2021), pp. 1119-1147.\n[21] T. Hyt\u00f6nen, J. van Neerven, M. Veraar, and L. Weis. Analysis in Banach spaces Vol. I. Martingales and Littlewood-Paley theory. Cham: Springer, 2016.\n[22] T. Hyt\u00f6nen, J. van Neerven, M. Veraar, and L. Weis. Analysis in Banach spaces Vol. III. Harmonic analysis and spectral theory. Cham: Springer, 2023.\n[23] O. Kallenberg. Foundations of modern probability. Cham: Springer, 2021.\n[24] I. Karatzas and S. E. Shreve. Brownian motion and stochastic calculus. New York: Springer, 1998.\n[25] A. S. Kechris. Classical descriptive set theory. New York: Springer, 1995.\n[26] N. V. Krylov and B. L. Rozovskii. \"Stochastic evolution equations\". In: J. Math. Sci. 16.4 (1981), pp. 1233-1277.\n[27] A. Kumar and M. Mohan. \"Large deviation principle for a class of stochastic partial differential equations with fully local monotone coefficients perturbed by L\u00e9vy noise\". In: Potential Anal. 62.3 (2025), pp. 563-623.\n[28] W. Liu. \"Large deviations for stochastic evolution equations with small multiplicative noise\". In: Appl. Math. Optim. 61.1 (2009), pp. 27-56.\n[29] W. Liu and M. R\u00f6ckner. Stochastic partial differential equations: an introduction. New York: Springer, 2015.\n[30] A. Matoussi, W. Sabbagh, and T. Zhang. \"Large deviation principles of obstacle problems for quasilinear stochastic PDEs\". In: Appl. Math. Optim. 83.2 (2021), pp. 849-879.\n[31] J. van Neerven, M. Veraar, and L. Weis. \"Stochastic integration in Banach spaces - a survey\". In: Stochastic analysis: a series of lectures. Vol. 68. Basel: Springer, 2015, pp. 297-332.\n[32] T. Pan and S. Shang. Large deviations of fully local monotone stochastic partial differential equations driven by gradient-dependent noise. 2022. arXiv: 2212.10282v1.\n[33] T. Pan, S. Shang, J. Zhai, and T. Zhang. Large deviations of fully local monotone stochastic partial differential equations driven by gradient-dependent noise. 2024. arXiv: 2212.10282v2.\n[34] E. Pardoux. \"Equations aux d\u00e9riv\u00e9es partielles stochastiques non lin\u00e9aires monotones; Etude de solutions fortes de type It\u00f4\". PhD thesis. Centre d'Orsay, 1975.\n[35] S. Peszat. \"Large deviation principle for stochastic evolution equations\". In: Probab. Theory Relat. Fields 98.1 (1994), pp. 113-136.\n[36] J. Pr\u00fcss and G. Simonett. Moving interfaces and quasilinear parabolic evolution equations. Cham: Birkh\u00e4user, 2016.\n[37] J. Pr\u00fcss, G. Simonett, and M. Wilke. \"Critical spaces for quasilinear parabolic evolution equations and applications\". In: J. Differ. Equ. 264.3 (2018), pp. 2028-2074.\n[38] J. Pr\u00fcss and M. Wilke. \"Addendum to the paper \"On quasilinear parabolic evolution equations in weighted $L_{p}$-spaces II\"\". In: J. Evol. Equ. 17.4 (2017), pp. 1381-1388.\n\n[39] J. Ren and X. Zhang. \"Freidlin-Wentzell's large deviations for stochastic evolution equations\". In: J. Funct. Anal. 254.12 (2008), pp. 3148-3172.\n[40] M. R\u00f6ckner, B. Schmuland, and X. Zhang. \"Yamada-Watanabe theorem for stochastic evolution equations in infinite dimensions\". In: Condens. Matter Phys. 54 (2008), pp. 247-259.\n[41] M. R\u00f6ckner, S. Shang, and T. Zhang. \"Well-posedness of stochastic partial differential equations with fully local monotone coefficients\". In: Math. Ann. 390.3 (2024), pp. 3419-3469.\n[42] M. R\u00f6ckner, F. Wang, and L. Wu. \"Large deviations for stochastic generalized porous media equations\". In: Stoch. Process. Their Appl. 116.12 (2006), pp. 1677-1689.\n[43] M. R\u00f6ckner, T. Zhang, and X. Zhang. \"Large deviations for stochastic tamed 3D NavierStokes equations\". In: Appl. Math. Optim. 61.2 (2010), pp. 267-285.\n[44] B. P. Rynne and M. A. Youngson. Linear functional analysis. Second edition. London: Springer, 2008.\n[45] S. S. Sritharan and P. Sundar. \"Large deviations for the two-dimensional Navier-Stokes equations with multiplicative noise\". In: Stoch. Process. Their Appl. 116.11 (2006), pp. 16361659 .\n(E. S. Theewis) Delft Institute of Applied Mathematics, Delft University of Technology, P.O. Box 5031, 2600 GA Delft, The Netherlands\nEmail address: E.S.Theewis@tudelft.nl\n(M. C. Veraar) Delft Institute of Applied Mathematics, Delft University of Technology, P.O. Box 5031, 2600 GA Delft, The Netherlands\nEmail address: M.C. Veraar@tudelft.nl", "tables": {}, "images": {}}], "id": "2402.16622v3", "authors": ["Esm\u00e9e Theewis", "Mark Veraar"], "categories": ["math.PR", "math.AP"], "abstract": "Using the weak convergence approach, we prove the large deviation principle\n(LDP) for solutions to quasilinear stochastic evolution equations with small\nGaussian noise in the critical variational setting, a recently developed\ngeneral variational framework. No additional assumptions are made apart from\nthose required for well-posedness. In particular, no monotonicity is required,\nnor a compact embedding in the Gelfand triple. Moreover, we allow for flexible\ngrowth of the diffusion coefficient, including gradient noise. This leads to\nnumerous applications for which the LDP was not established yet, in particular\nequations on unbounded domains with gradient noise. Since our framework\nincludes the 2D Navier-Stokes and Boussinesq equations with gradient noise and\nunbounded domains, our results resolve an open problem that has remained\nunsolved for over 15 years.", "updated": "2025-04-18T18:36:13Z", "published": "2024-02-26T14:52:48Z"}