{"title": "Transition of $\u03b1$-mixing in Random Iterations with Applications in\n  Queuing Theory", "sections": [{"section_id": 0, "text": "#### Abstract\n\nNonlinear time series models with exogenous regressors are essential in econometrics, queuing theory, and machine learning, though their statistical analysis remains incomplete. Key results, such as the law of large numbers and the functional central limit theorem, are known for weakly dependent variables. We demonstrate the transfer of mixing properties from the exogenous regressor to the response via coupling arguments. Additionally, we study Markov chains in random environments with drift and minorization conditions, even under non-stationary environments with favorable mixing properties, and apply this framework to single-server queuing models.", "tables": {}, "images": {}}, {"section_id": 1, "text": "## Introduction\n\nIt is very common in natural and social sciences that for describing the time evolution of certain quantity of interests, researchers build models incorporating input variables not influenced by other variables in the system and on which the output variable depends. Such explicative variables, especially in econometrics literature, are called exogeneous covariates. Let $\\mathcal{X}, \\mathcal{Y}$, and $\\mathcal{Z}$ be complete and separable metric spaces. The $\\mathcal{X}$-valued process $\\left(X_{t}\\right)_{t \\in \\mathbb{N}}$ represents the time series of interest and the $\\mathcal{Y}$-valued process $\\left(Y_{t}\\right)_{t \\in \\mathbb{Z}}$ denotes the exogeneous covariate. We postulate that $\\left(X_{t}\\right)_{t \\in \\mathbb{N}}$ satisfies the recursion\n\n$$\nX_{t+1}=f\\left(X_{t}, Y_{t}, \\varepsilon_{t+1}\\right)\n$$\n\nwhere $X_{0}$ is a possibly random initial state, $f: \\mathcal{X} \\times \\mathcal{Y} \\times \\mathcal{Z} \\rightarrow \\mathcal{X}$ is a measurable function, and $\\varepsilon_{t} \\in \\mathcal{Z}, t \\in \\mathbb{N}$ represents the noise entering to the system.\n\nThe exploration and analysis of non-linear autoregressive processes of this kind constitute a recent and actively developing area of research. In particular, there is a pronounced surge of interest within the fields of applied statistics and econometrics regarding the investigation of standard time series models that incorporate exogeneous regressors. Notable examples include a novel class of Poisson autoregressive models with exogeneous covariates (PARX) introduced by Agosto et al. [1] for modeling corporate defaults. Additionally, the recent research by Gorgi and Koopman [23] has provided valuable insights on observation-driven models involving beta autoregressive processes with exogeneous factors. Furthermore, the theory of non-linear autoregressive processes allows researchers for analyzing large-scale stochastic optimization algorithms, which play a pivotal role in machine learning applications, see $[7,35]$.\n\nThe statistical analysis of general non-linear time series models with exogenous covariates necessitates the law of large numbers (LLN), central limit theorem (CLT), and others. However, this\n\n[^0]\n[^0]:    *The author was supported by the National Research, Development and Innovation Office within the framework of the Thematic Excellence Program 2021; National Research subprogram \"Artificial intelligence, large networks, data security: mathematical foundation and applications\" and also by the grant K 143529.\n\nframework is presently unavailable. Researchers have investigated these models under additional assumptions that facilitate their analysis. The ergodicity of iterations given by (1) has been extensively studied under the restrictive assumption that the data $\\left(Y_{t}\\right)_{t \\in \\mathbb{Z}}$ and the noise $\\left(\\varepsilon_{t}\\right)_{t \\in \\mathbb{N}}$ are both i.i.d. and also independent of each other (See, [14], [30], and [48]). In this case, the process $\\left(X_{t}\\right)_{t \\in \\mathbb{N}}$ is a Markov chain, and this setting now can be considered to be textbook material. Moving beyond this simplifying yet unrealistic assumption, Debaly and Truquet established general results for getting stationarity, ergodicity and stochastic dependence properties for general nonlinear dynamics defined in terms of iterations of random maps [13]. Additionally, there are earlier contributions that consider more general schemes and investigate them without assuming independence. For instance, in the paper of Borovkov and Foss [6], Foss and Konstantopoulos [20] and also in the monograph of Borovkov [5] such processes are treated under the name \"stochastically recursive sequences\". Among the most recent results, we can mention the paper [24] by Gy\u00f6rfi et al. that introduces a novel concept called strong stability and provides sufficient conditions for strong stability of iterations given by (1). Furthermore, new findings related to Langevin-type iterations with dependent noise and multitype branching processes were also established.\n\nAssuming that the noise $\\left(\\varepsilon_{t}\\right)_{t \\in \\mathbb{N}}$ is i.i.d. and independent of the regressor $\\mathbf{Y}:=\\left(Y_{t}\\right)_{t \\in \\mathbb{Z}}$, we have\n\n$$\n\\mathbb{P}\\left(X_{t} \\in B \\mid\\left(X_{j}\\right)_{j<t}, \\mathbf{Y}\\right)=\\int_{\\mathcal{Z}} \\mathbb{1}_{\\left\\{f\\left(X_{t-1}, Y_{t-1}, z\\right) \\in B\\right\\}} \\nu(\\mathrm{d} z), t \\geq 1\n$$\n\nwhere $\\nu=\\operatorname{Law}\\left(\\varepsilon_{0}\\right)$. Clearly, the process $\\left(X_{t}\\right)_{t \\in \\mathbb{N}}$ defines a time-inhomogeneous Markov chain conditionally on the exogeneous process $\\left(Y_{t}\\right)_{t \\in \\mathbb{N}}$ being interpreted as random environment. This characterization leads us to term this process a Markov chain in a random environment (MCRE). This concept is proved to be a good compromise since, many interesting models can be treated as a MCRE. Furthermore, it is worth noting that the rich theory of general state Markov chains equips us with powerful analytical tools to study and understand these processes in-depth. Markov chains in random environments were first studied on countable state spaces in [11, 12, 44]. On general state spaces $[31,32,47]$ investigated their ergodic properties under a rather stringent hypothesis: essentially, the Doeblin condition was assumed (see Chapter 16 of [42]). Such assumptions are acceptable on compact state spaces but they fail in most models evolving in $\\mathbb{R}^{d}$. For non-compact state spaces the results of [48] apply (see also Chapter 3 of [5]) but the system dynamics is assumed to be strictly contracting, which, again, is too stringent for most applications. Markov chains in stationary random environments were first treated on non-compact state spaces under Lyapunov and \"small set\"-type conditions in [22] and [35]. The former paper was based on the control of the maximal process of the random environment but its techniques worked only assuming that the system dynamics is contractive with respect to a certain Lyapunov function, whatever the random environment is. In [35] this decreasing property is required only in an averaged sense. This result covers important model classes that none of the previous works could: queuing systems with non-independent service times (or inter-arrival times), linear systems that are stable in the average, and stochastic gradient Langevin dynamics when the data is merely stationary. In [49], under a notably weaker, yet in certain aspects, optimal form of the Lyapunov and the small set conditions, Truquet showed that for a given strongly stationary process $\\left(Y_{t}\\right)_{t \\in \\mathbb{N}}$, there exists a process $\\left(X_{t}\\right)_{t \\in \\mathbb{N}}$ satisfying the iteration in (1), and the distribution of the process $\\left(X_{t}, Y_{t}\\right)_{t \\in \\mathbb{N}}$ is unique. Additionally, if the process $\\left(Y_{t}\\right)_{t \\in \\mathbb{N}}$ is ergodic, then the process $\\left(X_{t}, Y_{t}\\right)_{t \\in \\mathbb{N}}$ is ergodic as well, hence the strong law of large numbers applies.\n\nAs far as we know, there are no known results regarding MCREs when the environment $\\left(Y_{t}\\right)_{t \\in \\mathbb{N}}$ is non-stationary. Furthermore, the sequence of iterates $\\left(X_{t}\\right)_{t \\in \\mathbb{N}}$ is typically non-stationary even in cases when the environment is stationary but the initial state $x_{0} \\in \\mathcal{X}$ is independent of $\\sigma\\left(\\left\\{\\varepsilon_{t}, Y_{t} \\mid\\right.\\right.$ $t \\in \\mathbb{N}\\}$ ). Weak dependence assumptions offer a valuable approach to address this problem while allowing for long-range dependencies to be present. The recent work by Truquet [50] directed our attention to the fact that through arguments based on coupling inequalities, it can be established under general conditions that the mixing properties of the process $\\left(Y_{t}\\right)_{t \\in \\mathbb{N}}$ are inherited by the iterates $\\left(X_{t}\\right)_{t \\in \\mathbb{N}}$. Combining this idea with Corollary 2 from Herrndorf's paper [29], we were able to establish the functional central limit theorem for the stochastic gradient Langevin iteration in cases where the data stream is stationary and exhibits favorable mixing properties [36].\n\nRosenblatt introduced the alpha-mixing coefficient in 1965, defined the class of strongly mixing processes and proved the central limit theorem for strongly mixing stationary processes [46]. Over\n\nthe past decades, researchers have established numerous strong results for non-stationary mixing processes, including various versions of the law of large numbers and the central limit theorem. The main goal of this paper is to investigate the sequence of iterates $\\left(X_{t}\\right)_{t \\in \\mathbb{N}}$ through the transitions of mixing properties, leveraging these established results.\n\nThe paper is organized as follows: In the first section, we provide sufficient conditions for a recursion of the form (1) to inherit the mixing properties of the process $\\left(Y_{t}\\right)_{t \\in \\mathbb{N}}$. Leveraging these conditions along with existing results from the literature on strongly mixing sequences, we prove the strong and $L^{1}$ law of large numbers for suitable functionals of the process $\\left(X_{t}\\right)_{t \\in \\mathbb{N}}$. Furthermore, we also show the possibility of constructing confidence intervals.\n\nThe second section focuses on the investigation of MCREs under long-term contractivity and minorization conditions satisfied by models discussed in [35]. By establishing a coupling inequality and a moment estimate for such chains, the framework presented in Section 1 becomes directly applicable to these processes. Additionally, in this section, using the Cram\u00e9r-Rao bound, we prove an inequality for variances of sums crucial for the functional cental limit theorem by Merlev\u00e8de and Peligrad [39]. To the best of our knowledge, this technique represents a novel contribution to the theory of MCREs. In the third and final section of the paper, we revisit single-server queuing models discussed in [35] and [34], and prove the functional central limit theorem for them.\n\nNotations and conventions. Let $\\mathbb{R}_{+}:=\\{x \\in \\mathbb{R}: x \\geq 0\\}$ and $\\mathbb{N}_{+}:=\\{n \\in \\mathbb{N}: n \\geq 1\\}$. Let $(\\Omega, \\mathcal{F}, \\mathbb{P})$ be a probability space. We denote by $\\mathbb{E}[X]$ the expectation of a random variable $X$. For $1 \\leq p<\\infty, L^{p}$ is used to denote the usual space of $p$-integrable real-valued random variables and $\\|X\\|_{p}$ stands for the $L^{p}$-norm of a random variable $X$.\n\nIn the sequel, we employ the convention that $\\inf \\emptyset=\\infty, \\sum_{k}^{l}=0$ and $\\prod_{k}^{l}=1$ whenever $k, l \\in \\mathbb{Z}$, $k>l$. Lastly, $\\langle\\cdot \\mid \\cdot\\rangle$ denotes the standard Euclidean inner product on finite dimensional vector spaces. For example, on $\\mathbb{R}^{d},\\langle x \\mid y\\rangle=\\sum_{i=1}^{d} x_{i} y_{i}$.", "tables": {}, "images": {}}, {"section_id": 2, "text": "# 1 Transition of mixing properties \n\n$?(\\mathrm{sec}:$ mistrans $)^{7}$ In this section, we study the transition of mixing properties of the covariate process to the response and its immediate consequences under minimal assumptions on the iteration (1). To this end, we first introduce the basic concepts that we use in our analysis. Several notions of mixing exist in the literature. The interested reader should consult the excellent survey by Bradley [8], for example. In our context $\\alpha$-mixing holds particular importance, therefore let us first recall the key concepts related to this type of mixing. We define the measure of dependence, denoted as $\\alpha(\\mathcal{G}, \\mathcal{H})$, for any two sub- $\\sigma$-algebras $\\mathcal{G}, \\mathcal{H} \\subset \\mathcal{F}$, using the equation:\n\n$$\n\\alpha(\\mathcal{G}, \\mathcal{H})=\\sup _{G \\in \\mathcal{G}, H \\in \\mathcal{H}}\\left|\\mathbb{P}(G \\cap H)-\\mathbb{P}(G) \\mathbb{P}(H)\\right|\n$$\n\nFurthermore, considering an arbitrary sequence of random variables $\\left(W_{t}\\right)_{t \\in \\mathbb{Z}}$, we introduce the $\\sigma$-algebras $\\mathcal{F}_{t, s}^{W}:=\\sigma\\left(W_{k}, t \\leq k \\leq s\\right)$, where $-\\infty \\leq t \\leq s \\leq \\infty$. Additionally, we define the dependence coefficients as follows:\n\n$$\n\\alpha_{j}^{W}(n)=\\alpha\\left(\\mathcal{F}_{-\\infty, j}^{W}, \\mathcal{F}_{j+n, \\infty}^{W}\\right), j \\in \\mathbb{Z}\n$$\n\nThe mixing coefficient of $W$ is $\\alpha^{W}(n)=\\sup _{j \\in \\mathbb{Z}} \\alpha_{j}^{W}(n), n \\geq 1$ which is obviously non-increasing. Note that, for strictly stationary $W, \\alpha_{j}^{W}(n)$ does not depend on $j$, and thus $\\alpha^{W}(n)=\\alpha_{0}^{W}(n)$. We classify $W$ as strongly mixing if $\\lim _{n \\rightarrow \\infty} \\alpha^{W}(n)=0$. Strongly mixing processes are significant because many fundamental theorems known for sequences of i.i.d. random variables can be appropriately extended to such processes. The primary importance of this lies in enabling the statistical analysis of heterogeneously distributed dependent data even when the exact underlying dynamics generating the time series are unknown. The available theoretical framework includes the strong law of large numbers by McLeish [38], the $L^{1}$-law of large numbers by Hansen [28], and the Central Limit Theorem by White [52], among others. For better clarity, these results are collected in Appendix A.\n\nNow, we turn to the analysis of the iteration (1). For better readability, we introduced the complete separable metric space $\\mathcal{Z}$ in the introduction. However, we can always assume that\n\n$\\mathcal{Z}=[0,1]$ without loss of generality. Indeed, since $\\mathcal{Z}$ is a complete separable metric space, the Borel isomorphism theorem guarantees the existence of a bi-measurable bijection $\\phi: \\mathcal{Z} \\rightarrow A$, where $A \\subseteq[0,1]$. Given an iteration of the form (1), we can always define an equivalent iteration:\n\n$$\nX_{t+1}=\\hat{f}\\left(X_{t}, Y_{t}, \\hat{\\varepsilon}_{t+1}\\right)\n$$\n\nwhere $\\hat{\\varepsilon}_{t}=\\phi\\left(\\varepsilon_{t}\\right) \\in[0,1], t \\in \\mathbb{N}$, and\n\n$$\n\\hat{f}(x, y, u)=f\\left(x, y, \\phi^{-1}(u)\\right), \\quad x \\in \\mathcal{X}, y \\in \\mathcal{Y}, u \\in A\n$$\n\nSince this transformation does not alter the dynamics of the iteration, we conclude that it suffices to assume $\\mathcal{Z}=[0,1]$. Therefore, from this point onward, we adopt this assumption.\n\nLet us introduce the notation $\\tilde{Y}_{n}=\\left(Y_{n}, \\varepsilon_{n+1}\\right), n \\in \\mathbb{N}$. Furthermore, for a fixed $x \\in \\mathcal{X}$, we define the process\n\n$$\nZ_{s, t}^{x}= \\begin{cases}x, & \\text { if } t \\leq s \\\\ f\\left(Z_{s, t-1}^{x}, Y_{t-1}, \\varepsilon_{t}\\right), & \\text { if } t>s\\end{cases}\n$$\n\nNote that, for $s \\in \\mathbb{N}$ and $t \\geq s, Z_{s, t}^{X}=X_{t}$.\n7(def: coupling)? Definition 1.1. We say that the iteration (1) satisfies the coupling condition if for some $x_{0} \\in \\mathcal{X}$,\n\n$$\n\\sup _{j \\in \\mathbb{N}} \\mathbb{P}\\left(Z_{j, j+n}^{X_{j}} \\neq Z_{j, j+n}^{x_{0}}\\right) \\rightarrow 0, n \\rightarrow \\infty\n$$\n\nBounding the mixing coefficient of a process is typically a non-trivial task in general. The following lemma presents an upper bound for the $\\alpha$-mixing coefficient of the iterates $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ given $\\alpha^{\\tilde{Y}}$.\n7(1em:Mixing)? Lemma 1.2. Assume that $X_{0}$ is a random initial state independent of $\\sigma\\left(Y_{n}, \\varepsilon_{n+1} \\mid n \\in \\mathbb{N}\\right)$, moreover the iteration (1) satisfies the coupling condition with $x_{0} \\in \\mathcal{X}$.\n\nThen for $0 \\leq m<n$, we have\n\n$$\n\\alpha^{X}(n) \\leq \\alpha^{\\tilde{Y}}(m+1)+b(n-m)\n$$\n\nwhere $b(n)=\\sup _{j \\in \\mathbb{N}} \\mathbb{P}\\left(Z_{j, j+n}^{X_{j}} \\neq Z_{j, j+n}^{x_{0}}\\right)$.\nProof. Let $j \\in \\mathbb{N}$ and $n \\geq 1$ be arbitrary. Suppose $A \\in \\mathcal{F}_{0, j}^{X}$ and $B \\in \\mathcal{F}_{j+n, \\infty}^{X}$ are arbitrary events. Then by the definition of the generated $\\sigma$-algebra, exist collections of Borel sets $\\left(A_{k}\\right)_{k \\leq j},\\left(B_{k}\\right)_{k \\geq j+n} \\subseteq \\mathcal{B}(\\mathcal{X})$ such that\n\n$$\nA=\\left(X_{k} \\in A_{k}, 0 \\leq k \\leq j\\right) \\text { and } B=\\left(X_{k} \\in B_{k}, k \\geq j+n\\right)\n$$\n\nLet $0 \\leq m<n$ be arbitrary, and introduce the event $\\tilde{B}=\\left(Z_{j+m, k}^{x_{0}} \\in B_{k}, k \\geq j+n\\right)$. We can estimate\n\n$$\n|P(A \\cap B)-P(A) P(B)|=\\left|\\operatorname{cov}\\left(\\mathbb{1}_{A}, \\mathbb{1}_{B}\\right)\\right| \\leq\\left|\\operatorname{cov}\\left(\\mathbb{1}_{A}, \\mathbb{1}_{\\tilde{B}}\\right)\\right|+\\left|\\operatorname{cov}\\left(\\mathbb{1}_{A}, \\mathbb{1}_{B}-\\mathbb{1}_{\\tilde{B}}\\right)\\right|\n$$\n\nUsing that $A$ is $\\sigma\\left(X_{0}\\right) \\vee \\mathcal{F}_{0, j-1}^{Y} \\vee \\mathcal{F}_{1, j}^{z}$ and $\\tilde{B}$ is $\\mathcal{F}_{j+m, \\infty}^{Y} \\vee \\mathcal{F}_{j+m+1, \\infty}^{z}$-measurable, and that $X_{0}$ is independent of $\\sigma\\left(Y_{n}, \\varepsilon_{n+1} \\mid n \\in \\mathbb{N}\\right)$, we have\n\n$$\n\\begin{aligned}\n\\left|\\operatorname{cov}\\left(\\mathbb{1}_{A}, \\mathbb{1}_{\\tilde{B}}\\right)\\right| & \\leq \\mathbb{E}\\left|\\mathbb{E}\\left[\\mathbb{1}_{A}\\left(\\mathbb{1}_{\\tilde{B}}-\\mathbb{P}(\\tilde{B})\\right) \\mid X_{0}\\right]\\right| \\leq \\alpha\\left(\\mathcal{F}_{0, j-1}^{Y} \\vee \\mathcal{F}_{1, j}^{z}, \\mathcal{F}_{j+m, \\infty}^{Y} \\vee \\mathcal{F}_{j+m+1, \\infty}^{z}\\right) \\\\\n& =\\alpha\\left(\\mathcal{F}_{0, j-1}^{\\tilde{Y}}, \\mathcal{F}_{j+m, \\infty}^{\\tilde{Y}}\\right) \\leq \\alpha^{\\tilde{Y}}(m+1)\n\\end{aligned}\n$$\n\nObserve that on the event $\\left\\{X_{j+n}=Z_{j+m, j+n}^{x_{0}}\\right\\}$, we have $\\mathbb{1}_{B}=\\mathbb{1}_{\\tilde{B}}$, and thus the second term in (5) can be estimated as\n\n$$\n\\begin{aligned}\n\\left|\\operatorname{Cov}\\left(\\mathbb{1}_{A}, \\mathbb{1}_{B}-\\mathbb{1}_{\\tilde{B}}\\right)\\right| & =\\left|\\mathbb{E}\\left[\\left(\\mathbb{1}_{A}-\\mathbb{P}(A)\\right)\\left(\\mathbb{1}_{B}-\\mathbb{1}_{\\tilde{B}}\\right)\\right]\\right| \\leq \\mathbb{P}\\left(Z_{0, j+n}^{X_{0}} \\neq Z_{j+m, j+n}^{x_{0}}\\right) \\\\\n& =\\mathbb{P}\\left(Z_{j+m, j+n}^{X_{j+n}} \\neq Z_{j+m, j+n}^{x_{0}}\\right) \\leq b(n-m)\n\\end{aligned}\n$$\n\nGiven that $A \\in \\mathcal{F}_{0, j}^{X}$ and $B \\in \\mathcal{F}_{j+n, \\infty}^{X}$ were arbitrary, we have shown that\n\n$$\n\\alpha\\left(\\mathcal{F}_{0, j}^{X}, \\mathcal{F}_{j+n, \\infty}^{X}\\right) \\leq \\alpha^{\\tilde{Y}}(m+1)+b(n-m)\n$$\n\nSince the upper bound is independent of $j$, taking the supremum over $j$, we arrive at the desired inequality.\n\nRemark 1.3. In the above Lemma, it is enough to prescribe that an appropriate version of $X$ satisfy the coupling condition. The proof of the coupling condition for Markov chains in random environments (See Appendix C) hinges on this observation.\nRemark 1.4. The recent work by Truquet [50] employs a similar inequality (equation (3) on page 3) to establish the transition of mixing in random iteration. However, that approach differs from ours in two significant aspects. Firstly, the analysis in [50] is limited to discrete-valued time series models with strictly stationary exogenous covariates. Secondly, unlike in Lemma 1.2, the upper estimate of the strong mixing coefficient in [50] incorporates the tail sum of non-coupling probabilities.\n\nCombining Lemma 1.2 with the theorems on strongly mixing processes presented in Appendix A, we obtain the following general umbrella theorem. This result equips us with essential tools for the statistical analysis of time series involving non-stationary exogenous covariates, including versions of the weak and strong law of large numbers and theoretical guarantees for constructing confidence intervals. However, this theorem does not cover all relevant aspects. For strongly mixing processes, there are further results concerning the distribution of extreme values [51], concentration inequalities [40], and the law of the iterated logarithm [45]. Leveraging Lemma 1.2, these results can be readily extended to random iterations driven by strongly mixing sequences.\n[thm:GeneralResult) ${ }^{7}$ Theorem 1.5. Assume that $X_{0}$ is a random initial state independent of $\\sigma\\left(Y_{n}, \\varepsilon_{n+1} \\mid n \\in \\mathbb{N}\\right)$, moreover the iteration (1) satisfies the coupling condition with $x_{0} \\in \\mathcal{X}$.\n\nConsider a measurable function $\\Phi: \\mathcal{X} \\rightarrow \\mathbb{R}$ such that $\\mu_{n}=\\mathbb{E}\\left[\\Phi\\left(X_{n}\\right)\\right]$ exists and is finite for all $n \\in \\mathbb{N}$. Let $b(n), n \\in \\mathbb{N}$ be as in Lemma 1.2, and define\n\n$$\nS_{n}=\\sum_{k=1}^{n}\\left(\\Phi\\left(X_{k}\\right)-\\mu_{k}\\right), \\quad n \\geq 1\n$$\n\nThen the following statements hold:\nA) If the process $\\left(\\tilde{Y}_{n}\\right)_{n \\in \\mathbb{N}}$ is strongly mixing and $\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left[\\Phi\\left(X_{n}\\right)\\right]^{p}<\\infty$ for some $p>1$, then the $L^{1}$ law of large numbers holds:\n\n$$\n\\frac{S_{n}}{n} \\stackrel{k^{1}}{\\rightarrow} 0, \\quad \\text { as } \\quad n \\rightarrow \\infty\n$$\n\nB) Assume that there exist constants $c>0$ and $r>2$ such that\n\n$$\n\\alpha^{\\tilde{Y}}(n)+b(n) \\leq c n^{-\\frac{r}{r-2}}\n$$\n\nMoreover, suppose that for some $r / 2<p \\leq r<\\infty$, we have $\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left[\\Phi\\left(X_{n}\\right)\\right]^{p}<\\infty$. Then,\n\n$$\n\\frac{S_{n}}{n} \\stackrel{n . r}{\\rightarrow} 0, \\quad \\text { as } \\quad n \\rightarrow \\infty\n$$\n\nC) If for $r>2, \\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left[\\Phi\\left(X_{n}\\right)\\right]^{r}<\\infty$ and\n\n$$\n\\sum_{k=0}^{\\infty}(k+1)^{2}\\left(\\alpha^{\\tilde{Y}}(k)^{\\frac{r-2}{r-2}}+b(k)^{\\frac{r-2}{r-2}}\\right)<\\infty\n$$\n\nthen the distributions of $n^{-1 / 2} S_{n}$ and $\\mathcal{N}\\left(0, \\operatorname{Var}\\left(n^{-1 / 2} S_{n}\\right)\\right)$ are weakly approaching. Furthermore, there exists $\\sigma>0$ such that for any $a>0$, we have\n\n$$\n\\limsup _{n \\rightarrow \\infty} \\mathbb{P}\\left(n^{-1 / 2}\\left|S_{n}\\right| \\geq a\\right) \\leq \\int_{\\mathbb{R}} \\mathbb{1}_{[-a, a]^{r}}(\\sigma t) \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{t^{2}}{2}} \\mathrm{~d} t\n$$\n\nProof. Define the process $W_{n}=\\Phi\\left(X_{n}\\right)-\\mu_{n}$, for $n \\in \\mathbb{N}$. By Lemma 1.2, we have\n\n$$\n\\alpha^{W}(n) \\leq \\alpha^{X}(n) \\leq \\alpha^{\\tilde{Y}}(\\lfloor n / 2\\rfloor+1)+b(n-\\lfloor n / 2\\rfloor)\n$$\n\nFrom inequality (6), it follows immediately that if $\\left(\\tilde{Y}_{n}\\right)_{n \\in \\mathbb{N}}$ is strongly mixing, then so is $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$. Thus, part A) follows directly from Theorem A. 3 and Remark A.4.\n\nFor part B), again using (6) and applying Remark A.2, we see that the conditions of Theorem A. 1 are satisfied, from which the result follows immediately.\n\nFinally, under the assumptions of part C), we can verify that\n\n$$\n\\sum_{k=0}^{\\infty}(k+1)^{2} \\alpha^{W}(k)^{\\frac{r-2}{r-2}}<\\infty\n$$\n\nand hence by Theorem A. 5 and Corollary A.6, the distributions of $n^{-1 / 2} S_{n}$ and $\\mathcal{N}\\left(0, \\operatorname{Var}\\left(n^{-1 / 2} S_{n}\\right)\\right)$ are weakly approaching. Furthermore, Remark A. 7 guarantees the existence of $\\sigma>0$ such that $\\sigma_{n}:=\\operatorname{Var}\\left(n^{-1 / 2} S_{n}\\right)^{1 / 2}<\\sigma$ for all $n \\geq 1$. Therefore, for any $a>0$, we have\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(n^{-1 / 2}\\left|S_{n}\\right| \\geq a\\right) \\leq & \\mathbb{P}\\left(n^{-1 / 2}\\left|S_{n}\\right| \\geq a\\right)-\\int_{\\mathbb{R}} \\mathbb{1}_{[-a, a]^{\\circ}}\\left(\\sigma_{n} t\\right) \\frac{1}{\\sqrt{2 \\pi}} e^{-t^{2} / 2} \\mathrm{~d} t \\\\\n& +\\int_{\\mathbb{R}} \\mathbb{1}_{[-a, a]^{\\circ}}(\\sigma t) \\frac{1}{\\sqrt{2 \\pi}} e^{-t^{2} / 2} \\mathrm{~d} t\n\\end{aligned}\n$$\n\nTaking the upper limit as $n \\rightarrow \\infty$ yields\n\n$$\n\\limsup _{n \\rightarrow \\infty} \\mathbb{P}\\left(n^{-1 / 2}\\left|S_{n}\\right| \\geq a\\right) \\leq \\int_{\\mathbb{R}} \\mathbb{1}_{[-a, a]^{\\circ}}(\\sigma t) \\frac{1}{\\sqrt{2 \\pi}} e^{-t^{2} / 2} \\mathrm{~d} t\n$$", "tables": {}, "images": {}}, {"section_id": 3, "text": "# 2 Markov chains in random environments \n\n7(sec:MCNE) ${ }^{7}$ This section is devoted to study an important class of random iterations incorporating exogeneous covariates, called Markov chains in random environments. For convenience, we adopt the parametric kernel formalism to set Lyapunov and \"small set\"-type conditions. Let us introduce\n\n$$\nQ(y, x, B)=\\int_{[0,1]} \\mathbb{1}_{\\{f(x, y, z) \\in B\\}} \\mathrm{d} z\n$$\n\nThe function $Q: \\mathcal{X} \\times \\mathcal{Y} \\times \\mathcal{B}(\\mathcal{X}) \\rightarrow[0,1]$ is a parametric probabilistic kernel, which means:\ni For each pair $(y, x) \\in \\mathcal{Y} \\times \\mathcal{X}$, the mapping $B \\mapsto Q(y, x, B)$ defines a Borel probability measure on the Borel sigma-algebra $\\mathcal{B}(\\mathcal{X})$.\nii For any choice of set $B \\in \\mathcal{B}(\\mathcal{X})$, the mapping $(x, y) \\mapsto Q(y, x, B)$ is a measurable function with respect to the product sigma-algebra $\\mathcal{B}(\\mathcal{X}) \\otimes \\mathcal{B}(\\mathcal{Y})$.\n$7\\left(\\right.$ def : act) ${ }^{7}$ Definition 2.1. Let $P: \\mathcal{X} \\times \\mathcal{B} \\rightarrow[0,1]$ be a probabilistic kernel. For a bounded measurable function $\\phi: \\mathcal{X} \\rightarrow \\mathbb{R}$, we define\n\n$$\n[P \\phi](x)=\\int_{\\mathcal{X}} \\phi(z) P(x, \\mathrm{~d} z), x \\in \\mathcal{X}\n$$\n\nThis definition makes sense for any non-negative measurable $\\phi$, too.\nConsistently with Definition 2.1, for $y \\in \\mathcal{Y}$, we write $Q(y) \\phi$ to denote the action of the kernel $Q(y, \\cdot, \\cdot)$ on $\\phi$. It is important to note that if $y_{l}, \\ldots, y_{k-1} \\in \\mathcal{Y}$ with $0 \\leq l<k$, then the successive application of the kernels is interpreted in the order corresponding to the composition of conditional expectations:\n\n$$\n\\left[Q\\left(y_{k-1}\\right) \\ldots Q\\left(y_{l}\\right) \\phi\\right]=\\left[Q\\left(y_{l}\\right)\\left[\\ldots\\left[Q\\left(y_{k-1}\\right) \\phi\\right]\\right]\\right]\n$$\n\nThis convention will be important later in the proof of Lemma C.1.\n\nWe say that $Q$ satisfies the drift (or Lyapunov) condition if there exists a measurable mapping $V: \\mathcal{X} \\rightarrow[0, \\infty)$, which we call Lyapunov-function, and measurable functions $\\gamma, K: \\mathcal{Y} \\rightarrow(0, \\infty)$, such that for all $(y, x) \\in \\mathcal{Y} \\times \\mathcal{X}$,\n\n$$\n[Q(y) V](x):=\\int_{\\mathcal{X}} V(z) Q(y, x, \\mathrm{~d} z) \\leq \\gamma(y) V(x)+K(y)\n$$\n\nWe may, and from now on, we will assume that $K(.) \\geq 1$ in the drift condition (7).\nThe parametric kernel obeys the minorization condition with $R>0$, if there exists a probability kernel $\\kappa_{R}: \\mathcal{Y} \\times \\mathcal{B}(\\mathcal{X}) \\rightarrow[0,1]$ and a measurable function $\\beta:[0, \\infty) \\times \\mathcal{Y} \\rightarrow[0,1)$ such that for all $(y, x, A) \\in \\mathcal{Y} \\times \\stackrel{\\sim}{V}([0, R]) \\times \\mathcal{B}(\\mathcal{X})$,\n\n$$\nQ(y, x, A) \\geq(1-\\beta(R, y)) \\kappa_{R}(y, A)\n$$\n\nThe minorization condition stipulates the existence of \"small sets\". Therefore, it is also referred to as a \"small set\"-type condition.\n\nIf $\\gamma, K$ are independent of $y$ and $\\gamma<1$ then (7) is the standard drift condition for geometrically ergodic Markov chains, see Chapter 15 of [42]. Ergodic properties of Markov chains in stationary random environments was studied by Lovas and R\u00e1sonyi in [35] when $\\gamma(y) \\geq 1$ may well occur but the environment satisfies the following long-term contractivity condition:\n\n$$\n\\limsup _{n \\rightarrow \\infty} \\mathbb{E}^{1 / n}\\left(K\\left(Y_{0}\\right) \\prod_{k=1}^{n} \\gamma\\left(Y_{k}\\right)\\right)<1\n$$\n\nUnder the assumption that $\\mathbb{E}\\left[\\log \\left(\\gamma\\left(Y_{0}\\right)\\right)_{+}\\right]+\\mathbb{E}\\left[\\log \\left(K\\left(Y_{0}\\right)\\right)_{+}\\right]<\\infty$ and\n\n$$\n\\limsup _{n \\rightarrow \\infty} \\prod_{k=1}^{n} \\gamma\\left(Y_{-k}\\right)^{1 / n}<1, \\mathbb{P}-\\text { a.s. }\n$$\n\nwhich is notably weaker than (9), in [49] Truquet proved that there exists a stationary process $\\left(\\left(Y_{t}, X_{t}^{*}\\right)\\right)_{t \\in \\mathbb{Z}}$ satisfying the iteration (1), and the distribution of this process is unique. If, in addition, the environment $\\left(Y_{t}\\right)_{t \\in \\mathbb{Z}}$ is ergodic, the process $\\left(\\left(Y_{t}, X_{t}^{*}\\right)\\right)_{t \\in \\mathbb{Z}}$ is also ergodic. As a result, the strong law of large numbers holds for any measurable function $\\Psi: \\mathcal{Y} \\times \\mathcal{X} \\rightarrow \\mathbb{R}$ with $\\mathbb{E}\\left(\\left|\\Psi\\left(Y_{0}, X_{0}^{*}\\right)\\right|\\right)<\\infty$ i.e.\n\n$$\n\\frac{1}{n} \\sum_{k=1}^{n} \\Psi\\left(Y_{k}, X_{k}^{*}\\right) \\rightarrow \\mathbb{E}\\left(\\Psi\\left(Y_{0}, X_{0}^{*}\\right)\\right), \\text { as } n \\rightarrow \\infty, \\mathbb{P}-\\text { a.s. }\n$$\n\nIn this case, the condition (10) boils down to $\\mathbb{E}\\left[\\log \\left(\\gamma\\left(Y_{0}\\right)\\right)\\right]<0$. Truquet has also shown that if the iteration (1) is initialized with deterministic $x_{0} \\in \\mathcal{X}$, denoted as $\\left(X_{0}^{x_{0}}\\right)_{n \\in \\mathbb{N}}$, then $\\operatorname{Law}\\left(X_{0}^{x_{0}}\\right)$ converges to $\\operatorname{Law}\\left(X_{0}^{*}\\right)$ in total variation as $n \\rightarrow \\infty$, where $\\operatorname{Law}\\left(X_{0}^{*}\\right)$ here denotes the marginal distribution of the stationary solution $\\left(\\left(Y_{t}, X_{t}^{*}\\right)\\right)_{t \\in \\mathbb{Z}}$. On the other hand, contrarily to [35], Truquet did not provide a rate estimate.\n\nIndependent and identically distributed sequences of random variables $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$ satisfy the longterm contractivity condition (9) if $\\mathbb{E}\\left(\\gamma\\left(Y_{0}\\right)\\right)<1$. Naturally, the question arises whether the inequality (9) still holds when $\\mathbb{E}\\left(\\gamma\\left(Y_{0}\\right)\\right)<1$ and the sequence $\\alpha^{Y}(n), n \\in \\mathbb{N}$, tends to zero rapidly enough. In his Master's thesis on the stability of general state Markov chains [19], Bal\u00e1zs Felsmann provided an example of a strongly stationary stochastic process $\\left(Y_{n}\\right)_{n \\in \\mathbb{Z}}$ and a function $\\gamma$ : $\\mathcal{Y} \\rightarrow(0, \\infty)$ such that $\\mathbb{E}\\left(\\gamma\\left(Y_{0}\\right)\\right)<1$, yet $\\lim _{n \\rightarrow \\infty} \\mathbb{E}\\left(\\prod_{k=1}^{n} \\gamma\\left(Y_{k}\\right)\\right)$, i.e., the long-term contractivity condition in (9) is not satisfied. Since the thesis is available only in Hungarian, the example in question is presented in Appendix B.\n\nIn the forthcoming discussion, we refrain from assuming stationarity for the environment $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$. Instead, we regard it purely as a sequence of weakly dependent random variables. Consequently, the anticipation of the existence of limiting distributions, as demonstrated in [35], [36], or [49], is not viable. Instead, we employ the methodology delineated in Section 1 to establish the $L^{1}$-law of large numbers and the functional central limit theorem.\n\nWe impose the following additional assumptions on the environment. In absence of stationarity, it is required that the long-term contractivity condition (9) holds uniformly along trajectories. With the second condition, essentially, we stipulate that the minorization coefficient $\\beta:[0, \\infty) \\times \\mathcal{Y} \\rightarrow$ $[0,1)$ appearing in (8) can be substituted with a constant on appropriately chosen level sets of the Lyapunov function. This latter criterion is satisfied in all applications discussed in [35].\n7(as:dynamics) ${ }^{7}$ Assumption 2.2. We assume that the parametric kernel $Q: \\mathcal{Y} \\times \\mathcal{X} \\times \\mathcal{B}(\\mathcal{X}) \\rightarrow[0,1]$ satisfies the drift condition (7) with $\\gamma, K: \\mathcal{Y} \\rightarrow(0, \\infty)$ such that\n\n$$\n\\mathbb{E}\\left(K\\left(Y_{j}\\right) \\prod_{k=1}^{n} \\gamma\\left(Y_{k+j}\\right)\\right)<\\infty, j \\in \\mathbb{N}, n \\geq 1\n$$\n\nFurthermore the following two conditions hold:\nA) $\\bar{\\gamma}:=\\limsup _{n \\rightarrow \\infty} \\sup _{j \\geq-1} \\mathbb{E}^{1 / n}\\left(K\\left(Y_{j}\\right) \\prod_{k=1}^{n} \\gamma\\left(Y_{k+j}\\right)\\right)<1$, where we define $K\\left(Y_{-1}\\right):=1$.\nB) For some $0<r<1 / \\bar{\\gamma}-1$, the parametric kernel $Q$ obeys the minorization condition with\n\n$$\nR(y)=\\frac{2 K(y)}{r \\gamma(y)}, \\text { and } \\bar{\\beta}:=\\sup _{y \\in \\mathcal{Y}} \\beta(R(y), y)<1\n$$\n\n7(1en:PhiVisual) ${ }^{7}$ Lemma 2.3. Let $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ be a Markov chain in a random environment $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$ with parametric kernel $Q: \\mathcal{Y} \\times \\mathcal{X} \\times \\mathcal{B}(\\mathcal{X}) \\rightarrow[0,1]$ satisfying part $A$ ) of Assumption 2.2. Additionally, let $X_{0}$ be a random initial state independent of $\\sigma\\left(Y_{n}, \\varepsilon_{n+1} \\mid n \\in \\mathbb{N}\\right)$ and such that $\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)<\\infty$.\n\nThen for any measurable function $\\Phi: \\mathcal{X} \\rightarrow \\mathbb{R}$ satisfying\n\n$$\n|\\Phi(x)|^{r} \\leq C(1+V(x)), x \\in \\mathcal{X}\n$$\n\nfor some constants $C>0$ and $r \\in \\mathbb{R}$, it follows that\n\n$$\n\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left(\\left|\\Phi\\left(X_{n}\\right)\\right|^{r}\\right)<\\infty\n$$\n\nProof. Using Lemma C. 1 from Appendix C, we can derive the following estimate:\n\n$$\n\\mathbb{E}\\left(\\left[Q\\left(Y_{n-1}\\right) \\ldots Q\\left(Y_{0}\\right) V\\right]\\left(X_{0}\\right)\\right) \\leq \\mathbb{E}\\left(V\\left(X_{0}\\right)\\right) \\mathbb{E}\\left(\\prod_{k=0}^{n-1} \\gamma\\left(Y_{k}\\right)\\right)+\\sum_{k=0}^{n-1} \\mathbb{E}\\left(K\\left(Y_{k}\\right) \\prod_{j=k+1}^{n-1} \\gamma\\left(Y_{j}\\right)\\right)\n$$\n\nGiven Assumption 2.2, the Cauchy criterion applies to the sum in the second term. Consequently,\n\n$$\n\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left(\\left[Q\\left(Y_{n-1}\\right) \\ldots Q\\left(Y_{0}\\right) V\\right]\\left(X_{0}\\right)\\right)<\\infty\n$$\n\nwhich further implies\n\n$$\n\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left(\\left|\\Phi\\left(X_{n}\\right)\\right|^{r}\\right) \\leq C\\left(1+\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left(V\\left(X_{n}\\right)\\right)\\right)=C\\left(1+\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left(\\left[Q\\left(Y_{n-1}\\right) \\ldots Q\\left(Y_{0}\\right) V\\right]\\left(X_{0}\\right)\\right)\\right)<\\infty\n$$\n\nThe following lemma ensures that under the drift and minorization conditions specified in Definition 2.2, the coupling condition holds for a suitable version of the chain.\n7(1en:MCREmixing) ${ }^{7}$ Lemma 2.4. Let $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ be a Markov chain in a random environment $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$ with random initial state $X_{0}$ independent of $\\sigma\\left(Y_{n}, \\varepsilon_{n+1} \\mid n \\in \\mathbb{N}\\right)$ such that $\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)<\\infty$. Then under Assumption 2.2, the chain $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ admits a random iteration representation of the form (1) with appropriate $f: \\mathcal{X} \\times \\mathcal{Y} \\times[0,1] \\rightarrow \\mathcal{X}$ which satisfies the coupling condition. More precisely, there exist $c_{1}, c_{2}>0$ constants depending only on $\\bar{\\gamma}, \\bar{\\beta}$ and $r$ such that\n\n$$\n\\sup _{j \\in \\mathbb{N}} \\mathbb{P}\\left(Z_{j, j+n}^{X_{j}} \\neq Z_{j, j+n}^{x}\\right) \\leq c_{1}\\left(V(x)+\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)+1\\right) e^{-c_{2} n^{1 / 2}}, n \\geq N\n$$\n\nholds for $x \\in \\mathcal{X}$ and appropriate $N>0$.\n\nProof. The proof follows a similar argument as in [36]. For detailed steps, see Appendix C.\nWith the above Lemma and the results obtained for general random iterations in Section 1 in hand, we are now ready to prove the following theorem.\nod_weakapproaching) ${ }^{7}$ Theorem 2.5. Let $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ be a Markov chain in a random environment $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$ satisfying Assumption 2.2, with $X_{0}$ a random initial state independent of $\\sigma\\left(Y_{n}, \\varepsilon_{n+1} \\mid n \\in \\mathbb{N}\\right)$, such that $\\mathbb{E}\\left[V\\left(X_{0}\\right)\\right]<\\infty$.\n\nConsider a measurable function $\\Phi: \\mathcal{X} \\rightarrow \\mathbb{R}$ satisfying\n\n$$\n|\\Phi(x)|^{p} \\leq C(1+V(x)), \\quad x \\in \\mathcal{X}\n$$\n\nfor some constants $C>0$ and $p>1$, and define\n\n$$\nS_{n}:=\\sum_{k=1}^{n}\\left(\\Phi\\left(X_{k}\\right)-\\mathbb{E}\\left[\\Phi\\left(X_{k}\\right)\\right]\\right), \\quad n \\in \\mathbb{N}\n$$\n\nUnder the above conditions, the following statements hold:\nA) If the environment process $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$ is strongly mixing, then the $L^{1}$ law of large numbers holds:\n\n$$\n\\frac{S_{n}}{n} \\xrightarrow{L^{1}} 0, \\quad \\text { as } n \\rightarrow \\infty\n$$\n\nB) Suppose that for some constants $c>0$ and $r>2$, the mixing coefficients satisfy $\\alpha^{Y}(n) \\leq$ $c n^{-\\frac{r}{r-2}}, n \\in \\mathbb{N}$, and (11) holds with an exponent $p$ such that $r / 2<p \\leq r<\\infty$. Then,\n\n$$\n\\frac{S_{n}}{n} \\xrightarrow{a . \\mathrm{y}} 0, \\quad \\text { as } n \\rightarrow \\infty\n$$\n\nC) If (11) holds with $p>2$ and the mixing coefficients satisfy\n\n$$\n\\sum_{n \\in \\mathbb{N}}(n+1)^{2} \\alpha^{Y}(n)^{\\frac{p-2}{p+2}}<\\infty\n$$\n\nthen the distribution of $S_{n} / \\sqrt{n}$ and $\\mathcal{N}\\left(0, \\operatorname{Var}\\left(n^{-1 / 2} S_{n}\\right)\\right)$ are weakly approaching. Moreover, there exists $\\sigma>0$ such that for any $a>0$, we have\n\n$$\n\\limsup _{n \\rightarrow \\infty} \\mathbb{P}\\left(n^{-1 / 2}\\left|S_{n}\\right| \\geq a\\right) \\leq \\int_{\\mathbb{R}} \\mathbb{1}_{[-a, a]^{\\circ}}(\\sigma t) \\frac{1}{\\sqrt{2 \\pi}} e^{-t^{2} / 2} \\mathrm{~d} t\n$$\n\nProof. For any $n, j \\in \\mathbb{N}$, the sigma-algebras $\\mathcal{F}_{0, j}^{Y} \\vee \\mathcal{F}_{n+j, \\infty}^{Y}$ and $\\mathcal{F}_{1, j}^{z} \\vee \\mathcal{F}_{n+j, \\infty}^{z}$ are independent. Hence, by [9, Lemma 8 on page 13], we obtain\n\n$$\n\\begin{aligned}\n\\alpha\\left(\\mathcal{F}_{0, j}^{\\tilde{Y}}, \\mathcal{F}_{n+j, \\infty}^{\\tilde{Y}}\\right) & =\\alpha\\left(\\mathcal{F}_{0, j}^{Y} \\vee \\mathcal{F}_{1, j}^{z}, \\mathcal{F}_{n+j, \\infty}^{Y} \\vee \\mathcal{F}_{n+j, \\infty}^{z}\\right) \\\\\n& \\leq \\alpha\\left(\\mathcal{F}_{0, j}^{Y}, \\mathcal{F}_{n+j, \\infty}^{Y}\\right)+\\alpha\\left(\\mathcal{F}_{1, j}^{z}, \\mathcal{F}_{n+j, \\infty}^{z}\\right)\n\\end{aligned}\n$$\n\nwhere $\\tilde{Y}_{n}=\\left(Y_{n}, \\varepsilon_{n+1}\\right)$ for $n \\in \\mathbb{N}$.\nOn the other hand, since $\\mathcal{F}_{1, j}^{z}$ and $\\mathcal{F}_{n+j, \\infty}^{z}$ are also independent, we have $\\alpha\\left(\\mathcal{F}_{1, j}^{z}, \\mathcal{F}_{n+j, \\infty}^{z}\\right)=0$. By the definition of the dependence coefficient (3), the reverse inequality holds trivially, and therefore\n\n$$\n\\alpha\\left(\\mathcal{F}_{0, j}^{\\tilde{Y}}, \\mathcal{F}_{n+j, \\infty}^{\\tilde{Y}}\\right)=\\alpha\\left(\\mathcal{F}_{0, j}^{Y}, \\mathcal{F}_{n+j, \\infty}^{Y}\\right), \\quad n, j \\in \\mathbb{N}\n$$\n\nThis implies that $\\alpha^{\\tilde{Y}}(n)=\\alpha^{Y}(n)$ for all $n \\in \\mathbb{N}$.\nFurthermore, by Lemma 2.3, the bound $\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left|\\Phi\\left(X_{n}\\right)\\right|^{p}<\\infty$ holds for the same $p>1$ as in (11).\n\nFinally, by Lemma 2.4, the chain $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ admits a random iteration representation satisfying the coupling condition with $b(n)=O\\left(e^{-c n^{1 / 2}}\\right)$ for some $c>0$.\n\nTherefore, all conditions of Theorem 1.5 are satisfied, which completes the proof.\n\nFollowing Lindvall [33], Gy\u00f6rfi and Morvai introduced a stronger concept of stability known as forward coupling [25]. This notion of stability has proven useful in the study of queuing systems. Specifically, under mild ergodicity assumptions, it was found that waiting times in single-server queuing systems operating in a subcritical regime are forward coupled with a stationary and ergodic sequence (See in Section 3).\n7(def_fwd_cp1) ${ }^{7}$ Definition 2.6. We say that the sequence $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ is forward coupled with the sequence $\\left(W_{n}^{\\prime}\\right)_{n \\in \\mathbb{N}}$ if there exists an almost surely finite random time $\\tau$ such that\n\n$$\nW_{n}=W_{n}^{\\prime}\n$$\n\nfor $n>\\tau$.\nThe next theorem revisits the case of a stationary environment, previously studied by Gerencs\u00e9r [21], R\u00e1sonyi [22], Lovas [35], Truquet [49], and others, and establishes novel results.\nc_forward_coupling) ${ }^{7}$ Theorem 2.7. Let $\\left(Y_{n}\\right)_{n \\in \\mathbb{Z}}$ be a strongly stationary process, and assume that Assumption 2.2 holds. Furthermore, let $X_{0}$ be a random initial state independent of $\\sigma\\left(Y_{m}, \\varepsilon_{n+1} \\mid m \\in \\mathbb{Z}, n \\in\\right.$ $\\mathbb{N})$. Consider the stationary process $\\left(Y_{n}, X_{n}^{*}\\right)_{n \\in \\mathbb{Z}}$ satisfying the iteration (1). Then, appropriate versions of $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ and $\\left(X_{n}^{*}\\right)_{n \\in \\mathbb{N}}$ are forward coupled. Moreover, the tail probability of the random coupling time $\\tau$ satisfies the estimate\n\n$$\n\\mathbb{P}(\\tau>n) \\leq c_{1}\\left(1+\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)\\right) e^{-c_{2} n^{1 / 2}}\n$$\n\nwith constants $c_{1}, c_{2}>0$ depending only on $\\bar{\\beta}, \\bar{\\gamma}$ and $r$.\nProof. The proof follows similar lines as the proof of Lemma 2.4. For readability, it is provided in Appendix C.\n\nThe following important corollary of the above theorem provides an explicit and tractable upper bound for the total variation distance between $\\operatorname{Law}\\left(X_{n}\\right)$ and $\\operatorname{Law}\\left(X_{n}^{*}\\right), n \\in \\mathbb{N}$. This bound is significantly sharper than those presented in our earlier paper [35].\n7(cor_fwd_stv) ${ }^{7}$ Corollary 2.8. Under the conditions of Theorem 2.7, the following rate estimate holds:\n\n$$\n\\left\\|\\operatorname{Law}\\left(X_{n}\\right)-\\operatorname{Law}\\left(X_{n}^{*}\\right)\\right\\|_{T V} \\leq 2 c_{1}\\left(1+\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)\\right) e^{-c_{2} n^{1 / 2}}\n$$\n\nwith the same constants $c_{1}$ and $c_{2}$ as in Theorem 2.7.\nProof. According to the optimal transportation cost characterization of the total variation distance, we have\n\n$$\n\\frac{1}{2}\\left\\|\\operatorname{Law}\\left(X_{n}\\right)-\\operatorname{Law}\\left(X_{n}^{*}\\right)\\right\\|_{T V} \\leq \\inf _{n \\in \\mathcal{C}\\left(X_{n}, X_{n}^{*}\\right)} \\int_{\\mathcal{X} \\times \\mathcal{X}} \\mathbb{1}_{x \\neq y} \\kappa(\\mathrm{~d} x, \\mathrm{~d} y)\n$$\n\nwhere $\\mathcal{C}\\left(X_{n}, X_{n}^{*}\\right)$ denotes the set of probability measures on $\\mathcal{B}(\\mathcal{X} \\times \\mathcal{X})$ with marginals $\\operatorname{Law}\\left(X_{n}\\right)$ and $\\operatorname{Law}\\left(X_{n}^{*}\\right)$, respectively. By a slight abuse of notation, we can assume that $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ and $\\left(X_{n}^{*}\\right)_{n \\in \\mathbb{N}}$ are forward coupled. Using Theorem 2.7, we can estimate the right-hand side further by writing\n\n$$\n\\inf _{n \\in \\mathcal{C}\\left(X_{n}, X_{n}^{*}\\right)} \\int_{\\mathcal{X} \\times \\mathcal{X}} \\mathbb{1}_{x \\neq y} \\kappa(\\mathrm{~d} x, \\mathrm{~d} y) \\leq \\mathbb{P}\\left(X_{n} \\neq X_{n}^{*}\\right)=\\mathbb{P}(\\tau>n) \\leq c_{1}\\left(1+\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)\\right) e^{-c_{2} n^{1 / 2}}\n$$\n\nwhich gives the desired inequality.\nIn the remaining part of this section, we aim to verify the Central Limit Theorem (CLT) for certain functionals of a Markov chain in a non-stationary random environment. There are multiple approaches to achieve this result. For instance, we can use Corollary A.6, or the results described in Merleve\u0300de and Peligrad's recent paper [39]. The advantage of the latter approach is that it not only yields the usual CLT but also the functional CLT, and the conditions on the decay of the mixing properties are weaker. Regardless of the chosen method, we must verify the equality (35), which states that the variance of the sum grows at the same rate as the sum of the variances.\n\nUsing either Remark A. 7 or Lemma 2.3, it can be easily shown that $\\operatorname{Var}\\left(S_{n}\\right)$ grows at most at the same rate as the sum of the variances $\\operatorname{Var}\\left(\\Phi\\left(X_{k}\\right)\\right), k=1,2, \\ldots, n$. However, it is far from trivial to establish a lower bound for $\\operatorname{Var}\\left(S_{n}\\right)$ to ensure the equality in (35). For this, we follow a new approach employing the law of total variance and the Cram\u00e9r-Rao bound known from estimation theory and information geometry. For any fixed $n \\geq 1$, we treat the conditional distribution of $\\underline{X}:=\\left(X_{1}, \\ldots, X_{n}\\right)$ given the environment $\\underline{Y}:=\\left(Y_{0}, \\ldots, Y_{n-1}\\right)$ as a parametric statistical model, where the environment $\\underline{Y}$ is considered as the parameter. For technical reasons, we will restrict our discussion in the remaining part of this section to the case when $\\mathcal{Y}=\\mathbb{R}^{m}$ with $m \\in \\mathbb{N}_{+}$.\n7(as:Fisher) ${ }^{7}$ Assumption 2.9. We assume the existence of a reference Borel measure $\\nu$ on $\\mathcal{B}(\\mathcal{X})$ such that, for all $(y, x) \\in \\mathcal{Y} \\times \\mathcal{X}$, the measure $Q(y, x, \\cdot)$ is absolutely continuous with respect to $\\nu$. Furthermore, the parametric family of conditional densities\n\n$$\n\\mathcal{Y} \\ni y \\mapsto p_{y}(z \\mid x)=\\frac{\\mathrm{d} Q(y, x, \\cdot)}{\\mathrm{d} \\nu}(z),(x, z) \\in \\mathcal{X} \\times \\mathcal{X}\n$$\n\nand the measurable function $\\Phi: \\mathcal{X} \\rightarrow \\mathbb{R}$, playing the role of an estimator, satisfy all the regularity conditions required for the Cram\u00e9r-Rao inequality (See Theorem 1A on page 147 in [3] or for a more general version, Corollary 5 in [2]).\n7(1em:Var5n) ${ }^{7}$ Lemma 2.10. Let $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ be a Markov chain in a random environment $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$ with parametric kernel $Q: \\mathcal{Y} \\times \\mathcal{X} \\times \\mathcal{B}(\\mathcal{X}) \\rightarrow[0,1]$ and $\\Phi: \\mathcal{X} \\rightarrow \\mathbb{R}$ satisfying Assumption 2.9. Suppose that $X_{0}$ is a random initial state independent of $\\sigma\\left(Y_{n}, \\varepsilon_{n+1} \\mid n \\in \\mathbb{N}\\right)$ with distribution $\\operatorname{Law}\\left(X_{0}\\right)$ being absolutely continuous w.r.t. $\\nu$, where $\\nu$ is as in Assumption 2.9.\n\nThen, for the variance of the parial sum $S_{n}=\\Phi\\left(X_{1}\\right)+\\ldots+\\Phi\\left(X_{n}\\right)$, we have the lower bound\n\n$$\n\\operatorname{Var}\\left(S_{n}\\right) \\geq \\sum_{k=0}^{n-1} \\mathbb{E}\\left[\\frac{1}{r\\left(I_{k}\\right)}\\left\\|\\partial_{y_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}\\right]\\right\\|^{2}\\right], n \\geq 1\n$$\n\nwhere $r\\left(I_{k}\\right)$ denotes the spectral radius of the Fisher information matrix\n\n$$\nI_{k}:=\\mathbb{E}\\left[\\left(\\partial_{y} \\log p_{y}\\left(X_{k+1} \\mid X_{k}\\right)\\right)^{\\top}\\left(\\partial_{y} \\log p_{y}\\left(X_{k+1} \\mid X_{k}\\right)\\right) \\mid \\underline{Y}\\right]\n$$\n\nProof. By the law of total variance, we can write\n\n$$\n\\operatorname{Var}\\left(S_{n}\\right)=\\mathbb{E}\\left[\\operatorname{Var}\\left(S_{n} \\mid \\mathcal{F}_{0, n-1}^{Y}\\right)\\right]+\\operatorname{Var}\\left(\\mathbb{E}\\left[S_{n} \\mid \\mathcal{F}_{0, n-1}^{Y}\\right]\\right) \\geq \\mathbb{E}\\left[\\operatorname{Var}\\left(S_{n} \\mid \\mathcal{F}_{0, n-1}^{Y}\\right)\\right]\n$$\n\nFor typographical reasons, we use the notations $\\operatorname{Var}_{\\underline{Y}}\\left(S_{n}\\right):=\\operatorname{Var}\\left(S_{n} \\mid \\underline{Y}\\right)$ and $\\operatorname{Cov}_{\\underline{Y}}(\\cdot, \\cdot):=$ $\\operatorname{Cov}(\\cdot, \\cdot \\mid \\underline{Y})$. The conditional variance of the partial sum can be expressed as follows:\n\n$$\n\\operatorname{Var}_{\\underline{Y}}\\left(S_{n}\\right)=\\sum_{k, l=1}^{n} \\operatorname{Cov}_{\\underline{Y}}\\left(\\Phi\\left(X_{k}\\right), \\Phi\\left(X_{l}\\right)\\right)=\\mathbf{1}^{\\top} \\operatorname{Cov}_{\\underline{Y}}(\\Phi(\\underline{X})) \\mathbf{1}\n$$\n\nwhere $\\operatorname{Cov}_{\\underline{Y}}(\\Phi(\\underline{X}))$ is the conditional covariance matrix of the random vector\n\n$$\n\\Phi(\\underline{X})=\\left(\\Phi\\left(X_{1}\\right), \\ldots, \\Phi\\left(X_{n}\\right)\\right)^{\\top}\n$$\n\n$\\mathbf{1}=[1, \\ldots, 1]^{\\top} \\in \\mathbb{R}^{n}$ denotes the size $n$ vector of 1 -s.\nUsing the Cram\u00e9r-Rao inequality, we arrive at the following estimate\n\n$$\n\\operatorname{Cov}_{\\underline{Y}}(\\Phi(\\underline{X})) \\geq\\left(\\partial_{\\underline{y}} \\phi(\\underline{Y})\\right) I(\\underline{Y})^{-1}\\left(\\partial_{\\underline{y}} \\phi(\\underline{Y})\\right)^{\\top}\n$$\n\nwhere $\\phi: \\mathcal{Y}^{n} \\rightarrow \\mathbb{R}^{n}, \\phi(\\underline{y})=\\mathbb{E}\\left[\\Phi(\\underline{X}) \\mid \\underline{Y}=\\underline{y}\\right]$ and $I(\\underline{y})$ is the Fisher information matrix.\nNote that $\\partial_{\\underline{y}} \\phi(\\underline{y}) \\in \\operatorname{Lin}\\left(\\mathcal{Y}^{n}, \\mathbb{R}^{n}\\right)$ and $I(\\underline{y}) \\in \\operatorname{Lin}\\left(\\mathcal{Y}^{n}\\right)$ are linear operators with block representation\n\n$$\n\\begin{aligned}\n& \\partial_{\\underline{y}} \\phi(\\underline{y})=\\left[\\partial_{y_{0}} \\phi(\\underline{y}), \\ldots, \\partial_{y_{n-1}} \\phi(\\underline{y})\\right] \\\\\n& {[I(\\underline{y})]_{k l}=\\mathbb{E}\\left[\\left(\\partial_{y_{k}} \\log p(\\underline{X} \\mid \\underline{y})\\right)^{\\top}\\left(\\partial_{y_{l}} \\log p(\\underline{X} \\mid \\underline{y})\\right) \\mid \\underline{Y}=\\underline{y}\\right]=-\\mathbb{E}\\left[\\partial_{y_{k} y_{l}}^{2} \\log p(\\underline{X} \\mid \\underline{y}) \\mid \\underline{Y}=\\underline{y}\\right]}\n\\end{aligned}\n$$\n\nwhere $\\partial_{y_{i}} \\phi(\\underline{y}) \\in \\operatorname{Lin}\\left(\\mathcal{Y}, \\mathbb{R}^{n}\\right), i=0, \\ldots, n-1$, and $[I(\\underline{y})]_{k l} \\in \\operatorname{Lin}(\\mathcal{Y}), k, l=0, \\ldots, n-1$.\nBy the Markov property, for the conditional density of $\\underline{X}$ given $\\underline{y}$ can be expressed as the product of $\\pi\\left(X_{0}\\right)=\\frac{\\operatorname{d} \\operatorname{Low}\\left(X_{0}\\right)}{\\mathrm{d} \\nu}$ and the parametric transition densities $p_{y_{k-1}}\\left(x_{k} \\mid x_{k-1}\\right), k=1, \\ldots, n$. Consequently, we obtain\n\n$$\n\\log p(\\underline{X} \\mid \\underline{y})=\\log \\pi\\left(X_{0}\\right)+\\sum_{k=1}^{n} \\log p_{y_{k-1}}\\left(X_{k} \\mid X_{k-1}\\right)\n$$\n\nwhich implies that the Fisher information matrix has a block-diagonal form:\n\n$$\n[I(\\underline{y})]_{k l}=\\left\\{\\begin{array}{ll}\nI_{k}:=\\mathbb{E}\\left[\\left(\\partial_{y_{k}} \\log p_{y_{k}}\\left(X_{k+1} \\mid X_{k}\\right)\\right)^{\\top}\\left(\\partial_{y_{k}} \\log p_{y_{k}}\\left(X_{k+1} \\mid X_{k}\\right)\\right) \\mid \\underline{\\mathbf{Y}}=\\underline{y}\\right] & \\text { if } k=l \\\\\n0 & \\text { if } k \\neq l\n\\end{array}\\right.\n$$\n\nObserve that $\\mathbf{1}^{\\top} \\partial_{\\underline{y}} \\phi(\\underline{y})=\\partial_{\\underline{y}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}=\\underline{y}\\right] \\in \\operatorname{Lin}\\left(\\mathcal{Y}^{n}, \\mathbb{R}\\right)$ hence substituting back the above form of the Fisher information matrix into (14) and applying (15) yields\n\n$$\n\\operatorname{Var}_{\\underline{Y}}\\left(S_{n}\\right) \\geq \\sum_{k=0}^{n-1} \\partial_{y_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}\\right] I_{k}^{-1} \\partial_{y_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}\\right]^{\\top} \\geq \\sum_{k=0}^{n-1} \\frac{1}{r\\left(I_{k}\\right)}\\left\\|\\partial_{y_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}\\right]\\right\\|^{2}\n$$\n\nwhere $r\\left(I_{k}\\right)$ refers to the spectral radius of the Fisher operator $I_{k}$. At least, by (13), we obtain\n\n$$\n\\operatorname{Var}\\left(S_{n}\\right) \\geq \\sum_{k=0}^{n-1} \\mathbb{E}\\left[\\frac{1}{r\\left(I_{k}\\right)}\\left\\|\\partial_{y_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}\\right]\\right\\|^{2}\\right]\n$$\n\nCombining the above lemma with Corollary A. 6 leads to the following significant conclusion.\n7(cor:ekstrom2) ${ }^{7}$ Corollary 2.11. In addition to the conditions of Theorem 2.5 and Lemma 2.10, assume that the function $\\Phi: \\mathcal{X} \\rightarrow \\mathbb{R}$ satisfies inequality (11) for some exponent $p>2$. Further, suppose that\n\n$$\n\\liminf _{n \\rightarrow \\infty} \\frac{1}{n} \\sum_{k=0}^{n-1} \\mathbb{E}\\left[\\frac{1}{r\\left(I_{k}\\right)}\\left\\|\\partial_{y_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}\\right]\\right\\|^{2}\\right]>0\n$$\n\nThen it is evident that the sequence $\\left(n / \\operatorname{Var}\\left(S_{n}\\right)\\right)_{n \\geq 1}$ is bounded. Consequently, by Corollary A.6, it follows that in addition to the results of Theorem 2.5, we also have\n\n$$\n\\frac{1}{\\operatorname{Var}\\left(S_{n}\\right)^{1 / 2}} S_{n} \\Longrightarrow \\mathcal{N}(0,1), \\text { as } n \\rightarrow \\infty\n$$\n\nin distribution. Therefore, the Central Limit Theorem holds.\nTo derive a lower bound for $\\operatorname{Var}\\left(S_{n}\\right)$, we strongly relied on the Cram\u00e9r-Rao bound, which requires certain differentiability and regularity conditions. However, these differentiability assumptions can be relaxed, either by applying a version of the Cram\u00e9r-Rao inequality developed for non-differentiable models [18], or by using some other information inequality (see, e.g., paragraph 3 in Chapter 30 of [3]).\n\nIt seems that it might be as difficult to evaluate the lower bound in (16) as to directly verify that\n\n$$\n\\operatorname{Var}\\left(S_{n}\\right)=O\\left(\\sum_{k=1}^{n} \\operatorname{Var}\\left(\\Phi\\left(X_{k}\\right)\\right)\\right)\n$$\n\nTo show that the lower bound on the right-hand side of (16) is tractable, we establish a more explicit sufficient condition under the assumptions that $\\mathcal{X}, \\mathcal{Y} \\subseteq \\mathbb{R}$ and the function $f$ in the iteration (1) satisfies some monotonicity condition.\n\nProposition 2.12. Assume that $\\mathcal{X}, \\mathcal{Y} \\subseteq \\mathbb{R}$, moreover the function $f: \\mathcal{X} \\times \\mathcal{Y} \\times[0,1] \\rightarrow \\mathbb{R}$ defining the iteration (1) is continuously differentiable and monotonically increasing in its first two variables. Besides the assumptions of Lemma 2.10, assume also that\n\n$$\nr^{*}:=\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left[r\\left(I_{n}\\right)\\right]=\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left[\\left(\\partial_{y} \\log p_{y}\\left(X_{n+1} \\mid X_{n}\\right)\\right)^{2}\\right]<\\infty\n$$\n\nand there exists a function $g: \\mathcal{Y} \\times[0,1] \\rightarrow(0, \\infty)$ such that\n\n$$\n\\partial_{y} f(x, y, u) \\geq g(y, u), \\quad x, y \\in \\mathbb{R}, u \\in[0,1]\n$$\n\nThen, for the variance of the partial sums $S_{n}=X_{1}+\\ldots+X_{n}$, we have\n\n$$\n\\operatorname{Var}\\left(S_{n}\\right) \\geq \\frac{1}{r^{*}} \\sum_{k=0}^{n-1} \\mathbb{E}\\left[g\\left(Y_{k}, \\varepsilon_{1}\\right)\\right]^{2}\n$$\n\nProof. By the Cauchy-Schwartz inequality, for $k=0, \\ldots, n-1$, we have\n\n$$\n\\mathbb{E}\\left[\\partial_{y_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}\\right]\\right]^{2} \\leq \\mathbb{E}\\left[\\frac{1}{r\\left(I_{k}\\right)}\\left(\\partial_{y_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}\\right]\\right)^{2}\\right] \\mathbb{E}\\left[r\\left(I_{k}\\right)\\right]\n$$\n\nhence using the inequality (17), we arrive at\n\n$$\n\\operatorname{Var}\\left(S_{n}\\right) \\geq \\sum_{k=0}^{n-1} \\mathbb{E}\\left[\\frac{1}{r\\left(I_{k}\\right)}\\left\\|\\partial_{y_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}\\right]\\right\\|^{2}\\right] \\geq \\frac{1}{r^{*}} \\sum_{k=0}^{n-1} \\mathbb{E}\\left[\\partial_{y_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}\\right]\\right]^{2}\n$$\n\nFix $0 \\leq k<n$. Then, by the monotonicity assumption, we have $\\partial_{y_{k}} \\mathbb{E}\\left[X_{l} \\mid \\underline{Y}\\right] \\geq 0$ for any $l=1, \\ldots, n$. Hence, using that the process $\\left(\\varepsilon_{n}\\right)_{n \\geq 1}$ is i.i.d. and independent of the environment $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$, we can estimate as\n$\\partial_{y_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{Y}\\right]=\\sum_{l=1}^{n} \\partial_{y_{k}} \\mathbb{E}\\left[X_{l} \\mid \\underline{Y}\\right] \\geq \\partial_{y_{k}} \\mathbb{E}\\left[X_{k+1} \\mid \\underline{Y}\\right]=\\mathbb{E}\\left[\\partial_{y} f\\left(X_{k}, Y_{k}, \\varepsilon_{k+1}\\right) \\mid \\underline{Y}\\right] \\geq \\mathbb{E}\\left[g\\left(Y_{k}, \\varepsilon_{1}\\right) \\mid \\underline{Y}\\right]$.\nSubstituting this estimate back into the inequality (18), we obtain the desired result.\n\nRemark 2.13. If the environment $\\left(Y_{n}\\right)_{n \\in \\mathbb{Z}}$ is stationary, then the lower bound for the variance of $S_{n}=X_{1}+\\ldots+X_{n}$ given in Proposition 2.12 simplifies to\n\n$$\n\\operatorname{Var}\\left(S_{n}\\right) \\geq \\frac{n}{r^{*}} \\mathbb{E}\\left[g\\left(Y_{0}, \\varepsilon_{1}\\right)\\right]^{2}\n$$\n\nso the inequality required in the assumptions of Corollary 2.11 is clearly satisfied.\nUsing the recent results by Merlev\u00e8de and Peligrad in [39], we can derive the following functional central limit theorem for certain functionals of a MCRE. This result is significantly stronger than the statement formulated in Corollary 2.11.\n7(thm:MCRE_FCLT) ${ }^{7}$ Theorem 2.14. Assume that the conditions of Corollary 2.11 hold, with the exception that instead of the inequality (12) appearing among the conditions of Theorem 2.5, we only require that\n\n$$\n\\sum_{n \\geq 1} n^{2 /(p-2)} \\alpha^{Y}(n)<\\infty\n$$\n\nFurthermore, for $n \\geq 1$, let $v_{n}(t)=\\min \\left\\{1 \\leq k \\leq n \\mid \\operatorname{Var}\\left(S_{k}\\right) \\geq t \\operatorname{Var}\\left(S_{n}\\right)\\right\\}$, and for $1 \\leq k \\leq n$, define\n\n$$\n\\xi_{k, n}=\\frac{\\Phi\\left(X_{k}\\right)-\\mathbb{E}\\left[\\Phi\\left(X_{k}\\right)\\right]}{\\operatorname{Var}\\left(S_{n}\\right)^{1 / 2}}\n$$\n\nThen the sequence of functions $B_{n}(t)=\\sum_{k=1}^{v_{n}(t)} \\xi_{k, n}, t \\in(0,1], n \\geq 1$, converges in distribution in $D([0,1])$ (equipped with the uniform topology) to $\\left(B_{t}\\right)_{t \\in[0,1]}$, where $\\left(B_{t}\\right)_{t \\in[0,1]}$ is a standard Brownian motion.\n\nProof. In the proof, we check the conditions of Corollary 2.2 found on page 3 of [39]. These conditions can be divided into two groups: conditions on the moments of the random variables $\\xi_{k, n}, 1 \\leq k \\leq n$, and conditions on the mixing properties of these variables. We first verify the fulfillment of the conditions in the first group.\n\nBy Lemma 2.3, we have $c_{1}=\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left(\\left|\\Phi\\left(X_{n}\\right)\\right|^{p}\\right)<\\infty$, and Lemma 2.10 ensures that $n / \\operatorname{Var}\\left(S_{n}\\right)<$ $c_{2}$ for some constant $c_{2}>0$ and for all $n \\geq 1$. Then, we have\n\n$$\n\\left\\|\\xi_{k, n}\\right\\|_{p}=\\frac{1}{\\operatorname{Var}\\left(S_{n}\\right)^{1 / 2}}\\left\\|\\Phi\\left(X_{k}\\right)-\\mathbb{E}\\left[\\Phi\\left(X_{k}\\right)\\right]\\right\\|_{p} \\leq 2 n^{-1 / 2}\\left(\\frac{n}{\\operatorname{Var}\\left(S_{n}\\right)}\\right)^{1 / 2}\\left\\|\\Phi\\left(X_{k}\\right)\\right\\|_{p} \\leq 2 c_{1}^{1 / r} c_{2}^{1 / 2} n^{-1 / 2}\n$$\n\nfrom which it immediately follows that $\\max _{1 \\leq k \\leq n}\\left\\|\\xi_{k, n}\\right\\|_{p} \\rightarrow 0$ as $n \\rightarrow \\infty$, and furthermore, $\\sup _{n \\geq 1} \\sum_{k=1}^{n}\\left\\|\\xi_{k, n}\\right\\|_{p}^{2}<\\infty$. Comparing this with the remark following Corollary 2.2 in [39], we conclude that condition (3) and the first part of condition (7) related to moments in [39] are satisfied. Additionally, condition (1) is inherently satisfied by the array $\\left\\{\\xi_{k, n} \\mid 1 \\leq k \\leq n, n \\geq 1\\right\\}$ due to its definition.\n\nWe now proceed to verify the conditions related to the mixing properties. The precise definitions of the weak strong mixing coefficients $\\alpha_{1}(k), \\alpha_{1, n}(k)$, and $\\alpha_{2, n}(k)$ can also be found in [39]. For our purposes, it suffices to note that the following sequence of inequalities holds:\n\n$$\n\\alpha_{1, n}(k) \\leq \\alpha_{2, n}(k) \\leq 2 \\alpha^{\\Phi(X)}(k), \\quad 1 \\leq k \\leq n, n \\geq 1\n$$\n\ntherefore, to verify the second part of condition (7) in [39] and to satisfy condition (8), it is enough to establish that\n\n$$\n\\sum_{n \\geq 1} n^{2 /(p-2)} \\alpha^{\\Phi(X)}(n)<\\infty\n$$\n\nFrom here, the proof continues by estimating the mixing coefficient $\\alpha^{\\Phi(X)}$ and follows exactly the same path as described in the proof of Theorem 1.5 and 2.5. By Lemma 2.4, the chain $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ admits a random iteration representation satisfying the coupling condition with $b(n)=O\\left(e^{-c n^{1 / 2}}\\right)$, $c>0$. Therefore, we can estimate\n\n$$\n\\alpha^{\\Phi(X)}(n) \\leq \\alpha^{X}(n) \\leq \\alpha^{Y}(\\lfloor n / 2\\rfloor+1)+b(n-\\lfloor n / 2\\rfloor), \\quad n>2 N\n$$\n\nwhere $N>0$ is as in Lemma 2.4. Considering that $\\sum_{n=1}^{\\infty} n^{2 /(p-2)} b(n-\\lfloor n / 2\\rfloor)<\\infty$, and that the condition $\\sum_{n \\geq 1} n^{2 /(p-2)} \\alpha^{Y}(n)<\\infty$ assumed, we obtain that the infinite series appearing in condition (19) is convergent.\n\nWith this, we have verified all of the conditions of Corollary 2.2 in [39], from which it follows that the statement formulated in the theorem holds. This completes the proof.\n\nRemark 2.15. In the proof of the above Theorem 2.14, we do not use Theorem 2.1 of [39] in its strongest form, but rather we verify only the conditions of Corollary 2.2. It is likely that Theorem 2.14 can be further strengthened and generalized for Markov chains in a random environment satisfying a weak-strong mixing-type condition. However, this is beyond the scope of the present study.", "tables": {}, "images": {}}, {"section_id": 4, "text": "# 3 Single server queuing systems \n\n7 (sec:queuing) ${ }^{7}$ In the early 20th century, Danish engineer Agner Krarup Erlang pioneered what would later be known as queuing theory [17]. His work at a telephone company, where he developed a mathematical model to determine the minimum number of telephones needed to handle calls efficiently, laid the foundation for this field. Today, queuing theory extends far beyond telecommunications, significantly influencing areas like inventory management, logistics, transportation, industrial engineering, and service design. Notably, it plays a key role in reducing costs within product-service design $[43]$.\n\nFor simplicity, we focus on single-server queuing systems with infinite buffer and first-in, firstout (FIFO) service discipline (see Figure 1). It's worth noting that more complex queuing systems,\n\n![img-0.jpeg](img-0.jpeg)\n\nFigure 1: Schematic overview of the single-server queuing system under investigation: $Z_{n}$ is the time between the arrivals of the $n$-th and $(n+1)$-th customers, $S_{n}$ is the time to serve the $n$-th customer, and $W_{n}$ is their waiting time before service.\n$?($ fig:queue $)$ ?\nsuch as those with multiple servers, can be analyzed using analogous methods. Let the time between the arrival of customers $n+1$ and $n$ is be denoted by $Z_{n+1}$, and the service time for customer $n$ is given by $S_{n}$, for $n \\in \\mathbb{N}$. Then, the evolution of the waiting time $W_{n}$ of customer $n$ can be described by the Lindley recursion\n\n$$\nW_{n+1}=\\left(W_{n}+S_{n}-Z_{n+1}\\right)_{+}, n \\in \\mathbb{N}\n$$\n\nwith $W_{0}:=0$, meaning that we begin with an empty queue.\nThe ergodic theory of general state space Markov chains allows to treat the case where $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$, $\\left(Z_{n}\\right)_{n \\in \\mathbb{N}}$ are i.i.d. sequences, independent of each other. However, dependencies frequently arise in queuing networks when the arrival processes intertwine with the departure processes of other queues. Additionally, factors like complex processing operations, including batching or the presence of multiple distinct customer classes, can introduce intricate interdependencies within the system. Consequently, the renewal process assumption for the arrival process, which makes queueing models amenable to simple analysis, no longer holds.\n\nTo the best of our knowledge, Loynes was the first who studied the stability of waiting times under the assumption that the pair $(S, Z)$ is merely stationary and ergodic [37]. Stability of $W_{n}$, $n \\in \\mathbb{N}$ means here that there exist a unique limit distribution of $W_{n}$ as $n \\rightarrow \\infty$, whatever the initialization $W_{0}$ is. Loynes introduced the terminology categorizing queues as 'subcritical' when $\\mathbb{E}\\left(S_{0}\\right)<\\mathbb{E}\\left(Z_{0}\\right)$, 'critical' when $\\mathbb{E}\\left(S_{0}\\right)=\\mathbb{E}\\left(Z_{0}\\right)$, and 'supercritical' when $\\mathbb{E}\\left(S_{0}\\right)>\\mathbb{E}\\left(Z_{0}\\right)$. Loynes proved for single-server queuing systems that subcritical queues are stable, supercritical queues are unstable and critical queues can be stable, properly substable, or unstable [37].\n\nBuilding upon Loynes's foundational work, Gy\u00f6rfi and Morvai expanded and refined the understanding of these queuing systems in [25]. They extended Loynes' result by proving that for subcritical queues, an even stronger version of stability called forward coupling holds also true (c.f. Definition 2.6). Gy\u00f6rfi and Morvai's theorem concerning queues in this general setting reads as follows:\n$?($ this:gyorfi $)^{7}$ Theorem 3.1. Let $\\xi_{n}=S_{n}-Z_{n+1}$ and assume that the process $\\left(\\xi_{n}\\right)_{n \\in \\mathbb{Z}}$ is stationary and ergodic with $\\mathbb{E}\\left(S_{0}\\right)<\\mathbb{E}\\left(Z_{0}\\right)$. Then $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ is forward coupled with a stationary and ergodic $\\left(W_{n}^{\\prime}\\right)_{n \\in \\mathbb{Z}}$ such that $W_{0}^{\\prime}=\\sup _{n \\in \\mathbb{N}} Y_{n}$, where $Y_{0}=0$ and $Y_{n}=\\sum_{k=1}^{n} \\xi_{-k}, n \\geq 1$.\n\nWhile the aforementioned theorems ensure that the distribution of waiting times converges to a well-defined limiting law, they regrettably do not furnish any insights into the properties of this stationary limit, nor do they shed light on the speed of convergence. When addressing the latter question, the only available rate estimate that comes to our aid is encapsulated in an inequality found in Theorem 4 on page 25 of [4], which is expressed as:\n\n$$\n\\left\\|\\operatorname{Law}\\left(W_{n}\\right)-\\operatorname{Law}\\left(W_{0}^{\\prime}\\right)\\right\\|_{T V} \\leq \\mathbb{P}\\left(\\min _{0<k<n} X_{k}>\\max \\left(W_{1}, W_{0}^{\\prime}+\\xi_{0}\\right)\\right)\n$$\n\nwhere $\\xi_{n}$ is as in Theorem 3.1, and $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ is defined as $X_{0}=0, X_{n}=\\sum_{k=1}^{n} \\xi_{k}, n \\geq 1$. However, it's worth noting that the primary limitation of this formula lies in its practical applicability. Evaluating the probability on the right-hand side of this equation can be a formidable task, rendering it impractical as a concrete and readily usable rate estimate.\n\nIf the inter-arrival times are i.i.d. and the sequences $S$ and $Z$ are independent of each other, then the process $W$ can be viewed as a Markov chain in the random environment $S$, with driving noise $Z$. Conversely, if the service times are i.i.d., and again $S$ and $Z$ are independent, $W$ can be regarded as a Markov chain in the random environment $Z$, with driving noise $S$. Therefore, both of these special cases of queuing systems fall within the theoretical framework outlined in Section 2. In $[34,35]$, we analyzed such queuing models with an additional G\u00e4rtner-Ellis-type condition (see Assumption 3.4 below or Assumption 4.2 in [35]), which is a well-established practice in queuing theory. For instance, in Section 3 of [25], similar conditions are employed to investigate the exponential tail behavior of the limit distribution of queue length when arrivals exhibit weak dependence. Further justification for the applicability of G\u00e4rtner-Ellis-type conditions can be found in Remark 4.3 of [35].\n\nIn what follows, we revisit the queuing model studied in [35]. Specifically, we consider the case where $S$ and $Z$ are independent, and the latter is an i.i.d. sequence. The reverse case discussed in [34] can be treated analogously. We begin by examining the scenario where the sequence of service times is strictly stationary. Regarding this case, we formulate our standing assumptions.\n7(as:queue:proc) ${ }^{7}$ Assumption 3.2. There exists an $M>0$ such that the sequence of service times $\\left(S_{n}\\right)_{n \\in \\mathbb{Z}}$ is a strictly stationary process taking values in $[0, M]$. Furthermore, $\\left(S_{n}\\right)_{n \\in \\mathbb{Z}}$ is independent of the sequence $\\left(Z_{n}\\right)_{n \\in \\mathbb{Z}}$.\n7(as:queue:stab) ${ }^{7}$ Assumption 3.3. The inter-arrival times $\\left(Z_{n}\\right)_{n \\in \\mathbb{Z}}$ form an i.i.d. sequence of $\\mathbb{R}_{+}$-valued random variables, and $\\mathbb{E}\\left[S_{0}\\right]<\\mathbb{E}\\left[Z_{1}\\right]$ holds.\n7(as:queue:GE) ${ }^{7}$ Assumption 3.4. There exists $\\eta>0$ such that for all $t \\in(-\\eta, \\eta)$, the limit\n\n$$\n\\Gamma(t):=\\lim _{n \\rightarrow \\infty} \\frac{1}{n} \\log \\mathbb{E} e^{t\\left(S_{1}+\\ldots+S_{n}\\right)}\n$$\n\nexists and $\\Gamma$ is differentiable on $(-\\eta, \\eta)$.\nUnder Assumptions 3.2, 3.3, and 3.4, by Lemma 4.4 of [35], the sequence of waiting times $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$, defined by the Lindley recursion (20), forms a Markov chain in the random environment $\\left(S_{n}\\right)_{n \\in \\mathbb{Z}}$ on the state space $\\mathcal{X}=\\mathbb{R}_{+}$with parametric kernel\n\n$$\nQ(s, w, A):=\\mathbb{P}\\left[\\left(w+s-Z_{1}\\right)_{+} \\in A\\right], s \\in[0, M], w \\in \\mathbb{R}_{+}, A \\in \\mathcal{B}\\left(\\mathbb{R}_{+}\\right)\n$$\n\nFurthermore, there exists $\\bar{t}>0$ such that, with the following coefficients:\n\n$$\n\\begin{aligned}\nV(w) & :=e^{\\bar{t} w}-1, \\quad w \\geq 0 \\\\\n\\gamma(s) & :=\\mathbb{E}\\left[e^{\\bar{t}\\left(s-Z_{1}\\right)}\\right], \\quad s \\geq 0 \\\\\nK & :=e^{\\bar{t} M}\n\\end{aligned}\n$$\n\nthe drift condition (7) and the long-term contractivity condition (9) are satisfied, meaning\n\n$$\n[Q(s) V](w) \\leq \\gamma(s) V(w)+K\n$$\n\nand\n\n$$\n\\bar{\\gamma}:=\\limsup _{n \\rightarrow \\infty}\\left(\\mathbb{E}^{1 / n}\\left[K \\prod_{k=1}^{n} \\gamma\\left(S_{k}\\right)\\right]\\right)<1\n$$\n\nWe now introduce an additional assumption on the inter-arrival times, which will be required to establish the minorization condition.\n7(as:queue:minor) ${ }^{7}$ Assumption 3.5. One has $\\mathbb{P}\\left(Z_{0} \\geq \\tau\\right)>0$ for\n\n$$\n\\tau:=M+\\frac{4}{\\frac{1}{\\bar{\\gamma}^{1 / 2}}-1}\n$$\n\nThis does not impose a significant restriction, since if $Z_{0}$ is an unbounded random variable, Assumption 3.5 is automatically satisfied.\n\nBy Lemma 4.6 of [35], under Assumptions 3.2, 3.3, 3.4, and 3.5, it can be shown that there exists $\\bar{\\beta} \\in(0,1)$ such that, for all $s \\in[0, M], A \\in \\mathcal{B}\\left(\\mathbb{R}_{+}\\right)$, and $w \\in \\stackrel{-1}{V}([0, R(s)])$,\n\n$$\nQ(s, w, A) \\geq(1-\\bar{\\beta}) \\delta_{0}(A), \\text { where } R(s)=\\frac{2 K(s)}{\\epsilon \\gamma(s)}\n$$\n\n$\\epsilon:=\\left(\\frac{1}{\\gamma / 7}-1\\right) / 2$, and $\\delta_{0}$ is the one-point mass concentrated at 0 .\nThe main result of Chapter 4, which discusses queuing theory applications in [35], is Theorem 4.7. It states that under Assumptions 3.2, 3.3, 3.4, and 3.5, there exists a probability measure $\\mu_{*}$ on $\\mathcal{B}\\left(\\mathbb{R}_{+}\\right)$, independent of the initial length of the queue, such that\n\n$$\n\\left\\|\\operatorname{Law}\\left(W_{n}\\right)-\\mu_{*}\\right\\|_{T V} \\leq c_{1} e^{-c_{2} n^{1 / 3}}\n$$\n\nfor some $c_{1}, c_{2}>0$. Furthermore, if $\\left(S_{n}\\right)_{n \\in \\mathbb{Z}}$ is ergodic, then for an arbitrary measurable and bounded function $\\Phi: \\mathbb{R}_{+} \\rightarrow \\mathbb{R}$,\n\n$$\n\\frac{\\Phi\\left(W_{0}\\right)+\\ldots+\\Phi\\left(W_{n-1}\\right)}{n} \\rightarrow \\int_{\\mathbb{R}_{+}} \\Phi(z) \\mu_{*}(\\mathrm{~d} z)\n$$\n\nin $L^{p}$, for all $1 \\leq p<\\infty$.\nUsing Theorem 2.7 and Corollary 2.8, we can prove even more. In the queuing model we study, for instance, the sequence of waiting times $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ is forward coupled with a strictly stationary sequence $\\left(W_{n}^{*}\\right)_{n \\in \\mathbb{N}}$. This does not require assuming the ergodicity of the service time sequence, and we obtain a tractable upper bound on the tail probability of the random coupling time. Finally, we demonstrate a faster convergence rate than that presented in the estimate (23). The following theorem addresses this result.\n7(thm:queue:stac) ${ }^{7}$ Theorem 3.6. Let Assumptions 3.2, 3.3, 3.4, and 3.5 be in force. Then there exists a stationary process $\\left(S_{n}, W_{n}^{*}\\right)_{n \\in \\mathbb{Z}}$ that satisfies the Lindley recursion (20). Moreover, appropriate versions of the processes $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ and $\\left(W_{n}^{*}\\right)_{n \\in \\mathbb{N}}$ are forward coupled. For the tail probability of the random coupling time $\\tau$, we have the bound\n\n$$\n\\mathbb{P}(\\tau>n) \\leq c_{1} e^{-c_{2} n^{1 / 2}}\n$$\n\nfor suitable constants $c_{1}, c_{2}>0$, depending only on the quantities $\\bar{\\beta}, \\bar{\\gamma}$, and $\\epsilon$. Furthermore, for the total variation distance of $\\operatorname{Law}\\left(W_{n}\\right)$ and $\\operatorname{Law}\\left(W_{n}^{*}\\right)$ we have the following estimate:\n\n$$\n\\left\\|\\operatorname{Law}\\left(W_{n}\\right)-\\operatorname{Law}\\left(W_{n}^{*}\\right)\\right\\|_{T V} \\leq 2 c_{1} e^{-c_{2} n^{1 / 2}}\n$$\n\nwith the same constants $c_{1}$ and $c_{2}$.\nProof. The sequence of service times $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$ is strictly stationary, so Assumption 2.2 A) simplifies to the (9) long-term contractivity condition used in our earlier paper [35]. We have already shown above that this holds under the conditions of the theorem. From the minorization condition (22), part B) of Assumption 2.2 follows. Thus, we can apply Theorem 2.7, which states that there exists a stationary process $\\left(S_{n}, W_{n}^{*}\\right)_{n \\in \\mathbb{Z}}$ that satisfies the Lindley recursion (20). Moreover, appropriate versions of the processes $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ and $\\left(W_{n}^{*}\\right)_{n \\in \\mathbb{N}}$ are forward coupled. Considering the specific form of the Lyapunov function in the drift condition, $V(w)=e^{t w}-1$, and the initial condition $W_{0}=0$, we obtain\n\n$$\n\\mathbb{E}\\left(V\\left(W_{0}\\right)\\right)=0\n$$\n\nTherefore, for the tail probability of the random coupling time $\\tau$, we have\n\n$$\n\\mathbb{P}(\\tau>n) \\leq c_{1}\\left(1+\\mathbb{E}\\left(V\\left(W_{0}\\right)\\right)\\right) e^{-c_{2} n^{1 / 2}}=c_{1} e^{-c_{2} n^{1 / 2}}\n$$\n\nas stated. Finally, the estimate for the total variation distance between $\\operatorname{Law}\\left(W_{n}\\right)$ and $\\operatorname{Law}\\left(W_{n}^{*}\\right)$ immediately follows from Corollary 2.8.\n\nIn the remaining part of this section, we relax the assumption that the sequence of service times $\\left(S_{n}\\right)_{n \\in \\mathbb{Z}}$ is stationary. We only assume that it is a sequence of weakly dependent variables with sufficiently favorable mixing properties. Accordingly, our assumptions will be as follows.\n7(as:queue: $\\mathbb{Z}$ ) 7 Assumption 3.7. We assume that the inter-arrival time sequence $\\left(Z_{n}\\right)_{n \\geq 1}$ is i.i.d. and independent of the service time sequence $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$. Moreover, we also assume that $\\mathbb{E}\\left(Z_{0}^{2}\\right)<\\infty$.\n7(as:queue: $\\mathbb{S}$ ) 7 Assumption 3.8. We assume that the service time sequence $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$ takes values in $\\mathcal{Y}=[0, M]$. For $t \\geq 0$, we define the function\n\n$$\n\\Lambda(t)=\\limsup _{n \\rightarrow \\infty} \\sup _{j \\in \\mathbb{N}} \\frac{1}{n} \\log \\mathbb{E}\\left[\\exp \\left(t \\sum_{k=0}^{n}\\left(S_{k+j}-Z_{k+j+1}\\right)\\right)\\right]\n$$\n\nAssume that there exists a parameter $\\bar{t}>0$ such that $\\Lambda(\\bar{t})<0$.\n7(rem:number) 7 Remark 3.9. In Lemma 4.4 of [35], under Assumption 3.4, we showed that there exists a parameter $\\bar{t}>0$ such that in Assumption 3.8, $\\Lambda(\\bar{t})<0$. Although such a condition is quite standard in both queuing theory and large deviation theory, verifying the differentiability of the function $t \\mapsto \\Gamma(t)$ in Assumption 3.4 can be challenging in practice. Moreover, the proof of Lemma 4.4 in [35] does not generalize to the case of a non-stationary sequence $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$, since the definition of the function $\\Lambda$ includes a supremum, which prevents the application of convexity-based arguments.\n\nFor fixed $n, j \\in \\mathbb{N}$, define\n\n$$\n\\lambda_{n, j}(t)=\\frac{1}{n} \\log \\mathbb{E}\\left[\\exp \\left(t \\sum_{k=0}^{n}\\left(S_{k+j}-Z_{k+j+1}\\right)\\right)\\right]\n$$\n\nIf $\\lim \\sup _{n \\rightarrow \\infty} \\mathbb{E}\\left(S_{n}\\right)<\\mathbb{E}\\left(Z_{1}\\right)$, it can be shown that for sufficiently large $n, \\lambda_{n, j}^{\\prime}(0)<0$. Additionally, if the mixing coefficients $\\alpha^{S}(n)$ decay sufficiently fast to zero, it can be established that $\\lambda_{n, j}^{\\prime \\prime}(0)<\\infty$. However, this alone does not ensure the existence of a parameter $\\bar{t}>0$ such that $\\Lambda(\\bar{t})<0$.\n\nThe goal of the next proposition is to provide a sufficient condition under which the otherwise difficult-to-verify requirement on $\\Lambda(t)$ in Assumption 3.8 holds. This condition relies on a mixing property stronger than $\\alpha$-mixing, known as $\\psi$-mixing. In analogy with the dependence measure $\\alpha(\\mathcal{G}, \\mathcal{H})$ introduced in Section 1, we define\n\n$$\n\\psi(\\mathcal{G}, \\mathcal{H})=\\sup \\left\\{\\left|\\frac{\\mathbb{P}(G \\cap H)}{\\mathbb{P}(G) \\mathbb{P}(H)}-1\\right| \\mid \\mathbb{P}(G)>0, \\mathbb{P}(\\mathcal{H})>0, G \\in \\mathcal{G}, H \\in \\mathcal{H}\\right\\}\n$$\n\nFurthermore, for an arbitrary sequence of random variables $\\left(W_{t}\\right)_{t \\in \\mathbb{Z}}$, the sequence of $\\psi$-mixing coefficients is defined as\n\n$$\n\\psi^{W}(n)=\\sup _{j \\in \\mathbb{Z}} \\psi\\left(\\mathcal{F}_{-\\infty, j}^{W}, \\mathcal{F}_{j+n, \\infty}^{W}\\right), \\quad n \\in \\mathbb{N}\n$$\n\nWe say that the process $\\left(W_{n}\\right)_{n \\in \\mathbb{Z}}$ is $\\psi$-mixing if $\\psi^{W}(n) \\rightarrow 0$ as $n \\rightarrow \\infty$.\nIt is straightforward to show that every $\\psi$-mixing process is also $\\alpha$-mixing, but the converse does not hold. Moreover, $\\psi$-mixing is one of the strongest forms of strong mixing conditions, implying several others such as $\\alpha-, \\beta-, \\phi$-, and $\\rho$-mixing. Nevertheless, the class of $\\psi$-mixing processes remains of considerable interest. For instance, in the case of strictly stationary, finite-state Markov chains, the notions of $\\alpha$ - and $\\psi$-mixing coincide (See Theorem 3.1 in [8]).\n\nTo formulate the next proposition, we need the notion of stochastic ordering. A real-valued random variable $W_{1}$ is said to be stochastically smaller than another random variable $W_{2}$, denoted by $W_{1} \\preceq W_{2}$, if\n\n$$\n\\mathbb{P}\\left(W_{1}>x\\right) \\leq \\mathbb{P}\\left(W_{2}>x\\right), \\quad x \\in \\mathbb{R}\n$$\n\nor, equivalently,\n\n$$\n\\mathbb{E}\\left[u\\left(W_{1}\\right)\\right] \\leq \\mathbb{E}\\left[u\\left(W_{2}\\right)\\right]\n$$\n\nfor every monotonically increasing function $u: \\mathbb{R} \\rightarrow \\mathbb{R}$.\n\n7prop:psi_mix)7 Proposition 3.10. Let the sequence of inter-arrival times $\\left(Z_{n}\\right)_{n \\geq 1}$ be i.i.d. and independent of the service time sequence $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$, which is assumed to be $\\psi$-mixing and takes values in $\\mathcal{Y}=[0, M]$. Suppose furthermore that there exists a random variable $S^{*}$ such that $\\mathbb{E}\\left[S^{*}\\right]<\\mathbb{E}\\left[Z_{1}\\right]$, moreover $S_{n} \\preceq S^{*}$ for all $n \\in \\mathbb{N}$.\n\nThen there exists $\\bar{t}>0$ such that\n\n$$\n\\Lambda(\\bar{t})<0\n$$\n\nwhere $\\Lambda(t)$ is the rate function defined in Assumption 3.8.\nProof. Let $j \\in \\mathbb{N}$ and $n \\geq 1$ be arbitrary but fixed, and define $W_{k}=e^{t\\left(S_{k-1}-Z_{k}\\right)}, k=1, \\ldots, n$. Our goal is to estimate $\\mathbb{E}\\left[W_{j+1} \\cdots W_{j+n}\\right]$. For integers $p, q$ satisfying $p q \\leq n<p(q+1)$, which allows us to write\n\n$$\nW_{j+1} \\cdots W_{j+n}=\\eta_{1} \\cdots \\eta_{p} \\Delta_{n}\n$$\n\nwhere $\\eta_{k}=\\prod_{l=0}^{q-1} W_{j+k+l p}, k=1, \\ldots, p$, and $\\Delta_{n}=W_{j+p q+1} \\cdots W_{j+n}$.\nUsing $\\Delta_{n} \\leq e^{t M(p-1)}$ and H\u00f6lder-inequality, we have\n\n$$\n\\mathbb{E}\\left[W_{j+1} \\cdots W_{j+n}\\right] \\leq e^{t M(p-1)} \\prod_{k=1}^{p} \\mathbb{E}^{1 / p}\\left[\\eta_{k}^{p}\\right]\n$$\n\nFor any fixed $k$, by independence, we have\n\n$$\n\\mathbb{E}\\left[\\eta_{k}^{p}\\right]=\\mathbb{E}\\left[\\prod_{l=0}^{q-1} e^{t p\\left(S_{j+k-1+l p}-Z_{j+k+l p}\\right)}\\right]=\\mathbb{E}\\left[e^{-t p Z_{1}}\\right]^{q} \\mathbb{E}\\left[\\prod_{l=0}^{q-1} e^{t p S_{j+k-1+l p}}\\right]\n$$\n\nUsing layer cake representation, and that $S_{n} \\preceq S^{*}$, for $n \\in \\mathbb{N}$, we can write\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[\\prod_{l=0}^{q-1} e^{t p S_{j+k-1+l p}}\\right] & =\\int_{[0, \\infty)^{q}} \\mathbb{P}\\left(e^{t p S_{j+k-1+l p}} \\geq \\tau_{l}, l=0, \\ldots, q-1\\right) \\mathrm{d} \\tau_{0} \\ldots \\mathrm{~d} \\tau_{q-1} \\\\\n& \\leq\\left(1+\\psi^{S}(p)\\right)^{q-1} \\prod_{l=0}^{q-1} \\int_{[0, \\infty)} \\mathbb{P}\\left(e^{t p S_{j+k-1+l p}} \\geq \\tau_{l}\\right) \\mathrm{d} \\tau_{l} \\\\\n& =\\left(1+\\psi^{S}(p)\\right)^{q-1} \\prod_{l=0}^{q-1} \\mathbb{E}\\left[e^{t p S_{j+k-1+l p}}\\right] \\leq\\left(1+\\psi^{S}(p)\\right)^{q-1} \\mathbb{E}\\left[e^{t p S^{*}}\\right]^{q}\n\\end{aligned}\n$$\n\nTo sum up, and taking the supremum in $j$, we obtain the following estimate:\n\n$$\n\\sup _{j \\in \\mathbb{N}} \\mathbb{E}\\left[W_{j+1} \\cdots W_{j+n}\\right] \\leq e^{t M(p-1)}\\left(1+\\psi^{S}(p)\\right)^{q-1} \\mathbb{E}\\left[e^{t p\\left(S^{*}-Z_{1}\\right)}\\right]^{q}\n$$\n\nSince $\\left.\\frac{\\mathrm{d}}{\\mathrm{d} k} \\mathbb{E}\\left[e^{h\\left(S^{*}-Z_{1}\\right)}\\right]\\right|_{t=0}=\\mathbb{E}\\left[S^{*}-Z_{1}\\right]<0$, for arbitrary $m$ satisfying $\\mathbb{E}\\left[S^{*}-Z_{1}\\right]<m<0$ there exists $h_{0}>0$ such that\n\n$$\n\\mathbb{E}\\left[e^{h\\left(S^{*}-Z_{1}\\right)}\\right]<1+m h, \\quad 0<h<h_{0}\n$$\n\nLet $h_{0}^{\\prime} \\in\\left(0, h_{0}\\right)$ be fixed. By the $\\psi$-mixing property of the sequence $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$, there exists $p_{0} \\geq 1$ such that\n\n$$\n\\zeta:=\\left(1+\\psi^{S}\\left(p_{0}\\right)\\right)\\left(1+m h_{0}^{\\prime}\\right)<1\n$$\n\nUsing (27) with $t=\\bar{t}:=h_{0}^{\\prime} / p_{0}$ and $q_{n}=\\left\\lfloor\\frac{n}{p_{0}}\\right\\rfloor, n \\geq 1$, we obtain\n\n$$\n\\sup _{j \\in \\mathbb{N}} \\mathbb{E}\\left[W_{j+1} \\cdots W_{j+n}\\right] \\leq e^{h_{0}^{\\prime} M} \\zeta^{q_{n}} \\leq e^{h_{0}^{\\prime} M} \\zeta^{-1} \\zeta^{n / p_{0}}\n$$\n\nand thus\n\n$$\n\\sup _{j \\in \\mathbb{N}} \\frac{1}{n} \\log \\mathbb{E}\\left[\\exp \\left(\\bar{t} \\sum_{k=0}^{n}\\left(S_{k+j}-Z_{k+j+1}\\right)\\right)\\right] \\leq \\frac{n+1}{n p_{0}} \\log \\zeta+\\frac{1}{n} \\log \\left(e^{h_{0}^{\\prime} M} \\zeta^{-1}\\right)\n$$\n\nwhich immediately implies that\n\n$$\n\\Lambda(\\bar{t})=\\limsup _{n \\rightarrow \\infty} \\sup _{j \\in \\mathbb{N}} \\frac{1}{n} \\log \\mathbb{E}\\left[\\exp \\left(i \\sum_{k=0}^{n}\\left(S_{k+j}-Z_{k+j+1}\\right)\\right)\\right] \\leq \\frac{1}{p_{0}} \\log \\zeta<0\n$$\n\nIt is conceivable that the requirement on $\\Lambda(t)$ in Assumption 3.8 could be verified under mixing conditions on the sequence $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$ that are weaker than $\\psi$-mixing. In particular, [10] addresses large deviation theorems under strong mixing. The authors showed that for stationary processes with a hyper-exponential mixing rate-specifically, $\\alpha(n) \\ll \\exp (-n(\\log n)^{1+\\delta})$ for some $\\delta>0$-the existence of a limit analogous to the one in the definition of the rate function $\\Lambda$ is ensured (see Theorem 1 in [10]). However, they also provided counterexamples based on Doeblin recurrent, irreducible Markov chains with countable state spaces to demonstrate that this decay condition on the mixing coefficient cannot be significantly weakened.\n(lem:queue:drift17) ${ }^{7}$ Lemma 3.11. Under Assumption 3.7, the sequence of waiting times $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$, defined by the Lindley recursion (20), forms a Markov chain in the random environment $\\left(S_{n}\\right)_{n \\in \\mathbb{Z}}$ on the state space $\\mathcal{X}=\\mathbb{R}_{+}$with the parametric kernel\n\n$$\nQ(s, w, A):=\\mathbb{P}\\left[\\left(w+s-Z_{1}\\right)_{+} \\in A\\right], s, w \\in \\mathbb{R}_{+}, A \\in \\mathcal{B}\\left(\\mathbb{R}_{+}\\right)\n$$\n\nFor the Lyapunov function $V(w)=e^{t w}-1, w \\in \\mathbb{R}_{+}$, the drift condition holds for any choice of $t>0$ :\n\n$$\n[Q(s) V](w) \\leq \\gamma(s) V(w)+K(s)\n$$\n\nwith $\\gamma(s)=K(s)=\\mathbb{E}\\left[e^{t\\left(s-Z_{1}\\right)}\\right], s \\geq 0$.\nProof. The sequence of waiting times $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$, governed by the Lindley recursion (20), constitutes a non-linear autoregressive process of the form (1). In this framework, $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$ represents the sequence of exogenous covariates, while $\\left(Z_{n}\\right)_{n \\in \\mathbb{N}}$ plays the role of the noise process $\\left(\\varepsilon_{n}\\right)_{n \\in \\mathbb{N}}$. Furthermore, by Assumption 3.7, $\\left(Z_{n}\\right)_{n \\in \\mathbb{N}}$ is i.i.d. and independent of $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$, and thus the identity in the form (2) holds. Consequently, $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ can be interpreted as a Markov chain in a random environment defined by $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$, with the corresponding parametric kernel given by\n\n$$\nQ(s, w, A)=\\mathbb{P}\\left(\\left(s+w-Z_{1}\\right) \\in A\\right)_{+}, \\quad s, w \\in \\mathbb{R}_{+}, A \\in \\mathcal{B}\\left(\\mathbb{R}_{+}\\right)\n$$\n\nLet $t>0$ be arbitrary and define $V(w)=e^{t w}-1$. Using the inequality $e^{(x)_{+}}-1 \\leq e^{x}$ for all $x \\in \\mathbb{R}$, we obtain the drift condition:\n\n$$\n\\begin{aligned}\n{[Q(s) V](w) } & =\\mathbb{E}\\left[V\\left(\\left(w+s-Z_{1}\\right)_{+}\\right)\\right]=\\mathbb{E}\\left[e^{t\\left(w+s-Z_{1}\\right)_{+}}-1\\right] \\\\\n& \\leq \\mathbb{E}\\left[e^{t\\left(w+s-Z_{1}\\right)}\\right]=\\mathbb{E}\\left[e^{t\\left(s-Z_{1}\\right)}\\right]\\left(e^{t w}-1\\right)+\\mathbb{E}\\left[e^{t\\left(s-Z_{1}\\right)}\\right] \\\\\n& =\\gamma(s) V(w)+K(s)\n\\end{aligned}\n$$\n\nwhere $\\gamma(s)=K(s)=\\mathbb{E}\\left[e^{t\\left(s-Z_{1}\\right)}\\right], s \\geq 0$ which completes the proof.\nThe following lemma, which ensures the fulfillment of part B) of Assumption 2.2, essentially coincides with Lemma 4.6 in [35]. We include the proof here solely for the sake of completeness.\n7(lem:q:tech) ${ }^{7}$ Lemma 3.12. Assume that $\\mathbb{P}\\left(Z_{1} \\geq M+\\tau\\right)>0$ holds for some $\\tau>0$. Then, there exists $\\bar{\\beta} \\in(0,1)$ such that, for all $s \\in[0, M]$ and $w \\in[0, \\tau]$,\n\n$$\nQ(s, w, A) \\geq(1-\\bar{\\beta}) \\delta_{0}(A), A \\in \\mathcal{B}\\left(\\mathbb{R}_{+}\\right)\n$$\n\nwhere $\\delta_{0}$ denotes the Dirac measure concentrated at 0 .\n\nProof. Let $s \\in[0, M], w \\in[0, \\tau]$, and $A \\in \\mathcal{B}\\left(\\mathbb{R}_{+}\\right)$. We can write\n\n$$\n\\begin{aligned}\nQ(s, w, A) & =\\mathbb{P}\\left(\\left[w+s-Z_{1}\\right]_{+} \\in A\\right) \\geq \\mathbb{P}\\left(\\left[w+s-Z_{1}\\right]_{+}=0\\right) \\delta_{0}(A) \\\\\n& =\\left(1-\\mathbb{P}\\left(s+w-Z_{1}>0\\right)\\right) \\delta_{0}(A) \\\\\n& \\geq\\left(1-\\mathbb{P}\\left(M+\\tau-Z_{1}>0\\right)\\right) \\delta_{0}(A)\n\\end{aligned}\n$$\n\nwhich shows that the desired inequality holds for any choice of $\\bar{\\beta}$ satisfying\n\n$$\n\\mathbb{P}\\left(Z_{1}<M+\\tau\\right)<\\bar{\\beta}<1\n$$\n\nLet Assumptions 3.7 and 3.8 be in force, and let $\\bar{t}>0$ be as specified in Assumption 3.8. Then, by Lemma 3.11, for the Lyapunov function $V(w)=e^{\\bar{t} w}-1, w \\geq 0$, the drift condition (7) holds with $\\gamma(s)=K(s)=\\mathbb{E}\\left[e^{\\bar{t}\\left(s-Z_{1}\\right)}\\right]$, for $s \\in \\mathcal{Y}=[0, M]$. Furthermore, since $\\gamma(s)=K(s) \\leq e^{\\bar{t} M}$, we have\n\n$$\n\\mathbb{E}\\left[K\\left(S_{j}\\right) \\prod_{k=1}^{n} \\gamma\\left(S_{k+j}\\right)\\right] \\leq e^{\\bar{t} M(n+1)}\n$$\n\nfor all $j \\in \\mathbb{N}$ and $n \\geq 1$, hence the integrability condition in Assumption 2.2 is satisfied. Moreover, by Assumptions 3.7 and 3.8,\n\n$$\n\\bar{\\gamma}=\\limsup _{n \\rightarrow \\infty} \\sup _{j \\geq-1} \\mathbb{E}^{1 / n}\\left[\\exp \\left(\\bar{t} \\sum_{k=0}^{n}\\left(S_{k+j}-Z_{k+j+1}\\right)\\right)\\right]=e^{\\Lambda(\\bar{t})}<1\n$$\n\nwhich implies that part A) of Assumption 2.2 also holds.\nSuppose that for some $0<r<1 / \\bar{\\gamma}$ and $\\tau:=\\frac{1}{t} \\log \\left(1+\\frac{2}{r}\\right)$,\n\n$$\n\\mathbb{P}\\left(Z_{1} \\geq M+\\tau\\right)>0\n$$\n\nWe now verify part B) of Assumption 2.2. We have $R(s)=\\frac{2 K(s)}{\\tau \\gamma(s)}=2 / r$ since $\\gamma(s)=K(s)$ for all $s \\in[0, M]$. By Lemma 3.12, there exists $\\bar{\\beta} \\in(0,1)$ such that for all $s \\in[0, M]$ and $w \\in[0, \\tau]$,\n\n$$\nQ(s, w, A) \\geq(1-\\bar{\\beta}) \\delta_{0}(A), \\quad A \\in \\mathcal{B}\\left(\\mathbb{R}_{+}\\right)\n$$\n\nwhere $\\delta_{0}$ denotes the Dirac measure concentrated at 0 . Note that $w \\in[0, \\tau]$ if and only if $V(w) \\in$ $[0,2 / r]=[0, R(s)]$, for $s \\in[0, M]$. Therefore, the minorization condition (8) holds with $\\kappa_{R}(s, \\cdot)=$ $\\delta_{0}(\\cdot)$ for $s \\in[0, M]$. Furthermore, the minorization coefficient $\\beta(R(s), s)=\\bar{\\beta} \\in(0,1)$ is independent of $s$, hence part B) of Assumption 2.2 is also satisfied.\n7 (thm:queue:main) ${ }^{7}$ Theorem 3.13. Assume that the sequences $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$ and $\\left(Z_{n}\\right)_{n \\geq 1}$ satisfy Assumptions 3.7 and 3.8, moreover for some $0<r<1 / \\bar{\\gamma}$,\n\n$$\n\\mathbb{P}\\left(Z_{1} \\geq M+\\frac{1}{\\bar{t}} \\log \\left(1+\\frac{2}{r}\\right)\\right)>0\n$$\n\nwhere $\\bar{t}$ is as in Assumption 3.8, and $\\bar{\\gamma}=\\exp (\\Lambda(\\bar{t}))$.\nThen for the sequence of waiting times $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$, defined by the Lindley recursion (20), the following statements hold.\nA) If the sequence of service times $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$ is strongly mixing, then the $L^{1}$ weak law of large numbers holds:\n\n$$\n\\frac{1}{n} \\sum_{k=1}^{n}\\left[W_{k}-\\mathbb{E}\\left(W_{k}\\right)\\right] \\xrightarrow{L^{1}} 0, \\quad \\text { as } \\quad n \\rightarrow \\infty\n$$\n\nB) If there exists $c>0$ and $\\kappa>1$ such that $\\alpha^{S}(n) \\leq c n^{-\\kappa}, n \\geq 1$, then\n\n$$\n\\frac{1}{n} \\sum_{k=1}^{n}\\left[W_{k}-\\mathbb{E}\\left(W_{k}\\right)\\right] \\xrightarrow{\\kappa \\cdot \\kappa} 0, \\quad \\text { as } \\quad n \\rightarrow \\infty\n$$\n\nC) If the sequence of mixing coefficients $\\left(\\alpha^{S}(n)\\right)_{n \\in \\mathbb{N}}$ satisfies the condition\n\n$$\n\\sum_{n \\in \\mathbb{N}}(n+1)^{2} \\alpha^{S}(n)^{\\delta}<\\infty\n$$\n\nfor some exponent $\\delta \\in(0,1)$, then there exists a constant $\\sigma>0$ such that\n\n$$\n\\limsup _{n \\rightarrow \\infty} \\mathbb{P}\\left(\\frac{1}{\\sqrt{n}}\\left|\\sum_{k=1}^{n}\\left(W_{k}-\\mathbb{E}\\left(W_{k}\\right)\\right)\\right| \\geq a\\right) \\leq \\int_{\\mathbb{R}} \\mathbb{1}_{[-a, a]^{\\circ}}(\\sigma t) \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{t^{2}}{2}} \\mathrm{~d} t, \\quad a>0\n$$\n\nProof. From Lemma 3.11, it follows that the sequence of waiting times $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ is a Markov chain in a random environment $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$, which satisfies the drift condition (7) with $V(w)=e^{t w}-1$ and $\\gamma(s)=K(s)=\\mathbb{E}\\left[e^{t\\left(s-Z_{0}\\right)}\\right]$.\n\nGiven that $S_{n} \\in[0, M]$ for all $n \\in \\mathbb{N}$, it holds that $\\mathbb{E}\\left[K\\left(S_{j}\\right) \\prod_{k=1}^{n} \\gamma\\left(S_{k+j}\\right)\\right] \\leq e^{t M(n+1)}$, which implies that the integrability condition in Assumption 2.2 is trivially satisfied, i.e.,\n\n$$\n\\mathbb{E}\\left[K\\left(S_{j}\\right) \\prod_{k=1}^{n} \\gamma\\left(S_{k+j}\\right)\\right]<\\infty \\quad \\text { for all } \\quad j \\in \\mathbb{N} \\text { and } n \\geq 1\n$$\n\nMoreover, by Assumption 3.8, the parameter $t>0$ can be chosen such that\n\n$$\n\\bar{\\gamma}=\\limsup _{n \\rightarrow \\infty} \\sup _{j \\in \\mathbb{N}} \\mathbb{E}^{1 / n}\\left[\\prod_{k=0}^{n} \\gamma\\left(S_{k+j}\\right)\\right]<1\n$$\n\nwhich ensures that part A) of Assumption 2.2 is satisfied.\nNotice that, since $\\gamma=K$, hence by Lemma 3.12, the parametric kernel $Q$ satisfies the minorization condition (8) with\n\n$$\nR(s)=\\frac{2 K(s)}{r \\gamma(s)}=\\frac{2}{r}, \\beta(R(s), s)=\\bar{\\beta}<1, \\text { and } \\kappa_{R(s)}(s, A)=\\delta_{0}(A)\n$$\n\nWe can conclude that part B) of Assumption 2.2 also holds.\nIn Theorem 2.5, the inequality (11) is satisfied with $\\Phi=\\operatorname{id}_{[0, \\infty)}$ for any $p>1$, while the deterministic initial condition $W_{0}=0$ obviously ensures $\\mathbb{E} V\\left(W_{0}\\right)<\\infty$.\n\nWe have thus shown that all conditions of Theorem 2.5 are met, from which the assertions of the present theorem follow.\n\nIn what follows, we will demonstrate that the seemingly complex and technical conditions of Lemma 2.10 and Theorem 2.14 boil down to easily verifiable and natural conditions concerning the sequence $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$ and the inter-arrival time distribution $Z_{1}$. Utilizing this framework, we establish the functional central limit theorem for the sequence of waiting times $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$.\n\nAssume that the law of $Z_{1}$ is absolutely continuous with respect to the Lebesgue measure, i.e., $\\operatorname{Law}\\left(Z_{1}\\right)(\\mathrm{d} z)=f_{Z_{1}}(z) \\mathrm{d} z$, where $f_{Z_{1}}(z)=0$ for $z \\leq 0$. For any Borel set $A \\in \\mathcal{B}\\left(\\mathbb{R}_{+}\\right)$, we can express $Q(s, w, A)$ as follows:\n\n$$\n\\begin{aligned}\nQ(s, w, A) & =\\int_{[0, \\infty)} \\mathbb{1}_{A}\\left((w+s-z)_{+}\\right) f_{Z_{1}}(z) \\mathrm{d} z \\\\\n& =\\mathbb{1}_{A}(0) \\mathbb{P}\\left(Z_{1}>w+s\\right)+\\int_{0}^{w+s} \\mathbb{1}_{A}(w+s-z) f_{Z_{1}}(z) \\mathrm{d} z \\\\\n& =\\mathbb{1}_{A}(0) \\mathbb{P}\\left(Z_{1}>w+s\\right)+\\int_{[0, \\infty)} \\mathbb{1}_{A}(z) f_{Z_{1}}(w+s-z) \\mathrm{d} z \\\\\n& =\\int_{\\mathcal{X}=\\mathbb{R}_{+}} \\mathbb{1}_{A}(z)\\left(\\mathbb{P}\\left(Z_{1}>w+s\\right) \\mathbb{1}_{\\{0\\}}(z)+f_{Z_{1}}(w+s-z) \\mathbb{1}_{(0, \\infty)}(z)\\right) \\mathrm{d} \\nu(z)\n\\end{aligned}\n$$\n\nwhere $\\nu(\\mathrm{d} z)=\\delta_{0}(\\mathrm{~d} z)+\\mathrm{d} z$.\n\nTo sum up, we obtained that there exists a Borel measure $\\nu$ on $\\mathcal{B}(\\mathcal{X})$, such that $Q(s, w, \\cdot) \\ll \\nu$ for all $(s, w) \\in \\mathcal{Y} \\times \\mathcal{X}$, where $\\mathcal{X}=\\mathbb{R}_{+}$and $\\mathcal{Y}=[0, M]$. Moreover, the transition densities are given by\n\n$$\np_{s}(z \\mid w)=\\frac{\\mathrm{d} Q(s, w, \\cdot)}{\\mathrm{d} \\nu}(z)=\\mathbb{P}\\left(Z_{1}>w+s\\right) \\mathbb{1}_{\\{0\\}}(z)+f_{Z_{1}}(w+s-z) \\mathbb{1}_{(0, \\infty)}(z)\n$$\n\nFor a fixed $n \\geq 1$, let $\\underline{w}=\\left[w_{1}, \\ldots, w_{n}\\right]$ and $\\underline{s}=\\left[s_{0}, \\ldots, s_{n-1}\\right]$, and define the likelihood function as\n\n$$\np(\\underline{w} \\mid \\underline{s})=\\prod_{k=1}^{n} p_{s_{k-1}}\\left(w_{k} \\mid w_{k-1}\\right)\n$$\n\nIf the density function $f_{Z_{1}}: \\mathbb{R} \\rightarrow[0, \\infty)$ is continuously differentiable everywhere, then at every point $\\underline{w} \\in[0, \\infty)^{n}$ where $p(\\underline{w} \\mid \\underline{s})>0$, the derivative $\\partial_{s_{i}} \\log p(\\underline{w} \\mid \\underline{s})=\\partial_{s_{i}} p_{s_{i}}\\left(w_{i+1} \\mid w_{i}\\right)$ for $i=0, \\ldots, n-1$ exists and is finite. Furthermore, we have\n\n$$\n\\frac{\\partial}{\\partial s_{i}} \\int_{\\mathcal{X}^{n}}\\left(w_{1}+\\ldots+w_{n}\\right) p(\\underline{w} \\mid \\underline{s}) \\mathrm{d} \\underline{w}=\\int_{\\mathcal{X}^{n}}\\left(w_{1}+\\ldots+w_{n}\\right) \\partial_{s_{i}} p(\\underline{w} \\mid \\underline{s}) \\mathrm{d} \\underline{w}\n$$\n\nhence the regularity conditions required for the Cram\u00e9r-Rao inequality are satisfied.\n7(lem:q:feit) ${ }^{7}$ Lemma 3.14. Assume that $f_{Z_{1}}:[0, \\infty) \\rightarrow[0, \\infty)$ is continuously differentiable everywhere, and\n\n$$\n\\int_{[0, \\infty)} \\frac{f_{Z_{1}}^{\\prime}(z)^{2}}{f_{Z_{1}}(z)} \\mathrm{d} z<\\infty\n$$\n\nThen there exists a constant $r^{*}>0$ such that for any $n \\geq 1$, and $\\Sigma_{n}=\\sum_{k=1}^{n} W_{k}$, the following inequality holds:\n\n$$\n\\operatorname{Var}\\left(\\Sigma_{n}\\right) \\geq \\frac{1}{r^{*}} \\sum_{k=0}^{n-1} \\mathbb{P}\\left(S_{k}>Z_{1}\\right)^{2}\n$$\n\nProof. Fix $n \\geq 1$ and let $\\underline{s}=\\left[s_{0}, \\ldots, s_{n-1}\\right] \\in[0, M]^{n}$. Since $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$ is a scalar-valued process, the Fisher information matrix is diagonal. Therefore, using (28), for $k=0, \\ldots, n-1$, we have\n\n$$\n\\begin{aligned}\nr\\left(I\\left(s_{k}\\right)\\right) & =[I(\\underline{s})]_{k k}=\\mathbb{E}\\left[\\left(\\partial_{s_{k}} \\log p_{s_{k}}\\left(W_{k+1} \\mid W_{k}\\right)\\right)^{2} \\mid \\underline{S}=\\underline{s}\\right] \\\\\n& =\\mathbb{E}\\left[\\int_{\\mathbb{R}} \\frac{f_{Z_{1}}\\left(W_{k}+s_{k}\\right)^{2}}{\\mathbb{P}\\left(Z_{1}>W_{k}+s_{k}\\right)} \\mathbb{1}_{\\{0\\}}(z)+\\frac{f_{Z_{1}}^{\\prime}\\left(W_{k}+s_{k}-z\\right)^{2}}{f_{Z_{1}}\\left(W_{k}+s_{k}-z\\right)} \\mathbb{1}_{(0, \\infty)}(z)\\left(\\delta_{0}(\\mathrm{~d} z)+\\mathrm{d} z\\right) \\mid \\underline{S}=\\underline{s}\\right] \\\\\n& =\\mathbb{E}\\left[\\left.\\frac{f_{Z_{1}}\\left(W_{k}+s_{k}\\right)^{2}}{\\mathbb{P}\\left(Z_{1}>W_{k}+s_{k}\\right)}+\\int_{[0, \\infty)} \\frac{f_{Z_{1}}^{\\prime}\\left(W_{k}+s_{k}-z\\right)^{2}}{f_{Z_{1}}\\left(W_{k}+s_{k}-z\\right)} \\mathrm{d} z \\right\\rvert\\, \\underline{S}=\\underline{s}\\right] \\\\\n& \\leq \\sup _{z \\in[0, \\infty)} \\frac{f_{Z_{1}}(z)^{2}}{\\mathbb{P}\\left(Z_{1}>z\\right)}+\\int_{[0, \\infty)} \\frac{f_{Z_{1}}^{\\prime}(z)^{2}}{f_{Z_{1}}(z)} \\mathrm{d} z\n\\end{aligned}\n$$\n\nBy l'H\u00f4pital's rule, we have $\\lim _{z \\rightarrow \\infty} \\frac{f_{Z_{1}}(z)^{2}}{\\mathbb{P}\\left(Z_{1}>z\\right)}=\\lim _{z \\rightarrow \\infty}-f_{Z_{1}}^{\\prime}(z)=0$, which implies that\n\n$$\n\\sup _{z \\in[0, \\infty)} \\frac{f_{Z_{1}}(z)^{2}}{\\mathbb{P}\\left(Z_{1}>z\\right)}<\\infty\n$$\n\nTherefore, there exists an upper bound for $r\\left(I\\left(s_{k}\\right)\\right)$ that is independent of both $k$ and $n$; let this bound be denoted by $r^{*}$.\n\nSince the mapping $(s, w, z) \\mapsto(s+w-z)_{+}$, defining the Lindley recursion (20), is monotonic in both $s$ and $w$, we observe that for each $1 \\leq j \\leq n$ and $0 \\leq k \\leq n-1$, the derivative $\\partial_{s_{k}} \\mathbb{E}\\left[W_{j} \\mid \\underline{S}\\right] \\geq$ 0 . Therefore,\n\n$$\n\\begin{aligned}\n\\left\\|\\partial_{s_{k}} \\mathbb{E}\\left[\\Sigma_{n} \\mid \\underline{S}\\right]\\right\\|^{2} & =\\left(\\sum_{j=1}^{n} \\partial_{s_{k}} \\mathbb{E}\\left[W_{j} \\mid \\underline{S}\\right]\\right)^{2} \\geq\\left(\\partial_{s_{k}} \\mathbb{E}\\left[W_{k+1} \\mid \\underline{S}\\right]\\right)^{2}=\\mathbb{P}\\left(W_{k}+S_{k}-Z_{k+1}>0 \\mid \\underline{S}\\right)^{2} \\\\\n& \\geq \\mathbb{P}\\left(S_{k}-Z_{1}>0 \\mid \\underline{S}\\right)^{2}\n\\end{aligned}\n$$\n\nBy Lemma 2.10 and the Cauchy-Schwartz inequality, using the bounds obtained above, we get\n\n$$\n\\begin{aligned}\n\\operatorname{Var}\\left(\\Sigma_{n}\\right) & \\geq \\sum_{k=0}^{n-1} \\mathbb{E}\\left[\\frac{1}{r\\left(I_{k}\\right)} \\| \\partial_{s_{k}} \\mathbb{E}\\left[\\Sigma_{n} \\mid \\underline{S}\\right] \\|^{2}\\right] \\\\\n& \\geq \\sum_{k=0}^{n-1} \\frac{1}{r^{s}} \\mathbb{E}\\left[\\mathbb{P}\\left(S_{k}-Z_{1}>0 \\mid \\underline{S}\\right)^{2}\\right] \\geq \\frac{1}{r^{s}} \\sum_{k=0}^{n-1} \\mathbb{P}\\left(S_{k}>Z_{1}\\right)^{2}\n\\end{aligned}\n$$\n\nwhich completes the proof.\n7(thm:queue:FOLT) ${ }^{7}$ Theorem 3.15. Beyond the conditions established in Theorem 3.13, suppose that the function $f_{Z_{1}}:[0, \\infty) \\rightarrow[0, \\infty)$ is continuously differentiable everywhere, and that\n\n$$\n\\int_{[0, \\infty)} \\frac{f_{Z_{1}}^{\\prime}(z)^{2}}{f_{Z_{1}}(z)} \\mathrm{d} z<\\infty\n$$\n\nAdditionally, assume that\n\n$$\n\\liminf _{n \\rightarrow \\infty} \\frac{1}{n} \\sum_{k=0}^{n-1} \\mathbb{P}\\left(S_{k}>Z_{1}\\right)^{2}>0\n$$\n\nand that for some exponent $\\delta>0$, the series of mixing coefficients $\\left(\\alpha^{S}(n)\\right)_{n \\in \\mathbb{N}}$ satisfies\n\n$$\n\\sum_{n \\geq 1} n^{\\delta} \\alpha^{S}(n)<\\infty\n$$\n\nLet $\\Sigma_{n}=W_{1}+\\ldots+W_{n}, v_{n}(t)=\\min \\left\\{1 \\leq k \\leq n \\mid \\operatorname{Var}\\left(\\Sigma_{k}\\right) \\geq t \\operatorname{Var}\\left(\\Sigma_{n}\\right)\\right\\}$, and for $1 \\leq k \\leq n$, define\n\n$$\n\\xi_{k, n}=\\frac{W_{k}-\\mathbb{E}\\left[W_{k}\\right]}{\\operatorname{Var}\\left(\\Sigma_{n}\\right)^{1 / 2}}\n$$\n\nThen the sequence of functions $B_{n}(t)=\\sum_{k=1}^{v_{n}(t)} \\xi_{k, n}$, for $t \\in(0,1]$ and $n \\geq 1$, converges in distribution in $D([0,1])$ (equipped with the uniform topology) to a standard Brownian motion $B$.\n\nProof. In the proof of Theorem 3.13, we showed that under these conditions, the sequence $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ forms a Markov chain in a random environment, which satisfies the conditions of Theorem 2.5. Additionally, Lemma 3.14, in conjunction with the condition (31), guarantees that\n\n$$\n\\liminf _{n \\rightarrow \\infty} \\frac{1}{n} \\sum_{k=0}^{n-1} \\mathbb{E}\\left[\\frac{1}{r\\left(I_{k}\\right)} \\| \\partial_{s_{k}} \\mathbb{E}\\left[S_{n} \\mid \\underline{S}\\right] \\|^{2}\\right]>0\n$$\n\nWith the Lyapunov function $V(w)=e^{t w-1}$, the inequality (11) that appears in the conditions of Theorem 2.5 holds for $\\Phi=\\mathrm{id}_{\\mathbb{R}^{+}}$and any $p>1$. Consequently, the sequence $\\left(\\alpha^{S}(n)\\right)_{n \\in \\mathbb{N}}$ satisfies the condition regarding the mixing coefficients in Theorem 2.14.\n\nOverall, we conclude that the conditions of Theorem 2.14 are met, which leads to the desired result.\n\nThe conditions in Assumptions 3.7 and 3.8 can most likely be significantly weakened. We conjecture that the boundedness condition on the service times $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$ and the assumption on the tail probabilities of $Z_{1}$ are of a purely technical nature and may be removed in future work. Theorem 1.8 in [34], for instance, addresses the case when both $S$ and $Z$ are unbounded, $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$ is i.i.d., and so is $\\left(Z_{n}\\right)_{n \\geq 1}$. In that setting, the main challenge is that the condition on the minorization coefficient in part B) of Assumption 2.2 is no longer satisfied. However, the results of our paper [35] can still be applied under appropriate assumptions on the environment. One such condition, as formulated in Theorem 1.8 of [34], is that $Z_{1}$ has a Gumbel-like tail:\n\n$$\n\\mathbb{P}\\left(Z_{1} \\geq z\\right) \\leq C_{1} \\exp \\left(-C_{2} e^{C_{3} z}\\right), \\quad \\text { for some } C_{1}, C_{2}, C_{3}>0\n$$\n\nAnswering such questions, as well as investigating the case when the service times $\\left(S_{n}\\right)_{n \\in \\mathbb{N}}$ are i.i.d. and the inter-arrival times $\\left(Z_{n}\\right)_{n \\geq 1}$ are weakly dependent, will be the subject of our future research.", "tables": {}, "images": {"img-0.jpeg": "data:image/jpeg;base64,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"}}, {"section_id": 5, "text": "# Acknowledgment \n\nI extend my sincere gratitude to Mikl\u00f3s R\u00e1sonyi for his invaluable assistance and insightful discussions on the subject matter, which greatly contributed to the development of this paper. I would also like to thank the two anonymous reviewers for their careful reading and constructive comments, which significantly improved the quality of the manuscript.", "tables": {}, "images": {}}, {"section_id": 6, "text": "## Declaration of generative AI and AI-assisted technologies in the writing process\n\nThe author(s) would like to declare that during the preparation of this work, ChatGPT 3.5 was utilized to enhance the language and readability of the paper. As a non-native English speaker, the author(s) sought to improve the quality of the English language presentation. It is important to emphasize that the ideas and content of this article represent the author's original intellectual contributions. After utilizing this tool, the author(s) thoroughly reviewed and edited the content as necessary and take(s) full responsibility for the final publication.", "tables": {}, "images": {}}, {"section_id": 7, "text": "## References\n\nPARX_AGOSTO2016640 [1] A. Agosto, G. Cavaliere, D. Kristensen, and A. Rahbek, Modeling corporate defaults: Poisson autoregressions with exogenous covariates (PARX), Journal of Empirical Finance, 38 (2016), pp. 640-663. Recent developments in financial econometrics and empirical finance.\nBercherCramer [2] J. F. Bercher, On generalized Cram\u00e9r-Rao inequalities, and an extension of the Shannon-Fisher-Gauss setting, New Perspectives on Stochastic Modeling and Data Analysis, (2014), pp. 19-35.\nBorovkovCramer [3] A. A. Borovkov, Mathematical Statistics, CRC Press, 1999.\nbborovkov72 [4] A. A. Borovkov, Stochastic Processes in Queuing Theory, Nauka, 1972. In Russian.\nborovkov [5] A. A. Borovkov, Ergodicity and Stability of Stochastic Processes, John Wiley \\& Sons, 1998.\nlov1993stochastically [6] A. A. Borovkov and S. G. Foss, Stochastically recursive sequences and their generalizations, Limit theorems for random processes and their applications (Russian), 20 (1993), pp. 32-103.\nlargescaleML2018 [7] L. Bottou, F. E. Curtis, and J. Nocedal, Optimization methods for large-scale machine learning, SIAM Review, 60 (2018), pp. 223-311.\nBradley2005 [8] R. C. Bradley, Basic properties of strong mixing conditions. a survey and some open questions, Probability Surveys, 2 (2005), pp. 107-144.\nBRADLEY19811 [9] R. C. Bradley, Central limit theorems under weak dependence, Journal of Multivariate Analysis, 11 (1981), pp. 1-16.\nBryc1996LDP [10] W. Bryc and A. Dembo, Large deviations and strong mixing, Annales de l'IHP Probabilit\u00e9s et statistiques, 32(4) 1996, pp. 549-569.\ncogburn1984ergodic [11] R. Cogburn, The ergodic theory of Markov chains in random environments, Zeitschrift f\u00fc Wahrscheinlichkeitstheorie und verwandte Gebiete, 66 (1984), pp. 109-128.\ncogburn1990direct [12] , On direct convergence and periodicity for transition probabilities of Markov chains in random environments, The Annals of Probability, (1990), pp. 642-654.\ndebaly_truquet_2021 [13] Z. M. Debaly and L. Truquet, Iterations of dependent random maps and exogeneity in nonlinear dynamics, Econometric Theory, 37 (2021), pp. 1135-1172.\nDiFr99 [14] P. Diaconis and D. Freedman, Iterated random functions, SIAM Review, (1999), pp. 4576 .\n\n[15] P. Doukhan, Mixing. In: Mixing. Lecture Notes in Statistics, Springer, New York, NY, vol $85,1994$.\n[16] M. EkSTR\u00d6M, A general central limit theorem for strong mixing sequences, Statistics \\& Probability Letters, 94 (2014), pp. 236-238.\n[17] A. K. Erlang, The theory of probabilities and telephone conversations, Nyt Tidsskrift for Matematik B, 20 (1909), pp. 33-39.\n[18] T. Espinasse and P. Rochet, Cram\u00e9r-Rao inequality for non-differentiable models, Comptes Rendus Mathematique, 350 (2012), 711-715.\n[19] D. Felsmann, Stability of general state space Markov chains, Master's thesis, E\u00f6tv\u00f6s Lor\u00e1nd University, 2022. (in Hungarian).\n[20] S. Foss and T. Konstantopoulos, Extended renovation theory and limit theorems for stochastic ordered graphs, Markov Process. Related Fields, 9 (2003), pp. 413-468.\n[21] B. GERENCS\u00c9R AND M. R\u00c1SONYI, Invariant measures for multidimensional fractional stochastic volatility models, Stochastics and Partial Differential Equations: Analysis and Computations, (2022), pp. 1-33.\n[22] B. Gerencs\u00c9r and M. R\u00c1sonyi, On the ergodicity of certain Markov chains in random environments, Journal of Theoretical Probability, (2023), pp. 1-33.\n[23] P. Gorgi and S. J. Koopman, Beta observation-driven models with exogenous regressors: a joint analysis of realized correlation and leverage effects, Tinbergen Institute Discussion Papers 20-004/III, Tinbergen Institute, Jan. 2020.\n[24] L. Gy\u00f6rfi, A. Lovas, and M. R\u00c1sonyi, On the strong stability of ergodic iterations, arXiv preprint, (2023), p. 2304.04657.\n[25] L. Gy\u00f6rfi and G. Morvai, Queueing for ergodic arrivals and services, in Limit theorems in probability and statistics, I. Berkes, et al., ed., vol. 2, 2002, pp. 127-141. Fourth Hungarian colloquium on limit theorems in probability and statistics, Balatonlelle, Hungary, 1999.\n[26] Y. Hafouta, On the functional CLT for slowly mixing triangular arrays, arXiv preprint arXiv:2111.05807, (2021).\n[27] P. Hall and C. C. Heyde, Martingale limit theory and its application, Academic press, 2014.\n[28] B. HANSEN, A weak law of large numbers under weak mixing, https://users.ssc.wisc.edu/-bhansen/papers/wlln.pdf (2019).\n[29] N. Herrndorf, A Functional Central Limit Theorem for Weakly Dependent Sequences of Random Variables, The Annals of Probability, 12 (1984), pp. 141 - 153.\n[30] M. IosifesCU, Iterated function sytems. a critical survey, Mathematical Reports, (2009), pp. 181-229.\n[31] Y. KIfer, Perron-Frobenius theorem, large deviations, and random perturbations in random environments, Math. Zeitschrift, 222 (1996), pp. 677-698.\n[32] Y. KIfer, Limit theorems for random transformations and processes in random environments, Transactions of the American Mathematical Society, 350 (1998), pp. 1481-1518.\n[33] T. LindVALL, Lectures on the coupling method, Courier Corporation, 2002.\n[34] A. LovAS AND M. R\u00c1SONYI, Ergodic theorems for queuing systems with dependent interarrival times, Operations Research Letters, 49 (2021), pp. 682-687.\n\nlovas [35] A. Lovas and M. R\u00c1sonyi, Markov chains in random environment with applications in queuing theory and machine learning, Stochastic Processes and their Applications, 137 (2021), pp. 294-326.\nlovasCLT [36] A. Lovas and M. R\u00c1sonyi, Functional central limit theorem and strong law of large numbers for stochastic gradient Langevin dynamics, Appl Math Optim, (2023)), p. 78.\nloynes1962 [37] R. M. LoYnES, The stability of a queue with non-independent inter-arrival and service times, Mathematical Proceedings of the Cambridge Philosophical Society, 58 (1962), pp. 497-520.\nMcLeish [38] D. L. McLeish, A maximal inequality and dependent strong laws, The Annals of probability, (1975), 3(5), pp. 829-839.\nevede2020functional [39] F. Merlevede and M. Peligrad, Functional clt for nonstationary strongly mixing processes, Statistics \\& Probability Letters, 156 (2020), p. 108581.\nde2011concentration [40] F. MerleV\u00c8de and M. Peligrad, and E. Rio, A Bernstein type inequality and moderate deviations for weakly dependent sequences, Probab. Theory Relat. Fields 151 (2011), pp. 435474 .\nevede2019functional [41] F. MerleV\u00c8de, M. Peligrad, and S. Utev, Functional clt for martingale-like nonstationary dependent structures, Bernoulli, 25 (2019), pp. 3203-3233.\nat [42] S. P. Meyn and R. L. Tweedie, Markov chains and stochastic stability, Springer-Verlag, 1993.\n\nNguyen2017 [43] D. S. Nguyen, Application of queuing theory in service design, in 2017 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM), 2017, pp. 837840 .\norey1991markov [44] S. Orey, Markov chains with stochastically stationary transition probabilities, The Annals of Probability, 19 (1991), pp. 907-928.\nrio1995LL [45] E. Rio, The functional law of the iterated logarithm for stationary strongly mixing sequences, The Annals of Probability, 23(3) (1995), pp. 1188-1203\nsenblatt1956central [46] M. Rosenblatt, A central limit theorem and a strong mixing condition, Proceedings of the national Academy of Sciences, 42 (1956), pp. 43-47.\noppalainen1994large [47] T. Seppalainen, Large deviations for Markov chains with random transitions, The Annals of Probability, 22 (1994), pp. 713-748.\nstenflo [48] O. Stenflo, Markov chains in random environments and random iterated function systems, Trans. American Math. Soc., 353 (2001), pp. 3547-3562.\nTruquet1 [49] L. Truquet, Ergodic properties of some Markov chains models in random environments, 2021.\n\nTROQUET2023294 [50] L. Truquet, Strong mixing properties of discrete-valued time series with exogenous covariates, Stochastic Processes and their Applications, 160 (2023), pp. 294-317.\nWelsch1972 [51] . R. E. Welsch, Limit laws for extreme order statistics from strong-mixing processes, The Annals of Mathematical Statistics, 43(2) (1972), pp. 439-446.\nwhite2000 [52] H. White, Asymptotic Theory for Econometricians, Emerald Group Publishing Limited, 2000 .", "tables": {}, "images": {}}, {"section_id": 8, "text": "# A Brief survey of key results on $\\alpha$-mixing sequences \n\n\u3008sec:mixing_survey\u3009 In this section, we present a selection of theorems from the literature on $\\alpha$-mixing sequences. These results encompass fundamental topics such as the law of large numbers, and the central limit theorem. However, we do not address all relevant topics-for instance, the distribution of extreme values in $\\alpha$-mixing sequences or concentration inequalities. For a detailed treatment of these subjects, we refer the interested reader to [51] and [40].\n\nBy integrating the theorems presented here with the transition of mixing results from Sections 1 and 2, we establish a robust theoretical framework. This framework enables the statistical analysis of non-linear autoregressive processes with exogenous covariates and Markov chains in random environments. Given the vast literature on $\\alpha$-mixing processes, a comprehensive review is beyond the scope of this paper. Instead, we focus on key results that are particularly useful for the statistical analysis of weakly dependent sequences. For readers seeking a more in-depth overview, we recommend Doukhan [15], which, with its detailed references and literature survey, provides an excellent starting point.\n\nIn theorems concerning $\\alpha$-mixing sequences, the key condition is typically about how rapidly the mixing coefficient sequence $\\left(\\alpha^{W}(n)\\right)_{n \\in \\mathbb{N}}$ decays to zero. In the econometric literature, the term size is frequently used to characterize this behavior (cf. Definition 3.45 in [52]). However, since the definition is not uniform, despite its ability to make theorems more concise and elegant, we avoid using size to prevent misunderstandings.\n\nIn the context of stationary processes, it is well-known that strong mixing implies ergodicity ensuring the applicability of the strong law of large numbers. For non-stationary, heterogeneously distributed $\\alpha$-mixing sequences, McLeish [38] established the following version of the strong law of large numbers.\n7(thm:McLeish) ${ }^{7}$ Theorem A. 1 (McLeish, 1975). Consider a sequence of $\\mathbb{R}$-valued random variables $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ with $\\mathbb{E} W_{n}=0, n \\in \\mathbb{N}$ and with $\\alpha$-mixing coefficients satisfying $\\alpha^{W}(n) \\leq c n^{-\\frac{1}{r-2}}, n \\in \\mathbb{N}$, for $c>0$ and $r>2$. Suppose that for some $p$ such that $r / 2<p \\leq r<\\infty$,\n\n$$\n\\sum_{n=1}^{\\infty} \\frac{\\mathbb{E}^{2 / r}\\left|W_{n}\\right|^{p}}{n^{2 p / r}}<\\infty\n$$\n\nUnder these conditions,\n\n$$\n\\frac{1}{n} \\sum_{k=1}^{n} W_{n} \\xrightarrow{\\text { a.s. }} 0, \\quad n \\rightarrow \\infty\n$$\n\n7 (rem:McLeish) ${ }^{7}$ Remark A.2. The condition related to the decay of the moments in Theorem A.1\n\n$$\n\\sum_{n=1}^{\\infty} \\frac{\\mathbb{E}^{2 / r}\\left|W_{n}\\right|^{p}}{n^{2 p / r}}<\\infty\n$$\n\nis automatically satisfied if $\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left|W_{n}\\right|^{p}<\\infty$.\nIn the context of ergodic theory, we distinguish between ergodic, weakly mixing, and strongly mixing processes. We classify a collection of random variables of the form $\\left\\{\\xi_{n, i} \\mid 1 \\leq i \\leq n\\right\\}$ as weakly mixing if\n\n$$\n\\frac{1}{n} \\sum_{k=1}^{n} \\alpha^{\\xi_{n, i}}(k) \\rightarrow 0, \\quad n \\rightarrow \\infty\n$$\n\nwhere $\\alpha^{\\xi_{n, i}}(\\cdot)$ denotes the $\\alpha$-mixing coefficient corresponding to the $n$th row of the array.\nHansen established the weak law of large numbers, more precisely $L^{1}$-law of large numbers, for heterogenous weak mixing processes and arrays [28]. A notable and valuable characteristic of this result is the absence of a stationarity assumption, thereby broadening the applicability of the result. The elegance of Hansen's proof lies in its simplicity, leveraging the standard representation of the variance of the truncated mean as the weighted Ces\u00e0ro sum of covariances, and bounds the latter using the mixing inequality for bounded random variables.\n\nAs noted by Hansen [28], strong mixing implies weak mixing, and weak mixing, in turn, implies ergodicity, moreover this nesting is strict. However, for any process $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$, the sequence\n\nof mixing coefficients $\\left(\\alpha^{W}(n)\\right)_{n \\in \\mathbb{N}}$ is monotonically decreasing. Consequently, their Ces\u00e0ro sum converges to zero if and only if $\\alpha^{W}(n) \\rightarrow 0$ as $n \\rightarrow \\infty$. As a result, the classes of weakly mixing and strongly mixing random sequences coincide. Thus, for weakly dependent sequences, Hansen's theorem can be stated as follows:\n7(thm:Hansen) ${ }^{7}$ Theorem A. 3 (Hansen, 2019). Consider a strongly mixing $\\mathbb{R}$-valued process $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$, and define the sequence of partial sums $S_{n}:=\\sum_{k=1}^{n} W_{k}, n \\geq 1$. Additionally, suppose that the condition\n\n$$\n\\lim _{B \\rightarrow \\infty} \\sup _{n \\geq 1} \\frac{1}{n} \\sum_{k=1}^{n} \\mathbb{E}\\left(\\left|W_{k}\\right| \\mathbb{1}\\left(\\left|W_{k}\\right| \\geq B\\right)\\right)=0\n$$\n\nholds. Then, we have\n\n$$\n\\frac{S_{n}}{n}-\\frac{\\mathbb{E}\\left(S_{n}\\right)}{n} L_{1}^{1} 0, n \\rightarrow \\infty\n$$\n\nProof. Hansen stated and proved this theorem, in a bit more general setting, for triangular arrays of weakly mixing variables (See Theorem 1 on page 4 in [28]). For making the explanation selfcontained, we present the proof of this simpler version here.\n\nWithout the loss of generality we can assume that $\\mathbb{E}\\left(W_{n}\\right)=0, n \\in \\mathbb{N}$. Let $\\varepsilon>0$ be arbitrary and choose $B>0$ such that\n\n$$\n\\sup _{n} \\frac{1}{n} \\sum_{k=1}^{n} \\mathbb{E}\\left(\\left|W_{k}\\right| \\mathbb{1}\\left(\\left|W_{k}\\right|>B\\right)\\right)<\\varepsilon\n$$\n\nLet us introduce\n\n$$\n\\begin{aligned}\n& W_{n}^{\\prime}=W_{n} \\mathbb{1}\\left(\\left|W_{k}\\right| \\leq B\\right)-\\mathbb{E}\\left(W_{n} \\mathbb{1}\\left(\\left|W_{k}\\right| \\leq B\\right)\\right) \\\\\n& W_{n}^{\\prime \\prime}=W_{n} \\mathbb{1}\\left(\\left|W_{k}\\right|>B\\right)-\\mathbb{E}\\left(W_{n} \\mathbb{1}\\left(\\left|W_{k}\\right|>B\\right)\\right)\n\\end{aligned}\n$$\n\nObviously, $W_{n}=W_{n}^{\\prime}+W_{n}^{\\prime \\prime}, n \\in \\mathbb{N}$ hence by the triangle inequality and (33), we have\n\n$$\n\\frac{1}{n} \\mathbb{E}\\left|\\sum_{k=1}^{n} W_{k}\\right| \\leq \\frac{1}{n} \\mathbb{E}\\left|\\sum_{k=1}^{n} W_{k}^{\\prime}\\right|+\\frac{2}{n} \\sum_{k=1}^{n} \\mathbb{E}\\left(\\left|W_{k}\\right| \\mathbb{1}\\left(\\left|W_{k}\\right|>B\\right)\\right)<\\frac{1}{n} \\mathbb{E}\\left|\\sum_{k=1}^{n} W_{k}^{\\prime}\\right|+2 \\varepsilon\n$$\n\nFurthermore, $W_{n}^{\\prime}$ satisfies the bound $\\left|W_{n}^{\\prime}\\right| \\leq 2 B$, and for its mixing coefficient $\\alpha^{W^{\\prime}}(n) \\leq \\alpha^{W}(n)$, $n \\in \\mathbb{N}$ holds, consequently by the mixing inequality for bounded variables (cf. Theorem A. 5 in [27] or the proof of Lemma A.1. in [36]),\n\n$$\n\\left|\\mathbb{E}\\left(W_{k}^{\\prime} W_{l}^{\\prime}\\right)\\right|=\\left|\\operatorname{Cov}\\left(W_{k}^{\\prime}, W_{l}^{\\prime}\\right)\\right| \\leq 16 B^{2} \\alpha^{W}(|k-l|)\n$$\n\nBy Jensen's inequality, we can estimate\n\n$$\n\\mathbb{E}^{2}\\left|\\sum_{k=1}^{n} W_{k}^{\\prime}\\right| \\leq \\sum_{k, l=1}^{n} \\mathbb{E}\\left(W_{k}^{\\prime} W_{l}^{\\prime}\\right) \\leq 16 B^{2} \\sum_{k, l=1}^{n} \\alpha^{W}(|k-l|)=16 B^{2} n\\left(\\alpha^{W}(0)+2 \\sum_{k=1}^{n} \\alpha^{W}(k)\\right)\n$$\n\nSubstituting this into (34) yields\n\n$$\n\\frac{1}{n} \\mathbb{E}\\left|\\sum_{k=1}^{n} W_{k}\\right|<4 B\\left(\\frac{\\alpha^{W}(0)}{n}+\\frac{2}{n} \\sum_{k=1}^{n} \\alpha^{W}(k)\\right)^{1 / 2}+2 \\varepsilon\n$$\n\nwhere the upper bound tends to $2 \\varepsilon$ as $n \\rightarrow \\infty$ since $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ is strongly mixing, and thus $\\lim \\sup _{n \\rightarrow \\infty} \\frac{1}{n} \\mathbb{E}\\left|\\sum_{k=1}^{n} W_{k}\\right|<2 \\varepsilon$ holds for arbitrary $\\varepsilon>0$ which completes the proof.\n7(rem:Hansen) ${ }^{7}$ Remark A.4. The average uniform integrability condition (32) is automatically satisfied if the process $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ has a uniformly bounded moment $\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left(\\left|W_{n}\\right|^{r}\\right)<\\infty$ for some $r>1$.\n\nOur objective is to establish the (functional) central limit theorem for certain functionals of the sequence of iterates $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ when $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$ is merely $\\alpha$-mixing and stationarity is not assumed. While we studied this problem in the context of stochastic gradient Langevin dynamics [36], our focus was limited to stationary data streams. Our approach relied significantly on Corollary 2 in [29], which offers broad applicability, extending even to non-stationary processes. However, the condition $\\lim _{n \\rightarrow \\infty} n^{-1} \\mathbb{E}\\left(S_{n}^{2}\\right)=\\sigma^{2}$ required by this corollary is not generally met in cases when the exogenous regressor $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$ is non-stationary.\n\nVery recently there was major progress on the functional CLT for non-stationary mixing sequences. In [41] Merlev\u00e9de, Peligrad and Utev answered the question raised by Ibragimov concerning the CLT for triangular arrays of non-stationary weakly dependent variables under the Lindeberg condition (cf. page 1 in [26]). Subsequently, Merlev\u00e9de and Peligrad proved the functional CLT for triangular arrays satisfying a dependence condition weaker than the standard strong mixing condition, termed the weak strong mixing condition [39]. Both of these results require the condition:\n\n$$\n\\sum_{k=1}^{n} \\operatorname{Var}\\left(W_{k}\\right)=O\\left(\\operatorname{Var}\\left(S_{n}\\right)\\right)\n$$\n\nwhich is difficult to verify in general. A key contribution of our paper is the derivation of a Cram\u00e9r-Rao lower bound for the variance of partial sums in (35), facilitating a functional CLT when $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ forms a Markov chain in a random environment (See Section 2).\n\nEssentially, aside from certain moment conditions, Theorem 1 in Ekstr\u00f6m's paper [16] mandates only the verification that the $\\alpha$-mixing coefficients exhibit a sufficiently rapid decrease:\n7(thm:Ekstrom) ${ }^{7}$ Theorem A. 5 (Ekstr\u00f6m, 2014). Let $\\left\\{\\xi_{n, i} \\mid 1 \\leq i \\leq d_{n}, n \\in \\mathbb{N}\\right\\}$ be an array of $\\mathbb{R}$-valued random variables with $\\mathbb{E} \\xi_{n, i}=0,1 \\leq i \\leq d_{n}, n \\in \\mathbb{N}$, and define $S_{n}=\\sum_{k=1}^{d_{n}} \\xi_{n, k}, n \\in \\mathbb{N}$. Assume that for some $r>0$,\ni. $\\sup _{n \\in \\mathbb{N}} \\max _{1 \\leq i \\leq d_{n}} \\mathbb{E}\\left|\\xi_{n, i}\\right|^{2+r}<\\infty$, and\nii. $\\sup _{n \\in \\mathbb{N}} \\sum_{k=0}^{\\infty}(k+1)^{2}\\left(\\alpha^{\\xi_{n, \\cdot}}(k)\\right)^{\\frac{r}{2+r}}<\\infty$,\nwhere $\\alpha^{\\xi_{n,}} \\cdot(\\cdot)$ denotes the strong mixing coefficient corresponding to the nth row in the array.\nThen the distributions $\\operatorname{Law}\\left(d_{n}^{-1 / 2} S_{n}\\right)$ and $\\mathcal{N}\\left(0, \\operatorname{Var}\\left(d_{n}^{-1 / 2} S_{n}\\right)\\right)$ are weakly approaching, that is for any bounded continuous function $g: \\mathbb{R} \\rightarrow \\mathbb{R}$,\n\n$$\n\\mathbb{E}\\left[g\\left(d_{n}^{-1 / 2} S_{n}\\right)\\right]-\\int_{\\mathbb{R}} g\\left(\\operatorname{Var}\\left(d_{n}^{-1 / 2} S_{n}\\right)^{1 / 2} t\\right) \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{t^{2}}{2}} \\mathrm{~d} t \\rightarrow 0 \\text { as } n \\rightarrow \\infty\n$$\n\nProof. For the proof, we refer the reader to [16].\n7(cor:ekstrom) ${ }^{7}$ Corollary A.6. Let $\\left(W_{n}\\right)_{n \\in \\mathbb{N}}$ be a sequence of $\\mathbb{R}$-valued zero mean random variables. Suppose there exists $r>0$ such that $\\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left|W_{n}\\right|^{2+r}<\\infty$ and $\\sum_{k=0}^{\\infty}(k+1)^{2}\\left(\\alpha^{W}(k)\\right)^{\\frac{r}{2+r}}<\\infty$ holds. Under these conditions, the distributions of $n^{-1 / 2} S_{n}$ and $\\mathcal{N}\\left(0, \\operatorname{Var}\\left(n^{-1 / 2} S_{n}\\right)\\right)$ are weakly approaching.\n\nMoreover, if the sequence $\\left(n / \\sigma_{n}^{2}\\right)_{n \\geq 1}$ is bounded, where $\\sigma_{n}^{2}=\\mathbb{E} S_{n}^{2}, n \\in \\mathbb{N}$, then $\\operatorname{Law}\\left(S_{n} / \\sigma_{n}\\right)$ converges weakly to the standard normal distribution.\nProof. The first part of the statement is immediately follows from Theorem A. 5 with $\\xi_{n, i}=\\frac{\\sqrt{n}}{\\sigma_{n}} W_{i}$, $1 \\leq i \\leq d_{n}=n, n \\geq 1$, since $\\xi_{n, \\cdot}$ and $W$ have the same $\\alpha$-mixing coefficient for every $n$.\n\nAs for the second part, let $\\xi_{n, i}=\\frac{\\sqrt{n}}{\\sigma_{n}} W_{i}, 1 \\leq i \\leq n, n \\geq 1$. Easily seen that $\\max _{1 \\leq i \\leq n} \\mathbb{E}\\left|\\xi_{n, i}\\right|^{2+r} \\leq$ $\\left(n / \\sigma_{n}^{2}\\right)^{1+r / 2} \\mathbb{E}\\left|W_{i}\\right|^{2+r}$ hence by Theorem A.5, for any bounded continuous function $g: \\mathbb{R} \\rightarrow \\mathbb{R}$,\n\n$$\n\\mathbb{E}\\left[g\\left(n^{-1 / 2} \\sum_{k=1}^{n} \\xi_{n, k}\\right)\\right]-\\int_{\\mathbb{R}} g(t) \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{t^{2}}{2}} \\mathrm{~d} t \\rightarrow 0, \\text { as } n \\rightarrow \\infty\n$$\n\nwhich completes the proof.\nThe next important remark in its original form can be found in Ekstr\u00f6m's paper (c.f. Remark 1 on page 1 in [16]).\n(rem:ekstromremark) ${ }^{7}$ Remark A.7. Assume that for $r>2, \\sup _{n \\in \\mathbb{N}} \\mathbb{E}\\left|W_{n}\\right|^{r}<\\infty$ and $\\sum_{k=0}^{\\infty}\\left(\\alpha^{W}(k)\\right)^{1-\\frac{2}{r}}<\\infty$. Then the variance of $n^{-1 / 2} S_{n}$ is bounded.", "tables": {}, "images": {}}, {"section_id": 9, "text": "# B Counterexample to long-term contractivity condition \n\n? (ap:Felsmann)? In this point we present an example for a stationary stochastic process $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$ and a function $\\gamma: \\mathcal{Y} \\rightarrow(0, \\infty)$, outlined in Bal\u00e1zs Felsmann's Master's thesis, where $\\mathbb{E}\\left(\\gamma\\left(Y_{0}\\right)\\right)<1$, and despite the favorable mixing properties of $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$, the long-term contractivity condition (9) fails to hold.\n\nLet $\\left(Z_{n}\\right)_{n \\in \\mathbb{Z}}$ be a sequence of i.i.d. Bernoulli variables with $\\mathbb{P}\\left(Z_{0}=0\\right)=\\mathbb{P}\\left(Z_{0}=1\\right)=1 / 2$, and define the process\n\n$$\nY_{n}=Z_{n}+Z_{n-1}, n \\in \\mathbb{Z}\n$$\n\nwhich takes its values in $\\mathcal{Y}=\\{0,1,2\\}$. Clearly, $\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$ is a stationary process such that $Y_{n}$ and $Y_{m}$ are independent for $|m-n|>1$ hence $\\alpha^{Y}(n)=0$ for $n \\geq 2$. We consider a function $\\gamma: \\mathcal{Y} \\rightarrow(0,1)$, where $\\gamma(i)=\\gamma_{i}, i=0,1,2$ will be specified later. Let us introduce the following sequences.\n\n$$\na_{n}=\\mathbb{E}\\left(\\prod_{k=1}^{n} \\gamma\\left(Y_{k}\\right)\\right), b_{n}=\\mathbb{E}\\left(\\mathbb{1}_{\\left\\{Z_{n}=0\\right\\}} \\prod_{k=1}^{n} \\gamma\\left(Y_{k}\\right)\\right), c_{n}=\\mathbb{E}\\left(\\mathbb{1}_{\\left\\{Z_{n}=1\\right\\}} \\prod_{k=1}^{n} \\gamma\\left(Y_{k}\\right)\\right), n \\in \\mathbb{N}\n$$\n\nClearly, we have $a_{n}=b_{n}+c_{n}, n \\in \\mathbb{N}$, moreover we can write\n\n$$\n\\begin{aligned}\nb_{n+1} & =\\mathbb{E}\\left(\\mathbb{1}_{\\left\\{Z_{n+1}=0\\right\\}} \\mathbb{1}_{\\left\\{Z_{n}=0\\right\\}} \\prod_{k=1}^{n+1} \\gamma\\left(Y_{k}\\right)\\right)+\\mathbb{E}\\left(\\mathbb{1}_{\\left\\{Z_{n+1}=0\\right\\}} \\mathbb{1}_{\\left\\{Z_{n}=1\\right\\}} \\prod_{k=1}^{n+1} \\gamma\\left(Y_{k}\\right)\\right) \\\\\n& =\\frac{1}{2}\\left(\\gamma_{0} b_{n}+\\gamma_{1} c_{n}\\right)\n\\end{aligned}\n$$\n\nand similarly\n\n$$\n\\begin{aligned}\nc_{n+1} & =\\mathbb{E}\\left(\\mathbb{1}_{\\left\\{Z_{n+1}=1\\right\\}} \\mathbb{1}_{\\left\\{Z_{n}=0\\right\\}} \\prod_{k=1}^{n+1} \\gamma\\left(Y_{k}\\right)\\right)+\\mathbb{E}\\left(\\mathbb{1}_{\\left\\{Z_{n+1}=1\\right\\}} \\mathbb{1}_{\\left\\{Z_{n}=1\\right\\}} \\prod_{k=1}^{n+1} \\gamma\\left(Y_{k}\\right)\\right) \\\\\n& =\\frac{1}{2}\\left(\\gamma_{1} b_{n}+\\gamma_{2} c_{n}\\right)\n\\end{aligned}\n$$\n\nhence the linear recursion\n\n$$\n\\left[\\begin{array}{c}\nb_{n+1} \\\\\nc_{n+1}\n\\end{array}\\right]=\\frac{1}{2} \\Gamma\\left[\\begin{array}{c}\nb_{n} \\\\\nc_{n}\n\\end{array}\\right]\n$$\n\nholds, where $\\Gamma=\\left[\\begin{array}{ll}\\gamma_{0} & \\gamma_{1} \\\\ \\gamma_{1} & \\gamma_{2}\\end{array}\\right]$, and $b_{0}=c_{0}=1 / 2$. Thus for $\\left(a_{n}\\right)_{n \\in \\mathbb{N}}$, we have\n\n$$\na_{n}=\\frac{1}{2^{n+1}}[1,1] \\Gamma^{n}\\left[\\begin{array}{l}\n1 \\\\\n1\n\\end{array}\\right]\n$$\n\nBy setting $\\gamma_{0}=3, \\gamma_{1}=\\gamma_{2}=0$, we obtain $a_{0}=1$ and $a_{n}=\\frac{1}{2}(3 / 2)^{n}$, for $n \\geq 1$, thus $a_{n} \\rightarrow \\infty$, as $n \\rightarrow \\infty$. For $\\varepsilon \\in(0,1 / 4)$, let us define $\\gamma_{\\varepsilon}: \\mathcal{Y} \\rightarrow(0, \\infty), \\gamma_{\\varepsilon}(y)=\\gamma(y)+\\varepsilon, y=0,1,2$. So, we have $\\mathbb{E}\\left(\\gamma_{\\varepsilon}\\left(Y_{0}\\right)\\right)=3 / 4+\\varepsilon<1$, on the other hand\n\n$$\n\\mathbb{E}^{1 / n}\\left(\\prod_{k=1}^{n} \\gamma_{\\varepsilon}\\left(Y_{k}\\right)\\right) \\geq \\mathbb{E}^{1 / n}\\left(\\prod_{k=1}^{n} \\gamma\\left(Y_{k}\\right)\\right)=\\frac{3}{2} 2^{-1 / n}, n \\geq 1\n$$\n\nand thus\n\n$$\n\\liminf _{n \\rightarrow \\infty} \\mathbb{E}^{1 / n}\\left(\\prod_{k=1}^{n} \\gamma_{\\varepsilon}\\left(Y_{k}\\right)\\right) \\geq \\frac{3}{2}\n$$\n\nwhich means that the long-term contractivity condition fails to hold in this situation.", "tables": {}, "images": {}}, {"section_id": 10, "text": "## C Coupling condition for MCREs\n\nCouplingCondition)? In this section, our primary objective is to establish an upper bound for the non-coupling probabilities as in Definition 1.1. Our approach refines the proof of Lemma 3.10 in [36]. To achieve this, we introduce the following lemma, which is identical to Lemma 7.4 in [35]. It describes the consequences of the drift condition satisfied by $Q\\left(y_{k-1}\\right) \\ldots Q\\left(y_{l}\\right)$, where $\\mathbf{y} \\in \\mathcal{Y}^{\\mathbb{N}}$ and $k, l \\in \\mathbb{N}, l<k$ are arbitrary and fixed.\n\n7(1em:1ta) ${ }^{7}$ Lemma C.1. For $x \\in \\mathcal{X}, \\mathbf{y} \\in \\mathcal{Y}^{\\mathbb{N}}$ and $k, l \\in \\mathbb{N}, l<k$, we have\n\n$$\n\\left[Q\\left(y_{k-1}\\right) \\ldots Q\\left(y_{l}\\right) V\\right](x) \\leq V(x) \\prod_{r=l}^{k-1} \\gamma\\left(y_{r}\\right)+\\sum_{r=l}^{k-1} K\\left(y_{r}\\right) \\prod_{j=r+1}^{k-1} \\gamma\\left(y_{j}\\right)\n$$\n\nProof. We proceed by induction. Let $x \\in \\mathcal{X}$ and $l \\in \\mathbb{N}$ be arbitrary but fixed. For the base case $k=l+1$, we have\n\n$$\n\\left[Q\\left(y_{l}\\right) V\\right](x) \\leq \\gamma\\left(y_{l}\\right) V(x)+K\\left(y_{l}\\right)\n$$\n\nwhich follows directly from the drift condition (7).\nInduction hypothesis: Assume that the inequality holds for some $k>l$, with fixed $x \\in \\mathcal{X}$ and $l \\in \\mathbb{N}$ :\n\n$$\n\\left[Q\\left(y_{k-1}\\right) \\ldots Q\\left(y_{l}\\right) V\\right](x) \\leq V(x) \\prod_{r=l}^{k-1} \\gamma\\left(y_{r}\\right)+\\sum_{r=l}^{k-1} K\\left(y_{r}\\right) \\prod_{j=r+1}^{k-1} \\gamma\\left(y_{j}\\right)\n$$\n\nInduction step: We verify that inequality (39) holds for $k+1$. By the drift property for $Q\\left(y_{k}\\right)$ we have\n\n$$\n\\left[Q\\left(y_{k}\\right) V\\right](x) \\leq \\gamma\\left(y_{k}\\right) V(x)+K\\left(y_{k}\\right)\n$$\n\nOperators $V \\mapsto[Q(y) V], y \\in \\mathcal{Y}$ are linear, monotone and for $V \\equiv 1[Q(y) V] \\equiv 1, y \\in \\mathcal{Y}$. Therefore, we can write\n\n$$\n\\begin{aligned}\n{\\left[Q\\left(y_{k}\\right) \\ldots Q\\left(y_{l}\\right) V\\right](x) } & =\\left[Q\\left(y_{k-1}\\right) \\ldots Q\\left(y_{l}\\right)\\right] Q\\left(y_{k}\\right) V][(x) \\\\\n& \\leq \\gamma\\left(y_{k}\\right)\\left[Q\\left(y_{k-1}\\right) \\ldots Q\\left(y_{l}\\right) V\\right](x)+K\\left(y_{k}\\right)\n\\end{aligned}\n$$\n\nthus by applying the induction hypothesis (39), we obtain\n\n$$\n\\begin{aligned}\n{\\left[Q\\left(y_{k}\\right) \\ldots Q\\left(y_{l}\\right) V\\right](x) } & \\leq \\gamma\\left(y_{k}\\right)\\left[V(x) \\prod_{r=l}^{k-1} \\gamma\\left(y_{r}\\right)+\\sum_{r=l}^{k-1} K\\left(y_{r}\\right) \\prod_{j=r+1}^{k-1} \\gamma\\left(y_{j}\\right)\\right]+K\\left(y_{k}\\right) \\\\\n& =V(x) \\prod_{r=l}^{k} \\gamma\\left(y_{r}\\right)+\\sum_{r=l}^{k} K\\left(y_{r}\\right) \\prod_{j=r+1}^{k} \\gamma\\left(y_{j}\\right)\n\\end{aligned}\n$$\n\nwhich completes the proof.\nIn our earlier papers (See Lemma 7.1 in [35] and Lemma 3.9 in [36]), we relied on special cases of the following lemma. It is also a variant of Lemma 6.1 in [22], albeit in a somewhat broader context. Such representations of parametric kernels satisfying the minorization condition (8) can be deemed standard. For the sake of completeness and to ensure self-containment of our explanation, we present and prove it in its most general form.\n$7(1 \\mathrm{~cm}: \\mathrm{T})^{7}$ Lemma C.2. Let $R>0$ be arbitrary and suppose the parametric kernel $Q: \\mathcal{Y} \\times \\mathcal{X} \\times \\mathcal{B}(\\mathcal{X}) \\rightarrow[0,1]$ satisfies the minorization condition given by (8). Then there exists a measurable mapping $T^{R}$ : $\\mathcal{X} \\times \\mathcal{Y} \\times[0,1] \\rightarrow \\mathcal{X}$ such that\n\n$$\nQ(y, x, A)=\\int_{[0,1]} \\mathbb{1}_{T^{R}(x, y, u) \\in A} \\mathrm{~d} u\n$$\n\nfor all $x \\in \\mathcal{X}, A \\in \\mathcal{B}(\\mathcal{X})$ and $y \\in \\mathcal{Y}$. Furthermore, for any fixed $y \\in \\mathcal{Y}$, there exists a Borel set $U=U(y) \\in \\mathcal{B}([0,1])$ with Lebesgue measure $\\operatorname{Leb}_{1}(U) \\geq 1-\\beta(R, y)$ such that for $u \\in U$,\n\n$$\nT^{R}\\left(x_{1}, y, u\\right)=T^{R}\\left(x_{2}, y, u\\right), x_{1}, x_{2} \\in \\stackrel{-1}{V}([0, R])\n$$\n\nProof. We proceed as in Lemma 7.1 in [35], following the proof of Lemma 6.1 in [22]. The case of countable $\\mathcal{X}$ is straightforward and thus omitted. For the uncountable case, we can assume, by the Borel isomorphism theorem, that $\\mathcal{X}=\\mathbb{R}$ and $\\mathcal{B}(\\mathcal{X})=\\mathcal{B}(\\mathbb{R})$ is the standard Borel $\\sigma$-algebra of $\\mathbb{R}$.\n\nIt is easy to see that if $\\beta(R, y)=0$ for some $y \\in \\mathcal{Y}$ in the minorization condition (8), then for any $A \\in \\mathcal{B}(\\mathcal{X})$ and $x \\in \\stackrel{-}{\\overline{V}}([0, R])$, both $Q(y, x, A) \\geq \\kappa_{R}(y, A)$ and $Q(y, x, \\mathcal{X} \\backslash A) \\geq \\kappa_{R}(y, \\mathcal{X} \\backslash A)$ hold simultaneously. Consequently, we have\n\n$$\nQ(y, \\cdot, A) \\mid_{\\stackrel{-}{\\overline{V}}([0, R])}=\\kappa_{R}(y, A), A \\in \\mathcal{B}(\\mathcal{X})\n$$\n\nFor $x \\in \\stackrel{-}{\\overline{V}}([0, R]), A \\in \\mathcal{B}(\\mathcal{X})=\\mathcal{B}(\\mathbb{R})$, and $y \\in \\mathcal{Y}$ let\n\n$$\nq_{R}(y, x, A):= \\begin{cases}\\frac{1}{\\beta(R, y)}[Q(y, x, A)-(1-\\beta(R, y)) \\kappa_{R}(y, A)] & \\text { if } \\beta(R, y) \\neq 0 \\\\ 0 & \\text { if } \\beta(R, y)=0\\end{cases}\n$$\n\nAdditionally, introduce the pseudoinverses of the corresponding cumulative distribution functions as follows:\n\n$$\n\\begin{aligned}\nQ^{-1}(y, x, z) & :=\\inf \\{r \\in \\mathbb{Q} \\mid Q(y, x,(-\\infty, r]) \\geq z\\} \\\\\n\\kappa_{R}^{-1}(y, z) & :=\\inf \\left\\{r \\in \\mathbb{Q} \\mid \\kappa_{R}(y,(-\\infty, r]) \\geq z\\right\\} \\\\\nq_{R}^{-1}(y, x, z) & :=\\inf \\left\\{r \\in \\mathbb{Q} \\mid q_{R}(y, x,(-\\infty, r]) \\geq z\\right\\}\n\\end{aligned}\n$$\n\nThere exists a measurable mapping $\\chi:[0,1] \\rightarrow[0,1]^{2}$ such that the pushforward measure $\\chi_{*}(\\mathrm{~d} x)$ equals $\\mathrm{d} x \\mathrm{~d} y$. In other words, for every Borel set $B \\in \\mathcal{B}\\left([0,1]^{2}\\right), \\operatorname{Leb}_{2}(B)=\\operatorname{Leb}_{1}\\left(\\stackrel{-}{\\chi}^{1}(B)\\right)$, where $\\operatorname{Leb}_{k}$ refers to the Lebesgue measure on $[0,1]^{k}, k=1,2$. Finally, we define\n\n$$\nT^{R}(x, y, u)= \\begin{cases}\\mathbb{1}_{\\chi(u)_{1} \\geq \\beta(R, y)} \\kappa_{R}^{-1}\\left(y, \\chi(u)_{2}\\right)+\\mathbb{1}_{\\chi(u)_{1}<\\beta(R, y)} q_{R}^{-1}\\left(y, x, \\chi(u)_{2}\\right) & \\text { if } V(x) \\leq R \\\\ Q^{-1}\\left(y, x, \\chi(u)_{2}\\right) & \\text { if } V(x)>R\\end{cases}\n$$\n\nIt is evident that $x \\mapsto T^{R}(x, y, u)$ is constant on $\\stackrel{-}{\\overline{V}}([0, R])$ whenever $\\chi(u)_{1} \\geq \\beta(R, y)$, implying (40) with $U=\\stackrel{-}{\\chi}^{1}([\\beta(R, y), 1] \\times[0,1])$.\n\nFurthermore, for any fixed $r \\in \\mathbb{R}, y \\in \\mathcal{Y}$ and $x \\in \\stackrel{-}{\\overline{V}}([0, R])$ by the change of variable formula and the definitions of $T^{R}$ and $q_{R}$, we can write\n\n$$\n\\begin{aligned}\n\\int_{[0,1]} \\mathbb{1}_{\\left\\{T^{R}(x, y, u) \\leq r\\right\\}} \\mathrm{d} u & =\\int_{0}^{1} \\int_{0}^{1} \\mathbb{1}_{\\left\\{\\mathbb{1}_{s \\geq \\beta(R, y)} \\kappa_{R}^{-1}(y, t)+\\mathbb{1}_{s<\\beta(R, y)} q_{R}^{-1}(y, x, t) \\leq r\\right\\}} \\mathrm{d} s \\mathrm{~d} t \\\\\n& =(1-\\beta(R, y)) \\int_{0}^{1} \\mathbb{1}_{\\kappa_{R}^{-1}(y, t) \\leq r} \\mathrm{~d} t+\\beta(R, y) \\int_{0}^{1} \\mathbb{1}_{q_{R}^{-1}(y, x, t) \\leq r} \\mathrm{~d} t \\\\\n& =(1-\\beta(R, y)) \\kappa_{R}(y,(-\\infty, r])+\\beta(R, y) q_{R}(y, x,(-\\infty, r]) \\\\\n& =Q(y, x,(-\\infty, r])\n\\end{aligned}\n$$\n\nSimilarly, for $x \\notin \\stackrel{-}{\\overline{V}}([0, R])$, we have\n\n$$\n\\int_{[0,1]} \\mathbb{1}_{T^{R}(x, y, u) \\leq r} \\mathrm{~d} u=\\int_{0}^{1} \\int_{0}^{1} \\mathbb{1}_{Q^{-1}(y, x, s) \\leq r} \\mathrm{~d} s \\mathrm{~d} t=\\int_{0}^{1} \\mathbb{1}_{Q^{-1}(y, x, s) \\leq r} \\mathrm{~d} s=Q(y, x,(-\\infty, r])\n$$\n\nthus the claimed identity holds.\nIt remains only to show that $T^{R}$ is measurable with respect to sigma algebras $\\mathcal{B}(\\mathbb{R}) \\otimes \\mathcal{B}(\\mathcal{Y}) \\otimes$ $\\mathcal{B}([0,1])$ and $\\mathcal{B}(\\mathbb{R})$. Indeed, $T^{R}$ is a composition of measurable functions.\n\nBy Assumption 2.2 B), there exists $0<r<1 / \\bar{\\gamma}-1$ such that $\\bar{\\beta}:=\\sup _{y \\in \\mathcal{Y}} \\beta(R(y), y)<1$ holds with $R(y):=\\frac{2 K(y)}{r \\gamma(y)}$. We define the measurable mapping\n\n$$\n(x, y, u) \\mapsto f(x, y, u):=T^{R(y)}(x, y, u), x \\in \\mathcal{X}, y \\in \\mathcal{Y}, u \\in[0,1]\n$$\n\nLet $\\left(\\varepsilon_{t}\\right)_{t \\in \\mathbb{N}}$ be a sequence of i.i.d. variables uniformly distributed on $[0,1]$ such that sigma algebras $\\mathcal{F}_{0, \\infty}^{s}$ and $\\sigma\\left(Y_{t}, X_{t}, t \\in \\mathbb{N}\\right)$ are independent. Furthermore, for $s \\in \\mathbb{N}$ and $x \\in \\mathcal{X}$, let us introduce the family of auxiliary processes\n\n$$\nZ_{s, t}^{x, \\mathbf{y}}= \\begin{cases}x & \\text { if } t \\leq s \\\\ f\\left(Z_{s, t-1}^{x, \\mathbf{y}}, y_{t-1}, \\varepsilon_{t}\\right) & \\text { if } t>s\\end{cases}\n$$\n\nwhere $\\mathbf{y}=\\left(y_{0}, y_{1}, \\ldots\\right) \\in \\mathcal{Y}^{\\mathbb{N}}$ can be any fixed trajectory. Clearly, for $\\mathbf{Y}=\\left(Y_{n}\\right)_{n \\in \\mathbb{N}}$, the process $Z_{s, t}^{\\mathcal{X}_{s}, \\mathbf{Y}}, t \\geq s$ is a version of $\\left(X_{t}\\right)_{t \\geq s}$. In the forthcoming part of the section, we will prove that this process satisfies the coupling condition. First, we will show that for any fixed $x \\in \\mathbb{N}$ and $\\mathbf{y} \\in \\mathcal{Y}^{\\mathbb{N}}$, the process $Z_{s, t}^{x, \\mathbf{y}}, t \\geq s$ is a Harris recurrent time-inhomogeneous Markov chain. The next lemma provides a quenched version of the coupling condition, controlling the coupling time between iterations starting from different initial values.\n$\\boldsymbol{\\tau}($ lem: coupling $) 7$ Lemma C.3. Let $x_{1}, x_{2} \\in \\mathcal{X}$ and $\\mathbf{y} \\in \\mathcal{Y}^{\\mathbb{N}}$ be arbitrary but fixed. Then for $0<m<n$, we have\n\nProof. For the sake of brevity, we employ a more concise notation: $Z_{n}^{i}=Z_{0, n}^{x_{i}, \\mathbf{y}}, i=1,2$, and $n \\in \\mathbb{N}$, moreover we introduce\n\n$$\n\\bar{Z}_{n}:=\\left(Z_{n}^{1}, Z_{n}^{2}\\right),\\left\\|\\bar{Z}_{n}\\right\\|:=\\max \\left(V\\left(Z_{n}^{1}\\right), V\\left(Z_{n}^{2}\\right)\\right)\n$$\n\nand the sequence of successive visiting times\n\n$$\n\\sigma_{0}:=0, \\sigma_{k+1}=\\inf \\left\\{n>\\sigma_{k}\\left|\\left\\|\\bar{Z}_{n}\\right\\| \\leq R\\left(y_{n}\\right)\\right\\}, k \\in \\mathbb{N}\\right.\n$$\n\nthat are obviously $\\mathcal{F}_{1, \\infty}^{s}$-stopping times. Note that on $\\left\\{\\left\\|\\bar{Z}_{n}\\right\\|>R\\left(y_{n}\\right)\\right\\}$ we have\n\n$$\n\\gamma\\left(y_{n}\\right)\\left(V\\left(Z_{n}^{1}\\right)+V\\left(Z_{n}^{2}\\right)\\right)+2 K\\left(y_{n}\\right) \\leq(1+r) \\gamma\\left(y_{n}\\right)\\left(V\\left(Z_{n}^{1}\\right)+V\\left(Z_{n}^{2}\\right)\\right)\n$$\n\nand thus for $k \\geq 1$ and $s \\geq 1$, by the Markov inequality, we obtain\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(\\sigma_{k+1}-\\sigma_{k}>s \\mid \\mathcal{F}_{1, \\sigma_{k}}^{c}\\right) & \\leq \\mathbb{E}\\left(\\mathbb{P}\\left(C_{\\sigma_{k}+s} \\mid \\bar{Z}_{\\sigma_{k}+s-1}\\right) \\prod_{j=1}^{s-1} \\mathbb{1}_{C_{\\sigma_{k}+j}} \\mid \\mathcal{F}_{1, \\sigma_{k}}^{c}\\right) \\\\\n& \\leq \\frac{(1+r) \\gamma\\left(y_{\\sigma_{k}+s-1}\\right)}{R\\left(y_{\\sigma_{k}+s}\\right)} \\mathbb{E}\\left(\\left(V\\left(Z_{\\sigma_{k}+s-1}^{1}\\right)+V\\left(Z_{\\sigma_{k}+s-1}^{2}\\right)\\right) \\prod_{j=1}^{s-2} \\mathbb{1}_{C_{\\sigma_{k}+j}} \\mid \\mathcal{F}_{1, \\sigma_{k}}^{c}\\right)\n\\end{aligned}\n$$\n\nwhere $C_{n}$ is the shorthand notation for the event $\\left\\{\\left\\|\\bar{Z}_{n}\\right\\|>R\\left(y_{n}\\right)\\right\\}, n \\in \\mathbb{N}$.\nBy the tower rule, we can write\n\n$$\n\\begin{aligned}\n& \\mathbb{E}\\left(\\left(V\\left(Z_{\\sigma_{k}+s-1}^{1}\\right)+V\\left(Z_{\\sigma_{k}+s-1}^{2}\\right)\\right) \\prod_{j=1}^{s-2} \\mathbb{1}_{C_{\\sigma_{k}+j}} \\mid \\mathcal{F}_{1, \\sigma_{k}}^{c}\\right)= \\\\\n& \\mathbb{E}\\left(\\mathbb{E}\\left[V\\left(Z_{\\sigma_{k}+s-1}^{1}\\right)+V\\left(Z_{\\sigma_{k}+s-1}^{2}\\right) \\mid \\mathcal{F}_{1, \\sigma_{k}+s-2}^{c}\\right] \\prod_{j=1}^{s-2} \\mathbb{1}_{C_{\\sigma_{k}+j}} \\mid \\mathcal{F}_{1, \\sigma_{k}}^{c}\\right)\n\\end{aligned}\n$$\n\nUsing the Markov property of $\\left(\\bar{Z}_{n}\\right)_{n \\in \\mathbb{N}}$ and the drift property of the parametric kernel (7), we have\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[V\\left(Z_{\\sigma_{k}+s-1}^{1}\\right)+V\\left(Z_{\\sigma_{k}+s-1}^{2}\\right) \\mid \\mathcal{F}_{1, \\sigma_{k}+s-2}^{s}\\right] & =\\mathbb{E}\\left[V\\left(Z_{\\sigma_{k}+s-1}^{1}\\right)+V\\left(Z_{\\sigma_{k}+s-1}^{2}\\right) \\mid \\bar{Z}_{\\sigma_{k}+s-2}\\right] \\\\\n& =[Q\\left(y_{\\sigma_{k}+s-2}\\right) V]\\left(Z_{\\sigma_{k}+s-2}^{1}\\right)+\\mid Q\\left(y_{\\sigma_{k}+s-2}\\right) V]\\left(Z_{\\sigma_{k}+s-2}^{2}\\right) \\\\\n& \\leq \\gamma\\left(y_{\\sigma_{k}+s-2}\\right)\\left(V\\left(Z_{\\sigma_{k}+s-2}^{1}\\right)+\\left(Z_{\\sigma_{k}+s-2}^{2}\\right)\\right)+2 K\\left(y_{\\sigma_{k}+s-2}\\right)\n\\end{aligned}\n$$\n\nNow, inequality (43) yields\n\n$$\n\\mathbb{E}\\left[V\\left(Z_{\\sigma_{k}+s-1}^{1}\\right)+V\\left(Z_{\\sigma_{k}+s-1}^{2}\\right) \\mid \\mathcal{F}_{1, \\sigma_{k}+s-2}^{s}\\right] \\mathbb{1}_{C_{\\sigma_{k}+s-2}} \\leq(1+r) \\gamma\\left(y_{\\sigma_{k}+s-2}\\right)\\left(V\\left(Z_{\\sigma_{k}+s-2}^{1}\\right)+\\left(Z_{\\sigma_{k}+s-2}^{2}\\right)\\right)\n$$\n\nFinally, we arrive at\n\n$$\n\\begin{aligned}\n& \\mathbb{E}\\left(\\left(V\\left(Z_{\\sigma_{k}+s-1}^{1}\\right)+V\\left(Z_{\\sigma_{k}+s-1}^{2}\\right)\\right) \\prod_{j=1}^{s-2} \\mathbb{1}_{C_{\\sigma_{k}+j}} \\mid \\mathcal{F}_{1, \\sigma_{k}}^{s}\\right) \\leq \\\\\n&(1+r) \\gamma\\left(y_{\\sigma_{k}+s-2}\\right) \\mathbb{E}\\left(\\left(V\\left(Z_{\\sigma_{k}+s-2}^{1}\\right)+V\\left(Z_{\\sigma_{k}+s-2}^{2}\\right)\\right) \\prod_{j=1}^{s-3} \\mathbb{1}_{C_{\\sigma_{k}+j}} \\mid \\mathcal{F}_{1, \\sigma_{k}}^{s}\\right)\n\\end{aligned}\n$$\n\nIteration of this argument in $s-2$ steps leads to the following estimation:\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(\\sigma_{k+1}-\\sigma_{k}>s \\mid \\mathcal{F}_{1, \\sigma_{k}}^{s}\\right) & \\leq \\frac{(1+r)^{s-1} \\prod_{j=1}^{s-1} \\gamma\\left(y_{\\sigma_{k}+j}\\right)}{R\\left(y_{\\sigma_{k}+s}\\right)} \\mathbb{E}\\left(V\\left(Z_{\\sigma_{k}+1}^{1}\\right)+V\\left(Z_{\\sigma_{k}+1}^{2}\\right) \\mid \\bar{Z}_{\\sigma_{k}}\\right) \\\\\n& \\leq \\frac{r(1+r)^{s-1} \\prod_{j=1}^{s} \\gamma\\left(y_{\\sigma_{k}+j}\\right)}{2 K\\left(y_{\\sigma_{k}+s}\\right)}\\left[\\gamma\\left(y_{\\sigma_{k}}\\right)\\left(V\\left(Z_{\\sigma_{k}}^{1}\\right)+V\\left(Z_{\\sigma_{k}}^{2}\\right)\\right)+2 K\\left(y_{\\sigma_{k}}\\right)\\right] \\\\\n& \\leq(1+r)^{s} K\\left(y_{\\sigma_{k}}\\right) \\prod_{j=1}^{s} \\gamma\\left(y_{\\sigma_{k}+j}\\right)\n\\end{aligned}\n$$\n\nwhere we used that $V\\left(Z_{\\sigma_{k}}^{1}\\right)+V\\left(Z_{\\sigma_{k}}^{2}\\right) \\leq 2 R\\left(y_{\\sigma_{k}}\\right)$, and $K(\\cdot) \\geq 1$.\nAlong similar lines, we can show that\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(\\sigma_{1}>s\\right) & \\leq \\frac{(1+r)^{s-1} \\prod_{j=1}^{s-1} \\gamma\\left(y_{j}\\right)}{R\\left(y_{s}\\right)}\\left[\\gamma\\left(y_{0}\\right)\\left(V\\left(x_{1}\\right)+V\\left(x_{2}\\right)\\right)+2 K\\left(y_{0}\\right)\\right] \\\\\n& \\leq(1+r)^{s} \\prod_{j=1}^{s} \\gamma\\left(y_{j}\\right)\\left[\\frac{\\gamma\\left(y_{0}\\right)}{2}\\left(V\\left(x_{1}\\right)+V\\left(x_{2}\\right)\\right)+K\\left(y_{0}\\right)\\right]\n\\end{aligned}\n$$\n\nClearly, for any $0<m \\leq n$, on the event $\\left\\{\\sigma_{m}>n\\right\\}$ we have $\\left\\{\\sigma_{k+1}-\\sigma_{k}>\\lfloor n / m\\rfloor\\right\\} \\cap\\left\\{\\sigma_{k} \\leq\\right.$ $k\\lfloor n / m\\rfloor\\}$ for some $k=0,1, \\ldots m-1$ hence by the union bound and the estimates we obtain for\n\nthe time elapsed between consecutive visits, we can write\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(\\sigma_{m}>n\\right) & \\leq \\mathbb{P}\\left(\\bigcup_{k=0}^{m-1}\\left\\{\\sigma_{k+1}-\\sigma_{k}>\\lfloor n / m\\rfloor\\right\\} \\cap\\left\\{\\sigma_{k} \\leq k\\lfloor n / m\\rfloor\\right\\}\\right) \\\\\n& \\leq \\sum_{k=0}^{m-1} \\mathbb{P}\\left(\\left\\{\\sigma_{k+1}-\\sigma_{k}>\\lfloor n / m\\rfloor\\right\\} \\cap\\left\\{\\sigma_{k} \\leq k\\lfloor n / m\\rfloor\\right\\}\\right) \\\\\n& =\\sum_{k=0}^{m-1} \\sum_{l=k}^{k\\lfloor n / m\\rfloor} \\mathbb{P}\\left(\\sigma_{k+1}-\\sigma_{k}>\\lfloor n / m\\rfloor \\mid \\sigma_{k}=l\\right) \\mathbb{P}\\left(\\sigma_{k}=l\\right) \\\\\n& \\leq \\mathbb{P}\\left(\\sigma_{1}>\\lfloor n / m\\rfloor\\right)+\\sum_{k=1}^{m-1} \\sum_{l=k}^{k\\lfloor n / m\\rfloor} \\mathbb{P}\\left(\\sigma_{k+1}-\\sigma_{k}>\\lfloor n / m\\rfloor \\mid \\sigma_{k}=l\\right) \\\\\n& \\leq\\left[\\frac{\\gamma\\left(y_{0}\\right)}{2}\\left(V\\left(x_{1}\\right)+V\\left(x_{2}\\right)\\right)+K\\left(y_{0}\\right)\\right](1+r)^{\\lfloor n / m\\rfloor} \\prod_{j=1}^{\\lfloor n / m\\rfloor} \\gamma\\left(y_{j}\\right) \\\\\n& +(1+r)^{\\lfloor n / m\\rfloor} \\sum_{k=1}^{m-1} \\sum_{l=k}^{k\\lfloor n / m\\rfloor} K\\left(y_{l}\\right) \\prod_{j=1}^{\\lfloor n / m\\rfloor} \\gamma\\left(y_{l+j}\\right)\n\\end{aligned}\n$$\n\nNext, we estimate the probability of no-coupling on events when small sets are visited at least $m$-times. By Lemma C. 2 and the choice of $R(y)$ in the definition of $f$ in (41) and (42), for each $j=1, \\ldots, m, x \\mapsto f\\left(x, y_{j}, \\varepsilon_{\\sigma_{j}+1}\\right)$ is constant on the level set $\\stackrel{\\rightharpoonup}{V}\\left(\\left[0, R\\left(y_{\\sigma_{j}}\\right)\\right]\\right)$ with probability at least $1-\\bar{\\beta}$ independently of $\\mathcal{F}_{0, \\sigma_{j}}^{\\varepsilon}$ thus no-coupling happens with probability at most $\\bar{\\beta}$. Therefore, we can estimate:\n\n$$\n\\mathbb{P}\\left(Z_{0, n}^{\\sigma_{1}, \\mathbf{y}} \\neq Z_{0, n}^{\\sigma_{2}, \\mathbf{y}}, \\sigma_{m}<n\\right) \\leq \\bar{\\beta}^{m}\n$$\n\nFinally, we combine this upper bound with that one what we got for the tail probability of the visiting times, and obtain\n\n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(Z_{0, n}^{\\sigma_{1}, \\mathbf{y}} \\neq Z_{0, n}^{\\sigma_{2}, \\mathbf{y}}\\right) \\leq \\mathbb{P}\\left(Z_{0, n}^{\\sigma_{1}, \\mathbf{y}} \\neq Z_{0, n}^{\\sigma_{2}, \\mathbf{y}}, \\sigma_{m}<n\\right)+\\mathbb{P}\\left(\\sigma_{m}>n-1\\right) \\\\\n& \\leq \\bar{\\beta}^{m}+\\left[\\frac{\\gamma\\left(y_{0}\\right)}{2}\\left(V\\left(x_{1}\\right)+V\\left(x_{2}\\right)\\right)+K\\left(y_{0}\\right)\\right](1+r)^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\prod_{j=1}^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\gamma\\left(y_{j}\\right) \\\\\n& +(1+r)^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\sum_{k=1}^{m-1} \\sum_{l=k}^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} K\\left(y_{l}\\right) \\prod_{j=1}^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\gamma\\left(y_{l+j}\\right) \\\\\n& =\\bar{\\beta}^{m}+(1+r)^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor}\\left\\{\\frac{V\\left(x_{1}\\right)+V\\left(x_{2}\\right)}{2} \\prod_{j=0}^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\gamma\\left(y_{j}\\right)+\\sum_{k=0}^{m-1} \\sum_{l=k}^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} K\\left(y_{l}\\right) \\prod_{j=1}^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\gamma\\left(y_{l+j}\\right)\\right\\}\n\\end{aligned}\n$$\n\nwhich completes the proof.\n\nProof of Lemma 2.4. The process $Z_{0, n}^{X_{0}, \\mathbf{Y}}, n \\in \\mathbb{N}$ is a version of $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ thus to simplify the notation in this proof, we may and will redefine $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ as $X_{n}:=Z_{0, n}^{X_{0}, \\mathbf{Y}}$. Furthermore, we indicate the dependence of $Z$ on the driving noise by writing $Z_{s, t}^{\\sigma, \\mathbf{y}, \\varepsilon}$ instead of $Z_{s, t}^{\\sigma, \\mathbf{y}}$, where $\\varepsilon$ refers to $\\varepsilon=\\left(\\varepsilon_{1}, \\varepsilon_{2}, \\ldots\\right)$. We also introduce the usual left shift operation: $(S \\mathbf{y})_{j}=y_{j+1}$ and similarly $\\left(S \\varepsilon\\right)_{j}=\\varepsilon_{j+1}, j \\in \\mathbb{N}$.\n\nFor arbitrary but fixed $j \\in \\mathbb{N}$ and $x \\in \\mathcal{X}$, we can write\n\n$$\n\\mathbb{P}\\left(Z_{j, j+n}^{X_{j}, \\mathbf{Y}, \\varepsilon} \\neq Z_{j, j+n}^{\\sigma, \\mathbf{y}, \\varepsilon}\\right)=\\mathbb{P}\\left(Z_{0, n}^{X_{j}, S^{j} \\mathbf{Y}, S^{j} \\varepsilon} \\neq Z_{0, n}^{\\sigma, S^{j} \\mathbf{Y}, S^{j} \\varepsilon}\\right)\n$$\n\nthus by the tower rule and Lemma C.3, for $0<m<n$, we have\n\n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(Z_{0, n}^{X_{j}, S^{\\prime} \\mathbf{Y}, S^{\\prime} e} \\neq Z_{0, n}^{\\sigma, S^{\\prime} \\mathbf{Y}, S^{\\prime} e}\\right)=\\mathbb{E}\\left[\\mathbb{P}\\left(Z_{0, n}^{X_{j}, S^{\\prime} \\mathbf{Y}, S^{\\prime} e} \\neq Z_{0, n}^{\\sigma, S^{\\prime} \\mathbf{Y}, S^{\\prime} e}\\left[\\mathcal{F}_{0, \\infty}^{Y} \\vee \\sigma\\left(X_{j}\\right)\\right)\\right] \\leq \\bar{\\beta}^{m}+\\right. \\\\\n& (1+r)^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\mathbb{E}\\left[\\frac{\\mathbb{E}\\left[V\\left(X_{j}\\right) \\mid \\mathcal{F}_{0, \\infty}^{Y}\\right]+V(x)}{2} \\prod_{r=0}^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\gamma\\left(Y_{r+j}\\right)+\\sum_{k=0}^{m-1} \\sum_{l=k}^{k\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} K\\left(Y_{l+j}\\right) \\prod_{r=1}^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\gamma\\left(Y_{l+r+j}\\right)\\right] .\n\\end{aligned}\n$$\n\nAs for $\\mathbb{E}\\left[V\\left(X_{j}\\right) \\mid \\mathcal{F}_{0, \\infty}^{Y}\\right]$, by Lemma C.1, we obtain\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[V\\left(X_{j}\\right) \\mid \\mathcal{F}_{0, \\infty}^{Y}\\right] & =\\mathbb{E}\\left[\\left[Q\\left(Y_{j-1}\\right), \\ldots, Q\\left(Y_{0}\\right) V\\right]\\left(X_{0}\\right) \\mid \\mathcal{F}_{0, \\infty}^{Y}\\right] \\\\\n& \\leq \\mathbb{E}\\left(V\\left(X_{0}\\right)\\right) \\prod_{i=0}^{j-1} \\gamma\\left(Y_{i}\\right)+\\sum_{r=0}^{j-1} K\\left(Y_{r}\\right) \\prod_{i=r+1}^{j-1} \\gamma\\left(Y_{i}\\right)\n\\end{aligned}\n$$\n\nwhere we used that the initial state $X_{0}$ is independent of $\\sigma\\left(Y_{n}, \\varepsilon_{n+1} \\mid n \\in \\mathbb{N}\\right)$.\nFor $n>1$, we choose $m_{n}=\\frac{n-1}{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1}$. It is easy to check that $m_{n} \\geq\\left\\lfloor n^{1 / 2}\\right\\rfloor$ for $n>1$ hence $\\bar{\\beta}^{m_{n}} \\leq \\bar{\\beta}^{\\left\\lfloor n^{1 / 2}\\right\\rfloor}$. Furthermore, let us fix $\\gamma^{\\prime}>\\bar{\\gamma}$ such that $\\bar{\\gamma}:=(1+r) \\gamma^{\\prime}<1$. Then by Assumption 2.2 A$)$, there exists $N \\in \\mathbb{N}$ such that\n\n$$\n\\sup _{j \\geq-1} \\mathbb{E}\\left[K\\left(Y_{j}\\right) \\prod_{k=1}^{n} \\gamma\\left(Y_{k+j}\\right)\\right] \\leq\\left(\\gamma^{\\prime}\\right)^{n}, n \\geq N\n$$\n\nwhere for our convenience, we employ the convention $K\\left(Y_{-1}\\right):=1$. Using (45), for $\\left\\lfloor n^{1 / 2}\\right\\rfloor \\geq N$, we obtain\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[\\mathbb{E}\\left[V\\left(X_{j}\\right) \\mid \\mathcal{F}_{0, \\infty}^{Y}\\right] \\prod_{r=0}^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1} \\gamma\\left(Y_{r+j}\\right)\\right] & \\leq \\mathbb{E}\\left(V\\left(X_{0}\\right)\\right) \\mathbb{E}\\left[\\prod_{i=0}^{\\left\\lfloor n^{1 / 2}\\right\\rfloor+j-1} \\gamma\\left(Y_{i}\\right)\\right]+\\sum_{r=0}^{j-1} \\mathbb{E}\\left[K\\left(Y_{r}\\right) \\prod_{i=r+1}^{\\left\\lfloor n^{1 / 2}\\right\\rfloor+j-1} \\gamma\\left(Y_{i}\\right)\\right] \\\\\n& \\leq \\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)\\left(\\gamma^{\\prime}\\right)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor+j}+\\sum_{r=0}^{j-1}\\left(\\gamma^{\\prime}\\right)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor+j-1-r} \\\\\n& \\leq\\left(\\gamma^{\\prime}\\right)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor}\\left(\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)+\\frac{1}{1-\\gamma^{\\prime}}\\right)\n\\end{aligned}\n$$\n\nSimilarly, for $\\left\\lfloor n^{1 / 2}\\right\\rfloor-1 \\geq N$, we get\n\n$$\n\\mathbb{E}\\left[V(x) \\prod_{r=0}^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1} \\gamma\\left(Y_{r+j}\\right)\\right] \\leq\\left(\\gamma^{\\prime}\\right)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor} V(x)\n$$\n\nmoreover\n\n$$\n\\begin{aligned}\n\\sum_{k=0}^{m_{n}-1} \\sum_{l=k}^{k\\left(\\left\\lfloor n^{1 / 2}\\right\\rfloor-1\\right)} \\mathbb{E}\\left[K\\left(Y_{l+j}\\right) \\prod_{r=1}^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1} \\gamma\\left(Y_{l+r+j}\\right)\\right] & \\leq \\sum_{k=0}^{m_{n}-1} \\sum_{l=k}^{k\\left(\\left\\lfloor n^{1 / 2}\\right\\rfloor-1\\right)}\\left(\\gamma^{\\prime}\\right)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1} \\\\\n& =m_{n}\\left[\\frac{\\left(m_{n}-1\\right)\\left(\\left\\lfloor n^{1 / 2}\\right\\rfloor-2\\right)}{2}+1\\right]\\left(\\gamma^{\\prime}\\right)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1}\n\\end{aligned}\n$$\n\nTo sum up, and taking into account that $m_{n}=O\\left(n^{1 / 2}\\right)$, we obtain\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(Z_{j, j+n}^{X_{j}, \\mathbf{Y}, e} \\neq Z_{j, j+n}^{\\sigma, e}\\right) & \\leq \\bar{\\beta}^{n^{1 / 2}-1}+\\frac{(1+r)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1}}{2}\\left(\\gamma^{\\prime}\\right)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor}\\left(V(x)+\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)+\\frac{1}{1-\\gamma^{\\prime}}\\right) \\\\\n& +c n^{3 / 2}(1+r)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1}\\left(\\gamma^{\\prime}\\right)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1} \\\\\n& \\leq \\bar{\\beta}^{n^{1 / 2}-1}+\\left[\\frac{\\left(V(x)+\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)+\\frac{1}{1-c}\\right.}{2}+c n^{3 / 2}\\right] \\bar{\\gamma}^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1}\n\\end{aligned}\n$$\n\nfor some $c>0$, whenever $n \\geq(N+2)^{2}$ which implies the desired estimate.\nThe proof of Theorem 2.7 follows a similar approach to that of Lemma 2.4, with a few key differences. The most significant distinction to keep in mind is that the distribution of $X_{0}^{*}$ heavily depends on the whole trajectory $\\left(Y_{n}\\right)_{n \\in \\mathbb{Z}}$.\n7(lam:Ybound) ${ }^{7}$ Lemma C.4. Under the conditions of Theorem 2.7, we have\n\n$$\n\\limsup _{n \\rightarrow \\infty} \\mathbb{E}^{1 / n}\\left[V\\left(X_{0}^{*}\\right) \\prod_{k=0}^{n-1} \\gamma\\left(Y_{k}\\right)\\right] \\leq \\bar{\\gamma}\n$$\n\nProof. Without the loss of generality, for our convenience, we can assume that the i.i.d. driving noise is a double-sided infinite process $\\left(\\varepsilon_{n}\\right)_{n \\in \\mathbb{Z}}$, as well. Let $x \\in \\mathcal{X}$ be arbitrary and deterministic. Then by Corollary 1 and the subsequent Note in [49], $\\operatorname{Law}\\left(Z_{0, m}^{x, \\mathbf{Y}}\\right)=\\operatorname{Law}\\left(Z_{-m, 0}^{x, \\mathbf{Y}}\\right) \\rightarrow \\operatorname{Law}\\left(X_{0}^{*}\\right)$, as $m \\rightarrow \\infty$ in total variation hence\n\n$$\n\\mathbb{E}\\left[V\\left(X_{0}^{*}\\right) \\prod_{k=0}^{n-1} \\gamma\\left(Y_{k}\\right)\\right]=\\lim _{M \\rightarrow \\infty} \\lim _{m \\rightarrow \\infty} \\mathbb{E}\\left[\\min \\left(M, V\\left(Z_{-m, 0}^{x, \\mathbf{Y}}\\right) \\prod_{k=0}^{n-1} \\gamma\\left(Y_{k}\\right)\\right)\\right]\n$$\n\nBy Lemma C.1, we can write\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[V\\left(Z_{-m, 0}^{x, \\mathbf{Y}}\\right) \\prod_{k=0}^{n-1} \\gamma\\left(Y_{k}\\right) \\mid \\mathcal{F}_{-\\infty, \\infty}^{Y}\\right] & =[Q\\left(Y_{-1}\\right) \\ldots Q\\left(Y_{-m}\\right) V](x) \\prod_{k=0}^{n-1} \\gamma\\left(Y_{k}\\right) \\\\\n& \\leq V(x) \\prod_{r=-m}^{n-1} \\gamma\\left(Y_{r}\\right)+\\sum_{r=-m}^{-1} K\\left(Y_{r}\\right) \\prod_{j=r+1}^{n-1} \\gamma\\left(Y_{j}\\right)\n\\end{aligned}\n$$\n\nthus by the tower rule, we have\n\n$$\n\\mathbb{E}\\left[\\min \\left(M, V\\left(Z_{-m, 0}^{x, \\mathbf{Y}}\\right) \\prod_{k=0}^{n-1} \\gamma\\left(Y_{k}\\right)\\right)\\right] \\leq V(x) \\mathbb{E}\\left[\\prod_{r=-m}^{n-1} \\gamma\\left(Y_{r}\\right)\\right]+\\sum_{r=-m}^{-1} \\mathbb{E}\\left[K\\left(Y_{r}\\right) \\prod_{j=r+1}^{n-1} \\gamma\\left(Y_{j}\\right)\\right]\n$$\n\nBy Assumtion 2.2, for any fixed $\\bar{\\gamma}<\\gamma^{\\prime}<1$, exists $N \\in \\mathbb{N}$ such that\n\n$$\n\\mathbb{E}\\left(K\\left(Y_{0}\\right) \\prod_{j=1}^{n} \\gamma\\left(Y_{j}\\right)\\right) \\leq\\left(\\gamma^{\\prime}\\right)^{n}, n \\geq N\n$$\n\nand thus we can further estimate the right-hand side in (47) as follows:\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[\\min \\left(M, V\\left(Z_{-m, 0}^{x, \\mathbf{Y}}\\right) \\prod_{k=0}^{n-1} \\gamma\\left(Y_{k}\\right)\\right)\\right] & \\leq V(x)\\left(\\gamma^{\\prime}\\right)^{n+m}+\\sum_{r=-m}^{-1}\\left(\\gamma^{\\prime}\\right)^{n-1-r} \\\\\n& \\leq V(x)\\left(\\gamma^{\\prime}\\right)^{n+m}+\\frac{\\left(\\gamma^{\\prime}\\right)^{n}}{1-\\gamma^{\\prime}}\n\\end{aligned}\n$$\n\nSubstituting this estimate back into (46) yields\n\n$$\n\\limsup _{n \\rightarrow \\infty} \\mathbb{E}^{1 / n}\\left[V\\left(X_{0}^{*}\\right) \\prod_{k=0}^{n-1} \\gamma\\left(Y_{k}\\right)\\right] \\leq \\gamma^{\\prime}\n$$\n\nNow, taking the limit $\\gamma^{\\prime} \\downarrow \\bar{\\gamma}$ gives the desired inequality.\n\nProof of Theorem 2.7. We consider the processes $Z_{0, n}^{X_{0}, \\mathbf{Y}}$ and $Z_{0, n}^{X_{0}^{\\prime}, \\mathbf{Y}}, n \\in \\mathbb{N}$, where the latter is a version of $\\left(X_{n}^{\\prime}\\right)_{n \\in \\mathbb{N}}$. For the coupling time, along similar lines as in the proof of Lemma 2.4, by using Lemma C.3, we obtain\n\n$$\n\\begin{aligned}\n\\mathbb{P}(\\tau>n) & \\leq \\mathbb{P}\\left(Z_{0, n}^{X_{0}, \\mathbf{Y}} \\neq Z_{0, n}^{X_{0}^{\\prime}, \\mathbf{Y}}\\right) \\\\\n& \\leq \\bar{\\beta}^{m}+\\frac{(1+r)^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor}}{2} \\mathbb{E}\\left[\\left(\\mathbb{E}\\left[V\\left(X_{0}^{*}\\right) \\mid \\mathcal{F}_{-\\infty, \\infty}^{Y}\\right]+\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)\\right) \\prod_{r=0}^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\gamma\\left(Y_{r}\\right)\\right] \\\\\n& +(1+r)^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\sum_{k=0}^{m-1} \\sum_{l=k}^{k\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\mathbb{E}\\left[K\\left(Y_{l}\\right) \\prod_{r=1}^{\\left\\lfloor\\frac{n-1}{m}\\right\\rfloor} \\gamma\\left(Y_{l+r}\\right)\\right]\n\\end{aligned}\n$$\n\nwhere $0<m<n$. Again, as in the proof of Lemma 2.4, let us fix $m_{n}=\\frac{n-1}{\\left[n^{1 / 2}\\right]-1}, n>1$, and $\\gamma^{\\prime}>\\bar{\\gamma}$ such that $\\bar{\\gamma}:=(1+r) \\gamma^{\\prime}<1$. By Assumption 2.2 and Lemma C.4, we can choose $N \\in \\mathbb{N}$ be so large that such that\n\n$$\n\\mathbb{E}\\left[K\\left(Y_{0}\\right) \\prod_{k=1}^{n} \\gamma\\left(Y_{k}\\right)\\right] \\leq\\left(\\gamma^{\\prime}\\right)^{n} \\text { and } \\mathbb{E}\\left[V\\left(X_{0}^{*}\\right) \\prod_{k=0}^{n-1} \\gamma\\left(Y_{k}\\right)\\right] \\leq\\left(\\gamma^{\\prime}\\right)^{n}, n \\geq N\n$$\n\nFor $\\left\\lfloor n^{1 / 2}\\right\\rfloor \\geq N$, we have\n\n$$\n\\begin{aligned}\n\\mathbb{P}(\\tau \\geq n) & \\leq \\bar{\\beta}^{\\left\\lfloor n^{1 / 2}\\right\\rfloor}+\\frac{(1+r)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1}}{2}\\left(1+\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)\\right)\\left(\\gamma^{\\prime}\\right)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor} \\\\\n& +(1+r)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1} \\sum_{k=0}^{m_{n}-1} \\sum_{l=k}^{k\\left(\\left\\lfloor n^{1 / 2}\\right\\rfloor-1\\right)}\\left(\\gamma^{\\prime}\\right)^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1} \\\\\n& \\leq \\bar{\\beta}^{\\left\\lfloor n^{1 / 2}\\right\\rfloor}+\\frac{1+\\mathbb{E}\\left(V\\left(X_{0}\\right)\\right)}{2} \\bar{\\gamma}^{\\left\\lfloor n^{1 / 2}\\right\\rfloor}+\\bar{\\gamma}^{\\left\\lfloor n^{1 / 2}\\right\\rfloor-1} \\sum_{k=0}^{m_{n}-1}\\left(k\\left(\\left\\lfloor n^{1 / 2}\\right\\rfloor-2\\right)+1\\right)\n\\end{aligned}\n$$\n\nwhere $\\sum_{k=0}^{m_{n}-1}\\left(k\\left(\\left\\lfloor n^{1 / 2}\\right\\rfloor-2\\right)+1\\right)=O\\left(n^{3 / 2}\\right)$ which completes the proof.", "tables": {}, "images": {}}], "id": "2410.05056v3", "authors": ["Attila Lovas"], "categories": ["math.ST", "cs.AI", "math.PR", "stat.TH"], "abstract": "Nonlinear time series models with exogenous regressors are essential in\neconometrics, queuing theory, and machine learning, though their statistical\nanalysis remains incomplete. Key results, such as the law of large numbers and\nthe functional central limit theorem, are known for weakly dependent variables.\nWe demonstrate the transfer of mixing properties from the exogenous regressor\nto the response via coupling arguments. Additionally, we study Markov chains in\nrandom environments with drift and minorization conditions, even under\nnon-stationary environments with favorable mixing properties, and apply this\nframework to single-server queuing models.", "updated": "2025-04-22T15:01:48Z", "published": "2024-10-07T14:13:37Z"}