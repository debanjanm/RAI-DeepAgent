{
  "title": "An Adaptive Importance Sampling for Locally Stable Point Processes",
  "sections": [
    {
      "section_id": 0,
      "text": "#### Abstract\n\nThe problem of finding the expected value of a statistic of a locally stable point process in a bounded region is addressed. We propose an adaptive importance sampling for solving the problem. In our proposal, we restrict the importance point process to the family of homogeneous Poisson point processes, which enables us to generate quickly independent samples of the importance point process. The optimal intensity of the importance point process is found by applying the crossentropy minimization method. In the proposed scheme, the expected value of the statistic and the optimal intensity are iteratively estimated in an adaptive manner. We show that the proposed estimator converges to the target value almost surely, and prove the asymptotic normality of it. We explain how to apply the proposed scheme to the estimation of the intensity of a stationary pairwise interaction point process. The performance of the proposed scheme is compared numerically with Markov chain Monte Carlo simulation and perfect sampling.\n\n\nKeywords: locally stable point process, pairwise interaction point process, Monte Carlo method, adaptive importance sampling, cross entropy minimization",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 1,
      "text": "## Statements and Declarations\n\nConflicts of interest All authors declare that they have no conflicts of interest.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 2,
      "text": "# 1 Introduction \n\nStationary pairwise interaction point processes are important stochastic models in the study of spatial point patterns (Baddeley et al. (2016)). The summary characteristics such as the intensity and higher moments are usually unknown. Such statistic can be estimated by restricting the process to a sufficiently large bounded region (Baddeley et al. (2016), Illian et al. (2008)). The probability density function (pdf) of a finite pairwise interaction point process is usually known up to constant. In order to find the explicit form of the normalization constant, the intensity, or some higher moments, we need to integrate a function of the point process with respect to the unnormalized pdf, which is not an easy task. The same is the case with locally stable point processes which are general point processes including stationary interaction point processes. The pdf of a locally stable point process in a bounded region is also usually known up to constant, and it is hard to find the explicit form of the normalization constant and the expected value of a statistic of the locally stable point process. Instead of finding exactly the integral value, one can resort to Monte Carlo methods such as Markov chain Monte Carlo and perfect sampling (M\u00f8ller and Waagepetersen (2003)).\n\nIn this paper, we propose an adaptive importance sampling for finding the expected value of a statistic of a locally stable point process or a real-valued function of a locally stable point process in a bounded region. By restricting the importance sampling point process to the family of homogeneous Poisson point processes in our proposal, we can quickly generate sample point processes. The optimal intensity of the importance point process is found by applying the cross-entropy minimization method. In the proposed scheme, the expected value of the function and the optimal intensity are iteratively estimated in an adaptive manner. We show that the proposed estimator converges to the target value almost surely, and prove the asymptotic normality of it.\n\nAnderssen et al. (2014) and Baddeley and Nair (2012) proposed the Poissonsaddlepoint approximation method to approximate the intensity of a stationary Gibbs point process. The method was extended to the case of a stationary Gibbs point process with any order by Baddeley and Nair (2017). In order to obtain sample point processes following the pdf of a locally stable point process, Markov chain Monte Carlo (MCMC) methods were proposed. Geyer and M\u00f8ller (1994) and M\u00f8ller (1999) proposed the birth-death Metropolis-Hastings algorithm. Kelly and Ripley (1976) and Ripley (1977) proposed a spatial birth and death process. However, these methods may suffer from the slow convergence to the stationary distribution and a strong autocorrelation existing in generated sample point processes, which leads to a large number of samples required to obtain an accurate estimate to the target value. In order to obtain a random samples from the target distribution, perfect sampling is proposed (Robert et al. (1999)). It has been studied to apply perfect sampling to generate independent samples following exactly the pdf of a locally stable point process. To this end, Kendall and M\u00f8ller (2000a; 2000b) gave a general formulation of the method of dominated coupling from the past (CFTP) and applied it to the problem of perfect sampling of locally stable point processes. However, it takes a very long time to generate samples of point processes by applying perfect sampling (M\u00f8ller and Waagepetersen (2003)).\n\nImportance sampling is a Monte Carlo method to estimate the integral value of a function with respect to the nominal distribution (Robert and Casella (1999),\n\nRubinstein and Kroese (2016)). Instead of generating samples following the nominal distribution, it generates samples from an appropriately selected distribution called an importance sampling distribution. By restricting the importance sampling distribution to a parametric family of distributions, one can find the optimal parameter of the importance sampling distribution. Variance minimization and cross-entropy minimization methods are used generally to find the optimal parameter (De Boer et al. (2005)). However, in many situations, it is difficult to find the optimal parameter explicitly, or it needs a large number of samples to estimate it accurately. Starting from a somewhat arbitrary parameter, adaptive importance sampling adjusts the parameter of the importance sampling distribution during the sampling process (Bugallo et al. (2017)). In adaptive importance sampling, the importance sampling distribution is updated iteratively, and generates more samples of higher importance. In this way, the efficiency of the estimation continues to improve with each iteration. Oh and Berger (1992) showed the convergence of the adaptive importance sampling estimator to the target value and the asymptotic normality of it. We extend their results to the case of locally stable point processes defined in a bounded region.\n\nThis paper is organized as follows. In Section 2, we describe the birth-death Metropolis-Hastings algorithm and the dominated CFTP algorithm to estimate the expected value of a function of a locally stable point process in a bounded region. We introduce our proposed estimator, and prove some asymptotic properties of it in Sections 3 and 4. We explain how to apply the proposed scheme to estimate the intensity of a stationary pairwise interaction point process in Section 5. In Section 6, the performance of the proposed scheme is compared numerically with the birth-death Metropolis-Hastings simulation and the perfect sampling. In the latter simulation, point processes are generated by the dominated CFTP algorithm. Finally, we conclude the paper in Section 7.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 3,
      "text": "# 2 Monte Carlo methods for locally stable point processes \n\nSuppose that $S$ is a bounded region on $\\mathbb{R}^{d}$. A point process on $S$ is a set of random number of points randomly located on $S$. A simple point process on $S$ is a homogeneous Poisson point process, which is a completely random point process on $S$ in the sense that the points of the process occur independently of one another. If $X$ is the homogeneous Poisson point process with intensity $\\rho(\\rho>0)$ on $S$, then for a subregion $A$ of $S$, the number of points of $X$ belonging to $A$ follows the Poisson distribution with mean $\\rho|A|$, where $|A|$ is the volume or the Lebesgue measure of $A$. For a collection of disjoint subregions of $S$, the number of points of $X$ belonging to a subregion is independent with those of other subregions. In the case of $\\rho=1$, it is called the standard homogeneous Poisson point process.\n\nWe call a set of finite points on $S$ a point pattern, and denote by $\\mathcal{N}$ the collection of point patterns on $S$, i.e. $\\mathcal{N}=\\{x \\subset S ; n(x)<\\infty\\}$, where $n(x)$ is the number of\n\npoints of $x$. Then, $\\mathcal{N}$ is also represented as follows:\n\n$$\n\\mathcal{N}=\\bigcup_{n=0}^{\\infty} S^{n}\n$$\n\nwhere $S^{n}=S \\times \\cdots \\times S$, the $n$-fold Cartesian product of $S$ with itself, and $S^{0}$ is the empty set $\\emptyset$.\n\nLet $X$ be the homogeneous Poisson point process with intensity $\\rho$ on $S$. Then, the probability density function (pdf) of $X$ is as follows:\n\n$$\nf_{P}(x ; \\rho)=\\frac{\\rho^{n(x)} e^{-\\rho|S|}}{n(x)!}, \\quad x \\in \\mathcal{N}\n$$\n\nWe can see that $f_{P}(x ; \\rho)$ does not depend on $x$, but depends on $n(x)$, and that if the number of points of $X$ is given, then the points of $X$ are uniformly distributed on $S$, and their locations are mutually independent.\n\nThe pdf $f_{P}(\\cdot ; \\rho)$ in Eq (1) induces a probability measure on $\\mathcal{N}$, i.e. $\\operatorname{Pr}(X \\in d x)=$ $f_{P}(x ; \\rho) d x, x \\in \\mathcal{N}$. Then, it follows that for $\\mathcal{A} \\subset \\mathcal{N}$,\n\n$$\n\\operatorname{Pr}(X \\in \\mathcal{A})=\\sum_{n=0}^{\\infty} \\frac{\\rho^{n} e^{-\\rho|S|}}{n!} \\int_{S^{n}} I_{\\mathcal{A}}(x) d x\n$$\n\nwhere $I_{\\mathcal{A}}(x)$ is the indicator function of $\\mathcal{A}$. In the above equation, $\\int_{S^{n}} I_{\\mathcal{A}}(x) d x$ is defined to be 1 if $\\mathcal{A}$ contains the empty set. We denote by $\\operatorname{Poi}(S, \\rho)$ the probability measure defined in Eq (2), and call that a point process $X$ follows $\\operatorname{Poi}(S, \\rho)$ if $X$ satisfies Eq (2).\n\nFor a point process $X$ on $S$, the pdf of $X$ with respect to $\\operatorname{Poi}(S, 1)$ is defined as a function $f$ on $\\mathcal{N}$ satisfying that for $\\mathcal{A} \\subset \\mathcal{N}$,\n\n$$\n\\operatorname{Pr}(X \\in \\mathcal{A})=\\sum_{n=0}^{\\infty} \\frac{e^{-|S|}}{n!} \\int_{S^{n}} I_{\\mathcal{A}}(x) f(x) d x\n$$\n\nDue to Eq (2), the above equation can be rewritten as follows: for $Y$ the standard homogeneous Poisson point process on $S$,\n\n$$\n\\operatorname{Pr}(X \\in \\mathcal{A})=E[I(Y \\in \\mathcal{A}) f(Y)], \\quad \\mathcal{A} \\subset \\mathcal{N}\n$$\n\nWe assume that $f(x)$ has the following form:\n\n$$\nf(x)=\\frac{1}{c_{f}} h(x), x \\in \\mathcal{N}\n$$\n\nwhere $h(\\emptyset)=1$ for the empty set $\\emptyset$. By substituting $\\mathcal{N}$ for $\\mathcal{A}$ in Eq (4), we have that\n\n$$\nc_{f}=E[h(Y)]\n$$\n\nWe also assume that the normalizing constant $c_{f}$ is unknown.\nThe Papangelou conditional intensity of $X$ is defined as\n\n$$\n\\lambda_{f}(x, \\xi)=\\frac{f(x \\cup \\xi)}{f(x)}, \\quad x \\in \\mathcal{N}, \\xi \\in S \\backslash x\n$$\n\n$\\lambda_{f}(x, \\xi)$ can be considered as the ratio of the point patterns of $x \\cup \\xi$ to $x$ in a huge collection of random copies of $X$ with pdf $f . \\lambda_{f}(x, \\xi)$ represents the intensity that $\\xi$ will occur additionally given that the rest of $X$ is $x$. Note that the Papangelou conditional intensity does not depend on $c_{f}$.\n\nIf $\\lambda_{f}(x, \\xi)$ is bounded by an integrable function of $\\xi$, i.e. for a function $\\phi$ defined on $S$ such that $\\int_{S} \\phi(\\xi) d \\xi<\\infty$,\n\n$$\n\\lambda_{f}(x, \\xi) \\leq \\phi(\\xi), \\quad x \\in \\mathcal{N}, \\xi \\in S \\backslash x\n$$\n\nthen $f$ is said to be $\\phi$-locally stable, and the point process with pdf $f$ is said to be locally stable. In order for the pdf $f$ in Eq (5) to be well-defined, $c_{f}$ should be finite. In this case, it follows from Eq (3) that $f$ induces a probability measure on $\\mathcal{N}$ with respect to $\\operatorname{Poi}(S, 1)$. A sufficient condition for $c_{f}$ to be finite is that $X$ is locally stable (M\u00f8ller and Waagepetersen, 2003, Chapter 6.1).\n\nA particular example of a locally stable point process is the stationary Strauss point process (Strauss (1975)). Let $X$ be a finite stationary Strauss point process on $S$, and let $R$ be the range of interaction of $X$. Then, the pdf $X$ with respect to $\\operatorname{Poi}(S, 1)$ is as follows: for $\\beta>0,0 \\leq \\gamma \\leq 1$, and $R>0$,\n\n$$\nf(x ; \\beta, \\gamma, R) \\propto \\beta^{n(x)} \\gamma^{D(x)}, \\quad x \\in \\mathcal{N}\n$$\n\nwhere $D(x)=\\sum_{\\{\\xi, \\eta\\} \\subseteq x} I(\\|\\xi-\\eta\\| \\leq R)$. In the above pdf, $\\beta$ controls how dense $X$ is, and $\\gamma$ controls how regular $X$ is. If $\\gamma=0$, the process is called the hard-core process. If $\\gamma=1$, the process is equivalent to the homogeneous Poisson point process with intensity $\\beta$.\n\nApplying the pdf (9) to Eq (7) gives that the Papangelou conditional intensity of $X$ is\n\n$$\n\\lambda_{f}(x, \\xi)=\\beta \\gamma^{\\sum_{\\eta \\in x} I(\\|\\xi-\\eta\\| \\leq R)}, \\quad x \\in \\mathcal{N}, \\xi \\in S \\backslash x\n$$\n\nSince $0 \\leq \\gamma \\leq 1$, it satisfies that $\\lambda_{f}(x, \\xi) \\leq \\beta$. It implies that a finite stationary Strauss point process is locally stable.\n\nFigure 1 illustrates the realizations of stationary Strauss point processes on unit square with varying values of the parameters $\\beta, \\gamma$, and $R$. The left two panels in the figure show that the more points occurred with increased value of $\\beta$. By comparing top two panels, we can see that the distance between two neighboring points has decreased by increasing the value of $\\gamma$ from 0.2 to 0.8 . In the two panels in the bottom of the figure, the range of interactions is 0.1 for the left, and 0.025 for the right. We can see that decreasing the range of interaction also resulted in decreasing the distance between two neighboring points.\n\nWe consider a locally stable point process $X$ on $S$. We assume that $f$, the pdf of $X$, is $\\phi$-locally stable for an integrable function $\\phi$ on $S$. For a real-valued function\n\n![img-0.jpeg](img-0.jpeg)\n\nFig. 1: Realizations of stationary Strauss point processes on the unit square with varying values of the parameters $\\beta, \\gamma, R$.\n$K$ defined on $\\mathcal{N}$, we will denote by $E_{f}[K(X)]$ the expected value of $K(X)$. Let $\\mu=$ $E_{f}[K(X)]$. It follows from Eq (3) that\n\n$$\n\\mu=\\sum_{n=0}^{\\infty} \\frac{e^{-|S|}{n!} \\int_{S^{n}} K(x) f(x) d x\n$$\n\nequivalently,\n\n$$\n\\mu=E[K(X) f(X)]\n$$\n\nwhere $E[\\cdot]$ is the expectation with respect to $\\operatorname{Poi}(S, 1)$. It follows from Eqs (5) and (6) that\n\n$$\n\\mu=\\frac{E[K(X) h(X)]}{E[h(X)]}\n$$\n\nIn what follows, we assume that\n\n$$\nE_{f}\\left[K^{2}(X)\\right]<\\infty\n$$\n\nand that\n\n$$\nE_{f}\\left[n^{2}(X)\\right]<\\infty\n$$",
      "tables": {},
      "images": {
        "img-0.jpeg": "data:image/jpeg;base64,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"
      }
    },
    {
      "section_id": 4,
      "text": "# 2.1 Metropolis-Hastings algorithm for the estimation of $E_{f}[K(X)]$ \n\nThe birth-death Metropolis-Hastings algorithm is a type of Metropolis-Hastings algorithm for generating samples of a locally stable point process (M\u00f8ller and Waagepetersen, 2003). In this algorithm, samples of point processes following a given pdf $f$ which is $\\phi$-locally stable are sequentially generated.\n\nAt the initial step, we may generate a point pattern following a homogeneous Poisson point process with an appropriate intensity. Suppose that we have generated $X_{n}$, the point process at the $n$-th step. Then, $X_{n+1}$ is generated by adding a point to $X_{n}$, deleting a point from $X_{n}$, or keeping $X_{n}$ the same. The first is called a birth of a point, and the second a death of a point. Either of a birth or a death is proposed at each step. If $X_{n}=\\emptyset$, then only a birth proposal is possible. Let $p$ be the probability of proposing a birth. Suppose that $X_{n}=x$. If a birth of a point is proposed in this step, then we generate a point $\\xi$ with pdf $q_{b}(x, \\xi)=\\phi(\\xi) / c^{*}$, where $c^{*}=\\int_{S} \\phi(\\xi) d \\xi$, as the candidate to be added. If a death of a point from $x$ is proposed, then we choose each point belonging to $x$ uniformly as the candidate to be deleted, i.e. $q_{d}(x, \\eta)=1 / n(x)$ is the probability mass function for choosing a point $\\eta \\in x$ in a death proposal.\n\nIn the case of the birth proposal, we compute the acceptance ratio of the birth of $\\xi$ given by\n\n$$\nr_{b}(x, \\xi)=\\frac{\\lambda_{f}(x, \\xi) q_{d}(x \\cup \\xi)(1-p)}{q_{b}(x, \\xi) p}\n$$\n\nand let $X_{n+1}=X_{n} \\cup \\xi$ with probability $\\min \\left\\{1, r_{b}(x, \\xi)\\right\\}$, and $X_{n+1}=X_{n}$ with probability $1-\\min \\left\\{1, r_{b}(x, \\xi)\\right\\}$. In the other case, we compute the acceptance ratio of the death of $\\eta$ given by\n\n$$\nr_{d}(x, \\eta)=\\frac{1}{r_{b}(x \\backslash \\eta, \\eta)}\n$$\n\nand let $X_{n+1}=X_{n} \\backslash \\eta$ with probability $\\min \\left\\{1, r_{d}(x, \\eta)\\right\\}$, and $X_{n+1}=X_{n}$ with probability $1-\\min \\left\\{1, r_{d}(x, \\eta)\\right\\}$.\n\nWhen a sequence of samples $\\left\\{X_{1}, X_{2}, \\ldots, X_{n}\\right\\}$ is generated by the birth-death Metropolis-Hastings algorithm described above, they are dependent on each other, and do not follow $f$ exactly, but their stationary pdf is $f$. We remove some initial samples from $\\left\\{X_{1}, X_{2}, \\ldots, X_{n}\\right\\}$ that may not follow the stationary distribution. We apply subsampling from the remaining samples at fixed intervals to reduce the dependence between successive samples.\n\nLet $Y_{1}, Y_{2}, \\ldots, Y_{n}$ be the resulting samples. Then, they are near independent with stationary pdf $f$. The sample mean of $K\\left(Y_{1}\\right), K\\left(Y_{2}\\right), \\ldots, K\\left(Y_{n}\\right)$ is an estimator of $\\mu$. We denote it by $\\hat{\\mu}_{\\mathrm{MH}}$, i.e,\n\n$$\n\\hat{\\mu}_{\\mathrm{MH}}=\\frac{1}{n} \\sum_{i=1}^{n} K\\left(Y_{i}\\right)\n$$\n\nWe denote by MH method the sampling scheme described above.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 5,
      "text": "### 2.2 Perfect sampling for the estimation of $E_{f}[K(X)]$\n\nThe dominated coupling from the past (CFTP) algorithm is a perfect sampling for generating random samples of a locally stable point process with pdf $f$ on a bounded\n\nregion $S$ (Kendall and M\u00f8ller, 2000a,b). This algorithm constructs the backward step to generate a birth-death process and the forward step to update the dominating processes in reverse order of the birth-death process. To reduce the computational time, we employ the doubling scheme introduced by Propp and Wilson (1996). We denote the upper process as $U$ and the lower process as $L$, which are the dominating processes. Let $c^{*}=\\int_{\\mathcal{S}} \\phi(\\xi) d \\xi$ where $\\phi(\\cdot)$ is a $\\phi$-function in Eq (8).\n\nThe CFTP algorithm with doubling scheme proceeds as follows.\n\n1. At the initial stage, we generate $X_{0} \\sim \\operatorname{Poi}(S, \\phi(\\xi))$. If $X_{0}=\\emptyset$, then we return $\\emptyset$, and stop the procedure. Otherwise, at each stage $j=1,2, \\ldots$, we first execute the backward step, and then the forward step, which are described below. Set $T_{0}=0$, $T_{j}=2^{j-1}$ for $j=1,2, \\ldots$\n2. In the backward step of the $j$-th stage, we initialize $X_{-T_{j-1}}$ as the starting point process, and sequentially generate $X_{t}$ from time $-T_{j-1}-1$ to $-T_{j}$. For $t \\in\\left\\{-T_{j-1}, \\ldots,-T_{j}+1\\right\\}$, the death of a point in $X_{t}$ is proposed with probability $1-c^{*} /\\left(c^{*}+n\\left(X_{t}\\right)\\right)$. In this case, we randomly choose $\\xi_{t-1} \\in X_{t}$, and set $X_{t-1}=X_{t} \\backslash \\xi_{t-1}$. We also assign a uniform random variable $R_{t-1}$ on $[0,1]$ to the point $\\xi_{t-1}$. Otherwise, we generate a point $\\eta_{t-1}$ from $\\operatorname{pdf} \\phi(\\eta) / c^{*}$, and set $X_{t-1}=X_{t} \\cup \\eta_{t-1}$.\n3. In the forward step of the $j$-th stage, we update sequentially the upper and the lower processes from time $-T_{j}$ to -1 . Let $U_{-T_{j}}^{t}$ and $L_{-T_{j}}^{t}$ be the upper and lower processes of $X_{t}$, respectively. At time $-T_{j}$, we initialize $U_{-T_{j}}^{-T_{j}}=X_{-T_{j}}$ and $L_{-T_{j}}^{-T_{j}}=\\emptyset$. If the death of a point was proposed at time $t \\in\\left\\{-T_{j}, \\ldots,-1\\right\\}$ in the backward step, i.e., $X_{t+1} \\backslash \\xi_{t}=X_{t}$, then the upper and lower processes are updated as follows:\n\n$$\nU_{-T_{j}}^{t+1}=\\left\\{\\begin{array}{cl}\nU_{-T_{j}}^{t} \\cup \\xi_{t} & \\text { if } R_{t} \\leq r_{U} \\\\\nU_{-T_{j}}^{t} & \\text { otherwise }\n\\end{array}\\right.\n$$\n\nand\n\n$$\nL_{-T_{j}}^{t+1}=\\left\\{\\begin{array}{cl}\nL_{-T_{j}}^{t} \\cup \\xi_{t} & \\text { if } R_{t} \\leq r_{L} \\\\\nL_{-T_{j}}^{t} & \\text { otherwise }\n\\end{array}\\right.\n$$\n\nwhere $r_{U}=\\lambda_{f}\\left(L_{-T_{j}}^{t}, \\xi_{t}\\right) / \\phi\\left(\\xi_{t}\\right), r_{L}=\\lambda_{f}\\left(U_{-T_{j}}^{t}, \\xi_{t}\\right) / \\phi\\left(\\xi_{t}\\right)$, and $R_{t}$ is the uniform random variable assigned to $\\xi_{t}$ in the backward step. Otherwise (i.e., $X_{t+1} \\cup \\eta_{t}=$ $X_{t}$ ), the processes are updated as $U_{-T_{j}}^{t+1}=U_{-T_{j}}^{t} \\backslash \\eta_{t}$ and $L_{-T_{j}}^{t+1}=L_{-T_{j}}^{t} \\backslash \\eta_{t}$.\n4. If $U_{-T_{j}}^{0}=L_{-T_{j}}^{0}$, then we return $U_{-T_{j}}^{0}$. Otherwise, we go to the next stage with setting $j \\leftarrow j+1$. We repeat the above procedure until $U_{-T_{j}}^{0}=L_{-T_{j}}^{t}$ is satisfied.\nLet $X_{1}, X_{2}, \\ldots, X_{n}$ be the samples generated by applying the dominated CFTP algorithm with the doubling scheme. Then, an estimator of $\\mu$ is given by\n\n$$\n\\hat{\\mu}_{\\mathrm{CFTP}}=\\frac{1}{n} \\sum_{i=1}^{n} K\\left(X_{i}\\right)\n$$\n\nThe CFTP estimator in Eq (15) gives a more reliable estimate to $\\mu$ than $\\hat{\\mu}_{\\mathrm{MH}}$ in terms of variance reduction. We denote by CFTP method the sampling scheme described above.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 6,
      "text": "# 3 The proposed estimator\n### 3.1 Importance sampling for the estimation of $E_{f}[K(X)]$\n\nSuppose that $g(x)$ is an importance sampling pdf of $X$, and that it dominates the nominal pdf $f$, i.e. $f(x)>0$ implies $g(x)>0$. It follows from Eq (11) that\n\n$$\n\\mu=\\frac{E_{g}[K(X) w(X)]}{E_{g}[w(X)]}\n$$\n\nwhere $w(x)$ is the unnormalized likelihood ratio of sample $x$, i.e.\n\n$$\nw(x)=\\frac{h(x)}{g(x)}\n$$\n\nIn Hesterberg (1995), if $X_{1}, \\ldots, X_{n}$ are samples from the importance sampling pdf $g(x)$, then the self-normalized importance sampling estimator of $\\mu$ is given as\n\n$$\n\\hat{\\mu}_{\\mathrm{IS}}=\\frac{\\sum_{i=1}^{n} K\\left(X_{i}\\right) w\\left(X_{i}\\right)}{\\sum_{i=1}^{n} w\\left(X_{i}\\right)}\n$$\n\nClearly, $\\hat{\\mu}_{\\mathrm{IS}}$ converges to $\\mu$ with probability 1 as $n$ goes to the infinity (Owen (2013)). Under additional assumptions, the central limit theorem for $\\hat{\\mu}_{\\mathrm{IS}}$ was obtained by Geweke (1989).\n\nAccording to Oh and Berger (1992) and Owen (2013), an approximate variance of $\\hat{\\mu}_{\\mathrm{IS}}$ is given by $\\sigma^{2} / n$, where\n\n$$\n\\sigma^{2}=\\frac{E_{g}\\left[(K(X)-\\mu)^{2} w(X)^{2}\\right]}{E_{g}[w(X)]^{2}}\n$$\n\nor equivalently\n\n$$\n\\sigma^{2}=\\frac{\\operatorname{Var}_{g}[K(X) w(X)]-2 \\mu \\operatorname{Cov}_{g}\\left[K(X) w(X), w(X)\\right]+\\mu^{2} \\operatorname{Var}_{g}[w(X)]}{E_{g}[w(X)]^{2}}\n$$\n\nwhere $\\operatorname{Var}_{g}[\\cdot]$ and $\\operatorname{Cov}_{g}[\\cdot, \\cdot]$ mean the variance and the covariance with respect to pdf $g(x)$, respectively. The value of $\\sigma^{2}$ is estimated by\n\n$$\n\\begin{aligned}\n\\hat{\\sigma}^{2} & =\\frac{n \\sum_{i=1}^{n}\\left(K\\left(X_{i}\\right)-\\hat{\\mu}\\right)^{2} w\\left(X_{i}\\right)^{2}}{\\left(\\sum_{i=1}^{n} w\\left(X_{i}\\right)\\right)^{2}} \\\\\n& =\\frac{\\widehat{\\operatorname{Var}}_{g}[K(X) w(X)]-2 \\hat{\\mu} \\widehat{\\operatorname{Cov}}_{g}\\left[K(X) w(X), w(X)\\right]+\\hat{\\mu}^{2} \\widehat{\\operatorname{Var}}_{g}[w(X)]}{\\bar{w}^{2}}\n\\end{aligned}\n$$\n\nwhere\n\n$$\n\\begin{aligned}\n\\bar{w} & =\\frac{1}{n} \\sum_{i=1}^{n} w\\left(X_{i}\\right) \\\\\n\\widehat{\\operatorname{Var}}_{g}[K(X) w(X)] & =\\frac{1}{n} \\sum_{i=1}^{n} K^{2}\\left(X_{i}\\right) w^{2}\\left(X_{i}\\right)-\\hat{\\mu}^{2} \\bar{w}^{2} \\\\\n\\widehat{\\operatorname{Cov}}_{g}[K(X) w(X), w(X)] & =\\frac{1}{n} \\sum_{i=1}^{n} K\\left(X_{i}\\right) w^{2}\\left(X_{i}\\right)-\\hat{\\mu} \\bar{w}^{2} \\\\\n\\widehat{\\operatorname{Var}}_{g}[w(X)] & =\\frac{1}{n} \\sum_{i=1}^{n} w^{2}\\left(X_{i}\\right)-\\bar{w}^{2}\n\\end{aligned}\n$$\n\nLet $f^{*}(x)$ be the optimal importance sampling pdf for $\\hat{\\mu}_{\\mathrm{IS}}$ in terms of variance minimization. Hesterberg (1995) showed that\n\n$$\nf^{*}(x) \\propto|K(x)-\\mu| h(x), \\quad x \\in \\mathcal{N}\n$$\n\nSince the pdf $f^{*}(x)$ includes the unknown value $\\mu$, it can not be used as the importance sampling pdf.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 7,
      "text": "# 3.2 An adaptive importance sampling estimator \n\nIn our proposal, we restrict the point process of the importance samples to the family of homogeneous Poisson point processes on $S$. Suppose that $X$ follows $\\operatorname{Poi}(S, \\rho)$. Then, it follows from Eqs (2) and (3) that the pdf of $X$ with respect to $\\operatorname{Poi}(S, 1)$ is\n\n$$\ng(x ; \\rho)=\\exp ((1-\\rho)|S|) \\rho^{n(x)}, \\quad x \\in \\mathcal{N}\n$$\n\nThe value of intensity $\\rho$ minimizing the cross-entropy of $g(x ; \\rho)$ relative to $f^{*}(x)$ is found by solving the following optimization problem (Rubinstein and Kroese, 2016):\n\n$$\n\\underset{\\rho}{\\operatorname{maximize}} E_{f}[|K(X)-\\mu| \\log g(X ; \\rho)]\n$$\n\nFrom Eq (20), the above problem is rewritten as\n\n$$\n\\underset{\\rho}{\\operatorname{maximize}} E_{f}[|K(X)-\\mu|]|S|(1-\\rho)+E_{f}[n(X)|K(X)-\\mu|] \\log \\rho\n$$\n\nBy differentiating the objective function of the above problem with respect to $\\rho$, we obtain the solution to the above problem as follows:\n\n$$\n\\rho^{*}=\\frac{1}{|S|} \\frac{E_{f}[n(X)|K(X)-\\mu|]}{E_{f}[|K(X)-\\mu|]}\n$$\n\nSince $\\mu$ is unknown, it is not an easy task to get a consistent estimator of $\\rho^{*}$. If we knew the normalization constant $c_{f}$, then the optimal importance sampling pdf would be as follows (Rubinstein and Kroese, 2016, Chapter 5):\n\n$$\nf^{*}(x)=\\frac{|K(x)| h(x)}{c_{f}}, \\quad x \\in \\mathcal{N}\n$$\n\nThen, the value of intensity $\\rho$ minimizing the cross-entropy of $g(x ; \\rho)$ relative to $f^{*}(x)$ in the above equation is found by solving the following optimization problem instead of Eq (21):\n\n$$\n\\underset{\\rho}{\\operatorname{maximize}} E_{f}[|K(X)| \\log g(X ; \\rho)]\n$$\n\nIn the same manner as the above, it can be shown that the optimal intensity in this case is given by\n\n$$\n\\rho^{\\prime}=\\frac{1}{|S|} \\frac{E_{f}[n(X)|K(X)|]}{E_{f}[|K(X)|]}\n$$\n\nWe consider $\\rho^{\\prime}$ as a pseudo-optimal parameter of the importance sampling pdf $g(x ; \\rho)$. Eqs (12) and (13) show the existence of $\\rho^{\\prime}$.\n\nWe propose an adaptive importance sampling to estimate $\\mu$. In the proposed method, the value of $\\mu$ is estimated iteratively, and the importance sampling pdf at each step is a homogeneous Poisson process whose intensity converges to a value close to $\\rho^{\\prime}$. Let $\\hat{\\rho}_{t}, t=1,2, \\ldots$, be the estimator of $\\rho^{\\prime}$ at the $t$-th step. Then, we generate a number of $n_{t}$ samples of point processes independently from the importance sampling pdf $g\\left(x ; \\hat{\\rho}_{t-1}\\right)$ at the $t$-th step. In order to get a consistent estimator of $\\mu$, we restrict the value of $\\hat{\\rho}_{t}$ to the interval $\\left[m_{\\rho}, M_{\\rho}\\right]$ for a sufficiently small $m_{\\rho}$ and a sufficiently large $M_{\\rho}$. Initially, we choose $\\hat{\\rho}_{0} \\in\\left[m_{\\rho}, M_{\\rho}\\right]$.\n\nLet $X_{1}^{(t)}, \\ldots, X_{n_{t}}^{(t)}$ be the generated samples at the $t$-th step. The unnormalized likelihood ratio of $X_{i}^{(t)}$ is given by\n\n$$\nw_{t}\\left(X_{i}^{(t)}\\right)=\\frac{h\\left(X_{i}^{(t)}\\right)}{g\\left(X_{i}^{(t)} ; \\hat{\\rho}_{t-1}\\right)}\n$$\n\nThe estimator of $\\mu$ at the $t$-th step is given by\n\n$$\n\\hat{\\rho}_{t}=\\frac{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} K\\left(X_{i}^{(j)}\\right) w_{j}\\left(X_{i}^{(j)}\\right)}{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} w_{j}\\left(X_{i}^{(j)}\\right)}\n$$\n\nIf we set $\\hat{\\rho}_{t}$ to be the plug-in estimator of $\\rho^{\\prime}$ given in Eq (22), then it cannot be guaranteed that $\\hat{\\rho}_{t} \\in\\left[m_{\\rho}, M_{\\rho}\\right]$. Instead, we define $\\tilde{n}(x)$ as the truncated value of $n(x)$ with lower bound of $m_{\\rho}|S|$ and upper bound of $M_{\\rho}|S|$, and set\n\n$$\n\\hat{\\rho}_{t}=\\frac{1}{|S|} \\frac{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} \\tilde{n}\\left(X_{i}^{(j)}\\right)\\left|K\\left(X_{i}^{(j)}\\right)\\right| w_{j}\\left(X_{i}^{(j)}\\right)}{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}}\\left|K\\left(X_{i}^{(j)}\\right)\\right| w_{j}\\left(X_{i}^{(j)}\\right)}\n$$",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 8,
      "text": "# Algorithm 1 AIS for locally stable processes \n\nRequire: $h(x), K(x), m_{\\rho}, M_{\\rho},\\left\\{n_{1}, n_{2}, \\ldots\\right\\}, \\eta_{1}, \\eta_{2}$\nEnsure: $\\hat{\\mu}_{t}$\n\n1: Choose $\\hat{\\rho}_{0} \\in\\left[m_{\\rho}, M_{\\rho}\\right]$\n2: Set $t=1$\n3: repeat\n4: $\\quad$ Generate $X_{1}^{(t)}, X_{2}^{(t)}, \\ldots, X_{n_{t}}^{(t)}$ independently from $g\\left(x ; \\hat{\\rho}_{t-1}\\right)$\n5: Set $w_{t}\\left(X_{i}^{(t)}\\right)=\\frac{h\\left(X_{i}^{(t)}\\right)}{g\\left(X_{i}^{(t)} \\mid \\hat{\\rho}_{t-1}\\right)}$ for $i=1,2, \\ldots, n_{t}$\n6: Compute\n\n$$\n\\hat{\\mu}_{t}=\\frac{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} K\\left(X_{i}^{(j)}\\right) w_{j}\\left(X_{i}^{(j)}\\right)}{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} w_{j}\\left(X_{i}^{(j)}\\right)}\n$$\n\n7: Set $\\tilde{n}\\left(X_{i}^{(t)}\\right)=\\operatorname{median}\\left\\{m_{\\rho}|S|, n\\left(X_{i}^{(t)}\\right), M_{\\rho}|S|\\right\\}$ for $i=1,2, \\ldots, n_{t}$\n8: Compute\n\n$$\n\\hat{\\rho}_{t}=\\frac{1}{|S|} \\frac{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} \\tilde{n}\\left(X_{i}^{(j)}\\right)\\left|K\\left(X_{i}^{(j)}\\right)\\right| w_{j}\\left(X_{i}^{(j)}\\right)}{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}}\\left|K\\left(X_{i}^{(j)}\\right)\\right| w_{j}\\left(X_{i}^{(j)}\\right)}\n$$\n\n9: Set $n^{(t)}=\\sum_{j=1}^{t} n_{j}$\n10: Compute\n\n$$\n\\hat{\\sigma}_{t}^{2}=\\frac{n^{(t)} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}}\\left(K\\left(X_{i}^{(j)}\\right)-\\hat{\\mu}_{t}\\right)^{2} w_{j}^{2}\\left(X_{i}^{(j)}\\right)}{\\left(\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} w_{j}\\left(X_{i}^{(j)}\\right)\\right)^{2}}\n$$\n\n11: Set $t=t+1$\n12: until $\\frac{\\hat{\\sigma}_{t}^{2}}{n^{(t)} \\hat{\\mu}_{t}^{2}} \\leq \\eta_{1}$ and $\\frac{\\left|\\hat{\\rho}_{t}-\\hat{\\rho}_{t-1}\\right|}{\\hat{\\rho}_{t-1}} \\leq \\eta_{2}$\n13: Return $\\hat{\\mu}_{t}$\n\nThen, it can be easily checked that $\\hat{\\rho}_{t} \\in\\left[m_{\\rho}, M_{\\rho}\\right]$.\nWe denote by $n^{(t)}$ the number of samples of $X$ until the $t$-th step, i.e, $n^{(t)}=$ $\\sum_{j=1}^{t} n_{j}$. It follows from Eq (19) that the approximate variance of $\\hat{\\mu}_{t}$ is estimated as $\\hat{\\sigma}_{t}^{2} / n^{(t)}$, where\n\n$$\n\\hat{\\sigma}_{t}^{2}=\\frac{n^{(t)} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}}\\left(K\\left(X_{i}^{(j)}\\right)-\\hat{\\mu}_{t}\\right)^{2} w_{j}^{2}\\left(X_{i}^{(j)}\\right)}{\\left(\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} w_{j}\\left(X_{i}^{(j)}\\right)\\right)^{2}}\n$$\n\nThe iterative estimation of $\\mu$ and $\\rho^{\\prime}$ continues until both the following conditions are satisfied;\n\n$$\n\\frac{\\hat{\\sigma}_{t}^{2}}{n^{(t)} \\hat{\\mu}_{t}^{2}} \\leq \\eta_{1}\n$$\n\nand\n\n$$\n\\frac{\\left|\\hat{\\rho}_{t}-\\hat{\\rho}_{t-1}\\right|}{\\hat{\\rho}_{t-1}} \\leq \\eta_{2}\n$$\n\nThe value of $\\eta_{1}$ is determined as follows: for a sufficiently small $\\epsilon>0$,\n\n$$\n\\eta_{1}=\\left(\\frac{\\epsilon}{z_{\\alpha / 2}}\\right)^{2}\n$$\n\nwhere $z_{\\alpha / 2}$ is the $\\left(1-\\frac{\\alpha}{2}\\right)$ quantile of the standard normal distribution. The term in the left-hand side of Eq (26) is the squared relative standard error of $\\hat{\\mu}_{t}$. We determine the values of $\\epsilon$ and $\\alpha$ appropriately so that if the squared relative standard error is sufficiently small, then the iteration stops. A small constant is assigned as the value of $\\eta_{2}$ so that the sufficiently small change of $\\hat{\\rho}_{t}$ makes the iteration stop. The condition (26) can be considered as the condition on the relative error of $\\hat{\\mu}_{t}$ as well as on the relative standard error. It will be explained in Section 4.3 how the condition (26) regulates the relative error of the final estimate to $\\mu$, and how the values of $\\epsilon$ and $\\alpha$ are determined. Why we should consider the condition (27) as well as the condition (26) will be explained also in the section. Algorithm 1 shows the procedure to obtain the proposed estimator, which will be denoted by AIS estimator.\n\nWe assume that the sample sizes $n_{1}, n_{2}, \\ldots$, satisfy the following three conditions:\n\n$$\n\\begin{gathered}\n\\sup _{t \\geq 1} \\frac{t n_{t}}{n^{(t)}}<\\infty \\\\\n\\sup _{t \\geq 2} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t-1} j\\left|n_{j+1}-n_{j}\\right|<\\infty\n\\end{gathered}\n$$\n\nand\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{\\left(n^{(t)}\\right)^{2}} \\sum_{j=1}^{t} n_{j}^{2}=0\n$$\n\nUnder the conditions (28) and (29), Etemadi (2006, Theorem 1) showed that for a sequence of random variables $\\left\\{Y_{i}, i=1,2, \\ldots\\right\\}$, if $\\sum_{i=1}^{t} Y_{i} / t$ converges to a random variable $Y_{0}$ almost surely, then\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} n_{j} Y_{j}=Y_{0}, \\quad \\text { a.s. }\n$$\n\nThe above three conditions on the sample sizes combined with some other conditions on the functions $K$ and $\\phi$ guarantee the almost sure convergence of $\\left\\{\\hat{\\mu}_{t}, t=\\right.$ $1,2, \\ldots\\}$ to the target value $\\mu$, and also the asymptotic normality of it, which will be shown in the next section.\n\nAccording to Oh and Berger (1992), if the sample size in the first step is small, then the estimator $\\hat{\\mu}_{t}$ may have a large error, and it slows down the convergence of $\\hat{\\mu}_{t}$. Thus, we also assume that $n_{1}$ is sufficiently large in Algorithm 1.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 9,
      "text": "# 4 Asymptotic properties of the proposed estimator \n\nIn this section, we prove that both $\\left\\{\\hat{\\mu}_{t}, t=1,2, \\ldots\\right\\}$ and $\\left\\{\\hat{\\rho}_{t}, t=1,2, \\ldots\\right\\}$ converge almost surely, also prove the asymptotic normality of $\\left\\{\\hat{\\mu}_{t}, t=1,2, \\ldots\\right\\}$. In Section 4.1, we construct a martingale difference sequence of functionals of $\\left\\{X_{i}^{(j)}, j=1,2, \\ldots, i=\\right.$ $\\left.1, \\ldots, n_{j}\\right\\}$, and show the almost-sure convergence of it by applying the technique described in Feller (1991, Theorem 3, p.243). Then, it gives that the denominator and the nominator of $\\hat{\\mu}_{t}$ converge to $E[K(X) h(X)]$ and $E[h(X)]$ almost surely, respectively, which leads to the almost-sure convergence of $\\left\\{\\hat{\\mu}_{t}, t=1,2, \\ldots\\right\\}$ to $\\mu$. In the similar manner to this, we also show that $\\hat{\\rho}_{t}$ converges to a value close to $\\rho^{\\prime}$ almost surely. In Section 4.2, we construct a martingale triangular array of functionals of $\\left\\{X_{i}^{(j)}, j=1,2, \\ldots, i=1, \\ldots, n_{j}\\right\\}$, and show that the array is a zero-mean square integrable martingale, and converges to a normal random in distribution. As an immediate corollary, the asymptotic normality of $\\left\\{\\hat{\\mu}_{t}, t=1,2, \\ldots,\\right\\}$ follows. Proofs for these results are basically in the same line with Oh and Berger (1992).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 10,
      "text": "### 4.1 Convergence of the proposed estimator\n\nLet $\\mathcal{X}_{t}=\\left\\{X_{i}^{(t)}, i=1, \\ldots, n_{t}\\right\\}, t=1,2, \\ldots$, be the $n_{t}$ number of point processes generated at the $t$-th step in Algorithm 1. We define $\\mathcal{F}_{t}$ as the $\\sigma$-algebra generated by $\\left\\{\\mathcal{X}_{j}, j=1,2, \\ldots, t\\right\\}$. Then, $\\left\\{\\mathcal{F}_{t}, t=1,2, \\ldots\\right\\}$ is a filtration. We also define $\\mathcal{F}_{\\infty}$ as the smallest $\\sigma$-algebra containing $\\left\\{\\mathcal{F}_{t}, t=1,2, \\ldots\\right\\}$. Let $\\boldsymbol{Y}$ be the stochastic process $\\left\\{\\mathcal{X}_{1}, \\mathcal{X}_{2}, \\ldots\\right\\}$ of the generated point processes. We define $\\Omega$ as the set of the possible sample paths of $\\boldsymbol{Y}$, and define $G$ as the probability measure induced by $\\boldsymbol{Y}$. Then, $\\left(\\Omega, \\mathcal{F}_{\\infty}, G\\right)$ is a probability space.\n\nFor a $\\mathcal{F}_{\\infty}$-measurable function $H$, we denote by $E_{G}[H(\\boldsymbol{Y})]$ the expectation of $H(\\boldsymbol{Y})$ with respect to measure $G$, and by $E_{G}\\left[H(\\boldsymbol{Y}) \\mid \\mathcal{F}_{t}\\right]$ the conditional expectation of $H(\\boldsymbol{Y})$ with respect to $\\mathcal{F}_{t}$. Since $\\hat{\\rho}_{t}$ is a function of $\\left\\{\\mathcal{X}_{1}, \\mathcal{X}_{2}, \\ldots, \\mathcal{X}_{t}\\right\\}$ and the stochastic behavior of $\\mathcal{X}_{t+1}$ is completely determined by $\\hat{\\rho}_{t}, E_{G}\\left[H\\left(\\mathcal{X}_{t+1}\\right) \\mid \\mathcal{F}_{t}\\right]$ can be considered as the expectation with respect to pdf $g\\left(x ; \\hat{\\rho}_{t}\\right)$, i.e. the expected value of $H\\left(\\mathcal{X}_{t+1}\\right)$ when $X_{i}^{(t+1)}, i=1, \\ldots, n_{t+1}$, follows $g\\left(x ; \\hat{\\rho}_{t}\\right)$. For sake of notation, we let $E_{G}\\left[H\\left(\\mathcal{X}_{1}\\right) \\mid \\mathcal{F}_{0}\\right]$ be the expectation with respect to $g\\left(\\cdot ; \\hat{\\rho}_{0}\\right)$.\n\nFor the sample point processes $\\left\\{X_{i}^{(t)}, i=1, \\ldots, n_{t}\\right\\}$, we define $\\psi_{t}$ and $\\Psi_{t}$ as follows: for $t=1,2, \\ldots$,\n\n$$\n\\begin{aligned}\n\\psi_{t}\\left(X_{i}^{(t)}\\right) & =K\\left(X_{i}^{(t)}\\right) w_{t}\\left(X_{i}^{(t)}\\right)-E_{G}\\left[K\\left(X_{i}^{(t)}\\right) w_{t}\\left(X_{i}^{(t)}\\right) \\mid \\mathcal{F}_{t-1}\\right] \\\\\n\\Psi_{t} & =\\sum_{i=1}^{n_{t}} \\psi_{t}\\left(X_{i}^{(t)}\\right)\n\\end{aligned}\n$$\n\nNote that both $\\psi_{t}$ and $\\Psi_{t}$ are functionals depending on the function $K(x)$, and that $E_{G}\\left[K\\left(X_{i}^{(t)}\\right) w_{t}\\left(X_{i}^{(t)}\\right)\\left|\\mathcal{F}_{t-1}\\right|\\right.$ is equal to $E_{g_{t-1}}\\left[K\\left(X_{i}^{(t)}\\right) w_{t}\\left(X_{i}^{(t)}\\right)\\right]$, where $E_{g_{t-1}}[\\cdot]$ denotes the expectation with respect to $g\\left(x ; \\dot{\\rho}_{t-1}\\right)$. Since $w_{t}(x)=h(x) / g\\left(x ; \\dot{\\rho}_{t-1}\\right)$, we have that\n\n$$\nE_{G}\\left[K\\left(X_{i}^{(t)}\\right) w_{t}\\left(X_{i}^{(t)}\\right)\\left|\\mathcal{F}_{t-1}\\right|=E[K(X) h(X)]\\right.\n$$\n\nThen, Eq (31) is rewritten as\n\n$$\n\\begin{aligned}\n\\psi_{t}\\left(X_{i}^{(t)}\\right) & =K\\left(X_{i}^{(t)}\\right) w_{t}\\left(X_{i}^{(t)}\\right)-E[K(X) h(X)] \\\\\n\\Psi_{t} & =\\sum_{i=1}^{n_{t}} K\\left(X_{i}^{(t)}\\right) w_{t}\\left(X_{i}^{(t)}\\right)-n_{t} E[K(X) h(X)]\n\\end{aligned}\n$$\n\nSuppose that for a non-negative valued function $\\rho(\\xi)$ on $S, \\int_{S} \\rho(\\xi) d \\xi<\\infty$. Then, the pdf of the non-homogeneous Poisson point process with intensity function $\\rho(\\xi)$, $\\xi \\in S$, with respect to $\\operatorname{Poi}(S, 1)$ is as follows (M\u00f8ller and Waagepetersen, 2003):\n\n$$\np(x ; \\rho(\\xi))=\\exp \\left(|S|-\\int_{S} \\rho(\\xi) d \\xi\\right) \\prod_{\\xi \\in s} \\rho(\\xi), \\quad x \\in \\mathcal{N}\n$$\n\nFor convenience of presentation, we denote by $q_{i}(x)$ the pdf $p\\left(x, \\frac{1}{m_{\\rho}^{i}} \\phi^{i+1}(\\xi)\\right)$, and by $E_{q_{i}}[\\cdot]$ the expectation with respect to $q_{i}(x)$ for $i=1,2,3$.\nTheorem 1. Suppose that $\\int_{S} \\phi^{2}(\\xi) d \\xi<\\infty$ and $E_{q_{1}}\\left[K(X)^{2}\\right]<\\infty$. Then, for a point process $X$ following $\\operatorname{Poi}(S, 1)$,\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} K\\left(X_{i}^{(j)}\\right) w_{j}\\left(X_{i}^{(j)}\\right)=E[K(X) h(X)], \\quad \\text { a.s. }\n$$\n\nProof. We can see from the form of $\\Psi_{t}$ given in Eq (31) that Eq (33) is equivalent to\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} \\Psi_{j}=0, \\quad \\text { a.s. }\n$$\n\nEq (31) gives that\n\n$$\nE_{G}\\left[\\psi_{t}\\left(X_{i}^{(t)}\\right) \\mid \\mathcal{F}_{t-1}\\right]=0, \\quad i=1, \\ldots, n_{t}\n$$\n\nand that\n\n$$\nE_{G}\\left[\\Psi_{t} \\mid \\mathcal{F}_{t-1}\\right]=0, \\quad t=1,2, \\ldots\n$$\n\nThen, due to Feller (1991, Theorem 3, p.243), it is sufficient to show that\n\n$$\n\\sum_{t=1}^{\\infty} \\frac{E_{G}\\left[\\Psi_{t}^{2}\\right]}{\\left(n^{(t)}\\right)^{2}}<\\infty\n$$\n\nWe will first show that $E_{G}\\left[\\psi_{t}^{2}\\left(X_{i}^{(t)}\\right)\\right], t \\geq 1$, is bounded above by a constant. It can be easily shown from the definition of $\\psi_{t}(x)$ that\n\n$$\nE_{G}\\left[\\psi_{t}^{2}\\left(X_{i}^{(t)}\\right)\\left|\\mathcal{F}_{t-1}\\right| \\leq E_{G}\\left[K^{2}\\left(X_{i}^{(t)}\\right) w_{t}^{2}\\left(X_{i}^{(t)}\\right) \\mid \\mathcal{F}_{t-1}\\right]\\right.\n$$\n\nIt follows from Eqs (7) and (8) that\n\n$$\nh(x) \\leq \\prod_{\\xi \\in e} \\phi(\\xi), \\quad x \\in \\mathcal{N}\n$$\n\nNote that $w_{t}(x)=h(x) / g\\left(x ; \\hat{\\rho}_{t-1}\\right)$. Then, Eqs (20) and (36) imply that\n\n$$\nw_{t}(x)<\\exp \\left(\\hat{\\rho}_{t-1}|S|\\right) \\prod_{\\xi \\in e} \\frac{\\phi(\\xi)}{\\hat{\\rho}_{t-1}}\n$$\n\nSince $m_{\\rho} \\leq \\hat{\\rho}_{t-1} \\leq M_{\\rho}$, we have that\n\n$$\nw_{t}(x)<\\exp \\left(M_{\\rho}|S|\\right) \\prod_{\\xi \\in e} \\frac{\\phi(\\xi)}{m_{\\rho}}\n$$\n\nThen, we have from Eq (32) that\n\n$$\nw_{t}(x) h(x)<\\exp \\left(M_{\\rho}|S|+\\frac{1}{m_{\\rho}} \\int_{S} \\phi^{2}(\\xi) d \\xi\\right) q_{1}(x)\n$$\n\nSince $w_{t}^{2}(x)=w_{t}(x) h(x) / g\\left(x ; \\hat{\\rho}_{t-1}\\right)$, we have that\n\n$$\n\\begin{aligned}\n& E_{G}\\left[K^{2}\\left(X_{i}^{(t)}\\right) w_{t}^{2}\\left(X_{i}^{(t)}\\right) \\mid \\mathcal{F}_{t-1}\\right] \\\\\n& <\\exp \\left(M_{\\rho}|S|+\\frac{1}{m_{\\rho}} \\int_{S} \\phi^{2}(\\xi) d \\xi\\right) E_{G}\\left[\\frac{K^{2}\\left(X_{i}^{(t)}\\right) q_{1}\\left(X_{i}^{(t)}\\right)}{g\\left(X_{i}^{(t)} ; \\hat{\\rho}_{t-1}\\right)} \\mid \\mathcal{F}_{t-1}\\right]\n\\end{aligned}\n$$\n\nWe obtain from the above equation that\n\n$$\nE_{G}\\left[K^{2}\\left(X_{i}^{(t)}\\right) w_{t}^{2}\\left(X_{i}^{(t)}\\right) \\mid \\mathcal{F}_{t-1}\\right]<\\exp \\left(M_{\\rho}|S|+\\frac{1}{m_{\\rho}} \\int_{S} \\phi^{2}(\\xi) d \\xi\\right) E_{q_{1}}\\left[K^{2}(X)\\right]\n$$\n\nWe denote by $C$ the right hand side of the above equation. Then, $C$ is finite from the assumptions on $\\phi$ and $K$. Eq (35) shows that for $i=1,2, \\ldots, n_{t}$,\n\n$$\nE_{G}\\left[\\psi_{t}^{2}\\left(X_{i}^{(t)}\\right)\\right]<C\n$$\n\nSince $\\psi_{t}\\left(X_{1}^{(t)}\\right), \\ldots, \\psi_{t}\\left(X_{n_{t}}^{(t)}\\right)$ given $\\hat{\\rho}_{t-1}$ are conditionally i.i.d. with mean zero, it follows that\n\n$$\nE_{G}\\left[\\Psi_{t}^{2}\\left|\\mathcal{F}_{t-1}\\right|=n_{t} E_{G}\\left[\\psi_{t}\\left(X^{(t)}\\right)^{2}\\right] \\mathcal{F}_{t-1}\\right]\n$$\n\nwhere $X^{(t)}$ is a point process following $g\\left(x ; \\hat{\\rho}_{t-1}\\right)$. Then, we obtain that $E_{G}\\left[\\Psi_{t}^{2}\\right]=$ $n_{t} E_{G}\\left[\\psi_{t}\\left(X^{(t)}\\right)^{2}\\right]$, which implies that\n\n$$\nE_{G}\\left[\\Psi_{t}^{2}\\right]<n_{t} C\n$$\n\nLet $u_{0}=\\sup _{t \\geq 1} t n_{t} / n^{(t)}$. Then, $n_{t} / n^{(t)} \\leq u_{0} / t$ for $t \\geq 1$. Since $n^{(t)} \\geq t$, we have that\n\n$$\n\\frac{n_{t}}{\\left(n^{(t)}\\right)^{2}} \\leq \\frac{u_{0}}{t^{2}}, \\quad t \\geq 1\n$$\n\nCondition (28) implies that\n\n$$\n\\sum_{t=1}^{\\infty} \\frac{n_{t}}{\\left(n^{(t)}\\right)^{2}}<\\infty\n$$\n\nThen, we can see that $\\sum_{t=1}^{\\infty} E_{G}\\left[\\Psi_{t}^{2}\\right] /\\left(n^{(t)}\\right)^{2}$ is finite.\nBy exploiting Theorem 1, we can show the almost sure convergence of $\\left\\{\\hat{\\mu}_{t}, t=\\right.$ $1,2, \\ldots\\}$ in Eq (23) under the same condition as Theorem 1.\nTheorem 2. Suppose that $\\int_{S} \\phi^{2}(\\xi) d \\xi<\\infty$ and $E_{q_{1}}\\left[K(X)^{2}\\right]<\\infty$. Then,\n\n$$\n\\lim _{t \\rightarrow \\infty} \\hat{\\mu}_{t}=\\mu, \\quad \\text { a.s. }\n$$\n\nProof. Letting $K(X)=1$ in Theorem 1, we obtain that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} w_{j}\\left(X_{i}^{(j)}\\right)=E[h(X)], \\quad \\text { a.s. }\n$$\n\nTheorem 1 and the above equation give that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} K\\left(X_{i}^{(j)}\\right) w_{j}\\left(X_{i}^{(j)}\\right)}{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} w_{j}\\left(X_{i}^{(j)}\\right)}=\\frac{E[K(X) h(X)]}{E[h(X)]}, \\quad \\text { a.s. }\n$$\n\nThe right-hand side of the above equation is equal to $\\mu$ in Eq (11), which completes the proof.\n\nIn the proposed adaptive importance sampling shown in Algorithm 1, the importance samples of $X$ generated at the $t$-th step are the homogeneous Poisson point processes with intensity $\\hat{\\rho}_{t}$ in Eq (24). As mentioned in Section 3.2, the pseudo-optimal value of the intensity is $\\rho^{\\prime}$ in Eq (22). However, $\\left\\{\\hat{\\rho}_{t}, t=1,2, \\ldots\\right\\}$ does not converge to $\\rho^{\\prime}$, but converges to a value close to it. We define $\\tilde{\\rho}$ as follows:\n\n$$\n\\tilde{\\rho}=\\frac{1}{|S|} \\frac{E_{f}[\\tilde{n}(X)|K(X)|]}{E_{f}[|K(X)|]}\n$$\n\nThe following theorem shows that $\\hat{\\rho}_{t}$ converges to $\\tilde{\\rho}$ as $t$ goes to the infinity.\n\nTheorem 3. Under the same condition as Theorem 2, we have that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\hat{\\rho}_{t}=\\tilde{\\rho}, \\quad \\text { a.s. }\n$$\n\nProof. Suppose that $\\int_{S} \\phi^{2}(\\xi) d \\xi<\\infty$ and $E_{q_{1}}\\left[K^{2}(X)\\right]<\\infty$. Since $\\tilde{n}(x), x \\in \\mathcal{N}$, is bounded above by $M_{\\rho}$, we also have that $E_{q_{1}}\\left[\\tilde{n}^{2}(X) K^{2}(X)\\right]<\\infty$. By substituting $\\tilde{n}(x)|K(x)|$ for $K(x)$ in Theorem 1, we obtain that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} \\tilde{n}\\left(X_{i}^{(j)}\\right)\\left|K\\left(X_{i}^{(j)}\\right)\\right| w_{j}\\left(X_{i}^{(j)}\\right)=E[\\tilde{n}(X)|K(X)| h(X)], \\quad \\text { a.s. }\n$$\n\nBy substituting $|K(x)|$ for $K(x)$ in Theorem 1, we obtain that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}}\\left|K\\left(X_{i}^{(j)}\\right)\\right| w_{j}\\left(X_{i}^{(j)}\\right)=E[|K(X)| h(X)], \\quad \\text { a.s. }\n$$\n\nThe above two equations give that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{|S|} \\frac{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} \\tilde{n}\\left(X_{i}^{(j)}\\right)\\left|K\\left(X_{i}^{(j)}\\right)\\right| w_{j}\\left(X_{i}^{(j)}\\right)}{\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}}\\left|K\\left(X_{i}^{(j)}\\right)\\right| w_{j}\\left(X_{i}^{(j)}\\right)}=\\frac{1}{|S|} \\frac{E[\\tilde{n}(X)|K(X)| h(X)]}{E[|K(X)| h(X)]}, \\quad \\text { a.s. }\n$$\n\nSince the right-hand side in the above equation is equal to $\\tilde{\\rho}$, the proof is complete.\nAn upper bound on the difference between $\\rho^{\\prime}$ and $\\tilde{\\rho}$ is obtained as follows:\n\n$$\n\\left|\\rho^{\\prime}-\\tilde{\\rho}\\right| \\leq \\frac{1}{|S|} \\frac{E_{f}[|n(X)-\\tilde{n}(X)||K(X)|]}{E_{f}[|K(X)|]}\n$$\n\nSince we have chosen a sufficiently small $m_{\\rho}$ and a sufficiently large $M_{\\rho}, \\tilde{n}(X)$ and $n(X)$ are the same with a probability close to 1 , and $\\tilde{\\rho}$ may be close to $\\rho^{\\prime}$. Thus, in Algorithm 1, the importance samples of $X$ are generated near optimally as steps go by.\n\nThe importance sampling pdf $g(x ; \\rho)$ in Eq (20) is continuous with respect to $\\rho$. Due to Theorem 3, we can see that for $x \\in \\mathcal{N}$,\n\n$$\n\\lim _{t \\rightarrow \\infty} g\\left(x ; \\hat{\\rho}_{t}\\right)=g(x ; \\tilde{\\rho}), \\quad \\text { a.s. }\n$$\n\nThe above equation implies that $X^{(t)}$, the importance sample generated from $g\\left(x ; \\hat{\\rho}_{t-1}\\right)$, converges in distribution as $t \\rightarrow \\infty$, and that $g(x ; \\tilde{\\rho})$ is the limiting pdf. For a point process $X$ following $g(x ; \\tilde{\\rho})$ and a function $H(x), x \\in \\mathcal{N}$, we denote by $E_{\\tilde{g}}[H(X)]$ the expected value of $H(X)$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 11,
      "text": "# 4.2 Asymptotic normality of the proposed estimator \n\nWe have shown that $\\hat{\\mu}_{t}$ converged to $\\mu$ almost surely as $t \\rightarrow \\infty$ in Theorem 2. In this subsection, we will show the asymptotic normality of $\\left\\{\\hat{\\mu}_{t}, t=1,2, \\ldots\\right\\}$. Let $K^{\\prime}(x)=$\n\n$a_{1}+a_{2} K(x), x \\in \\mathcal{N}$, for real-valued constants $a_{1}$ and $a_{2}$. We define $\\psi_{j}^{K^{\\prime}}(X)$ as $\\psi_{j}(X)$ with $K(X)$ being substituted with $K^{\\prime}(X)$. For a positive integer $\\tau$, we define\n\n$$\nr_{j}^{(\\tau)}=\\frac{1}{\\sqrt{n^{(\\tau)}} \\sum_{i=1}^{n_{j}} \\psi_{j}^{K^{\\prime}}\\left(X_{i}^{(j)}\\right), \\quad j=1,2, \\ldots, \\tau}\n$$\n\nand\n\n$$\nS_{\\tau, t}=\\sum_{j=1}^{t} r_{j}^{(\\tau)}, \\quad t=1,2, \\ldots, \\tau\n$$\n\nTheorem 4. Under the same condition as Theorem 2, we have that for a positive integer $\\tau,\\left\\{S_{\\tau, t}, t=1,2, \\ldots, \\tau\\right\\}$ is a zero-mean square integrable martingale with respect to the filtration $\\left\\{\\mathcal{F}_{t}, t=1,2, \\ldots\\right\\}$.\n\nProof. By substituting $\\psi_{t}^{K^{\\prime}}(x)$ for $\\psi_{t}(x)$ in Eq (34), we have that $E_{G}\\left[\\psi_{t}^{K^{\\prime}}\\left(X_{i}^{(t)}\\right) \\mid \\mathcal{F}_{t-1}\\right]=0$ for $i=1,2, \\ldots, n_{t}$, which means that $E_{G}\\left[r_{t}^{(\\tau)} \\mid \\mathcal{F}_{t-1}\\right]=0$ for $t=1,2, \\ldots, \\tau$. Then, it follows that for $t=2,3, \\ldots$,\n\n$$\n\\begin{aligned}\nE_{G}\\left[S_{\\tau, t} \\mid \\mathcal{F}_{t-1}\\right] & =E_{G}\\left[S_{\\tau, t-1}+r_{t}^{(\\tau)} \\mid \\mathcal{F}_{t-1}\\right] \\\\\n& =S_{\\tau, t-1}+E_{G}\\left[r_{t}^{(\\tau)} \\mid \\mathcal{F}_{t-1}\\right] \\\\\n& =S_{\\tau, t-1}\n\\end{aligned}\n$$\n\nSince $E_{G}\\left[S_{\\tau, 1}\\right]=0$, we have that\n\n$$\nE_{G}\\left[S_{\\tau, t}\\right]=0, \\text { for } t=1,2, \\ldots, \\tau\n$$\n\nThus, $\\left\\{S_{\\tau, t}, t=1,2, \\ldots, \\tau\\right\\}$ is a zero-mean martingale.\nSince $\\psi_{t}^{K^{\\prime}}\\left(X_{1}^{(t)}\\right), \\ldots, \\psi_{t}^{K^{\\prime}}\\left(X_{n_{t}}^{(t)}\\right)$ given $\\hat{\\rho}_{t-1}$ are i.i.d with mean zero, it follows that\n\n$$\n\\begin{aligned}\nE_{G}\\left[\\left(r_{t}^{(\\tau)}\\right)^{2} \\mid \\mathcal{F}_{t-1}\\right] & =\\frac{1}{n^{(\\tau)}} \\sum_{i=1}^{n_{t}} E_{G}\\left[\\psi_{t}^{K^{\\prime}}\\left(X_{i}^{(t)}\\right)^{2} \\mid \\mathcal{F}_{t-1}\\right] \\\\\n& =\\frac{n_{t}}{n^{(\\tau)}} E_{G}\\left[\\psi_{t}^{K^{\\prime}}\\left(X^{(t)}\\right)^{2} \\mid \\mathcal{F}_{t-1}\\right]\n\\end{aligned}\n$$\n\nwhich gives that\n\n$$\nE_{G}\\left[\\left(r_{t}^{(\\tau)}\\right)^{2}\\right]=\\frac{n_{t}}{n^{(\\tau)}} E_{G}\\left[\\psi_{t}^{K^{\\prime}}\\left(X^{(t)}\\right)^{2}\\right], \\quad t=1,2, \\ldots, \\tau\n$$\n\nEq (39) implies that\n\n$$\nE_{G}\\left[\\left(r_{t}^{(\\tau)}\\right)^{2}\\right] \\leq \\frac{n_{t}}{n^{(\\tau)}} C\n$$\n\nwhere $C=\\exp \\left(M|S|+\\frac{1}{m_{\\rho}} \\int_{S} \\phi^{2}(\\xi) d \\xi\\right)\\left(a_{1}^{2}+2 a_{1} a_{2} E_{q_{1}}[K(X)]+a_{2}^{2} E_{q_{1}}\\left[K(X)^{2}\\right]\\right)$. The conditional expectation of $S_{\\tau, t}^{2}$ is represented as follows:\n\n$$\n\\begin{aligned}\nE_{G}\\left[S_{\\tau, t}^{2} \\mid \\mathcal{F}_{t-1}\\right] & =E_{G}\\left[\\left(S_{\\tau, t-1}+r_{t}^{(\\tau)}\\right)^{2} \\mid \\mathcal{F}_{t-1}\\right] \\\\\n& =E_{G}\\left[S_{\\tau, t-1}^{2} \\mid \\mathcal{F}_{t-1}\\right]+2 E_{G}\\left[S_{\\tau, t-1} r_{t}^{(\\tau)} \\mid \\mathcal{F}_{t-1}\\right]+E_{G}\\left[\\left(r_{t}^{(\\tau)}\\right)^{2} \\mid \\mathcal{F}_{t-1}\\right]\n\\end{aligned}\n$$\n\nSince $E_{G}\\left[S_{\\tau, t-1} r_{t}^{(\\tau)} \\mid \\mathcal{F}_{t-1}\\right]=S_{\\tau, t-1} E_{G}\\left[r_{t}^{(\\tau)} \\mid \\mathcal{F}_{t-1}\\right]$ and $E_{G}\\left[r_{t}^{(\\tau)} \\mid \\mathcal{F}_{t-1}\\right]=0$, the above equation is rewritten as\n\n$$\nE_{G}\\left[S_{\\tau, t}^{2} \\mid \\mathcal{F}_{t-1}\\right]=E_{G}\\left[S_{\\tau, t-1}^{2} \\mid \\mathcal{F}_{t-1}\\right]+E_{G}\\left[\\left(r_{t}^{(\\tau)}\\right)^{2} \\mid \\mathcal{F}_{t-1}\\right]\n$$\n\nwhich gives that\n\n$$\nE_{G}\\left[S_{\\tau, t}^{2}\\right]=E_{G}\\left[S_{\\tau, t-1}^{2}\\right]+E_{G}\\left[\\left(r_{t}^{(\\tau)}\\right)^{2}\\right], t=2,3, \\ldots, \\tau\n$$\n\nNote that $S_{\\tau, 1}=r_{1}^{(\\tau)}$. Then, it follows from the above recurrence relation that\n\n$$\nE_{G}\\left[S_{\\tau, t}^{2}\\right]=\\sum_{j=1}^{t} E_{G}\\left[\\left(r_{j}^{(\\tau)}\\right)^{2}\\right], t=1,2, \\ldots, \\tau\n$$\n\nBy applying Eq (43) to the above equation, we obtain that\n\n$$\nE_{G}\\left[S_{\\tau, t}^{2}\\right] \\leq C, t=1,2, \\ldots, \\tau\n$$\n\nwhich completes the proof.\n\nIn our proposed method, the importance sampling pdf of $X$ at each step converges to $g(x ; \\tilde{\\rho})$, the pdf of the homogeneous Poisson point process with intensity $\\tilde{\\rho}$. Let $\\tilde{\\mu}_{\\tilde{\\rho}}$ be the importance sampling estimator of $\\mu$ when the importance sampling pdf of $X$ is equal to $g(x ; \\tilde{\\rho})$. In this case, the unnormalized likelihood ratio is given by $\\tilde{w}(x)=h(x) / g(x ; \\tilde{\\rho})$. The exact form of $\\tilde{\\mu}_{\\tilde{\\rho}}$ is given by substituting $\\tilde{w}(x)$ for $w(x)$ in Eq (17). An approximate variance of $\\tilde{\\mu}_{\\tilde{\\rho}}$ can be found from Eq (18). Since the unnormalized likelihood ratio is $\\tilde{w}(x)$, the approximate variance of $\\tilde{\\mu}_{\\tilde{\\rho}}$ is as follows:\n\n$$\n\\tilde{\\sigma}^{2}=\\frac{E_{\\tilde{\\rho}}\\left[(K(X)-\\mu)^{2} \\tilde{w}^{2}(X)\\right]}{E_{\\tilde{\\rho}}[\\tilde{w}(X)]^{2}}\n$$\n\nWe let\n\n$$\n\\begin{aligned}\n\\tilde{\\sigma}_{1}^{2} & =E_{\\tilde{g}}\\left[\\tilde{w}(X)^{2}\\right]-E_{\\tilde{g}}[\\tilde{w}(X)]^{2} \\\\\n\\tilde{\\sigma}_{12} & =E_{\\tilde{g}}\\left[K(X) \\tilde{w}^{2}(X)\\right]-E_{\\tilde{g}}\\left[K(X) \\tilde{w}(X)\\right] E_{\\tilde{g}}[\\tilde{w}(X)] \\\\\n\\tilde{\\sigma}_{2}^{2} & =E_{\\tilde{g}}\\left[K^{2}(X) \\tilde{w}^{2}(X)\\right]-E_{\\tilde{g}}\\left[K(X) \\tilde{w}(X)\\right]^{2}\n\\end{aligned}\n$$\n\nThen, it can be easily checked that\n\n$$\n\\tilde{\\sigma}^{2}=\\frac{\\mu^{2} \\tilde{\\sigma}_{1}^{2}-2 \\mu \\tilde{\\sigma}_{12}+\\tilde{\\sigma}_{2}^{2}}{E_{\\tilde{g}}[\\tilde{w}(X)]^{2}}\n$$\n\nTheorem 5. Suppose that $\\int_{S} \\phi^{4}(\\xi) d \\xi<\\infty, E_{q_{i}}\\left[K(X)^{i+1}\\right]<\\infty$ for $i=1,2,3$. Then, we have that for arbitrary constants $a_{1}, a_{2}$,\n\n$$\nS_{t, t} \\rightarrow N\\left(0, a_{1}^{2} \\tilde{\\sigma}_{1}^{2}+2 a_{1} a_{2} \\tilde{\\sigma}_{12}+a_{2}^{2} \\tilde{\\sigma}_{2}^{2}\\right) \\quad \\text { in dist }\n$$\n\nwhere $N\\left(\\mu, \\sigma^{2}\\right)$ is the normal distribution with mean $\\mu$ and variance $\\sigma^{2}$.\nProof. It follows from the definition of $\\psi_{t}^{K^{\\prime}}\\left(X_{i}^{(t)}\\right)$ that for $i=1,2, \\ldots, n_{t}$,\n\n$$\n\\begin{aligned}\n& E_{G}\\left[\\psi_{t}^{K^{\\prime}}\\left(X_{i}^{(t)}\\right)^{2} \\mid \\mathcal{F}_{t-1}\\right] \\\\\n& =E_{G}\\left[K^{\\prime}\\left(X_{i}^{(t)}\\right)^{2} w_{t}^{2}\\left(X_{i}^{(t)}\\right) \\mid \\mathcal{F}_{t-1}\\right]-E_{G}\\left[K^{\\prime}\\left(X_{i}^{(t)}\\right) w_{t}\\left(X_{i}^{(t)}\\right) \\mid F_{t-1}\\right]^{2}\n\\end{aligned}\n$$\n\nWe have that\n\n$$\n\\begin{aligned}\nE_{G}\\left[K^{\\prime}\\left(X_{i}^{(t)}\\right)^{2} w_{t}^{2}\\left(X_{i}^{(t)}\\right) \\mid \\mathcal{F}_{t-1}\\right] & =E_{G}\\left[K^{\\prime}\\left(X_{i}^{(t)}\\right)^{2} \\frac{h^{2}\\left(X_{i}^{(t)}\\right)}{g^{2}\\left(X_{i}^{(t)} ; \\hat{\\rho}_{t-1}\\right)} \\mid \\mathcal{F}_{t-1}\\right] \\\\\n& =E\\left[K^{\\prime}(X)^{2} \\frac{h^{2}(X)}{g\\left(X ; \\hat{\\rho}_{t-1}\\right)}\\right]\n\\end{aligned}\n$$\n\nSince $g(x ; \\rho)$ in Eq (20) is a continuous function of $\\rho$, and $\\hat{\\rho}_{t}$ converges to $\\tilde{\\rho}$ almost surely, we have that for $x \\in \\mathcal{N}$,\n\n$$\n\\lim _{t \\rightarrow \\infty} K^{\\prime}(x)^{2} \\frac{h^{2}(x)}{g\\left(x ; \\hat{\\rho}_{t-1}\\right)}=K^{\\prime}(x)^{2} \\frac{h^{2}(x)}{g(x ; \\tilde{\\rho})}, \\quad \\text { a.s. }\n$$\n\nWe define $\\zeta(x)$ as follows:\n\n$$\n\\zeta(x)=\\exp \\left(M_{\\rho}|S|+\\frac{1}{m_{\\rho}} \\int_{S} \\phi^{2}(\\xi) d \\xi\\right) K^{\\prime}(x)^{2} q_{1}(x), \\quad x \\in \\mathcal{N}\n$$\n\nEq (38) shows that for $t=1,2, \\ldots$,\n\n$$\nK^{\\prime}(x)^{2} \\frac{h^{2}(x)}{g\\left(x ; \\hat{\\rho}_{t-1}\\right)}<\\zeta(x), \\quad x \\in \\mathcal{N}\n$$\n\nWe have from the assumptions of the theorem that both $\\int_{S} \\phi^{2}(\\xi) d \\xi$ and $E_{q_{1}}\\left[K^{2}(X)\\right]$ are finite, which gives that $E[\\zeta(X)]$ is also finite. Then, it follows from the dominated convergence theorem that\n\n$$\n\\lim _{t \\rightarrow \\infty} E\\left[K^{\\prime}(X)^{2} \\frac{h^{2}(X)}{g\\left(X ; \\hat{\\rho}_{t-1}\\right)}\\right]=E\\left[K^{\\prime}(X)^{2} \\frac{h^{2}(X)}{g(X ; \\hat{\\rho})}\\right], \\quad \\text { a.s. }\n$$\n\nequivalently, for $i=1,2, \\ldots, n_{t}$,\n\n$$\n\\lim _{t \\rightarrow \\infty} E_{G}\\left[K^{\\prime}\\left(X_{i}^{(t)}\\right)^{2} w_{t}^{2}\\left(X_{i}^{(t)}\\right) \\mid F_{t-1}\\right]=E_{\\tilde{g}}\\left[K^{\\prime}(X)^{2} \\tilde{w}^{2}(X)\\right], \\quad \\text { a.s. }\n$$\n\nNote that $E_{G}\\left[K^{\\prime}\\left(X_{i}^{(t)}\\right) w_{t}\\left(X_{i}^{(t)}\\right) \\mid F_{t-1}\\right]=E\\left[K^{\\prime}(X) h(X)\\right]$, which gives that\n\n$$\nE_{G}\\left[K^{\\prime}\\left(X_{i}^{(t)}\\right) w_{t}\\left(X_{i}^{(t)}\\right) \\mid F_{t-1}\\right]=E_{\\tilde{g}}\\left[K^{\\prime}(X) \\tilde{w}(X)\\right]\n$$\n\nThen, it follows from Eq (48) and the above two equations that\n\n$$\n\\lim _{t \\rightarrow \\infty} E_{G}\\left[\\psi_{t}^{K^{\\prime}}\\left(X_{i}^{(t)}\\right)^{2} \\mid \\mathcal{F}_{t-1}\\right]=E_{\\tilde{g}}\\left[K^{\\prime}(X)^{2} \\tilde{w}^{2}(X)\\right]-E_{\\tilde{g}}\\left[K^{\\prime}(X) \\tilde{w}(X)\\right]^{2}, \\quad \\text { a.s. }\n$$\n\nDue to Eq (46), the right-hand side of the above equation is computed to be $a_{1}^{2} \\hat{\\sigma}_{1}^{2}+2 a_{1} a_{2} \\hat{\\sigma}_{12}+a_{2}^{2} \\hat{\\sigma}_{2}^{2}$. Then, we obtain that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{t} \\sum_{j=1}^{t} E_{G}\\left[\\psi_{j}^{K^{\\prime}}\\left(X^{(j)}\\right)^{2} \\mid \\mathcal{F}_{j-1}\\right]=a_{1}^{2} \\hat{\\sigma}_{1}^{2}+2 a_{1} a_{2} \\hat{\\sigma}_{12}+a_{2}^{2} \\hat{\\sigma}_{2}^{2}, \\quad \\text { a.s. }\n$$\n\nEqs (44) and (42) give that\n\n$$\n\\begin{aligned}\nE_{G}\\left[S_{t, t}^{2} \\mid \\mathcal{F}_{t-1}\\right] & =\\sum_{j=1}^{t} E_{G}\\left[\\left(r_{j}^{(t)}\\right)^{2} \\mid \\mathcal{F}_{t-1}\\right] \\\\\n& =\\frac{1}{n^{(t)}} \\sum_{j=1}^{t} n_{j} E_{G}\\left[\\psi_{j}^{K^{\\prime}}\\left(X^{(j)}\\right)^{2} \\mid \\mathcal{F}_{j-1}\\right]\n\\end{aligned}\n$$\n\nDue to Etemadi (2006, Theorem 1), the above two equations imply that\n\n$$\n\\lim _{t \\rightarrow \\infty} E_{G}\\left[S_{t, t}^{2} \\mid \\mathcal{F}_{t-1}\\right]=a_{1}^{2} \\hat{\\sigma}_{1}^{2}+2 a_{1} a_{2} \\hat{\\sigma}_{12}+a_{2}^{2} \\hat{\\sigma}_{2}^{2}, \\quad \\text { a.s. }\n$$\n\nNote that $\\left\\{S_{\\tau, t}, t=1,2, \\ldots, \\tau\\right\\}$ is a square integrable martingale for given $\\tau$. Then, by Hall et al. (2014, Corollary 3.1, p.58), it is sufficient to show that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\sum_{j=1}^{t} E_{G}\\left[\\left(r_{j}^{(t)}\\right)^{4} \\mid \\mathcal{F}_{j-1}\\right]=0\n$$\n\nfor the completion of the proof. Since $E_{G}\\left[\\psi_{j}^{K^{\\prime}}\\left(X_{i}^{(j)}\\right) \\mid \\mathcal{F}_{j-1}\\right]=0$, we have that\n\n$$\n\\begin{aligned}\n\\sum_{j=1}^{t} E_{G}\\left[\\left(r_{j}^{(t)}\\right)^{4} \\mid \\mathcal{F}_{j-1}\\right]= & \\frac{1}{\\left(n^{(t)}\\right)^{2}} \\sum_{j=1}^{t} E_{G}\\left[\\left(\\sum_{i=1}^{n_{j}} \\psi_{j}^{K^{\\prime}}\\left(X_{i}^{(j)}\\right)\\right)^{4} \\mid \\mathcal{F}_{j-1}\\right] \\\\\n= & \\frac{1}{\\left(n^{(t)}\\right)^{2}} \\sum_{j=1}^{t}\\left(n_{j} E_{G}\\left[\\psi_{j}^{K^{\\prime}}\\left(X^{(j)}\\right)^{4} \\mid \\mathcal{F}_{j-1}\\right]\\right. \\\\\n& \\left.+6 n_{j}\\left(n_{j}-1\\right) E_{G}\\left[\\psi_{j}^{K^{\\prime}}\\left(X^{(j)}\\right)^{2} \\mid \\mathcal{F}_{j-1}\\right]^{2}\\right)\n\\end{aligned}\n$$\n\nBy applying the Jensen's inequality to $E_{G}\\left[\\psi_{j}^{K^{\\prime}}\\left(X^{(j)}\\right)^{2} \\mid \\mathcal{F}_{j-1}\\right]^{2}$, we obtain that\n\n$$\n\\sum_{j=1}^{t} E_{G}\\left[\\left(r_{j}^{(t)}\\right)^{4} \\mid \\mathcal{F}_{j-1}\\right]<\\frac{6}{\\left(n^{(t)}\\right)^{2}} \\sum_{j=1}^{t} n_{j}^{2} E_{G}\\left[\\psi_{j}^{K^{\\prime}}\\left(X^{(j)}\\right)^{4} \\mid \\mathcal{F}_{j-1}\\right]\n$$\n\nEqs (36) and (37) imply that\n\n$$\n\\begin{aligned}\nE_{G}\\left[\\psi_{j}^{K^{\\prime}}\\left(X^{(j)}\\right)^{4} \\mid F_{j-1}\\right] & =E_{G}\\left[\\left(K^{\\prime}\\left(X^{(j)}\\right) w_{j}\\left(X^{(j)}\\right)-E\\left[K^{\\prime}(X) h(X)\\right]\\right)^{4} \\mid \\mathcal{F}_{j-1}\\right] \\\\\n& \\leq \\exp \\left(3 M_{\\rho}|S|+\\frac{1}{m_{\\rho}^{3}} \\int_{S} \\phi^{4}(\\xi) d \\xi\\right) E_{q_{3}}\\left[K^{\\prime}(X)^{4}\\right] \\\\\n& +4\\left|\\exp \\left(2 M_{\\rho}|S|+\\frac{1}{m_{\\rho}^{2}} \\int_{S} \\phi^{3}(\\xi) d \\xi\\right) E_{q_{3}}\\left[K^{\\prime}(X)^{3}\\right] E\\left[K^{\\prime}(X) h(X)\\right]\\right| \\\\\n& +6 \\exp \\left(M_{\\rho}|S|+\\frac{1}{m_{\\rho}} \\int_{S} \\phi^{2}(\\xi) d \\xi\\right) E_{q_{1}}\\left[K^{\\prime}(X)^{2}\\right] E\\left[K^{\\prime}(X) h(X)\\right]^{2} \\\\\n& +5 E\\left[K^{\\prime}(X) h(X)\\right]^{4}\n\\end{aligned}\n$$\n\nWe denote by $C$ the right hand side of the above inequality. Then, $C$ is finite from the assumption of the theorem. Eq (50) gives that\n\n$$\n\\sum_{j=1}^{t} E_{G}\\left[\\left(r_{j}^{(t)}\\right)^{4} \\mid \\mathcal{F}_{j-1}\\right]<\\frac{6 C}{\\left(n^{(t)}\\right)^{2}} \\sum_{j=1}^{t} n_{j}^{2}\n$$\n\nApplying condition (30) to the above inequality completes the proof.\nNow, we obtain the asymptotic normality of $\\left\\{\\hat{\\mu}_{t}, t=1,2, \\ldots\\right\\}$ from Theorem 5 as follows.\nCorollary 1. Under the same conditions as Theorem 5, we have that\n\n$$\n\\sqrt{n^{(t)}}\\left(\\hat{\\mu}_{t}-\\mu\\right) \\rightarrow N\\left(0, \\tilde{\\sigma}^{2}\\right), \\quad \\text { in dist. }\n$$\n\nProof. Let $K^{\\prime}(x)=K(x)-\\mu$. Then, $E_{f}\\left[K^{\\prime}(X)\\right]=0$, which gives that\n\n$$\nE_{G}\\left[K^{\\prime}\\left(X^{(t)}\\right) w_{t}\\left(X^{(t)}\\right) \\mid \\mathcal{F}_{t-1}\\right]=0\n$$\n\nIt follows from Eq (31) that\n\n$$\n\\psi_{t}^{K^{\\prime}}\\left(X_{i}^{(t)}\\right)=\\left(K\\left(X_{i}^{(t)}\\right)-\\mu\\right) w_{t}\\left(X_{i}^{(t)}\\right)\n$$\n\nTheorem 5 says that\n\n$$\n\\frac{1}{\\sqrt{n^{(t)}} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}}\\left(K\\left(X_{i}^{(t)}\\right)-\\mu\\right) w_{t}\\left(X_{i}^{(t)}\\right) \\rightarrow N\\left(0, \\mu^{2} \\tilde{\\sigma}_{1}^{2}-2 \\mu \\tilde{\\sigma}_{12}+\\tilde{\\sigma}_{2}^{2}\\right), \\quad \\text { in dist. }\n$$\n\nDividing the left hand side of the above equation by $\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} w_{j}\\left(X_{i}^{(j)}\\right) / n^{(t)}$ gives $\\sqrt{n^{(t)}}\\left(\\hat{\\mu}_{t}-\\mu\\right)$. Eq. (41) says that $\\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} w_{j}\\left(X_{i}^{(j)}\\right) / n^{(t)}$ converges to $E_{\\tilde{g}}[\\tilde{w}(X)]$ almost surely. We have from the Slutsky theorem that\n\n$$\n\\sqrt{n^{(t)}}\\left(\\hat{\\mu}_{t}-\\mu\\right) \\rightarrow N\\left(0, \\frac{\\mu^{2} \\tilde{\\sigma}_{1}^{2}-2 \\mu \\tilde{\\sigma}_{12}+\\tilde{\\sigma}_{2}^{2}}{E_{\\tilde{g}}[\\tilde{w}(X)]^{2}}\\right), \\quad \\text { in dist. }\n$$\n\nThe variance of the above normal distribution is equal to $\\tilde{\\sigma}^{2}$ according to Eq (47).\nGiven the importance samples of $X$ generated until the $t$-th step in Algorithm 1, the approximate variance of $\\hat{\\mu}_{t}$ is computed from Eq (25). The following theorem shows that the approximate variance of $\\hat{\\mu}_{t}$ converges to $\\tilde{\\sigma}^{2}$ almost surely.\nTheorem 6. Under the same conditions as Theorem 5, we have that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\tilde{\\sigma}_{t}^{2}=\\tilde{\\sigma}^{2}, \\quad \\text { a.s. }\n$$\n\nwhere $\\tilde{\\sigma}_{t}^{2}$ is the estimator in Eq (25).\nProof. We define $\\theta_{j}\\left(X_{i}^{(j)}\\right)$ as follows: for $j=1,2, \\ldots$, and $i=1,2, \\ldots, n_{j}$,\n\n$$\n\\theta_{j}\\left(X_{i}^{(j)}\\right)=K^{2}\\left(X_{i}^{(j)}\\right) w_{j}^{2}\\left(X_{i}^{(j)}\\right)-E_{G}\\left[K^{2}\\left(X_{i}^{(j)}\\right) w_{j}^{2}\\left(X_{i}^{(j)}\\right) \\mid \\mathcal{F}_{j-1}\\right]\n$$\n\nLet $\\Theta_{j}=\\sum_{i=1}^{n_{j}} \\theta_{j}\\left(X_{i}^{(j)}\\right)$. Since $E_{G}\\left[\\theta_{j}\\left(X_{i}^{(j)}\\right) \\mid \\mathcal{F}_{j-1}\\right]=0$, we obtain that\n\n$$\n\\begin{aligned}\nE_{G}\\left[\\Theta_{j}^{2} \\mid \\mathcal{F}_{j-1}\\right] & =\\sum_{i=1}^{n_{j}} E_{G}\\left[\\theta_{j}^{2}\\left(X_{i}^{(j)}\\right) \\mid \\mathcal{F}_{j-1}\\right] \\\\\n& \\leq n_{j} E_{G}\\left[K^{4}\\left(X^{(j)}\\right) w_{j}^{4}\\left(X^{(j)}\\right) \\mid \\mathcal{F}_{j-1}\\right]\n\\end{aligned}\n$$\n\nEqs (36) and (37) show that\n\n$$\nE_{G}\\left[K^{4}\\left(X^{(j)}\\right) w_{j}^{4}\\left(X_{i}^{(j)}\\right) \\mid \\mathcal{F}_{j-1}\\right]<\\exp \\left\\{3 M_{\\rho}|S|\\right\\} E\\left[K^{4}(X) \\prod_{\\xi \\in X} \\frac{\\phi^{4}(\\xi)}{m_{\\rho}^{3}}\\right]\n$$\n\nThe right hand side of the above inequality is equal to\n\n$$\nC=\\exp \\left\\{\\left(3 M_{\\rho}-1\\right)|S|+\\frac{1}{m_{\\rho}^{3}} \\int_{S} \\phi^{4}(\\xi) d \\xi\\right\\} E_{q_{3}}\\left[K^{4}(X)\\right]\n$$\n\nwhich is finite from the assumption of the theorem. Since $E_{G}\\left[E_{G}\\left[\\Theta_{j}^{2}\\left[\\mathcal{F}_{j-1}\\right]\\right]=E_{G}\\left[\\Theta_{j}^{2}\\right]\\right.$, we have that\n\n$$\nE_{G}\\left[\\Theta_{j}^{2}\\right]<n_{j} C\n$$\n\nBy applying Eq (40) to the above equation, we obtain that $\\sum_{j=1}^{\\infty} E_{G}\\left[\\Theta_{j}^{2}\\right] /\\left(n^{(j)}\\right)^{2}$ is finite. Then, it follows from Feller (1991, Theorem 3, p.243) that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} \\Theta_{j}=0\n$$\n\nWe obtain from the above equation that\n\n$$\n\\begin{aligned}\n& \\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} K^{2}\\left(X_{i}^{(j)}\\right) w_{j}^{2}\\left(X_{i}^{(j)}\\right) \\\\\n& =\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} n_{j} E_{G}\\left[K^{2}\\left(X^{(j)}\\right) w_{j}^{2}\\left(X^{(j)}\\right) \\mid \\mathcal{F}_{j-1}\\right] \\quad \\text { a.s. }\n\\end{aligned}\n$$\n\nif the right hand side of the above equation exists. We have from Eq (49) that the right hand side of the above equation converges to $E_{\\bar{g}}\\left[K^{2}(X) \\tilde{w}^{2}(X)\\right]$ almost surely (Etemadi (2006, Theorem 1)). Then, we obtain that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} K^{2}\\left(X_{i}^{(j)}\\right) w_{j}^{2}\\left(X_{i}^{(j)}\\right)=E_{\\bar{g}}\\left[K^{2}(X) \\tilde{w}^{2}(X)\\right], \\quad \\text { a.s. }\n$$\n\nIn obtaining the above convergence on the weighted average of $\\left\\{K^{2}\\left(X_{i}^{(j)}\\right), j=\\right.$ $1,2, \\ldots, t, i=1,2, \\ldots, n_{j}\\}$, we have assumed that $E_{q_{3}}\\left[K^{4}(X)\\right]$ is finite. Due to the Liaponov inequality (Chung, 1974, p.50), $E_{q_{3}}\\left[K^{2}(X)\\right]$ is also finite. Thus, we can replace $K^{2}(x)$ with $K(x)$ in the above equation, which gives that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} K\\left(X_{i}^{(j)}\\right) w_{j}^{2}\\left(X_{i}^{(j)}\\right)=E_{\\bar{g}}\\left[K(X) \\tilde{w}^{2}(X)\\right], \\quad \\text { a.s. }\n$$\n\nLetting $K(x)=1$ in the above equation gives that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}} w_{j}^{2}\\left(X_{i}^{(j)}\\right)=E_{\\tilde{g}}\\left[\\tilde{w}^{2}(X)\\right], \\quad \\text { a.s. }\n$$\n\nIt follows from the above three equations and Theorem 2 that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\frac{1}{n^{(t)}} \\sum_{j=1}^{t} \\sum_{i=1}^{n_{j}}\\left(K\\left(X_{i}^{(j)}\\right)-\\hat{\\mu}_{t}\\right)^{2} w_{j}^{2}\\left(X_{i}^{(j)}\\right)=E_{\\tilde{g}}\\left[(K(X)-\\mu)^{2} \\tilde{w}^{2}(X)\\right], \\quad \\text { a.s. }\n$$\n\nEq (41) and the above equation imply that\n\n$$\n\\lim _{t \\rightarrow \\infty} \\hat{\\sigma}_{t}^{2}=\\frac{E_{\\tilde{g}}\\left[(K(X)-\\mu)^{2} \\tilde{w}^{2}(X)\\right]}{E_{\\tilde{g}}[\\tilde{w}(X)]^{2}}, \\quad \\text { a.s. }\n$$\n\nThe right hand side of the above equation is equal to $\\hat{\\sigma}^{2}$ given in Eq (45).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 12,
      "text": "# 4.3 Stopping criteria \n\nOh and Berger (1992) suggested that the iterative estimation of $\\mu$ should continue until the following condition is satisfied: for a sufficiently small values of $\\epsilon$ and $\\alpha$,\n\n$$\n\\operatorname{Pr}\\left\\{\\left|\\frac{\\hat{\\mu}_{t}-\\mu}{\\mu}\\right| \\leq \\epsilon\\right\\} \\geq 1-\\alpha\n$$\n\nIn other words, if the relative error of $\\hat{\\mu}_{t}$ is very small with a probability close to 1 , then the iterative estimation of $\\mu$ stops, and the current value of $\\hat{\\mu}_{t}$ is the estimate to $\\mu$. Due to the asymptotic normality of $\\hat{\\mu}_{t}$ given in Corollary 1, the above condition is converted to that\n\n$$\n\\frac{\\hat{\\sigma}^{2}}{n^{(t)} \\mu^{2}} \\leq\\left(\\frac{\\epsilon}{z_{\\alpha / 2}}\\right)^{2}\n$$\n\nBy substituting $\\hat{\\mu}_{t}$ for $\\mu$ and substituting $\\hat{\\sigma}_{t}^{2}$ for $\\hat{\\sigma}^{2}$ in the above condition, we obtain the stopping criterion on $\\hat{\\mu}_{t}$ given in Algorithm 1. In the numerical study in Section 6, we set $\\epsilon=0.09$ and $\\alpha=0.01$, which implies that $\\eta_{1} \\approx(0.05)^{2}$.\n\nThe stopping criterion obtained above is valid only when $\\mu_{t}$ and $\\hat{\\sigma}_{t}^{2}$ are sufficiently close to $\\mu$ and $\\hat{\\sigma}^{2}$, respectively. These events may occur when $\\hat{\\mu}_{t}$ is very close to $\\hat{\\rho}$. In order to check this, we add the following condition on $\\hat{\\mu}_{t}$ to the stopping criterion: for a small $\\eta_{2}>0$,\n\n$$\n\\frac{\\left|\\hat{\\rho}_{t}-\\hat{\\rho}_{t-1}\\right|}{\\hat{\\rho}_{t-1}} \\leq \\eta_{2}\n$$\n\nIf both the stopping conditions described above are satisfied, then we stop the iterative estimation of $\\mu$, and return the final value of $\\hat{\\mu}_{t}$ as the estimate to $\\mu$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 13,
      "text": "# 5 Estimation of the intensity of a stationary pairwise interaction point process \n\nIn this section, we assume that $X$ is a stationary pairwise interaction point process defined on $\\mathbb{R}^{d}$. Let $\\nu$ be the interaction function of $X$, and $\\beta$ be the activity parameter of it. We assume that $\\nu(\\xi, \\eta), \\xi, \\eta \\in \\mathbb{R}^{d}$, only depends on the distance between $\\xi$ and $\\eta$, i.e. $\\nu(\\xi, \\eta)=\\nu(\\|\\xi-\\eta\\|)$. We also assume that $X$ is repulsive with finite range of interaction $r$. Since the number of points of $X$ is infinite on $\\mathbb{R}^{d}$, the pdf of $X$ in $\\mathbb{R}^{d}$ is not well defined (Chiu et al., 2013, Chapter 5.5.3). Instead, the Papangelou conditional intensity defined for a finite point process can be extended to $X$ as follows (M\u00f8ller and Waagepetersen, 2003):\n\n$$\n\\lambda^{*}(x, \\xi)=\\beta \\prod_{\\eta \\in x} \\nu(\\|\\eta-\\xi\\|), \\quad x \\in \\mathcal{N}_{\\mathrm{ff}}, \\xi \\in \\mathbb{R}^{d}\n$$\n\nwhere $\\mathcal{N}_{\\mathrm{ff}}$ is the set of locally finite point patterns on $\\mathbb{R}^{d}$, i.e. $\\mathcal{N}_{\\mathrm{ff}}=\\left\\{x \\subset \\mathbb{R}^{d}\\right.$ : $n(x \\cap B)<\\infty$, for all bounded region $B \\in \\mathbb{R}^{d}\\}$. Since the range of interaction is finite, we can see that the value of $\\lambda^{*}(x, \\xi)$ is determined by the product of finite number of interactions and $\\beta$.\n\nThe intensity of $X$ is defined as the expected number of points occurring per unit region, i.e. for any bounded region $B \\in \\mathbb{R}^{d}$,\n\n$$\n\\lambda=\\frac{\\text { the expected number of points of } X \\text { on } B}{|B|}\n$$\n\nClearly, the value of $\\lambda$ does not depend on the choice of $B$ due to the stationarity of $X$. Let $o$ be the origin, and $B(o, r)$ be the ball with center $o$ and radius $r$. Then, it follows from Eq (52) that $\\lambda^{*}(X, o)$ is represented as\n\n$$\n\\lambda^{*}(X, o)=\\beta \\prod_{\\eta \\in X \\cap B(o, r)} \\nu(\\|\\eta\\|)\n$$\n\nLet $f^{*}$ be the pdf of $X$ on $B(o, r)$. Then, $\\lambda$ is represented by Georggii-Nguyen-Zessin formula (Nguyen and Zessin, 1979; Georgii, 1976) as follows:\n\n$$\n\\lambda=E_{f^{*}}\\left[\\lambda^{*}(X, o)\\right]\n$$\n\nBounded regions are considered as the domain of the process for the estimation of the summary characteristics such as the intensity and the higher order moments of $X$ (Illian et al., 2008)). Suppose that $X_{S}=X \\cap S$ is a finite pairwise interaction point process defined on a bounded region $S$, and that $X_{S}$ has the same parameters as $X$. Then, the pdf of $X_{S}$ with respect to $\\operatorname{Poi}(S, 1)$ is defined, for $\\beta>0$, as\n\n$$\nf(x) \\propto \\beta^{n(x)} \\prod_{\\{\\xi, \\eta\\} \\subseteq x} \\nu(\\|\\xi-\\eta\\|), \\quad x \\in \\mathcal{N}\n$$\n\nThen, the Papangelou conditional intensity of $f$ is obtained as\n\n$$\n\\lambda_{f}(x, \\xi)=\\beta \\prod_{\\eta \\in x} \\nu(\\|\\eta-\\xi\\|), \\quad x \\in \\mathcal{N}, \\xi \\in S \\backslash x\n$$\n\nSince $X_{S}$ is repulsive, $\\lambda_{f}$ is bounded by $\\beta$, which implies that $f$ is locally stable.\nWe choose $S$ such that it contains the origin, and that it is sufficiently large compared to $B(o, r)$. In this case, the Papangelou conditional intensity $\\lambda\\left(X_{S}, o\\right)$ at the origin may have the very similar distribution to $\\lambda(X, o)$, which enables us to apply Eq (53) to $X_{S}$ instead of $X$ for the estimation of $\\lambda$. By letting $K(x)=\\lambda_{f}(x, o)$ and $\\mu=E_{f}\\left[\\lambda_{f}(X, o)\\right]$, we can apply the proposed scheme as well as the MH and the CFTP methods to estimate the value of $\\lambda$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 14,
      "text": "# 6 Numerical results \n\nIn this section, we estimate the intensity for a stationary Strauss point process, and estimate the expected number of points in a region for a non-stationary Strauss point process. We apply the estimators described in Sections 2 and 3; the MH estimator in Eq (14), the CFTP estimator in Eq (15), and the AIS estimator in Algorithm 1. The efficiency of the estimators is compared in terms of the simulation time to get the same level of accuracy. This type of efficiency can be measured by the product of the squared standard error of the estimate and the simulation time to get the estimate (Glynn and Whitt (1992), Sak and H\u00f6rmann (2012)). We denote it by time-variance. The smaller the time-variance of an estimator is, the more efficient the estimator is. For pair comparison of the time-variance performance, we implemented the algorithms of three estimation methods using R (2021) instead of using the built-in functions provided by the R package spatstat (2005).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 15,
      "text": "### 6.1 Estimation of the intensity of a stationary Strauss point process\n\nWe consider a finite Strauss point process $X$ on a bounded region $S=[-0.5,0.5] \\times$ $[-0.5,0.5]$. The range of interaction of $X$ is 0.1 . Let $o$ be the origin $(0,0)$. It follows from Eq (10) that if $X$ does not contain $o$, the Papangelou conditional intensity of $X$ is given by\n\n$$\n\\lambda_{f}(x, o)=\\beta \\gamma^{\\sum_{\\eta} I(\\|\\eta\\|<0.1)}\n$$\n\nBy applying the three estimation methods with $K(x)=\\lambda_{f}(x, o)$, we have estimated the value of $E_{f}\\left[\\lambda_{f}(X, o)\\right]$ with various values of $\\beta$ and $\\gamma$. Then, these estimated values can be considered as the estimates to $\\lambda$, the intensity of the stationary Strauss point process with the same parameters. The number of sample point processes generated for obtaining an estimate to $\\lambda$ was determined so that the estimate has a relative standard error of about 0.05 or less, i.e. s.e. $/ \\hat{\\lambda} \\leq 0.05$. Table 1 shows $\\hat{\\lambda}_{\\mathrm{MH}}, \\hat{\\lambda}_{\\mathrm{CFTP}}$, and $\\hat{\\lambda}_{\\text {AIS }}$ for each pair of $\\beta$ and $\\gamma$, and shows their standard errors. The simulation times in second and the numbers of samples generated to obtain $\\hat{\\lambda}_{\\mathrm{MH}}, \\hat{\\lambda}_{\\mathrm{CFTP}}$, and $\\hat{\\lambda}_{\\text {AIS }}$, respectively, are also shown in Table 1.\n\nTable 1: The estimate to $\\lambda$, its standard error, and some metrics related to the corresponding simulation\n\n![table_0](table_0)\n\nIn order to get $\\hat{\\lambda}_{\\mathrm{MH}}$ for a pair of $\\beta$ and $\\gamma$, samples of $X$ were generated by applying the MH algorithm described in Section 2. We set the probability of a birth proposal to be 0.5 . The generated samples of $X$ follow the pdf $f$ in Eq (9) asymptotically. We set the burn-in period to be 3000 and choose each 200-th sample of the remaining samples for obtaining $\\hat{\\lambda}_{\\mathrm{MH}}$. Let $\\left\\{Y_{1}, Y_{2}, \\ldots, Y_{n}\\right\\}$ be the resulting samples. Then, the sample mean of $\\left\\{\\lambda\\left(Y_{1}, o\\right), \\lambda\\left(Y_{2}, o\\right), \\ldots, \\lambda\\left(Y_{n}, o\\right)\\right\\}$ is the MH estimate to $\\lambda$. In order to get $\\hat{\\lambda}_{\\text {CFTP }}$ for a pair of $\\beta$ and $\\gamma$, we have generated independent random copies of $X$ following the pdf $f$ in Eq (9). In the generation of a sample point process of $X$, we applied the CFTP method. We computed the value of $\\lambda(X, o)$ for each sample of $X$. The sample mean of $\\lambda(X, o)$ 's is the CFTP estimate to $\\lambda$. In obtaining $\\hat{\\lambda}_{\\text {AIS }}$, we have generated samples of homogeneous Poisson point processes with varying values of intensity using Algorithm 1. The number of samples in step $t, t \\geq 1$, was set to be $n_{1}=500$ in the first step, and $n_{2}=n_{3}=\\ldots=100$ in the following steps. By setting $\\eta_{1}=0.05^{2}$, the relative standard error of $\\hat{\\lambda}_{\\text {AIS }}$ was intended to be 0.05 or less. We also set $\\hat{\\rho}_{0}=\\beta / 3, m_{\\rho}=10^{-10}, M_{\\rho}=10^{10}$, and $\\eta_{2}=0.01$. In the cases of $(\\beta, \\gamma)=(50,0.8)$ and $(\\beta, \\gamma)=(100,0.8)$, the relative standard errors of $\\hat{\\lambda}_{\\text {AIS }}$ are less than 0.05 , the required relative standard error. In the two cases, more iterations were required to satisfy the other stopping criterion that $\\left|\\hat{\\rho}_{t}-\\hat{\\rho}_{t-1}\\right| / \\hat{\\rho}_{t-1}$ should be less than $\\eta_{2}$.\n\nTable 1 shows that the three estimators give similar estimates to $\\lambda$ for all pairs of $\\beta$ and $\\gamma$. Note that both $\\hat{\\lambda}_{\\mathrm{MH}}$ and $\\hat{\\lambda}_{\\mathrm{AIS}}$ are asymptotically unbiased estimator of $\\lambda$, while $\\hat{\\lambda}_{\\mathrm{CFTP}}$ is an unbiased estimator of $\\lambda$ for any finite number of samples. Since the relative standard error of $\\hat{\\lambda}_{\\text {CFTP }}$ is sufficiently small in this example, the estimated value of $\\lambda$ by the CFTP method may be close to the true value of $\\lambda$ for given pair of $\\beta$ and $\\gamma$, which means that both $\\hat{\\lambda}_{\\mathrm{MH}}$ and $\\hat{\\lambda}_{\\mathrm{AIS}}$ gave reliable estimates of $\\lambda$. Thus, we can see that we have done a sufficient number of iterations in obtaining $\\hat{\\lambda}_{\\mathrm{MH}}$, and that the estimator $\\hat{\\lambda}_{\\mathrm{MH}}$ worked well. This conclusion also holds for the estimator $\\hat{\\lambda}_{\\text {AIS }}$.\n\nContrary to the fact that both the CFTP and the MH methods require approximately the same number of samples to get an estimate to $\\lambda$, the simulation time to get $\\hat{\\lambda}_{\\text {CFTP }}$ is much larger than that of $\\hat{\\lambda}_{\\mathrm{MH}}$. This is because it takes a very long time to generate a sample point process of $X$ using the CFTP method compared to the MH method. We can see from Table 1 that it took a little time to get an estimate of $\\lambda$ using the AIS method except the cases of $\\gamma=0.2$. Since it takes a very little time to generate a homogeneous Poisson point process, the AIS method is much faster than the MH and the CFTP methods in generation of a sample point process. This explains why the simulation time of the AIS method is smaller than the other methods except the cases of $\\gamma=0.2$. In the cases of $\\gamma=0.2$, the required number of samples for $\\hat{\\lambda}_{\\text {AIS }}$ to have the desired relative standard error is huge and it took very long time to generate the required number of samples.\n\nWe can see from Table 1 that the number of samples required for $\\hat{\\lambda}_{\\text {AIS }}$ is larger than those of $\\hat{\\lambda}_{\\mathrm{MH}}$ and $\\hat{\\lambda}_{\\text {CFTP }}$ for all pairs of $\\beta$ and $\\gamma$. This is due to the fact that in the AIS method the generated point processes do not follow the pdf $f$ in Eq (9) but follow a homogeneous Poisson point process. This makes the variance of the likelihood ratio $w_{t}(X)$ for a generated sample $X$ in Algorithm 1 be large, which results in the large value of $\\hat{\\sigma}_{t}^{2}$ in Algorithm 1. By generating a large number of sample point processes, the AIS method reduces the relative standard error of $\\hat{\\lambda}_{\\text {AIS }}$. The sample point processes generated by the CFTP method follow the pdf $f$ exactly, and those of the MH method follow the pdf $f$ asymptotically. This explains why the two methods require approximately the same number of samples to get the same relative standard error.\n\nFigure 2 illustrates realizations of Strauss point processes and homogeneous Poisson point processes. The top-left panel of the figure shows a realization of the Strauss point process with $\\beta=100$ and $\\gamma=0.2$, and the top-right panel with $\\beta=100$ and $\\gamma=0.8$. The bottom-left panel of the figure shows a realization of the homogeneous Poisson point process with intensity 34 , which is the estimated value of $\\lambda$ of the Strauss point process shown on the top-left panel. This is the same with the bottom-right panel, where the intensity is 62 . The estimated $\\lambda$ 's of the Strauss point processes on the top panels can be found in Table 1.\n\nWe can see that that the left two panels of Figure 2 look very different from each other. It implies that for a point process $X$ generated from $\\operatorname{Poi}(S, 34)$, the likelihood ratio $w(X)$ computed in Algorithm 1 for the estimation of $\\lambda$ of the Strauss point process shown on the top-left panel may be very small, which results in the degeneracy, and leads a large variance of $\\hat{\\mu}_{t}$. The right two panels of the figure look similar to each other. It implies that the degeneracy does not occur, and that the variance of the\n\n![img-1.jpeg](img-1.jpeg)\n\nFig. 2: Plots of realizations for point processes on the unit square: (a) the stationary Strauss point process with $\\beta=100$ and $\\gamma=0.2$, (b) the stationary Strauss point process with $\\beta=100$ and $\\gamma=0.8$, (c) the Poisson point process with $\\rho=34$, and (d) the Poisson point process with $\\rho=62$.\nestimator will not take a large value. Thus, we needed much more importance samples of $X$ in the former case in order to get the desired relative error.\n\nTable 1 shows the time-variances of $\\bar{\\lambda}_{\\mathrm{MH}}, \\bar{\\lambda}_{\\text {CFTP }}$, and $\\bar{\\lambda}_{\\text {AIS }}$. For the cases with $(\\beta, \\gamma) \\neq(100,0.2)$, the table shows that the time-variances of $\\bar{\\lambda}_{\\text {AIS }}$ are 2 to 58 times smaller than those of $\\bar{\\lambda}_{\\mathrm{MH}}$, and they are 23 to 410 times smaller than those of $\\bar{\\lambda}_{\\mathrm{CFTP}}$. This means that the AIS method is 2 to 58 times faster than the MH method, and that it is 23 to 410 times faster than the CFTP method in terms of the simulation time to get the same level of accuracy. Thus, in the case of $(\\beta, \\gamma) \\neq(100,0.2)$, the AIS method is more efficient than the CFTP and the MH methods.\n\nFor the pair of $(\\beta, \\gamma)=(100,0.2)$, the ratio of the time-variance of $\\bar{\\lambda}_{\\mathrm{MH}}$ to that of $\\bar{\\lambda}_{\\text {AIS }}$ is 0.01 . Thus, the MH method is more efficient than the AIS method in these cases. The ratio of the time-variance of $\\bar{\\lambda}_{\\text {CFTP }}$ to that of $\\bar{\\lambda}_{\\text {AIS }}$ for the pair of $(\\beta, \\gamma)=(100,0.2)$ is 0.7 , which means that the CFTP method is more efficient than the AIS method in this pair. In conclusion, we can see that the AIS method is more efficient than the other methods in the case with large values of $\\gamma$, and that the larger the value of $\\gamma$ is, the more efficient the AIS method is.\n\nTable 2: The estimate to $\\mu$, its standard error, and some metrics related to the corresponding simulation\n\n![table_1](table_1)",
      "tables": {
        "table_0": "| $\\beta=50$ |  |  |  |  |  |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n| $\\gamma$ | method | $\\hat{\\lambda}$ | s.e | simulation time | number of samples | time-variance | t-v ratio |\n| 0.2 | MH | 23.6 | 1.2 | 292 | 313 | 408 | 2.1 |\n|  | CFTP | 23.6 | 1.2 | 3211 | 309 | 4510 | 23 |\n|  | AIS | 24.8 | 1.2 | 129 | $9.1 \\times 10^{4}$ | 199 | 1 |\n| 0.4 | MH | 25.6 | 1.3 | 176 | 184 | 286 | 22 |\n|  | CFTP | 28.0 | 1.4 | 1558 | 164 | 3034 | 237 |\n|  | AIS | 28.9 | 1.4 | 6.3 | 4000 | 13 | 1 |\n| 0.6 | MH | 30.5 | 1.5 | 92 | 87 | 209 | 58 |\n|  | CFTP | 31.5 | 1.6 | 566 | 71 | 1387 | 385 |\n|  | AIS | 30.0 | 1.5 | 1.7 | 1100 | 3.6 | 1 |\n| 0.8 | MH | 38.5 | 1.9 | 34 | 21 | 123 | 44 |\n|  | CFTP | 37.2 | 1.8 | 193 | 29 | 629 | 225 |\n|  | AIS | 39.3 | 1.4 | 1.4 | 900 | 2.8 | 1 |\n| $\\beta=100$ |  |  |  |  |  |  |  |\n| 0.2 | MH | 31.1 | 1.6 | 822 | 558 | 1981 | 0.01 |\n|  | CFTP | 35.4 | 1.8 | $4.0 \\times 10^{4}$ | 460 | $1.3 \\times 10^{5}$ | 0.7 |\n|  | AIS | 34.0 | 1.7 | $6.2 \\times 10^{4}$ | $5.2 \\times 10^{6}$ | $1.8 \\times 10^{5}$ | 1 |\n| 0.4 | MH | 38.8 | 1.9 | 445 | 284 | 1670 | 5.1 |\n|  | CFTP | 39.9 | 2.0 | $1.2 \\times 10^{4}$ | 220 | $4.8 \\times 10^{4}$ | 147 |\n|  | AIS | 42.3 | 2.1 | 73 | $3.3 \\times 10^{4}$ | 328 | 1 |\n| 0.6 | MH | 47.8 | 2.4 | 206 | 125 | 1172 | 25 |\n|  | CFTP | 47.2 | 2.3 | 3141 | 82 | $1.7 \\times 10^{4}$ | 368 |\n|  | AIS | 45.9 | 2.3 | 9.0 | 3500 | 48 | 1 |\n| 0.8 | MH | 62.6 | 3.1 | 85 | 40 | 826 | 33 |\n|  | CFTP | 64.4 | 3.2 | 999 | 34 | $1.0 \\times 10^{5}$ | 410 |\n|  | AIS | 62.5 | 2.8 | 3.2 | 1200 | 25 | 1 |",
        "table_1": "| $\\beta=50$ |  |  |  |  |  |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n| $\\gamma$ | method | $\\hat{\\mu}$ | s.e | simulation time | number of samples | time-variance | t-v ratio |\n| 0.4 | MH | 0.61 | 0.031 | 861 | 623 | 0.8 | 83 |\n|  | CFTP | 0.64 | 0.032 | 6556 | 622 | 6.6 | 678 |\n|  | AIS | 0.61 | 0.030 | 11 | $1.8 \\times 10^{4}$ | $\\mathbf{0 . 0 1}$ | 1 |\n| 0.8 | MH | 0.69 | 0.035 | 1001 | 596 | 1.2 | 891 |\n|  | CFTP | 0.72 | 0.036 | 5174 | 579 | 6.7 | 5028 |\n|  | AIS | 0.69 | 0.033 | 1.2 | 2000 | $\\mathbf{0 . 0 0 1}$ | 1 |\n| $\\beta=100$ |  |  |  |  |  |  |  |\n| 0.4 | MH | 1.00 | 0.050 | 790 | 395 | 2.0 | 16 |\n|  | CFTP | 1.06 | 0.053 | $6.3 \\times 10^{5}$ | 420 | 1740 | $1.4 \\times 10^{4}$ |\n|  | AIS | 0.96 | 0.048 | 54 | $8.8 \\times 10^{4}$ | $\\mathbf{0 . 1 2}$ | 1 |\n| 0.8 | MH | 1.16 | 0.058 | 963 | 342 | 3.3 | 771 |\n|  | CFTP | 1.46 | 0.073 | $1.4 \\times 10^{5}$ | 261 | 723 | $1.7 \\times 10^{5}$ |\n|  | AIS | 1.20 | 0.059 | 1.2 | 1800 | $\\mathbf{0 . 0 0 4}$ | 1 |"
      },
      "images": {
        "img-1.jpeg": "data:image/jpeg;base64,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"
      }
    },
    {
      "section_id": 16,
      "text": "# 6.2 Estimation of the expected number of points for an inhomogeneous Strauss point process \n\nIn this subsection, we consider an inhomogeneous Strauss point process $X$ on a bounded region $S=[-0.5,0.5] \\times[-0.5,0.5]$. The range of interaction of $X$ is 0.1 . The pdf of $X$ is as follows: for $\\beta>0,0<\\gamma<1$,\n\n$$\nf(x ; \\beta, \\gamma) \\propto \\beta^{n(x)} \\gamma^{D(x)} \\prod_{\\xi \\in x} \\exp \\left(-\\alpha \\xi_{2}^{2}\\right), \\quad x \\in \\mathcal{N}\n$$\n\nwhere $D(x)=\\sum_{\\{\\xi, \\eta\\} \\subset x} I(\\|\\xi-\\eta\\| \\leq 0.1)$ and $\\xi_{2}$ is the $y$-coordinate of a point $\\xi$. Then, the Papangelou conditional intensity is given by\n\n$$\n\\lambda_{f}(x, \\xi)=\\beta \\gamma^{\\sum_{\\eta \\in x} I(\\|\\xi-\\eta\\| \\leq 0.1)} \\exp \\left(-\\xi_{2}^{2}\\right), \\quad x \\in \\mathcal{N}, \\xi \\in S \\backslash x\n$$\n\nNote that $\\lambda_{f}(x, \\xi) \\leq \\beta$. This implies that $X$ is a locally stable point process. Let $S_{b}=\\left\\{\\xi \\in S ;\\left|\\xi_{2}\\right| \\geq 0.49\\right\\}$. If we define $K(x)=\\sum_{\\xi \\in x} I\\left(\\xi \\in S_{b}\\right)$, then the expected number of points of $X$ belonging to $S_{b}$ is represented as\n\n$$\n\\mu=E_{f}[K(X)]\n$$\n\nFor various values of $\\beta$ and $\\gamma$, we estimated the value of $\\mu$ by the three estimation methods. As in the previous example, the number of sample point processes generated for obtaining an estimate was determined so that the estimate has a relative standard error of about 0.05 or less. In obtaining $\\hat{\\mu}_{\\mathrm{MH}}, \\hat{\\mu}_{\\mathrm{CFTP}}$, and $\\hat{\\mu}_{\\mathrm{AIS}}$, we applied the same procedures as described in the previous subsection. Table 2 shows $\\hat{\\mu}_{\\mathrm{MH}}, \\hat{\\mu}_{\\mathrm{CFTP}}$, and $\\hat{\\mu}_{\\mathrm{AIS}}$ for each pair of $\\beta$ and $\\gamma$, and shows their standard errors. The simulation times and the numbers of samples generated to obtain $\\hat{\\mu}_{\\mathrm{MH}}, \\hat{\\mu}_{\\mathrm{CFTP}}$, and $\\hat{\\mu}_{\\mathrm{AIS}}$, respectively, are also shown in Table 2.\n\nIn Table 2, we can see that the three estimators gave similar estimates to $\\mu$ for all pairs of $\\beta$ and $\\gamma$. In the same reason as in the previous subsection, $\\hat{\\mu}_{\\text {CFTP }}$ is a reliable estimate to $\\mu$, which implies that $\\hat{\\mu}_{\\mathrm{MH}}$ and $\\hat{\\mu}_{\\mathrm{AIS}}$ are also reliable estimates to $\\mu$. As expected, the number of samples for $\\hat{\\mu}_{\\mathrm{AIS}}$ is much larger than those of $\\hat{\\mu}_{\\mathrm{MH}}$ and $\\hat{\\mu}_{\\text {CFTP }}$ for all pairs of $\\beta, \\gamma$. However, it took very little time to get a single estimate to $\\mu$ using the AIS method compared to those of the CFTP and the MH methods for all pairs of $\\beta$ and $\\gamma$.\n\nTable 2 shows that the time-variances of $\\hat{\\mu}_{\\text {AIS }}$ are 16 to 891 times smaller than those of $\\hat{\\mu}_{\\mathrm{MH}}$, and they are 678 to $1.7 \\times 10^{5}$ times smaller than those of $\\hat{\\mu}_{\\mathrm{CFTP}}$. In order to get an estimate with the same relative standard error, the AIS method is 16 to 891 times faster than the MH method, and that it is 678 to $1.7 \\times 10^{5}$ times faster than the CFTP method in terms of the simulation time. Thus, the AIS method is more efficient than both the CFTP and the MH methods.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 17,
      "text": "# 7 Conclusion \n\nFor a statistic of a locally stable point process in a bounded region, we proposed an adaptive importance sampling for the estimation of the expected value of the statistic. In our proposal, the importance sampling point process is restricted to the family of homogeneous Poisson point processes. We applied the cross-entropy minimization method to find the optimal intensity of the importance point process. In the proposed scheme, the expected value of the statistic and the optimal intensity are iteratively estimated in an adaptive manner. We proved the consistency of the proposed estimator and the asymptotic normality of it. In the numerical study, we considered two examples, in which we applied the proposed scheme to the estimation of the intensity of a stationary Strauss point process, and to the estimation of the expected number of points belonging to a subregion for an inhomogeneous Strauss point process on a bounded region. Numerical results showed that the proposed estimator is more efficient than the CFTP and the MH estimators in terms of the time-variance performance. This is due to the fact that it takes very little time to generate a sample point process following a homogeneous Poisson point process. However, if the stochastic property of the nominal density is too different from that of the homogeneous Poisson point process, then the variance of likelihood ratio becomes large, which results in requiring a large number of samples in order to get a reliable estimate, and thus makes the proposed scheme inefficient.\n\nAs for further research, we suggest to apply the sequential importance resampling when generating sample point processes. Through the method, we expect to generate sample point processes whose stochastic property is similar to that of the nominal point process, or to that of a desired distribution.\n\nAcknowledgements. This research was supported by the 2023 Research Fund of the University of Seoul. We would like to thank the three anonymous referees. Their comments on the first draft of the paper are critical and helpful for the great improvement in the representation of the paper.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 18,
      "text": "# References \n\nAnderssen, R., Baddeley, A., Hoog, F.d., Nair, G.: Numerical solution of an integral equation from point process theory. Journal of Integral Equations and Applications 26(4), 437-452 (2014)\n\nBugallo, M.F., Elvira, V., Martino, L., Luengo, D., Miguez, J., Djuric, P.M.: Adaptive importance sampling: The past, the present, and the future. IEEE Signal Processing Magazine 34(4), 60-79 (2017)\n\nBaddeley, A., Nair, G.: Fast approximation of the intensity of Gibbs point processes. Electronic Journal of Statistics 6, 1155-1169 (2012)\n\nBaddeley, A., Nair, G.: Poisson-saddlepoint approximation for Gibbs point processes with infinite-order interaction: in memory of Peter Hall. Journal of Applied Probability 54(4), 1008-1026 (2017)\n\nBaddeley, A., Rubak, E., Turner, R.: Spatial Point Patterns: Methodology and Applications with R. CRC press, Boca Raton (2016)\n\nBaddeley, A., Turner, R.: spatstat: An R package for analyzing spatial point patterns. Journal of Statistical Software 12(6), 1-42 (2005)\n\nChung, K.L.: A Course in Probability Theory, 2nd edn. Academic Press, San Diego (1974)\n\nChiu, S.N., Stoyan, D., Kendall, W.S., Mecke, J.: Stochastic Geometry and Its Applications, 3rd edn. John Wiley \\& Sons, Chichester (2013)\n\nDe Boer, P.-T., Kroese, D.P., Mannor, S., Rubinstein, R.Y.: A tutorial on the crossentropy method. Annals of Operations Research 134, 19-67 (2005)\n\nEtemadi, N.: Convergence of weighted averages of random variables revisited. Proceedings of the American Mathematical Society 134, 2739-2744 (2006)\n\nFeller, W.: An Introduction to Probability Theory and Its Applications vol. 2, 2nd edn. John Wiley \\& Sons, New York (1991)\n\nGeorgii, H.-O.: Canonical and grand canonical Gibbs states for continuum systems. Communications in Mathematical Physics 48(1), 31-51 (1976)\n\nGeweke, J.: Bayesian inference in econometric models using Monte Carlo integration. Econometrica: Journal of the Econometric Society 57(6), 1317-1339 (1989)\n\nGeyer, C.J., M\u00f8ller, J.: Simulation procedures and likelihood inference for spatial point processes. Scandinavian Journal of Statistics 21(4), 359-373 (1994)\n\nGlynn, P.W., Whitt, W.: The asymptotic efficiency of simulation estimators. Operations Research 40(3), 505-520 (1992)\n\nHesterberg, T.: Weighted average importance sampling and defensive mixture distributions. Technometrics 37(2), 185-194 (1995)\n\nHall, P., Heyde, C.C.: Martingale Limit Theory and Its Application. Academic press, New York (2014)\n\nIllian, J., Penttinen, A., Stoyan, H., Stoyan, D.: Statistical Analysis and Modelling of Spatial Point Patterns. John Wiley \\& Sons, Chichester (2008)\n\nKendall, W.S., M\u00f8ller, J.: Perfect Metropolis-Hastings Simulation of Locally Stable Point Processes. University of Aarhus. Centre for Mathematical Physics and Stochastics, Aarhus (2000)\n\nKendall, W.S., M\u00f8ller, J.: Perfect simulation using dominating processes on ordered spaces, with application to locally stable point processes. Advances in Applied Probability 32(3), 844-865 (2000)\n\nKelly, F.P., Ripley, B.D.: A note on strauss's model for clustering. Biometrika 63(2), $357-360(1976)$\n\nM\u00f8ller, J.: Markov chain Monte Carlo and spatial point processes. In: Stochastic Geometry, pp. 141-172. Chapman \\& Hall/CRC Press, Boca Raton (1999)\n\nM\u00f8ller, J., Waagepetersen, R.P.: Statistical Inference and Simulation for Spatial Point Processes. CRC Press, Boca Raton (2003)\n\nNguyen, X.X., Zessin, H.: Ergodic theorems for spatial processes. Zeitschrift f\u00fcr Wahrscheinlichkeitstheorie und verwandte Gebiete 48(2), 133-158 (1979)\n\nOh, M.-S., Berger, J.O.: Adaptive importance sampling in monte carlo integration. Journal of Statistical Computation and Simulation 41(3-4), 143-168 (1992)\n\nOwen, A.B.: Monte Carlo Theory, Methods and Examples, (2013). https://artowen. su.domains/mc/\n\nPropp, J.G., Wilson, D.B.: Exact sampling with coupled Markov chains and applications to statistical mechanics. Random Structures \\& Algorithms 9(1-2), 223-252 (1996)\n\nR Core Team: R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna (2021). R Foundation for Statistical Computing. https://www.R-project.org/\n\nRobert, C.P., Casella, G.: Monte Carlo Statistical Methods, 2nd edn. Springer, New York (1999)\n\nRipley, B.D.: Modelling spatial patterns. Journal of the Royal Statistical Society: Series B (Methodological) 39(2), 172-192 (1977)\n\nRubinstein, R.Y., Kroese, D.P.: Simulation and the Monte Carlo Method, 3rd edn. John Wiley \\& Sons, Hoboken (2016)\n\nSak, H., H\u00f6rmann, W.: Fast simulations in credit risk. Quantitative Finance 12(10), $1557-1569$ (2012)\n\nStrauss, D.J.: A model for clustering. Biometrika 62(2), 467-475 (1975)",
      "tables": {},
      "images": {}
    }
  ],
  "id": "2408.07372v2",
  "authors": [
    "Hee-Geon Kang",
    "Sunggon Kim"
  ],
  "categories": [
    "stat.ML",
    "cs.LG",
    "stat.CO"
  ],
  "abstract": "The problem of finding the expected value of a statistic of a locally stable\npoint process in a bounded region is addressed. We propose an adaptive\nimportance sampling for solving the problem. In our proposal, we restrict the\nimportance point process to the family of homogeneous Poisson point processes,\nwhich enables us to generate quickly independent samples of the importance\npoint process. The optimal intensity of the importance point process is found\nby applying the cross-entropy minimization method. In the proposed scheme, the\nexpected value of the function and the optimal intensity are iteratively\nestimated in an adaptive manner. We show that the proposed estimator converges\nto the target value almost surely, and prove the asymptotic normality of it. We\nexplain how to apply the proposed scheme to the estimation of the intensity of\na stationary pairwise interaction point process. The performance of the\nproposed scheme is compared numerically with the Markov chain Monte Carlo\nsimulation and the perfect sampling.",
  "updated": "2025-03-01T05:24:13Z",
  "published": "2024-08-14T08:38:41Z"
}