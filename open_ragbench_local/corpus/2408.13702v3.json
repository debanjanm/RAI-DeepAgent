{
  "title": "Examining Differential Item Functioning (DIF) in Self-Reported Health\n  Survey Data: Via Multilevel Modeling",
  "sections": [
    {
      "section_id": 0,
      "text": "#### Abstract\n\nFew health-related constructs or measures have received a critical evaluation in terms of measurement equivalence, such as self-reported health survey data. Differential item functioning (DIF) analysis is crucial for evaluating measurement equivalence in self-reported health surveys, which are often hierarchical in structure. Traditional single-level DIF methods in this case fall short, making multilevel models a better alternative. We highlight the benefits of multilevel modeling for DIF analysis, when applying a health survey data set to multilevel binary logistic regression (for analyzing binary response data) and multilevel multinominal logistic regression (for analyzing polytomous response data), and comparing them with their single-level counterparts. Our findings show that multilevel models fit better and explain more variance than single-level models. This article is expected to raise awareness of multilevel modeling and help healthcare researchers and practitioners understand the use of multilevel modeling for DIF analysis.\n\n\nKeywords: differential item functioning, measurement equivalence, multilevel modeling, health disparity, population density, depression",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 1,
      "text": "# 1 Introduction \n\nTo examine the disproportionate impact of health interventions or other determinants on health outcomes for certain populations, including disadvantaged minorities, it is crucial to establish measurement equivalence when evaluating outcomes across groups differing in gender, ethnicity, and other demographic factors. While validating psychometric instruments has been a routine practice in research, critical evaluations of measurement equivalence, particularly through differential item functioning (DIF) analysis, have historically been limited [1]. In recent years, however, there has been significant progress in this area, with a growing body of research employing DIF analysis to investigate measurement equivalence [e.g., 2-7].\n\nThis growing research underscores the need for continued evaluation of health constructs and measures to ensure fairness and validity in assessing health outcomes for diverse populations. It is worth noting that some health studies did not clearly describe the method used for DIF analysis [e.g., 3], and conventional DIF methods based on single-level models were frequently used to analyze health survey data with a nesting structure [e.g., 2], for which recent DIF methods based on multilevel models are better alternatives in terms of accuracy of DIF estimation. By employing advanced methodologies for DIF, researchers can better evaluate health measures to ensure fairness and validity in assessing health outcomes for diverse populations.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 2,
      "text": "## 2 Challenge: Examine DIF in self-reported health survey data\n\nSelf-reported health survey data encapsulate rich information about physical, mental, and social health trends of the studied population [e.g., 8, 9]. However, its inherent subjectivity makes it susceptible to geographical, cultural, and socioeconomic biases, which can threaten the validity of the data and pose challenges in getting to know the truth [e.g., 10]. The utilization of self-reported health survey data in public health research and interventions necessitates a rigorous examination of the validity of this data. It underscores the importance of adopting appropriate methods that can navigate the complexities associated with self-reported health data and improve the accuracy of our findings.\n\nExisting research has shown that bias can manifest itself as construct bias, method bias, and item bias [e.g., 11, 12]. The framework of differential item functioning [DIF; 13] underpins many modern methods to investigate item bias, specifically. In the psychometric literature, DIF analysis examines whether there is a systematic betweengroup difference in examinees' probability to answer an item correctly when controlling for their ability [14]. While DIF is not equivalent to item bias, the former can provide evidence for the latter when it arises from content or characteristics of the item that are unrelated to the intended construct being measured $[15,16]$. Some existing DIF methods examine both uniform and nonuniform DIF while many others do not. Uniform DIF occurs when respondents from one group consistently outperform respondents of the same latent trait from another group; nonuniform DIF exists when this performance difference is not consistent [17].\n\nTo examine systematic between-group differences in self-reported health survey data, we can apply existing DIF methods by generalizing DIF-related concepts via the following modifications:\n\n1. focusing on the response of interest instead of a \"correct\" response,\n2. describing the subjects who provide responses as \"respondents\" instead of \"examinees,\"\n3. using a latent trait variable instead of \"ability,\" selecting one closely related to the probability of obtaining the response of interest (similar to how \"ability\" relates to the probability of a correct response in the conventional DIF framework).\n\nThe corresponding terminology may shift in the applications of DIF to address the unique contexts in health research.\n\nMost DIF methods currently used in health research, as well as in the broader DIF literature, are based on single-level modeling [e.g., 2]. They are not best suited for selfreported health survey data that has a nesting or hierarchical structure (e.g., individual responses are nested within larger units differentiated by population density, economy, and culture). These single-level DIF methods include the logistic regression procedure [LR; 18], the Mantel-Haenszel procedure [MH; 19], Lord's Wald test [20], and the IRT likelihood-ratio test [IRT-LR; 21]. The first two do not require the IRT model and are labeled with \"the observed-score approach,\" whereas the latter two require the IRT model and are categorized as \"the IRT approach\" [22, 23]. An extensive review of these methods can be found in Chen [24].\n\nSingle-level modeling approaches have at least three problems when the response data has a hierarchical structure. First, they waste information and render inaccurate estimates because of the lack of consideration of variances between hierarchies of the data [25]. Second, they do not help model the effect of higher-level variables associated with DIF on the outcome variable at the lower level [26]. Third, their model estimates are limited to describing the sample and are not generalizable to describe the population [27]. Moreover, most of the single-level DIF methods are limited to the analysis of two groups at a time, showing inflated error rates for DIF analyses involving more than two groups [24, 28, 29].",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 3,
      "text": "# 3 Solution: Multilevel modeling for DIF analysis \n\nFor the self-reported health survey data that is hierarchical in nature, multilevel modeling has been demonstrated to be a superior alternative to single-level modeling. It effectively addresses issues that arise in DIF methods built on single-level models. First, multilevel modeling is advantageous when fundamental assumptions in singlelevel modeling such as independence and homoscedasticity are violated, as is often the case with hierarchical data [25]. In this regard, multilevel modeling can account for correlated errors resulting from the dependency of individual observations within a nested structure, and it does not require the same sample size or variance for higher-level units due to its randomization approach [30].\n\nSecond, multilevel modeling allows for the assessment of higher-level variables' impact on DIF [26]. For instance, it can evaluate how cluster-level factors, like access\n\nto healthcare facilities, influence individual responses in health surveys, and identify whether these cluster characteristics contribute to DIF observed between population groups (e.g., gender, ethnicity, location) at the lower level of the model. Third, results from multilevel modeling are generalizable to the population because it incorporates random effects from higher-level clusters [27]. This ensures that conclusions about DIF in self-reported response data are applicable to a broader range of demographic groups. Fourth, multilevel modeling accommodates multi-group analyses by using multiple dummy-coded variables to cover more than two groups [31]. For instance, it can include multiple age groups in health data, allowing researchers to analyze and compare health outcomes across various age categories while accounting for cluster-specific random effects.\n\nThe first published work on DIF using multilevel modeling was by Swanson et al. [31], who adopted a multilevel binary LR model. This approach significantly improved the accuracy of DIF estimates and pooled information across items to explain sources of DIF, when including random item effects. Subsequently, den Noortgate and de Boeck [32] proposed a series of multilevel models for DIF analysis, grounded in the Rasch model within item response theory (IRT). These models demonstrated the potential to integrate random effects associated with respondents, items, or other factors, along with item- or group-related covariates, to explain DIF. French and Finch [33] proposed a multilevel MH statistic that adjusts the traditional MH statistic using a ratio of random variances from the multilevel model from Swanson et al. [31]. Huang and Valdivia [34] introduced a multilevel Wald test for polytomous items based on Lord's Wald $\\chi^{2}$ test.\n\nEach of these multilevel approaches offers unique benefits, but they also come with specific limitations. For instance, the models from den Noortgate and de Boeck [32] leverage the rigor of IRT, allowing for a deeper integration of item- and respondentlevel characteristics and providing insights into hierarchical data structures. However, these models rely on assumptions such as local independence of item responses and monotonicity of response probabilities, which can be restrictive or challenging to meet in certain applications [35]. In contrast, the multilevel LR model adapted from Swanson et al. [31] offers greater versatility by not requiring such stringent assumptions, making it suitable for contexts where IRT assumptions might not hold.\n\nThe choice of method depends on the research objectives and the nature of the data. For example, the IRT-based multilevel models proposed by den Noortgate and de Boeck [32] are particularly useful when the goal is to investigate complex random effects structures or when there is a need for a model grounded in the theoretical framework of IRT. However, these models may be computationally intensive and less intuitive for practitioners unfamiliar with IRT. Conversely, the multilevel LR model provides a balance of flexibility and interpretability, making it a practical choice for broader applications.\n\nIn the following sections, we demonstrate the use of two types of multilevel models corresponding to binary and polytomous response data, based on Swanson et al. [31] because of the versatility. First, for analyzing DIF in binary response data from a survey item, we utilize the multilevel binary $L R$ adapted from Swanson et al. [31]. Its single-level counterpart, the LR procedure [18], is reviewed in Appendix A, hereafter\n\nreferred to as \"traditional LR\". Second, for analyzing DIF in polytomous response data, we propose the multilevel multinominal $L R$. Its single-level counterpart is the multinominal LR, a type of multicategory logit models for unordered categories and is seen as a generalization of the binary LR [36]. Throughout this writing, we use the word \"group\" when referring to the group membership variable for group comparisons in DIF analysis, and the word \"cluster\" when referring to units of analyses across levels in the hierarchical data structure in multilevel modeling.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 4,
      "text": "# 3.1 Multilevel Binary LR for Binary Responses \n\nThe multilevel binary LR [31] was initially designed to include random effects associated with items, accounting for variations among items and offering more accurate DIF estimates compared to the traditional LR [18]. We have modified its notation to allow the incorporation of more than one focal group and of random effects from higherlevel clusters in hierarchical data (e.g., access to healthcare, geographical locations, age groups, education levels).\n\nIn this modified version, the level-1 submodel pertains to responses to a studied item from individual respondents, indexed by $p$, within a level-2 stratum, indexed by $i$. This two-level binary LR model is specified as follows:\n\nLevel 1:\n\n$$\n\\operatorname{logit}\\left(\\pi_{p i}\\right)=\\log \\left(\\frac{\\pi_{p i}}{1-\\pi_{p i}}\\right)=\\beta_{0 i}+\\beta_{1 i} \\theta_{p}+\\boldsymbol{\\beta}_{\\mathbf{2 i}} \\boldsymbol{g}_{\\boldsymbol{p}}\n$$\n\nLevel 2:\n\n$$\n\\begin{aligned}\n& \\beta_{0 i}=\\delta_{00}+U_{0 i} \\\\\n& \\beta_{1 i}=\\delta_{10}+U_{1 i} \\\\\n& \\boldsymbol{\\beta}_{\\mathbf{2 i}}=\\boldsymbol{\\delta}_{\\mathbf{2 0}}+U_{2 i}\n\\end{aligned}\n$$\n\nwhere\n$\\pi_{p i}$ is the probability for respondent $p$ to provide the targeted response to the studied item (i.e., the \"probability targeted\");\n$\\beta_{0 i}$ denotes the log-odds of the \"probability targeted\" in the reference group;\n$\\beta_{1 i}$ is the effect of respondents' latent trait on the log-odds of the \"probability targeted\" in the reference group;\n$\\boldsymbol{\\beta}_{\\mathbf{2 i}}$ is a vector for the deviation effect in a focal group from the reference group;\n$\\theta_{p}$ is the latent trait of respondent $p$ (e.g., it could be proxied by a continuous variable concerning the respondent's overall health status);\n$\\boldsymbol{g}_{\\boldsymbol{p}}$ is a vector containing dummy-coded variables representing the group membership of respondent $p$, specified as $\\left[g_{p 1} g_{p 2} \\cdots g_{p J}\\right]\\left(g_{p j}=1\\right.$ for being in the target group, indexed by $j=1,2, \\cdots, J$ );\n$\\delta_{00}$ is the average log-odds of the \"probability targeted;\"\n$\\delta_{10}$ is the average effect associated with respondents' latent trait;\n$\\boldsymbol{\\delta}_{\\mathbf{2 0}}$ is a vector for the average effect associated with being in each focal group;\n$U_{0 i}$ is the random effect associated with level-2 clusters on the intercept $\\beta_{0 i}$;\n$U_{1 i}$ and $U_{2 i}$ denote the random effect associated with level-2 clusters on the slopes $\\beta_{1 i}$ and $\\boldsymbol{\\beta}_{\\mathbf{2 i}}$, respectively;\n\n$U_{0 i}, U_{1 i}$, and $U_{2 i}$ follow a multivariate normal distribution with the mean being 0 .\nThe level-1 submodel of the multilevel binary LR is a binary LR model, similar to the one in traditional LR but without an ability-group interaction term. It is limited to binary response data analysis. The level-2 submodel in the multilevel binary LR accounts for random effects associated with higher-level clusters. When using this multilevel binary LR, the studied item exhibits DIF if any coefficient value in the vector $\\boldsymbol{\\beta}_{\\mathbf{2 i}}$ is significantly different from 0 .",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 5,
      "text": "# 3.2 Multilevel Multinominal LR for Polytomous Responses \n\nWe propose the multilevel multinominal LR for analyzing DIF in polytomous response data. Its level-1 submodel is the multinominal extension of the traditional LR but without the ability-group interation term. Its level-2 submodel incorporates random effects tied to higher-level clusters. This two-level multilevel multinominal LR is written as",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 6,
      "text": "## Level 1:\n\n$$\n\\log \\left(\\frac{\\pi_{c . p i}}{\\pi_{B . p i}}\\right)=\\beta_{0 i}+\\beta_{1 i} \\theta_{p}+\\boldsymbol{\\beta}_{2 i} g_{p}\n$$\n\nLevel 2:\n\n$$\n\\begin{aligned}\n\\beta_{0 i} & =\\delta_{00}+U_{0 i} \\\\\n\\beta_{1 i} & =\\delta_{10}+U_{1 i} \\\\\n\\boldsymbol{\\beta}_{2 i} & =\\boldsymbol{\\delta}_{20}+U_{2 i}\n\\end{aligned}\n$$\n\nwhere\n$\\pi_{c . p i}$ is the probability for respondent $p$ to provide a non-baseline response, indexed by $c$, to the studied item $(c=1,2, \\cdots, C)$;\n$\\pi_{B . p i}$ is the probability for respondent $p$ to provide the baseline response, denoted by $B$, to the studied item.\nThe level-1 submodel pairs a selected baseline response with each of the other responses to the survey item, and it has $C$ equations, corresponding to the number of non-baseline responses. Parameters for these equations are estimated separately. For example, when the response data has three unique responses (e.g., 0,1 , and 2 ) and we choose one as the baseline (e.g., 0 ), $C=2$ and the level-1 submodel is written into\n\n$$\n\\begin{aligned}\n& \\text { Equation 1: } \\log \\left(\\frac{\\pi_{1 . p i}}{\\pi_{B . p i}}\\right)=\\beta_{1.0 i}+\\beta_{1.1 i} \\theta_{p}+\\boldsymbol{\\beta}_{1.2 i} g_{p} \\\\\n& \\text { Equation 2: } \\log \\left(\\frac{\\pi_{2 . p i}}{\\pi_{B . p i}}\\right)=\\beta_{2.0 i}+\\beta_{2.1 i} \\theta_{p}+\\boldsymbol{\\beta}_{2.2 i} g_{p}\n\\end{aligned}\n$$",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 7,
      "text": "## 4 Example: Analysis of population-density DIF in NSDUH data\n\nExisting research has demonstrated that population density can affect the quality of life and health perceptions [37-40]. We utilize the NSDUH data released in 2022 to examine population-density-related DIF in the self-reported health survey questions evaluating depression. This data provides comprehensive information on substance use and mental health trends among the U.S. population aged 12 and older. To show the impact of multilevel modeling on DIF results, below we compare the results from\n\nthe multilevel binary LR and the multilevel multinominal LR with their single-level counterparts. We use respondents' education levels as the level-2 clusters in multilevel modeling, for existing research has unveiled that an additional year of education could reduce the likelihood of reporting depression and anxiety [41].\n\nSpecifically, we want to examine whether DIF exists for respondents from high and low population density areas in the probability to answer \"Yes\" to a selected NSDUH survey item. Hence, the targeted response in this DIF analysis is \"Yes\". This item asks respondents the following question: \"Have you ever in your life had a period of time lasting several days or longer when most of the day you felt sad, empty or depressed?\" The latent trait variable to be controlled for is respondents' psychological distress level over the past 30 days, proxied by a score based on their responses to another six survey questions. We acknowledge the potential for DIF in this derived score; however, we do not examine DIF in this instance to maintain our focus on demonstrating the application of multilevel modeling. The reference group is the respondents from areas with low population density, and there are two focal groups: one is the respondents from areas with high population density, and the other is from non-classified areas.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 8,
      "text": "# 4.1 Data preparation \n\nThe original NSDUH data file contains 2,605 variables and 59,069 respondents, composed by 27,047 males and 32,022 females aged 12 and older. We obtained two different data sets from this original data file. In the first data set, we reserve responses recoded with 1 for the response \"Yes\" and 0 for \"No\", retain 45,827 eligible respondents to enable multilevel binary LR. In the second data set, we include responses recoded with 2 for the other valid responses including \"Don't know\", \"Refused\", and blank answers, retaining 47,094 eligible respondents for multilevel multinominal LR. Both the data sets contain no missing values. Table 1 displays sample sizes by level-2 cluster.\n\nWe keep the following four variables for DIF analysis:\n\n1. The item response variable (named \"ADDPREV\" in the survey). It contains responses 0 and 1 for multilevel binary LR modeling, and it include the response 2 for multilevel multinominal LR modeling.\n2. The group membership variable (named \"PDEN10\"). It indicates the population density of the area where respondents are residing. It is recoded to have 0 for \"lowdensity\" (i.e., with fewer than one million people), 1 for \"high-density\" (i.e., with one million or more people), and 2 for areas that are not involved in Core Based Statistical Area (CBSA) classifications. In modeling, this variable is dummy-coded.\n3. The latent trait variable (named \"KSSLR6MON\"). It is a score that describes respondents' distress, ranging from 0 to 24 . This score is closely associated with the probability of obtaining the response of interest in the item response variable.\n4. The level-2 variable (named \"IREDUHIGHST2\"). It describes respondents' education level, and there are 11 distinct levels, ranging from 1 for \"completing fifth grade or less\" to 11 for \"completing college or more advanced education.\"\n\nAppendix B displays information from the NSDUH codebook about how the selected categorical variables were originally coded. Appendix C. 1 documents the R code for this data preparation.\n\nTable 1 Sample size of respondents, by cluster.\n\n![table_0](table_0)\n\nNote. Numbers in parentheses in the header are codes in the data.",
      "tables": {
        "table_0": "| Level-2 clusters | Group |  |  | Response |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n| Edu. level | (0) Low- <br> density area | (1) High- <br> density area | (2) Non- <br> classified area | (0) No | (1) Yes | (2) <br> Others |\n| Data Set 1: With binary responses |  |  |  |  |  |  |\n| 1 | 126 | 140 | 10 | 232 | 44 |  |\n| 2 | 75 | 115 | 5 | 177 | 18 |  |\n| 3 | 45 | 49 | 7 | 82 | 19 |  |\n| 4 | 158 | 102 | 56 | 240 | 76 |  |\n| 5 | 314 | 206 | 39 | 414 | 145 |  |\n| 6 | 407 | 273 | 57 | 529 | 208 |  |\n| 7 | 1228 | 1059 | 142 | 1691 | 738 |  |\n| 8 | 6488 | 4430 | 746 | 7942 | 3722 |  |\n| 9 | 5208 | 3895 | 447 | 5607 | 3943 |  |\n| 10 | 2286 | 1563 | 226 | 2616 | 1459 |  |\n| 11 | 7630 | 7874 | 421 | 10029 | 5896 |  |\n| Data Set 2: With polytomous responses |  |  |  |  |  |  |\n| 1 | 129 | 148 | 10 | 232 | 44 | 11 |\n| 2 | 77 | 120 | 5 | 177 | 18 | 7 |\n| 3 | 47 | 52 | 7 | 82 | 19 | 5 |\n| 4 | 165 | 104 | 58 | 240 | 76 | 11 |\n| 5 | 329 | 214 | 40 | 414 | 145 | 24 |\n| 6 | 422 | 289 | 57 | 529 | 208 | 31 |\n| 7 | 1270 | 1082 | 146 | 1691 | 738 | 69 |\n| 8 | 6716 | 4579 | 769 | 7942 | 3722 | 400 |\n| 9 | 5337 | 3985 | 456 | 5607 | 3943 | 228 |\n| 10 | 2350 | 1603 | 232 | 2616 | 1459 | 110 |\n| 11 | 7791 | 8075 | 430 | 10029 | 5896 | 371 |"
      },
      "images": {}
    },
    {
      "section_id": 9,
      "text": "# 4.2 Analysis and Results \n\nThe modeling results are in Table 2 and Table 3. The models in Table 2 are associated with the multilevel binary LR in (1) for analyzing binary responses, while the models in Table 3 are related to the multilevel multinominal LR in (2) for analyzing polytomous responses. The models in Table 2 were fitted via lme4 package [42] and the models in Table 3 were fitted via brms and rstan packages, with R4.4.0 in RStudio. Appendix C. 2 documents the R code for this modeling.\n\nIn both the tables, the first three models are for multilevel model building, named \"Model 0,\" \"Model 1,\" and \"Model 2,\" and the last model is the single-level model, labeled with \"Model 3.\" Model 0 does not contain explanatory variables in the level1 submodel, commonly known as null model or empty model that sets a baseline for understanding the proportion of variance explained by the hierarchical structure of the data [30]. Model 1 is the exact model used in (1) or (2), incorporating the latent trait and group membership variables. Model 2 adds the interaction term between the latent trait and group membership, which is the interaction term we drop from the traditional LR, to check how the model performance would change with this interaction.\n\nTable 2 Multilevel binary LR: Analyzing binary responses.\n\n![table_1](table_1)\n\nNote. ${ }^{*} p<0.05 ;{ }^{* *} p<0.01 ;{ }^{* * *} p<0.001 . g_{p .1}$ and $g_{p .2}$ correspond to $g_{p}$ when the group membership is 1 and 2 , respectively.\n\nTable 3 Multilevel multinominal LR: Analyzing polytomous responses.\n\n![table_2](table_2)\n\nNote. ${ }^{*} p<0.05 ;{ }^{* *} p<0.01 ;{ }^{* * *} p<0.001 . g_{p .1}$ and $g_{p .2}$ correspond to $g_{p}$ when the focal group's group membership value is 1 and 2 , respectively. $E q_{1}$ and $E q_{2}$ refer to \"Equation 1\" and \"Equation 2\" when the targeted response is 1 and 2 , respectively. They share the same WAIC and $R^{2}$ values for each model.\n\nThe modeling results reveal several key insights regarding the model performance. Model 0 serves as the baseline, showing the proportion of variance attributable to the hierarchical structure of the data. Its intraclass correlation coefficient [ICC; 25] is 0.07 in Table 2 and 0.10 in Table 3, indicating that $7 \\%$ of the response variability stemmed from differences between education levels for the first data set and this proportion is $10 \\%$ for the second data set. These values highlight that accounting for the hierarchical structure in DIF analyses matters with both the data sets.\n\nModel 1 displays a significant negative effect of being from high-density areas on the probability of responding \"Yes\" to the item, for both the data sets. This suggests that the selected survey item has population-density-associated DIF, as individuals residing in high-density areas were less likely to provide the targeted response to the selected item compared to those in low-density areas, after accounting for all these individuals' latent trait about depression. Model 3, the single-level model, does not reveal a significant effect of high population density, which leads to the conclusion that there is no DIF when comparing high- and low-density areas, contrasting with the result from Model 1. This difference underscores the importance of model selection when conducting DIF analyses.\n\nOverall, Model 1 outperforms others, based on model performance statistics. Its intercept variance $\\tau_{0}^{2}$ is among the lowest in both the tables, indicating an advantage of Model 1 in capturing more data variability. Additionally, Model 1 has the lowest value in the model fit index, namely the Akaike information criterion (AIC) in Table 2 and the widely applicable information criterion (WAIC) in Table 3. In addition, Model 1 has the highest conditional $R^{2}$ [43], signifying that the entire model, with random effects and fixed effects in combination, explains $38 \\%$ of the variability in the first data set and $23 \\%$ in the second data set.",
      "tables": {
        "table_1": "|  | Model 0 | Model 1 | Model 2 | Model 3 |\n| :--: | :--: | :--: | :--: | :--: |\n| Fixed effects |  |  |  |  |\n| (Intercept) | $\\begin{gathered} -1.02^{* * *} \\\\ (0.15) \\end{gathered}$ | $\\begin{gathered} -2.37^{* * *} \\\\ (0.15) \\end{gathered}$ | $\\begin{gathered} -2.39^{* * *} \\\\ (0.15) \\end{gathered}$ | $\\begin{gathered} -1.90^{* * *} \\\\ (0.03) \\end{gathered}$ |\n| $\\theta_{p}$ |  | $\\begin{gathered} 0.25^{* * *} \\\\ (0.00) \\end{gathered}$ | $\\begin{gathered} 0.25^{* * *} \\\\ (0.00) \\end{gathered}$ | $\\begin{gathered} 0.25^{* * *} \\\\ (0.00) \\end{gathered}$ |\n| $g_{p .1}$ |  | $\\begin{gathered} -0.12^{* * *} \\\\ (0.02) \\end{gathered}$ | $\\begin{gathered} -0.09^{*} \\\\ (0.04) \\end{gathered}$ | $\\begin{gathered} -0.07 \\\\ (0.04) \\end{gathered}$ |\n| $g_{p .2}$ |  | $\\begin{gathered} 0.01 \\\\ (0.06) \\end{gathered}$ | $\\begin{gathered} -0.05 \\\\ (0.09) \\end{gathered}$ | $\\begin{gathered} -0.12 \\\\ (0.09) \\end{gathered}$ |\n| $\\theta_{p} g_{p .1}$ |  |  | $\\begin{gathered} -0.01 \\\\ (0.01) \\end{gathered}$ | $\\begin{gathered} -0.00 \\\\ (0.01) \\end{gathered}$ |\n| $\\theta_{p} g_{p .2}$ |  |  | $\\begin{gathered} 0.01 \\\\ (0.01) \\end{gathered}$ | $\\begin{gathered} 0.01 \\\\ (0.01) \\end{gathered}$ |\n| Level-2 Variances |  |  |  |  |\n| $\\eta_{1}^{2}$ | 0.25 | 0.22 | 0.22 |  |\n| N | 45827 | 45827 | 45827 | 45827 |\n| ICC | 0.07 | 0.06 | 0.06 |  |\n| AIC | 59233 | 46286 | 46288 | 46809 |\n| $R^{2}$ | 0.07 | 0.38 | 0.38 |  |",
        "table_2": "|  | Model 0 |  | Model 1 |  | Model 2 |  | Model 3 |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  | $E q_{1}$ | $E q_{2}$ | $E q_{1}$ | $E q_{2}$ | $E q_{1}$ | $E q_{2}$ | $E q_{1}$ | $E q_{2}$ |\n| Fixed effects |  |  |  |  |  |  |  |  |\n| (Intercept) | $\\begin{gathered} -1.02^{* * *} \\\\ (0.19) \\end{gathered}$ | $\\begin{gathered} -3.12^{* * *} \\\\ (0.07) \\end{gathered}$ | $\\begin{gathered} -2.37^{* * *} \\\\ (0.18) \\end{gathered}$ | $\\begin{gathered} -3.66^{* * *} \\\\ (0.09) \\end{gathered}$ | $\\begin{gathered} -2.37^{* * *} \\\\ (0.18) \\end{gathered}$ | $\\begin{gathered} -3.69^{* * *} \\\\ (0.09) \\end{gathered}$ | $\\begin{gathered} -1.89^{* * *} \\\\ (0.02) \\end{gathered}$ | $\\begin{gathered} -3.73^{* * *} \\\\ (0.06) \\end{gathered}$ |\n| $\\theta_{p}$ |  |  | $\\begin{gathered} 0.25^{* * *} \\\\ (0.00) \\end{gathered}$ | $\\begin{gathered} 0.13^{* * *} \\\\ (0.01) \\end{gathered}$ | $\\begin{gathered} 0.25^{* * *} \\\\ (0.00) \\end{gathered}$ | $\\begin{gathered} 0.14^{* * *} \\\\ (0.01) \\end{gathered}$ | $\\begin{gathered} 0.24^{* * *} \\\\ (0.00) \\end{gathered}$ | $\\begin{gathered} 0.14^{* * *} \\\\ (0.01) \\end{gathered}$ |\n| $g_{p .1}$ |  |  | $\\begin{gathered} -0.12^{* * *} \\\\ (0.02) \\end{gathered}$ | $\\begin{gathered} -0.02 \\\\ (0.06) \\end{gathered}$ | $\\begin{gathered} -0.09^{*} \\\\ (0.04) \\end{gathered}$ | $\\begin{gathered} 0.03 \\\\ (0.09) \\end{gathered}$ | $\\begin{gathered} -0.07 \\\\ (0.04) \\end{gathered}$ | $\\begin{gathered} 0.01 \\\\ (0.09) \\end{gathered}$ |\n| $g_{p .2}$ |  |  | $\\begin{gathered} 0.01 \\\\ (0.05) \\end{gathered}$ | $\\begin{gathered} -0.14 \\\\ (0.15) \\end{gathered}$ | $\\begin{gathered} -0.06 \\\\ (0.09) \\end{gathered}$ | $\\begin{gathered} -0.17 \\\\ (0.22) \\end{gathered}$ | $\\begin{gathered} -0.23^{*} \\\\ (0.09) \\end{gathered}$ | $\\begin{gathered} -0.29 \\\\ (0.22) \\end{gathered}$ |\n| $\\theta_{p} g_{p .1}$ |  |  |  |  | $\\begin{gathered} -0.01 \\\\ (0.01) \\end{gathered}$ | $\\begin{gathered} -0.01 \\\\ (0.01) \\end{gathered}$ | $\\begin{gathered} 0.00 \\\\ (0.01) \\end{gathered}$ | $\\begin{gathered} -0.01 \\\\ (0.01) \\end{gathered}$ |\n| $\\theta_{p} g_{p .2}$ |  |  |  |  | $\\begin{gathered} 0.01 \\\\ (0.01) \\end{gathered}$ | $\\begin{gathered} 0.01 \\\\ (0.03) \\end{gathered}$ | $\\begin{gathered} 0.04^{*} \\\\ (0.01) \\end{gathered}$ | $\\begin{gathered} 0.06 \\\\ (0.03) \\end{gathered}$ |\n| Level-2 Variances |  |  |  |  |  |  |  |  |\n| $\\eta_{1}^{2}$ | 0.37 | 0.02 | 0.31 | 0.02 | 0.32 | 0.02 |  |  |\n| N | 47094 | 47094 | 47094 | 47094 | 47094 | 47094 | 47094 | 47094 |\n| ICC | 0.10 | 0.01 | 0.09 | 0.01 | 0.09 | 0.01 |  |  |\n| WAIC | 70824 | 70824 | 57909 | 57909 | 57915 | 57915 | 58506 | 58506 |\n| $R^{2}$ | 0.00 | 0.00 | 0.23 | 0.23 | 0.23 | 0.23 | 0.23 |  |"
      },
      "images": {}
    },
    {
      "section_id": 10,
      "text": "# 5 Discussion \n\nMultilevel modeling we describe in this article is a useful tool for examining DIF in the data from health-related constructs or measures, such as self-reported health survey data. By leveraging this approach, researchers can gain a more accurate understanding of DIF and glean valuable insights into health survey data, ultimately enhancing the precision and reliability of health research findings. Built on prior research that highlights the benefits of multilevel modeling in DIF analysis, our study provides a practical application of how this approach can be used with self-reported health survey data.\n\nOur empirical analyses cover the DIF analysis of a dichotomous item and a polytomous item, using multilevel binary LR and multlevel multinominal LR in addition to their single-level counterparts. Rather than making a blanket recommendation in favor of multilevel models, we intend to raise awareness of how to use multilevel modeling to analyze DIF and how to choose the appropriate model when a series of competing models are available. Different from some other studies that evaluated models via Monte Carlo simulation [e.g., 44], our empirical analysis examines a series of competing models based on model performance statistics. Our findings indicate that multilevel modeling more effectively captures variability in our data compared to single-level\n\nmodeling. Future research could explore the generalizability of our findings by applying multilevel DIF analysis to other self-reported health survey data. Also, researchers might consider comparing our models with other models capable of multilevel modeling for DIF analysis with polytomous items or more than two groups, ideally models without IRT-related assumptions such as ordinal LR [45, 46] or nonparametric measures [e.g., 47].\n\nMore research is needed to support multilevel modeling. First, literature limitations exist regarding model construction, ICC calculation, and generalizability [24], despite existing efforts to explore multilevel DIF analysis [e.g., 48-50]. Second, it would be worthwhile to examine the cost-benefit balance of multilevel modeling for DIF analysis in dynamic health survey settings, such as using Monte Carlo simulations to systematically evaluate model performance under a wide range of data structures. These simulations can vary factors such as ICC, number and size of clusters, the magnitude and proportion of DIF items, and data distribution within each cluster [30]. Studies by Moineddin et al. [51] and [28] provide valuable groundwork, but further exploration is necessary. Third, scrutinizing model performance under various realistic scenarios that mimic real-world health survey data is essential. This includes exploring the impact of factors like missing data patterns (missing completely at random, missing at random, or missing not at random) and different types of DIF (uniform vs. non-uniform) on model performance. By addressing these limitations, we can solidify the role of multilevel modeling in DIF analysis for health research, ultimately leading to more robust and reliable estimates captured through self-reported surveys.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 11,
      "text": "# Declarations \n\nFunding. The authors declare that no funds, grants, or other support were received during the preparation of this manuscript.\n\nCompeting Interests. The authors have no relevant financial or non-financial interests to disclose.\n\nAvailability of Data and Materials. The NSDUH data and the codebook used in this article can be downloaded here: https://www.datafiles.samhsa.gov/dataset/national-survey-drug-use-and-health-2022-nsduh-2022-ds0001",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 12,
      "text": "## References\n\n[1] Teresi, J. A. and Fleishman, J. A. (2007). Differential item functioning and health assessment. Quality of Life Research, 16(1):33-42.\n[2] Rice, S. M., Parker, A. G., Mawren, D., Clifton, P., Harcourt, P., Lloyd, M., Kountouris, A., Smith, B., McGorry, P. D., and Purcell, R. (2020). Preliminary psychometric validation of a brief screening tool for athlete mental health among male elite athletes: The Athlete Psychological Strain Questionnaire. International Journal of Sport and Exercise Psychology, 18(6):850-865.\n\n[3] Rouquette, A., Nadot, T., Labitrie, P., Broucke, S., Mancini, J., Rigal, L., and Ringa, V. (2018). Validity and measurement invariance across sex, age, and education level of the French short versions of the European Health Literacy Survey Questionnaire. PLOS ONE, 13(12):1-15.\n[4] Quistberg, D. A., Diez Roux, A. V., Bilal, U., Moore, K., Ortigoza, A., Rodriguez, D. A., Sarmiento, O. L., Frenz, P., Friche, A. A., Caiaffa, W. T., Vives, A., Miranda, J. J., and the SALURBAL Group (2019). Building a data platform for crosscountry urban health studies: The SALURBAL study. Journal of Urban Health, $96(2): 311-337$.\n[5] Tiego, J., Martin, E. A., DeYoung, C. G., Hagan, K., Cooper, S. E., Pasion, R., Satchell, L., Shackman, A. J., Bellgrove, M. A., and Fornito, A. (2023). Precision behavioral phenotyping as a strategy for uncovering the biological correlates of psychopathology. Nature Mental Health, 1(5):304-315.\n[6] Jones, R. N. (2019). Differential item functioning and its relevance to epidemiology. Current Epidemiology Reports, 6:174-183.\n[7] Teresi, J. A., Wang, C., Kleinman, M., Jones, R. N., and Weiss, D. J. (2021). Differential item functioning analyses of the Patient-Reported Outcomes Measurement Information System (PROMIS\u00ae) measures: Methods, challenges, advances, and future directions. Psychometrika, 86(3):674-711.\n[8] Lorem, G., Cook, S., Leon, D. A., Emaus, N., and Schirmer, H. Self-reported health as a predictor of mortality: A cohort study of its relation to other health measurements and observation time. 10(1):4886.\n[9] Wuorela, M., Lavonius, S., Salminen, M., Vahlberg, T., Viitanen, M., and Viikari, L. Self-rated health and objective health status as predictors of all-cause mortality among older people: A prospective study with a 5 -, 10 -, and 27 -year follow-up. $20(1): 120$.\n[10] Ulitzsch, E., Henninger, M., and Meiser, T. (2024). Differences in response-scale usage are ubiquitous in cross-country comparisons and a potential driver of elusive relationships. Scientific Reports, 14(1):10890.\n[11] van de Vijver, F. J. R. and Poortinga, Y. H. (1997). Towards an integrated analysis of bias in cross-cultural assessment. European Journal of Psychological Assessment, 13(1):29-37.\n[12] Werner, O. and Campbell, D. (1970). Translating, working through interpreters, and the problem of decentering. In Naroll, R. and Cohen, R., editors, A Handbook of Cultural Anthropology, pages 389-418. American Museum of Natural History, New York.\n\n[13] Berk, R., editor (1982). Handbook of Methods for Detecting Item Bias. The Johns Hopkins University Press, Baltimore, MD.\n[14] American Educational Research Association, American Psychological Association, and National Council on Measurement in Education (2014). Standards for educational and psychological testing. American Educational Research Association, Washington, DC.\n[15] Penfield, R. D. and Camilli, G. (2006). Item functioning and item bias. In Rao, C. R. and Sinharay, S., editors, Handbook of Statistics, volume 26 of Psychometrics, pages $125-167$. Elsevier.\n[16] Lee, Y.-H. and Zhang, J. (2017). Effects of differential item functioning on examinees' test performance and reliability of test. International Journal of Testing, $17(1): 23-54$.\n[17] Mellenbergh, G. J. (1982). Contingency table models for assessing item bias. Journal of Educational Statistics, 7(2):105-118.\n[18] Swaminathan, H. and Rogers, H. J. (1990). Detecting differential item functioning using logistic regression procedures. Journal of Educational Measurement, $27(4): 361-370$.\n[19] Holland, P. and Thayer, D. T. (1985). An alternate definition of the ETS delta scale of item difficulty. Technical Report 85-43, Educational Testing Service, Princeton, NJ.\n[20] Lord, F. (1976). A study of item bias, using item characteristic curve theory. Technical Report ED137486, Educational Testing Service, Princeton, NJ.\n[21] Thissen, D., Steinberg, L., and Gerrard, M. (1986). Beyond group-mean differences: The concept of item bias. Psychological Bulletin, 99(1):118-128.\n[22] Osterlind, S. and Everson, H. (2009). Differential Item Functioning. SAGE Publications, Inc, Thousand Oakes, CA, second edition.\n[23] Lee, S. Y. (2015). Lord's Wald test for detecting DIF in multidimensional IRT Models: A comparison of two estimation approaches. PhD thesis, Rutgers, The State University of New Jersey.\n[24] Chen, D. (2023). Modeling item bias in fixed-item tests and computerized adaptive tests. PhD thesis, University of Illinois at Urbana-Champaign.\n[25] Raudenbush, S. and Bryk, A. (2002). Hierarchical linear models: Applications and data analysis methods. SAGE Publications, Inc, Thousand Oaks, CA, second edition.\n\n[26] Gelman, A. and Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models. Cambridge University Press, New York, NY.\n[27] Shadish, W. R., Cook, T. D., and Campbell, D. T. (2002). Experimental and quasi-experimental designs for generalized causal inference. Houghton Mifflin Company, Boston, second edition.\n[28] Woods, C. M., Cai, L., and Wang, M. (2013). The Langer-improved Wald test for DIF testing with multiple groups: Evaluation and comparison to two-group IRT. Educational and Psychological Measurement, 73(3):532-547.\n[29] Penfield, R. D. (2001). Assessing differential item functioning among multiple groups: A comparison of three Mantel-Haenszel procedures. Applied Measurement in Education, 14(3):235-259.\n[30] Snijders, T. A. B. and Bosker, R. (2011). Multilevel analysis: An introduction to basic and advanced multilevel modeling. SAGE Publications, Inc, Thousand Oaks, CA, second edition.\n[31] Swanson, D. B., Clauser, B. E., Case, S. M., Nungester, R. J., and Featherman, C. (2002). Analysis of differential item functioning (DIF) using hierarchical logistic regression models. Journal of Educational and Behavioral Statistics, 27(1):53-75.\n[32] den Noortgate, W. and de Boeck, P. (2005). Assessing and explaining differential item functioning using logistic mixed models. Journal of Educational and Behavioral Statistics, 30(4):443-464.\n[33] French, B. F. and Finch, H. (2013). Extensions of Mantel-Haenszel for multilevel DIF detection. Educational and Psychological Measurement, 73(4):648-671.\n[34] Huang, S. and Valdivia, D. S. (2024). Wald $\\chi^{2}$ test for differential item functioning detection with polytomous items in multilevel data. Educational and Psychological Measurement, 84(3):530-548.\n[35] Lord, F. (1980). Applications of Item Response Theory to Practical Testing Problems. Lawrence Erlbaum Associates, Inc, Hillsdale, NJ.\n[36] Agresti, A. (2019). An Introduction to Categorical Data Analysis. John Wiley \\& Sons, Hoboken, NJ, third edition.\n[37] Douglas, E. (2022). Examining the relationship between urban density and sense of community in the Greater Vancouver Regional District. Cities, 130:103870.\n[38] Zander, K. K., Cadag, J. R., Escarcha, J., and Garnett, S. T. (2018). Perceived heat stress increases with population density in urban Philippines. Environmental Research Letters, 13(8):084009.\n\n[39] Fassio, O., Rollero, C., and De Piccoli, N. (2013). Health, quality of life and population density: A preliminary study on \"contextualized\" quality of life. Social Indicators Research, 110(2):479-488.\n[40] Walton, D., Murray, S. J., and Thomas, J. A. (2008). Relationships between population density and the perceived quality of neighbourhood. Social Indicators Research, 89(3):405-420.\n[41] Kondirolli, F. and Sunder, N. (2022). Mental health effects of education. Health Economics, 31(S2):22-39.\n[42] Bates, D., Maechler, M., Bolker, B., and Walker, S. (2022). Linear mixed-effects models using 'Eigen' and S4.\n[43] Nakagawa, S. and Schielzeth, H. (2013). A general and simple method for obtaining R2 from generalized linear mixed-effects models. Methods in Ecology and Evolution, 4(2):133-142.\n[44] Svetina Valdivia, D., Huang, S., and Botter, P. (2024). Detecting differential item functioning in presence of multilevel data: Do methods accounting for multilevel data structure make a DIFference? Frontiers in Education, 9. Publisher: Frontiers.\n[45] Crane, P. K., Gibbons, L. E., Narasimhalu, K., Lai, J.-S., and Cella, D. (2007). Rapid detection of differential item functioning in assessments of health-related quality of life: The Functional Assessment of Cancer Therapy. Quality of Life Research, 16(1):101-114.\n[46] Zumbo, B. D. (1999). A handbook on the theory and methods of differential item functioning (DIF): Logistic regression modeling as a unitary framework for binary and likert-type (ordinal) item scores. Directorate of Human Resources Research and Evaluation, Department of National Defense, Ottawa, ON.\n[47] Zwick, R. and Thayer, D. T. (1996). Evaluating the magnitude of differential item functioning in polytomous items. Journal of Educational and Behavioral Statistics, 21(3):187-201. Publisher: [American Educational Research Association, Sage Publications, Inc., American Statistical Association].\n[48] French, B. F. and Finch, H. (2010). Hierarchical logistic regression: Accounting for multilevel data in DIF detection. Journal of Educational Measurement, 47(3):299317 .\n[49] French, B. F. and Finch, H. (2015). Transforming SIBTEST to account for multilevel data structures. Journal of Educational Measurement, 52(2):159-180.\n[50] French, B. F., Finch, W. H., and Immekus, J. C. (2019). Multilevel generalized Mantel-Haenszel for differential item functioning detection. Frontiers in Education, $4(47): 1-10$.\n\n[51] Moineddin, R., Matheson, F. I., and Glazier, R. H. (2007). A simulation study of sample size for multilevel logistic regression models. BMC Medical Research Methodology, 7(34):1-10.",
      "tables": {},
      "images": {}
    }
  ],
  "id": "2408.13702v3",
  "authors": [
    "Dandan Chen Kaptur",
    "Yiqing Liu",
    "Bradley Kaptur",
    "Nicholas Peterman",
    "Jinming Zhang",
    "Justin Kern",
    "Carolyn Anderson"
  ],
  "categories": [
    "stat.AP"
  ],
  "abstract": "Few health-related constructs or measures have received a critical evaluation\nin terms of measurement equivalence, such as self-reported health survey data.\nDifferential item functioning (DIF) analysis is crucial for evaluating\nmeasurement equivalence in self-reported health surveys, which are often\nhierarchical in structure. Traditional single-level DIF methods in this case\nfall short, making multilevel models a better alternative. We highlight the\nbenefits of multilevel modeling for DIF analysis, when applying a health survey\ndata set to multilevel binary logistic regression (for analyzing binary\nresponse data) and multilevel multinominal logistic regression (for analyzing\npolytomous response data), and comparing them with their single-level\ncounterparts. Our findings show that multilevel models fit better and explain\nmore variance than single-level models. This article is expected to raise\nawareness of multilevel modeling and help healthcare researchers and\npractitioners understand the use of multilevel modeling for DIF analysis.",
  "updated": "2025-03-01T03:22:18Z",
  "published": "2024-08-25T01:35:46Z"
}