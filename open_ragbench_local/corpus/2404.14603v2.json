{
  "title": "Quantifying the Internal Validity of Weighted Estimands",
  "sections": [
    {
      "section_id": 0,
      "text": "#### Abstract\n\nIn this paper we study a class of weighted estimands, which we define as parameters that can be expressed as weighted averages of the underlying heterogeneous treatment effects. The popular ordinary least squares (OLS), two-stage least squares (2SLS), and two-way fixed effects (TWFE) estimands are all special cases within our framework. Our focus is on answering two questions concerning weighted estimands. First, under what conditions can they be interpreted as the average treatment effect for some (possibly latent) subpopulation? Second, when these conditions are satisfied, what is the upper bound on the size of that subpopulation, either in absolute terms or relative to a target population of interest? We argue that this upper bound provides a valuable diagnostic for empirical research. When a given weighted estimand corresponds to the average treatment effect for a small subset of the population of interest, we say its internal validity is low. Our paper develops practical tools to quantify the internal validity of weighted estimands.\n\n\nKeywords: internal validity, ordinary least squares, representativeness, treatment effects, two-stage least squares, two-way fixed effects, weakly causal estimands, weighted estimands\n\nJEL classification: C20, C21, C23, C26\n\n[^0]\n[^0]:    *First arXiv draft: April 22, 2024. This paper was presented at LMU Munich, University of Bonn, Brown University, Brandeis University, University of Pittsburgh, McMaster University, the 2024 Annual Congress of the European Economic Association, the 2024 DC-MD-VA Econometrics Workshop, the 2024 Midwest Econometrics Group Meeting, the 2024 Southern Economic Association Meeting, the $2024 \\mathrm{EC}^{2}$ Conference, and the 2024 BU/BC Greenline Econometrics Workshop. We thank audiences at those seminars and conferences, as well as Greg Caetano, Brant Callaway, Kevin Chen, Cl\u00e9ment de Chaisemartin, Joachim Freyberger, Christian Hansen, Peter Hull, Toru Kitagawa, Matt Masten, Tomasz Olma, Guillaume Pouliot, Jonathan Roth, Pedro Sant'Anna, Alex Torgovitsky, and Daniel Wilhelm for helpful conversations and comments.\n    ${ }^{\\dagger}$ Department of Economics, Georgetown University, alexandre.poirier@georgetown.edu\n    $\\ddagger$ Department of Economics, Brandeis University, tslocz@brandeis.edu",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 1,
      "text": "# 1 Introduction \n\nEstimating average treatment effects is an important objective in many areas of empirical research. Applied researchers usually believe that treatment effects are heterogeneous, which means that they vary across units. Yet, many researchers also favor using well-established estimation methods that were not originally designed with treatment effect heterogeneity in mind. These methods may be chosen because of their computational simplicity, comparability across studies, effectiveness at incorporating high-dimensional covariates, and other reasons. In turn, these methods often lead to estimands that can be represented as weighted averages of the underlying treatment effects of interest.\n\nFor example, consider a scenario where unconfoundedness holds given covariates $X$. Let treatment $D$ be binary, $(Y(1), Y(0))$ be potential outcomes, and let $\\tau_{0}(X)=\\mathbb{E}[Y(1)-Y(0) \\mid X]$ be the conditional average treatment effect, or CATE, for covariate value $X$. Following Angrist (1998), if we additionally assume that $\\mathbb{E}[D \\mid X]$ is linear in $X$, the population regression of $Y$ on a constant, treatment $D$, and covariates $X$ yields a coefficient on $D$ that can be written as\n\n$$\n\\beta_{\\mathrm{OLS}}=\\frac{\\mathbb{E}\\left[\\operatorname{var}(D \\mid X) \\tau_{0}(X)\\right]}{\\mathbb{E}[\\operatorname{var}(D \\mid X)]}\n$$\n\na weighted average of CATEs with nonnegative weights that integrate to 1 . This parameter will be equal to the average treatment effect, $\\mathbb{E}[Y(1)-Y(0)]$, if and only if $\\operatorname{var}(D \\mid X)$ and $\\tau_{0}(X)$ are uncorrelated.\n\nIn this paper we are concerned with a general class of weighted estimands that can be expressed as follows:\n\n$$\n\\mu\\left(a, \\tau_{0}\\right):=\\frac{\\mathbb{E}\\left[a(X) w_{0}(X) \\tau_{0}(X)\\right]}{\\mathbb{E}\\left[a(X) w_{0}(X)\\right]}=\\frac{\\mathbb{E}\\left[a(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}\n$$\n\nwhere $W_{0} \\in\\{0,1\\}$ is an indicator for a subpopulation, $\\tau_{0}(X)=\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1, X]$ are the CATEs given covariates $X$ in the same subpopulation $W_{0}, w_{0}(X)=\\mathbb{P}\\left(W_{0}=1 \\mid X\\right)$ is the probability of being in this subpopulation given $X$, and $a(X)$ is an identified weight function. The regression estimand above belongs to this class, which can be seen by letting $W_{0}=1$ with probability 1 , and letting the weight function $a(X)$ be the conditional variance of treatment given covariates. Under some assumptions, this class also includes the two-stage least squares (2SLS) and two-way fixed effects (TWFE) estimands in instrumental variables and difference-in-differences settings, as well as many other parameters. Here, the leading cases of $W_{0}$ are compliers in the case of 2SLS and treated units in the case of TWFE. In the case of 2SLS, we would thus interpret $\\tau_{0}(X)$ as the average treatment effect for compliers with covariates $X$.\n\nThere are two main questions that this paper seeks to answer. The first is whether, and under what circumstances, the estimand in (1.1) corresponds to an average treatment effect of the form $\\mathbb{E}[Y(1)-Y(0) \\mid$ $\\left.W^{*}=1\\right]$, where $W^{*} \\in\\{0,1\\}$ is an indicator for a (possibly latent) subpopulation of $W_{0}$. An affirmative answer to this question would endow a specific weighted estimand with some degree of validity as a causal parameter, given that it would then measure the average effect of treatment for a subset of all units.\n\nThe second and primary aim of this paper is to quantify the degree of validity of $\\mu\\left(a, \\tau_{0}\\right)$ as a causal parameter. To do this, we characterize the size, and the size relative to $W_{0}$, of subpopulations $W^{*}$ associated with the estimand in (1.1). More plainly, we ask how large $\\mathbb{P}\\left(W^{*}=1\\right)$ and $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ can be in the representation $\\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1]$. If these probabilities can be large, the estimand\n\ncorresponds to the average treatment effect for a (relatively) large subpopulation, and when they are small, it corresponds to the average effect for a (relatively) small number of units. If $\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]$ is the target parameter, we interpret a large value of $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ as evidence of a high degree of internal validity of $\\mu\\left(a, \\tau_{0}\\right)$ with respect to the target. If $\\mathbb{P}\\left(W^{*}=1\\right)$, the corresponding marginal probability, is large, we say that $\\mu\\left(a, \\tau_{0}\\right)$ is highly representative of the underlying population.\n\nThe answer to our questions about subpopulation existence and size depends on the information we have about the CATE function, $\\tau_{0}$. Specifically, in one case, we may want to know whether $\\mu\\left(a, \\tau_{0}\\right)$ can be written as $\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1]$ for any choice of $\\tau_{0}$, or without any knowledge of this function. If this is the case, then we know that the interpretation of $\\mu\\left(a, \\tau_{0}\\right)$ as a causal parameter is robust to heterogeneous treatment effects of any form, including the most adversarial CATE functions. We can also answer the second question about the maximum values of $\\mathbb{P}\\left(W^{*}=1\\right)$ and $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ without needing to estimate or know the structure of the CATEs. In a second case, we may want to know how representative $\\mu\\left(a, \\tau_{0}\\right)$ is given knowledge of the CATE function. While the resulting maximum values of $\\mathbb{P}\\left(W^{*}=1\\right)$ and $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ are less useful as measures of robustness than in the first case-after all, if the researcher knows or estimates the entire CATE function, they can as well report any average of $\\tau_{0}(X)$ that may be relevant - we consider this problem to be of independent theoretical interest. Additionally, if the researcher estimates and compares the maximum values of $\\mathbb{P}\\left(W^{*}=1\\right)$ or $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ in both cases, they can evaluate the importance of treatment effect heterogeneity for the interpretation of $\\mu\\left(a, \\tau_{0}\\right)$ in a given application.\n\nIn the first case, when the CATE function is unrestricted, we formally show that $\\mu\\left(a, \\tau_{0}\\right)$ can be written as the average treatment effect for a subpopulation of $W_{0}$ if and only if $a(X) \\geq 0$ with probability 1 given $W_{0}=1$. The contrapositive of this statement is that the incidence of \"negative weights,\" that is, $\\mathbb{P}\\left(a(X)<0 \\mid W_{0}=1\\right)>0$, implies that $\\mu\\left(a, \\tau_{0}\\right)$ cannot be represented as an average treatment effect for some subpopulation uniformly in $\\tau_{0}$. This result provides a novel justification for the commonly invoked requirement that the weights underlying a suitable estimand must all be positive. In a related contribution, Blandhol, Bonney, Mogstad, and Torgovitsky (2022) have shown that, for estimands that do not depend on potential outcome levels, the lack of negative weights is a sufficient and necessary condition for the weighted estimand to be \"weakly causal,\" that is, to guarantee that the sign of $\\tau_{0}$ will be preserved whenever it is uniform across all units. We also provide simple expressions for the maxima of $\\mathbb{P}\\left(W^{*}=1\\right)$ and $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$. We show how knowledge of the estimand and of these expressions can be used to construct simple bounds on the target parameter. We also propose an analog estimator for our measure of internal validity. We then establish the nonstandard limiting distribution of this estimator, and describe inference procedures for it.\n\nIn the second case, when the CATE function is assumed to be known, we show that $\\mu\\left(a, \\tau_{0}\\right)$ can be written as an average treatment effect whenever it lies in the convex hull of CATE values, a weaker criterion than having nonnegative weights. The maximum values of $\\mathbb{P}\\left(W^{*}=1\\right)$ and $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ now depend on $\\tau_{0}$, and can be obtained via linear programming when $X$ is discrete. We show the solution to this linear program also admits a closed-form expression even when the support of $X$ includes discrete, continuous, and mixed components. This expression can be used to derive plug-in estimators.\n\nBesides theoretical interest, we argue that $\\mathbb{P}\\left(W^{*}=1\\right)$ and $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ are a practically relevant measure that may be appealing to applied researchers. First, as stated above, our initial results demonstrate\n\nthat two commonly invoked criteria for weighted estimands-that they lack negative weights and that they lie in the convex hull of CATE values-are necessary and sufficient (under different assumptions) for the existence of their causal representation, that is, for $\\mathbb{P}\\left(W^{*}=1\\right)$ and $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ to be strictly positive. This suggests that researchers invoking these criteria are (indirectly) interested in whether their estimands can be represented as an average treatment effect for some subpopulation. If this is the case, it makes sense to better understand this implicit subpopulation, similar to how it is standard practice in instrumental variables settings to study the subpopulation of compliers. Relatedly, even though our main results concern subpopulation size, we also show that the distribution of covariates in the implicit subpopulation is identified. Thus, practitioners can examine whether this subpopulation has similar characteristics as the entire population, and report the associated sample statistics.\n\nSecond, we argue that when $\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]$ is the parameter of interest, it is reassuring for $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ to be large. For one, related claims have been made by other researchers. Mogstad and Torgovitsky (2024) assert that \" $[t]$ arget parameters that reflect larger subpopulations of the population of interest are more interesting than those that reflect smaller and more specific subpopulations.\" In a setting with multiple instrumental variables, van 't Hoff, Lewbel, and Mellace (2024) argue that the largest subpopulation of compliers is generally more interesting than other complier subpopulations. However, we also formalize this claim and show how to construct bounds on $\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]$ that only depend on $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right), \\mu\\left(a, \\tau_{0}\\right)$, and a support restriction. The bounds are easy to compute and converge to a point as $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ approaches 1 . Indeed, large values of $\\mathbb{P}\\left(W^{*}=1\\right)$ and $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$, our primary measures of interest, guarantee that the weighted estimand is not \"too different\" from $\\mathbb{E}[Y(1)-Y(0)]$ and $\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 2,
      "text": "# Literature Review \n\nThis paper is related to a large literature studying weighted average representations of common estimands, including ordinary least squares (OLS), 2SLS, and TWFE in additive linear models. Some of the contributions to this literature include Angrist (1998), Humphreys (2009), Aronow and Samii (2016), Blandhol, Bonney, Mogstad, and Torgovitsky (2022), S\u0142oczy\u0144ski (2022), Chen (2024), and Goldsmith-Pinkham, Hull, and Koles\u00e1r (2024) for OLS; Imbens and Angrist (1994), Angrist and Imbens (1995), Koles\u00e1r (2013), S\u0142oczy\u0144ski (2020), and Blandhol, Bonney, Mogstad, and Torgovitsky (2022) for 2SLS; and de Chaisemartin and D'Haultf\u0153uille (2020), Goodman-Bacon (2021), Sun and Abraham (2021), Athey and Imbens (2022), Caetano and Callaway (2023), Borusyak, Jaravel, and Spiess (2024), and Callaway, Goodman-Bacon, and Sant'Anna (2024) for TWFE.\n\nA common view in much of this literature, attributable to Imbens and Angrist (1994), is that causal interpretability of weighted estimands requires all weights to be positive. For example, Sun and Abraham (2021) explicitly associate \"reasonable weights\" with weights that \"sum to one and are non-negative.\" Blandhol, Bonney, Mogstad, and Torgovitsky (2022) show that the lack of negative weights and level dependence is necessary and sufficient for an estimand to be \"weakly causal,\" that is, to guarantee sign preservation when all treatment effects have the same sign. In this paper we focus on the related problem of whether a weighted estimand can be written as the average treatment effect for some (possibly latent) subpopulation. While the lack of negative weights is essential in our framework when the CATE function is unrestricted, negative and nonuniform weights play a similar role when the CATE function is assumed to be known, at least as long as\n\nthe weighted estimand lies in the convex hull of CATE values. This point is related to the negative view of both negative and nonuniform weights in Callaway, Goodman-Bacon, and Sant'Anna (2024).\n\nSome papers focus on weighted averages of heterogeneous treatment effects as legitimate targets in their own right rather than as probability limits of existing estimators. Hirano, Imbens, and Ridder (2003) introduce the class of weighted average treatment effects, which are a subclass of the more general class of estimands in (1.1). Li, Morgan, and Zaslavsky (2018) discuss the connection between weighted average treatment effects and implicit target subpopulations. However, the internal validity and representativeness of weighted estimands have received very little attention to date.\n\nOne exception is de Chaisemartin $(2012,2017)$, who revisits the interpretation of the instrumental variables (IV) estimand in the framework of Imbens and Angrist (1994). First, de Chaisemartin (2012) studies the size of the largest subpopulation whose average treatment effect is equal to that of compliers. While this question is similar to ours, the corresponding subpopulation size is not point identified, unlike in this paper. Our framework is also more general and includes instrumental variables settings as a special case. Second, when the usual monotonicity assumption is violated, de Chaisemartin $(2012,2017)$ reinterprets the IV estimand as the average treatment effect for a subset of compliers. In our framework, this result can be seen as an existence result in an intermediate case between the setting where $\\tau_{0}$ is unrestricted and where it is fixed. The specific homogeneity assumption considered by de Chaisemartin $(2012,2017)$ allows him to salvage the causal representation of the IV estimand despite the incidence of negative weights.\n\nAnother exception is Aronow and Samii (2016), who explicitly acknowledge that the OLS estimand, like the local average treatment effect of Imbens and Angrist (1994), corresponds to the average effect for a \"highly specific subpopulation\" rather than the entire population, and consequently is not necessarily representative of that population. Then, Aronow and Samii (2016) focus on whether mean covariate values are similar in the entire sample and in the \"effective sample\" used by OLS. We focus on the size of the implicit subpopulation, which is different and complementary. We also extend the results on mean covariate values to the entire distribution of covariates and to other weighted estimands besides OLS.\n\nYet another exception is Miller, Shenhav, and Grosz (2023), who focus on (one-way) fixed effects estimands and argue that it is problematic if \"switchers,\" that is, fixed-effect groups with nonzero variation in treatment, are a small subset of the sample. They also recommend that applied researchers report the sample size when limited to \"switcher groups.\" In this paper we build a general framework to study the internal validity and representativeness of weighted estimands, with the fixed effects estimand (equivalent to OLS) as a special case. We argue, similar to Miller, Shenhav, and Grosz (2023), that if a given weighted estimand corresponds to the average treatment effect for a small subpopulation, then it may not be an appropriate target parameter, unless that subpopulation is interesting in its own right.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 3,
      "text": "# Plan of the Paper \n\nWe organize the paper as follows. In Section 2, we provide a more detailed discussion of the OLS estimand, which is our motivating example. In Section 3, we develop our theoretical framework and examine the conditions under which the estimand in (1.1) has a causal representation as an average treatment effect over a population. In Section 4, we establish our main results on the absolute and relative size of subpopulations associated with the estimand in (1.1), which we propose as measures of representativeness and internal\n\nvalidity of weighted estimands. In Section 5, we revisit our motivating example from Section 2 and apply our theoretical results to additional examples of weighted estimands. In particular, we study 2SLS with a binary instrument and TWFE under parallel trends assumptions. In Section 6, we briefly discuss estimation and inference for the proposed measures. In Section 7, we provide an empirical application to the effects of unilateral divorce laws on female suicide, as in Stevenson and Wolfers (2006) and Goodman-Bacon (2021). In Section 8, we conclude. The appendix contains our proofs as well as several additional results and derivations.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 4,
      "text": "# 2 Motivating Example \n\nHere we provide a more detailed discussion of the OLS estimand, which is our initial theoretical example. We postpone the discussion of the 2SLS and TWFE estimands to Section 5. In the initial example, we have a binary treatment $D \\in\\{0,1\\}$, potential outcomes $(Y(1), Y(0))$, covariate vector $X$, and realized outcome $Y=Y(D)$. We make the following two assumptions.\n\nAssumption 2.1 (Unconfoundedness). Let\n\n1. Conditional independence: $(Y(1), Y(0)) \\Perp D \\mid X$;\n2. Overlap: $p(X):=\\mathbb{P}(D=1 \\mid X) \\in(0,1)$ almost surely.\n\nFollowing Angrist (1998), we can establish that $\\beta_{\\text {OLS }}$, the coefficient on $D$ in the linear projection of $Y$ on $(1, D, X)$, satisfies the representation in (1.1). The following proposition summarizes Angrist's (1998) result.\n\nProposition 2.1. Suppose Assumption 2.1 holds. Suppose $p(X)$ is linear in $X$. Then\n\n$$\n\\beta_{\\mathrm{OLS}}=\\frac{\\mathbb{E}[p(X)(1-p(X)) \\cdot \\mathbb{E}[Y(1)-Y(0) \\mid X]]}{\\mathbb{E}[p(X)(1-p(X))]}\n$$\n\nThe linearity assumption can be removed if we instead regress $Y$ on $(1, D, h(X))$ where $h(X)$ is a vector of functions of $X$ such that $p(X)$ is in their linear span. The overlap assumption can also be weakened since it is not required for $\\beta_{\\text {OLS }}$ to be defined.\n\nProposition 2.1 implies that we can write $\\beta_{\\text {OLS }}$ as\n\n$$\n\\beta_{\\mathrm{OLS}}=\\frac{\\mathbb{E}\\left[a(X) \\tau_{0}(X)\\right]}{\\mathbb{E}[a(X)]}\n$$\n\nwhere $a(X)=p(X)(1-p(X))$ and $\\tau_{0}(X)=\\mathbb{E}[Y(1)-Y(0) \\mid X]$. Here we implicitly set $W_{0}=1$ with probability 1 . Thus, the regression coefficient $\\beta_{\\text {OLS }}$ is a weighted average of CATEs whose weights are $p(X)(1-p(X))$. Note that $\\beta_{\\mathrm{OLS}}=\\mathrm{ATE}:=\\mathbb{E}[Y(1)-Y(0)]$ if and only if $a(X)$ and $\\tau_{0}(X)$ are uncorrelated, which is the case, for example, when $p(X)$ or $\\tau_{0}(X)$ is constant.\n\nAn alternative representation of this estimand can be obtained by focusing on the subpopulation of treated units, $D=1$. Let $W_{0}=D, \\tau_{0}(X)=\\mathbb{E}[Y(1)-Y(0) \\mid D=1, X]=\\mathbb{E}[Y(1)-Y(0) \\mid X]$, which follows from conditional independence, and let $\\tilde{a}(X)=1-p(X)$. Then, we can write\n\n$$\n\\beta_{\\mathrm{OLS}}=\\frac{\\mathbb{E}\\left[(1-p(X)) w_{0}(X) \\tau_{0}(X)\\right]}{\\mathbb{E}\\left[(1-p(X)) w_{0}(X)\\right]}=\\frac{\\mathbb{E}\\left[\\tilde{a}(X) w_{0}(X) \\tau_{0}(X)\\right]}{\\mathbb{E}\\left[\\tilde{a}(X) w_{0}(X)\\right]}\n$$\n\nwhere $w_{0}(X)=\\mathbb{P}(D=1 \\mid X)=p(X)$. Yet another representation can be obtained when focusing on the subpopulation of untreated units by letting $W_{0}=1-D$. We omit details for brevity.\n\nWe will return to this example in Section 5 after establishing conditions under which weighted estimands have a causal representation (Section 3) and identifying the size of subpopulations that are represented by these estimands (Section 4).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 5,
      "text": "# 3 Causal Representation of Weighted Estimands \n\nWe now consider a general class of weighted estimands. In this section, we show necessary and sufficient conditions for an estimand in this class to have a causal representation as an average treatment effect over a subpopulation. We provide these conditions under various assumptions-including no assumptions-on the heterogeneity of treatment effects.\n\nRecall the earlier setting where we let $D \\in\\{0,1\\}$ denote a binary treatment variable, and let $(Y(1), Y(0))$ denote the corresponding potential outcomes under treatment and control, respectively. Let $X \\in \\operatorname{supp}(X) \\subseteq$ $\\mathbb{R}^{d_{X}}$ denote a $d_{X}$-vector of covariates, where $\\operatorname{supp}(\\cdot)$ denotes the support of a random vector. We suppose that $(Y(1), Y(0), D, X)$ are drawn from a common population distribution $F_{Y(1), Y(0), D, X}$.\n\nLet $W_{0} \\in\\{0,1\\}$ be an indicator variable used to denote a subpopulation $\\left\\{W_{0}=1\\right\\}$ and let $\\tau_{0}(X)=$ $\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1, X]$ denote the conditional average treatment effect given $X$ in that subpopulation. For example, this subpopulation can be the entire population by setting $W_{0}=1$ almost surely, in which case $\\tau_{0}$ denotes the usual CATE function. It can also denote the subpopulation of treated units by setting $W_{0}=D$. In the presence of a binary instrument $Z$, the complier subpopulation is defined by setting $W_{0}=\\mathbb{1}(D(1)>D(0))$, where $D(1)$ and $D(0)$ are potential treatments. In this case, $\\tau_{0}$ denotes the conditional local average treatment effect or conditional LATE.\n\nNote that $\\tau_{0}$ is defined for all values of $X$ such that $w_{0}(X)=\\mathbb{P}\\left(W_{0}=1 \\mid X\\right)>0 .{ }^{1}$ Throughout this paper, we assume that $\\mathbb{P}\\left(W_{0}=1\\right)>0$, so that this subpopulation has a positive mass, which avoids technical issues associated with conditioning on zero-probability events.\n\nAlso recall the weighted estimands of equation (1.1):\n\n$$\n\\mu\\left(a, \\tau_{0}\\right)=\\frac{\\mathbb{E}\\left[a(X) w_{0}(X) \\tau_{0}(X)\\right]}{\\mathbb{E}\\left[a(X) w_{0}(X)\\right]}=\\frac{\\mathbb{E}\\left[a(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}\n$$\n\nThe estimands we consider have the above representation and satisfy the following regularity conditions.\nAssumption 3.1 (Regularity). Let $\\mathbb{E}\\left[\\tau_{0}(X)^{2}\\right]<\\infty, \\mathbb{E}\\left[a(X)^{2}\\right]<\\infty$, and $\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]>0$.\nThe first two restrictions are weak regularity assumptions that ensure the finiteness of the numerator of $\\mu\\left(a, \\tau_{0}\\right)$. We rule out $\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]=0$ since it implies the estimand does not exist. The estimand in (1.1) is unchanged if the sign of $a(X)$ is reversed, so $\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]>0$ is a sign normalization.\n\n[^0]\n[^0]:    ${ }^{1}$ While $\\tau_{0}(X)$ is only defined when $w_{0}(X)>0$, we set $\\tau_{0}(X) w_{0}(X)=0$ when $w_{0}(X)=0$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 6,
      "text": "# 3.1 Alternative Representations of Weighted Estimands \n\nThe weighted estimands of equation (1.1) can also be written as a weighted sum when $X$ is discrete, or an integral when $X$ is continuous. In the discrete case, let $\\operatorname{supp}(X)=\\left\\{x_{1}, \\ldots, x_{K}\\right\\}$, let $p_{k}:=\\mathbb{P}\\left(X=x_{k}\\right)>0$ for $k=1, \\ldots, K$, and assume $W_{0}=1$ almost surely for simplicity. Then,\n\n$$\n\\mu\\left(a, \\tau_{0}\\right)=\\sum_{k=1}^{K} \\omega_{k} \\tau_{0}\\left(x_{k}\\right) \\quad \\text { where } \\quad \\omega_{k}=\\frac{a\\left(x_{k}\\right) p_{k}}{\\sum_{l=1}^{K} a\\left(x_{l}\\right) p_{l}}\n$$\n\nwhich are weights that sum to one. The representations in (1.1) and (3.1) are equivalent as we can obtain $a\\left(x_{k}\\right)$ (up to scale) as the ratio $\\omega_{k} / p_{k}$, and $\\omega_{k}$ is defined as a function of $\\left\\{\\left(a\\left(x_{k}\\right), p_{k}\\right)\\right\\}_{k=1}^{K}$ in equation (3.1).\n\nFrom equation (3.1), we can see that $a\\left(x_{k}\\right)$ being constant ensures $\\omega_{k}=p_{k}$, or that the estimand is the ATE. Moreover,\n\n$$\n\\frac{a\\left(x_{k}\\right)}{a\\left(x_{k^{\\prime}}\\right)}=\\frac{\\omega_{k}}{\\omega_{k^{\\prime}}} / \\frac{p_{k}}{p_{k^{\\prime}}}\n$$\n\nwhich is the ratio of the relative weights of covariate cells $\\left\\{X=x_{k}\\right\\}$ and $\\left\\{X=x_{k^{\\prime}}\\right\\}$ in the estimand $\\left(\\omega_{k} / \\omega_{k^{\\prime}}\\right)$ and in the population $\\left(p_{k} / p_{k^{\\prime}}\\right)$. The inequality $a\\left(x_{k}\\right)>a\\left(x_{k^{\\prime}}\\right)$ indicates that covariate cell $\\left\\{X=x_{k}\\right\\}$ is overweighted relative to $\\left\\{X=x_{k^{\\prime}}\\right\\}$, when compared to their relative weights in the population.\n\nAlternatively, consider the case where $X$ is continuously distributed with density ${ }^{2} f_{X}$. Still assuming $W_{0}=1$ almost surely, we can write\n\n$$\n\\mu\\left(a, \\tau_{0}\\right)=\\int_{\\operatorname{supp}(X)} \\omega(x) \\tau_{0}(x) d x \\quad \\text { where } \\quad \\omega(x)=\\frac{a(x) f_{X}(x)}{\\int_{\\operatorname{supp}(X)} a(x) f_{X}(x) d x}\n$$\n\nis a weight function that integrates to 1 . We focus on the representation in equation (1.1) since it seamlessly accommodates discrete, continuous, and mixed covariates.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 7,
      "text": "### 3.2 Regular Subpopulations\n\nThe first question we address is whether an estimand defined by (1.1) can be represented as $\\mathbb{E}[Y(1)-Y(0) \\mid$ $\\left.W^{*}=1\\right]$, where $W^{*} \\in\\{0,1\\}$ is binary and $\\left\\{W^{*}=1\\right\\}$ characterizes a subpopulation of $\\left\\{W_{0}=1\\right\\}$. Formally, $\\left\\{W^{*}=1\\right\\}$ forms a subpopulation if $\\left\\{W^{*}=1\\right\\} \\subseteq\\left\\{W_{0}=1\\right\\}$ or, equivalently, if $W^{*} \\leq W_{0}$ almost surely.\n\nWe impose some structure on this problem by restricting how these subpopulations may be formed. We will consider what we call \"regular subpopulations,\" which we define here.\n\nDefinition 3.1. Let $W^{*} \\in\\{0,1\\}$ such that $\\mathbb{P}\\left(W^{*}=1\\right)>0$. Say $\\left\\{W^{*}=1\\right\\}$ is a regular subpopulation of $\\left\\{W_{0}=1\\right\\}$ if\n\n1. (Inclusion) $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=0\\right)=0$;\n2. (Conditional independence) $W^{*} \\Perp(Y(1), Y(0)) \\mid X, W_{0}=1$.\n[^0]\n[^0]:    ${ }^{2}$ With respect to the Lebesgue measure.\n\nFor convenience, we will abbreviate this as \" $W^{*}$ is a regular subpopulation of $W_{0}$ \". We denote the set of regular subpopulations of $W_{0}$ as\n\n$$\n\\operatorname{SP}\\left(W_{0}\\right)=\\left\\{W^{*} \\in\\{0,1\\}: W^{*} \\text { is a regular subpopulation of } W_{0}\\right\\}\n$$\n\nWe consider subpopulations with positive masses that are subsets of $\\left\\{W_{0}=1\\right\\}$. The second and main requirement is that regular subpopulations do not depend on potential outcomes when conditioning on $X$ and the original population $W_{0}=1$. While this may seem restrictive, it allows for rich and natural classes of subpopulations. For example, consider the unconfoundedness restriction of Section 2 and let $W_{0}$ be the entire population, i.e. $\\mathbb{P}\\left(W_{0}=1\\right)=1$. In this case, regular subpopulations must satisfy $W^{*} \\Perp(Y(1), Y(0)) \\mid X$, or be unconfounded. Regular subpopulations include the population of all treated (or untreated) individuals, i.e. $W^{*}=D$ (or $W^{*}=1-D$ ), and any subpopulation characterized by a subset of $\\operatorname{supp}(X)$. More generally, they include any subpopulation that can be described through a combination of $(D, X, U)$ where $U$ is independent from $(Y(1), Y(0), X)$. For example, a subpopulation characterized by \"fraction $a(x)$ of units with covariate $X=x$ for all $x \\in \\operatorname{supp}(X)$ \" can be constructed as $W^{*}=\\mathbb{1}(U \\leq a(X))$ where $U \\sim \\operatorname{Unif}(0,1)$ is independent from $(Y(1), Y(0), X)$.\n\nThe conditional independence requirement rules out subpopulations that directly depend on the potential outcomes such as $W^{*}=\\mathbb{1}(Y(1) \\geq Y(0))$, the subpopulation of those who benefit from treatment. Note that $\\mathbb{P}\\left(W^{*}=1 \\mid X\\right)=\\mathbb{P}(Y(1) \\geq Y(0) \\mid X)$ and $\\mathbb{P}\\left(W^{*}=1\\right)=\\mathbb{P}(Y(1) \\geq Y(0))$ are not point-identified under unconfoundedness. Another way to view this requirement is that regular subpopulations are policy relevant in the sense that we could design a policy that targets a regular subpopulation. Indeed, a policy maker may observe $X$ and can use $U$ to randomly target a fraction of units with specific values of $X$, but cannot observe potential outcomes.\n\nThese particular subpopulations enjoy a number of useful properties. Two of them are characterized in the following proposition.\n\nProposition 3.1 (Properties of regular subpopulations). Suppose that $\\mathbb{P}\\left(W_{0}=1\\right)>0$ and $W^{*} \\in \\operatorname{SP}\\left(W_{0}\\right)$.\n\n1. Suppose $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1, X\\right)>0$. Then,\n\n$$\n\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1, X]=\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1, X]\n$$\n\n2. Suppose $\\mathbb{E}\\left[\\tau_{0}(X)^{2}\\right]<\\infty$. Then,\n\n$$\n\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1]=\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]}=\\mu\\left(\\underline{w}^{*}, \\tau_{0}\\right)\n$$\n\nwhere $\\underline{w}^{*}(x):=\\mathbb{P}\\left(W^{*}=1 \\mid X=x, W_{0}=1\\right)$.\nThe first part of this proposition shows that average effects within the original population $W_{0}$ and regular subpopulation $W^{*}$ are the same when conditioning on $X$. For example, this holds under unconfoundedness for the subpopulation of treated individuals, $W^{*}=D$. The second property allows us to write the average effect for $W^{*}=1$ using the same functional $\\mu(\\cdot, \\cdot)$ that was used to characterize the class of estimands we analyze. This property will be used when studying the mapping between weighted estimands and average effects for regular subpopulations of $W_{0}$.\n\nWe conclude this subsection by showing that regular subpopulations are transitive, or that regular subpopulations of a regular subpopulation of $W_{0}$ are also regular subpopulations of $W_{0}$.\n\nLemma 3.1 (Transitivity of regular subpopulations). Suppose $W^{*}$ is a regular subpopulation of $W^{\\prime}$ and that $W^{\\prime}$ is a regular subpopulation of $W_{0}$. Then, $W^{*}$ is a regular subpopulation of $W_{0}$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 8,
      "text": "# 3.3 Existence of a Causal Representation for Weighted Estimands \n\nWe now consider necessary and sufficient conditions for the weighted estimand $\\mu\\left(a, \\tau_{0}\\right)$ to be written as the average treatment effect within a regular subpopulation of $W_{0}$. As we will show, these conditions depend on what is assumed about the function $\\tau_{0}=\\mathbb{E}[Y(1)-Y(0) \\mid X=\\cdot, W_{0}=1]$.\n\nFor example, if $\\tau_{0}$ is constant in $X$, then any weighted estimand satisfying (1.1) equals $\\mathbb{E}[Y(1)-Y(0) \\mid$ $W_{0}=1]$, the average treatment effect within population $\\left\\{W_{0}=1\\right\\}$. This is the case even when the sign of weight function $a(X)$ varies with $X$. However, if $\\tau_{0}$ is nonconstant, the existence of causal representations will depend on the weight function $a(X)$. Among other cases, we will consider the case where no restrictions are placed on function $\\tau_{0}$, and in this case, the existence of a causal representation of $\\mu\\left(a, \\tau_{0}\\right)$ will require the sign of $a(X)$ to be constant.\n\nTo formalize this, let $\\mathcal{T}$ denote a class of functions such that $\\tau_{0} \\in \\mathcal{T}$ and define\n\n$$\n\\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}\\right)=\\left\\{W^{*} \\in \\operatorname{SP}\\left(W_{0}\\right): \\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=1\\right] \\text { for all } \\tau_{0} \\in \\mathcal{T}\\right\\}\n$$\n\nThis is the set of regular subpopulations of $W_{0}$ such that the estimand $\\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=1\\right]$ for all $\\tau_{0}$ functions in the set $\\mathcal{T}$. If the set $\\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}\\right)$ is empty, then estimand $\\mu\\left(a, \\tau_{0}\\right)$ cannot be written as an average treatment effect over a regular subpopulation of $W_{0}$ uniformly in $\\tau_{0} \\in \\mathcal{T}$. We use this set to formally define a notion of uniform causal representation.\n\nDefinition 3.2. A weighted estimand $\\mu\\left(a, \\tau_{0}\\right)$ has a causal representation uniformly in $\\tau_{0} \\in \\mathcal{T}$ if\n\n$$\n\\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}\\right) \\neq \\emptyset\n$$\n\nRecall that $\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=1\\right]=\\mu\\left(\\underline{w}^{*}, \\tau_{0}\\right)$ where $\\underline{w}^{*}(X)=\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1, X\\right)$, so $W^{*} \\in$ $\\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}\\right)$ if $\\mu\\left(a, \\tau_{0}\\right)=\\mu\\left(\\underline{w}^{*}, \\tau_{0}\\right)$ for all $\\tau_{0} \\in \\mathcal{T}$. We examine further two main cases for the set $\\mathcal{T}$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 9,
      "text": "### 3.3.1 Existence Uniformly in $\\tau_{0}$\n\nWe begin by considering the largest class of functions in which $\\tau_{0}$ lies: the class of all functions, subject to the moment condition in Assumption 3.1 that ensures the existence of $\\mu\\left(a, \\tau_{0}\\right)$. We denote this class by\n\n$$\n\\mathcal{T}_{\\mathrm{all}}:=\\left\\{\\tau_{0}: \\mathbb{E}\\left[\\tau_{0}(X)^{2}\\right]<\\infty\\right\\}\n$$\n\nIn this function class, we show the existence of a causal representation is equivalent to the estimand's weights being nonnegative. In what follows, let $a_{\\max }:=\\sup \\left(\\operatorname{supp}\\left(a(X) \\mid W_{0}=1\\right)\\right)$ be the essential supremum of $a(X)$ given $W_{0}=1$.\n\nTheorem 3.1. Let $\\mu\\left(a, \\tau_{0}\\right)$ be an estimand satisfying equation (1.1). Suppose Assumption 3.1 holds and that $a_{\\max }<\\infty$. Then, $\\mu\\left(a, \\tau_{0}\\right)$ has a causal representation uniformly in $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$ if and only if\n\n$$\n\\mathbb{P}(a(X) \\geq 0 \\mid W_{0}=1)=1\n$$\n\nA uniform (in $\\mathcal{T}_{\\text {all }}$ ) causal representation exists if and only if $a(X)$ is nonnegative on the support of $X \\mid$ $\\left\\{W_{0}=1\\right\\}$. To give some intuition on why the sign of $a(X)$ must be nonnegative with probability 1 , we present a contradiction that occurs when $a(X)$ can be negative. Suppose that $\\mathbb{P}\\left(a(X)<0 \\mid W_{0}=1\\right)>0$ and consider the \"adversarial\" CATE function $\\tau^{-}(X)=\\mathbb{1}(a(X)<0)$. This CATE function is nonnegative for all $X$, and implies a positive average effect only for units with negative weights. However, it yields a strictly negative weighted estimand, $\\mu\\left(a, \\tau^{-}\\right)=\\mathbb{E}[a(X) \\mathbb{1}(a(X)<0) \\mid W_{0}=1] / \\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]<0$. Clearly, $\\mu\\left(a, \\tau^{-}\\right)$cannot be the average treatment effect for any subpopulation of $W_{0}$, because averaging a nonnegative CATE function over any subpopulation cannot yield a negative average.\n\nConversely, if $a(X) \\geq 0$, our proof constructively defines a regular subpopulation $W^{*}$ for which the average effect is equal to the weighted estimand $\\mu\\left(a, \\tau_{0}\\right)$ uniformly in $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$. Let\n\n$$\nW^{*}=\\mathbb{1}\\left(U \\leq \\frac{a(X)}{a_{\\max }}\\right) \\cdot W_{0}\n$$\n\nwhere $U \\sim \\operatorname{Unif}(0,1) \\Perp(Y(1), Y(0), X, W_{0})$. This is a regular subpopulation of $W_{0}$ for which the probability of inclusion, conditional on $X$ and $W_{0}=1$, is proportional to $a(X)$. We can also interpret $\\mu\\left(a, \\tau_{0}\\right)$ as the average effect of an intervention in which units with covariate value $X$ are treated randomly with probability $a(X) / a_{\\max }$ given $W_{0}=1$. From this construction, we can see that $\\underline{w}^{*}(X)=\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1, X\\right)$ is proportional to $a(X)$, and therefore $\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=1\\right]=\\mu\\left(\\underline{w}^{*}, \\tau_{0}\\right)=\\mu\\left(a, \\tau_{0}\\right)$ uniformly in $\\tau_{0}$.\n\nThe condition $a_{\\max }<\\infty$ restricts our attention to subpopulations with positive mass. We note that $a_{\\max }$ is bounded above in each of our theoretical examples in Sections 2 and 5, implying that this condition trivially holds in these cases.\n\nAs mentioned earlier, the condition that weights are nonnegative is commonly invoked and was shown in Blandhol, Bonney, Mogstad, and Torgovitsky (2022) to be equivalent to an estimand being \"weakly causal,\" which means that it is guaranteed to match the sign of $\\tau_{0}$ whenever that sign is the same across all units. Thus, in the class of weighted estimands we consider, estimands have a causal representation uniformly in $\\mathcal{T}_{\\text {all }}$ if and only if they are weakly causal. This connection is formally established in Appendix A.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 10,
      "text": "# 3.3.2 Existence for a Given $\\tau_{0}$ \n\nWe now provide an existence result that requires the causal representation to exist only for the given $\\tau_{0}$, rather than uniformly for $\\tau_{0}$ in the larger set $\\mathcal{T}_{\\text {all }}$. The following result depends on the CATE function $\\tau_{0}$ in the population, whereas Theorem 3.1's condition depended only on the weight function $a(X)$ and the nature of the covariates' support. Thus, the distribution of the potential outcomes will have an impact on the existence of a causal representation given $\\tau_{0}$. Using the notation from Definition 3.2, a causal representation exists if and only if $\\mathcal{W}\\left(a ; W_{0},\\left\\{\\tau_{0}\\right\\}\\right) \\neq \\emptyset$. The following theorem characterizes this existence.\n\nTheorem 3.2. Let $\\mu\\left(a, \\tau_{0}\\right)$ be an estimand satisfying equation (1.1). Suppose Assumption 3.1 holds. Then,\n\n$\\mu\\left(a, \\tau_{0}\\right)$ has a causal representation for the given $\\tau_{0}$ if and only if\n\n$$\n\\mu\\left(a, \\tau_{0}\\right) \\in \\mathcal{S}\\left(\\tau_{0} ; W_{0}\\right):=\\left\\{t \\in \\mathbb{R}: \\mathbb{P}\\left(\\tau_{0}(X) \\leq t \\mid W_{0}=1\\right)>0 \\text { and } \\mathbb{P}\\left(\\tau_{0}(X) \\geq t \\mid W_{0}=1\\right)>0\\right\\}\n$$\n\nThe existence condition in Theorem 3.2 is weaker than the one in Theorem 3.1 since we no longer require this representation to be valid for any CATE function, but rather just for the one that is identified from the population. The necessary and sufficient condition in this theorem is rather weak, since it only requires that the estimand is in the convex hull of the support of the CATEs. This means $\\mu\\left(a, \\tau_{0}\\right)$ has a causal representation even with negative weights, as long as there are CATEs smaller and greater than $\\mu\\left(a, \\tau_{0}\\right)$. We can see this support condition holds for all $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$ if and only if $\\mu\\left(a, \\tau_{0}\\right)$ is in the support of $\\tau_{0}(X)$ for any $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$. This is precisely the case when the weights $a(X)$ are nonnegative since it guarantees $\\inf \\left(\\operatorname{supp}\\left(\\tau_{0}(X) \\mid W_{0}=1\\right)\\right) \\leq \\mu\\left(a, \\tau_{0}\\right) \\leq \\sup \\left(\\operatorname{supp}\\left(\\tau_{0}(X) \\mid W_{0}=1\\right)\\right)$ for any function $\\tau_{0}$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 11,
      "text": "# 3.3.3 Existence in Intermediate Cases \n\nAnalyzing the causal representation of an estimand under no restrictions on $\\tau_{0}$ could be viewed as unnecessarily conservative in some settings. At the other extreme, assuming knowledge of $\\tau_{0}$ may be unrealistic, especially in scenarios where $X$ has many components which makes the estimation of $\\tau_{0}$ more challenging. For example, some shape constraints may be known to hold for $\\tau_{0}$. In some economic applications one may posit that $\\tau_{0}$ is monotonic or convex in some components of $X$, or positive/negative over a subset of $\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)$. In these cases, the existence of a causal representation may occur under weaker conditions than those in Theorem 3.1, but stronger than those in Theorem 3.2. In particular, one may be able to relax the requirement that $a(X) \\geq 0$ without requiring that $\\tau_{0}$ be completely known to the researcher. The following proposition shows this is the case when $\\tau_{0}(X)$ is assumed to be linear in $X$.\n\nProposition 3.2. Let $\\mu\\left(a, \\tau_{0}\\right)$ be an estimand satisfying equation (1.1). Suppose Assumption 3.1 holds and define\n\n$$\n\\mathcal{T}_{\\text {lin }}=\\left\\{\\tau_{0} \\in \\mathcal{T}_{\\text {all }}: \\tau_{0}(X)=c+d^{\\prime} X:(c, d) \\in \\mathbb{R}^{1+d_{X}}\\right\\}\n$$\n\nThen, $\\mu\\left(a, \\tau_{0}\\right)$ has a causal representation uniformly in $\\tau_{0} \\in \\mathcal{T}_{\\text {lin }}$ if and only if\n\n$$\n\\frac{\\mathbb{E}\\left[a(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]} \\in \\operatorname{conv}\\left(\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)\\right)\n$$\n\nwhere $\\operatorname{conv}(\\cdot)$ denotes the convex hull.\n\nThe above proposition shows that restricting the class of CATE functions $\\tau_{0}$ belongs to may remove the requirement that $a(X) \\geq 0$ for the existence of a uniform causal representation for an estimand. In particular, the requirement here is that $\\frac{\\mathbb{E}\\left[a(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}$ lies in the convex hull of the support of $X$ given $W_{0}=1$. When $X$ is scalar, this consists of an interval. This condition does not require $a(X)$ be nonnegative. For example, if $\\operatorname{supp}(X)=\\{0,1,2\\}$ and $W_{0}=1$ almost surely, then any combination of values of $(a(0), a(1), a(2))$ such that $\\mathbb{E}[a(X) X] / \\mathbb{E}[a(X)] \\in[0,2]=\\operatorname{conv}(\\operatorname{supp}(X))$ implies a causal representation. Let $\\mathbb{P}(X=x)=1 / 3$ for $x \\in\\{0,1,2\\}$ and $(a(0), a(1), a(2))=(1,-1,1)$. Here units with $X=1$ have a negative weight, but\n\n$\\mathbb{E}[a(X) X] / \\mathbb{E}[a(X)]=1 \\in[0,2]$, implying that the corresponding weighted estimand has a causal representation uniformly in $\\tau_{0} \\in \\mathcal{T}_{\\text {lin }}$.\n\nWe consider another class of CATE functions that restricts their heterogeneity. For $K \\geq 0$, let\n\n$$\n\\mathcal{T}_{\\mathrm{BD}}(K)=\\left\\{\\tau_{0} \\in \\mathcal{T}_{\\mathrm{n} 1}: \\sup _{x, x^{\\prime} \\in \\operatorname{supp}\\left(X \\mid W_{0}=1\\right)}\\left|\\tau_{0}(x)-\\tau_{0}\\left(x^{\\prime}\\right)\\right| \\leq K\\right\\}\n$$\n\nThis function class uniformly bounds differences of the CATE function. When $K=0$, the CATE function is constant, and thus equal to $\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]$. When $K>0$, CATEs may differ in value, but the maximum discrepancy between two CATEs is bounded above by $K$. We show that restricting the CATEs to satisfy this bounded difference assumption does not remove the requirement that $a(X)$ be nonnegative, unless $K=0$, in which case all $a$ functions yield a causal representation uniformly in $\\mathcal{T}_{\\mathrm{BD}}(0)$. We formalize this in the next proposition.\n\nProposition 3.3. Let $\\mu\\left(a, \\tau_{0}\\right)$ be an estimand satisfying equation (1.1). Suppose Assumption 3.1 holds. Then, $\\mu\\left(a, \\tau_{0}\\right)$ has a causal representation uniformly in $\\mathcal{T}_{\\mathrm{BD}}(K)$ when $K>0$ if and only if\n\n$$\n\\mathbb{P}(a(X) \\geq 0 \\mid W_{0}=1)=1\n$$\n\nThe estimand $\\mu\\left(a, \\tau_{0}\\right)$ has a causal representation uniformly in $\\mathcal{T}_{\\mathrm{BD}}(0)$ for any $a(\\cdot)$.\nTo understand this proposition, consider the adversarial CATE function $\\tau^{-}(X)=K \\cdot \\mathbb{1}(a(X)<0)$, a member of $\\mathcal{T}_{\\mathrm{BD}}(K)$, and assume $\\mathbb{P}(a(X) \\geq 0)<1$. Then we obtain the same contradiction we discussed after Theorem 3.1, where the CATE is nonnegative for all covariate values but the estimand is negative, implying that it cannot be written as an average effect over a subpopulation.\n\nThese last two propositions show that the impact of restrictions on $\\tau_{0}$ on the requirement that $a(X)$ be nonnegative critically depends on the nature of these restrictions. Generalizations to additional or empirically motivated function classes are left for future work.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 12,
      "text": "# 4 Quantifying the Internal Validity of Weighted Estimands \n\nMany estimands will admit causal representations, but their associated subpopulations $\\left\\{W^{*}=1\\right\\}$ will generally differ. Also, a weighted estimand may not always correspond to the target estimand a researcher is interested in. For example, a researcher may be interested in setting $\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]$, the average effect in population $\\left\\{W_{0}=1\\right\\}$, as the target parameter. In general, this parameter differs from estimand $\\mu\\left(a, \\tau_{0}\\right)$.\n\nHowever, the set of subpopulations corresponding to a weighted estimand can be used to understand how representative the weighted estimand is of the target. For example, we may seek estimands for which $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ attains values closest to 1 , since they have a higher degree of internal validity with respect to the target $\\mathbb{E}\\left[Y(1)-Y(0) \\mid W_{0}=1\\right]$. At one extreme, an estimand for which $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=\\right.$ $1)=1$ would be deemed to have the highest degree of internal validity for this target parameter since it would equal $\\mathbb{E}\\left[Y(1)-Y(0) \\mid W_{0}=1\\right]$.\n\nWe convert this interpretation in a formal measure of internal validity that we define here.\n\nDefinition 4.1 (Internal validity). Let\n\n$$\n\\bar{P}\\left(a, W_{0} ; \\mathcal{T}\\right)=\\sup _{W^{*} \\in \\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}\\right)} \\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)\n$$\n\ndenote the measure of internal validity of weighted estimand $\\mu\\left(a, \\tau_{0}\\right)$ over function class $\\mathcal{T}$.\n\nFormally, $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}\\right)$ is the sharp upper bound on $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ for any regular subpopulation $W^{*}$ of $W_{0}$ such that the weighted estimand $\\mu\\left(a, \\tau_{0}\\right)$ has a causal representation as the average treatment effect over subpopulation $W^{*}$. Note that we set $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}\\right)=0$ when $\\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}\\right)$ is empty. This object depends on the chosen function class $\\mathcal{T}$, as did Theorems 3.1 and 3.2 in the previous section. Given the above terminology and assuming that $\\mathbb{E}\\left[Y(1)-Y(0) \\mid W_{0}=1\\right]$ is the target, we call $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}\\right)$ a measure of the internal validity of estimand $\\mu\\left(a, \\tau_{0}\\right)$, and we use this definition in the remainder of the paper.\n\nWe can also compute the maximum value of $\\mathbb{P}\\left(W^{*}=1\\right)$ across $W^{*} \\in \\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}\\right)$, which measures the largest share of the entire population for which the weighted estimand has a causal representation. We refer to this measure as a measure of representativeness. The measures of internal validity and representativeness are the same when $W_{0}=1$ almost surely.\n\nDefinition 4.2 (Representativeness). Let\n\n$$\n\\bar{P}\\left(a, W_{0} ; \\mathcal{T}\\right) \\cdot \\mathbb{P}\\left(W_{0}=1\\right)=\\sup _{W^{*} \\in \\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}\\right)} \\mathbb{P}\\left(W^{*}=1\\right)\n$$\n\ndenote the measure of representativeness of weighted estimand $\\mu\\left(a, \\tau_{0}\\right)$ over function class $\\mathcal{T}$.\nNote that $\\mathbb{P}\\left(W^{*}=1\\right)=\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right) \\cdot \\mathbb{P}\\left(W_{0}=1\\right)$ since $W^{*}$ is a subpopulation of $W_{0}$. This maximum value of $\\mathbb{P}\\left(W^{*}=1\\right)$ gives the internal validity of the weighted estimand with respect to target estimand $\\mathbb{E}[Y(1)-Y(0)]$, the average treatment effect in the population from which the sample is drawn. Our measures of internal validity and representativeness are closely linked and a subpopulation will maximize $\\mathbb{P}\\left(W^{*}=1\\right)$ if and only if it maximizes $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$. We will also show how to use these measures to obtain simple bounds on target estimands.\n\nWe now derive explicit expressions for $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}\\right)$. As earlier, we break down our results in two cases, the first being when $\\tau_{0}$ is unrestricted.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 13,
      "text": "# 4.1 Quantifying Internal Validity Uniformly in $\\tau_{0}$ \n\nWithout imposing any restrictions on the CATE function, except for the existence of second moments, the maximum value that $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ can achieve is given by the following theorem.\n\nTheorem 4.1. Let $\\mu\\left(a, \\tau_{0}\\right)$ be an estimand satisfying equation (1.1). Suppose Assumption 3.1 holds and that $a_{\\max }<\\infty$. If $\\mathbb{P}\\left(a(X) \\geq 0 \\mid W_{0}=1\\right)=1$, then\n\n$$\n\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\mathrm{all}}\\right)=\\frac{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}{a_{\\max }}\n$$\n\nIf $\\mathbb{P}\\left(a(X) \\geq 0 \\mid W_{0}=1\\right)<1$, then $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)=0$.\n\nHere we see that the maximum size of a subpopulation characterizing the estimand $\\mu\\left(a, \\tau_{0}\\right)$ depends on $a(X)$ through two terms: its conditional mean in the numerator, and its supremum $a_{\\max }$ in the denominator. This bound can be computed at what Imbens and Rubin (2015) call the \"design stage\" of the study, that is, without any knowledge of the conditional distribution of the outcome. The bound depends solely on the weight function $a(\\cdot)$ and the distribution of $X \\mid\\left\\{W_{0}=1\\right\\}$.\n\nTo understand the supremum's role in this expression, let $\\underline{w}^{*}(X)=\\mathbb{P}\\left(W^{*}=1 \\mid X, W_{0}=1\\right)$ and note that $\\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1]$ is equivalent to writing\n\n$$\n\\mu\\left(a, \\tau_{0}\\right)=\\frac{\\mathbb{E}\\left[a(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}=\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]}=\\mu\\left(\\underline{w}^{*}, \\tau_{0}\\right)\n$$\n\nfor all $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$. Equation (4.1) holding for all $\\tau_{0}$ requires $\\underline{w}^{*}(X)$ to be exactly proportional to $a(X)$. While the range of $a(X)$ is unconstrained, $\\underline{w}^{*}(X)$ must lie in $[0,1]$ to be a valid conditional probability. Since we seek to maximize $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)=\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]$, we let $\\underline{w}^{*}(X)$ be the largest multiple of $a(X)$ that lies in $[0,1]$ with probability 1 , which is defined below:\n\n$$\nW^{*}=\\mathbb{1}\\left(U \\leq \\frac{a(X)}{a_{\\max }}\\right) \\cdot W_{0} \\quad \\text { and } \\quad \\underline{w}^{*}(X)=\\frac{a(X)}{a_{\\max }}\n$$\n\nHere, $U \\sim \\operatorname{Unif}(0,1)$ and $U \\Perp(Y(1), Y(0), X, W_{0})$. This population places relatively more weight on units with larger values of $a(X)$. Specifically, the population $\\left\\{W^{*}=1\\right\\}$ contains a random subset of $\\left\\{W_{0}=1\\right\\}$ where the probability of inclusion is proportional to $a(X)$. Thus, units with larger values of $a(X)$ are more likely to be included in $W^{*}$. All units in $\\left\\{W_{0}=1\\right\\}$ with $X$ such that $a(X)=a_{\\max }$ are included in $W^{*}$, whereas no units where $a(X)=0$ are included.\n\nThe construction of this subpopulation is illustrated in Figure 1 for the case where $x$ is continuous and where we omit the conditioning on $W_{0}=1$ for simplicity. We seek to maximize $\\mathbb{P}\\left(W^{*}=1\\right)=$ $\\int \\underline{w}^{*}(x) f_{X}(x) d x$ with the requirement that $\\underline{w}^{*}(x) \\leq 1$ (or, equivalently, $\\underline{w}^{*}(x) f_{X}(x) \\leq f_{X}(x)$ ) and that $\\underline{w}^{*}(x)$ is a multiple of $a(x)$. In the figure, we see that $a_{\\max }>1$ and thus the largest multiple of $a(x)$ that is weakly smaller than 1 is illustrated by the gray curve. The area under this curve is precisely $\\mathbb{P}\\left(W^{*}=1\\right)$. Note that the area under $f_{X}(x)$ is one, so closer alignment of the gray curve and the density $f_{X}(x)$ corresponds to more representative estimands.\n\nSeveral further comments about Theorem 4.1 are in order.\nRemark 4.1 (Estimands and their corresponding interventions). We note that estimand $\\mu\\left(a, \\tau_{0}\\right)$ is invariant to the scale of $a(\\cdot)$ and thus can be written as\n\n$$\n\\mu\\left(a, \\tau_{0}\\right)=\\frac{\\mathbb{E}\\left[\\frac{a(X)}{a_{\\max }} \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\frac{a(X)}{a_{\\max }} \\mid W_{0}=1\\right]}\n$$\n\nwhere $a(X) / a_{\\max } \\in[0,1]$ almost surely when weights are nonnegative. From this representation, we can link estimand $\\mu\\left(a, \\tau_{0}\\right)$ with an intervention where fraction $a(X) / a_{\\max }$ of units with covariate value $X$ and $W_{0}=1$ are treated. For example, if $W_{0}=1$ almost surely and $a(X)=a_{\\max }$, then $\\mu\\left(a, \\tau_{0}\\right)$ is the average treatment effect, $\\mathbb{E}[Y(1)-Y(0)]$, and it measures the average effect of treatment among all units. Under\n\nFigure 1: Characterizing a Representative Subpopulation Uniformly in $\\mathcal{T}_{\\text {all }}$\n![img-0.jpeg](img-0.jpeg)\n\nNotes: $X$ is a single continuously distributed covariate.\nunconfoundedness, we also note that the average treatment effect on the treated (ATT) can be written as\n\n$$\n\\mathbb{E}[Y(1)-Y(0) \\mid D=1]=\\frac{\\mathbb{E}\\left[\\mathbb{P}\\left(D=1 \\mid X\\right) \\cdot \\tau_{0}(X)\\right]}{\\mathbb{E}[\\mathbb{P}(D=1 \\mid X)]}\n$$\n\nThus, a weighted estimand with weights $a(X)=\\mathbb{P}(D=1 \\mid X)$ can be interpreted either as the effect of an intervention where fraction $\\mathbb{P}(D=1 \\mid X)$ of units with covariate $X$ are treated or as the effect of an intervention where all treated units are treated. In our setting, we can interpret any weighted estimand with nonnegative weights as the effect of treatment for a feasible intervention defined only in terms of $X, W_{0}$, and independent noise $U \\sim \\operatorname{Unif}(0,1)$ via $W^{*}=\\mathbb{1}\\left(U \\leq a(X) / a_{\\max }\\right) \\cdot W_{0}$. However, some of these estimands correspond to interventions that are more likely to be of interest to researchers, such as the ATE or ATT.\n\nRemark 4.2 (Uniqueness of representative subpopulations). It is also worth noting that the subpopulation maximizing the level of internal validity is generally not unique. The population $W^{*}=\\mathbb{1}\\left(U \\leq a(X) / a_{\\max }\\right)$. $W_{0}$ will generally change if $U$ is replaced by another draw from a uniform distribution. The probability (conditional on $X$ ) of any unit being part of $W^{*}$ does not change with the draw of $U$, but whether any given unit is part of subpopulation $\\left\\{W^{*}=1\\right\\}$ cannot be determined.\n\nRemark 4.3 (Distributional characteristics of representative subpopulations). We can generally identify\n\ndistributional characteristics of units within the population $W^{*}$. For example, when $W_{0}$ is set to 1 almost surely, we can write the average values of $g(X)$ among subpopulation $\\left\\{W^{*}=1\\right\\}$ as\n\n$$\n\\mathbb{E}\\left[g(X) \\mid W^{*}=1\\right]=\\frac{\\mathbb{E}\\left[g(X) \\mathfrak{M}^{*}(X)\\right]}{\\mathbb{E}\\left[\\mathfrak{M}^{*}(X)\\right]}=\\frac{\\mathbb{E}[g(X) a(X)]}{\\mathbb{E}[a(X)]}\n$$\n\na simple function of weights $a(\\cdot)$ and the marginal distribution of $X$. We can recover the average covariate values in $\\left\\{W^{*}=1\\right\\}$ by setting $g(X)=X$, or the entire distribution by considering $g(X)=\\mathbb{1}(X \\leq x)$ for all $x \\in \\mathbb{R}^{d_{X}}$. Reporting the average covariate values of units within and outside of $W^{*}$ can be of interest when assessing the representativeness of $\\mu\\left(a, \\tau_{0}\\right)$.\n\nRemark 4.4 (Defining the target estimand from the weighted estimand). Suppose we consider $\\mathbb{E}[Y(1)-$ $Y(0) \\mid W^{*}=1]$ to be the target estimand, where $W^{*}=\\mathbb{1}\\left(U \\leq a(X) / a_{\\max }\\right) \\cdot W_{0}$ is the subpopulation for which $\\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1]$ uniformly in $\\tau_{0}$. For example, in the case of the OLS estimand in Section 2, this consists of a subpopulation where the probability of inclusion is proportional to $\\operatorname{var}(D \\mid X)$, the conditional variance of treatment. If this subpopulation is the target, it would be reasonable to infer that the measure of internal validity of the estimand $\\mu\\left(a, \\tau_{0}\\right)$ is the maximum value of 1 . Indeed, this is the case because the estimand can be written as\n\n$$\n\\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1]\n$$\n\nand $\\left\\{W^{*}=1\\right\\}$ is trivially the largest regular subpopulation of $\\left\\{W^{*}=1\\right\\}$. This illustrates how the internal validity of $\\mu\\left(a, \\tau_{0}\\right)$ is entirely dependent on the target estimand. On the other hand, the representativeness of the weighted estimand, as measured by the largest value of $\\mathbb{P}\\left(W^{*}=1\\right)$, is independent of this target. In this case, it is less than one unless $W^{*}=1$ almost surely, or that the weighted estimand actually equals the ATE. Theorem 4.4 below can also be applied to obtain this intuition.\n\nWe now consider a simple example to give further intuition for Theorem 4.1.",
      "tables": {},
      "images": {
        "img-0.jpeg": "data:image/jpeg;base64,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"
      }
    },
    {
      "section_id": 14,
      "text": "# 4.1.1 Illustrative Example: A Single Binary Covariate \n\nConsider an estimand $\\mu\\left(a, \\tau_{0}\\right)$ where $W_{0}=1$ almost surely, $a(X) \\geq 0$, and where $X$ is binary with support $\\operatorname{supp}(X)=\\{1,2\\}$. Let $p_{x}=\\mathbb{P}(X=x)$ for $x \\in\\{1,2\\}$. As in Section 3.1, the weighted estimand can be written as a linear combination of the two CATEs:\n\n$$\n\\mu\\left(a, \\tau_{0}\\right)=\\frac{a(1) p_{1}}{\\mathbb{E}[a(X)]} \\tau_{0}(1)+\\frac{a(2) p_{2}}{\\mathbb{E}[a(X)]} \\tau_{0}(2):=\\omega_{1} \\tau_{0}(1)+\\omega_{2} \\tau_{0}(2)\n$$\n\nLet $\\mathrm{ATE}=\\mathbb{E}[Y(1)-Y(0)]$ be the target estimand, which can be written as\n\n$$\n\\mathrm{ATE}=p_{1} \\tau_{0}(1)+p_{2} \\tau_{0}(2)\n$$\n\nIf $a(1)=a(2)$, the relative weights placed on $\\{X=1\\}$ and $\\{X=2\\}$ by the estimand are equal to $p_{1} / p_{2}$, the ratio of the weights placed by the ATE. Therefore, the estimand equals the ATE and thus clearly has the maximum degree of internal validity with respect to the ATE. Applying Theorem 4.1, we can directly see\n\nthat\n\n$$\n\\overline{\\mathcal{P}}\\left(a, W_{0} ; \\mathcal{T}_{\\mathrm{all}}\\right)=\\frac{\\mathbb{E}[a(X)]}{\\sup _{x \\in\\{1,2\\}} a(x)}=\\frac{a(1) p_{1}+a(2) p_{2}}{\\max \\{a(1), a(2)\\}}=\\frac{a(2)\\left(p_{1}+p_{2}\\right)}{a(2)}=1\n$$\n\nwhen $a(1)=a(2)$.\nHowever, when $a(1) \\neq a(2)$, the estimand's weights differ from $\\left(p_{1}, p_{2}\\right)$, the population weights for the two covariate cells. For concreteness, let $\\left(p_{1}, p_{2}\\right)=(0.2,0.8)$ and $(a(1), a(2))=(0.24,0.09)$, where the latter correspond, for example, to the OLS weights of Proposition 2.1 when the propensity score is $(p(1), p(2))=(0.4,0.1)$. In this case, $\\left(\\omega_{1}, \\omega_{2}\\right)=(0.4,0.6)$ and thus\n\n$$\n\\mu\\left(a, \\tau_{0}\\right)=0.4 \\cdot \\tau_{0}(1)+0.6 \\cdot \\tau_{0}(2) \\quad \\text { and } \\quad \\mathrm{ATE}=0.2 \\cdot \\tau_{0}(1)+0.8 \\cdot \\tau_{0}(2)\n$$\n\nRelative to the ATE, $\\mu\\left(a, \\tau_{0}\\right)$ overrepresents the population with $X=1$ and underrepresents the population with $X=2$. The largest subpopulation $\\left\\{W^{*}=1\\right\\}$ that causally represents the estimand can be constructed by combining subsets of the subpopulations defined by $\\{X=1\\}$ and $\\{X=2\\}$. Specifically, let\n\n$$\nW^{*}=\\mathbb{1}(X=1)+\\mathbb{1}\\left(U \\leq \\frac{a(2)}{a(1)}, X=2\\right)=\\mathbb{1}(X=1)+\\mathbb{1}\\left(U \\leq \\frac{3}{8}, X=2\\right)\n$$\n\nwhere $U \\sim \\operatorname{Unif}(0,1)$ is independent of $(Y(1), Y(0), X)$. This is a regular subpopulation that contains all units with $X=1$ and three eighths of units with $X=2$, selected uniformly at random. Therefore\n\n$$\n\\mathbb{P}\\left(W^{*}=1 \\mid X=1\\right)=\\underline{w}^{*}(1)=1 \\quad \\text { and } \\quad \\mathbb{P}\\left(W^{*}=1 \\mid X=2\\right)=\\underline{w}^{*}(2)=\\frac{3}{8}\n$$\n\nwhich yields $\\mathbb{P}\\left(W^{*}=1\\right)=p_{1} \\underline{w}^{*}(1)+p_{2} \\underline{w}^{*}(2)=0.5$. The same quantity can be obtained from Theorem 4.1, which implies that $\\overline{\\mathcal{P}}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)=\\mathbb{E}[a(X)] /\\left(\\sup _{x \\in\\{1,2\\}} a(x)\\right)=\\left(a(1) p_{1}+a(2) p_{2}\\right) / a(1)=0.5$. The average treatment effect in this subpopulation is given by\n\n$$\n\\begin{aligned}\n\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1] & =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X)\\right]}{\\mathbb{P}\\left(W^{*}=1\\right)} \\\\\n& =2\\left(1 \\cdot \\tau_{0}(1) \\cdot 0.2+3 / 8 \\cdot \\tau_{0}(2) \\cdot 0.8\\right) \\\\\n& =0.4 \\cdot \\tau_{0}(1)+0.6 \\cdot \\tau_{0}(2)\n\\end{aligned}\n$$\n\nwhich equals $\\mu\\left(a, \\tau_{0}\\right)$ for any choice of $\\tau_{0}$. Note that the relative weights placed on $\\{X=1\\}$ and $\\{X=2\\}$ in subpopulation $\\left\\{W^{*}=1\\right\\}$ are given by\n\n$$\n\\frac{\\mathbb{P}\\left(X=1 \\mid W^{*}=1\\right)}{\\mathbb{P}\\left(X=2 \\mid W^{*}=1\\right)}=\\frac{0.4}{0.6}=\\frac{\\omega_{1}}{\\omega_{2}}\n$$\n\nmatching the ratio of the weights on $\\{X=1\\}$ and $\\{X=2\\}$ assigned by the estimand. The subpopulation $\\left\\{W^{*}=1\\right\\}$ cannot expand while preserving this ratio since it already includes all units with $X=1$. Therefore, $W^{*}$ is the largest subpopulation for which $\\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1]$ for any $\\tau_{0}$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 15,
      "text": "# 4.2 Using the Measure of Internal Validity to Bound Average Effects \n\nThe subpopulation size in Theorem 4.1 can be used to bound the target estimand $\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]$. Consider a scenario where only the weighted estimand $\\mu\\left(a, \\tau_{0}\\right)$, which we assume has a causal representation uniformly in $\\mathcal{T}_{\\text {all }}$, and its internal validity are known. For example, this could be the case if a researcher uses a weighted estimand (e.g., OLS) and reports the measure we propose in Definition 4.1 to quantify its degree of internal validity for the ATE. To simplify notation, assume that $W_{0}=1$ almost surely. Abstracting from sample uncertainty, we only assume knowledge of the weighted estimand $\\mu\\left(a, \\tau_{0}\\right)$ and its internal validity, given by $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$. We can decompose the target estimand, here the ATE, as\n\n$$\n\\mathbb{E}[Y(1)-Y(0)]=\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=1\\right] \\cdot \\mathbb{P}\\left(W^{*}=1\\right)+\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=0\\right] \\cdot\\left(1-\\mathbb{P}\\left(W^{*}=1\\right)\\right)\n$$\n\nfor a $W^{*} \\in \\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\text {all }}\\right)$. If we have knowledge of bounds for the treatment effect $\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=0\\right]$, e.g. from the support of the potential outcomes, we can obtain bounds on $\\mathbb{E}[Y(1)-Y(0)]$. For example, if $\\operatorname{supp}(Y(1)-Y(0))=\\left[B_{\\ell}, B_{u}\\right]$, bounds for the target estimand are given by\n\n$$\n\\left[\\mu\\left(a, \\tau_{0}\\right) \\cdot \\mathbb{P}\\left(W^{*}=1\\right)+B_{\\ell} \\cdot\\left(1-\\mathbb{P}\\left(W^{*}=1\\right)\\right), \\mu\\left(a, \\tau_{0}\\right) \\cdot \\mathbb{P}\\left(W^{*}=1\\right)+B_{u} \\cdot\\left(1-\\mathbb{P}\\left(W^{*}=1\\right)\\right)\\right]\n$$\n\nThe width of these bounds is minimized when $\\mathbb{P}\\left(W^{*}=1\\right)$ is maximized, or when it equals the measure of internal validity for $\\mu\\left(a, \\tau_{0}\\right)$, given by $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$. The resulting bounds are\n\n$$\n\\left[\\mu\\left(a, \\tau_{0}\\right) \\cdot \\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)+B_{\\ell} \\cdot\\left(1-\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)\\right), \\mu\\left(a, \\tau_{0}\\right) \\cdot \\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)+B_{u} \\cdot\\left(1-\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)\\right)\\right]\n$$\n\nIf $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)=1$, it is easy to see that the estimand equals the ATE and that the bounds in (4.3) collapse to a point. However, the ATE is not uniquely determined from $\\left(\\mu\\left(a, \\tau_{0}\\right), \\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)\\right)$ when $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)<1$.\n\nThe width of these bounds is $\\left(B_{u}-B_{\\ell}\\right) \\cdot\\left(1-\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)\\right)$. Hence for fixed $\\left(B_{\\ell}, B_{u}\\right)$, this width decreases linearly with $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$. Moreover, values of $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$ close to 1 , or high degrees of internal validity, lead to narrow bounds. For example, if outcomes are binary with support $\\{0,1\\}$, then $\\left[B_{\\ell}, B_{u}\\right]=[-1,1]$ and knowing the values of $\\left(\\mu\\left(a, \\tau_{0}\\right), \\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)\\right)$ constrains the ATE to lie in\n\n$$\n\\left[\\mu\\left(a, \\tau_{0}\\right) \\cdot \\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)-\\left(1-\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)\\right), \\mu\\left(a, \\tau_{0}\\right) \\cdot \\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)+\\left(1-\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)\\right)\\right]\n$$\n\nIn this case, the bounds are centered at the estimand multiplied by our measure of internal validity, while the width of the bounds equals $2 \\cdot\\left(1-\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)\\right)$. It is easy to obtain a sample analog of these bounds by combining estimators for $\\mu\\left(a, \\tau_{0}\\right)$ and our proposed estimator for $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$ from Section 6 below.\n\nWe note that bounds on $\\mathbb{E}[Y(1)-Y(0)]$ may be tightened by assuming knowledge of other aspects of the joint distribution of $(Y(1), Y(0), D, X)$. For example, if knowledge of $a(\\cdot)$ is assumed, additional constraints on $\\mathbb{E}[Y(1)-Y(0)]$ can help narrow the bounds given in (4.3). We focus here on the case where we add a single piece of additional information to $\\mu\\left(a, \\tau_{0}\\right)$, namely its internal validity, and how simple bounds can be obtained from the estimand and our proposed measure. We leave refinements of such bounds under different information sets to future work.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 16,
      "text": "# Bounding Average Effects with Negative Weights \n\nNow consider a case where the weighted estimand $\\mu\\left(a, \\tau_{0}\\right)$ has weights that are sometimes negative, i.e., $\\mathbb{P}(a(X)<0)>0$. We continue to assume that $W_{0}=1$ almost surely. In this case, we know that $\\mu\\left(a, \\tau_{0}\\right)$ does not have a causal representation uniformly in $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$ and thus we cannot write $\\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}[Y(1)-Y(0) \\mid$ $W^{*}=1$ ] uniformly in $\\tau_{0}$. However, simple algebra reveals that an estimand with negative weights can be written as a weighted difference of two nonnegatively weighted estimands:\n\n$$\n\\begin{aligned}\n\\mu\\left(a, \\tau_{0}\\right) & =\\frac{\\mathbb{E}\\left[(a(X) \\mathbb{1}(a(X) \\geq 0)+a(X) \\mathbb{1}(a(X) \\leq 0)) \\tau_{0}(X)\\right]}{\\mathbb{E}[a(X)]} \\\\\n& =\\omega^{+} \\cdot \\mu\\left(a \\cdot \\mathbb{1}(a \\geq 0), \\tau_{0}\\right)-\\omega^{-} \\cdot \\mu((-a) \\cdot \\mathbb{1}(a \\leq 0), \\tau_{0})\n\\end{aligned}\n$$\n\nwhere $\\omega^{+}:=\\mathbb{E}[a(X) \\mathbb{1}(a(X) \\geq 0)] / \\mathbb{E}[a(X)]$ and $\\omega^{-}:=\\mathbb{E}[-a(X) \\mathbb{1}(a(X) \\leq 0)] / \\mathbb{E}[a(X)]$ are both nonnegative, and $\\omega^{+}-\\omega^{-}=1$. We note that $\\left(\\omega^{+}, \\omega^{-}\\right)=(1,0)$ when the estimand's weights are nonnegative, so this decomposition can be obtained regardless of the sign of $a$. Thus, by Theorem 3.1, we can write\n\n$$\n\\mu\\left(a, \\tau_{0}\\right)=\\omega^{+} \\cdot \\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{+}=1\\right]-\\omega^{-} \\cdot \\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{-}=1\\right]\n$$\n\nwhere $W^{+}$and $W^{-}$characterize two disjoint, regular subpopulations. As above, suppose we want to bound $\\mathbb{E}[Y(1)-Y(0)]$, the average treatment effect. Using the law of iterated expectations, we can write\n\n$$\n\\begin{aligned}\n\\mathbb{E}[Y(1)-Y(0)]=\\mathbb{P} & \\left(W^{+}=1\\right) \\cdot \\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{+}=1\\right]+\\mathbb{P}\\left(W^{-}=1\\right) \\cdot \\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{-}=1\\right] \\\\\n& +\\left[1-\\mathbb{P}\\left(W^{+}=1\\right)-\\mathbb{P}\\left(W^{-}=1\\right)\\right] \\cdot \\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{+}+W^{-}=0\\right]\n\\end{aligned}\n$$\n\nSubstituting equation (4.4) in (4.5) and assuming that $\\mathbb{E}[Y(1)-Y(0) \\mid W^{-}=1]$ and $\\mathbb{E}[Y(1)-Y(0) \\mid$ $\\left.W^{+}+W^{-}=0\\right]$ lie in $\\left[B_{\\ell}, B_{u}\\right]$ yields\n\n$$\n\\mathbb{E}[Y(1)-Y(0)] \\leq \\frac{\\mathbb{P}\\left(W^{+}=1\\right)}{\\omega^{+}} \\cdot \\mu\\left(a, \\tau_{0}\\right)+\\left(1-\\frac{\\mathbb{P}\\left(W^{+}=1\\right)}{\\omega^{+}}\\right) \\cdot B_{u}\n$$\n\nas an upper bound for the ATE. A lower bound is obtained by replacing $B_{u}$ with $B_{\\ell}$. Thus, the ATE lies in the interval\n\n$$\n\\left[\\frac{\\mathbb{P}\\left(W^{+}=1\\right)}{\\omega^{+}} \\cdot \\mu\\left(a, \\tau_{0}\\right)+\\left(1-\\frac{\\mathbb{P}\\left(W^{+}=1\\right)}{\\omega^{+}}\\right) \\cdot B_{\\ell}, \\frac{\\mathbb{P}\\left(W^{+}=1\\right)}{\\omega^{+}} \\cdot \\mu\\left(a, \\tau_{0}\\right)+\\left(1-\\frac{\\mathbb{P}\\left(W^{+}=1\\right)}{\\omega^{+}}\\right) \\cdot B_{u}\\right]\n$$\n\nThis interval is similar to the interval in (4.3), but the latter is only valid when weights are nonnegative. These intervals are identical when weights are nonnegative because $\\omega^{+}=1$ and $\\mathbb{P}\\left(W^{+}=1\\right)=\\mathbb{P}\\left(W^{*}=1\\right)$ in that case. In order to compute the interval in (4.6) and minimize its length, one needs to maximize the value of $\\mathbb{P}\\left(W^{+}=1\\right)$, which corresponds to the level of internal validity of the estimand $\\mu\\left(a \\cdot \\mathbb{1}(a \\geq 0), \\tau_{0}\\right)$ where $a \\cdot \\mathbb{1}(a \\geq 0) \\geq 0$, and compute the value of $\\omega^{+}$. This interval depends only on the ratio of the two quantities, which can be written as\n\n$$\n\\frac{\\mathbb{P}\\left(W^{+}=1\\right)}{\\omega^{+}} \\leq \\frac{\\bar{P}\\left(a \\cdot \\mathbb{1}(a \\geq 0), W_{0} ; \\mathcal{T}_{\\mathrm{all}}\\right)}{\\omega^{+}}=\\frac{\\mathbb{E}[a(X) \\mathbb{1}(a(X) \\geq 0)] / \\sup (\\operatorname{supp}(a(X) \\mathbb{1}(a(X) \\geq 0)))}{\\mathbb{E}[a(X) \\mathbb{1}(a(X) \\geq 0)] / \\mathbb{E}[a(X)]}=\\frac{\\mathbb{E}[a(X)]}{a_{\\max }}\n$$\n\nThis last expression equals the level of internal validity of the original estimand $\\mu\\left(a, \\tau_{0}\\right)$ when it is assumed (perhaps incorrectly) to have nonnegative weights. Thus, procedures used to quantify the internal validity of weighted estimands can also be used on estimands with negative weights if the goal is to bound average effects. As mentioned earlier, these bounds do not make use of the entire distribution of $(Y, D, X)$, but simply of the original estimand $\\mu\\left(a, \\tau_{0}\\right)$ and of $\\mathbb{E}[a(X)] / a_{\\max }$, the expression for the level of internal validity under nonnegative weights.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 17,
      "text": "# 4.3 Quantifying Internal Validity Given $\\tau_{0}$ \n\nWe can also ask how internally valid a weighted estimand can be, given knowledge of the CATE function. In this case, the object of interest is\n\n$$\n\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)=\\sup _{W^{*} \\in \\mathcal{W}\\left(a ; W_{0},\\left\\{\\tau_{0}\\right\\}\\right)} \\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)\n$$\n\nwhere $\\tau_{0}$ is a given CATE function. Since $\\tau_{0}$ is known, the condition $W^{*} \\in \\mathcal{W}\\left(a ; W_{0},\\left\\{\\tau_{0}\\right\\}\\right)$ can be written as\n\n$$\n\\mu\\left(a, \\tau_{0}\\right)=\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]}\n$$\n\nor, equivalently,\n\n$$\n\\mathbb{E}\\left[\\left(\\tau_{0}(X)-\\mu\\left(a, \\tau_{0}\\right)\\right) \\underline{w}^{*}(X) \\mid W_{0}=1\\right]=0\n$$\n\nwhere $\\underline{w}^{*}(X)=\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1, X\\right)$. Equation (4.8) is a linear constraint on the conditional probability of being in subpopulation $W^{*}$. Additionally, the objective function $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)=\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid\\right.$ $W_{0}=1$ ] is linear in $\\underline{w}^{*}$. Thus, the optimization in (4.7) can be cast as a linear program. To see this, consider as an example the case where $W_{0}=1$ almost surely and where $X$ is discrete with finite support, i.e. $\\operatorname{supp}(X)=\\left\\{x_{1}, \\ldots, x_{K}\\right\\}$. Let $f_{k}:=\\mathbb{P}\\left(W^{*}=1, X=x_{k}\\right)$ denote the probability of being in subpopulation $W^{*}$ and having covariate value $x_{k}$. Note that $f_{k} \\in\\left[0, p_{k}\\right]$ where $p_{k}=\\mathbb{P}\\left(X=x_{k}\\right)$.\n\nWe can write the above optimization problem as\n\n$$\n\\max _{\\left(f_{1}, \\ldots, f_{K}\\right) \\geq \\mathbf{0}} \\sum_{k=1}^{K} f_{k} \\quad \\text { such that } f_{k} \\leq p_{k} \\text { for } k \\in\\{1, \\ldots, K\\}\n$$\n\n$$\n\\text { and } \\sum_{k=1}^{K}\\left(\\tau_{0}\\left(x_{k}\\right)-\\mu\\left(a, \\tau_{0}\\right)\\right) f_{k}=0\n$$\n\na finite-dimensional linear program. This program has a feasible solution if $\\tau_{0}\\left(x_{k}\\right)-\\mu\\left(a, \\tau_{0}\\right)$ is not strictly positive or strictly negative for all $k$, meaning that the weighted estimand lies in the convex hull of CATE values, which is precisely stated in the condition for Theorem 3.2. While there exist many methods for solving linear programs, the value function can be obtained through an algorithm that is simple to describe analytically.\n\nLet $\\mathbf{f}=\\left(f_{1}, \\ldots, f_{K}\\right), \\mathbf{p}=\\left(p_{1}, \\ldots, p_{K}\\right)$, and $\\mathbf{t}_{\\mu}=\\left(\\tau_{0}\\left(x_{1}\\right)-\\mu\\left(a, \\tau_{0}\\right), \\ldots, \\tau_{0}\\left(x_{K}\\right)-\\mu\\left(a, \\tau_{0}\\right)\\right)$. Without loss\n\nof generality, assume that $\\tau_{0}\\left(x_{1}\\right)-\\mu\\left(a, \\tau_{0}\\right) \\leq \\tau_{0}\\left(x_{2}\\right)-\\mu\\left(a, \\tau_{0}\\right) \\leq \\cdots \\leq \\tau_{0}\\left(x_{K}\\right)-\\mu\\left(a, \\tau_{0}\\right)$.\n\n1. Set $\\mathbf{f}=\\mathbf{p}$.\n2. If $\\mathbf{t}_{\\mu}^{\\prime} \\mathbf{f}=0$, end the algorithm and report $\\sum_{k=1}^{K} f_{k}$.\n3. If $\\mathbf{t}_{\\mu}^{\\prime} \\mathbf{f} \\neq 0$ :\n(a) If $\\mathbf{t}_{\\mu}^{\\prime} \\mathbf{f}>0$, let $k^{*}=\\max \\left\\{k \\in\\{1, \\ldots, K\\}: f_{k}=p_{k}\\right\\}$ and set $f_{k^{*}}=\\max \\left\\{0, \\frac{-\\sum_{k=1}^{k^{*}-1}\\left(\\tau_{0}\\left(x_{k}\\right)-\\mu\\left(a, \\tau_{0}\\right)\\right) p_{k}}{\\tau_{0}\\left(x_{k^{*}}\\right)-\\mu\\left(a, \\tau_{0}\\right)}\\right\\}$.\n(b) If $\\mathbf{t}_{\\mu}^{\\prime} \\mathbf{f}<0$, let $k^{*}=\\min \\left\\{k \\in\\{1, \\ldots, K\\}: f_{k}=p_{k}\\right\\}$ and set $f_{k^{*}}=\\max \\left\\{0, \\frac{-\\sum_{k=k^{*}+1}^{K}\\left(\\tau_{0}\\left(x_{k}\\right)-\\mu\\left(a, \\tau_{0}\\right)\\right) p_{k}}{\\tau_{0}\\left(x_{k^{*}}\\right)-\\mu\\left(a, \\tau_{0}\\right)}\\right\\}$.\n4. Go to step 2 .\n\nWhen $\\mu\\left(a, \\tau_{0}\\right)$ exceeds $\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]$, this algorithm reduces the weights associated with smallest CATEs until $\\mu\\left(a, \\tau_{0}\\right)$ equals $\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1]$ for some subpopulation. When $\\mu\\left(a, \\tau_{0}\\right)<\\mathbb{E}[Y(1)-$ $Y(0) \\mid W_{0}=1]$, the same procedure is instead applied to the largest CATEs. The support assumption of Theorem 3.2 guarantees that this algorithm ends.\n\nWhen $X$ is not discretely supported, the problem can still be cast as a linear program, but its dimension may be infinite, which generates difficulties in implementation. However, we show this program has an analytical solution for the size of the subpopulation of interest, $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$. The following theorem gives its expression and is valid when vector $X$ has an arbitrary kind of distribution, with continuous, discrete, and mixed components, as is often the case in empirical applications.\n\nTheorem 4.2. Let $\\mu\\left(a, \\tau_{0}\\right)$ be an estimand satisfying equation (1.1). Suppose Assumption 3.1 holds. Let $T_{\\mu}=\\tau_{0}(X)-\\mu\\left(a, \\tau_{0}\\right)$. If $\\mu\\left(a, \\tau_{0}\\right) \\in \\mathcal{S}\\left(\\tau_{0} ; W_{0}\\right)$,\n$\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)$\n$=\\left\\{\\begin{array}{l}\\mathbb{P}\\left(T_{\\mu} \\leq \\alpha^{+} \\mid W_{0}=1\\right)-\\frac{\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha^{+}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+}} \\\\ \\quad \\text { where } \\alpha^{+}=\\inf \\left\\{\\alpha \\in \\mathbb{R}: \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha\\right) \\mid W_{0}=1\\right] \\geq 0\\right\\} \\text { if } \\mu\\left(a, \\tau_{0}\\right)<\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1] \\\\ \\mathbb{P}\\left(T_{\\mu} \\geq \\alpha^{-} \\mid W_{0}=1\\right)-\\frac{\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\geq \\alpha^{-}\\right) \\mid W_{0}=1\\right]}{\\alpha^{-}} \\\\ \\quad \\text { where } \\alpha^{-}=\\sup \\left\\{\\alpha \\in \\mathbb{R}: \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\geq \\alpha\\right) \\mid W_{0}=1\\right] \\leq 0\\right\\} \\text { if } \\mu\\left(a, \\tau_{0}\\right)>\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1] \\\\ 1 \\quad \\text { if } \\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]\\end{array}\\right.$\n\nIf $\\mu\\left(a, \\tau_{0}\\right) \\notin \\mathcal{S}\\left(\\tau_{0} ; W_{0}\\right)$, then $\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)=0$.\nThe computation of these bounds can be done using a linear programming algorithm when $X$ is discrete, or through plug-in estimators of the terms in equation (4.9) regardless of the nature of the support of $X$.\n\nIn this setting, the value $\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)$ is larger when the truncated subpopulations are smaller. In particular, this is the case when there are a few units with extreme values of $\\tau_{0}$ whose removal has a large impact on the estimand, but a small impact on the share of the population.\n\nTheorem 4.2 can also be illustrated visually. In Figure 2, the probability density function of $\\tau_{0}(X)$ is drawn. In this figure, it is assumed that $\\tau_{0}(X)$ is continuously distributed, that $W_{0}=1$ almost surely, and\n\nFigure 2: Characterizing a Representative Subpopulation When $\\tau_{0}$ Is Known\n![img-1.jpeg](img-1.jpeg)\n\nNotes: The figure assumes that $\\tau_{0}(X)$ is continuously distributed, that $W_{0}=1$ almost surely, and that $\\mu<$ $\\mathbb{E}\\left[\\tau_{0}(X)\\right]=$ ATE.\nthat $\\mu<\\mathbb{E}\\left[\\tau_{0}(X)\\right]=$ ATE. The representative subpopulation is obtained by trimming away covariate values that correspond to $\\tau_{0}(X) \\geq \\alpha^{+}$, where $\\alpha^{+}$is determined by the equation $\\mathbb{E}\\left[\\tau_{0}(X) \\mid \\tau_{0}(X) \\leq \\alpha^{+}\\right]=\\mu$. The size of the shaded area is the measure of internal validity.",
      "tables": {},
      "images": {
        "img-1.jpeg": "data:image/jpeg;base64,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"
      }
    },
    {
      "section_id": 18,
      "text": "# 4.3.1 Illustrative Example: A Single Continuous Covariate \n\nTo illustrate the previous theorem, let $X$ be a continuously distributed covariate with support $\\left[x_{L}, x_{U}\\right]$. Let $W_{0}=1$ almost surely, and let $\\mu:=\\mu\\left(a, \\tau_{0}\\right)$ denote the estimand. Also, for simplicity assume that $\\tau_{0}(x)$ is increasing in $x$ and that $\\tau_{0}\\left(x_{L}\\right)<\\mu<\\tau_{0}\\left(x_{U}\\right)$. Without loss of generality, let $\\mathbb{E}[Y(1)-Y(0)] \\geq \\mu$. If $\\mathbb{E}[Y(1)-Y(0)]=\\mu$, then the estimand is perfectly representative of the population since it equals the average treatment effect over it. Now consider the case where $\\mathbb{E}[Y(1)-Y(0)]>\\mu$. In this case, the estimand is larger than the ATE so it is not representative of the entire population.\n\nWe are seeking the largest subpopulation $\\left\\{W^{*}=1\\right\\}$ such that $\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1]=\\mu$. Equivalently, we can seek the smallest subpopulation $\\left\\{W^{-}=1\\right\\}$ such that, when it is removed from the original population, the average treatment effect equals $\\mu$. The subpopulation $\\left\\{W^{-}=1\\right\\}$ is related to $\\left\\{W^{*}=1\\right\\}$ via $W^{-}+W^{*}=$ 1. We will search for $W^{-}$such that $\\mathbb{E}[Y(1)-Y(0) \\mid W^{-}=0]=\\mu$ and $\\mathbb{P}\\left(W^{-}=1\\right)$ is minimized.\n\nSince the ATE exceeds $\\mu$, we must have that $\\mathbb{E}\\left[\\tau_{0}(X) \\mid W^{-}=1\\right]>\\mu$. For a given subpopulation of size $\\mathbb{P}\\left(W^{-}=1\\right)$, removing the subpopulation with the largest values of $\\tau_{0}(x)$ yields the largest decrease in $\\mathbb{E}[Y(1)-Y(0) \\mid W^{-}=0]$. Therefore, $\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)$ is obtained by removing a subpopulation of the kind\n\n$$\nW^{-}(\\alpha)=\\mathbb{1}\\left(\\tau_{0}(X)>\\alpha\\right)\n$$\n\nfor a given threshold $\\alpha$. This subpopulation consists of units whose CATEs exceed $\\alpha$. This threshold is determined by the constraint $\\mathbb{E}\\left[\\tau_{0}(X) \\mid W^{-}(\\alpha)=0\\right]=\\mu$, or\n\n$$\n\\mathbb{E}\\left[\\tau_{0}(X) \\mid \\tau_{0}(X) \\leq \\alpha\\right]=\\mu\n$$\n\nThis constraint states that once units with covariate values satisfying $\\tau_{0}(X)>\\alpha$ are removed, the average treatment effect for the remaining units equals the weighted estimand. Since we assumed $\\tau_{0}$ is increasing, $W^{*}$ corresponds to all units with covariate values below threshold $\\delta=\\tau_{0}^{-1}(\\alpha)$. Therefore,\n\n$$\nW^{*}=\\mathbb{1}\\left(X \\leq \\delta^{+}\\right)\n$$\n\nwhere $\\delta^{+}=\\tau_{0}^{-1}\\left(\\alpha^{+}\\right)$and $\\alpha^{+}$is the unique solution to (4.10). How large $\\mathbb{P}\\left(W^{*}=1\\right)$ is depends on the size of this fraction of removed units. A smaller subpopulation needs to be removed when $\\tau_{0}(X)$ has a long right tail, and a larger subpopulation needs to be removed when the distribution of $\\tau_{0}(X)$ in this right tail is shorter.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 19,
      "text": "# 4.4 Generalizing to Subpopulations \n\nThe results from the previous two sections can be generalized to cases where we hold the average effect for a subset of $W_{0}$ as the object of interest. Let $W^{\\prime}$ be a regular subpopulation of $W_{0}$ and $\\mathbb{E}[Y(1)-Y(0) \\mid W^{\\prime}=1]$ be the target parameter. In analogy with the previous sections, we ask (i) when does there exist a regular subpopulation $W^{*}$ of $W^{\\prime}$ such that $\\mu\\left(a, \\tau_{0}\\right)$ can be written as the average treatment effect over $W^{*}$ and (ii) how representative of $W^{\\prime}$ is this estimand.\n\nFor concreteness, consider the example of Section 2 where $W_{0}=1$. We can let $W^{\\prime}=D$, the treated subpopulation, and have the ATT as the target parameter. This section's results can be used to show that there exists a uniform causal representation of the OLS estimand as an average effect for a subpopulation of the treated units. These results also allow us to compute the internal validity of the OLS estimand for this target subpopulation.\n\nWe first present a result showing conditions for the existence of such population $W^{*}$ in the case where $\\tau_{0}$ is unrestricted, and when $\\tau_{0}$ is fixed. In what follows, we let $\\underline{w}^{\\prime}(X)=\\mathbb{P}\\left(W^{\\prime}=1 \\mid X, W_{0}=1\\right)$.\n\nTheorem 4.3. Let $\\mu\\left(a, \\tau_{0}\\right)$ be an estimand satisfying equation (1.1). Suppose Assumption 3.1 holds and that $W^{\\prime}$ is a regular subpopulation of $W_{0}$.\n\n1. (Uniformly in $\\tau_{0}$ ) Suppose $\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W_{0}=1\\right)\\right)<\\infty .^{3}$ Then, there exists $W^{*} \\in$ $\\mathcal{W}\\left(a ; W^{\\prime}, \\mathcal{T}_{\\text {all }}\\right)$ if and only if $\\mathbb{P}\\left(a(X) \\geq 0 \\mid W^{\\prime}=1\\right)=1$.\n[^0]\n[^0]:    ${ }^{3}$ We use the conventions $0 / 0=1$ and $a / 0=\\infty$ when $a>0$.\n\n2. (Given $\\tau_{0}$ ) There exists $W^{*} \\in \\mathcal{W}\\left(a ; W^{\\prime},\\left\\{\\tau_{0}\\right\\}\\right)$ if and only if $\\mu\\left(a, \\tau_{0}\\right) \\in \\mathcal{S}\\left(\\tau_{0} ; W^{\\prime}\\right)$.\n\nNote that letting $W^{\\prime}=W_{0}$ yields Theorems 3.1 and 3.2 as special cases since $W_{0}$ is a regular subpopulation of itself by definition.\n\nThe condition $\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W_{0}=1\\right)\\right)<\\infty$ rules out uniform causal representations if there are covariate values for which $a(x)$ is strictly positive but are not represented in $W^{\\prime}$, i.e. $\\mathbb{P}\\left(W^{\\prime}=1 \\mid X=\\right.$ $\\left.x, W_{0}=1\\right)=0$ when $a(x)>0$. For example, if $W^{\\prime}$ is a subpopulation of $W_{0}$ defined by a subset of covariate values such that $W^{\\prime}=\\mathbb{1}\\left(X \\in \\mathcal{X}_{0}\\right) \\cdot W_{0}$, then $W^{\\prime}$ is a regular subpopulation but will fail the above inequality if $a(X)>0$ for $X \\in \\operatorname{supp}\\left(X \\mid W_{0}=1\\right) \\backslash \\mathcal{X}_{0}$. In the case where $\\tau_{0}$ is known, the existence of a representative subpopulation of $W^{\\prime}$ is equivalent to the estimand being in the convex hull of $\\operatorname{supp}\\left(\\tau_{0}(X) \\mid W^{\\prime}=1\\right)$.\n\nRegarding the internal validity of a weighted estimand, we generalize Theorems 4.1 and 4.2 and ask how large $\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right)$ can be given that $W^{*}$ is a regular subpopulation of $W^{\\prime}$, which is itself a regular subpopulation of $W_{0}$.\n\nTheorem 4.4. Let $\\mu\\left(a, \\tau_{0}\\right)$ be an estimand satisfying equation (1.1). Suppose Assumption 3.1 holds and that $W^{\\prime}$ is a regular subpopulation of $W_{0}$.\n\n1. (Uniformly in $\\tau_{0}$ ) Suppose $\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W_{0}=1\\right)\\right)<\\infty$. If $\\mathbb{P}\\left(a(X) \\geq 0 \\mid W^{\\prime}=1\\right)=1$, then\n\n$$\n\\bar{P}\\left(a, W^{\\prime} ; \\mathcal{T}_{\\mathrm{all}}\\right)=\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right] \\cdot \\frac{\\mathbb{P}\\left(W_{0}=1\\right)}{\\mathbb{P}\\left(W^{\\prime}=1\\right)} \\cdot \\inf \\left(\\operatorname{supp}\\left(\\frac{\\underline{w}^{\\prime}(X)}{a(X)} \\mid W^{\\prime}=1\\right)\\right)\n$$\n\nIf $\\mathbb{P}\\left(a(X) \\geq 0 \\mid W^{\\prime}=1\\right)<1$, then $\\bar{P}\\left(a, W^{\\prime} ; \\mathcal{T}_{\\text {all }}\\right)=0$.\n2. (Given $\\tau_{0}$ ) If $\\mu\\left(a, \\tau_{0}\\right) \\in \\mathcal{S}\\left(\\tau_{0} ; W^{\\prime}\\right)$, then\n\n$$\n\\begin{aligned}\n& \\bar{P}\\left(a, W^{\\prime} ;\\left\\{\\tau_{0}\\right\\}\\right) \\\\\n& =\\left\\{\\begin{array}{l}\n\\mathbb{P}\\left(T_{\\mu} \\leq \\alpha^{+} \\mid W^{\\prime}=1\\right)-\\frac{\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha^{+}\\right) \\mid W^{\\prime}=1\\right]}{\\alpha^{+}} \\\\\n\\quad \\text { where } \\alpha^{+}=\\inf \\left\\{\\alpha \\in \\mathbb{R}: \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha\\right) \\mid W^{\\prime}=1\\right] \\geq 0\\right\\} \\text { if } \\mu\\left(a, \\tau_{0}\\right)<\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{\\prime}=1\\right] \\\\\n\\mathbb{P}\\left(T_{\\mu} \\geq \\alpha^{-} \\mid W^{\\prime}=1\\right)-\\frac{\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\geq \\alpha^{-}\\right) \\mid W^{\\prime}=1\\right]}{\\alpha^{-}} \\\\\n\\quad \\text { where } \\alpha^{-}=\\sup \\left\\{\\alpha \\in \\mathbb{R}: \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\geq \\alpha\\right) \\mid W^{\\prime}=1\\right] \\leq 0\\right\\} \\text { if } \\mu\\left(a, \\tau_{0}\\right)>\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{\\prime}=1\\right] \\\\\n1 \\quad \\text { if } \\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{\\prime}=1\\right] .\n\\end{array}\\right.\n\\end{aligned}\n$$\n\nIf $\\mu\\left(a, \\tau_{0}\\right) \\notin \\mathcal{S}\\left(\\tau_{0} ; W^{\\prime}\\right)$, then $\\bar{P}\\left(a, W^{\\prime} ;\\left\\{\\tau_{0}\\right\\}\\right)=0$.\nWe can also use this result to obtain bounds on $\\mathbb{P}\\left(W^{*}=1\\right)$ or $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$. This can be done by noting that $W^{*}$ is a subpopulation of both $W^{\\prime}$ and $W_{0}$, so\n$\\mathbb{P}\\left(W^{*}=1\\right)=\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right) \\cdot \\mathbb{P}\\left(W^{\\prime}=1\\right) \\quad$ and $\\quad \\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)=\\frac{\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right) \\cdot \\mathbb{P}\\left(W^{\\prime}=1\\right)}{\\mathbb{P}\\left(W_{0}=1\\right)}$.\nThus, bounds on these probabilities are trivially obtained from the bound on $\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right)$ from Theorem 4.4 and knowledge of $\\left(\\mathbb{P}\\left(W^{\\prime}=1\\right), \\mathbb{P}\\left(W_{0}=1\\right)\\right)$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 20,
      "text": "# 5 Applications to Common Estimands \n\nHere we consider three identification strategies where commonly used estimands follow the structure of equation (1.1). We show how the results in Sections 3 and 4 apply in each of these cases. For simplicity, we assume that $a_{\\max }=\\sup \\left(\\operatorname{supp}\\left(a(X) \\mid W_{0}=1\\right)\\right)=\\sup _{x \\in \\operatorname{supp}(X \\mid W_{0}=1)} a(x)$ for the remainder of the paper. This condition is satisfied when $a(\\cdot)$ is continuous or when $X$ has finite support, for example. We also note that our assumption $a_{\\max }<\\infty$ holds trivially in every case considered below.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 21,
      "text": "### 5.1 Unconfoundedness\n### 5.1.1 Causal Representation and Internal Validity of OLS\n\nIn Section 2, we provided the expression for the coefficient on $D$ in a population regression of $Y$ on $(1, D, X)$ :\n\n$$\n\\beta_{\\mathrm{OLS}}=\\frac{\\mathbb{E}\\left[p(X)(1-p(X)) \\tau_{0}(X)\\right]}{\\mathbb{E}[p(X)(1-p(X))]}\n$$\n\nSuppose the target estimand is the average treatment effect, i.e. $W_{0}=1$ almost surely. By Theorem 3.1, there exists a regular subpopulation $W^{*}$ such that $\\beta_{\\text {OLS }}$ equals the average treatment effect over $W^{*}$ since the weight function $a(X)=p(X)(1-p(X))$ is nonnegative. By Theorem 4.1, the upper bound on the size of subpopulation $W^{*}$ is given by\n\n$$\n\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)=\\frac{\\mathbb{E}[p(X)(1-p(X))]}{\\sup _{x \\in \\operatorname{supp}(X)} p(x)(1-p(x))}\n$$\n\nA corresponding subpopulation $W^{*}$ can be written as\n\n$$\nW^{*}=\\mathbb{1}\\left(U \\leq \\frac{p(X)(1-p(X))}{\\sup _{x \\in \\operatorname{supp}(X)} p(x)(1-p(x))}\\right)\n$$\n\nwhere $U \\sim \\operatorname{Unif}(0,1) \\Perp(Y(1), Y(0), X)$. This is a subpopulation where units which have a larger variation in treatment given their covariate values are more likely to be included. The size of this subpopulation is largest when $\\operatorname{var}(D \\mid X)=p(X)(1-p(X))$ is constant, in which case $\\mathbb{P}\\left(W^{*}=1 \\mid X\\right)=1$. This is the case if and only if $p(X)$ has support equal to $\\{b, 1-b\\}$ for some $b \\in(0,1)$. This is implied by $D \\Perp X$, or random assignment. It can also be achieved if there exists a partition of $\\operatorname{supp}(X)$ where $\\mathbb{P}(D=1 \\mid X)=b$ on one element and $\\mathbb{P}(D=1 \\mid X)=1-b$ on its complement. Whenever $\\operatorname{var}(p(X)(1-p(X)))>0,\\left\\{W^{*}=1\\right\\}$ will be a strict subpopulation.\n\nThe size of this subpopulation is the expectation of $\\operatorname{var}(D \\mid X)$ divided by its maximum value. There are a few ways this expression can be further simplified or bounded. Its numerator is bounded above by $\\operatorname{var}(D)=\\mathbb{P}(D=1) \\cdot \\mathbb{P}(D=0)$, which is particularly simple to estimate. As for the denominator, it is a nonsmooth functional of $p(\\cdot)$. However, if $X$ is continuously distributed, it may be likely that $p(X)$ is continuously distributed and thus that $1 / 2 \\in \\operatorname{supp}(p(X))$. If this is the case, $\\sup _{x \\in \\operatorname{supp}(X)} p(x)(1-p(x))=$ $1 / 4$. Combining these two approximations yields\n\n$$\n\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right) \\leq 4 \\cdot \\mathbb{P}(D=1) \\cdot \\mathbb{P}(D=0)\n$$\n\nwhen the support of $p(X)$ includes $1 / 2$. This bound is trivial when $\\mathbb{P}(D=1)=1 / 2$, but is informative when the unconditional treatment probability is close to 0 or 1 . For example, if $\\mathbb{P}(D=1)=0.1$, the OLS estimand cannot causally represent more than $36 \\%$ of the population. This is consistent with the result in S\u0142oczy\u0144ski (2022) that the OLS estimand is more similar to the ATE when $\\mathbb{P}(D=1)$ is close to $1 / 2$.\n\nWhen $1 / 2 \\in \\operatorname{supp}(p(X))$, we can also compute bounds on the ATE derived from the OLS estimand, bounds on the support of $(Y(1), Y(0))$, and our measure of representativeness $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$. Following the expression in (4.3), bounds on the ATE are given by\n\n$$\n\\left[\\left(\\beta_{\\mathrm{OLS}}-B_{\\ell}\\right) \\cdot 4 \\mathbb{E}[\\operatorname{var}(D \\mid X)]+B_{\\ell},\\left(\\beta_{\\mathrm{OLS}}-B_{u}\\right) \\cdot 4 \\mathbb{E}[\\operatorname{var}(D \\mid X)]+B_{u}\\right]\n$$\n\nEstimating these bounds requires the estimation of one additional quantity beyond the OLS estimand, which is the expectation of $\\operatorname{var}(D \\mid X)$. The width of these bounds depends crucially on $B_{u}-B_{\\ell}$, or the width of the support for unit-level treatment effects.\n\nAlternatively, we can assess the internal validity of $\\beta_{\\text {OLS }}$ with respect to an alternative estimand such as $\\mathbb{E}[Y(1)-Y(0) \\mid D=1]$, the average treatment effect on the treated. In this case, we can write\n\n$$\n\\beta_{\\mathrm{OLS}}=\\frac{\\mathbb{E}\\left[(1-p(X)) w_{0}(X) \\tau_{0}(X)\\right]}{\\mathbb{E}\\left[(1-p(X)) w_{0}(X)\\right]}\n$$\n\nwhere $w_{0}(X)=\\mathbb{P}(D=1 \\mid X)=p(X)$, the propensity score, and $\\tilde{a}(X)=\\mathbb{P}(D=0 \\mid X)=1-p(X)$. Applying Theorem 4.1 yields that\n\n$$\n\\bar{P}\\left(\\tilde{a}, D ; \\mathcal{T}_{\\mathrm{all}}\\right)=\\frac{\\mathbb{E}[1-p(X) \\mid D=1]}{\\sup _{x \\in \\operatorname{supp}(X \\mid D=1)}(1-p(x))}=\\frac{\\mathbb{E}[p(X)(1-p(X))]}{\\mathbb{P}(D=1) \\cdot \\sup _{x \\in \\operatorname{supp}(X \\mid D=1)}(1-p(x))}\n$$\n\nis the largest value that $\\mathbb{P}\\left(W^{*}=1 \\mid D=1\\right)$ can take. Once again, this bound depends only on the propensity score and the distribution of $X$. This bound can also be obtained by using Theorem 4.4 and setting $W_{0}=1$ and $W^{\\prime}=D$. This subpopulation satisfies\n\n$$\n\\mathbb{P}\\left(W^{*}=1 \\mid X, D=1\\right)=\\frac{1-p(X)}{1-\\inf _{x \\in \\operatorname{supp}(X \\mid D=1)} p(X)}\n$$\n\nso units with smaller propensity scores are more likely to be included in $W^{*}$, given that they are treated. $\\bar{P}\\left(\\tilde{a}, D ; \\mathcal{T}_{\\text {all }}\\right)$ is maximized at 1 when $p(X)$ is constant, or if $D \\Perp X$. In this case, $\\mathbb{P}\\left(W^{*}=1 \\mid D=1\\right)=1$ and $\\mathbb{P}\\left(W^{*}=1\\right)=\\mathbb{P}(D=1)$.\n\nIf $p(X)$ takes values close to 0 , this bound equals\n\n$$\n\\bar{P}\\left(\\tilde{a}, D ; \\mathcal{T}_{\\mathrm{all}}\\right)=\\frac{\\mathbb{E}[p(X)(1-p(X))]}{\\mathbb{P}(D=1)} \\leq \\frac{\\mathbb{P}(D=1) \\cdot \\mathbb{P}(D=0)}{\\mathbb{P}(D=1)}=\\mathbb{P}(D=0)\n$$\n\nThis suggests that the OLS estimand is more representative of the ATT when the fraction of untreated units is larger. This again echoes the results in S\u0142oczy\u0144ski (2022) on the relationship between $\\mathbb{P}(D=1)$ and the interpretation of the OLS estimand.\n\nWe can also assess the internal validity of $\\beta_{\\text {OLS }}$ given $\\tau_{0}(X)=\\mathbb{E}[Y(1)-Y(0) \\mid X]$. For simplicity, assume that $\\tau_{0}(X)$ has a continuous distribution and, without loss of generality, assume that $\\mathrm{ATE}>\\beta_{\\mathrm{OLS}}$. Then,\n\nusing Theorem 4.2, we obtain\n\n$$\n\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)=\\mathbb{P}\\left(\\tau_{0}(X) \\leq b^{*}\\right)\n$$\n\nwhere $b^{*}$ satisfies $\\mathbb{E}\\left[\\tau_{0}(X) \\mid \\tau_{0}(X) \\leq b^{*}\\right]=\\beta_{\\text {OLS }}$. The quantity $\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)$ is largest when the least amount of trimming needs to be applied. This is the case when the trimmed values are largest, or when $\\mathbb{E}\\left[\\tau_{0}(X) \\mid \\tau_{0}(X) \\geq b\\right]$ is large when $b$ is near the maximum of $\\operatorname{supp}\\left(\\tau_{0}(X)\\right)$. More concretely, if some covariate values in $\\operatorname{supp}(X)$ have large CATEs, then considering a subpopulation that removes only a small subset of $\\operatorname{supp}(X)$-those corresponding to large CATE values-can allow $\\mathbb{E}\\left[\\tau_{0}(X) \\mid \\tau_{0}(X) \\leq b^{*}\\right]$ and $\\beta_{\\text {OLS }}$ to be equal.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 22,
      "text": "# 5.2 Instrumental Variables\n### 5.2.1 Relevant Results on 2SLS\n\nConsider an endogenous binary treatment $D \\in\\{0,1\\}$ and a binary instrument $Z \\in\\{0,1\\}$. Potential treatments, denoted by $(D(1), D(0))$, are linked to the realized treatment through $Z$, that is, $D=D(Z)$. Potential outcomes, $Y(d, z)$ for $d, z \\in\\{0,1\\}$, may depend on both $D$ and $Z$ in the absence of an exclusion restriction. Let $Y=Y(D, Z)$ be the realized outcome. As before, let $X$ denote covariates. We make the following assumptions.\n\nAssumption 5.1 (Instrument validity). We have\n\n1. Exogeneity: $(Y(0,0), Y(1,0), Y(0,1), Y(1,1), D(1), D(0)) \\Perp Z \\mid X$\n2. Exclusion: $\\mathbb{P}(Y(d, 0)=Y(d, 1))=1$ for $d \\in\\{0,1\\}$;\n3. First stage: $e(X):=\\mathbb{P}(Z=1 \\mid X) \\in(0,1)$ and $\\mathbb{P}(D(1)=1 \\mid X) \\neq \\mathbb{P}(D(0)=1 \\mid X)$ almost surely.\n\nWe also make one of the following two nested monotonicity assumptions.\nAssumption 5.2 (Strong monotonicity). $\\mathbb{P}(D(1) \\geq D(0) \\mid X)=1$ almost surely.\nAssumption 5.3 (Weak monotonicity). There exists a subset of the support of $X$ such that $\\mathbb{P}(D(1) \\geq$ $D(0) \\mid X)=1$ on it and $\\mathbb{P}(D(1) \\leq D(0) \\mid X)=1$ on its complement.\n\nThe first instrumental variables estimand we consider was originally studied by Angrist and Imbens (1995). In addition to Assumptions 5.1 and 5.3, suppose that the model for $X$ is saturated, with $K$ possible combinations of covariate values, i.e. let $\\operatorname{supp}(X)=\\left\\{x_{1}, \\ldots, x_{K}\\right\\}$. Let $X_{S}=\\left(1, \\mathbb{1}\\left(X=x_{1}\\right), \\ldots, \\mathbb{1}\\left(X=x_{K-1}\\right)\\right)$ and $Z_{S}=\\left(Z, Z \\cdot \\mathbb{1}\\left(X=x_{1}\\right), \\ldots, Z \\cdot \\mathbb{1}\\left(X=x_{K-1}\\right)\\right)=Z X_{S}$, where $Z_{S}$ is the constructed instrument vector. The estimand in Angrist and Imbens (1995) is the following 2SLS estimand:\n\n$$\n\\beta_{2 S L S}:=\\left[\\left(\\mathbb{E}\\left[W_{S}^{\\prime} Q_{S}\\right]\\left(\\mathbb{E}\\left[Q_{S}^{\\prime} Q_{S}\\right]\\right)^{-1} \\mathbb{E}\\left[Q_{S}^{\\prime} W_{S}\\right]\\right)^{-1} \\mathbb{E}\\left[W_{S}^{\\prime} Q_{S}\\right]\\left(\\mathbb{E}\\left[Q_{S}^{\\prime} Q_{S}\\right]\\right)^{-1} \\mathbb{E}\\left[Q_{S}^{\\prime} Y\\right]\\right]_{1}\n$$\n\nwhere $W_{S}=\\left(D, X_{S}\\right), Q_{S}=\\left(Z_{S}, X_{S}\\right)$, and $[\\cdot]_{k}$ denotes the $k$ th element of the corresponding vector. This estimand has been studied by Angrist and Imbens (1995), Koles\u00e1r (2013), S\u0142oczy\u0144ski (2020), and Bland-\n\nhol, Bonney, Mogstad, and Torgovitsky (2022), and the specific representation in Proposition 5.1 follows S\u0142oczy\u0144ski (2020).\n\nProposition 5.1. Suppose Assumptions 5.1 and 5.3 hold. Suppose $X$ is discrete with finite support. Then\n\n$$\n\\begin{aligned}\n\\beta_{2 \\mathrm{SLS}} & =\\frac{\\mathbb{E}\\left[e(X)(1-e(X)) \\cdot \\mathbb{P}(D(1) \\neq D(0) \\mid X)^{2} \\cdot \\mathbb{E}[Y(1)-Y(0) \\mid D(1) \\neq D(0), X]\\right]}{\\mathbb{E}\\left[e(X)(1-e(X)) \\cdot \\mathbb{P}(D(1) \\neq D(0) \\mid X)^{2}\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[|\\operatorname{cov}(D, Z \\mid X)| \\cdot \\mathbb{E}[Y(1)-Y(0) \\mid D(1) \\neq D(0), X] \\mid D(1) \\neq D(0)]\\right.}{\\mathbb{E}[|\\operatorname{cov}(D, Z \\mid X)| \\mid D(1) \\neq D(0)]}\n\\end{aligned}\n$$\n\nThis means that we can write $\\beta_{2 \\mathrm{SLS}}$ as\n\n$$\n\\beta_{2 \\mathrm{SLS}}=\\frac{\\mathbb{E}\\left[a(X) w_{0}(X) \\tau_{0}(X)\\right]}{\\mathbb{E}\\left[a(X) w_{0}(X)\\right]}\n$$\n\nwhere $W_{0}=\\mathbb{1}(D(1) \\neq D(0))$ is the population of compliers and defiers, $w_{0}(X)=\\mathbb{P}(D(1) \\neq D(0) \\mid X)$, $\\tau_{0}(X)=\\mathbb{E}[Y(1)-Y(0) \\mid D(1) \\neq D(0), X]$, and $a(X)=e(X)(1-e(X)) \\cdot \\mathbb{P}(D(1) \\neq D(0) \\mid X)=|\\operatorname{cov}(D, Z|$ $X)$ ], a nonnegative weight function. Note that $\\beta_{2 \\mathrm{SLS}}=\\operatorname{LATE}:=\\mathbb{E}[Y(1)-Y(0) \\mid D(1) \\neq D(0)]$ if and only if $a(X)$ is uncorrelated with $\\tau_{0}(X)$ given $D(1) \\neq D(0)$.\n\nThe practical limitation of focusing on $\\beta_{2 \\mathrm{SLS}}$ is that applied researchers rarely create additional instruments by interacting the original instrument with covariates (cf. Blandhol, Bonney, Mogstad, and Torgovitsky, 2022), which is how $Z_{S}$ is constructed to obtain $\\beta_{2 \\mathrm{SLS}}$ above. A more practically relevant estimand is the \"noninteracted\" IV estimand,\n\n$$\n\\beta_{\\mathrm{IV}}:=\\left[\\left(\\mathbb{E}\\left[Q^{\\prime} W\\right]\\right)^{-1} \\mathbb{E}\\left[Q^{\\prime} Y\\right]\\right]_{1}\n$$\n\nwhere $Q=(Z, X)$ and $W=(D, X)$. To introduce one of the representations of $\\beta_{\\mathrm{IV}}$ below, define\n\n$$\nc(X):=\\operatorname{sign}\\left(\\mathbb{P}[D(1) \\geq D(0) \\mid X]-\\mathbb{P}[D(1) \\leq D(0) \\mid X]\\right)\n$$\n\nwhere $\\operatorname{sign}(\\cdot)$ is the sign function. We also make the following \"rich covariates\" assumption on the instrument propensity score, which is implied by the saturated specification in Proposition 5.1.\n\nAssumption 5.4 (Rich covariates). $e(X)$ is linear in $X$.\nUnder the instrument validity assumption, the rich covariates assumption, and either monotonicity assumption, S\u0142oczy\u0144ski (2020) obtains the following representations for the \"noninteracted\" IV estimand.\n\nProposition 5.2. Suppose Assumptions 5.1, 5.3, and 5.4 hold. Then\n\n$$\n\\begin{aligned}\n\\beta_{\\mathrm{IV}} & =\\frac{\\mathbb{E}[c(X) \\cdot e(X)(1-e(X)) \\cdot \\mathbb{P}(D(1) \\neq D(0) \\mid X) \\cdot \\mathbb{E}[Y(1)-Y(0) \\mid D(1) \\neq D(0), X]]}{\\mathbb{E}[c(X) \\cdot e(X)(1-e(X)) \\cdot \\mathbb{P}(D(1) \\neq D(0) \\mid X)]} \\\\\n& =\\frac{\\mathbb{E}[c(X) \\cdot \\operatorname{var}(Z \\mid X) \\cdot \\mathbb{E}[Y(1)-Y(0) \\mid D(1) \\neq D(0), X] \\mid D(1) \\neq D(0)]}{\\mathbb{E}[c(X) \\cdot \\operatorname{var}(Z \\mid X) \\mid D(1) \\neq D(0)]}\n\\end{aligned}\n$$\n\nSuppose Assumptions 5.1, 5.2, and 5.4 hold instead. Then\n\n$$\n\\beta_{\\mathrm{IV}}=\\frac{\\mathbb{E}[e(X)(1-e(X)) \\cdot \\mathbb{P}(D(1)>D(0) \\mid X) \\cdot \\mathbb{E}[Y(1)-Y(0) \\mid D(1)>D(0), X]]}{\\mathbb{E}[e(X)(1-e(X)) \\cdot \\mathbb{P}(D(1)>D(0) \\mid X)]}\n$$\n\n$$\n=\\frac{\\mathbb{E}[\\operatorname{var}(Z \\mid X) \\cdot \\mathbb{E}[Y(1)-Y(0) \\mid D(1)>D(0), X] \\mid D(1)>D(0)]}{\\mathbb{E}[\\operatorname{var}(Z \\mid X) \\mid D(1)>D(0)]}\n$$\n\nIt follows that we can write $\\beta_{\\mathrm{IV}}$ as\n\n$$\n\\beta_{\\mathrm{IV}}=\\frac{\\mathbb{E}\\left[a(X) w_{0}(X) \\tau_{0}(X)\\right]}{\\mathbb{E}\\left[a(X) w_{0}(X)\\right]}\n$$\n\nunder either monotonicity assumption. Under weak monotonicity, $W_{0}=\\mathbb{1}(D(1) \\neq D(0)), w_{0}(X)=$ $\\mathbb{P}(D(1) \\neq D(0) \\mid X), \\tau_{0}(X)=\\mathbb{E}[Y(1)-Y(0) \\mid D(1) \\neq D(0), X]$, and possibly negative weights $a(X)=$ $c(X) \\cdot \\operatorname{var}(Z \\mid X)$. Under strong monotonicity, $W_{0}=\\mathbb{1}(D(1)>D(0)), w_{0}(X)=\\mathbb{P}(D(1)>D(0) \\mid X)$, $\\tau_{0}(X)=\\mathbb{E}[Y(1)-Y(0) \\mid D(1)>D(0), X]$, and nonnegative weights $a(X)=\\operatorname{var}(Z \\mid X) \\geq 0$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 23,
      "text": "# 5.2.2 Causal Representation and Internal Validity of 2SLS \n\nConsider again the setting of Section 5.2.1. The estimand $\\beta_{2 \\text { SLS }}$ can be characterized as $\\mu\\left(a_{2 \\text { SLS }}, \\tau_{0}\\right)$ for $a_{2 \\mathrm{SLS}}(X)=|\\operatorname{cov}(D, Z \\mid X)|, W_{0}=\\mathbb{1}(D(1) \\neq D(0)), w_{0}(X)=\\mathbb{P}(D(1) \\neq D(0) \\mid X)$, and $\\tau_{0}(X)=$ $\\mathbb{E}[Y(1)-Y(0) \\mid D(1) \\neq D(0), X]$.\n\nSince $a_{2 \\mathrm{SLS}}(X) \\geq 0$, there exists a subpopulation of $\\{D(1) \\neq D(0)\\}$ such that $\\beta_{2 \\mathrm{SLS}}$ is an average treatment effect over that subpopulation. The maximum size of that subpopulation is given by\n\n$$\n\\bar{P}\\left(a_{2 \\mathrm{SLS}}, W_{0} ; \\mathcal{T}_{\\mathrm{all}}\\right)=\\frac{\\mathbb{E}\\left[a_{2 \\mathrm{SLS}}(X) \\mid W_{0}=1\\right]}{\\sup _{x \\in \\operatorname{supp}\\left(X \\mid W_{0}=1\\right)} a_{2 \\mathrm{SLS}}(x)}=\\frac{\\mathbb{E}[|\\operatorname{cov}(D, Z \\mid X)| \\mid D(1) \\neq D(0)]}{\\sup _{x \\in \\operatorname{supp}(X \\mid D(1) \\neq D(0))}|\\operatorname{cov}(D, Z \\mid X=x)|}\n$$\n\nThe maximum value of $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ is obtained when $|\\operatorname{cov}(D, Z \\mid X)|$ does not depend on $X$. This occurs, for example, when the instrument and the fraction of units for which $D(1) \\neq D(0)$ are independent of $X$. In this case, we have that $\\beta_{2 \\mathrm{SLS}}=\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]$, the average effect of treatment in the complier and defier subpopulation.\n\nUnder weak monotonicity, the IV estimand has the same $W_{0}$ and $w_{0}(X)$, but has $a_{\\mathrm{IV}}(X)=\\operatorname{sign}(\\mathbb{P}(D(1) \\geq$ $D(0) \\mid X)-\\mathbb{P}(D(1) \\leq D(0) \\mid X)) \\cdot \\operatorname{var}(Z \\mid X)=c(X) \\cdot \\operatorname{var}(Z \\mid X)$ instead. If $\\mathbb{P}(c(X)=-1)>0$, then weights are negative with positive probability and there does not exist a causal representation for the estimand $\\beta_{\\mathrm{IV}}$ that is uniform in $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$. However, there will exist a causal representation given $\\tau_{0}$ if the support condition of Theorem 3.2 holds, i.e. if $\\beta_{\\mathrm{IV}}$ lies in the support of $\\tau_{0}(X)$.\n\nIf we assume strong monotonicity (Assumption 5.2), then $a_{\\mathrm{IV}}(X)=\\operatorname{var}(Z \\mid X) \\geq 0$ and\n\n$$\n\\bar{P}\\left(a_{\\mathrm{IV}}, W_{0} ; \\mathcal{T}_{\\mathrm{all}}\\right)=\\frac{\\mathbb{E}\\left[a_{\\mathrm{IV}}(X) \\mid W_{0}=1\\right]}{\\sup _{x \\in \\operatorname{supp}\\left(X \\mid W_{0}=1\\right)} a_{\\mathrm{IV}}(x)}=\\frac{\\mathbb{E}[\\operatorname{var}(Z \\mid X) \\mid D(1)>D(0)]}{\\sup _{x \\in \\operatorname{supp}(X \\mid D(1)>D(0))} \\operatorname{var}(Z \\mid X=x)}\n$$\n\nHere the internal validity of the IV estimand is maximized when $\\operatorname{var}(Z \\mid X)$ is constant, which occurs when $Z$ is independent of $X$. In this case, $\\beta_{\\mathrm{IV}}$ equals LATE. The quantities $\\bar{P}\\left(a_{\\mathrm{IV}}, W_{0} ; \\mathcal{T}_{\\mathrm{all}}\\right)$ and $\\bar{P}\\left(a_{2 \\mathrm{SLS}}, W_{0} ; \\mathcal{T}_{\\mathrm{all}}\\right)$ are not ranked uniformly in the distributions of $(D(1), D(0), X, Z)$ as there are data-generating processes that make each of these two quantities larger than the other. For example, if $\\operatorname{var}(Z \\mid X)$ is constant but $\\mathbb{P}(D(1) \\neq D(0) \\mid X)$ is not, then $\\bar{P}\\left(a_{2 \\mathrm{SLS}}, W_{0} ; \\mathcal{T}_{\\mathrm{all}}\\right)<\\bar{P}\\left(a_{\\mathrm{IV}}, W_{0} ; \\mathcal{T}_{\\mathrm{all}}\\right)$. This scenario is plausible if $Z$ is randomly assigned and $X$ is a vector of pre-assignment characteristics. This inequality is reversed if $a_{2 \\mathrm{SLS}}(X)=|\\operatorname{cov}(D, Z \\mid X)|$ is constant but $\\mathbb{P}(D(1) \\neq D(0) \\mid X)$ is not. They are equally representative\n\nwhen $\\mathbb{P}(D(1) \\neq D(0) \\mid X)$ is constant. In this case, the estimands are equal, so this is not unexpected.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 24,
      "text": "# 5.3 Difference-in-Differences\n### 5.3.1 Relevant Results on TWFE\n\nNow suppose units are observed for $T$ periods and, for $t \\in\\{1, \\ldots, T\\}$, denote binary treatment by $D_{t} \\in\\{0,1\\}$, potential outcomes $\\left(Y_{t}(1), Y_{t}(0)\\right)$, and realized outcome $Y_{t}=Y_{t}\\left(D_{t}\\right)$. We assume units are untreated prior to period $G \\in\\{2,3, \\ldots, T\\} \\cup\\{+\\infty\\}$, receive the treatment in period $G$, and remain treated thereafter. We assume no units are treated in the first time period. This may include a group that remains untreated throughout, for which $G=+\\infty$. Thus, $D_{t}=\\mathbb{1}(G \\leq t)$. The panel is balanced, that is, no group appears or disappears over time.\n\nThe two-way fixed effects estimand is often used in this setting, and consists of regressing the outcome on the treatment indicator, group indicators, and period indicators. Using partitioned regression results, the coefficient on treatment indicator is\n\n$$\n\\beta_{\\text {TWFE }}:=\\frac{\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[\\hat{D}_{t} Y_{t}\\right]}{\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[\\hat{D}_{t}^{2}\\right]}\n$$\n\nwhere $\\hat{D}_{t}=D_{t}-\\frac{1}{T} \\sum_{s=1}^{T} D_{s}-\\mathbb{E}\\left[D_{t}\\right]+\\frac{1}{T} \\sum_{s=1}^{T} \\mathbb{E}\\left[D_{s}\\right]$.\nWe assume a version of parallel trends most similar to the one in de Chaisemartin and D'Haultf\u0153uille (2020).\n\nAssumption 5.5 (Difference-in-differences). We have\n\n1. $\\operatorname{supp}(G)=\\{2,3, \\ldots, T\\} \\cup\\{+\\infty\\}$\n2. For all $t \\in\\{2, \\ldots, T\\}$ and $g, g^{\\prime} \\in \\operatorname{supp}(G)$, we have that $\\mathbb{E}\\left[Y_{t}(0)-Y_{t-1}(0) \\mid G=g\\right]=\\mathbb{E}\\left[Y_{t}(0)-Y_{t-1}(0) \\mid\\right.$ $\\left.G=g^{\\prime}\\right]$.\n\nWe use a proposition that is essentially a special case of Theorem 1 in de Chaisemartin and D'Haultf\u0153uille (2020) to obtain a representation of the two-way fixed effects estimand as a weighted average.\n\nProposition 5.3. Suppose Assumption 5.5 holds. Then\n\n$$\n\\beta_{\\text {TWFE }}=\\frac{\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[\\left(1-\\frac{1}{T} \\sum_{s=1}^{T} \\mathbb{E}\\left[D_{s} \\mid G\\right]-\\mathbb{E}\\left[D_{t}\\right]+\\frac{1}{T} \\sum_{s=1}^{T} \\mathbb{E}\\left[D_{s}\\right]\\right) \\cdot \\mathbb{P}\\left(D_{t}=1 \\mid G\\right) \\cdot \\mathbb{E}\\left[Y_{t}(1)-Y_{t}(0) \\mid G, D_{t}=1\\right]\\right]}{\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[\\left(1-\\frac{1}{T} \\sum_{s=1}^{T} \\mathbb{E}\\left[D_{s} \\mid G\\right]-\\mathbb{E}\\left[D_{t}\\right]+\\frac{1}{T} \\sum_{s=1}^{T} \\mathbb{E}\\left[D_{s}\\right]\\right) \\cdot \\mathbb{P}\\left(D_{t}=1 \\mid G\\right)\\right]}\n$$\n\nWe show the above representation satisfies equation (1.1) by introducing an auxiliary variable $P$ that is uniformly distributed on $\\{1, \\ldots, T\\}$ independently from $\\left\\{\\left(Y_{t}(0), Y_{t}(1), G\\right)\\right\\}_{t=1}^{T}$. This period variable denotes the time period and we use it to define $\\left(Y(1), Y(0), Y, D\\right):=\\left(Y_{P}(1), Y_{P}(0), Y_{P}, D_{P}\\right)$, which are potential outcomes, the realized outcome, and treatment at random period $P$, respectively.\n\nLetting $X=(G, P)$, this means we can write $\\beta_{\\text {TWFE }}$ as\n\n$$\n\\beta_{\\mathrm{TWFE}}=\\frac{\\mathbb{E}\\left[a(X) w_{0}(X) \\tau_{0}(X)\\right]}{\\mathbb{E}\\left[a(X) w_{0}(X)\\right]}\n$$\n\nwhere $W_{0}=D, w_{0}(X)=\\mathbb{P}(D=1 \\mid G, P)=D \\in\\{0,1\\}, \\tau_{0}(X)=\\mathbb{E}[Y(1)-Y(0) \\mid D=1, G, P]$, and the weight function $a(X)=a_{\\mathrm{TWFE}}(X)=1-\\mathbb{P}(D=1 \\mid G)-\\mathbb{P}(D=1 \\mid P)+\\mathbb{P}(D=1)$ is not generally nonnegative. ${ }^{4}$ A nonnegative weight function can be obtained under the assumption that group-level average treatment effects are constant over time. This property was described in de Chaisemartin and D'Haultfreuille (2020, Appendix 3.1) and Goodman-Bacon (2021, Section 3.1.1), and the resulting representations of the two-way fixed effects estimand are given in their Theorem S2 and equation (16), respectively. The following proposition yields a simple expression for the weights in our setting.\n\nProposition 5.4. Suppose Assumption 5.5 holds and that $\\mathbb{E}\\left[Y_{t}(1)-Y_{t}(0) \\mid D=1, G\\right]=\\mathbb{E}\\left[Y_{s}(1)-Y_{s}(0)\\right]$ $D=1, G]$ for any $s, t \\in\\{1, \\ldots, T\\}$. Then\n\n$$\n\\beta_{\\mathrm{TWFE}}=\\frac{\\mathbb{E}\\left[a_{\\mathrm{TWFE}, \\mathrm{H}}(G) \\cdot \\mathbb{P}(D=1 \\mid G) \\cdot \\mathbb{E}[Y(1)-Y(0) \\mid D=1, G]\\right]}{\\mathbb{E}\\left[a_{\\mathrm{TWFE}, \\mathrm{H}}(G) \\cdot \\mathbb{P}(D=1 \\mid G)\\right]}\n$$\n\nwhere $a_{\\mathrm{TWFE}, \\mathrm{H}}(g)=\\mathbb{P}(D=0 \\mid G=g) \\cdot(\\mathbb{P}(D=0 \\mid P \\geq g)+\\mathbb{P}(D=1 \\mid P<g)) \\geq 0$ for $g \\in\\{2, \\ldots, T\\}$.\nAs is the case of the representation in Proposition 5.3, the two-way fixed effects estimand in Proposition 5.4 satisfies the representation in (1.1), with $X=G, W_{0}=D, w_{0}(X)=\\mathbb{P}(D=1 \\mid G), \\tau_{0}(X)=\\mathbb{E}[Y(1)-Y(0) \\mid$ $D=1, G]$, and the weight function $a(X)=a_{\\mathrm{TWFE}, \\mathrm{H}}(G) \\geq 0$. This weight function is derived in the proof of the proposition, and we show it is equivalent to equation (16) in Goodman-Bacon (2021) in Appendix G.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 25,
      "text": "# 5.3.2 Causal Representation and Internal Validity of TWFE \n\nWe now consider the weights obtained in Proposition 5.4 under its assumptions. These weights are nonnegative and therefore Theorem 3.1 guarantees the existence of a causal representation for $\\beta_{\\text {TWFE }}$ uniformly in $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$. Using Theorem 4.1, the internal validity of $\\beta_{\\text {TWFE }}$ relative to target parameter $\\mathbb{E}[Y(1)-Y(0) \\mid D=1]$ is given by\n\n$$\n\\begin{aligned}\n\\bar{P}\\left(a_{\\mathrm{TWFE}, \\mathrm{H}}, D ; \\mathcal{T}_{\\mathrm{all}}\\right) & =\\frac{\\mathbb{E}\\left[a_{\\mathrm{TWFE}, \\mathrm{H}}(G) w_{0}(G)\\right]}{\\mathbb{E}\\left[w_{0}(G)\\right] \\cdot \\sup _{g \\in \\operatorname{supp}(G \\mid D=1)} a_{\\mathrm{TWFE}, \\mathrm{H}}(g)} \\\\\n& =\\frac{\\sum_{g=2}^{T} \\operatorname{var}(D \\mid G=g) \\cdot(\\mathbb{P}(D=0 \\mid P \\geq g)+\\mathbb{P}(D=1 \\mid P<g)) \\cdot \\mathbb{P}(G=g)}{\\mathbb{P}(D=1) \\cdot \\sup _{g \\in\\{2, \\ldots, T\\}} \\mathbb{P}(D=0 \\mid G=g) \\cdot(\\mathbb{P}(D=0 \\mid P \\geq g)+\\mathbb{P}(D=1 \\mid P<g))}\n\\end{aligned}\n$$\n\nDue to the absorbing nature of the treatment in our setting, all expressions involving the distribution of $D$ given $P$ or $G$ can be derived as a function of the marginal distribution of $G$. Therefore, $\\bar{P}\\left(a_{\\mathrm{TWFE}, \\mathrm{H}}, D ; \\mathcal{T}_{\\mathrm{all}}\\right)$ depends only on $\\{\\mathbb{P}(G=g)\\}_{g \\in\\{2, \\ldots, T\\}}$.\n\nTo give some intuition, consider the case where $T=3$ and therefore $G \\in\\{2,3,+\\infty\\}$. In this case,\n\n[^0]\n[^0]:    ${ }^{4}$ Here, $\\tau_{0}(X)$ is what Callaway and Sant'Anna (2021) call \"the group-time average treatment effect.\"\n\n$\\bar{P}\\left(a_{\\text {TWFE,H }}, D ; \\mathcal{T}_{\\text {all }}\\right)$ will simply be a function of $(\\mathbb{P}(G=2), \\mathbb{P}(G=3))$. Calculations yield that\n\n$$\n\\bar{P}\\left(a_{\\mathrm{TWFE}, \\mathrm{H}}, D ; \\mathcal{T}_{\\mathrm{all}}\\right)= \\begin{cases}\\frac{2 \\mathbb{P}(G=2)+\\omega \\mathbb{P}(G=3)}{2 \\mathbb{P}(G=2)+\\mathbb{P}(G=3)} & \\text { if } \\omega<1 \\\\ \\frac{\\omega^{-1} 2 \\mathbb{P}(G=2)+\\mathbb{P}(G=3)}{2 \\mathbb{P}(G=2)+\\mathbb{P}(G=3)} & \\text { if } \\omega>1 \\\\ 1 & \\text { if } \\omega=1\\end{cases}\n$$\n\nwhere\n\n$$\n\\omega=\\frac{4-2 \\mathbb{P}(G=2)-4 \\mathbb{P}(G=3)}{2-2 \\mathbb{P}(G=2)-\\mathbb{P}(G=3)}=\\frac{a_{\\mathrm{TWFE}, \\mathrm{H}}(2)}{a_{\\mathrm{TWFE}, \\mathrm{H}}(3)}\n$$\n\nTherefore, the TWFE estimand is perfectly representative of the ATT if and only if $\\omega=1$.\nWith some algebra, we can see that $\\omega<1$ if and only if $\\mathbb{P}(G=3)>2 / 3$, while $\\omega>1$ if and only if $\\mathbb{P}(G=3)<2 / 3$. We can also see that $\\bar{P}\\left(a_{\\text {TWFE,H }}, D ; \\mathcal{T}_{\\text {all }}\\right)$ is equal to 1 when $\\mathbb{P}(G=3)=2 / 3$, and that the internal validity of the TWFE estimand declines as $|\\mathbb{P}(G=3)-2 / 3|$ increases. This is due to weight function $a_{\\text {TWFE,H }}(g)$ being constant in $g$ if and only if the fraction of units treated in the third period is $2 / 3$. As before, constant weights imply that the weighted estimand equals the average treatment effect over $\\left\\{W_{0}=1\\right\\}$, which corresponds to the treated subpopulation here.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 26,
      "text": "# 6 Estimation and Inference \n\nWe now consider the estimation and inference for our measures of internal validity and representativeness.\nWe will focus our attention on the case when $\\mathcal{T}=\\mathcal{T}_{\\text {all }}$. Estimation and inference for $\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)$ is related to the question of estimation and inference in linear programs with estimated constraints. See Andrews, Roth, and Pakes (2023), Cox and Shi (2023), Fang, Santos, Shaikh, and Torgovitsky (2023), and Cho and Russell (2024) for recent advances on this topic.\n\nTo measure internal validity, we seek to estimate\n\n$$\n\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\mathrm{all}}\\right)=\\frac{\\mathbb{E}[a(X) \\mid W_{0}=1]}{a_{\\max }}=\\frac{\\mathbb{E}[a(X) w_{0}(X)]}{\\mathbb{E}\\left[w_{0}(X)\\right] \\cdot a_{\\max }}\n$$\n\nSuppose we observe a random sample of size $n,\\left\\{\\left(W_{i}, X_{i}\\right)\\right\\}_{i=1}^{n}$, where $W_{i}$ are a set of variables that allow the estimation of $a(\\cdot)$ and $w_{0}(\\cdot)$. For example, under unconfoundedness we can let $W_{i}=D_{i}$ since the distribution of $(D, X)$ is sufficient to identify $a(\\cdot)$; the outcome's distribution does not affect $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$. In our instrumental variables examples, we let $W_{i}=\\left(D_{i}, Z_{i}\\right)$.\n\nAssuming the existence of estimators for $a(\\cdot)$ and $w_{0}(\\cdot)$, we can propose the following analog estimator for $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$. Start by noting that we can estimate $\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]$ via\n\n$$\n\\frac{\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{a}\\left(X_{i}\\right) \\widehat{w}_{0}\\left(X_{i}\\right)}{\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{w}_{0}\\left(X_{i}\\right)}\n$$\n\nwhich will be consistent under standard conditions on $\\widehat{a}$ and $\\widehat{w}_{0}$. However, estimating $a_{\\max }$, the essential supremum of $a(X)$ given $W_{0}=1$, is more delicate. In some of our examples, this supremum is known or can\n\nbe bounded above without needing the use of data. For example, the OLS estimand under unconfoundedness has weight function $a(X)=p(X)(1-p(X))$ which is naturally bounded above by $1 / 4$. If $X$ is continuously distributed, it is possible that $1 / 4$ lies in the support of $a(X)$, and thus we may side-step the estimation of this term. The IV estimand of Section 5.2 .1 has weights $a_{\\mathrm{IV}}(X)=\\operatorname{var}(Z \\mid X)$ which are also naturally bounded above by $1 / 4$. Similarly, $a_{2 \\mathrm{SLS}}(X)=|\\operatorname{cov}(D, Z \\mid X)| \\leq \\sqrt{\\operatorname{var}(D \\mid X) \\operatorname{var}(Z \\mid X)} \\leq 1 / 4$ using the Cauchy-Schwarz inequality. If knowledge of $a_{\\max }$ is not assumed, but $\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)$ is known and $a(x)$ is continuous ${ }^{5}$, then one could use $\\sup _{x \\in \\operatorname{supp}\\left(X \\mid W_{0}=1\\right)} \\widehat{a}(x)$ as an estimator for $a_{\\max }$. This estimator will be consistent when $\\widehat{a}(x)$ is consistent for $a(x)$ uniformly in $x \\in \\operatorname{supp}\\left(X \\mid W_{0}=1\\right)$. Many parametric and nonparametric estimators for $a(\\cdot)$ can be shown to satisfy this requirement.\n\nIn the case when $\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)$ is not known a priori, one can also estimate it. We focus the rest of this section on one particularly common case, where $X$ is discretely distributed. In this case, $a(x)$ and $w_{0}(x)$ can usually be estimated \"cell-by-cell\" and be $\\sqrt{n}$-consistent with a limiting Gaussian distribution. In this case, we will see that inference on $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$ is generally nonstandard and, as a result, most common bootstrap procedures fail. When $X$ has a continuous component, there are many different estimation approaches and the limiting distribution of estimators of $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$ will vary with the type of estimators (parametric/nonparametric), rate of convergence, type of knowledge assumed for $\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)$, etc.\n\nWe consider the following simple plug-in estimator which does not require knowledge of $\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)$ :\n\n$$\n\\widehat{\\bar{P}}=\\frac{\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{a}\\left(X_{i}\\right) \\widehat{w}_{0}\\left(X_{i}\\right)}{\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{w}_{0}\\left(X_{i}\\right) \\cdot \\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)}\n$$\n\nwhere $c_{n}$ is a tuning parameter that converges to 0 as $n \\rightarrow \\infty$. Note that this tuning parameter is absent when $w_{0}$ is known, such as under unconfoundedness: see Section 2. This estimator does not assume knowledge of the support of $X$ given $W_{0}=1$, but it can also be implemented by taking the maximum over $\\operatorname{supp}(X \\mid$ $\\left.W_{0}=1\\right)$ when it is known.\n\nLet $\\operatorname{supp}(X)=\\left\\{x_{1}, \\ldots, x_{K}\\right\\}$ and denote by $p_{j}=\\mathbb{P}\\left(X=x_{j}\\right)$ the frequency of cell $j$ and let $\\widehat{p}_{j}=$ $\\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{1}\\left(X_{i}=x_{j}\\right)$ denote its sample frequency. Let $\\widehat{\\theta}=\\left(\\widehat{\\mathbf{a}}, \\widehat{\\mathbf{w}}_{0}, \\widehat{\\mathbf{p}}\\right)$ where $\\widehat{\\mathbf{a}}=\\left(\\widehat{a}\\left(x_{1}\\right), \\ldots, \\widehat{a}\\left(x_{K}\\right)\\right), \\widehat{\\mathbf{w}}_{0}=$ $\\left(\\widehat{w}_{0}\\left(x_{1}\\right), \\ldots, \\widehat{w}_{0}\\left(x_{K}\\right)\\right)$, and $\\widehat{\\mathbf{p}}=\\left(\\widehat{p}_{1}, \\ldots, \\widehat{p}_{K}\\right)$. Let $\\theta=\\left(\\mathbf{a}, \\mathbf{w}_{0}, \\mathbf{p}\\right)$ denote their population counterparts.\n\nWe make the following assumptions on the behavior of the preliminary estimators.\nAssumption 6.1 (Preliminary estimators). Let\n\n$$\n\\sqrt{n}(\\widehat{\\theta}-\\theta) \\xrightarrow{d} \\mathbb{Z}\n$$\n\nwhere $\\mathbb{Z}:=\\left(\\mathbb{Z}_{\\mathbf{a}}, \\mathbb{Z}_{\\mathbf{w}_{0}}, \\mathbb{Z}_{X}\\right) \\in \\mathbb{R}^{3 K}$ has a Gaussian distribution.\nThe above assumption is often satisfied when $X$ has finite support since estimators for $a\\left(x_{j}\\right)$ and $w_{0}\\left(x_{j}\\right)$ can be obtained using only the observations for which $X_{i}=x_{j}$. Note that the limiting distribution of $\\mathbb{Z}_{\\mathbf{w}_{0}}$ may be degenerate. For example, if $W_{0}=1$ a.s., then $\\widehat{w}_{0}(x)=w_{0}(x)=1$ for all $x \\in \\operatorname{supp}(X)$ and thus $\\mathbb{Z}_{\\mathbf{w}_{0}}=\\mathbf{0}_{K}$ almost surely, where $\\mathbf{0}_{K}$ is a $K$-vector of zeros.\n\nThe next theorem shows the consistency of $\\widehat{\\bar{P}}$ and establishes the limiting distribution of this estimator. To simplify the exposition, we use $\\bar{P}$ to denote $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$ in what follows.\n\n[^0]\n[^0]:    ${ }^{5}$ Note that $a(x)$ is trivially continuous on finite support.\n\nTheorem 6.1 (Consistency and asymptotic distribution). Suppose Assumption 6.1 holds. Suppose $c_{n}=$ $o(1)$ and $c_{n} \\sqrt{n} \\rightarrow \\infty$ as $n \\rightarrow \\infty$. Suppose $\\bar{P} \\neq 0$. Then, $\\overline{\\bar{P}}$ is consistent for $\\bar{P}$ and\n\n$$\n\\sqrt{n}(\\overline{\\bar{P}}-\\bar{P}) \\xrightarrow{d} \\psi(\\mathbb{Z})\n$$\n\nwhere $\\psi$ is a continuous mapping defined in equation (6.2).\nWe now characterize the mapping $\\psi$. Let $\\mathbb{Z}_{\\mathbf{a}}(j)$ denote the $j$ th element of $\\mathbb{Z}_{\\mathbf{a}}$ and similarly define $\\mathbb{Z}_{\\mathbf{w}_{0}}(j)$ and $\\mathbb{Z}_{X}(j)$ for $j \\in\\{1, \\ldots, K\\}$. Let\n\n$$\n\\begin{aligned}\n\\psi(\\mathbb{Z}) & =\\sum_{j=1}^{K} \\frac{w_{0}\\left(x_{j}\\right) p_{j}}{\\mathbb{P}\\left(W_{0}=1\\right) a_{\\max }} \\mathbb{Z}_{\\mathbf{a}}(j)-\\frac{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}{a_{\\max }^{2}} \\max _{j \\in \\Psi_{X^{+}}} \\mathbb{Z}_{\\mathbf{a}}(j) \\\\\n& +\\sum_{j=1}^{K} \\frac{\\left(a\\left(x_{j}\\right)-\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]\\right) p_{j}}{\\mathbb{P}\\left(W_{0}=1\\right) a_{\\max }} \\mathbb{Z}_{\\mathbf{w}_{0}}(j)+\\sum_{j=1}^{K} \\frac{\\left(a\\left(x_{j}\\right)-\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]\\right) w_{0}\\left(x_{j}\\right)}{\\mathbb{P}\\left(W_{0}=1\\right) a_{\\max }} \\mathbb{Z}_{X}(j)\n\\end{aligned}\n$$\n\nwhere $\\Psi_{X^{+}}=\\left\\{j \\in\\{1, \\ldots, K\\}: a\\left(x_{j}\\right)=a_{\\max }\\right\\}$.\nThe mapping $\\psi$ is linear if and only if $a(x)$ is maximized at a unique value $x \\in \\operatorname{supp}\\left(X \\mid W_{0}=1\\right)$, and nonlinear if multiple values maximize $a(x)$. The linearity of this mapping crucially affects the choice of the inference procedure. When $\\psi$ is linear, the limiting distribution of $\\overline{\\bar{P}}$ is Gaussian and common bootstrap procedures, such as the nonparametric bootstrap, are valid whenever they are valid for $\\overline{\\bar{\\theta}}$.\n\nHowever, when $a(x)$ is maximized at more than one value, the limiting distribution of $\\overline{\\bar{P}}$ is nonlinear in $\\mathbb{Z}$ and non-Gaussian, because it depends on the maximum of two Gaussian variables. In these cases, it can be shown (see Theorem 3.1 in Fang and Santos (2019)) that standard bootstrap approaches are invalid. However, using the fact that the estimand $\\bar{P}$ can be written as a Hadamard directionally differentiable mapping of $\\theta$ implies that alternative bootstrap procedures, such as those proposed by Hong and Li (2018) and Fang and Santos (2019), can be applied to obtain valid inferences on $\\bar{P}$.\n\nWe propose a bootstrap procedure that can be applied regardless of the linearity of $\\psi$. In order to show its validity, we assume that the limiting distribution $\\mathbb{Z}$ can be approximated via a bootstrap procedure.\n\nAssumption 6.2 (Bootstrap for first-step estimators). Let $\\mathbb{Z}^{*}:=\\left(\\mathbb{Z}_{\\mathbf{a}}^{*}, \\mathbb{Z}_{\\mathbf{w}_{0}}^{*}, \\mathbb{Z}_{X}^{*}\\right) \\in \\mathbb{R}^{3 K}$ be a random vector such that $\\mathbb{Z}^{*} \\xrightarrow{d} \\mathbb{Z}$, where $\\xrightarrow{p}$ denotes convergence in probability conditioning on the data used to compute $\\overline{\\bar{\\theta}}$.\n\nThis assumption is easily satisfied when $\\widehat{\\mathbf{p}}$ are sample frequencies, $\\left(\\widehat{\\mathbf{a}}, \\widehat{\\mathbf{w}}_{0}\\right)$ are cell-by-cell estimators that are asymptotically linear and Gaussian, and when $\\mathbb{Z}^{*}$ is the distribution of these estimators under a standard bootstrap approach. For example, under the nonparametric bootstrap we can let $\\mathbb{Z}_{X}^{*}(j)=\\sqrt{n}\\left(\\widehat{p}_{j}^{*}-\\widehat{p}_{j}\\right)$ where $\\widehat{p}_{j}^{*}=\\frac{1}{n} \\sum_{i=1}^{N} \\mathbb{1}\\left(X_{i}^{*}=x_{j}\\right)$, where $\\left(X_{1}^{*}, \\ldots, X_{n}^{*}\\right)$ are drawn from the empirical distribution of $\\left(X_{1}, \\ldots, X_{n}\\right)$.\n\nTheorem 6.2 (Bootstrap validity). Suppose the assumptions of Theorem 6.1 hold and that Assumption 6.2 holds. Then,\n\n$$\n\\widehat{\\psi}\\left(\\mathbb{Z}^{*}\\right) \\xrightarrow{p} \\psi(\\mathbb{Z})\n$$\n\nas $n \\rightarrow \\infty$, where $\\widehat{\\psi}$ is defined in equation (6.3).\n\nWe now characterize the mapping $\\widehat{\\psi}$. Let $\\mathbb{Z}_{\\mathbf{a}}^{*}(j)$ denote the $j$ th element of $\\mathbb{Z}_{\\mathbf{a}}^{*}$ and similarly define $\\mathbb{Z}_{\\mathbf{w}_{0}}^{*}(j)$. Let\n\n$$\n\\begin{aligned}\n\\widehat{\\psi}\\left(\\mathbb{Z}^{*}\\right) & =\\sum_{j=1}^{K} \\frac{\\widehat{w}_{0}\\left(x_{j}\\right) \\widehat{p}_{j}}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right) \\widehat{a}_{\\max }} \\mathbb{Z}_{\\mathbf{a}}^{*}(j)-\\frac{\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]}{\\widehat{a}_{\\max }^{2}} \\max _{j \\in \\widehat{\\Psi}_{\\mathcal{X}^{+}}} \\mathbb{Z}_{\\mathbf{a}}^{*}(j) \\\\\n& +\\sum_{j=1}^{K} \\frac{\\left(\\widehat{a}\\left(x_{j}\\right)-\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]\\right) \\widehat{p}_{j}}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right) \\widehat{a}_{\\max }} \\mathbb{Z}_{\\mathbf{w}_{0}}^{*}(j)+\\sum_{j=1}^{K} \\frac{\\left(\\widehat{a}\\left(x_{j}\\right)-\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]\\right) \\widehat{w}_{0}\\left(x_{j}\\right)}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right) \\widehat{a}_{\\max }} \\mathbb{Z}_{X}^{*}(j)\n\\end{aligned}\n$$\n\nwhere\n\n$$\n\\widehat{\\mathbb{E}}\\left[a(X) \\mid W_{0}=1\\right]=\\frac{\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{a}\\left(X_{i}\\right) \\widehat{w}_{0}\\left(X_{i}\\right)}{\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{w}_{0}\\left(X_{i}\\right)}, \\quad \\widehat{\\mathbb{P}}\\left(W_{0}=1\\right)=\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{w}_{0}\\left(X_{i}\\right), \\quad \\widehat{a}_{\\max }=\\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)\n$$\n\nThe set $\\widehat{\\Psi}_{\\mathcal{X}^{+}}$is defined as all elements $j \\in\\{1, \\ldots, K\\}$ for which $\\widehat{a}\\left(x_{j}\\right)$ is within $\\xi_{n}$ of the maximal value, where $\\xi_{n}$ is a positive sequence satisfying $\\xi_{n}=o(1)$ and $\\xi_{n} \\sqrt{n} \\rightarrow \\infty$ as $n \\rightarrow \\infty$.\n\nFormally,\n\n$$\n\\widehat{\\Psi}_{\\mathcal{X}^{+}}=\\left\\{k \\in\\{1, \\ldots, K\\}: \\widehat{a}\\left(x_{k}\\right) \\geq \\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)-\\xi_{n}\\right\\}\n$$\n\nThe proof of Theorem 6.2 shows that this set consistently estimates $\\Psi_{\\mathcal{X}^{+}}$and thus satisfies the conditions of Theorem 3.2 in Fang and Santos (2019).\n\nThe bootstrap procedure is valid whether the limiting distribution is Gaussian or not. If we assume $a(x)$ is maximized at a single value, standard bootstrap procedures can also be used to approximate the limiting distribution of $\\widehat{P}$.\n\nWe propose the following bootstrap procedure to compute a one-sided $(1-\\alpha)$ confidence interval for $\\bar{P}$.\nAlgorithm 6.1 (One-sided confidence interval for $\\bar{P}$ ). We compute the confidence interval in three steps:\n\n1. Compute $\\widehat{\\theta}$ and $\\widehat{\\widehat{P}}$ using the random sample $\\left\\{\\left(W_{i}, X_{i}\\right)\\right\\}_{i=1}^{n}$;\n2. For bootstrap samples $b=1, \\ldots, B$, compute $\\widehat{\\theta}^{*, b}=\\left(\\widehat{\\mathbf{a}}^{*, b}, \\widehat{\\mathbf{w}}_{0}^{*, b}, \\widehat{\\mathbf{p}}^{*, b}\\right)$ and $\\mathbb{Z}^{*, b}=\\sqrt{n}\\left(\\widehat{\\theta}^{*, b}-\\widehat{\\theta}\\right)$;\n3. Compute $\\widehat{q}_{\\alpha}$, the $\\alpha$ quantile of $\\widehat{\\psi}\\left(\\mathbb{Z}^{*, b}\\right)$, and report the interval $\\left[0, \\widehat{P}-\\widehat{q}_{\\alpha} / \\sqrt{n}\\right]$.\n\nWe can also view these inferential problems through the lens of intersection or union bounds. For example, we can write\n\n$$\n\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\mathrm{all}}\\right)=\\inf _{x \\in \\operatorname{supp}(X \\mid W_{0}=1)} \\frac{\\mathbb{E}\\left[a(X) w_{0}(X)\\right]}{\\mathbb{E}\\left[w_{0}(X)\\right] \\cdot a(x)}:=\\inf _{x \\in \\operatorname{supp}(X \\mid W_{0}=1)} \\bar{P}(x)\n$$\n\nComputing a one-sided confidence interval for $\\bar{P}\\left(a, W_{0} ; \\mathcal{T}_{\\text {all }}\\right)$ of the kind $\\left[0, \\widehat{P}^{+}\\right]$can be cast as doing inference on intersection bounds. Chernozhukov, Lee, and Rosen (2013) offer methods for such problems. Equivalently, the computation of a one-sided confidence interval $\\left[\\widehat{P}^{-}, 1\\right]$ is related to inferential questions in union bounds: see Bei (2024). We leave all details for future work.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 27,
      "text": "# 7 Empirical Application \n\nIn this section, we implement the proposed tools in an application to the effects of unilateral divorce laws in the U.S. on female suicide, as in Stevenson and Wolfers (2006). Between 1969 and 1985, 37 states (including the District of Columbia) reformed their law by enabling each spouse to seek divorce without the other spouse's consent. Stevenson and Wolfers (2006) argue that these \"unilateral\" or \"no-fault\" divorce laws reduced female suicide, domestic violence, and spousal homicide. The results on female suicide are also replicated by Goodman-Bacon (2021), whose analysis we follow here.\n\nOur sample consists of 41 states observed over the 1964-1996 period. The outcome of interest is the state- and year-specific female suicide rate (per million women), as computed by the National Center for Health Statistics (NCHS). The treatment is whether the state allowed unilateral divorce in a given year. Following Goodman-Bacon (2021), our sample omits Alaska and Hawaii. Additionally, we omit Louisiana, Maryland, North Carolina, Oklahoma, Utah, Vermont, Virginia, and West Virginia. These eight states (and Alaska) had unilateral divorce laws preceding 1964 and are therefore always treated within our timeframe.\n\nPanel A of Table 1 reports our baseline estimates of the average effects of unilateral divorce laws on female suicide. After we drop the eight always-treated states, the TWFE estimate, -0.604 , becomes much smaller in absolute value than the corresponding estimate in Goodman-Bacon (2021), -3.080. Unlike that estimate, ours is also statistically insignificant, with $p$-value $=0.819$.\n\nThe conclusion changes, however, when we explicitly target the average treatment effect on the treated\n\nTable 1: Internal Validity of the TWFE Estimand of the Effects of Unilateral Divorce Laws\n\n![table_0](table_0)\n\nC. Internal validity of the TWFE estimand based on Proposition 5.4\n\n![table_1](table_1)\n\nNotes: The dataset is Goodman-Bacon (2021)'s panel of the 1964-1996 U.S. The outcome is the state- and yearspecific female suicide rate (per million women), as computed by the National Center for Health Statistics (NCHS). The treatment is whether the state allowed unilateral divorce in a given year. The sample includes the District of Columbia but excludes Alaska and Hawaii, as in Goodman-Bacon (2021), as well as Louisiana, Maryland, North Carolina, Oklahoma, Utah, Vermont, Virginia, and West Virginia, which had unilateral divorce laws preceding 1964. The measures of internal validity \"uniformly in $\\tau_{0}$ \" are based on Theorem 4.1, while those \"given $\\tau_{0}$ \" are based on Theorem 4.2. The latter measures require an estimate of the CATE function, which we obtain using the approach of Wooldridge (2021).\n\nFigure 3: The Distribution of $\\widehat{\\alpha}_{\\text {TWFE,H }}(g) /\\left(\\sup _{g \\in \\operatorname{supp}(G)} \\widehat{\\alpha}_{\\text {TWFE,H }}(g)\\right)$ Based on Proposition 5.4\n![img-2.jpeg](img-2.jpeg)\n\nNotes: The values of $\\widehat{\\alpha}_{\\text {TWFE,H }}(g)$ are computed as $\\widehat{\\mathbb{P}}(D=0 \\mid G=g) \\cdot(\\widehat{\\mathbb{P}}(D=0 \\mid P \\geq g)+\\widehat{\\mathbb{P}}(D=1 \\mid P<g))$. The largest value is obtained for South Dakota. The \"never-treated\" states (Arkansas, Delaware, Mississippi, New York, and Tennessee) have an imputed value of 0 for $\\widehat{\\alpha}_{\\text {TWFE,H }}(g)$ since they are not part of the treated subpopulation and do not contribute to the TWFE estimand. The \"always-treated\" states (Louisiana, Maryland, North Carolina, Oklahoma, Utah, Vermont, Virginia, and West Virginia) have values of $\\widehat{\\alpha}_{\\text {TWFE,H }}(g)$ displayed as 0 since these states are dropped from our sample.\n(ATT), that is, the average effect for the largest subpopulation for which such an effect is identified under standard assumptions. Using the approach of Wooldridge (2021), we obtain an estimate of -5.530 with a $p$-value of 0.138 . The approach of Callaway and Sant'Anna (2021) produces an estimate of -10.220 and a $p$-value of 0.001 . These estimates are more strongly suggestive of a causal effect of unilateral divorce laws than the TWFE estimate.\n\nWhile the TWFE estimate and the two estimates of the ATT are quite different, this paper focuses on another implication of the nonuniformity of the TWFE weight function. We ask: How representative of the underlying population is the TWFE estimand? What is the internal validity of this estimand if we are interested in the treated subpopulation? Panel B of Table 1 reports our estimates of $\\mathbb{P}\\left(W^{*}=1\\right)$ and $\\mathbb{P}\\left(W^{*}=1 \\mid D=1\\right)=\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$, based on the representation of the TWFE estimand in de Chaisemartin and D'Haultf\u0153uille (2020), revisited in our Proposition 5.3. First, because the weights on some of the group-time average treatment effects are negative, the TWFE estimand does not have a causal interpretation uniformly in $\\tau_{0}, \\widehat{\\mathbb{P}}\\left(W^{*}=1\\right)=\\widehat{\\mathbb{P}}\\left(W^{*}=1 \\mid D=1\\right)=0$. Second, when we estimate the CATE function and use these estimates in constructing the bounds, we conclude that the TWFE estimand corresponds to the average treatment effect for at most $62.16 \\%$ of the treated units or $38.73 \\%$ of the entire population.\n\nPanel C of Table 1 revisits these questions on the basis of the representation of the TWFE estimand in Proposition 5.4. Here, we assume that group-level average treatment effects are constant over time, which eliminates the problem of negative weights. Indeed, we now conclude that the TWFE estimand has a causal\n\ninterpretation uniformly in $\\tau_{0}$, even if it is still not particularly representative of the underlying population or the treated subpopulation. Our estimates of $\\mathbb{P}\\left(W^{*}=1\\right)$ and $\\mathbb{P}\\left(W^{*}=1 \\mid D=1\\right)$ are equal to $14.00 \\%$ and $22.46 \\%$, respectively. When we use the estimated CATE function in constructing the bounds, these estimates increase to $48.02 \\%$ and $77.07 \\%$. This is obviously much more than our initial estimate of 0 , but still substantially less than 1 , guaranteed in the case of $\\mathbb{P}\\left(W^{*}=1 \\mid D=1\\right)$ when using the estimation methods in Callaway and Sant'Anna (2021), Wooldridge (2021), and other recent papers, each of which explicitly targets the ATT.\n\nFigure 3 provides another illustration of the weight function in Proposition 5.4 and the corresponding measures of internal validity. Here, each state across the contiguous U.S. is associated with its value of $\\widehat{a}_{\\text {TWFE,H }}(g) /\\left(\\sup _{g \\in \\operatorname{supp}(G)} \\widehat{a}_{\\text {TWFE,H }}(g)\\right)$. This value is maximized at 1 for South Dakota. Because $\\bar{P}\\left(a_{\\text {TWFE,H }}, D ; \\mathcal{T}_{\\text {all }}\\right)=\\mathbb{E}\\left[a_{\\text {TWFE,H }}(G) \\mid D=1\\right] /\\left(\\sup _{g \\in \\operatorname{supp}(G)} a_{\\text {TWFE,H }}(g)\\right)$, our estimate of this parameter, reported as $22.46 \\%$ in Table 1, can be obtained as a weighted mean of the nonzero values in Figure 3 with weights equal to each state's length of exposure to the treatment.",
      "tables": {
        "table_0": "| A. Estimates of the effects of unilateral divorce laws |  |  |\n| :--: | :--: | :--: |\n| TWFE | ATT |  |\n|  | Callaway and Sant'Anna | Wooldridge |\n| $-0.604$ | $-10.220$ | $-5.530$ |\n| $(2.622)$ | $(3.086)$ | $(3.650)$ |\n| B. Internal validity of the TWFE estimand based on Proposition 5.3 |  |  |\n| $\\widehat{\\mathbb{P}}\\left(W^{*}=1\\right)$ | uniformly in $\\tau_{0}$ | given $\\tau_{0}$ |\n| $\\widehat{\\mathbb{P}}\\left(W^{*}=1 \\mid D=1\\right)$ | 0 | 0.3873 |\n|  | 0 | 0.6216 |",
        "table_1": "|  | uniformly in $\\tau_{0}$ | given $\\tau_{0}$ |\n| :--: | :--: | :--: |\n| $\\widehat{\\mathbb{P}}\\left(W^{*}=1\\right)$ | 0.1400 | 0.4802 |\n| $\\widehat{\\mathbb{P}}\\left(W^{*}=1 \\mid D=1\\right)$ | 0.2246 | 0.7707 |"
      },
      "images": {
        "img-2.jpeg": "data:image/jpeg;base64,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"
      }
    },
    {
      "section_id": 28,
      "text": "# 8 Conclusion \n\nIn this paper, we studied the representativeness and internal validity of a class of weighted estimands, which includes the popular OLS, 2SLS, and TWFE estimands in additive linear models. We examined the conditions under which such estimands can be written as the average treatment effect for some (possibly latent) subpopulation. In our main result, we derived the sharp upper bound on the size of that subpopulation. We consider this bound to be a valuable diagnostic for empirical research. When a given estimand can be shown to correspond to the average treatment effect for a large subset of the population of interest, we say its internal validity is high. In an application to the effects of unilateral divorce laws in the U.S. on female suicide, as in Stevenson and Wolfers (2006) and Goodman-Bacon (2021), we showed that the TWFE estimand has a low degree of internal validity (assuming that the treated subpopulation is of interest), even when we assume away the existence of negative weights. Because this result is then necessarily driven by the nonuniformity of the TWFE weight function, it corroborates the negative view of both negative and nonuniform weights in Callaway, Goodman-Bacon, and Sant'Anna (2024).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 29,
      "text": "# References \n\nAndrews, I., J. Roth, and A. Pakes (2023): \"Inference for Linear Conditional Moment Inequalities,\" Review of Economic Studies, 90(6), 2763-2791.\n\nAngrist, J. D. (1998): \"Estimating the Labor Market Impact of Voluntary Military Service Using Social Security Data on Military Applicants,\" Econometrica, 66(2), 249-288.\n\nAngrist, J. D., and G. W. Imbens (1995): \"Two-Stage Least Squares Estimation of Average Causal Effects in Models with Variable Treatment Intensity,\" Journal of the American Statistical Association, $90(430), 431-442$.\n\nAronow, P. M., and C. Samii (2016): \"Does Regression Produce Representative Estimates of Causal Effects?,\" American Journal of Political Science, 60(1), 250-267.\n\nAthey, S., and G. W. Imbens (2022): \"Design-Based Analysis in Difference-in-Differences Settings with Staggered Adoption,\" Journal of Econometrics, 226(1), 62-79.\n\nBei, X. (2024): \"Inference on Union Bounds with Applications to DiD, RDD, Bunching, and Structural Counterfactuals,\" working paper, Duke University.\n\nBlandhol, C., J. Bonney, M. Mogstad, and A. Torgovitsky (2022): \"When Is TSLS Actually LATE?,\" NBER Working Paper No. 29709.\n\nBoru\u015fyak, K., X. Jaravel, and J. Spiess (2024): \"Revisiting Event-Study Designs: Robust and Efficient Estimation,\" Review of Economic Studies, 91(6), 3253-3285.\n\nCaetano, C., and B. Callaway (2023): \"Difference-in-Differences with Time-Varying Covariates in the Parallel Trends Assumption,\" arXiv preprint arXiv:2202.02903.\n\nCallaway, B., A. Goodman-Bacon, and P. H. C. Sant'Anna (2024): \"Difference-in-Differences with a Continuous Treatment,\" NBER Working Paper No. 32117.\n\nCallaway, B., and P. H. C. Sant'Anna (2021): \"Difference-in-Differences with Multiple Time Periods,\" Journal of Econometrics, 225(2), 200-230.\n\nChen, J. (2024): \"Potential Weights and Implicit Causal Designs in Linear Regression,\" arXiv preprint arXiv:2407.21119.\n\nChernozhukov, V., S. Lee, and A. M. Rosen (2013): \"Intersection Bounds: Estimation and Inference,\" Econometrica, 81(2), 667-737.\n\nCho, J., and T. M. Russell (2024): \"Simple Inference on Functionals of Set-Identified Parameters Defined by Linear Moments,\" Journal of Business $\\mathcal{E}^{2}$ Economic Statistics, 42(2), 563-578.\n\nCox, G., and X. Shi (2023): \"Simple Adaptive Size-Exact Testing for Full-Vector and Subvector Inference in Moment Inequality Models,\" Review of Economic Studies, 90(1), 201-228.\n\nDE Chaisemartin, C. (2012): \"All You Need Is LATE,\" working paper, CREST and Paris School of Economics.\n(2017): \"Tolerating Defiance? Local Average Treatment Effects without Monotonicity,\" Quantitative Economics, 8(2), 367-396.\nde Chaisemartin, C., and X. D'Haultfiduille (2020): \"Two-Way Fixed Effects Estimators with Heterogeneous Treatment Effects,\" American Economic Review, 110(9), 2964-96.\n\nFang, Z., and A. Santos (2019): \"Inference on Directionally Differentiable Functions,\" Review of Economic Studies, 86(1), 377-412.\n\nFang, Z., A. Santos, A. M. Shaikh, and A. Torgovitsky (2023): \"Inference for Large-Scale Linear Systems with Known Coefficients,\" Econometrica, 91(1), 299-327.\n\nGoldsmith-Pinkham, P., P. Hull, and M. Koles\u00e1r (2024): \"Contamination Bias in Linear Regressions,\" American Economic Review, 114(12), 4015-4051.\n\nGoodman-Bacon, A. (2021): \"Difference-in-Differences with Variation in Treatment Timing,\" Journal of Econometrics, 225(2), 254-277.\n\nHirano, K., G. W. Imbens, and G. Ridder (2003): \"Efficient Estimation of Average Treatment Effects Using the Estimated Propensity Score,\" Econometrica, 71(4), 1161-1189.\n\nHong, H., and J. Li (2018): \"The Numerical Delta Method,\" Journal of Econometrics, 206(2), 379-394.\nHumphreys, M. (2009): \"Bounds on Least Squares Estimates of Causal Effects in the Presence of Heterogeneous Assignment Probabilities,\" working paper, Columbia University.\n\nImbens, G. W., and J. D. Angrist (1994): \"Identification and Estimation of Local Average Treatment Effects,\" Econometrica, 62(2), 467-475.\n\nImbens, G. W., and D. B. Rubin (2015): Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction. Cambridge University Press, New York.\n\nKoles\u00c1r, M. (2013): \"Estimation in an Instrumental Variables Model with Treatment Effect Heterogeneity,\" working paper, Princeton University.\n\nLi, F., K. L. Morgan, and A. M. Zaslavsky (2018): \"Balancing Covariates via Propensity Score Weighting,\" Journal of the American Statistical Association, 113(521), 390-400.\n\nMiller, D. L., N. Shenhav, and M. Grosz (2023): \"Selection into Identification in Fixed Effects Models, with Application to Head Start,\" Journal of Human Resources, 58(5), 1523-1566.\n\nMogstad, M., and A. Torgovitsky (2024): \"Instrumental Variables with Unobserved Heterogeneity in Treatment Effects,\" in Handbook of Labor Economics, Vol. 5, ed. by C. Dustmann, and T. Lemieux, pp. 1-114. Elsevier, Amsterdam.\n\nS\u0142oczy\u0144ski, T. (2020): \"When Should We (Not) Interpret Linear IV Estimands as LATE?,\" arXiv preprint arXiv:2011.06695.\n(2022): \"Interpreting OLS Estimands When Treatment Effects Are Heterogeneous: Smaller Groups Get Larger Weights,\" Review of Economics and Statistics, 104(3), 501-509.\n\nStevenson, B., and J. Wolfers (2006): \"Bargaining in the Shadow of the Law: Divorce Laws and Family Distress,\" Quarterly Journal of Economics, 121(1), 267-288.\n\nSun, L., and S. Abraham (2021): \"Estimating Dynamic Treatment Effects in Event Studies with Heterogeneous Treatment Effects,\" Journal of Econometrics, 225(2), 175-199.\nvan 't Hoff, N., A. Lewbel, and G. Mellace (2024): \"Limited Monotonicity and the Combined Compliers LATE,\" working paper, University of Southern Denmark.\n\nWooldridge, J. M. (2021): \"Two-Way Fixed Effects, the Two-Way Mundlak Regression, and Difference-in-Differences Estimators,\" working paper, Michigan State University.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 30,
      "text": "# Appendix \n\nThis appendix is organized as follows: Appendix A establishes the connection between weakly causal estimands and uniform causal representations in $\\mathcal{T}_{\\text {all }}$, Appendix B contains proofs for Section 3, Appendix C contains proofs for Section 4, Appendix D contains proofs for Section 5, Appendix E contains proofs for Section 6, Appendix F contains proofs for Appendix A, and Appendix G contains additional results and derivations regarding difference-in-differences and associated weighted estimands.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 31,
      "text": "## A Connection Between Weakly Causal Estimands and Uniform Causal Representations in $\\mathcal{T}_{\\text {all }}$\n\nWe now establish equivalence between weakly causal estimands as defined in Blandhol, Bonney, Mogstad, and Torgovitsky (2022) (henceforth, BBMT) and estimands that have uniform causal representations as in Theorem 3.1. As in BBMT, consider the case where $X$ has finite support and, as in this paper, assume the treatment is binary. We also abstract from choice groups denoted by $G$ in BBMT.\n\nSince $X$ has finite support, let $\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)=\\left\\{x_{1}, \\ldots, x_{K}\\right\\}$ and let $\\tau:=\\left(\\tau\\left(x_{1}\\right), \\ldots, \\tau\\left(x_{K}\\right)\\right) \\in \\mathbb{R}^{K}$ be the collection of CATEs. For $d \\in\\{0,1\\}$ let $\\nu_{d}(x):=\\mathbb{E}[Y(d) \\mid X=x, W_{0}=1]$ denote the average structural function (ASF) which also conditions on $W_{0}=1$, let $\\nu_{d}:=\\left(\\nu_{d}\\left(x_{1}\\right), \\ldots, \\nu_{d}\\left(x_{K}\\right)\\right) \\in \\mathbb{R}^{K}$, and let $\\mathcal{M} \\subseteq \\mathbb{R}^{2 K}$ be a set of possible ASFs such that $\\left(\\nu_{0}, \\nu_{1}\\right) \\in \\mathcal{M}$. We now state the definition of weakly causal estimands from BBMT (i.e., their Definition WC) in our setting which features binary treatments.\n\nDefinition A.1. The estimand $\\beta$ is weakly causal if the following statements are true for all $\\left(\\nu_{0}, \\nu_{1}\\right) \\in \\mathcal{M}$ :\n\n1. If $\\nu_{1}-\\nu_{0} \\geq \\mathbf{0}_{K},{ }^{6}$ then $\\beta \\geq 0$.\n2. If $\\nu_{1}-\\nu_{0} \\leq \\mathbf{0}_{K}$, then $\\beta \\leq 0$.\n\nThus, an estimand is weakly causal if all CATEs having the same sign implies the estimand also has that sign. Whether an estimand satisfies this condition also depends on $\\mathcal{M}$, the set of allowed ASFs. To compare weak causality to our result on uniform causal representations, we consider $\\mathcal{M}_{\\text {all }}:=\\mathbb{R}^{2 K}$, the unrestricted set of ASFs. The corresponding unrestricted set of CATE functions, which we denoted by $\\mathcal{T}_{\\text {all }}$, allows $\\tau$ to be any vector in $\\mathbb{R}^{K}$. With these choices, we can show these two definitions are equivalent.\n\nProposition A.1. Let $\\mu\\left(a, \\tau_{0}\\right)$ be an estimand satisfying equation (1.1), and let $W_{0}=1$ almost surely. Suppose Assumption 3.1 holds and that $a_{\\max }<\\infty$. Then $\\mu\\left(a, \\tau_{0}\\right)$ is weakly causal with $\\mathcal{M}=\\mathcal{M}_{\\text {all }}$ if and only if it has a causal representation uniformly in $\\mathcal{T}_{\\text {all }}$.\n\nThe proof of this proposition hinges on the equivalence, under some conditions, of weakly causal estimands and estimands with nonnegative weights, as in Proposition 4 of BBMT. Also, as shown in Theorem 3.1, estimands with nonnegative weights have a uniform causal representation in $\\mathcal{T}_{\\text {all }}$. Therefore, a weighted estimand has nonnegative weights if and only if it is weakly causal and if and only if it has a causal representation uniformly in $\\mathcal{T}_{\\text {all }}$. Thus, a weakly causal estimand admits a regular subpopulation $W^{*}$ such that the estimand measures the average effect of treatment over that subpopulation.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 32,
      "text": "## B Proofs for Section 3\n\nProof of Proposition 3.1. We begin by showing the first claim of the proposition. The equation\n\n$$\n\\mathbb{E}\\left[(Y(1)-Y(0)) W^{*} \\mid W_{0}=1, X\\right]=\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1, X] \\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1, X\\right)\n$$\n\n[^0]\n[^0]:    ${ }^{6}$ Vector inequalities hold if they hold component-wise.\n\nholds since $W^{*} \\Perp(Y(1), Y(0)) \\mid X, W_{0}=1$, which holds by Definition 3.1. Since $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1, X\\right)$ is assumed positive, we can divide both sides of equation (B.1) by it and obtain\n\n$$\n\\begin{aligned}\n\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1, X] & =\\frac{\\mathbb{E}\\left[(Y(1)-Y(0)) W^{*} \\mid W_{0}=1, X\\right]}{\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1, X\\right)} \\\\\n& =\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1, W_{0}=1, X] \\\\\n& =\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1, X]\n\\end{aligned}\n$$\n\nwhere the second equality holds by definition, and the third holds from $W^{*}$ being a subpopulation of $W_{0}$.\nWe now show the second claim of the proposition. Equation (3.4) can be obtained as follows:\n\n$$\n\\begin{aligned}\n\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1] & =\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1, W_{0}=1] \\\\\n& =\\frac{\\mathbb{E}\\left[W^{*}(Y(1)-Y(0)) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[W^{*} \\mid W_{0}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\mathbb{E}\\left[W^{*}(Y(1)-Y(0)) \\mid X, W_{0}=1\\right] \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid X, W_{0}=1\\right) \\mid W_{0}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1, X\\right) \\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1, X] \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1, X\\right) \\mid W_{0}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]} \\\\\n& =\\mu\\left(\\underline{w}^{*}, \\tau_{0}\\right)\n\\end{aligned}\n$$\n\nThe first equality follows from $W^{*}$ being a subpopulation of $W_{0}$, the second from the definition of conditional expectation and $\\mathbb{P}\\left(W^{*}=1\\right)>0$, the third from the law of iterated expectations and $W^{*}=1$ implying $W_{0}=1$, the fourth from $W^{*} \\Perp(Y(1), Y(0)) \\mid X, W_{0}=1$, and the fifth and sixth follow immediately.\n\nProof of Lemma 3.1. We verify that $W^{*}$ satisfies the two conditions in Definition 3.1. Condition 1 holds since $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=0\\right)=\\mathbb{P}\\left(W^{*}=1, W^{\\prime}=1 \\mid W_{0}=0\\right) \\leq \\mathbb{P}\\left(W^{\\prime}=1 \\mid W_{0}=0\\right)=0$. The first equality follows from $W^{*} \\leq W^{\\prime}$ almost surely and the second from $W^{\\prime} \\in \\operatorname{SP}\\left(W_{0}\\right)$. To verify condition 2, note that\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(W^{*}=1 \\mid Y(1), Y(0), X, W_{0}=1\\right) & =\\mathbb{P}\\left(W^{*}=1, W^{\\prime}=1 \\mid Y(1), Y(0), X, W_{0}=1\\right) \\\\\n& =\\mathbb{P}\\left(W^{*}=1 \\mid Y(1), Y(0), X, W^{\\prime}=1, W_{0}=1\\right) \\mathbb{P}\\left(W^{\\prime}=1 \\mid Y(1), Y(0), X, W_{0}=1\\right) \\\\\n& =\\mathbb{P}\\left(W^{*}=1 \\mid Y(1), Y(0), X, W^{\\prime}=1\\right) \\mathbb{P}\\left(W^{\\prime}=1 \\mid Y(1), Y(0), X, W_{0}=1\\right) \\\\\n& =\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\mathbb{P}\\left(W^{\\prime}=1 \\mid X, W_{0}=1\\right) \\\\\n& =\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1, W_{0}=1\\right) \\mathbb{P}\\left(W^{\\prime}=1 \\mid X, W_{0}=1\\right) \\\\\n& =\\mathbb{P}\\left(W^{*}=1, W^{\\prime}=1 \\mid X, W_{0}=1\\right) \\\\\n& =\\mathbb{P}\\left(W^{*}=1 \\mid X, W_{0}=1\\right)\n\\end{aligned}\n$$\n\nThe first and seventh line follow from $W^{*} \\leq W^{\\prime}$ almost surely. The second and sixth line follow from factoring conditional probabilities. The third and fifth line follow from $W^{\\prime} \\leq W_{0}$ almost surely. The fourth line follows from $W^{\\prime} \\Perp(Y(1), Y(0)) \\mid X, W_{0}=1$ and $W^{*} \\Perp(Y(1), Y(0)) \\mid X, W^{\\prime}=1$.\n\nProof of Theorem 3.1. This theorem follows as a special case of the first part of Theorem 4.3 when $W^{\\prime}=W_{0}$. This is because $W_{0}$ is trivially a regular subpopulation of $W_{0}$, and because the condition\n\n$$\n\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W_{0}=1\\right)\\right)<\\infty\n$$\n\nis equivalent to $a_{\\max }<\\infty$. This equivalence follows from $\\underline{w}^{\\prime}(X)=\\mathbb{P}\\left(W_{0}=1 \\mid X, W_{0}=1\\right)=1$ almost surely.\n\nProof of Theorem 3.2. This is a special case of the second part of Theorem 4.3 where we set $W^{\\prime}=W_{0}$.\nProof of Proposition 3.2. First, we suppose there exists $W^{*} \\in \\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\text {lin }}\\right)$. Therefore, by Proposition 3.1, we have that $\\mu\\left(a, \\tau_{0}\\right)-\\mu\\left(\\underline{w}^{*}, \\tau_{0}\\right)=0$ for all $\\tau_{0} \\in \\mathcal{T}_{\\text {lin }}$ where $\\underline{w}^{*}(X)=\\mathbb{P}\\left(W^{*}=1 \\mid X, W_{0}=1\\right)$. Therefore,\n\n$$\n\\begin{aligned}\n0 & =\\mu\\left(a, \\tau_{0}\\right)-\\mu\\left(\\underline{w}^{*}, \\tau_{0}\\right) \\\\\n& =\\frac{\\mathbb{E}\\left[a(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}-\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[a(X)\\left(c+d^{\\prime} X\\right) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}-\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X)\\left(c+d^{\\prime} X\\right) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]} \\\\\n& =d^{\\prime}\\left(\\frac{\\mathbb{E}\\left[a(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}-\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]}\\right)\n\\end{aligned}\n$$\n\nfor all $d \\in \\mathbb{R}^{d_{X}}$, which implies that $\\frac{\\mathbb{E}\\left[a(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}=\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]}$. Letting $u(x)=\\underline{w}^{*}(x) / \\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=\\right.$ 1], we have that\n\n$$\n\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]}=\\int_{\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)} x u(x) d F_{X \\mid W_{0}=1}(x)\n$$\n\na convex combination of $x$ values in $\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)$ because $\\int_{\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)} u(x) d F_{X \\mid W_{0}=1}(x)=1$. Therefore, $\\frac{\\mathbb{E}\\left[a(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]} \\in \\operatorname{conv}\\left(\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)\\right)$.\n\nNow suppose that $\\frac{\\mathbb{E}\\left[a(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]} \\in \\operatorname{conv}\\left(\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)\\right)$. Then, we can write $\\frac{\\mathbb{E}\\left[a(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}$ as $\\int_{\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)} x u(x) d F_{X \\mid W_{0}=1}(x)$ for some function $u(x) \\geq 0$ satisfying $\\int_{\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)} u(x) d F_{X \\mid W_{0}=1}(x)=1$. Let\n\n$$\nW^{*}=\\mathbb{1}\\left(U \\leq \\frac{u(X)}{\\sup \\left(\\operatorname{supp}\\left(u(X) \\mid W_{0}=1\\right)\\right)}\\right) \\cdot W_{0}\n$$\n\nwhere $U \\sim \\operatorname{Unif}(0,1) \\Perp(X, Y(1), Y(0), W_{0})$. Then $W^{*}$ is a regular subpopulation of $W_{0}$ and $\\underline{w}^{*}(X)=$ $\\mathbb{P}\\left(W^{*}=1 \\mid X, W_{0}=1\\right)=\\frac{u(X)}{\\sup \\left(\\operatorname{supp}\\left(u(X) \\mid W_{0}=1\\right)\\right)}$ since $\\frac{u(X)}{\\sup \\left(\\operatorname{supp}\\left(u(X) \\mid W_{0}=1\\right)\\right)} \\in[0,1]$ with probability 1 given $W_{0}=1$. Therefore, for all $\\tau_{0}(x)=c+d^{\\prime} x \\in \\mathcal{T}_{\\text {lin }}$, we have that\n\n$$\n\\begin{aligned}\n\\mu\\left(\\underline{w}^{*}, \\tau_{0}\\right) & =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\frac{u(X)}{\\sup \\left(\\operatorname{supp}\\left(u(X) \\mid W_{0}=1)\\right)} \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\frac{u(X)}{\\sup \\left(\\operatorname{supp}(u(X) \\mid W_{0}=1)\\right)} \\mid W_{0}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[u(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[u(X) \\mid W_{0}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[u(X)\\left(c+d^{\\prime} X\\right) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[u(X) \\mid W_{0}=1\\right]} \\\\\n& =c+d^{\\prime} \\frac{\\mathbb{E}\\left[u(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[u(X) \\mid W_{0}=1\\right]} \\\\\n& =c+d^{\\prime} \\frac{\\mathbb{E}\\left[a(X) X \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[a(X)\\left(c+d^{\\prime} X\\right) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]} \\\\\n& =\\mu\\left(a, \\tau_{0}\\right)\n\\end{aligned}\n$$\n\nTherefore, by Proposition 3.1 we have that $W^{*} \\in \\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\text {lin }}\\right)$.\nProof of Proposition 3.3. We consider the $K>0$ case first and the $K=0$ case second.\nCase 1: $K>0$.\nFirst, let $\\mathbb{P}\\left(a(X) \\geq 0 \\mid W_{0}=1\\right)<1$. We will show that $\\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\mathrm{BD}}(K)\\right)=\\emptyset$ by way of contradiction.\nSuppose there is a $W^{*} \\in \\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\mathrm{BD}}(K)\\right)$ and let $\\underline{w}^{*}(X)=\\mathbb{P}\\left(W^{*}=1 \\mid X, W_{0}=1\\right) \\in[0,1]$. Let $\\tau^{*}(x)=K \\cdot \\mathbb{1}(a(x)<0)$. This definition implies $\\tau^{*} \\in \\mathcal{T}_{\\mathrm{BD}}(K)$. Since $W^{*} \\in \\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\mathrm{BD}}(K)\\right)$ we must have that $\\mu\\left(a, \\tau_{0}\\right)=\\mu\\left(\\underline{w}^{*}, \\tau_{0}\\right)$ for all $\\tau_{0} \\in \\mathcal{T}_{\\mathrm{BD}}(K)$. Since $\\tau^{*} \\in \\mathcal{T}_{\\mathrm{BD}}(K)$,\n\n$$\n\\begin{aligned}\n0 & =\\mu\\left(a, \\tau^{*}\\right)-\\mu\\left(\\underline{w}^{*}, \\tau^{*}\\right) \\\\\n& =\\mathbb{E}\\left[\\left(\\frac{a(X)}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}-\\frac{\\underline{w}^{*}(X)}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]}\\right) \\tau^{*}(X) \\mid W_{0}=1\\right] \\\\\n& =K \\cdot \\mathbb{E}\\left[\\left(\\frac{a(X)}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}-\\frac{\\underline{w}^{*}(X)}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]}\\right) \\mathbb{1}(a(X)<0) \\mid W_{0}=1\\right]\n\\end{aligned}\n$$\n\nThe right-hand side of (B.2) is $K$ times the expectation of a nonpositive function. This follows from $a(X) \\mathbb{1}(a(X)<0) \\leq 0, \\underline{w}^{*}(X) \\mathbb{1}(a(X)<0) \\geq 0$ by $\\underline{w}^{*}(X)=\\mathbb{P}\\left(W^{*}=1 \\mid X, W_{0}=1\\right) \\geq 0, \\mathbb{E}\\left[a(X) \\mid W_{0}=\\right.$ 1] $>0$ by Assumption 3.1, and $\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]=\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)>0$ by $W^{*} \\in \\operatorname{SP}\\left(W_{0}\\right)$. Since $K>0$, equation (B.2) implies the nonpositive function must equal 0 with probability 1 given $W_{0}=1$ :\n\n$$\n\\begin{aligned}\n1 & =\\mathbb{P}\\left(\\left(\\frac{a(X)}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}-\\frac{\\underline{w}^{*}(X)}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]}\\right) \\mathbb{1}(a(X)<0)=0 \\mid W_{0}=1\\right) \\\\\n& =\\mathbb{P}\\left(a(X)=\\frac{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]} \\cdot \\underline{w}^{*}(X) \\mid a(X)<0, W_{0}=1\\right)\n\\end{aligned}\n$$\n\nwhere the second equality follows from $\\mathbb{P}(a(X)<0 \\mid W_{0}=1)>0$. This implies $a(X)$ equals a positive multiple of $\\underline{w}^{*}(X)$, a nonnegative quantity, with probability 1 given $\\{a(X)<0, W_{0}=1\\}$, an event with positive probability that implies $a(X)$ is strictly negative. This is a contradiction and therefore $\\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\mathrm{BD}}(K)\\right)=\\emptyset$.\n\nSecond, suppose $\\mathbb{P}\\left(a(X) \\geq 0 \\mid W_{0}=1\\right)=1$. By Theorem 3.1, $\\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\text {all }}\\right) \\neq \\emptyset$. Since $\\mathcal{T}_{\\mathrm{BD}}(K) \\subseteq \\mathcal{T}_{\\text {all }}$, we have that $\\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\text {all }}\\right) \\subseteq \\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\mathrm{BD}}(K)\\right)$. Therefore, $\\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\mathrm{BD}}(K)\\right) \\neq \\emptyset$, which means that $\\mu\\left(a, \\tau_{0}\\right)$ has a causal representation uniformly in $\\tau_{0} \\in \\mathcal{T}_{\\mathrm{BD}}(K)$.\nCase 2: $K=0$.\nWhen $K=0$, the function class $\\mathcal{T}_{\\mathrm{BD}}(K)$ is the set of all constant functions. In this case, $\\tau_{0}(X)=t_{0}$, where $t_{0} \\in \\mathbb{R}$ denotes a constant. Thus $\\mathcal{W}\\left(a ; W_{0}, \\mathcal{T}_{\\mathrm{BD}}(0)\\right) \\neq \\emptyset$ for all weight functions $a(\\cdot)$ since $W_{0} \\in \\operatorname{SP}\\left(W_{0}\\right)$ and because $\\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}\\left[a(X) t_{0} \\mid W_{0}=1\\right] / \\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]=t_{0}=\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]$ for all $a(\\cdot)$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 33,
      "text": "# C Proofs for Section 4 \n\nProof of Theorem 4.1. This is a special case of the first part of Theorem 4.4 where we set $W^{\\prime}=W_{0}$.\nWe begin with a technical lemma that we use to prove the subsequent theorems.\nLemma C.1. Suppose Assumption 3.1 holds. Let $T_{\\mu}=\\tau_{0}(X)-\\mu$. Then, for any $W^{\\prime} \\in \\operatorname{SP}\\left(W_{0}\\right)$, we have that\n\n1. The functions $\\alpha \\mapsto \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha\\right) \\mid W^{\\prime}=1\\right]$ and $\\alpha \\mapsto \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\geq \\alpha\\right) \\mid W^{\\prime}=1\\right]$ are left-continuous.\n2. The functions $\\alpha \\mapsto \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}>\\alpha\\right) \\mid W^{\\prime}=1\\right]$ and $\\alpha \\mapsto \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha\\right) \\mid W^{\\prime}=1\\right]$ are right-continuous.\n\nProof of Lemma C.1. The function $\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha\\right) \\mid W^{\\prime}=1\\right]$ is left-continuous if for any strictly increasing sequence $\\alpha_{n} \\nearrow \\alpha$ we have that $\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha_{n}\\right) \\mid W^{\\prime}=1\\right] \\rightarrow \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha\\right) \\mid W^{\\prime}=1\\right]$. To see this holds, note that $f_{n}(t):=t \\mathbb{1}\\left(t<\\alpha_{n}\\right) \\rightarrow t \\mathbb{1}(t<\\alpha)$ since $t \\mathbb{1}\\left(t<\\alpha_{n}\\right)=0$ for all $t \\geq \\alpha$, and $t \\mathbb{1}\\left(t<\\alpha_{n}\\right)=t$ whenever $t<\\alpha$ for sufficiently large $n$. The random variable $\\left|T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha_{n}\\right)\\right|$ is dominated by $\\left|T_{\\mu}\\right|$ and $\\mathbb{E}\\left[\\left|T_{\\mu}\\right| \\mid W^{\\prime}=1\\right]<\\infty$ by Assumption 3.1 and by $\\mathbb{P}\\left(W^{\\prime}=1\\right)>0$. Therefore, by dominated convergence, $\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha_{n}\\right) \\mid W^{\\prime}=1\\right] \\rightarrow \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha\\right) \\mid W^{\\prime}=1\\right]$ hence $\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha\\right) \\mid W^{\\prime}=1\\right]$ is left-continuous. The function $\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\geq \\alpha\\right) \\mid W^{\\prime}=1\\right]$ is also left-continuous because $\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\geq \\alpha\\right) \\mid W^{\\prime}=1\\right]=\\mathbb{E}\\left[T_{\\mu} \\mid\\right.$ $\\left.W^{\\prime}=1\\right]-\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha\\right) \\mid W^{\\prime}=1\\right]$. The lemma's second claim can be similarly shown by considering a sequence $\\alpha_{n} \\searrow \\alpha$.\n\nProof of Theorem 4.2. To simplify the notation in the proof, let $\\mu:=\\mu\\left(a, \\tau_{0}\\right)$. We break down this proof into four cases.\nCase 1: $\\mu \\in \\mathcal{S}\\left(\\tau_{0} ; W_{0}\\right)$ and $\\mu<\\mathbb{E}\\left[Y(1)-Y(0) \\mid W_{0}=1\\right]$\nWe want to maximize $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ over the subpopulations $W^{*}$ in $\\mathcal{W}\\left(a ; W_{0},\\left\\{\\tau_{0}\\right\\}\\right)$. Recall that $W^{*} \\in$ $\\mathcal{W}\\left(a ; W_{0},\\left\\{\\tau_{0}\\right\\}\\right)$ if $\\mu=\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]}$ and $W^{*} \\in \\operatorname{SP}\\left(W_{0}\\right)$ hold, where $\\underline{w}^{*}(X)=\\mathbb{P}\\left(W^{*}=1 \\mid X, W_{0}=1\\right)$. Therefore,\n\n$$\n\\begin{aligned}\n\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right) & =\\max _{W^{*} \\in \\mathcal{W}\\left(a ; W_{0},\\left\\{\\tau_{0}\\right\\}\\right)} \\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right) \\\\\n& =\\max _{W^{*} \\in\\{0,1\\} \\cdot \\mu=\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right] / \\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right], W^{*} \\in \\operatorname{SP}\\left(W_{0}\\right)} \\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right) \\\\\n& \\leq \\max _{W^{*} \\in\\{0,1\\} \\cdot \\mu=\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right] / \\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]} \\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid X, W_{0}=1\\right) \\mid W_{0}=1\\right] \\\\\n& =\\max _{\\underline{w}^{*} \\cdot \\mu=\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right] / \\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right], \\underline{w}^{*}(X) \\in[0,1]} \\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right] .\n\\end{aligned}\n$$\n\nWe will first show a closed-form expression for an upper bound for $\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)$. Then, we will show that this upper bound can be attained by a corresponding $W^{+} \\in \\mathcal{W}\\left(a ; W_{0},\\left\\{\\tau_{0}\\right\\}\\right)$, and therefore it equals $\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)$.\n\nBefore proceeding, let $\\alpha^{+}=\\inf \\{\\alpha \\in \\mathbb{R}: R(\\alpha) \\geq 0\\}$ where $R(\\alpha)=\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha\\right) \\mid W_{0}=1\\right]$. By construction, $\\alpha^{+} \\geq 0$. By $\\mu<\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]$ we also have that $\\alpha^{+}<+\\infty$. By Lemma C.1, $R$ is a right-continuous function, and therefore $R\\left(\\alpha^{+}\\right)=\\lim _{\\alpha \\searrow \\alpha^{+}} R(\\alpha) \\geq 0$. We now claim that $\\alpha^{+}>0$. To show this claim, assume $\\alpha^{+}=0$. Then, $0 \\leq R\\left(\\alpha^{+}\\right)=R(0)=\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq 0\\right) \\mid W_{0}=1\\right] \\leq 0$, which implies $\\mathbb{P}\\left(\\tau_{0}(X)=\\mu \\mid W_{0}=1\\right)=1$. This is ruled out by the assumption that $\\mu>\\mathbb{E}[Y(1)-Y(0) \\mid W_{0}=1]=$ $\\mathbb{E}\\left[\\tau_{0}(X) \\mid W_{0}=1\\right]$. Therefore, $\\alpha^{+}>0$.\n\nWe now show an upper bound for $\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)$. For all $\\underline{w}^{*}$ such that $\\mu=\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=\\right.$ 1] $/ \\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]$ and $\\underline{w}^{*}(X) \\in[0,1]$, we have that\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right] & =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\alpha^{+} \\mid W_{0}=1\\right]}{\\alpha^{+}} \\\\\n& =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X)\\left(\\alpha^{+}-T_{\\mu}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+}}+\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) T_{\\mu} \\mid W_{0}=1\\right]}{\\alpha^{+}} \\\\\n& =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X)\\left(\\alpha^{+}-T_{\\mu}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+}} \\\\\n& =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X)\\left(\\alpha^{+}-T_{\\mu}\\right) \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha^{+}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+}}+\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X)\\left(\\alpha^{+}-T_{\\mu}\\right) \\mathbb{1}\\left(T_{\\mu}>\\alpha^{+}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+}} \\\\\n& \\leq \\frac{\\mathbb{E}\\left[1 \\cdot\\left(\\alpha^{+}-T_{\\mu}\\right) \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha^{+}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+}}+\\frac{\\mathbb{E}\\left[0 \\cdot\\left(\\alpha^{+}-T_{\\mu}\\right) \\mathbb{1}\\left(T_{\\mu}>\\alpha^{+}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+}} \\\\\n& =\\mathbb{E}\\left[\\mathbb{1}\\left(T_{\\mu} \\leq \\alpha^{+}\\right) \\mid W_{0}=1\\right]-\\frac{\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha^{+}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+}} \\\\\n& :=P^{+}\n\\end{aligned}\n$$\n\nThe third equality follows from $\\mu=\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right] / \\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]$. The inequality follows from $\\{0,1\\}$ being lower/upper bounds for $\\underline{w}^{*}(X)$.\n\nTherefore, $\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right) \\leq P^{+}$. We now show that this inequality is binding by finding $W^{+} \\in$ $\\mathcal{W}\\left(a ; W_{0},\\left\\{\\tau_{0}\\right\\}\\right)$ such that $\\mathbb{P}\\left(W^{+}=1 \\mid W_{0}=1\\right)=P^{+}$.\n\nLet\n\n$$\n\\underline{w}^{+}(X)= \\begin{cases}1 & \\text { if } T_{\\mu}<\\alpha^{+} \\\\ 1-\\frac{R\\left(\\alpha^{+}\\right) \\mathbb{1}\\left(\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right) \\neq 0\\right)}{\\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)} & \\text { if } T_{\\mu}=\\alpha^{+} \\\\ 0 & \\text { if } T_{\\mu}>\\alpha^{+}\\end{cases}\n$$\n\nThis function is bounded above by 1 because $R\\left(\\alpha^{+}\\right) \\geq 0$ and $\\alpha^{+}>0$. To show $\\underline{w}^{+}$is bounded below by 0 , consider cases where $\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)$ or $R\\left(\\alpha^{+}\\right)$equal and differ from 0 . If $\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)=0$ or $R\\left(\\alpha^{+}\\right)=0$, then $\\underline{w}^{+}(X) \\in\\{0,1\\} \\subseteq[0,1]$ and it is therefore bounded below by 0 . If $\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)>0$ and $R\\left(\\alpha^{+}\\right)>0$, then\n\n$$\n\\begin{aligned}\n1-\\frac{R\\left(\\alpha^{+}\\right)}{\\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)} & =\\frac{\\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)-\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha^{+}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)} \\\\\n& =\\frac{\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}=\\alpha^{+}\\right) \\mid W_{0}=1\\right]-\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha^{+}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)} \\\\\n& =\\frac{-\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha^{+}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)}\n\\end{aligned}\n$$\n\nBy the definition of $\\alpha^{+}$as an infimum, we must have that $R\\left(\\alpha^{+}-\\varepsilon\\right)<0$ for all $\\varepsilon>0$, implying that $R(\\alpha)$ is discontinuous at $\\alpha^{+}$. By Lemma C.1, $\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha\\right) \\mid W_{0}=1\\right]$ is left-continuous and satisfies $\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha\\right) \\mid W_{0}=1\\right] \\leq R(\\alpha)$. Therefore, since $R\\left(\\alpha^{+}-\\varepsilon\\right)<0$ for all $\\varepsilon>0$, we must have that $\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha^{+}-\\varepsilon\\right) \\mid W_{0}=1\\right]<0$ for all $\\varepsilon>0$. Letting $\\varepsilon \\searrow 0$ yields that $\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha^{+}\\right) \\mid W_{0}=1\\right] \\leq 0$. Therefore $-\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha^{+}\\right) \\mid W_{0}=1\\right] /\\left(\\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)\\right) \\geq 0$ and $\\underline{w}^{+}(X) \\geq 0$ in that case as well.\n\nNext, we compute\n\n$$\n\\begin{aligned}\n\\mathbb{E}[\\underline{w}^{+}(X) \\mid W_{0}=1]= & \\mathbb{E}\\left[\\mathbb{1}\\left(T_{\\mu}<\\alpha^{+}\\right) \\mid W_{0}=1\\right] \\\\\n& +\\left(1-\\frac{R\\left(\\alpha^{+}\\right) \\mathbb{1}\\left(\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right) \\neq 0\\right)}{\\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)}\\right) \\mathbb{E}\\left[\\mathbb{1}\\left(T_{\\mu}=\\alpha^{+}\\right) \\mid W_{0}=1\\right] \\\\\n= & \\mathbb{E}\\left[\\mathbb{1}\\left(T_{\\mu}<\\alpha^{+}\\right) \\mid W_{0}=1\\right]+\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right) \\\\\n& -\\frac{\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha^{+}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+}} \\mathbb{1}\\left(\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right) \\neq 0\\right) \\\\\n= & \\mathbb{P}\\left(T_{\\mu} \\leq \\alpha^{+} \\mid W_{0}=1\\right)-\\frac{\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha^{+}\\right) \\mid W_{0}=1\\right]}{\\alpha^{+}} \\\\\n= & P^{+}\n\\end{aligned}\n$$\n\nThe indicator function disappears in the third equality because $\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)=0$ implies $\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq\\right.\\right.$ $\\left.\\alpha^{+}\\right) \\mid W_{0}=1]=0$ as shown above.\n\nFinally we verify that $\\frac{\\mathbb{E}\\left[\\underline{w}^{+}(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{+}(X) \\mid W_{0}=1\\right]}=\\mu$. This condition is equivalent to $\\mathbb{E}\\left[\\underline{w}^{+}(X) T_{\\mu} \\mid W_{0}=1\\right]=0$, which we verify here:\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[\\underline{w}^{+}(X) T_{\\mu} \\mid W_{0}=1\\right]= & \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu}<\\alpha^{+}\\right) \\mid W_{0}=1\\right] \\\\\n& +\\left(1-\\frac{R\\left(\\alpha^{+}\\right) \\mathbb{1}\\left(\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right) \\neq 0\\right)}{\\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)}\\right) \\mathbb{E}\\left[T_{\\mu} 1\\left(T_{\\mu}=\\alpha^{+}\\right) \\mid W_{0}=1\\right] \\\\\n= & \\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\leq \\alpha^{+}\\right) \\mid W_{0}=1\\right]-\\frac{R\\left(\\alpha^{+}\\right) \\mathbb{1}\\left(\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right) \\neq 0\\right)}{\\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)} \\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n& =R\\left(\\alpha^{+}\\right)-R\\left(\\alpha^{+}\\right) \\mathbb{1}\\left(\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right) \\neq 0\\right) \\\\\n& =R\\left(\\alpha^{+}\\right) \\mathbb{1}\\left(\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)=0\\right)\n\\end{aligned}\n$$\n\nTherefore, $\\mathbb{E}\\left[\\underline{w}^{+}(X) T_{\\mu} \\mid W_{0}=1\\right]$ equals 0 when $R\\left(\\alpha^{+}\\right)=0$. When $R\\left(\\alpha^{+}\\right)>0$, we have that $\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid\\right.$ $W_{0}=1)>0$ as shown earlier. So $\\mathbb{E}\\left[\\underline{w}^{+}(X) T_{\\mu} \\mid W_{0}=1\\right]$ is also equal to 0 in this case.\n\nWe conclude the proof by showing that $\\underline{w}^{+}(X)$ corresponds to $\\mathbb{P}\\left(W^{+}=1 \\mid X, W_{0}=1\\right)$ for some $W^{+} \\in \\operatorname{SP}\\left(W_{0}\\right)$. Let $U \\sim \\operatorname{Unif}(0,1)$ satisfy $U \\Perp\\left(Y(1), Y(0), X, W_{0}\\right)$ and define\n\n$$\nW^{+}=\\left(\\mathbb{1}\\left(T_{\\mu}<\\alpha^{+}\\right)+\\mathbb{1}\\left(T_{\\mu}=\\alpha^{+}, U \\leq 1-\\frac{R\\left(\\alpha^{+}\\right) \\mathbb{1}\\left(\\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right) \\neq 0\\right)}{\\alpha^{+} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{+} \\mid W_{0}=1\\right)}\\right)\\right) \\cdot W_{0}\n$$\n\nBy construction, $W^{+} \\in\\{0,1\\}, \\mathbb{P}\\left(W^{+}=1 \\mid X, W_{0}=1\\right)=\\underline{w}^{+}(X), \\mathbb{P}\\left(W^{+}=1 \\mid W_{0}=0\\right)=0$, and $W^{+} \\Perp\\left(Y(1), Y(0)\\right) \\mid X, W_{0}=1$. Also, since $\\mu \\in \\mathcal{S}\\left(\\tau_{0} ; W_{0}\\right), \\mathbb{P}\\left(T_{\\mu} \\leq 0 \\mid W_{0}=1\\right)=\\mathbb{P}\\left(\\tau_{0}(X) \\leq \\mu \\mid W_{0}=\\right.$ $1)>0$. Since $\\alpha^{+}>0$ we have that $\\mathbb{P}\\left(W^{+}=1 \\mid W_{0}=1\\right) \\geq \\mathbb{P}\\left(T_{\\mu}<\\alpha^{+} \\mid W_{0}=1\\right) \\geq \\mathbb{P}\\left(T_{\\mu} \\leq 0 \\mid W_{0}=1\\right)>0$. Therefore $W^{+}$is a regular subpopulation of $W_{0}$ for which $\\mathbb{P}\\left(W^{+}=1 \\mid W_{0}=1\\right)=P^{+}$, hence $P^{+}$is the maximum.\nCase 2: $\\mu \\in \\mathcal{S}\\left(\\tau_{0} ; W_{0}\\right)$ and $\\mu>\\mathbb{E}\\left[Y(1)-Y(0) \\mid W_{0}=1\\right]$\nAs in case 1,\n\n$$\n\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right) \\leq \\max _{\\underline{w}^{*} \\cdot \\mu=\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=1\\right] / \\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right], \\underline{w}^{*}(X) \\in[0,1]} \\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]\n$$\n\nBefore proceeding, let $\\alpha^{-}=\\sup \\{\\alpha \\in \\mathbb{R}: L(\\alpha) \\leq 0\\}$ where $L(\\alpha)=\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\geq \\alpha\\right) \\mid W_{0}=1\\right]$. By construction, $\\alpha^{-} \\leq 0$ and by $\\mu>\\mathbb{E}\\left[Y(1)-Y(0) \\mid W_{0}=1\\right]$ we have that $\\alpha^{-}>-\\infty$. By Lemma C.1, $L$ is a left-continuous function, and therefore $L\\left(\\alpha^{-}\\right)=\\lim _{\\alpha, \\nearrow \\alpha^{-}} L(\\alpha) \\leq 0$. Similarly to case 1 , we can show that $\\alpha^{-}<0$.\n\nWe now show an upper bound for $\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right)$. For all $\\underline{w}^{*}$ such that $\\mu=\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W_{0}=\\right.$ $1] / \\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right]$ and $\\underline{w}^{*}(X) \\in[0,1]$, we have that\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W_{0}=1\\right] & =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\alpha^{-} \\mid W_{0}=1\\right]}{\\alpha^{-}} \\\\\n& =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X)\\left(\\alpha^{-}-T_{\\mu}\\right) \\mid W_{0}=1\\right]}{\\alpha^{-}}+\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) T_{\\mu} \\mid W_{0}=1\\right]}{\\alpha^{-}} \\\\\n& =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X)\\left(\\alpha^{-}-T_{\\mu}\\right) \\mid W_{0}=1\\right]}{\\alpha^{-}} \\\\\n& =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X)\\left(\\alpha^{-}-T_{\\mu}\\right) \\mathbb{1}\\left(T_{\\mu} \\geq \\alpha^{-}\\right) \\mid W_{0}=1\\right]}{\\alpha^{-}}+\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X)\\left(\\alpha^{-}-T_{\\mu}\\right) \\mathbb{1}\\left(T_{\\mu}<\\alpha^{-}\\right) \\mid W_{0}=1\\right]}{\\alpha^{-}} \\\\\n& \\leq \\frac{\\mathbb{E}\\left[1 \\cdot\\left(\\alpha^{-}-T_{\\mu}\\right) \\mathbb{1}\\left(T_{\\mu} \\geq \\alpha^{-}\\right) \\mid W_{0}=1\\right]}{\\alpha^{-}}+\\frac{\\mathbb{E}\\left[0 \\cdot\\left(\\alpha^{-}-T_{\\mu}\\right) \\mathbb{1}\\left(T_{\\mu}<\\alpha^{-}\\right) \\mid W_{0}=1\\right]}{\\alpha^{-}} \\\\\n& =\\mathbb{E}\\left[\\mathbb{1}\\left(T_{\\mu} \\geq \\alpha^{-}\\right) \\mid W_{0}=1\\right]-\\frac{\\mathbb{E}\\left[T_{\\mu} \\mathbb{1}\\left(T_{\\mu} \\geq \\alpha^{-}\\right) \\mid W_{0}=1\\right]}{\\alpha^{-}} \\\\\n& :=P^{-}\n\\end{aligned}\n$$\n\nwhich follows a similar argument as above. This implies $\\bar{P}\\left(a, W_{0} ;\\left\\{\\tau_{0}\\right\\}\\right) \\leq P^{-}$. We now show that this inequality is an equality by finding $W^{-} \\in \\mathcal{W}\\left(a ; W_{0},\\left\\{\\tau_{0}\\right\\}\\right)$ such that $\\mathbb{P}\\left(W^{-}=1 \\mid W_{0}=1\\right)=P^{-}$.\n\nLet\n\n$$\n\\underline{w}^{-}(X)= \\begin{cases}1 & \\text { if } T_{\\mu}>\\alpha^{-} \\\\ 1-\\frac{L\\left(\\alpha^{-}\\right) \\mathbb{1}\\left(\\mathbb{P}\\left(T_{\\mu}=\\alpha^{-} \\mid W_{0}=1\\right) \\neq 0\\right)}{\\alpha^{-} \\mathbb{P}\\left(T_{\\mu}=\\alpha^{-} \\mid W_{0}=1\\right)} & \\text { if } T_{\\mu}=\\alpha^{-} \\\\ 0 & \\text { if } T_{\\mu}<\\alpha^{-}\\end{cases}\n$$\n\nThe rest of the proof symmetrically follows the one for the previous case.\nCase 3: $\\mu \\in \\mathcal{S}\\left(\\tau_{0} ; W_{0}\\right)$ and $\\mu=\\mathbb{E}\\left[Y(1)-Y(0) \\mid W_{0}=1\\right]$\nNote that $W^{*}=W_{0}$ is the largest regular subpopulation of $W_{0}$. Since $\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1]=$ $\\mathbb{E}\\left[Y(1)-Y(0) \\mid W_{0}=1\\right]$, we have that $\\mathbb{P}\\left(W^{*}=1 \\mid W_{0}=1\\right)$ is trivially maximized at 1 .\n\nCase 4: $\\mu \\notin \\mathcal{S}\\left(\\tau_{0} ; W_{0}\\right)$\nBy Theorem 3.2, there does not exist a regular subpopulation $W^{*}$ satisfying $\\mu=\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=1\\right]$ and therefore the supremum equals 0 by its definition.\n\nProof of Theorem 4.3.\nPart 1: $\\mathcal{T}=\\mathcal{T}_{\\text {all }}$\n$(\\Longrightarrow)$ First, suppose there exists $W^{*} \\in \\mathcal{W}\\left(a ; W^{\\prime}, \\mathcal{T}_{\\text {all }}\\right)$. Using the law of iterated expectations and letting $\\underline{w}^{\\prime}(X)=\\mathbb{P}\\left(W^{\\prime}=1 \\mid W_{0}=1, X\\right)$, we can write\n\n$$\n\\begin{aligned}\n\\mu\\left(a, \\tau_{0}\\right) & =\\frac{\\mathbb{E}\\left[a(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\tau_{0}(X) \\underline{w}^{\\prime}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\underline{w}^{\\prime}(X) \\mid W_{0}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\tau_{0}(X) W^{\\prime} \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} W^{\\prime} \\mid W_{0}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\tau_{0}(X) \\mid W^{\\prime}=1, W_{0}=1\\right] \\mathbb{P}\\left(W^{\\prime}=1 \\mid W_{0}=1\\right)}{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\mid W^{\\prime}=1, W_{0}=1\\right] \\mathbb{P}\\left(W^{\\prime}=1 \\mid W_{0}=1\\right)} \\\\\n& =\\frac{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\mathbb{E}\\left[Y(1)-Y(0) \\mid W_{0}=1, X\\right] \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\mid W^{\\prime}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{\\prime}=1, X\\right] \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\mid W^{\\prime}=1\\right]} \\\\\n& :=\\mu^{\\prime}\\left(\\frac{a}{\\underline{w}^{\\prime}}, \\tau_{0}\\right)\n\\end{aligned}\n$$\n\nThe second equality is valid due to $\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W_{0}=1\\right)\\right)<\\infty$. The third and fourth follow from the law of iterated expectations, and the fifth from $W^{\\prime}$ being a subpopulation of $W_{0}$. The second to last line follows from Proposition 3.1 and from $\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W_{0}=1\\right)\\right)<\\infty$ implying $\\mathbb{P}\\left(\\underline{w}^{\\prime}(X)>\\right.$ $0 \\mid W_{0}=1)>0$.\n\nSimilarly, we can write $\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=1\\right]=\\mu^{\\prime}\\left(\\underline{w}^{*}, \\tau_{0}\\right)$ where $\\underline{w}^{*}(X)=\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1, X\\right)$. Therefore, by Proposition 3.1, we have that $\\mu^{\\prime}\\left(\\frac{a}{\\underline{w}^{\\prime}}, \\tau_{0}\\right)-\\mu^{\\prime}\\left(\\underline{w}^{*}, \\tau_{0}\\right)=0$ for all $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$.\n\nLet $\\tau^{*}(X)=\\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\mathbb{E}\\left[a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right]}-\\frac{\\underline{w}^{*}(X)}{\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right)}$. We have $\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W_{0}=1\\right)\\right)<\\infty$ and $\\mathbb{E}\\left[\\underline{w}^{*}(X)^{2}\\right] \\leq 1$ by construction. Hence, $\\mathbb{E}\\left[\\tau^{*}(X)^{2}\\right]<\\infty$ and $\\tau^{*} \\in \\mathcal{T}_{\\text {all }}$.\n\nThus, we must have $\\mu^{\\prime}\\left(\\frac{a}{\\underline{w}^{\\prime}}, \\tau^{*}\\right)-\\mu^{\\prime}\\left(\\underline{w}^{*}, \\tau^{*}\\right)=0$. Expanding this equality yields\n\n$$\n0=\\mu^{\\prime}\\left(\\frac{a}{\\underline{w}^{\\prime}}, \\tau^{*}\\right)-\\mu^{\\prime}\\left(\\underline{w}^{*}, \\tau^{*}\\right)\n$$\n\n$$\n\\begin{aligned}\n& =\\mathbb{E}\\left[\\tau^{*}(X)\\left(\\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\mathbb{E}[a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1]}-\\frac{\\underline{w}^{*}(X)}{\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right)}\\right) \\mid W^{\\prime}=1\\right] \\\\\n& =\\mathbb{E}\\left[\\tau^{*}(X)^{2} \\mid W^{\\prime}=1\\right]\n\\end{aligned}\n$$\n\nThis implies that $\\mathbb{P}\\left(\\tau^{*}(X)=0 \\mid W^{\\prime}=1\\right)=1$. In turn, this implies that\n\n$$\n\\mathbb{P}\\left(a(X)=\\frac{\\underline{w}^{\\prime}(X) \\underline{w}^{*}(X) \\mathbb{E}\\left[a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right]}{\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right)} \\mid W^{\\prime}=1\\right)=1\n$$\n\nWe have that $\\underline{w}^{*}(X) \\geq 0$ and $\\underline{w}^{\\prime}(X) \\geq 0$ almost surely, and $\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right)>0$ by the assumption that $W^{*} \\in \\mathcal{W}\\left(a ; W^{\\prime}, \\mathcal{T}_{\\mathrm{all}}\\right)$. Also, $\\mathbb{E}\\left[a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right]=\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right] / \\mathbb{P}\\left(W^{\\prime}=1 \\mid W_{0}=1\\right)>0$ by Assumption 3.1 and by $W^{\\prime}$ being a regular subpopulation of $W_{0}$. Therefore, $\\mathbb{P}(a(X) \\geq 0 \\mid W^{\\prime}=1)=1$.\n$(\\Longleftrightarrow)$ Second, suppose that $\\mathbb{P}\\left(a(X) \\geq 0 \\mid W^{\\prime}=1\\right)=1$ and fix $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$. Let $\\underline{w}^{\\prime}(X)=\\mathbb{P}\\left(W^{\\prime}=1 \\mid\\right.$ $X, W_{0}=1$ ). As in the first part of the proof, recall that\n\n$$\n\\begin{aligned}\n\\mu\\left(a, \\tau_{0}\\right) & =\\frac{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\mathbb{E}[Y(1)-Y(0) \\mid W^{\\prime}=1, X] \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\mid W^{\\prime}=1\\right]} \\\\\n& :=\\mu^{\\prime}\\left(\\frac{a}{\\underline{w}^{\\prime}}, \\tau_{0}\\right)\n\\end{aligned}\n$$\n\nLet $U \\sim \\operatorname{Unif}(0,1)$ where $U \\Perp\\left(Y(1), Y(0), X, W_{0}, W^{\\prime}\\right)$, and define\n\n$$\nW^{*}=\\mathbb{1}\\left(U \\leq \\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)}\\right) \\cdot W^{\\prime}\n$$\n\nWe verify that $W^{*}$ is a regular subpopulation of $W^{\\prime}$. First, we see that $\\mathbb{P}\\left(W^{*}=1\\right)>0$ because\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(W^{*}=1\\right) & =\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right) \\mathbb{P}\\left(W^{\\prime}=1\\right)+\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=0\\right) \\mathbb{P}\\left(W^{\\prime}=0\\right) \\\\\n& =\\mathbb{P}\\left(\\mathbb{1}\\left(U \\leq \\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)}\\right) \\cdot W^{\\prime}=1 \\mid W^{\\prime}=1\\right) \\mathbb{P}\\left(W^{\\prime}=1\\right) \\\\\n& =\\mathbb{E}\\left[\\mathbb{P}\\left(U \\leq \\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)} \\mid X, W^{\\prime}=1\\right) \\mid W^{\\prime}=1\\right] \\mathbb{P}\\left(W^{\\prime}=1\\right) \\\\\n& =\\mathbb{E}\\left[\\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)} \\mid W^{\\prime}=1\\right] \\mathbb{P}\\left(W^{\\prime}=1\\right) \\\\\n& =\\frac{\\mathbb{E}\\left[a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right] \\mathbb{P}\\left(W^{\\prime}=1\\right)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)} \\\\\n& =\\frac{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right] \\mathbb{P}\\left(W_{0}=1\\right)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)} \\\\\n& >0\n\\end{aligned}\n$$\n\nThe second equality follows from $\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=0\\right)=0$, which holds by the construction of $W^{*}$. The fourth equality holds from $U \\Perp\\left(X, W^{\\prime}\\right)$ and from $\\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)} \\in[0,1]$ almost surely given $W^{\\prime}=$ 1. The sixth equality holds from $\\mathbb{E}\\left[a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right]=\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right] / \\mathbb{P}\\left(W^{\\prime}=1 \\mid W_{0}=1\\right)$ and from $W^{\\prime}$ being a subpopulation of $W_{0}$. To establish the final inequality, recall that $\\mathbb{P}\\left(W^{\\prime}=1\\right)$ and $\\mathbb{E}[a(X) \\mid$ $\\left.W_{0}=1\\right]$ are positive by assumption. Also $\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right) \\leq \\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid\\right.\\right.$ $\\left.W_{0}=1\\right)\\right)<\\infty$ since $\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)$ is a subset of $\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W_{0}=1\\right)$. That $W^{*}$ satisfies the two properties of Definition 3.1 holds immediately. Therefore, $W^{*}$ is a regular subpopulation of $W^{\\prime}$.\n\nFinally, let\n\n$$\n\\begin{aligned}\n\\underline{w}^{*}(X) & =\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\\\\n& =\\mathbb{P}\\left(U \\leq \\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)} \\mid X, W^{\\prime}=1\\right) \\\\\n& =\\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)}\n\\end{aligned}\n$$\n\nLetting $\\mathbb{E}\\left[Y(1)-Y(0) \\mid X, W^{\\prime}=1\\right]=\\tau_{0}(X) \\in \\mathcal{T}_{\\text {all }}$ and using Proposition 3.1, we can see that\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=1\\right] & =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\tau_{0}(X) \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X) \\mid W^{\\prime}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)} \\tau_{0}(X) \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)} \\mid W^{\\prime}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\tau_{0}(X) \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\mid W^{\\prime}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[a(X) \\tau_{0}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]} \\\\\n& =\\mu\\left(a, \\tau_{0}\\right)\n\\end{aligned}\n$$\n\nSince $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$ was arbitrary, we have that $W^{*} \\in \\mathcal{W}\\left(a ; W^{\\prime}, \\mathcal{T}_{\\text {all }}\\right)$ which concludes the proof.\nPart 2: $\\mathcal{T}=\\left\\{\\tau_{0}\\right\\}$\nTo simplify the notation in the proof, we let $\\mu \\succ \\mu\\left(a, \\tau_{0}\\right)$.\n$(\\Longrightarrow)$ First, let $\\mu \\notin \\mathcal{S}\\left(\\tau_{0} ; W^{\\prime}\\right)$ and suppose there exists $W^{*} \\in \\mathcal{W}\\left(a ; W^{\\prime},\\left\\{\\tau_{0}\\right\\}\\right)$. Since $\\mu \\notin \\mathcal{S}\\left(\\tau_{0} ; W^{\\prime}\\right)$, we can without loss of generality suppose that $\\mathbb{P}\\left(\\tau_{0}(X) \\leq \\mu \\mid W^{\\prime}=1\\right)=0$, which implies $\\mathbb{P}\\left(\\tau_{0}(X)>\\mu \\mid W^{\\prime}=\\right.$ $1)=1$. Since $W^{*} \\in \\mathcal{W}\\left(a ; W^{\\prime},\\left\\{\\tau_{0}\\right\\}\\right)$, we can write by Proposition 3.1\n\n$$\n\\begin{aligned}\n\\mu & =\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=1\\right] \\\\\n& =\\frac{\\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\mathbb{E}\\left[Y(1)-Y(0) \\mid X, W^{\\prime}=1\\right] \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\mid W^{\\prime}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\tau_{0}(X) \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\mid W^{\\prime}=1\\right]} \\\\\n& \\geq \\frac{\\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\mu \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\mid W^{\\prime}=1\\right]}=\\mu\n\\end{aligned}\n$$\n\nThe inequality is strict unless $\\underbrace{\\mathbb{E}\\left[\\left(\\tau_{0}(X)-\\mu\\right) \\mid \\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right)\\right.}_{>0 \\leqslant \\mathrm{p} .1} \\underbrace{\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right)}_{\\in[0,1]} \\mid W^{\\prime}=1]=0$ holds. This holds if $\\mathbb{P}\\left(\\left(\\tau_{0}(X)-\\mu\\right) \\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right)=0 \\mid W^{\\prime}=1\\right)=1$, which in turns occurs if and only if $\\mathbb{P}\\left(\\mathbb{P}\\left(W^{*}=1 \\mid\\right.\\right.$ $X, W^{\\prime}=1)=0 \\mid W^{\\prime}=1)=1$. This implies $\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right)=0$ and $\\mathbb{P}\\left(W^{*}=1\\right)=\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=\\right.$ $1) \\mathbb{P}\\left(W^{\\prime}=1\\right)=0$, a contradiction of $W^{*} \\in \\mathcal{W}\\left(a, W^{\\prime},\\left\\{\\tau_{0}\\right\\}\\right)$. Therefore, the inequality in (C.2) is strict and yields $\\mu>\\mu$, a contradiction. Therefore, $\\mathcal{W}\\left(a ; W^{\\prime},\\left\\{\\tau_{0}\\right\\}\\right)=\\emptyset$ when $\\mu \\notin \\mathcal{S}\\left(\\tau_{0} ; W^{\\prime}\\right)$.\n$(\\Longleftarrow)$ Second, let $\\mu \\in \\mathcal{S}\\left(\\tau_{0} ; W^{\\prime}\\right)$. Let\n\n$$\n\\mathcal{X}^{-}=\\left\\{x \\in \\operatorname{supp}(X): \\tau_{0}(x) \\leq \\mu\\right\\} \\quad \\text { and } \\quad \\mathcal{X}^{+}=\\left\\{x \\in \\operatorname{supp}(X): \\tau_{0}(x) \\geq \\mu\\right\\}\n$$\n\nBy $\\mu \\in \\mathcal{S}\\left(\\tau_{0} ; W^{\\prime}\\right), \\mathbb{P}\\left(X \\in \\mathcal{X}^{-} \\mid W^{\\prime}=1\\right)=\\mathbb{P}\\left(\\tau_{0}(X) \\leq \\mu \\mid W^{\\prime}=1\\right)>0$. Similarly, $\\mathbb{P}\\left(X \\in \\mathcal{X}^{+} \\mid W^{\\prime}=1\\right)>0$.\n\nLet $U \\sim \\operatorname{Unif}(0,1)$ where $U \\Perp\\left(Y(1), Y(0), X, W^{\\prime}, W_{0}\\right)$. For $u \\in[0,1]$, let\n\n$$\nW^{*}(u)=\\left(\\mathbb{1}\\left(U>u, X \\in \\mathcal{X}^{-}\\right)+\\mathbb{1}\\left(U \\leq u, X \\in \\mathcal{X}^{+}\\right)\\right) \\cdot W^{\\prime}\n$$\n\nWe can see that $W^{*}(u) \\in\\{0,1\\}$, that $W^{*}(u) \\Perp\\left(Y(1), Y(0)\\right) \\mid X, W^{\\prime}=1$, and that $\\mathbb{P}\\left(W^{*}(u)=1 \\mid W^{\\prime}=\\right.$ $0)=0$. To show that $W^{*}(u)$ characterizes a regular subpopulation of $W^{\\prime}$, we also show that it is nonzero with positive probability:\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(W^{*}(u)=1 \\mid W^{\\prime}=1\\right) & =\\mathbb{P}\\left(\\mathbb{1}\\left(U>u, X \\in \\mathcal{X}^{-}\\right)+\\mathbb{1}\\left(U \\leq u, X \\in \\mathcal{X}^{+}\\right)=1 \\mid W^{\\prime}=1\\right) \\\\\n& =\\mathbb{P}\\left(U>u, X \\in \\mathcal{X}^{-} \\mid W^{\\prime}=1\\right)+\\mathbb{P}\\left(U \\leq u, X \\in \\mathcal{X}^{+} \\mid W^{\\prime}=1\\right) \\\\\n& =(1-u) \\mathbb{P}\\left(X \\in \\mathcal{X}^{-} \\mid W^{\\prime}=1\\right)+u \\mathbb{P}\\left(X \\in \\mathcal{X}^{+} \\mid W^{\\prime}=1\\right) \\\\\n& >0\n\\end{aligned}\n$$\n\nfor all $u \\in[0,1]$. Therefore, $\\mathbb{P}\\left(W^{*}(u)=1\\right)=\\mathbb{P}\\left(W^{*}(u)=1 \\mid W^{\\prime}=1\\right) \\mathbb{P}\\left(W^{\\prime}=1\\right)>0$ by $\\mathbb{P}\\left(W^{\\prime}=1\\right)>0$. Hence, $W^{*}(u) \\in \\operatorname{SP}\\left(W^{\\prime}\\right)$ for all $u \\in[0,1]$.\n\nFor a given $u$, we have that $\\underline{w}^{*}(X ; u):=\\mathbb{P}\\left(W^{*}(u)=1 \\mid X, W^{\\prime}=1\\right)=(1-u) \\mathbb{1}\\left(X \\in \\mathcal{X}^{-}\\right)+u \\mathbb{1}\\left(X \\in \\mathcal{X}^{+}\\right)$. Therefore, using Proposition 3.1,\n\n$$\n\\begin{aligned}\n\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}(u)=1] & =\\frac{\\mathbb{E}\\left[\\underline{w}^{*}(X ; u) \\mathbb{E}[Y(1)-Y(0) \\mid X, W^{\\prime}=1] \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\underline{w}^{*}(X ; u) \\mid W^{\\prime}=1\\right]} \\\\\n& =\\frac{\\mathbb{E}\\left[\\left((1-u) \\mathbb{1}\\left(X \\in \\mathcal{X}^{-}\\right)+u \\mathbb{1}\\left(X \\in \\mathcal{X}^{+}\\right)\\right) \\tau_{0}(X) \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\left((1-u) \\mathbb{1}\\left(X \\in \\mathcal{X}^{-}\\right)+u \\mathbb{1}\\left(X \\in \\mathcal{X}^{+}\\right)\\right) \\mid W^{\\prime}=1\\right]} \\\\\n& =\\frac{(1-u) \\mathbb{E}\\left[\\mathbb{1}\\left(X \\in \\mathcal{X}^{-}\\right) \\tau_{0}(X) \\mid W^{\\prime}=1\\right]+u \\mathbb{E}\\left[\\mathbb{1}\\left(X \\in \\mathcal{X}^{+}\\right) \\tau_{0}(X) \\mid W^{\\prime}=1\\right]}{(1-u) \\mathbb{P}\\left(X \\in \\mathcal{X}^{-} \\mid W^{\\prime}=1\\right)+u \\mathbb{P}\\left(X \\in \\mathcal{X}^{+} \\mid W^{\\prime}=1\\right)}\n\\end{aligned}\n$$\n\nBy construction, $\\tau_{0}(X) \\mathbb{1}\\left(X \\in \\mathcal{X}^{-}\\right) \\leq \\mu \\mathbb{1}\\left(X \\in \\mathcal{X}^{-}\\right)$and $\\tau_{0}(X) \\mathbb{1}\\left(X \\in \\mathcal{X}^{+}\\right) \\geq \\mu \\mathbb{1}\\left(X \\in \\mathcal{X}^{+}\\right)$almost surely. Therefore,\n\n$$\n\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}(0)=1]=\\frac{\\mathbb{E}\\left[\\mathbb{1}\\left(X \\in \\mathcal{X}^{-}\\right) \\tau_{0}(X) \\mid W^{\\prime}=1\\right]}{\\mathbb{P}\\left(X \\in \\mathcal{X}^{-} \\mid W^{\\prime}=1\\right)} \\leq \\frac{\\mathbb{E}\\left[\\mathbb{1}\\left(X \\in \\mathcal{X}^{-}\\right) \\mu \\mid W^{\\prime}=1\\right]}{\\mathbb{P}\\left(X \\in \\mathcal{X}^{-} \\mid W^{\\prime}=1\\right)}=\\mu\n$$\n\nand\n\n$$\n\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}(1)=1]=\\frac{\\mathbb{E}\\left[\\mathbb{1}\\left(X \\in \\mathcal{X}^{+}\\right) \\tau_{0}(X) \\mid W^{\\prime}=1\\right]}{\\mathbb{P}\\left(X \\in \\mathcal{X}^{+} \\mid W^{\\prime}=1\\right)} \\geq \\frac{\\mathbb{E}\\left[\\mathbb{1}\\left(X \\in \\mathcal{X}^{+}\\right) \\mu \\mid W^{\\prime}=1\\right]}{\\mathbb{P}\\left(X \\in \\mathcal{X}^{+} \\mid W^{\\prime}=1\\right)}=\\mu\n$$\n\nBy the continuity of $\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}(u)=1]$ in $u$ and the intermediate value theorem, there exists $u^{*} \\in[0,1]$ such that $\\mu=\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}\\left(u^{*}\\right)=1]$ and $W^{*}\\left(u^{*}\\right) \\in \\mathcal{W}\\left(a ; W^{\\prime},\\left\\{\\tau_{0}\\right\\}\\right)$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 34,
      "text": "# Proof of Theorem 4.4.\n## Part 1: $\\mathcal{T}=\\mathcal{T}_{\\text {all }}$\n\nFirst suppose $\\mathbb{P}(a(X) \\geq 0 \\mid W^{\\prime}=1)=1$. From Theorem 4.3, there exists $W^{*} \\in \\mathcal{W}\\left(a ; W^{\\prime}, \\mathcal{T}_{\\text {all }}\\right)$. Written differently, we have that\n$\\frac{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\tau_{0}(X) \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\mid W^{\\prime}=1\\right]}=\\mu\\left(a, \\tau_{0}\\right)=\\mathbb{E}[Y(1)-Y(0) \\mid W^{*}=1]=\\frac{\\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\tau_{0}(X) \\mid W^{\\prime}=1\\right]}{\\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\mid W^{\\prime}=1\\right]}$\nfor all $\\tau_{0} \\in \\mathcal{T}_{\\text {all }}$. From derivations in the proof of Theorem 4.3 (see equation (C.1)) we have that $\\mathbb{P}\\left(C \\cdot \\frac{a(X)}{\\underline{w}^{\\prime}(X)}=\\right.$ $\\left.\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\mid W^{\\prime}=1\\right)=1$ for some positive constant $C>0$.\n\nSince $\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\leq 1$ almost surely given $W^{\\prime}=1$, we must have $C \\cdot a(X) / \\underline{w}^{\\prime}(X) \\leq 1$ almost\n\nsurely given $W^{\\prime}=1$. This means $C$ is bounded above by $\\inf \\left(\\operatorname{supp}\\left(\\underline{w}^{\\prime}(X) / a(X) \\mid W^{\\prime}=1\\right)\\right)$, which is strictly positive by assumption. Therefore,\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right)= & \\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\mid W^{\\prime}=1\\right] \\\\\n\\leq & \\inf \\left(\\operatorname{supp}\\left(\\frac{\\underline{w}^{\\prime}(X)}{a(X)} \\mid W^{\\prime}=1\\right)\\right) \\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} \\mid W^{\\prime}=1\\right] \\\\\n= & \\inf \\left(\\operatorname{supp}\\left(\\frac{\\underline{w}^{\\prime}(X)}{a(X)} \\mid W^{\\prime}=1\\right)\\right) \\frac{\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} W^{\\prime}\\right]}{\\mathbb{P}\\left(W^{\\prime}=1\\right)} \\\\\n= & \\inf \\left(\\operatorname{supp}\\left(\\frac{\\underline{w}^{\\prime}(X)}{a(X)} \\mid W^{\\prime}=1\\right)\\right) \\\\\n& \\cdot \\mathbb{E}\\left[\\mathbb{E}\\left[\\frac{a(X)}{\\underline{w}^{\\prime}(X)} W^{\\prime} \\mid X, W_{0}=1\\right] \\mid W_{0}=1\\right] \\frac{\\mathbb{P}\\left(W_{0}=1\\right)}{\\mathbb{P}\\left(W^{\\prime}=1\\right)} \\\\\n= & \\inf \\left(\\operatorname{supp}\\left(\\frac{\\underline{w}^{\\prime}(X)}{a(X)} \\mid W^{\\prime}=1\\right)\\right) \\cdot \\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right] \\frac{\\mathbb{P}\\left(W_{0}=1\\right)}{\\mathbb{P}\\left(W^{\\prime}=1\\right)}\n\\end{aligned}\n$$\n\nThe fifth line follows from $W^{\\prime}$ being a subpopulation of $W_{0}$, and the last line follows from the law of iterated expectations.\n\nThis upper bound is sharp because it is attained by setting\n\n$$\nW^{*}=\\mathbb{1}\\left(U \\leq \\frac{a(X) / \\underline{w}^{\\prime}(X)}{\\sup \\left(\\operatorname{supp}\\left(a(X) / \\underline{w}^{\\prime}(X) \\mid W^{\\prime}=1\\right)\\right)}\\right) \\cdot W^{\\prime}\n$$\n\nand noting that $W^{*} \\in \\mathcal{W}\\left(a ; W^{\\prime}, \\mathcal{T}_{\\text {all }}\\right)$ from the proof of Theorem 4.3.\nNow suppose $\\mathbb{P}\\left(a(X) \\geq 0 \\mid W^{\\prime}=1\\right)<1$. By Theorem 4.3, $\\mathcal{W}\\left(a ; W^{\\prime}, \\mathcal{T}_{\\text {all }}\\right)=\\emptyset$ and therefore $\\bar{P}\\left(a, W^{\\prime} ; \\mathcal{T}_{\\text {all }}\\right)$ is zero.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 35,
      "text": "# Part 2: $\\mathcal{T}=\\left\\{\\tau_{0}\\right\\}$ \n\nIn this case, we seek to maximize $\\mathbb{P}\\left(W^{*}=1 \\mid W^{\\prime}=1\\right)$ subject to $W^{*} \\in \\mathcal{W}\\left(a ; W^{\\prime},\\left\\{\\tau_{0}\\right\\}\\right)$. Using Proposition 3.1, we can write $\\mathbb{E}\\left[Y(1)-Y(0) \\mid W^{*}=1\\right]$ as $\\mathbb{E}\\left[\\tau_{0}(X) \\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right) \\mid W^{\\prime}=1\\right] / \\mathbb{E}\\left[\\mathbb{P}\\left(W^{*}=1 \\mid\\right.\\right.$ $\\left.X, W^{\\prime}=1\\right) \\mid W^{\\prime}=1]$. The result then follows from a direct application of Theorem 4.2 that replaces $W_{0}$ by $W^{\\prime}$ in its statement and $\\mathbb{P}\\left(W^{*}=1 \\mid X, W_{0}=1\\right)$ by $\\mathbb{P}\\left(W^{*}=1 \\mid X, W^{\\prime}=1\\right)$ in the proofs.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 36,
      "text": "## D Proofs for Section 5\n\nProof of Proposition 5.3. We begin by noting that\n\n$$\n\\begin{aligned}\n\\beta_{\\text {TWFE }} & =\\frac{\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[\\bar{D}_{t} Y_{t}\\right]}{\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[\\bar{D}_{t}^{2}\\right]} \\\\\n& =\\frac{\\sum_{t=1}^{T} \\mathbb{E}\\left[\\bar{D}_{t} Y_{t} \\mid P=t\\right] \\mathbb{P}(P=t)}{\\sum_{t=1}^{T} \\mathbb{E}\\left[\\bar{D}_{t}^{2} \\mid P=t\\right] \\mathbb{P}(P=t)} \\\\\n& =\\frac{\\mathbb{E}[\\bar{D} Y]}{\\mathbb{E}\\left[\\bar{D}^{2}\\right]}\n\\end{aligned}\n$$\n\nwhere the second equality follows from the uniform distribution of $P$ which is independent from $\\left(\\bar{D}_{t}, Y_{t}\\right)$ for all $t \\in\\{1, \\ldots, T\\}$. The third equality follows from defining $\\bar{D}:=\\bar{D}_{P}$. We also note that\n\n$$\n\\bar{D}_{P}=D_{P}-\\frac{1}{T} \\sum_{s=1}^{T} D_{s}-\\sum_{t=1}^{T} \\mathbb{E}\\left[D_{t}\\right] \\mathbb{1}(P=t)+\\sum_{s=1}^{T} \\mathbb{E}\\left[D_{s}\\right] \\mathbb{E}[\\mathbb{1}(P=s)]\n$$\n\n$$\n\\begin{aligned}\n& =D-\\frac{1}{T} \\sum_{s=1}^{T} \\mathbb{1}(G \\leq s)-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D] \\\\\n& =D-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]\n\\end{aligned}\n$$\n\nThe third equality follows from $\\mathbb{E}[D \\mid G]=\\mathbb{E}[\\mathbb{1}(G \\leq P) \\mid G]=\\frac{1}{T} \\sum_{s=1}^{T} \\mathbb{1}(G \\leq s)=\\frac{1}{T} \\sum_{s=1}^{T} D_{s}$. We break down the rest of this proof into four steps.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 37,
      "text": "# Step 1: Splitting the Numerator in Two \n\nWe have that\n\n$$\n\\mathbb{E}[\\tilde{D} Y]=\\mathbb{E}[\\tilde{D}(Y(0)+D(Y(1)-Y(0)))]=\\mathbb{E}[\\tilde{D} \\mathbb{E}[Y(0) \\mid G, P]]+\\mathbb{E}[\\tilde{D} D \\mathbb{E}[Y(1)-Y(0) \\mid G, P]]\n$$\n\nThe first equality follows from $Y=Y(0)+D(Y(1)-Y(0))$ and the second from iterated expectations and $\\mathbb{E}[D \\mid G, P]=D$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 38,
      "text": "## Step 2: First Numerator Term\n\nWe have that\n\n$$\n\\mathbb{E}[\\tilde{D} \\mathbb{E}[Y(0) \\mid G, P]]=\\mathbb{E}[\\tilde{D} \\theta(G, P)]=\\mathbb{E}[\\tilde{D} \\tilde{\\theta}(G, P)]\n$$\n\nwhere $\\theta(G, P)=\\mathbb{E}[Y(0) \\mid G, P]$. The second equality follows by properties of projections and from defining $\\tilde{\\theta}(G, P)$ as follows:\n\n$$\n\\begin{aligned}\n\\tilde{\\theta}(G, P) & :=\\theta(G, P)-\\mathbb{E}[\\theta(G, P) \\mid G]-\\mathbb{E}[\\theta(G, P) \\mid P]+\\mathbb{E}[\\theta(G, P)] \\\\\n& =\\mathbb{E}[Y(0) \\mid G, P]-\\mathbb{E}[Y(0) \\mid G]-\\mathbb{E}[Y(0) \\mid P]+\\mathbb{E}[Y(0)]\n\\end{aligned}\n$$\n\nThen, we note that\n\n$$\n\\begin{aligned}\n\\tilde{\\theta}\\left(g^{\\prime}, t^{\\prime}\\right) & =\\mathbb{E}\\left[Y(0) \\mid G=g^{\\prime}, P=t^{\\prime}\\right]-\\mathbb{E}\\left[Y(0) \\mid G=g^{\\prime}\\right]-\\mathbb{E}\\left[Y(0) \\mid P=t^{\\prime}\\right]+\\mathbb{E}[Y(0)] \\\\\n& =\\mathbb{E}\\left[Y_{t^{\\prime}}(0) \\mid G=g^{\\prime}\\right]-\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[Y_{t}(0) \\mid G=g^{\\prime}\\right]-\\sum_{g \\in \\mathcal{G}}\\left(\\mathbb{E}\\left[Y_{t^{\\prime}}(0) \\mid G=g\\right]-\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[Y_{t}(0) \\mid G=g\\right]\\right) \\mathbb{P}(G=g) \\\\\n& =\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[Y_{t^{\\prime}}(0)-Y_{t}(0) \\mid G=g^{\\prime}\\right]-\\sum_{g \\in \\mathcal{G}}\\left(\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[Y_{t^{\\prime}}(0)-Y_{t}(0) \\mid G=g\\right]\\right) \\mathbb{P}(G=g)\n\\end{aligned}\n$$\n\nAssumption 5.5.2 implies that for any pair $t, t^{\\prime} \\in\\{1, \\ldots, T\\}$ and any $g^{\\prime} \\in \\mathcal{G}$\n\n$$\n\\mathbb{E}\\left[Y_{t^{\\prime}}(0)-Y_{t}(0) \\mid G=g^{\\prime}\\right]=\\mathbb{E}\\left[Y_{t^{\\prime}}(0)-Y_{t}(0)\\right]\n$$\n\nThis can be shown for $t^{\\prime}>t$ by writing $\\mathbb{E}\\left[Y_{t^{\\prime}}(0)-Y_{t}(0) \\mid G=g^{\\prime}\\right]=\\sum_{s=t+1}^{t^{\\prime}} \\mathbb{E}\\left[Y_{s}(0)-Y_{s-1}(0) \\mid G=g^{\\prime}\\right]=$ $\\sum_{s=t+1}^{t^{\\prime}} \\mathbb{E}\\left[Y_{s}(0)-Y_{s-1}(0)\\right]=\\mathbb{E}\\left[Y_{t^{\\prime}}(0)-Y_{t}(0)\\right]$. Similar derivations show this holds for $t^{\\prime}<t$. The case where $t^{\\prime}=t$ is trivial. Therefore,\n\n$$\n\\begin{aligned}\n\\theta\\left(g^{\\prime}, t^{\\prime}\\right) & =\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[Y_{t^{\\prime}}(0)-Y_{t}(0) \\mid G=g^{\\prime}\\right]-\\sum_{g \\in \\mathcal{G}}\\left(\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[Y_{t^{\\prime}}(0)-Y_{t}(0) \\mid G=g\\right]\\right) \\mathbb{P}(G=g) \\\\\n& =\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[Y_{t^{\\prime}}(0)-Y_{t}(0)\\right]-\\sum_{g \\in \\mathcal{G}}\\left(\\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{E}\\left[Y_{t^{\\prime}}(0)-Y_{t}(0)\\right]\\right) \\mathbb{P}(G=g) \\\\\n& =0\n\\end{aligned}\n$$\n\nfor all $\\left(g^{\\prime}, t^{\\prime}\\right) \\in \\mathcal{G} \\times\\{1, \\ldots, T\\}$, which implies $\\mathbb{E}[\\tilde{D} \\mathbb{E}[Y(0) \\mid G, P]]=0$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 39,
      "text": "# Step 3: Second Numerator Term \n\nWe can write\n\n$$\n\\begin{aligned}\n\\mathbb{E}[\\tilde{D} D \\mathbb{E}[Y(1)-Y(0) \\mid G, P]] & =\\mathbb{E}[(D-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) D \\mathbb{E}[Y(1)-Y(0) \\mid G, P]] \\\\\n& =\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) D \\mathbb{E}[Y(1)-Y(0) \\mid G, P]] \\\\\n& =\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) \\mathbb{E}[D(Y(1)-Y(0)) \\mid G, P]] \\\\\n& =\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) \\mathbb{E}[Y(1)-Y(0) \\mid G, P, D=1] \\mathbb{P}(D=1 \\mid G, P)]\n\\end{aligned}\n$$\n\nThe first equality is by definition, the second by $D^{2}=D$, the third by $\\mathbb{E}[D \\mid G, P]=D$, and the fourth by the law of total probability.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 40,
      "text": "## Step 4: Denominator\n\nIn this step, we show that\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[\\tilde{D}^{2}\\right] & =\\mathbb{E}[(D-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) D] \\\\\n& =\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) D] \\\\\n& =\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) \\mathbb{P}(D=1 \\mid G, P)]\n\\end{aligned}\n$$\n\nThe first line is obtained from properties of linear projections, the second from $D^{2}=D$, and the third from $D=\\mathbb{P}(D=1 \\mid G, P)$.\n\nWe conclude the proof by noting the equivalence of integrating over the distribution of $P$ and averages over time periods, which shows the equivalence between\n\n$$\n\\beta_{\\text {TWFE }}=\\frac{\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) \\mathbb{E}[Y(1)-Y(0) \\mid G, P, D=1] \\mathbb{P}(D=1 \\mid G, P)]}{\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) \\mathbb{P}(D=1 \\mid G, P)]}\n$$\n\nand the expression in Proposition 5.3.\nProof of Proposition 5.4. Proposition 5.3 and $\\mathbb{P}(D=1 \\mid G, P)=D$ yielded\n\n$$\n\\beta_{\\text {TWFE }}=\\frac{\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) D \\mathbb{E}[Y(1)-Y(0) \\mid G, P, D=1]]}{\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) D]}\n$$\n\nSince $\\mathbb{E}[Y(1)-Y(0) \\mid G, P, D=1]=\\mathbb{E}[Y(1)-Y(0) \\mid G, D=1]$ by assumption, we can use the law of iterated expectations to obtain\n\n$$\n\\beta_{\\text {TWFE }}=\\frac{\\mathbb{E}[\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) D \\mid G] \\mathbb{E}[Y(1)-Y(0) \\mid G, D=1]]}{\\mathbb{E}[\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) D \\mid G]]}\n$$\n\nWe now calculate the conditional expectation $\\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) D \\mid G=g]$ for $g \\in \\mathcal{G}$. If $g=+\\infty$, then this conditional expectation is 0 by construction, so we focus on the case where $g \\in\\{2, \\ldots, T\\}$. For these derivations, we let $F_{G}(p):=\\mathbb{P}(G \\leq p)$ denote the cdf of $G$ at $p$.\n\n$$\n\\begin{aligned}\n& \\mathbb{E}[(1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D]) D \\mid G=g] \\\\\n& =\\mathbb{E}[D \\mid G=g]\\left(1-\\mathbb{E}[D \\mid G=g]-\\frac{\\mathbb{E}[\\mathbb{E}[D \\mid P] D \\mid G=g]}{\\mathbb{E}[D \\mid G=g]}+\\mathbb{E}[D]\\right) \\\\\n& =\\mathbb{E}[D \\mid G=g]\\left(1-\\mathbb{E}[\\mathbb{1}(G \\leq P) \\mid G=g]-\\frac{\\mathbb{E}[F_{G}(P) \\mathbb{1}(G \\leq P) \\mid G=g]}{\\mathbb{E}[\\mathbb{1}(G \\leq P) \\mid G=g]}+\\mathbb{E}[\\mathbb{E}[\\mathbb{1}(G \\leq P) \\mid P]]\\right)\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n& =\\mathbb{E}[D \\mid G=g]\\left(1-\\mathbb{E}[\\mathbb{1}(g \\leq P)]-\\frac{\\mathbb{E}\\left[F_{G}(P) \\mathbb{1}(g \\leq P)\\right]}{\\mathbb{E}[\\mathbb{1}(g \\leq P)]}+\\mathbb{E}\\left[F_{G}(P)\\right]\\right) \\\\\n& =\\mathbb{E}[D \\mid G=g](1-\\mathbb{E}[\\mathbb{1}(g \\leq P)]-\\mathbb{E}\\left[F_{G}(P) \\mid g \\leq P\\right] \\\\\n& \\quad+\\mathbb{E}\\left[F_{G}(P) \\mid g \\leq P \\mid \\mathbb{E}[\\mathbb{1}(g \\leq P)]+\\mathbb{E}\\left[F_{G}(P) \\mid g>P \\mid \\mathbb{E}[\\mathbb{1}(g>P)]\\right)\\right. \\\\\n& =\\mathbb{E}[D \\mid G=g] \\mathbb{E}[\\mathbb{1}(g>P)]\\left(1+\\mathbb{E}\\left[F_{G}(P) \\mid g>P\\right]-\\mathbb{E}\\left[F_{G}(P) \\mid g \\leq P\\right]\\right) \\\\\n& =\\mathbb{E}[D \\mid G=g](1-\\mathbb{E}[D \\mid G=g])(1+\\mathbb{E}[D \\mid g>P]-\\mathbb{E}[D \\mid g \\leq P]) \\\\\n& =\\mathbb{P}(D=1 \\mid G=g) \\mathbb{P}(D=0 \\mid G=g)(\\mathbb{P}(D=1 \\mid P<g)+\\mathbb{P}(D=0 \\mid P \\geq g))\n\\end{aligned}\n$$\n\nThe first equality follows from $\\mathbb{E}[D \\mid G=g]>0$ for $g \\in\\{2, \\ldots, T\\}$. The second follows from $D=\\mathbb{1}(G \\leq P)$ and the law of iterated expectations, the third from $G \\Perp P$, the fourth from definitions of conditional expectations and the law of iterated expectations, the fifth from combining terms, the sixth from the law of iterated expectations again, and the last line is obtained by the fact that $D \\in\\{0,1\\}$. The representation in Proposition 5.4 follows.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 41,
      "text": "# E Proofs for Section 6 \n\nWe use the following lemma in the proof of Theorem 6.1.\nLemma E.1. Let $\\theta=(\\theta(1), \\ldots, \\theta(K)) \\in \\mathbb{R}^{K}$ and define the mapping $\\phi: \\mathbb{R}^{K} \\rightarrow \\mathbb{R}$ by $\\phi(\\theta)=\\max _{j \\in\\{1, \\ldots, K\\}} \\theta(j)$. Then, $\\phi$ is Hadamard directionally differentiable (HDD) for all $\\theta \\in \\mathbb{R}^{K}$ tangentially to $\\mathbb{R}^{K}$ with directional derivative at $\\theta$ in direction $h \\in \\mathbb{R}^{K}$ equal to\n\n$$\n\\phi_{\\theta}^{\\prime}(h)=\\max _{j \\in \\arg \\max _{k \\in\\{1, \\ldots, K\\}} \\theta(k)} h(j)\n$$\n\nProof of Lemma E.1. Let $h_{n} \\rightarrow h \\in \\mathbb{R}^{K}$ and $t_{n} \\searrow 0$ as $n \\rightarrow \\infty$. Then,\n\n$$\n\\frac{\\phi\\left(\\theta+t_{n} h_{n}\\right)-\\phi(\\theta)}{t_{n}}=\\frac{\\max _{k \\in\\{1, \\ldots, K\\}}\\left(\\theta(k)+t_{n} h_{n}(k)\\right)-\\max _{k \\in\\{1, \\ldots, K\\}} \\theta(k)}{t_{n}}\n$$\n\nLet $\\Theta_{\\max }=\\{j \\in\\{1, \\ldots, K\\}: \\theta(j)=\\max _{k \\in\\{1, \\ldots, K\\}} \\theta(k)\\}$ and let $j_{\\max }$ be an element of $\\Theta_{\\max }$. Then, $\\max _{k \\in\\{1, \\ldots, K\\}} \\theta(k)=\\theta\\left(j_{\\max }\\right)$ and thus\n\n$$\n\\frac{\\phi\\left(\\theta+t_{n} h_{n}\\right)-\\phi(\\theta)}{t_{n}}=\\max \\left\\{\\frac{\\theta(1)-\\theta\\left(j_{\\max }\\right)}{t_{n}}+h_{n}(1), \\ldots, \\frac{\\theta(K)-\\theta\\left(j_{\\max }\\right)}{t_{n}}+h_{n}(K)\\right\\}\n$$\n\nFor each $j \\in \\Theta_{\\max },\\left(\\theta(j)-\\theta\\left(j_{\\max }\\right)\\right) / t_{n}+h_{n}(j)=h_{n}(j) \\rightarrow h(j)$. For each $j \\notin \\Theta_{\\max },\\left(\\theta(j)-\\theta\\left(j_{\\max }\\right)\\right) / t_{n} \\rightarrow-\\infty$ since $\\theta(j)-\\theta\\left(j_{\\max }\\right)<0$ and $t_{n} \\searrow 0$. Therefore, by continuity of the maximum operator in its arguments,\n\n$$\n\\frac{\\phi\\left(\\theta+t_{n} h_{n}\\right)-\\phi(\\theta)}{t_{n}} \\rightarrow \\max _{j \\in \\Theta_{\\max }} h(j)\n$$\n\nProof of Theorem 6.1. We begin by showing the consistency of $\\widetilde{P}$ for $\\bar{P}$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 42,
      "text": "## Part 1: Consistency\n\nThe estimators $\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{a}\\left(X_{i}\\right) \\widehat{w}_{0}\\left(X_{i}\\right), \\frac{1}{n} \\sum_{i=1}^{n} \\widehat{w}_{0}\\left(X_{i}\\right)\\right)$ are consistent for $\\left(\\mathbb{E}\\left[a(X) w_{0}(X)\\right], \\mathbb{E}\\left[w_{0}(X)\\right]\\right)$ since their components are assumed consistent by Assumption 6.1. More explicitly, we can write\n\n$$\n\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{a}\\left(X_{i}\\right) \\widehat{w}_{0}\\left(X_{i}\\right)=\\sum_{j=1}^{K} \\widehat{a}\\left(x_{j}\\right) \\widehat{w}_{0}\\left(x_{j}\\right) \\widehat{p}_{j} \\stackrel{p}{\\rightarrow} \\sum_{j=1}^{K} a\\left(x_{j}\\right) w_{0}\\left(x_{j}\\right) p_{j}=\\mathbb{E}\\left[a(X) w_{0}(X)\\right]\n$$\n\nby the continuous mapping theorem. The consistency of $\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{w}_{0}\\left(X_{i}\\right)$ for $\\mathbb{E}\\left[w_{0}(X)\\right]$ is similarly established.\nWe now consider the maximum term in the denominator. We can write\n\n$$\n\\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)=\\max _{x: \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{1}\\left(X_{i}=x\\right)>0, \\widehat{w}_{0}(x)>c_{n}} \\widehat{a}(x)\n$$\n\nLet $\\mathcal{X}^{+}=\\left\\{x \\in \\operatorname{supp}(X): w_{0}(x)>0\\right\\}$, which equals $\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)$, and let $\\widehat{\\mathcal{X}}^{+}=\\left\\{x: \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{1}\\left(X_{i}=\\right.\\right.$ $x)>0, \\widehat{w}_{0}(x)>c_{n}\\}$. We first show that $\\mathbb{P}\\left(\\widehat{\\mathcal{X}}^{+}=\\mathcal{X}^{+}\\right) \\rightarrow 1$ as $n \\rightarrow \\infty$. To see this, first consider $x_{j} \\in \\mathcal{X}^{+}$. Then,\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(x_{j} \\in \\widehat{\\mathcal{X}}^{+}\\right) & =\\mathbb{P}\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{1}\\left(X_{i}=x_{j}\\right)>0 \\cap \\widehat{w}_{0}\\left(x_{j}\\right)>c_{n}\\right) \\\\\n& \\geq \\mathbb{P}\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{1}\\left(X_{i}=x_{j}\\right)>0\\right)+\\mathbb{P}\\left(\\widehat{w}_{0}\\left(x_{j}\\right)>c_{n}\\right)-1\n\\end{aligned}\n$$\n\nThe above inequality was obtained from\n\n$$\n\\mathbb{P}(A \\cap B)=1-\\mathbb{P}\\left(A^{c} \\cup B^{c}\\right) \\geq 1-\\left(\\mathbb{P}\\left(A^{c}\\right)+\\mathbb{P}\\left(B^{c}\\right)\\right)=\\mathbb{P}(A)+\\mathbb{P}(B)-1\n$$\n\nwhere $A$ and $B$ are Borel sets.\nWe have that $\\mathbb{P}\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{1}\\left(X_{i}=x_{j}\\right)>0\\right) \\rightarrow 1$ since $\\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{1}\\left(X_{i}=x_{j}\\right) \\xrightarrow{p} p_{j}>0$. We also have that $\\mathbb{P}\\left(\\widehat{w}_{0}\\left(x_{j}\\right)>c_{n}\\right)=\\mathbb{P}\\left(\\widehat{w}_{0}\\left(x_{j}\\right)-c_{n}>0\\right) \\rightarrow 1$ because $\\widehat{w}_{0}\\left(x_{j}\\right)-c_{n} \\xrightarrow{p} w_{0}\\left(x_{j}\\right)>0$ by $c_{n}=o(1)$ and $w_{0}\\left(x_{j}\\right)>0$, which follows from $x_{j} \\in \\mathcal{X}^{+}$. Therefore, $\\mathbb{P}\\left(x_{j} \\in \\widehat{\\mathcal{X}}^{+}\\right) \\geq \\mathbb{P}\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{1}\\left(X_{i}=x_{j}\\right)>0\\right)+\\mathbb{P}\\left(\\widehat{w}_{0}\\left(x_{j}\\right)>c_{n}\\right)-1 \\rightarrow 1$ as $n \\rightarrow \\infty$.\n\nNow let $x_{j} \\notin \\mathcal{X}^{+}$. Then\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(x_{j} \\notin \\widehat{\\mathcal{X}}^{+}\\right) & =\\mathbb{P}\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{1}\\left(X_{i}=x_{j}\\right)=0 \\cup \\widehat{w}_{0}\\left(x_{j}\\right) \\leq c_{n}\\right) \\\\\n& \\geq \\mathbb{P}\\left(\\widehat{w}_{0}\\left(x_{j}\\right) \\leq c_{n}\\right) \\\\\n& =\\mathbb{P}\\left(\\sqrt{n} \\widehat{w}_{0}\\left(x_{j}\\right) \\leq \\sqrt{n} c_{n}\\right)\n\\end{aligned}\n$$\n\nBy Assumption 6.1, $\\sqrt{n} \\widehat{w}_{0}\\left(x_{j}\\right)=\\sqrt{n}\\left(\\widehat{w}_{0}\\left(x_{j}\\right)-w_{0}\\left(x_{j}\\right)\\right) \\xrightarrow{d} \\mathbb{Z}_{\\mathbf{w}_{0}}(j)=O_{p}(1)$, since $w_{0}\\left(x_{j}\\right)=0$ for $x_{j} \\notin \\mathcal{X}^{+}$. Also $\\sqrt{n} c_{n} \\rightarrow+\\infty$ by the theorem assumption. Therefore, $\\mathbb{P}\\left(\\sqrt{n} \\widehat{w}_{0}\\left(x_{j}\\right) \\leq \\sqrt{n} c_{n}\\right) \\rightarrow 1$ and $\\mathbb{P}\\left(x_{j} \\notin \\widehat{\\mathcal{X}}^{+}\\right) \\rightarrow 1$ as $n \\rightarrow \\infty$. Because of this,\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(\\widehat{\\mathcal{X}}^{+}=\\mathcal{X}^{+}\\right) & =\\mathbb{P}\\left(\\bigcap_{x_{j} \\in \\mathcal{X}^{+}}\\left\\{x_{j} \\in \\widehat{\\mathcal{X}}^{+}\\right\\} \\cap \\bigcap_{x_{j} \\notin \\mathcal{X}^{+}}\\left\\{x_{j} \\notin \\widehat{\\mathcal{X}}^{+}\\right\\}\\right) \\\\\n& =1-\\mathbb{P}\\left(\\bigcup_{x_{j} \\in \\mathcal{X}^{+}}\\left\\{x_{j} \\notin \\widehat{\\mathcal{X}}^{+}\\right\\} \\cup \\bigcup_{x_{j} \\notin \\mathcal{X}^{+}}\\left\\{x_{j} \\in \\widehat{\\mathcal{X}}^{+}\\right\\}\\right) \\\\\n& \\geq 1-\\left(\\sum_{j: x_{j} \\in \\mathcal{X}^{+}} \\mathbb{P}\\left(x_{j} \\notin \\widehat{\\mathcal{X}}^{+}\\right)+\\sum_{j: x_{j} \\notin \\mathcal{X}^{+}} \\mathbb{P}\\left(x_{j} \\in \\widehat{\\mathcal{X}}^{+}\\right)\\right) \\\\\n& \\rightarrow 1-\\left(\\sum_{j: x_{j} \\in \\mathcal{X}^{+}} 0+\\sum_{j: x_{j} \\notin \\mathcal{X}^{+}} 0\\right) \\\\\n& =1\n\\end{aligned}\n$$\n\nUsing this, we obtain\n\n$$\n\\mathbb{P}\\left(\\max _{x \\in \\widehat{\\mathcal{X}}^{+}} \\widehat{a}(x)=\\max _{x \\in \\mathcal{X}^{+}} \\widehat{a}(x)\\right) \\geq \\mathbb{P}\\left(\\widehat{\\mathcal{X}}^{+} \\in \\mathcal{X}^{+}\\right) \\rightarrow 1\n$$\n\nwhich yields\n\n$$\n\\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)=\\max _{x \\in \\widehat{\\mathcal{X}}^{+}} \\widehat{a}(x)=\\max _{x \\in \\mathcal{X}^{+}} \\widehat{a}(x)+o_{p}(1)\n$$\n\nBy the consistency of $\\widehat{\\mathbf{a}}$ for $\\mathbf{a}$, the continuity of the maximum operator, and the continuous mapping theorem, $\\max _{x \\in \\mathcal{X}^{+}} \\widehat{a}(x) \\xrightarrow{p} \\max _{x \\in \\mathcal{X}^{+}} a(x)$. Because $\\mathcal{X}^{+}=\\operatorname{supp}\\left(X \\mid W_{0}=1\\right)$ is a finite set of points, we also have that $\\max _{x \\in \\mathcal{X}^{+}} a(x)=\\sup \\left(\\operatorname{supp}\\left(a(X) \\mid W_{0}=1\\right)\\right)$. Another application of the continuous mapping theorem suffices to show that $\\widehat{\\widetilde{P}}$ is consistent for $\\bar{P}$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 43,
      "text": "# Part 2: Asymptotic Distribution \n\nWe first establish the joint limiting distribution of terms (i) $\\sqrt{n}\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{a}\\left(X_{i}\\right) \\widehat{w}_{0}\\left(X_{i}\\right)-\\mathbb{E}\\left[a(X) w_{0}(X)\\right]\\right)$, (ii) $\\sqrt{n}\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{w}_{0}\\left(X_{i}\\right)-\\mathbb{E}\\left[w_{0}\\left(X_{i}\\right)\\right]\\right)$, and (iii) $\\sqrt{n}\\left(\\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)-\\max _{x \\in \\mathcal{X}^{+}} a(x)\\right)$. The terms (i) and (ii) can be expanded as follows using a first-order expansion:\n\n$$\n\\begin{aligned}\n& \\sqrt{n}\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{a}\\left(X_{i}\\right) \\widehat{w}_{0}\\left(X_{i}\\right)-\\mathbb{E}\\left[a(X) w_{0}(X)\\right]\\right)=\\sqrt{n}\\left(\\sum_{j=1}^{K} \\widehat{a}\\left(x_{j}\\right) \\widehat{w}_{0}\\left(x_{j}\\right) \\widehat{p}_{j}-\\sum_{j=1}^{K} a\\left(x_{j}\\right) w_{0}\\left(x_{j}\\right) p_{j}\\right) \\\\\n& \\quad=\\sum_{j=1}^{K}\\left(w_{0}\\left(x_{j}\\right) p_{j} \\sqrt{n}\\left(\\widehat{a}\\left(x_{j}\\right)-a\\left(x_{j}\\right)\\right)+a\\left(x_{j}\\right) p_{j} \\sqrt{n}\\left(\\widehat{w}_{0}\\left(x_{j}\\right)-w_{0}\\left(x_{j}\\right)\\right)+a\\left(x_{j}\\right) w_{0}\\left(x_{j}\\right) \\sqrt{n}\\left(\\widehat{p}_{j}-p_{j}\\right)\\right)+o_{p}(1)\n\\end{aligned}\n$$\n\nand\n\n$$\n\\begin{aligned}\n& \\sqrt{n}\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{w}_{0}\\left(X_{i}\\right)-\\mathbb{E}\\left[w_{0}(X)\\right]\\right)=\\sqrt{n}\\left(\\sum_{j=1}^{K} \\widehat{w}_{0}\\left(x_{j}\\right) \\widehat{p}_{j}-\\sum_{j=1}^{K} w_{0}\\left(x_{j}\\right) p_{j}\\right) \\\\\n& \\quad=\\sum_{j=1}^{K}\\left(p_{j} \\sqrt{n}\\left(\\widehat{w}_{0}\\left(x_{j}\\right)-w_{0}\\left(x_{j}\\right)\\right)+w_{0}\\left(x_{j}\\right) \\sqrt{n}\\left(\\widehat{p}_{j}-p_{j}\\right)\\right)+o_{p}(1)\n\\end{aligned}\n$$\n\nFor term (iii), we use the expansion\n\n$$\n\\begin{aligned}\n\\sqrt{n}\\left(\\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)-\\max _{x \\in \\mathcal{X}^{+}} a(x)\\right) & =\\sqrt{n}\\left(\\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)-\\max _{x \\in \\mathcal{X}^{+}} \\widehat{a}(x)\\right) \\\\\n& +\\sqrt{n}\\left(\\max _{x \\in \\mathcal{X}^{+}} \\widehat{a}(x)-\\max _{x \\in \\mathcal{X}^{+}} a(x)\\right)\n\\end{aligned}\n$$\n\nThe term in (E.3) is of order $o_{p}(1)$ because\n\n$$\n\\mathbb{P}\\left(\\sqrt{n}\\left(\\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)-\\max _{x \\in \\mathcal{X}^{+}} \\widehat{a}(x)\\right)=0\\right)=\\mathbb{P}\\left(\\max _{x \\in \\widehat{\\mathcal{X}}^{+}} \\widehat{a}(x)=\\max _{x \\in \\mathcal{X}^{+}} \\widehat{a}(x)\\right) \\geq \\mathbb{P}\\left(\\widehat{\\mathcal{X}}^{+} \\in \\mathcal{X}^{+}\\right) \\rightarrow 1\n$$\n\nas shown above.\nThe term in (E.4) can be analyzed using Theorem 2.1 in Fang and Santos (2019), which generalizes the delta method to the class of Hadamard directionally differentiable functions. Using Lemma E.1, we have\n\nthat\n\n$$\n\\begin{aligned}\n\\sqrt{n}\\left(\\max _{x \\in \\mathcal{X}^{+}} \\widehat{a}(x)-\\max _{x \\in \\mathcal{X}^{+}} a(x)\\right) & =\\max _{x_{j} \\in \\arg \\max _{x \\in \\mathcal{X}^{+}} a(x)} \\sqrt{n}\\left(\\widehat{a}\\left(x_{j}\\right)-a\\left(x_{j}\\right)\\right)+o_{p}(1) \\\\\n& :=\\max _{j \\in \\widehat{\\Psi}_{X^{+}}} \\sqrt{n}\\left(\\widehat{a}\\left(x_{j}\\right)-a\\left(x_{j}\\right)\\right)+o_{p}(1)\n\\end{aligned}\n$$\n\nCombining the expressions in (E.1), (E.2), and (E.5) with the delta method yields\n\n$$\n\\begin{aligned}\n\\sqrt{n}(\\widehat{P}-\\bar{P})= & \\frac{1}{\\mathbb{P}\\left(W_{0}=1\\right) \\max _{x \\in \\mathcal{X}^{+}} a(x)} \\sum_{j=1}^{K}\\left(w_{0}\\left(x_{j}\\right) p_{j} \\sqrt{n}\\left(\\widehat{a}\\left(x_{j}\\right)-a\\left(x_{j}\\right)\\right)+a\\left(x_{j}\\right) p_{j} \\sqrt{n}\\left(\\widehat{w}_{0}\\left(x_{j}\\right)-w_{0}\\left(x_{j}\\right)\\right)\\right. \\\\\n& \\left.+a\\left(x_{j}\\right) w_{0}\\left(x_{j}\\right) \\sqrt{n}\\left(\\widehat{p}_{j}-p_{j}\\right)\\right) \\\\\n& -\\frac{\\mathbb{E}[a(X) \\mid W_{0}=1]}{\\mathbb{P}\\left(W_{0}=1\\right) \\max _{x \\in \\mathcal{X}^{+}} a(x)} \\sum_{j=1}^{K}\\left(p_{j} \\sqrt{n}\\left(\\widehat{w}_{0}\\left(x_{j}\\right)-w_{0}\\left(x_{j}\\right)\\right)+w_{0}\\left(x_{j}\\right) \\sqrt{n}\\left(\\widehat{p}_{j}-p_{j}\\right)\\right) \\\\\n& -\\frac{\\mathbb{E}[a(X) \\mid W_{0}=1]}{\\max _{x \\in \\mathcal{X}^{+}} a(x)^{2}} \\max _{j \\in \\widehat{\\Psi}_{X^{+}}} \\sqrt{n}\\left(\\widehat{a}\\left(x_{j}\\right)-a\\left(x_{j}\\right)\\right)+o_{p}(1) \\\\\n& =\\psi\\left(\\sqrt{n}(\\widehat{\\mathbf{a}}-\\mathbf{a}), \\sqrt{n}\\left(\\widehat{\\mathbf{w}}_{0}-\\mathbf{w}_{0}\\right), \\sqrt{n}(\\widehat{\\mathbf{p}}-\\mathbf{p})\\right)+o_{p}(1) \\\\\n& \\xrightarrow{d} \\psi(\\mathbb{Z})\n\\end{aligned}\n$$\n\nby the continuity of $\\psi$ and Assumption 6.1.\nProof of Theorem 6.2. We verify the validity of the bootstrap by appealing to Theorem 3.2 in Fang and Santos (2019). We show that their Assumption 4 holds by showing the mapping $\\widehat{\\psi}$ satisfies $\\left|\\widehat{\\psi}\\left(h^{\\prime}\\right)-\\widehat{\\psi}(h)\\right| \\leq$ $C_{n}\\left\\|h^{\\prime}-h\\right\\|$ for any $h^{\\prime}, h \\in \\mathbb{R}^{3 K}$ and for $C_{n}=O_{p}(1)$, and by showing that $\\widehat{\\psi}(h) \\xrightarrow{p} \\psi(h)$ for all $h \\in \\mathbb{R}^{3 K}$.\n\nLet $h=\\left(h_{1}, h_{2}, h_{3}\\right)$ and $h^{\\prime}=\\left(h_{1}^{\\prime}, h_{2}^{\\prime}, h_{3}^{\\prime}\\right)$.\n\n$$\n\\begin{aligned}\n\\left|\\widehat{\\psi}\\left(h^{\\prime}\\right)-\\widehat{\\psi}(h)\\right| & \\leq\\left|\\sum_{j=1}^{K} \\frac{\\widehat{w}_{0}\\left(x_{j}\\right) \\widehat{p}_{j}}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right) \\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)}\\left(h_{1}^{\\prime}(j)-h_{1}(j)\\right)\\right| \\\\\n& +\\left|\\frac{\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]}{\\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)^{2}}\\left(\\max _{j \\in \\widehat{\\Psi}_{X^{+}}} h_{1}^{\\prime}(j)-\\max _{j \\in \\widehat{\\Psi}_{X^{+}}} h_{1}(j)\\right)\\right| \\\\\n& +\\left|\\sum_{j=1}^{K} \\frac{\\left(\\widehat{a}\\left(x_{j}\\right)-\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]\\right) \\widehat{p}_{j}}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right) \\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)}\\left(h_{2}^{\\prime}(j)-h_{2}(j)\\right)\\right| \\\\\n& +\\left|\\sum_{j=1}^{K} \\frac{\\left(\\widehat{a}\\left(x_{j}\\right)-\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]\\right) \\widehat{w}_{0}\\left(x_{j}\\right)}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right) \\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)}\\left(h_{3}^{\\prime}(j)-h_{3}(j)\\right)\\right| \\\\\n& \\leq\\left(\\sum_{j=1}^{K} \\frac{\\widehat{w}_{0}\\left(x_{j}\\right)^{2} \\widehat{p}_{j}^{2}}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right)^{2} \\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)^{2}}\\right)^{1 / 2}\\left\\|h_{1}^{\\prime}-h_{1}\\right\\| \\\\\n& +\\frac{\\left|\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]\\right|}{\\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)^{2}}\\left|\\max _{j \\in \\widehat{\\Psi}_{X^{+}}} h_{1}^{\\prime}(j)-\\max _{j \\in \\widehat{\\Psi}_{X^{+}}} h_{1}(j)\\right| \\\\\n& +\\left(\\sum_{j=1}^{K} \\frac{\\left(\\widehat{a}\\left(x_{j}\\right)-\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]\\right)^{2} \\widehat{p}_{j}^{2}}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right)^{2} \\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)^{2}}\\right)^{1 / 2}\\left\\|h_{2}^{\\prime}-h_{2}\\right\\|\n\\end{aligned}\n$$\n\n$$\n+\\left(\\sum_{j=1}^{K} \\frac{\\left(\\widehat{a}\\left(x_{j}\\right)-\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]\\right)^{2} \\widehat{w}_{0}\\left(x_{j}\\right)^{2}}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right)^{2} \\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)^{2}}\\right)^{1 / 2}\\left\\|h_{3}^{\\prime}-h_{3}\\right\\|\n$$\n\nwhere we applied the Cauchy-Schwarz inequality several times. Note that the maximum function is Lipschitz with Lipschitz constant one and therefore\n\n$$\n\\begin{aligned}\n\\left|\\max _{j \\in \\widehat{\\Psi}_{\\mathcal{X}^{+}}} h_{1}^{\\prime}(j)-\\max _{j \\in \\widehat{\\Psi}_{\\mathcal{X}^{+}}} h_{1}(j)\\right| & \\leq \\sum_{j \\in \\widehat{\\Psi}_{\\mathcal{X}^{+}}}\\left|h_{1}^{\\prime}(j)-h_{1}(j)\\right| \\\\\n& \\leq \\sum_{j=1}^{K}\\left|h_{1}^{\\prime}(j)-h_{1}(j)\\right| \\\\\n& \\leq \\sqrt{K}\\left\\|h_{1}^{\\prime}-h_{1}\\right\\|\n\\end{aligned}\n$$\n\nCombining equations (E.6)-(E.9) with the consistency of $\\left(\\widehat{\\mathbf{a}}, \\widehat{\\mathbf{w}}_{0}, \\widehat{\\mathbf{p}}\\right)$ established in Theorem 6.1 shows that $\\left|\\widehat{\\psi}\\left(h^{\\prime}\\right)-\\widehat{\\psi}(h)\\right| \\leq C_{n}\\left\\|h^{\\prime}-h\\right\\|$ for any $h^{\\prime}, h \\in \\mathbb{R}^{3 K}$ and for $C_{n}=O_{p}(1)$. Therefore, by Remark 3.4 in Fang and Santos (2019), showing $\\widehat{\\psi}(h) \\xrightarrow{p} \\psi(h)$ for all $h \\in \\mathbb{R}^{3 K}$ suffices.\n\nThus we now consider the consistency of the different components of $\\widehat{\\psi}(h)$. Applying Theorem 6.1, we can show that\n\n$$\n\\begin{aligned}\n\\sum_{j=1}^{K} \\frac{\\widehat{w}_{0}\\left(x_{j}\\right) \\widehat{p}_{j}}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right) \\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)} h_{1}(j) & =\\sum_{j=1}^{K} \\frac{w_{0}\\left(x_{j}\\right) p_{j}}{\\mathbb{P}\\left(W_{0}=1\\right) \\sup _{x \\in \\mathcal{X}^{+}} a(x)} h_{1}(j)+o_{p}(1) \\\\\n\\frac{\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]}{\\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)^{2}} & =\\frac{\\mathbb{E}[a(X) \\mid W_{0}=1]}{\\sup _{x \\in \\mathcal{X}^{+}} a(x)^{2}}+o_{p}(1) \\\\\n\\sum_{j=1}^{K} \\frac{\\left(\\widehat{a}\\left(x_{j}\\right)-\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]\\right) \\widehat{p}_{j}}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right) \\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)} h_{2}(j) & =\\sum_{j=1}^{K} \\frac{\\left(a\\left(x_{j}\\right)-\\mathbb{E}[a(X) \\mid W_{0}=1]\\right) p_{j}}{\\mathbb{P}\\left(W_{0}=1\\right) \\sup _{x \\in \\mathcal{X}^{+}} a(x)} h_{2}(j)+o_{p}(1) \\\\\n\\sum_{j=1}^{K} \\frac{\\left(\\widehat{a}\\left(x_{j}\\right)-\\widehat{\\mathbb{E}}[a(X) \\mid W_{0}=1]\\right) \\widehat{w}_{0}\\left(x_{j}\\right)}{\\widehat{\\mathbb{P}}\\left(W_{0}=1\\right) \\max _{i: \\widehat{w}_{0}\\left(X_{i}\\right)>c_{n}} \\widehat{a}\\left(X_{i}\\right)} h_{3}(j) & =\\sum_{j=1}^{K} \\frac{\\left(a\\left(x_{j}\\right)-\\mathbb{E}[a(X) \\mid W_{0}=1]\\right) w_{0}\\left(x_{j}\\right)}{\\mathbb{P}\\left(W_{0}=1\\right) \\sup _{x \\in \\mathcal{X}^{+}} a(x)} h_{3}(j)+o_{p}(1)\n\\end{aligned}\n$$\n\nIt remains to show that $\\max _{j \\in \\widehat{\\Psi}_{\\mathcal{X}^{+}}} h_{1}(j)=\\max _{j \\in \\Psi_{\\mathcal{X}^{+}}} h_{1}(j)+o_{p}(1)$. This holds if the set $\\widehat{\\Psi}_{\\mathcal{X}^{+}}$is consistent for $\\Psi_{\\mathcal{X}^{+}}$, which we establish here. Let $k \\in \\Psi_{\\mathcal{X}^{+}}$. Then,\n\n$$\n\\begin{aligned}\n\\mathbb{P}\\left(k \\in \\widehat{\\Psi}_{\\mathcal{X}^{+}}\\right) & =\\mathbb{P}\\left(\\widehat{a}\\left(x_{k}\\right) \\geq \\max _{j \\in \\mathcal{X}^{+}} \\widehat{a}\\left(x_{j}\\right)-\\xi_{n}\\right) \\\\\n& =\\mathbb{P}\\left(\\sqrt{n}\\left(\\widehat{a}\\left(x_{k}\\right)-\\max _{j \\in \\mathcal{X}^{+}} \\widehat{a}\\left(x_{j}\\right)\\right) \\geq-\\sqrt{n} \\xi_{n}\\right) \\\\\n& =\\mathbb{P}\\left(\\sqrt{n}\\left(\\max _{j \\in \\mathcal{X}^{+}} \\widehat{a}\\left(x_{j}\\right)-\\max _{j \\in \\mathcal{X}^{+}} \\widehat{a}\\left(x_{j}\\right)\\right) \\geq-\\sqrt{n} \\xi_{n}\\right)\n\\end{aligned}\n$$\n\nThe third equality follows from $k \\in \\Psi_{\\mathcal{X}^{+}}$. By the proof of Theorem 6.1, $\\sqrt{n}\\left(\\max _{j \\in \\mathcal{X}^{+}} \\widehat{a}\\left(x_{j}\\right)-\\max _{j \\in \\mathcal{X}^{+}} \\widehat{a}\\left(x_{j}\\right)\\right)=$ $o_{p}(1)$. Since $-\\sqrt{n} \\xi_{n} \\rightarrow-\\infty, \\mathbb{P}\\left(k \\in \\widehat{\\Psi}_{\\mathcal{X}^{+}}\\right) \\rightarrow \\mathbb{P}(0 \\geq-\\infty)=1$ when $k \\in \\Psi_{\\mathcal{X}^{+}}$.\n\nNow suppose that $k \\notin \\Psi_{\\mathcal{X}^{+}}$. Then,\n\n$$\n\\mathbb{P}\\left(k \\in \\widehat{\\Psi}_{\\mathcal{X}^{+}}\\right)=\\mathbb{P}\\left(\\widehat{a}\\left(x_{k}\\right) \\geq \\max _{j \\in \\mathcal{X}^{+}} \\widehat{a}\\left(x_{j}\\right)-\\xi_{n}\\right)\n$$\n\n$$\n\\rightarrow \\mathbb{P}\\left(a\\left(x_{k}\\right) \\geq \\max _{j \\in \\mathcal{X}^{+}} a\\left(x_{j}\\right)-0\\right)=0\n$$\n\nwhere the last equality holds from $k \\notin \\Psi_{\\mathcal{X}^{+}}$. Therefore, $\\mathbb{P}\\left(\\widetilde{\\Psi}_{\\mathcal{X}^{+}}=\\Psi_{\\mathcal{X}^{+}}\\right) \\rightarrow 1$ as $n \\rightarrow \\infty$. This implies $\\widetilde{\\psi}(h) \\xrightarrow{p} \\psi(h)$, which concludes the proof.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 44,
      "text": "# F Proofs for Appendix A \n\nProof of Proposition A.1. By Theorem 3.1, $\\mu\\left(a, \\tau_{0}\\right)$ has a uniform causal representation in $\\mathcal{T}_{\\text {all }}$ if and only if $a\\left(x_{k}\\right) \\geq 0$ for $k \\in\\{1, \\ldots, K\\}$. Therefore, it is sufficient to show the equivalence between weakly causal estimands and estimands with nonnegative weights. A similar result was shown in Proposition 4 of BBMT, but we nevertheless provide a proof here to account for the slight differences in notation.\n\nSuppose $\\mu\\left(a, \\tau_{0}\\right)$ is weakly causal. Let $\\nu_{1}=\\left(\\mathbb{1}\\left(a\\left(x_{1}\\right)<0\\right), \\ldots, \\mathbb{1}\\left(a\\left(x_{K}\\right)<0\\right)\\right)\\right.$ and $\\nu_{0}=\\mathbf{0}_{K}$. Trivially, $\\left(\\nu_{1}, \\nu_{0}\\right) \\in \\mathcal{M}_{\\text {all }}$ and $\\tau^{-}:=\\nu_{1}-\\nu_{0} \\in \\mathcal{T}_{\\text {all }}$, where $\\tau^{-} \\geq \\mathbf{0}_{K}$. Since $\\mu\\left(a, \\tau_{0}\\right)$ is weakly causal, $\\mu\\left(a, \\tau^{-}\\right) \\geq 0$ where\n\n$$\n\\mu\\left(a, \\tau^{-}\\right)=\\frac{\\mathbb{E}\\left[a(X) \\tau^{-}(X) \\mid W_{0}=1\\right]}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]}=\\frac{1}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]} \\sum_{k=1}^{K} a\\left(x_{k}\\right) \\mathbb{1}\\left(a\\left(x_{k}\\right)<0\\right) \\mathbb{P}\\left(X=x_{k} \\mid W_{0}=1\\right) \\geq 0\n$$\n\nThis implies $a\\left(x_{k}\\right) \\geq 0$ for all $k \\in\\{1, \\ldots, K\\}$. Thus, $\\mu\\left(a, \\tau_{0}\\right)$ has a uniform causal representation in $\\mathcal{T}_{\\text {all }}$.\nNow suppose $\\mu\\left(a, \\tau_{0}\\right)$ has a uniform causal representation in $\\mathcal{T}_{\\text {all }}$, or that $a\\left(x_{k}\\right) \\geq 0$ for $k=1, \\ldots, K$. Then, for any $\\left(\\nu_{0}, \\nu_{1}\\right) \\in \\mathcal{M}_{\\text {all }}$ such that $\\tau:=\\nu_{1}-\\nu_{0} \\geq \\mathbf{0}_{K}$, we have that\n\n$$\n\\mu(a, \\tau)=\\frac{1}{\\mathbb{E}\\left[a(X) \\mid W_{0}=1\\right]} \\sum_{k=1}^{K} a\\left(x_{k}\\right) \\tau\\left(x_{k}\\right) \\mathbb{P}\\left(X=x_{k} \\mid W_{0}=1\\right) \\geq 0\n$$\n\nThe inequality holds because $a\\left(x_{k}\\right)$ and $\\tau\\left(x_{k}\\right)$ are nonnegative for all $k \\in\\{1, \\ldots, K\\}$. This last inequality is reversed if we instead assume that $\\tau \\leq \\mathbf{0}_{K}$. Thus, $\\mu\\left(a, \\tau_{0}\\right)$ is weakly causal.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 45,
      "text": "## G Difference-in-Differences\n\nGoodman-Bacon (2021) provides the following representation of the two-way fixed effects estimand under the assumption that group-level average treatment effects are constant over time:\n\n$$\n\\beta_{\\text {TWFE }}=\\sum_{k: \\operatorname{var}(D \\mid G=k)>0}\\left[\\sum_{j=1}^{k-1} \\sigma_{j k}^{k}+\\sum_{j=k+1}^{K} \\sigma_{k j}^{k}\\right] \\cdot \\mathbb{E}[Y(1)-Y(0) \\mid G=k, D=1]\n$$\n\nwhere\n\n$$\n\\sigma_{j k}^{k}=\\frac{\\mathbb{P}(G=j) \\cdot \\mathbb{P}(G=k) \\cdot \\mathbb{P}(D=1 \\mid G=k) \\cdot[\\mathbb{P}(D=1 \\mid G=j)-\\mathbb{P}(D=1 \\mid G=k)]}{\\operatorname{var}\\left(D^{\\perp\\left(G_{i_{1}}, \\ldots, G_{i_{K-1}}, P_{1}, \\ldots, P_{T}\\right)}\\right)}\n$$\n\nand\n\n$$\n\\sigma_{k j}^{k}=\\frac{\\mathbb{P}(G=j) \\cdot \\mathbb{P}(G=k) \\cdot[1-\\mathbb{P}(D=1 \\mid G=k)][\\mathbb{P}(D=1 \\mid G=k)-\\mathbb{P}(D=1 \\mid G=j)]}{\\operatorname{var}\\left(D^{\\perp\\left(G_{i_{1}}, \\ldots, G_{i_{K-1}}, P_{1}, \\ldots, P_{T}\\right)}\\right)}\n$$\n\nHere $A^{\\perp B}$ is used to denote the residual in the linear projection of $A$ on $(1, B)$. It is also the case that $\\sum_{k: \\operatorname{var}(D \\mid G=k)>0} \\sum_{l>k}\\left(\\sigma_{k l}^{k}+\\sigma_{k l}^{l}\\right)=1 .{ }^{7}$ When we compare this representation with Proposition 5.4, that is,\n\n$$\n\\begin{aligned}\n\\beta_{\\text {TWFE }} & =\\frac{\\mathbb{E}\\left[a_{\\text {TWFE }, \\mathrm{H}}(G) \\cdot \\mathbb{P}(D=1 \\mid G) \\cdot \\mathbb{E}[Y(1)-Y(0) \\mid G, D=1]\\right]}{\\mathbb{E}\\left[a_{\\text {TWFE }, \\mathrm{H}}(G) \\cdot \\mathbb{P}(D=1 \\mid G)\\right]} \\\\\n& =\\frac{\\sum_{k: \\operatorname{var}(D \\mid G=k)>0} \\mathbb{P}(G=k) \\cdot a_{\\text {TWFE,H }}(k) \\cdot \\mathbb{P}(D=1 \\mid G=k) \\cdot \\mathbb{E}[Y(1)-Y(0) \\mid G=k, D=1]}{\\sum_{k: \\operatorname{var}(D \\mid G=k)>0} \\mathbb{P}(G=k) \\cdot a_{\\text {TWFE,H }}(k) \\cdot \\mathbb{P}(D=1 \\mid G=k)}\n\\end{aligned}\n$$\n\nit becomes clear that, for each group $k$ other than the always treated and the never treated,\n\n$$\n\\begin{aligned}\na_{\\text {TWFE,H }}(k) \\cdot \\mathbb{P}(D=1 \\mid G=k) & =\\sum_{j=1}^{k-1} \\mathbb{P}(G=j) \\cdot \\mathbb{P}(D=1 \\mid G=k) \\cdot[\\mathbb{P}(D=1 \\mid G=j)-\\mathbb{P}(D=1 \\mid G=k)] \\\\\n& +\\sum_{j=k+1}^{K} \\mathbb{P}(G=j) \\cdot[1-\\mathbb{P}(D=1 \\mid G=k)][\\mathbb{P}(D=1 \\mid G=k)-\\mathbb{P}(D=1 \\mid G=j)]\n\\end{aligned}\n$$\n\nand this, in turn, implies that\n\n$$\n\\begin{aligned}\na_{\\text {TWFE,H }}(k) & =\\sum_{j=1}^{k-1} \\mathbb{P}(G=j) \\cdot[\\mathbb{P}(D=1 \\mid G=j)-\\mathbb{P}(D=1 \\mid G=k)] \\\\\n& +\\sum_{j=k+1}^{K} \\mathbb{P}(G=j) \\cdot[\\mathbb{P}(D=1 \\mid G=k)-\\mathbb{P}(D=1 \\mid G=j)] \\cdot \\frac{1-\\mathbb{P}(D=1 \\mid G=k)}{\\mathbb{P}(D=1 \\mid G=k)}\n\\end{aligned}\n$$",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 46,
      "text": "# G. 1 Equivalence of Weight Functions \n\nWe now show that the weights obtained in equation (G.1) are equivalent to those in Proposition 5.4. First, we rewrite the weights in (G.1) as follows:\n\n$$\n\\begin{aligned}\na_{\\text {TWFE,H }}(k)= & \\sum_{j=1}^{k-1} \\mathbb{P}(G=j) \\cdot[\\mathbb{P}(D=1 \\mid G=j)-\\mathbb{P}(D=1 \\mid G=k)] \\\\\n+ & \\sum_{j=k+1}^{K} \\mathbb{P}(G=j) \\cdot[\\mathbb{P}(D=1 \\mid G=k)-\\mathbb{P}(D=1 \\mid G=j)] \\cdot \\frac{1-\\mathbb{P}(D=1 \\mid G=k)}{\\mathbb{P}(D=1 \\mid G=k)} \\\\\n= & \\mathbb{P}(D=1, G<k)-\\mathbb{P}(G<k) \\mathbb{E}[D \\mid G=k]+(1-\\mathbb{E}[D \\mid G=k]) \\mathbb{P}(G>k) \\\\\n& -\\frac{1-\\mathbb{E}[D \\mid G=k]}{\\mathbb{E}[D \\mid G=k]} \\mathbb{P}(D=1, G>k) \\\\\n= & \\mathbb{P}(D=1, G<k)-\\mathbb{P}(G<k) \\mathbb{E}[D \\mid G=k]+\\mathbb{P}(G>k)-\\mathbb{E}[D \\mid G=k] \\mathbb{P}(G>k) \\\\\n& -\\frac{1}{\\mathbb{E}[D \\mid G=k]} \\mathbb{P}(D=1, G>k)+\\mathbb{P}(D=1, G>k) \\\\\n= & \\mathbb{P}(D=1, G \\neq k)-\\mathbb{E}[D \\mid G=k] \\mathbb{P}(G \\neq k)+\\mathbb{P}(G>k)\\left(1-\\frac{\\mathbb{E}[D \\mid G>k]}{\\mathbb{E}[D \\mid G=k]}\\right) \\\\\n= & (\\mathbb{E}[D]-\\mathbb{E}[D \\mid G=k] \\mathbb{P}(G=k))-\\mathbb{E}[D \\mid G=k] \\mathbb{P}(G \\neq k)+\\mathbb{P}(G>k)\\left(1-\\frac{\\mathbb{E}[D \\mid G>k]}{\\mathbb{E}[D \\mid G=k]}\\right)\n\\end{aligned}\n$$\n\n[^0]\n[^0]:    ${ }^{7}$ The result in Goodman-Bacon (2021) technically also includes a weight $\\sigma_{k U}$ attached to the contrast between group $k$ and the never-treated group. We subsume this weight under $\\sigma_{k j}^{k}$, and likewise subsume the weight on the contrast with the always-treated group under $\\sigma_{j k}^{k}$.\n\n$$\n=\\mathbb{E}[D]-\\mathbb{E}[D \\mid G=k]+\\mathbb{P}(G>k)\\left(1-\\frac{\\mathbb{E}[D \\mid G>k]}{\\mathbb{E}[D \\mid G=k]}\\right)\n$$\n\nFor $k \\in\\{2, \\ldots, T\\}$, the weights in Proposition 5.4 are equal to\n\n$$\n\\mathbb{E}[1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D] \\mid G=k]=1-\\mathbb{E}[D \\mid G=k]-\\mathbb{E}[D \\mid P \\geq k]+\\mathbb{E}[D]\n$$\n\nbecause they are the average of the weights in Proposition 5.3 conditional on $G=k$. The proof of Proposition 5.4 explicitly shows that\n\n$$\n\\mathbb{E}[1-\\mathbb{E}[D \\mid G]-\\mathbb{E}[D \\mid P]+\\mathbb{E}[D] \\mid G=k]=\\mathbb{P}(D=0 \\mid G=k) \\cdot(\\mathbb{P}(D=0 \\mid P \\geq k)+\\mathbb{P}(D=1 \\mid P<g))\n$$\n\nLet us look at the difference between the weights in (G.1) and (G.2). Fix $k \\in\\{2, \\ldots, T\\}$ and write\n\n$$\n\\begin{aligned}\n& (1-\\mathbb{E}[D \\mid G=k]-\\mathbb{E}[D \\mid P \\geq k]+\\mathbb{E}[D])-\\left(\\mathbb{E}[D]-\\mathbb{E}[D \\mid G=k]+\\mathbb{P}(G>k)\\left(1-\\frac{\\mathbb{E}[D \\mid G>k]}{\\mathbb{E}[D \\mid G=k]}\\right)\\right) \\\\\n& =1-\\mathbb{E}[D \\mid P \\geq k]-\\mathbb{P}(G>k)+\\frac{\\mathbb{E}[D \\mathbb{1}(G>k)]}{\\mathbb{E}[D \\mid G=k]} \\\\\n& =\\mathbb{E}[\\mathbb{1}(G \\leq k)]-\\frac{\\mathbb{E}[D \\mathbb{1}(P \\geq k)]}{\\mathbb{E}[\\mathbb{1}(P \\geq k)]}+\\frac{\\mathbb{E}[D \\mathbb{1}(G>k)]}{\\mathbb{E}[\\mathbb{1}(k \\leq P)]} \\\\\n& =\\frac{1}{\\mathbb{E}[\\mathbb{1}(k \\leq P)]}\\left(F_{G}(k) \\mathbb{E}[\\mathbb{1}(k \\leq P)]+\\mathbb{E}[D \\mathbb{1}(G>k)]-\\mathbb{E}[D \\mathbb{1}(P \\geq k)]\\right) \\\\\n& =\\frac{1}{\\mathbb{E}[\\mathbb{1}(k \\leq P)]}\\left(F_{G}(k) \\mathbb{E}[\\mathbb{1}(k \\leq P)]+\\mathbb{E}[\\mathbb{1}(k<G \\leq P)]-\\mathbb{E}[\\mathbb{E}[D \\mid P] \\mathbb{1}(P \\geq k)]\\right) \\\\\n& =\\frac{1}{\\mathbb{E}[\\mathbb{1}(k \\leq P)]}\\left(F_{G}(k) \\mathbb{E}[\\mathbb{1}(k \\leq P)]+\\mathbb{E}[\\mathbb{E}[\\mathbb{1}(k<G \\leq P) \\mid P]]-\\mathbb{E}\\left[F_{G}(P) \\mathbb{1}(P \\geq k)\\right]\\right) \\\\\n& =\\frac{1}{\\mathbb{E}[\\mathbb{1}(k \\leq P)]}\\left(F_{G}(k) \\mathbb{E}[\\mathbb{1}(k \\leq P)]+\\mathbb{E}\\left[\\left(F_{G}(P)-F_{G}(k)\\right) \\mathbb{1}(P \\geq k)\\right]-\\mathbb{E}\\left[F_{G}(P) \\mathbb{1}(P \\geq k)\\right]\\right) \\\\\n& =\\frac{1}{\\mathbb{E}[\\mathbb{1}(k \\leq P)]}\\left(F_{G}(k) \\mathbb{E}[\\mathbb{1}(k \\leq P)]+\\mathbb{E}\\left[F_{G}(P) \\mathbb{1}(P \\geq k)\\right]-F_{G}(k) \\mathbb{E}[\\mathbb{1}(P \\geq k)]-\\mathbb{E}\\left[F_{G}(P) \\mathbb{1}(P \\geq k)\\right]\\right) \\\\\n& =0\n\\end{aligned}\n$$\n\nTherefore, the weights in Proposition 5.4 and equations (G.1) and (G.2) are all equal to one another.",
      "tables": {},
      "images": {}
    }
  ],
  "id": "2404.14603v2",
  "authors": [
    "Alexandre Poirier",
    "Tymon S\u0142oczy\u0144ski"
  ],
  "categories": [
    "econ.EM",
    "stat.ME"
  ],
  "abstract": "In this paper we study a class of weighted estimands, which we define as\nparameters that can be expressed as weighted averages of the underlying\nheterogeneous treatment effects. The popular ordinary least squares (OLS),\ntwo-stage least squares (2SLS), and two-way fixed effects (TWFE) estimands are\nall special cases within our framework. Our focus is on answering two questions\nconcerning weighted estimands. First, under what conditions can they be\ninterpreted as the average treatment effect for some (possibly latent)\nsubpopulation? Second, when these conditions are satisfied, what is the upper\nbound on the size of that subpopulation, either in absolute terms or relative\nto a target population of interest? We argue that this upper bound provides a\nvaluable diagnostic for empirical research. When a given weighted estimand\ncorresponds to the average treatment effect for a small subset of the\npopulation of interest, we say its internal validity is low. Our paper develops\npractical tools to quantify the internal validity of weighted estimands.",
  "updated": "2025-03-24T23:38:22Z",
  "published": "2024-04-22T21:59:33Z"
}