{"title": "Canonical insurance models: stochastic equations and comparison theorems", "sections": [{"section_id": 0, "text": "## 1 Introduction\n\nIn actuarial science, safe-side calculations for the prospective reserve based on prudent actuarial bases date back to at least [Lidstone, 1905]. In modern times, safe-side calculation results for survival models [Norberg, 1985] have been extended to first Markov models [Hoem, 1988, Ramlau-Hansen, 1988, Linnemann, 1993] and later semi-Markov models [Niemeyer, 2015]. The main idea is to carefully analyze the dynamics of the so-called state-wise prospective reserves, described by the celebrated Thiele equation, which allows for the comparison of differing insurance models. Beyond safe-side calculations, such comparison results are essential to modern life insurance mathematics in both resolving the circularity that arises from (implicitly defined) reservedependent payments and in the development of efficient computational schemes [Cantelli, 1914, Norberg, 1991, Milbrodt and Stracke, 1997, Milbrodt and Helbig, 2008, Christiansen et al., 2014].\n\nAnother emerging theme in stochastics relates to model uncertainty and robustness. There is an increasing interest in 'model lean' or 'model free' approaches. In actuarial multi-state modeling, this is reflected by a recent movement from Markov over semi-Markov [Christiansen, 2012,\n\nBuchardt et al., 2015, Ahmad et al., 2023, Bladt et al., 2023]towards so-called non-Markov modeling [Christiansen and Furrer, 2021, Christiansen, 2021, Furrer, 2022, Bathke and Furrer, 2024]. A similar tendency can be observed in the biostatistics literature [Putter and Spitoni, 2018, Overgaard, 2019, Maltzhan et al., 2021, Nie\u00dfl et al., 2023].\n\nIn this paper, we derive actuarial comparison theorems for finite state space models with no restrictions whatsoever on the intertemporal dependence structure. In that sense, our approach is 'model lean'. Given a canonical insurance model $(\\alpha, \\Lambda, \\Phi, B, b)$ in accordance with Definition 7.1, which consists of an initial distribution $\\alpha$, transition rates $\\Lambda$, interest rates $\\Phi$, sojourn payments $B$, and transition payments $b$, we show that the corresponding state-wise prospective reserves $\\left(V^{i}\\right)$ uniquely and surely (path-wise) solve the backward equation\n\n$$\n0=\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-)\\left(V^{i}(\\mathrm{~d} t)+B^{i}(\\mathrm{~d} t)-V^{i}(t-) \\Phi^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(b^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\\right)\n$$\n\nwith boundary condition $V^{i}(T)=0$ and with $I^{i}$ indicating whether the process is currently in state $i$, see Theorem 7.2. This stochastic Thiele equation is then used to establish a wide range of actuarial comparison theorems. Classic results for Markov processes are fully recovered and further refined.\n\nThe first stochastic Thiele equation may be found in [Norberg, 1992], but with no clarification on uniqueness of the solution and lack of clarity in the associated definition of state-wise prospective reserves. The latter was already noted in [Norberg, 1996], but not rigorously resolved until investigated in [Christiansen and Furrer, 2021]. However, the stochastic Thiele equation proposed in [Christiansen and Furrer, 2021] is only an almost sure equation, which can be problematic for comparisons between non-equivalent probabilistic models (actuarial bases). Contrary to [Christiansen and Furrer, 2021], this paper adopts a canonical approach which allows for pathwise statements.\n\nOur canonical approach takes its inspiration from [Jacobsen, 2006], which has hitherho received limited attention in the actuarial literature, see however [Furrer, 2022]. Different from [Jacobsen, 2006], we take not the distribution of the marked point process or even the compensators of the multivariate counting process as the starting point, but rather so-called (cumulative) transition rates. This comes with its own technical intricacies, but has the advantage that it offers a natural connection to Markov modeling - corresponding to deterministic transition rates - as well as the industry practice of composing and applying actuarial risk tables. The approach covers absolutely continuous as well as discrete modeling; both are currently common. Central to both approaches, Jacobsen's and ours, are sure representations for c\u00e0dl\u00e0g martingales. However, Jacobsen takes the existence of a c\u00e0dl\u00e0g modification as given, while we offer an actual construction.\n\nIn [Christiansen and Djehiche, 2020] an alternative approach based on backward stochastic differential equations is pursued, also aiming at resolving the circularity arising from implicitly defined payments. The advantage of the canonical approach pursued here is the elegance with which it handles non-equivalent probability measures. The backward stochastic differential equation literature contains a range of comparison theorems, see for example [Cohen and Elliott, 2012], and the results of this paper may be seen in light of these, but are tailored to the situation with non-equivalent rather than just dominating measures. This is not just to satisfy mathematical curiosity: non-equivalence occurs frequently in the comparison of actuarial models, with the actuary starting from a simpler (non-dominating) model that rules out the occurrence of some event. This could include policyholder behavior events such as surrender, also called lapse, or retirement. Furthermore, any approach based on backward stochastic differential equations is also limited by\n\nthe lack of background results outside the absolutely continuous case.\nThe paper is structured as follows. Sections $2-4$ provide the construction of canonical probability models generated by (cumulative) transition rates, culminating with Theorem 4.1. The following two sections contain key technical results. Section 5 deals with the time-dynamics of conditional expectations of state indicator processes, leading to a stochastic version of the Kolmogorov backward equation, see Theorem 5.2, while Section 6 concerns the extension from state indicator processes to a wider class of processes. In the final two sections, the narrative shifts towards actuarial science with Section 7 devoted to the stochastic Thiele equation and Section 8 to comparison theorems.", "tables": {}, "images": {}}, {"section_id": 1, "text": "# 2 Canonical measurable space \n\nStatus data from an individual life insurance policy is usually of the form\n\n![table_0](table_0)\n\nwith ordered time points $t_{0}<t_{1}<t_{2}<\\cdots$ from the time set $[0, \\infty)$ and states $z_{0} \\neq z_{1} \\neq z_{2} \\neq \\cdots$ from a finite state space $\\mathcal{Z}$. By convention, let $t_{0}=0$ be the starting time of the individual insurance contract. Further, without loss of generality let $\\mathcal{Z} \\subset \\mathbb{N}$. The total number of status updates may be countably infinite on the full time line, but on bounded time intervals the number of status updates shall be at most finite. For a convenient notation, if there are only finitely many updates in total, we extend the update sequence to a countably infinite sequence by adding artificial data points $(\\infty, \\nabla)$. Let $\\overline{\\mathcal{Z}}:=\\mathcal{Z} \\cup\\{\\nabla\\}$. All in all, the set of potential status developments is\n\n$$\n\\begin{aligned}\n\\Omega:=\\left\\{\\left(t_{k}, z_{k}\\right)_{k \\in \\mathbb{N}_{0}} \\in[0, \\infty]^{\\mathbb{N}_{0}} \\times \\overline{\\mathcal{Z}}^{\\mathbb{N}_{0}}: t_{0}\\right. & =0, t_{k}<t_{k+1} \\text { for } t_{k}<\\infty, t_{k}=t_{k+1} \\text { for } t_{k}=\\infty \\\\\n& \\left.z_{k} \\neq z_{k+1} \\text { for } t_{k}<\\infty, z_{k}=\\nabla \\text { for } t_{k}=\\infty, \\sup _{k} t_{k}=\\infty\\right\\}\n\\end{aligned}\n$$\n\nThe projection mappings\n\n$$\n\\begin{aligned}\n& \\tau_{k}: \\Omega \\rightarrow[0, \\infty], \\quad \\tau_{k}(\\omega) \\mapsto t_{k} \\\\\n& \\zeta_{k}: \\Omega \\rightarrow \\overline{\\mathcal{Z}}, \\quad \\zeta_{k}(\\omega) \\mapsto z_{k}\n\\end{aligned}\n$$\n\ndefine a marked point process\n\n$$\n\\left(\\tau_{k}, \\zeta_{k}\\right)_{k \\in \\mathbb{N}_{0}}\n$$\n\nAn alternative way of representing the insurance data is the multivariate counting process\n\n$$\nN=\\left(N^{i j}\\right)_{i, j \\in \\mathcal{Z}: i \\neq j}, \\quad N^{i j}:[0, \\infty) \\times \\Omega \\rightarrow \\mathbb{N}_{0}\n$$\n\ndefined by\n\n$$\nN^{i j}(t):=\\sum_{k \\in \\mathbb{N}} \\mathbb{1}_{\\left\\{\\tau_{k} \\leqslant t, \\zeta_{k-1}=i, \\zeta_{k}=j\\right\\}}\n$$\n\nThe multivariate counting process $N$ combined with the initial state $\\zeta_{0}$ carries the same information as the marked point process. Note that the paths are c\u00e0dl\u00e0g and have at most finitely many jumps in finite time. A third option to represent the insurance data is the multivariate state occupation process\n\n$$\nI=\\left(I^{i}\\right)_{i \\in \\mathcal{Z}}, \\quad I^{i}:[0, \\infty) \\times \\Omega \\rightarrow\\{0,1\\}\n$$\n\ndefined by\n\n$$\nI^{i}(t):=\\sum_{k \\in \\mathbb{N}_{0}} \\sum_{i \\in \\mathcal{Z}} \\mathbb{1}_{\\left\\{\\tau_{k} \\leqslant t<\\tau_{k+1}\\right\\}} \\mathbb{1}_{\\left\\{\\zeta_{k}=i\\right\\}}\n$$\n\nAgain, the paths are c\u00e0dl\u00e0g and have at most finitely many jumps in finite time. The counting processes and state occupation processes satisfy the fundament relation\n\n$$\nI^{i}(t)-I^{i}(s)=\\sum_{j: j \\neq i} \\int_{(s, t]}\\left(N^{j i}(\\mathrm{~d} u)-N^{i j}(\\mathrm{~d} u)\\right)\n$$\n\nA fourth option to represent the insurance data is the multi-state process\n\n$$\nZ:[0, \\infty) \\times \\Omega \\rightarrow \\mathcal{Z}\n$$\n\ndefined by\n\n$$\nZ(t):=\\sum_{k \\in \\mathbb{N}_{0}} \\mathbb{1}_{\\left\\{\\tau_{k} \\leqslant t<\\tau_{k+1}\\right\\}} \\zeta_{k}=\\sum_{i \\in \\mathcal{Z}} i I^{i}(t)\n$$\n\nAlso this process has c\u00e0dl\u00e0g paths with at most finitely many jumps in finite time. For notational convenience, we define $Z(0-):=Z(0)$.\n\nThe development of the observable information for an individual insurance contract is described by the filtration $\\mathcal{F}=\\left(\\mathcal{F}_{t}\\right)_{t \\in[0, \\infty)}$ defined by\n\n$$\n\\mathcal{F}_{t}:=\\sigma\\left(\\mathbb{1}_{\\left\\{\\tau_{k} \\leqslant t\\right\\}}\\left(\\tau_{k}, \\zeta_{k}\\right): k \\in \\mathbb{N}_{0}, i \\in \\mathcal{Z}\\right)\n$$\n\nNote that\n\n$$\n\\begin{aligned}\n\\mathcal{F}_{t}= & \\sigma\\left(Z(0), N^{i j}(s): s \\leqslant t, i, j \\in \\mathcal{Z}, i \\neq j\\right) \\\\\n= & \\sigma\\left(I^{i}(s): s \\leqslant t, i \\in \\mathcal{Z}\\right) \\\\\n= & \\sigma(Z(s): s \\leqslant t)\n\\end{aligned}\n$$\n\nwhich means that the marked point process, the multivariate counting process together with the initial state, the multivariate occupation process, and the multi-state process all generate the same information. Consequently, on the intere time line, all these processes are measurable with respect to the $\\sigma$-algebra\n\n$$\n\\mathcal{F}_{\\infty}:=\\sigma\\left(\\mathcal{F}_{u}: u \\in[0, \\infty)\\right)\n$$\n\nWhile the $\\sigma$-algebra $\\mathcal{F}_{t}$ describes the observable information of the present and the past, the interval $[0, t]$, the observable information of the past only, corresponding to the interval $[0, t)$, is given by\n\n$$\n\\mathcal{F}_{t-}:=\\sigma\\left(\\mathbb{1}_{\\left\\{\\tau_{k}<t\\right\\}}\\left(\\tau_{k}, \\zeta_{k}\\right): k \\in \\mathbb{N}_{0}, i \\in \\mathcal{Z}\\right)\n$$\n\nNote that $\\mathcal{F}_{0-}$ is the trivial $\\sigma$-algebra and, similar to before,\n\n$$\n\\begin{aligned}\n\\mathcal{F}_{t-} & =\\sigma\\left(Z(0) \\mathbb{1}_{\\{t>0\\}}, N^{i j}(s): s<t, i, j \\in \\mathcal{Z}, i \\neq j\\right) \\\\\n& =\\sigma\\left(I^{i}(s): s<t, i \\in \\mathcal{Z}\\right) \\\\\n& =\\sigma\\left(Z(s): s<t\\right) \\\\\n& =\\sigma\\left(\\mathcal{F}_{s}: s<t\\right)\n\\end{aligned}\n$$\n\nThe family of the left-limit $\\sigma$-algebras\n\n$$\n\\mathcal{F}^{-}:=\\left(\\mathcal{F}_{t-}\\right)_{t \\in[0, \\infty)}\n$$\n\nis also a filtration.\nThe information provided by the first $n \\in \\mathbb{N}_{0}$ elements of the marked point process is given by the $\\sigma$-algebra\n\n$$\n\\mathcal{G}_{n}:=\\sigma\\left(\\left(\\tau_{k}, \\zeta_{k}\\right): k \\leqslant n\\right)\n$$\n\nFor any $\\sigma$-algebra $\\mathcal{A}$ on $\\Omega$ and any event $B \\subset \\Omega$, the so-called trace $\\sigma$-algebra is defined by $\\mathcal{A} \\cap B:=\\{A \\cap B: A \\in \\mathcal{A}\\}$. For each $t \\in[0, \\infty)$ and $n \\in \\mathbb{N}_{0}$, it holds that\n\n$$\n\\begin{aligned}\n& \\mathcal{G}_{n} \\cap\\left\\{\\tau_{n} \\leqslant t<\\tau_{n+1}\\right\\}=\\mathcal{F}_{t} \\cap\\left\\{\\tau_{n} \\leqslant t<\\tau_{n+1}\\right\\} \\\\\n& \\mathcal{G}_{n} \\cap\\left\\{\\tau_{n}<t \\leqslant \\tau_{n+1}\\right\\}=\\mathcal{F}_{t-} \\cap\\left\\{\\tau_{n}<t \\leqslant \\tau_{n+1}\\right\\}\n\\end{aligned}\n$$\n\nThe $\\sigma$-algebra $\\mathcal{G}_{n}$ is equivalent to the stopping time $\\sigma$-algebra $\\mathcal{F}_{\\tau_{n}}$ :\n\n$$\n\\mathcal{F}_{\\tau_{n}}:=\\left\\{A \\in \\mathcal{F}_{\\infty}: A \\cap\\left\\{\\tau_{n} \\leqslant t\\right\\} \\in \\mathcal{F}_{t}, t \\geqslant 0\\right\\}=\\mathcal{G}_{n}\n$$\n\nFor each scenario $\\omega=\\left(t_{k}, z_{k}\\right)_{k \\in \\mathbb{N}_{0}} \\in \\Omega$ and tuple $(s, i) \\in[0, \\infty) \\times \\mathcal{Z}$, we define a so-called $(s, i)$ stopped status development $\\omega_{s}^{i}$ by\n\n$$\n\\omega_{s}^{i}:= \\begin{cases}\\left(\\left(t_{0}, z_{0}\\right), \\ldots,\\left(t_{n}, z_{n}\\right),(\\infty, \\nabla), \\ldots\\right) & : t_{n}<s \\leqslant t_{n+1}, z_{n}=i \\\\ \\left(\\left(t_{0}, z_{0}\\right), \\ldots,\\left(t_{n}, z_{n}\\right),(s, i),(\\infty, \\nabla), \\ldots\\right) & : t_{n}<s \\leqslant t_{n+1}, z_{n} \\neq i \\\\ ((0, i),(\\infty, \\nabla), \\ldots) & : s=0\\end{cases}\n$$\n\nThe stopped status development $\\omega_{s}^{i}$ is still an element of $\\Omega$. The $(s, i)$-stopping leaves the multistate process $Z$ unchanged on $[0, s)$ and makes it constantly equal to $i$ on $[s, \\infty)$.", "tables": {"table_0": "| date | status |\n| :--: | :--: |\n| $t_{0}$ | $z_{0}$ |\n| $t_{1}$ | $z_{1}$ |\n| $t_{2}$ | $z_{2}$ |\n| $\\vdots$ | $\\vdots$ |"}, "images": {}}, {"section_id": 2, "text": "# 3 Transition rates and initial distribution \n\nThere are several ways to specify a probability measure $\\mathbb{P}$ on the measurable space $\\left(\\Omega, \\mathcal{F}_{\\infty}\\right)$. Our approach is to start from the representation\n\n$$\n\\mathcal{F}_{\\infty}=\\sigma\\left(Z(0), N^{i j}: i, j \\in \\mathcal{Z}, i \\neq j\\right)\n$$\n\nand to specify the distribution of $Z(0)$ and $N$. We assume that we have the initial distribution of $Z$, specified by a distribution function\n\n$$\n\\alpha: \\mathcal{Z} \\rightarrow[0,1], \\quad \\sum_{i \\in \\mathcal{Z}} \\alpha(i)=1\n$$\n\nfor the initial state $Z(0)$, and we assume that we have (cumulative) transition rates\n\n$$\n\\Lambda=\\left(\\Lambda^{i j}\\right)_{i, j \\in \\mathcal{Z}: i \\neq j}, \\quad \\Lambda^{i j}:[0, \\infty) \\times \\Omega \\rightarrow \\mathbb{R}\n$$\n\nfor the multivariate counting process $N$. The total (combined) transition rate for leaving a current state $i \\in \\mathcal{Z}$ is in brief written as\n\n$$\n\\Lambda^{i \\cdot}:=\\sum_{j: j \\neq i} \\Lambda^{i j}\n$$\n\nThe increments of $\\Lambda^{i j}$ are meant to describe the expected increments of $N^{i j}$, conditional on the past information and provided that the last state was $i$, symbolically written as\n\n$$\n\\Lambda^{i j}(\\mathrm{~d} t)=\\mathbb{E}\\left[N^{i j}(\\mathrm{~d} t) \\mid \\mathcal{F}_{t-}\\right], \\quad Z(t-)=i\n$$\n\nThis intuitive equation is not mathematically precise. For a rigorous definition, we need to disentangle the information time variable from the integration variable. Based on the observation that\n\n$$\n\\mathcal{F}_{t-} \\cap\\{s<t \\leqslant \\tau(s)\\}=\\mathcal{F}_{s} \\cap\\{s<t \\leqslant \\tau(s)\\}\n$$\n\nfor any integrable random variable $Y$ one can show that almost surely\n\n$$\n\\mathbb{E}\\left[Y \\mid \\mathcal{F}_{t-}\\right]=\\frac{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} Y \\mid \\mathcal{F}_{s}\\right]}{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} \\mid \\mathcal{F}_{s}\\right]}, \\quad s<t \\leqslant \\tau(s)\n$$\n\ncompare with Remark 4.2 .3 in [Jacobsen, 2006]. Here the random variable $\\tau(s)$ is defined as the first jump of $Z$ on $(s, \\infty]$,\n\n$$\n\\tau(s):=\\sum_{n \\in \\mathbb{N}_{0}} \\tau_{n+1} \\mathbb{1}_{\\left\\{\\tau_{n} \\leqslant s<\\tau_{n+1}\\right\\}}\n$$\n\nBased on (3.2), we rewrite the symbolical characterization (3.1) of $\\Lambda^{i j}$ to obtain the mathematically rigorous equation\n\n$$\n\\Lambda^{i j}(\\mathrm{~d} t)=\\frac{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} N^{i j}(\\mathrm{~d} t) \\mid \\mathcal{F}_{s}\\right]}{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} \\mid \\mathcal{F}_{s}\\right]}, \\quad Z(t-)=i, s<t \\leqslant \\tau(s)\n$$\n\nThroughout, we use for any subintervals $I, J$ of $[0, \\infty)$ the shorthand notation\n\n$$\nF(\\mathrm{~d} t)=H(t) G(\\mathrm{~d} t) \\forall t \\in I \\quad \\Longleftrightarrow \\quad \\int_{J} F(\\mathrm{~d} t)=\\int_{J} H(t) G(\\mathrm{~d} t) \\forall J \\subset I\n$$\n\nIt is worthwhile to note that (3.3) already reveals a certain ambiguity or flexibility in the choice of (cumulative) transition rates. To see this, consider\n\n$$\nC=\\left(C^{j}\\right)_{j \\in \\mathcal{Z}}, \\quad C^{j}:[0, \\infty) \\times \\Omega \\rightarrow \\mathbb{R}\n$$\n\ndefined by\n\n$$\nC^{j}(\\mathrm{~d} t):=\\sum_{i \\in \\mathcal{Z}} I^{i}(t-) \\Lambda^{i j}(\\mathrm{~d} t), \\quad t \\geqslant 0\n$$\n\nThen (3.3) would still hold with $\\Lambda^{i j}$ replaced by $C^{j}$. Later, we shall demonstrate that $C^{j}$ is a compensator of\n\n$$\nN^{j}:=\\sum_{i: i \\neq j} N^{i j}\n$$\n\nTo remove this ambiguity and obtain an approach that is consistent with the specification of Markov processes through deterministic (cumulative) transition rates, we shall require that\n\n$$\n\\Lambda^{i j}(t)(\\omega)=\\Lambda^{i j}(t)\\left(\\omega_{\\tau_{n}(\\omega)}^{i}\\right), \\quad \\tau_{n}(\\omega)<t \\leqslant \\tau_{n+1}(\\omega)\n$$\n\nWe therefore, all in all, make the following technical assumptions for $\\Lambda$ :", "tables": {}, "images": {}}, {"section_id": 3, "text": "# Assumption 3.1. \n\n(a) For $0 \\leqslant t \\leqslant \\tau_{1}$, let $\\Lambda(t)$ be deterministic. For $n \\in \\mathbb{N}$ and $\\tau_{n}<t \\leqslant \\tau_{n+1}$, let $\\Lambda^{i j}(t)$ be measurable with respect to\n\n$$\n\\sigma\\left(\\tau_{0}, \\zeta_{0}, \\ldots, \\tau_{n-1}, \\zeta_{n-1}, \\mathbb{1}_{\\left\\{\\zeta_{n-1} \\neq i\\right\\}} \\tau_{n}\\right), \\quad i \\in \\mathcal{Z}\n$$\n\n(b) Let $\\Lambda$ be right-continuous and, except in a finite number of points in every finite time interval, non-decreasing with\n\n$$\n\\Delta \\Lambda^{i *}(t) \\leqslant 1, \\quad i \\in \\mathcal{Z}, t>0\n$$\n\n(c) If $\\Lambda^{i j}(\\cdot)(\\omega)$ jumps downward at time $r>0$, denoted as reset point, let\n\n$$\n\\Lambda^{i j}(r-)(\\omega)=\\infty, \\quad \\Lambda^{i j}(r)(\\omega)=0\n$$\n\n(d) For any sequence $i_{0} \\neq i_{1} \\neq \\cdots \\neq i_{n}$ of states in $\\mathcal{Z}$ with $i_{0}=i_{n}$, let at least one of the transition rates $\\Lambda^{i_{0} i_{1}}, \\ldots, \\Lambda^{i_{n-1} i_{n}}$ be bounded (uniformly on $\\Omega$ ) on finite intervals.\n\nAssumption 3.1(a) guarantees that $\\Lambda$ does not use superfluous information and is an equivalent assumption to (3.6). The right-continuity of Assumption 3.1(b) follows the right-continuity convention for the counting processes, while the upper jump bound prevents the transition probabilities from becoming greater than one. An upward jump in a cumulative transition rate corresponds to a discrete probability mass for the corresponding transition. The monotony statement in Assumption 3.1(b) prevents the transition probabilities from becoming negative, but we allow for downward jumps at so-called reset points, of which every path has at most a finite number in every finite time interval. Reset points are necessary when transition probabilities converge continuously to one in finite time, because such a convergence implies a pole for the cumulative transition rate, which must be reset to continue the model after the pole, confer with Assumption 3.1(c). The downward jump is not a probability mass and must be separated when calculating probabilities. Assumption 3.1(d) is a sufficient condition to exclude explosions of the counting processes. In particular, the assumptions ensure that $\\Lambda^{i j}$ and $C^{j}$ are $\\mathcal{F}^{-}$-adapted.", "tables": {}, "images": {}}, {"section_id": 4, "text": "## 4 Canonical probability model\n\nThis section shows that the initial distribution $\\alpha$ and the transition rates $\\Lambda=\\left(\\Lambda^{i j}\\right)_{i, j: i \\neq j}$ uniquely define a probability measure $\\mathbb{P}$ on the measurable space $\\left(\\Omega, \\mathcal{F}_{\\infty}\\right)$. In addition, we aim to define conditional probability measures\n\n$$\n\\mathbb{P}_{s}^{i}[\\cdot]=\\mathbb{P}\\left[\\cdot \\mid \\mathcal{F}_{s-}, Z(s)=i\\right], \\quad s \\in[0, \\infty), i \\in \\mathcal{Z}\n$$\n\nMore precisely, we are looking for $\\mathcal{F}_{s-}$-measurable probability kernels $\\mathbb{P}_{s}^{i}, s \\in[0, \\infty), i \\in \\mathcal{Z}$, that satisfy almost surely for each $A \\in \\mathcal{F}_{\\infty}$ the equation\n\n$$\nI^{i}(s) \\mathbb{P}_{s}^{i}[A]=I^{i}(s) \\mathbb{P}\\left[A \\mid \\mathcal{F}_{s}\\right]\n$$\n\nGiven the probability kernels $\\mathbb{P}_{s}^{i}, s \\in[0, \\infty), i \\in \\mathcal{Z}$, we moreover define corresponding conditional expectations by\n\n$$\n\\mathbb{E}_{s}^{i}[\\cdot]:=\\int_{\\Omega}(\\cdot) \\mathrm{d} \\mathbb{P}_{s}^{i}\n$$\n\nTheorem 4.1. There exist unique $\\mathcal{F}_{s-}$-measurable probability kernels $\\mathbb{P}_{s}^{i}, s \\in[0, \\infty), i \\in \\mathcal{Z}$, on $\\left(\\Omega, \\mathcal{F}_{\\infty}\\right)$ such that\n(i) For $s \\in[0, \\infty), \\omega \\in \\Omega$ and $i, j \\in \\mathcal{Z}$ with $j \\neq i$, it holds that\n\n$$\n\\Lambda^{i j}(\\mathrm{~d} t)(\\omega)=\\frac{\\mathbb{E}_{s}^{i}\\left[\\mathbb{1}_{\\{\\tau(s) \\geq t\\}} N^{i j}(\\mathrm{~d} t)\\right](\\omega)}{\\mathbb{E}_{s}^{i}\\left[\\mathbb{1}_{\\{\\tau(s) \\geq t\\}}\\right](\\omega)}\n$$\n\nfor those $t \\in(s, \\infty)$ such that neither $Z(\\cdot)(\\omega)$ has a jump in $(s, t)$ nor $\\Lambda^{i *}(\\cdot)(\\omega)$ has a pole or a jump of size +1 in $(s, t]$.\n\nFurther, there exists a unique probability measure $\\mathbb{P}$ on $\\left(\\Omega, \\mathcal{F}_{\\infty}\\right)$ such that\n(ii) Equation (4.2) holds almost surely for $A \\in \\mathcal{F}_{\\infty}, s \\in[0, \\infty)$,\n(iii) for $i \\in \\mathcal{Z}$, it holds that\n\n$$\n\\alpha(i)=\\mathbb{P}[Z(0)=i]\n$$\n\nProperty (i) refers to Equations (3.3)-(3.6) and helps clarify in what sense $\\Lambda$ indeed represents the transition rates with respect to the probability measure $\\mathbb{P}$.\n\nProof. We start by explicitly constructing the probability kernels and the probability measure, and we do this on the extended measurable space $\\left(\\widetilde{\\Omega}, \\widetilde{\\mathcal{F}}_{\\infty}\\right)$ defined by\n\n$$\n\\begin{gathered}\n\\widetilde{\\Omega}:=\\left\\{\\left(t_{l}, z_{l}\\right)_{l \\in \\mathbb{N}_{0}}: t_{0}=0, t_{l}<t_{l+1} \\text { for } t_{l}<\\infty, t_{l}=t_{l+1} \\text { for } t_{l}=\\infty\\right. \\\\\n\\left.z_{l} \\neq z_{l+1} \\text { for } z_{l} \\in \\mathcal{Z}, z_{l}=z_{l+1} \\text { for } z_{l}=\\nabla\\right\\}\n\\end{gathered}\n$$\n\nand\n\n$$\n\\widetilde{\\mathcal{F}}_{\\infty}:=\\sigma\\left(\\tau_{l}, \\zeta_{l}: l \\in \\mathbb{N}_{0}\\right)\n$$\n\nfor $\\tau_{l}, \\zeta_{l}$ defined similarly to before but on the extended domain $\\widetilde{\\Omega}$. Later on we will show that the difference $\\widetilde{\\Omega} \\backslash \\Omega$ has probability zero, which will bring us back to the original measurable space. For $s \\in[0, \\infty)$ and $i \\in \\mathcal{Z}$, the random variable\n\n$$\n\\rho_{s}^{i}(\\omega):=\\sup \\left\\{u \\geqslant s: \\sup _{t \\in[s, u]} \\Lambda^{i *}(t)\\left(\\omega_{s}^{i}\\right)<\\infty\\right\\}\n$$\n\ngives the first reset point of $\\Lambda^{i *}(\\cdot)\\left(\\omega_{s}^{i}\\right)$ on $[s, \\infty)$. Since the paths of $\\Lambda_{i j}(\\cdot)\\left(\\omega_{s}^{i}\\right)$ are non-decreasing on $\\left[s, \\rho_{i}(\\omega)\\right)$, they can have at most countably many jumps on $\\left[s, \\rho_{i}(\\omega)\\right)$. Let\n\n$$\n\\Lambda_{c}^{i j}(\\mathrm{~d} t)\\left(\\omega_{s}^{i}\\right):=\\Lambda_{i j}(\\mathrm{~d} t)\\left(\\omega_{s}^{i}\\right)-\\Delta \\Lambda^{i j}(t)\\left(\\omega_{s}^{i}\\right)\n$$\n\ndenote the continuous part of $\\Lambda^{i j}(\\cdot)\\left(\\omega_{s}^{i}\\right)$ on $\\left[s, \\rho_{i}(\\omega)\\right)$. In the following, let\n\n$$\n\\omega=\\left(t_{l}, z_{l}\\right)_{l \\in \\mathbb{N}_{0}} \\in \\widehat{\\Omega}\n$$\n\nbe arbitrary but fixed. For $i, j \\in \\mathcal{Z}, i \\neq j$ we define mappings $p_{s}^{i}$ and $p_{s}^{i j}$ on $[s, \\infty)$ by\n\n$$\n\\begin{aligned}\np_{s}^{i}(t)(\\omega) & :=e^{-\\left(\\Lambda_{c}^{i *}\\left(t \\wedge \\rho_{s}^{i}(\\omega)\\right)\\left(\\omega_{s}^{i}\\right)-\\Lambda_{c}^{i *}(s)\\left(\\omega_{s}^{i}\\right)\\right)} \\prod_{s<u \\leqslant t \\wedge \\rho_{s}^{i}(\\omega)}\\left(1-\\Delta \\Lambda^{i *}(u)\\left(\\omega_{s}^{i}\\right)\\right) \\\\\np_{s}^{i j}(t)(\\omega) & :=\\int_{(s, t] \\cap\\left(0, \\rho_{s}^{i}(\\omega)\\right)} p_{s}^{i}(u-)(\\omega) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right)\n\\end{aligned}\n$$\n\nThe latter definitions imply that\n\n$$\n\\begin{aligned}\n\\sum_{j: j \\neq i} p_{s}^{i j}(t) & =\\int_{(s, t] \\cap\\left(0, \\rho_{s}^{i}(\\omega)\\right)} p_{s}^{i}(u-)(\\omega)\\left(-\\Lambda^{i *}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right)\\right) \\\\\n& =-\\int_{(s, t] \\cap\\left(0, \\rho_{s}^{i}(\\omega)\\right)} p_{s}^{i}(\\mathrm{~d} u)(\\omega) \\\\\n& = \\begin{cases}1-p_{s}^{i}(t) & : t \\in\\left[s, \\rho_{s}^{i}(\\omega)\\right) \\\\\n0 & : t \\in\\left[\\rho_{s}^{i}(\\omega), \\infty\\right)\\end{cases}\n\\end{aligned}\n$$\n\nWe extend the domains of $p_{s}^{i}(\\cdot)(\\omega)$ and $p_{s}^{i j}(\\cdot)(\\omega)$ from $[s, \\infty)$ to $[s, \\infty]$ by setting\n\n$$\n\\begin{aligned}\np_{s}^{i}(\\infty) & :=p_{s}^{i}(\\infty-) \\\\\np_{s}^{i j}(\\infty) & :=p_{s}^{i j}(\\infty-), \\quad i, j \\in \\mathcal{Z}, i \\neq j\n\\end{aligned}\n$$\n\nFurthermore, we define\n\n$$\np_{s}^{\\gamma \\nabla}(t):=\\mathbb{1}_{[\\infty]}(t), \\quad t \\in[s, \\infty]\n$$\n\nWith these extensions, the mapping $(t, j) \\mapsto p_{s}^{i j}(t)$ defines a conditional probability distribution on $[s, \\infty] \\times(\\mathcal{Z} \\cup\\{\\nabla\\})$ for each $(s, i)$. For $(s, i)=\\left(t_{n}, z_{n}\\right)$, we interpret this conditional probability distribution as the probability kernel\n\n$$\np_{\\tau_{n}}^{i \\omega j}(t)(\\omega)=\\mathbb{P}\\left[\\tau_{n+1} \\leqslant t, \\zeta_{n+1}=j \\mid\\left(\\tau_{l}, \\zeta_{l}\\right)_{l \\leqslant n}\\right](\\omega), \\quad t \\geqslant \\tau_{n}(\\omega)\n$$\n\nHowever, we still have to show that the mapping $(s, i, \\omega) \\mapsto p_{s}^{i j}(t)(\\omega)$ is measurable for each $(t, j)$. The mapping $(s, i, \\omega) \\mapsto\\left(s, i, \\omega_{s}^{i}\\right)$ is measurable as a mapping from the measurable space $\\left([0, \\infty) \\times \\mathcal{Z} \\times \\Omega, \\mathcal{B}([0, \\infty)) \\otimes 2^{\\mathcal{Z}} \\otimes \\mathcal{F}_{\\infty}\\right)$ to the same space, since it is composed of simple functions and countably many case differentiations, see (2.4). As the transition rates are right-continuous by definition, they are jointly measurable, so the composition $(s, i, \\omega) \\mapsto \\Lambda^{i j}(s)\\left(\\omega_{s}^{i}\\right)$ is measurable too. Likewise, one can argue that $(s, i, \\omega, t) \\mapsto \\Lambda^{i j}(t)\\left(\\omega_{s}^{i}\\right)$ is measurable, and the arguments still apply for the continuous part $\\Lambda_{c}^{i j}$ and the pure jump part $\\Lambda^{i j}-\\Lambda_{c}^{i j}$ of $\\Lambda^{i j}$. From all these measurable mappings, the mapping $(s, i, \\omega, t) \\mapsto p_{s}^{i}(t)(\\omega)$ and then $(s, i, \\omega, t) \\mapsto p_{s}^{i j}(t)(\\omega)$ are formed by using simple operations and limits, see (4.5), so they are measurable too. That means that (4.7) indeed describes probability kernels.\n\nBy applying the Ionescu-Tulcea theorem, confer with Proposition V.1.1 in [Neveu, 1965], from the distribution function $\\left(t_{0}, z_{0}\\right) \\mapsto \\mathbb{1}_{\\{0\\}}\\left(t_{0}\\right) \\alpha\\left(z_{0}\\right)$ for $\\left(\\tau_{0}, \\zeta_{0}\\right)$ and the probability kernels (4.7) we construct a probability measure $\\mathbb{P}$ on $\\left(\\widehat{\\Omega}, \\widehat{\\mathcal{F}}_{\\infty}\\right)$ as the unique completion of\n\n$$\n\\mathbb{P}[A]:=\\sum_{i_{0}, \\ldots, i_{m}} \\int_{\\left(s_{0}, \\infty\\right]} \\cdots \\int_{\\left(s_{l-1}, \\infty\\right]} \\mathbb{1}_{A}\\left(\\omega_{s_{0} \\cdots s_{l}}^{i_{0} \\cdots i_{l}}\\right) p_{s_{l-1}}^{i_{l-1} i_{l}}\\left(\\mathrm{~d} s_{l}\\right)\\left(\\omega_{s_{0} \\cdots s_{l-1}}^{i_{0} \\cdots i_{l-1}}\\right) \\cdots p_{s_{0}}^{i_{0} i_{l}}\\left(\\mathrm{~d} s_{1}\\right)\\left(\\omega_{s_{0}}^{i_{0}}\\right) \\alpha\\left(i_{0}\\right)\n$$\n\nfor $s_{0}:=0, A \\in \\mathcal{G}_{l}, l \\in \\mathbb{N}$, and for $\\omega_{s_{0} \\cdots s_{l}}^{i_{0} \\cdots i_{l}}$ defined by the iterative formula\n\n$$\n\\omega_{s_{0} \\cdots s_{l}}^{i_{0} \\cdots i_{l}}:=\\left(\\omega_{s_{0} \\cdots s_{l-1}}^{i_{0} \\cdots i_{l-1}}\\right)_{s_{l}}^{i_{l}}, \\quad l=1, \\ldots, m\n$$\n\nEquation (4.8) implies property (iii), but for the extended probability space $\\left(\\widetilde{\\Omega}, \\widetilde{\\mathcal{F}}_{\\infty}\\right)$. Analogously, we define probability kernels $\\mathbb{P}_{s}^{i}, i \\in \\mathcal{Z}, s \\in[0, \\infty)$, on $\\left(\\widetilde{\\Omega}, \\widetilde{\\mathcal{F}}_{\\infty}\\right)$ as the unique completions of\n\n$$\n\\mathbb{P}_{s_{n}}^{i_{n}}[A](\\omega):=\\sum_{i_{n+1}, \\ldots, i_{l}} \\int_{\\left\\{s_{n}, \\infty\\right\\}} \\cdots \\int_{\\left\\{s_{l-1}, \\infty\\right\\}} \\mathbb{1}_{A}\\left(\\omega_{s_{n} \\cdots s_{l}}^{i_{n} \\cdots i_{l}}\\right) p_{s_{l-1}}^{i_{l-1} i_{l}}\\left(\\mathrm{~d} s_{l}\\right)\\left(\\omega_{s_{n} \\cdots s_{l-1}}^{i_{n} \\cdots i_{l-1}}\\right) \\cdots p_{s_{n}}^{i_{n} i_{n+1}}\\left(\\mathrm{~d} s_{n+1}\\right)\\left(\\omega_{s_{n}}^{i_{n}}\\right)\n$$\n\nfor $t_{n} \\leqslant s_{n}<t_{n+1}, A \\in \\mathcal{G}_{l}, n, l \\in \\mathbb{N}_{0}, n<l$. For $n<k \\leqslant l$, the term $\\mathbb{P}_{s_{k}}^{i_{k}}[A]\\left(\\omega_{s_{n} \\cdots s_{k-1}}^{i_{n} \\cdots i_{k-1}}\\right)$ equals the $l-k$ inner integrals of $\\mathbb{P}_{s_{n}}^{i_{n}}[A](\\omega)$, so it holds that\n\n$$\n\\mathbb{P}_{s_{n}}^{i_{n}}[A]=\\mathbb{E}_{s_{n}}^{i_{n}}\\left[\\mathbb{P}_{\\tau_{k}}^{\\zeta_{k}}[A]\\right], \\quad k>n, \\tau_{n} \\leqslant s_{n}<\\tau_{n+1}\n$$\n\nMoreover, by using the fact that definition (4.5) implies that\n\n$$\np_{s_{n}}^{i_{n} i_{n+1}}\\left(\\mathrm{~d} s_{n+1}\\right)\\left(\\omega_{s_{n}}^{i_{n}}\\right)=p_{s_{n}}^{i_{n}}(s)\\left(\\omega_{s_{n}}^{i_{n}}\\right) p_{s}^{i_{n} i_{n+1}}\\left(\\mathrm{~d} s_{n+1}\\right)\\left(\\omega_{s_{n}}^{i_{n}}\\right), \\quad s_{n} \\leqslant s<s_{n+1}\n$$\n\nfrom definition (4.9), equation (4.6), and the property $\\left(\\omega_{s_{n}}^{i}\\right)_{s}^{i}=\\omega_{s_{n}}^{i}$ for $s \\geqslant s_{n}$, we can conclude that\n\n$$\n\\begin{aligned}\n& \\mathbb{P}_{s_{n}}^{i_{n}}\\left[A \\cap\\left\\{\\tau_{n} \\leqslant s<\\tau_{n+1}\\right\\}\\right](\\omega) \\\\\n& =\\mathbb{P}_{s}^{i_{n}}\\left[A \\cap\\left\\{\\tau_{n} \\leqslant s<\\tau_{n+1}\\right\\}\\right]\\left(\\omega_{s_{n}}^{i_{n}}\\right) p_{s_{n}}^{i_{n}}(s)\\left(\\omega_{s_{n}}^{i_{n}}\\right) \\\\\n& =\\sum_{i_{n+1}} \\int_{(s, \\infty]} \\mathbb{P}_{s}^{Z(s)\\left(\\omega_{s_{n}}^{i_{n}}\\right)}\\left[A \\cap\\left\\{\\tau_{n} \\leqslant s<\\tau_{n+1}\\right\\}\\right]\\left(\\omega_{s_{n}}^{i_{n}}\\right) p_{s_{n}}^{i_{n} i_{n+1}}\\left(\\mathrm{~d} s_{n+1}\\right)\\left(\\omega_{s_{n}}^{i_{n}}\\right) \\\\\n& =\\mathbb{E}_{s_{n}}^{i_{n}}\\left[\\mathbb{P}_{s}^{Z(s)}\\left[A \\cap\\left\\{\\tau_{n} \\leqslant s<\\tau_{n+1}\\right\\}\\right]\\right](\\omega), \\quad t_{n} \\leqslant s_{n}<t_{n+1}, s \\geqslant s_{n}\n\\end{aligned}\n$$\n\nThis fact and equation (4.10) yield\n\n$$\n\\begin{aligned}\n\\mathbb{P}_{u}^{i}[A] & =\\sum_{n=0}^{\\infty} \\mathbb{1}_{\\left\\{\\tau_{k} \\leqslant u<\\tau_{k+1}\\right\\}} \\sum_{k=n}^{\\infty} \\mathbb{P}_{u}^{i}\\left[A \\cap\\left\\{\\tau_{k} \\leqslant s<\\tau_{k+1}\\right\\}\\right] \\\\\n& =\\sum_{n=0}^{\\infty} \\mathbb{1}_{\\left\\{\\tau_{k} \\leqslant u<\\tau_{k+1}\\right\\}} \\sum_{k=n}^{\\infty} \\mathbb{E}_{u}^{i}\\left[\\mathbb{E}_{\\tau_{k}}^{\\zeta_{k}}\\left[\\mathbb{P}_{s}^{Z(s)}\\left[A \\cap\\left\\{\\tau_{k} \\leqslant s<\\tau_{k+1}\\right\\}\\right]\\right]\\right] \\\\\n& =\\mathbb{E}_{u}^{i}\\left[\\mathbb{P}_{s}^{Z(s)}[A]\\right], \\quad s \\geqslant u\n\\end{aligned}\n$$\n\nFurthermore, since $I^{j}(s)\\left((\\cdot)_{s}^{i}\\right)=\\mathbb{1}_{j=i}$ and $\\mathbb{1}_{C}\\left((.)_{s}^{i}\\right)=\\mathbb{1}_{C}(\\cdot)$, definition (4.9) implies that\n\n$$\n\\mathbb{P}_{s}^{i}[A \\cap C \\cap\\{Z(s)=j\\}]=\\mathbb{1}_{j=i} \\mathbb{1}_{C} \\mathbb{P}_{s}^{i}[A], \\quad C \\in \\mathcal{F}_{s-}\n$$\n\nBy applying (4.10), (4.11), and (4.12), we can show that\n\n$$\n\\mathbb{P}[A \\cap C \\cap\\{Z(s)=i\\}]=\\mathbb{E}\\left[\\mathbb{1}_{C} I_{i}(s) \\mathbb{P}_{s}^{i}[A]\\right], \\quad C \\in \\mathcal{F}_{s-}\n$$\n\nwhich is property (ii), but for the extended probability space $\\left(\\widetilde{\\Omega}, \\widetilde{\\mathcal{F}}_{\\infty}\\right)$. Definition (4.9) implies that\n\n$$\n\\mathbb{P}_{s}^{i}\\left[\\tau_{n+1} \\leqslant t, \\zeta_{n+1}=j\\right]=p_{s}^{i j}(t), \\quad \\tau_{n} \\leqslant s<\\tau_{n+1}\n$$\n\nBecause of (4.12) and\n\n$$\n\\left\\{\\tau_{n} \\leqslant s<\\tau_{n+1}\\right\\} \\cap\\left\\{\\tau_{n+1} \\leqslant t, \\zeta_{n+1}=j\\right\\}=\\left\\{\\tau_{n} \\leqslant s<\\tau_{n+1}\\right\\} \\cap\\{\\tau(s) \\leqslant t, Z(\\tau(s))=j\\}\n$$\n\nwe moreover have\n\n$$\n\\mathbb{P}_{s}^{i}\\left[N^{i j}(t \\wedge \\tau(s))-N^{i j}(s)\\right]=p_{s}^{i j}(t), \\quad s<t<\\rho_{s}^{i}\n$$\n\nand by equation (4.6) we furthermore get\n\n$$\n\\mathbb{P}_{s}^{i}[\\tau(s) \\geqslant t]=p_{s}^{i}(t-), \\quad s<t<\\rho_{s}^{i}\n$$\n\nThe latter two equations, definition (4.5), and the measurability assumption (3.6) yield property (i).\n\nIn a next step, we are going to show that our construction still works on the restricted measurable space $\\left(\\Omega, \\mathcal{F}_{\\infty}\\right) \\subset\\left(\\widehat{\\Omega}, \\widetilde{\\mathcal{F}}_{\\infty}\\right)$. For $r \\geqslant s$, the definitions (4.9) and (4.5) imply that\n\n$$\n\\begin{aligned}\n& \\mathbb{E}_{s}^{i}\\left[\\int_{\\left\\{\\tau_{n}, \\tau_{n+1}\\right\\}} \\mathbb{1}_{(r, t]} N^{j k}(\\mathrm{~d} u)\\right](\\omega) \\\\\n& =\\mathbb{P}_{s}^{i}\\left[r<\\tau_{n+1} \\leqslant t, \\zeta_{n+1}=k, \\zeta_{n}=j\\right](\\omega) \\\\\n& =\\int_{(s, \\infty]} \\mathbb{1}_{(r, t]} \\mathbb{1}_{i=j} p_{s}^{i k}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\\\\n& =\\int_{(s, \\infty]} \\mathbb{1}_{(r, t]}(\\omega) \\mathbb{1}_{i=j} p_{s}^{i}(u-)(\\omega) \\Lambda^{j k}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\\\\n& =\\int_{(s, \\infty]} \\mathbb{1}_{(r, t]} \\mathbb{P}_{s}^{i}\\left[Z(u-)=j, \\tau_{n+1} \\geqslant u\\right](\\omega) \\Lambda^{j k}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right), \\quad t_{n} \\leqslant s<t_{n+1}\n\\end{aligned}\n$$\n\nOn the other hand, by applying definition (4.9), using the fact that\n\n$$\nI^{j}(u-)(\\omega) \\Lambda^{j k}(\\mathrm{~d} u)(\\omega)=I^{j}(u-)(\\omega_{t_{n}}^{i}) \\Lambda^{j k}(\\mathrm{~d} u)\\left(\\omega_{t_{n}}^{i}\\right), \\quad u \\leqslant t_{n+1}, z_{n}=i\n$$\n\nand applying Tonelli's theorem, we can show that\n\n$$\n\\begin{aligned}\n& \\mathbb{E}_{s}^{i}\\left[\\int_{\\left\\{\\tau_{n}, \\tau_{n+1}\\right\\}} \\mathbb{1}_{(r, t]} I^{j}(u-) \\Lambda^{j k}(\\mathrm{~d} u)\\right](\\omega) \\\\\n& =\\int_{(s, \\infty]}\\left(\\int_{\\left(s, s_{n+1}\\right]} \\mathbb{1}_{(r, t]}\\left(\\omega_{s}^{i}\\right) I^{j}(u-)(\\omega_{s}^{i}) \\Lambda^{j k}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right)\\right) \\mathbb{P}_{s}^{i}\\left[\\tau_{n+1} \\in \\mathrm{~d} s_{n+1}\\right](\\omega) \\\\\n& =\\int_{(s, \\infty]} \\mathbb{1}_{(r, t]}(\\omega) \\int_{[u, \\infty]} I^{j}(u-)(\\omega_{s}^{i}) \\mathbb{P}_{s}^{i}\\left[\\tau_{n+1} \\in \\mathrm{~d} s_{n+1}\\right](\\omega) \\Lambda^{j k}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\\\\n& =\\int_{(s, \\infty]} \\mathbb{1}_{(r, t]} \\mathbb{P}_{s}^{i}\\left[Z(u-)=j, \\tau_{n+1} \\geqslant u\\right](\\omega) \\Lambda^{j k}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right), \\quad t_{n} \\leqslant s<t_{n+1}\n\\end{aligned}\n$$\n\nso that we can conclude that\n\n$$\n\\mathbb{E}_{s}^{i}\\left[\\int_{(r, t]} \\mathbb{1}_{\\left\\{\\tau_{n}<u \\leqslant \\tau_{n+1}\\right\\}} N^{j k}(\\mathrm{~d} u)\\right]=\\mathbb{E}_{s}^{i}\\left[\\int_{(r, t]} \\mathbb{1}_{\\left\\{\\tau_{n}<u \\leqslant \\tau_{n+1}\\right\\}} I^{j}(u-) \\Lambda^{j k}(\\mathrm{~d} u)\\right], \\quad \\tau_{n} \\leqslant s<\\tau_{n+1}, r \\geqslant s\n$$\n\nBy setting $(s, i)=\\left(\\tau_{n}, \\zeta_{n}\\right)$, using equation (4.12) for pulling the factor $\\mathbb{1}_{r \\geqslant \\tau_{n}}$ inside the conditional expectations, and applying equation (4.11) together with Tonelli's theorem, we get\n\n$$\n\\mathbb{E}_{v}^{l}\\left[\\int_{(r \\vee v, t]} \\mathbb{1}_{\\left\\{\\tau_{n}<u \\leqslant \\tau_{n+1}\\right\\}} N^{j k}(\\mathrm{~d} u)\\right]=\\mathbb{E}_{v}^{l}\\left[\\int_{(r \\vee v, t]} \\mathbb{1}_{\\left\\{\\tau_{n}<u \\leqslant \\tau_{n+1}\\right\\}} I^{j}(u-) \\Lambda^{j k}(\\mathrm{~d} u)\\right]\n$$\n\nBy applying the latter two equations and using equation (4.12) for pulling the factor $\\mathbb{1}_{\\tau_{n} \\geqslant v}$ out of the conditional expectations, for any $(v, l) \\in[0, \\infty) \\times \\mathcal{Z}$ with $v \\leqslant r$ we can conclude that\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{v}^{l}\\left[N^{j k}(t \\vee v)-N^{j k}(r \\vee v)\\right] & =\\sum_{n \\in \\mathbb{N}_{0}} \\mathbb{E}_{v}^{l}\\left[\\int_{\\left\\{r \\vee v, t\\right\\}} \\mathbb{1}_{\\left\\{\\tau_{n}<u \\leqslant \\tau_{n+1}\\right\\}} N^{j k}(\\mathrm{~d} u)\\right] \\\\\n& =\\mathbb{E}_{v}^{l}\\left[\\int_{\\left\\{r \\vee v, t \\vee v\\right\\}} I_{j}(u-) \\Lambda^{j k}(\\mathrm{~d} u)\\right]\n\\end{aligned}\n$$\n\nLet $J \\subset\\left\\{(j, k) \\in \\mathcal{Z}^{2}: j \\neq k\\right\\}$ be the set of transitions for which the corresponding transition rates are bounded on finite intervals. We assumed that for any recurrent sequence of transitions $i_{0} \\neq i_{1} \\neq \\cdots \\neq i_{n}$, at least one of the transitions $\\left(i_{l-1}, i_{l}\\right)$ is from the set $J$. If the sequence has a length greater than $|\\mathcal{Z}|$, then it necessarily contains a recurrent sub-sequence of maximum length $|\\mathcal{Z}|$, and this sub-sequences contains at least one transition from $J$ by our assumption. By removing the sub-sequence and iterating our arguments, we can conclude that a sequence of length $n$ contains at least $[n /|\\mathcal{Z}|]+|\\mathcal{Z}|-1$ transitions from $J$. So we have\n\n$$\n\\sum_{j, k: j \\neq k} N^{j k}(t) \\leqslant|\\mathcal{Z}|-1+|\\mathcal{Z}| \\sum_{(j, k) \\in J} N^{j k}(t)\n$$\n\nfor each $t \\in[0, \\infty)$. This fact and (4.13) yield\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[\\sum_{j, k: j \\neq k} N^{j k}(t)\\right] & =\\sum_{i} \\alpha(i) \\mathbb{E}_{0}^{i}\\left[\\sum_{j, k: j \\neq k} N^{j k}(t)\\right] \\\\\n& \\leqslant \\sum_{i} \\alpha(i)\\left(|\\mathcal{Z}|-1+|\\mathcal{Z}| \\mathbb{E}\\left[\\sum_{(j, k) \\in J}\\left(\\Lambda^{j k}(t)-\\Lambda^{j k}(0)\\right)\\right]\\right)\n\\end{aligned}\n$$\n\nwhich is finite. Therefore, the event $\\left(\\sum_{i, j: i \\neq j} N^{i j}(t)=\\infty\\right)$ must have a probability of zero, so that\n\n$$\n\\mathbb{P}[\\Omega]=\\mathbb{P}\\left[\\lim _{n \\rightarrow \\infty} \\tau_{n}=\\infty\\right]=1\n$$\n\nSimilarly, using (4.14) and (4.13) one can also show that $\\mathbb{P}_{s}^{i}[\\Omega](\\omega)=1$ for all $\\omega \\in \\Omega$. That means that $\\mathbb{P}$ is a probability measure and $\\mathbb{P}_{s}^{i}, s \\geqslant 0, i \\in \\mathcal{Z}$, are probability kernels also on the restricted measurable space\n\n$$\n\\left(\\Omega, \\widetilde{\\mathcal{F}}_{\\infty} \\cap \\Omega\\right)=\\left(\\Omega, \\mathcal{F}_{\\infty}\\right)\n$$\n\nThe properties (i) to (iii) still hold on this restricted space.\nWe now show uniqueness of $\\mathbb{P}$ and $\\mathbb{P}_{s}^{i}, s \\in[0, \\infty), i \\in \\mathcal{Z}$. Suppose that $\\widetilde{\\mathbb{P}}$ and $\\widetilde{\\mathbb{P}}_{s}^{i}, s \\in[0, \\infty)$, $i \\in \\mathcal{Z}$, also satisfy the properties (i) to (iii). Property (i) implies that\n\n$$\n\\begin{aligned}\n\\widetilde{\\mathbb{P}}_{s}^{i}[\\tau(s)>t](\\omega) & =\\sum_{j: j \\neq i} \\int_{[t, \\infty]} \\widetilde{\\mathbb{E}}_{s}^{i}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant u\\}} N^{i j}(\\mathrm{~d} u)\\right](\\omega) \\\\\n& =\\sum_{j: j \\neq i} \\int_{[t, \\infty]} \\widetilde{\\mathbb{P}}_{s}^{i}[\\tau(s) \\geqslant u](\\omega) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right), \\quad s<t<\\rho_{s}^{i}(\\omega)\n\\end{aligned}\n$$\n\nSince $\\widetilde{\\mathbb{P}}_{s}^{i}[\\tau(s)>s]=\\widetilde{\\mathbb{P}}_{s}^{i}[\\Omega](\\omega)=1$, see the definition of $\\tau(s)$, we have that the latter equation is equivalent to\n\n$$\n\\widetilde{\\mathbb{P}}_{s}^{i}[\\tau(s)>t](\\omega)=1-\\sum_{j: j \\neq i} \\int_{(s, t]} \\widetilde{\\mathbb{P}}_{s}^{i}[\\tau(s) \\geqslant u](\\omega) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right), \\quad s<t<\\rho_{s}^{i}(\\omega)\n$$\n\nSo, for each fixed $i \\in \\mathcal{Z}, s \\in[0, \\infty)$ and $\\omega \\in \\Omega$, the function $f(t)=\\widetilde{\\mathbb{P}}_{s}^{i}[\\tau(s)>t](\\omega)$ solves the Volterra integral equation\n\n$$\nf(t)=1-\\int_{(s, t]} f(u-) \\Lambda^{i *}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right), \\quad s<t<\\rho_{s}^{i}(\\omega)\n$$\n\nwhich has the product integral\n\n$$\nf(t)=\\prod_{s}^{t}\\left(1+\\Lambda^{i *}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right)\\right)=e^{-\\left(\\Lambda_{s}^{i *}(t)\\left(\\omega_{s}^{i}\\right)-\\Lambda_{s}^{i *}(s)\\left(\\omega_{s}^{i}\\right)\\right)} \\prod_{s<u \\leqslant t}\\left(1-\\Delta \\Lambda^{i *}(u)\\left(\\omega_{s}^{i}\\right)\\right), \\quad s<t<\\rho_{s}^{i}(\\omega)\n$$\n\nas its unique solution. That means that property (i) defines $\\widetilde{\\mathbb{P}}_{s}^{i}[\\tau(s)>t](\\omega)$ uniquely on $\\left(s, \\rho_{s}^{i}(\\omega)\\right)$. Moreover, property (i) also implies that\n\n$$\n\\widetilde{\\mathbb{P}}_{s}^{i}\\left[N^{i j}(t \\wedge \\tau(s))-N^{i j}(s)\\right](\\omega)=\\int_{(t, \\infty]} \\widetilde{\\mathbb{P}}_{s}^{i}[\\tau(s) \\geqslant u](\\omega) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right), \\quad s<t<\\rho_{s}^{i}(\\omega)\n$$\n\nfor $j \\in \\mathcal{Z}, j \\neq i$, so that also the mappings $\\widetilde{\\mathbb{P}}_{s}^{i}\\left[N^{i j}(t \\wedge \\tau(s))-N^{i j}(s)\\right](\\omega), j \\in \\mathcal{Z}$, are unique on $\\left(s, \\rho_{s}^{i}(\\omega)\\right)$. That means that the probability kernels (4.7) are uniquely characterized by property (i), and by the Ionescu-Tulcea theorem we get that $\\widetilde{\\mathbb{P}}_{s}^{i}=\\mathbb{P}_{s}^{i}, s \\in[0, \\infty), i \\in \\mathcal{Z}$. In particular, we have $\\widetilde{\\mathbb{P}}_{0}^{i}=\\mathbb{P}_{0}^{i}$, so by properties (ii) and (iii) we finally get $\\widetilde{\\mathbb{P}}=\\mathbb{P}$.\n\nThe following result confirms the role of $C^{j}$ from (3.4) as the compensator of $N^{j}$ defined in (3.5).\nProposition 4.2. Let $Y$ be a jointly measurable and $\\mathcal{F}^{-}$-adapted process such that\n\n$$\n\\mathbb{E}_{s}^{i}\\left[\\int_{(s, t]} \\mid Y(u) \\mid I^{j}(u-) \\Lambda^{j k}(\\mathrm{~d} u)\\right]<\\infty\n$$\n\nThen we have\n\n$$\n\\mathbb{E}_{s}^{i}\\left[\\int_{(s, t]} Y(u) N^{j k}(\\mathrm{~d} u)\\right]=\\mathbb{E}_{s}^{i}\\left[\\int_{(s, t]} Y(u) I^{j}(u-) \\Lambda^{j k}(\\mathrm{~d} u)\\right]\n$$\n\nfor $0 \\leqslant s<t<\\infty$ and $i, j, k \\in \\mathcal{Z}$ with $j \\neq k$.\nProof. At first, we show the assertion for each of the bounded processes $Y_{n}(t):=(Y(t) \\wedge n) \\vee(-n)$, $n \\in \\mathbb{N}$. For any $Y_{n}$, the proof is similar to the proof of Equation (4.13), but instead of Tonelli's theorem we apply Fubini's theorem and additionally exploit the fact that, whenever $Z(s)=i$, it holds that $Y(u)(\\omega)=Y(u)\\left(\\omega_{s}^{i}\\right)$ for $s<u \\leqslant \\tau(s)(\\omega)$. Based on the integrability condition, for $n$ going to infinity we obtain the assertion also for the limit $Y=\\lim _{n \\rightarrow \\infty} Y_{n}$.\n\nDefinition 4.3. Given the canonical measurable space $\\left(\\Omega, \\mathcal{F}_{\\infty}\\right)$, the probability mesaure $\\mathbb{P}$ on $\\left(\\Omega, \\mathcal{F}_{\\infty}\\right)$, the probability kernels $\\mathbb{P}_{s}^{i}, s \\in[0, \\infty), i \\in \\mathcal{Z}$, on $\\left(\\Omega, \\mathcal{F}_{\\infty}\\right)$, and the collection\n\n$$\n\\mathcal{P}:=\\left(\\left(\\mathbb{P}_{s}^{i}\\right)_{s \\in[0, \\infty), i \\in \\mathcal{Z}}, \\mathbb{P}\\right)\n$$\n\ndefined by Theorem 4.1 are called the canonical probability measure, canonical probability kernels, and canonical probability model generated by $(\\alpha, \\Lambda)$, respectively.\n\nFrom now on we generally work with the canonical probability model, since it provides the conditional expectations $\\mathbb{E}_{s}^{i}[\\cdot], s \\in[0, \\infty), i \\in \\mathcal{Z}$, which have all the usual properties of conditional expectations not only almost surely, but everywhere on $\\Omega$.\n\nProposition 4.4. For $s \\in[0, \\infty)$ and $i \\in \\mathcal{Z}$, let $Y$ be a $\\mathbb{P}_{s}^{i}$-integrable random variable. Then\n(i) For $C \\in \\mathcal{F}_{s-}$ and $j \\in \\mathcal{Z}$ it holds that\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{s}^{i}\\left[\\mathbb{1}_{C} Y\\right] & =\\mathbb{1}_{C} \\mathbb{E}_{s}^{i}[Y] \\\\\n\\mathbb{E}_{s}^{i}\\left[I^{j}(s) Y\\right] & =\\mathbb{1}_{j=i} \\mathbb{E}_{s}^{i}[Y]\n\\end{aligned}\n$$\n\n(ii) for $t \\in[s, \\infty)$ and $n \\in \\mathbb{N}_{0}$ it holds that\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{s}^{i}[Y] & =\\mathbb{E}_{s}^{i}\\left[\\mathbb{E}_{t}^{Z(t)}[Y]\\right] \\\\\n\\mathbb{1}_{\\left\\{\\tau_{n}>s\\right\\}} \\mathbb{E}_{s}^{i}[Y] & =\\mathbb{1}_{\\left\\{\\tau_{n}>s\\right\\}} \\mathbb{E}_{s}^{i}\\left[\\mathbb{E}_{\\tau_{n}}^{\\zeta}[Y]\\right]\n\\end{aligned}\n$$\n\nNote that this proposition genuinely does not need the usual 'almost sure' constraints.\nProof. For $X=\\mathbb{1}_{A}, A \\in \\mathcal{F}_{\\infty}$, the properties (i) and (ii) have already been shown in the proof of Theorem 4.1, see Equations (4.12), (4.11), and (4.10). From the building blocks $X=\\mathbb{1}_{A}$, $A \\in \\mathcal{F}_{\\infty}$, we can construct general random variables as limits of linear combinations of these building blocks. The linearity of the expectation operator $\\mathbb{E}_{s}^{i}[\\cdot]$ and the dominated convergence theorem then give the assertions.", "tables": {}, "images": {}}, {"section_id": 5, "text": "# Proposition 4.5. \n\n(i) If $\\Lambda$ is deterministic, then for each $s \\in[0, \\infty)$ and $i \\in \\mathcal{Z}$ the canonical probability kernel $\\mathbb{P}_{s}^{i}$ restricted to $\\sigma(Z(t): t \\geqslant s)$ is deterministic, and $Z$ is a Markov process (with respect to $\\mathbb{P}$ ).\n(ii) If $Z$ is a Markov process (with respect to $\\mathbb{P}$ ), then there exist deterministic transition rates $\\hat{\\Lambda}$ such that the canonical probability measure $\\widehat{\\mathbb{P}}$ generated by $(\\alpha, \\hat{\\Lambda})$ satisfies $\\widehat{\\mathbb{P}}=\\mathbb{P}$.\n\nProof. Suppose that $\\Lambda$ is deterministic. In the construction of $\\mathbb{P}_{s}^{i}[A]$ in the proof of Theorem 4.1, the value of $\\mathbb{P}_{s}^{i}[A](\\omega)$ depends on $\\omega$ via $\\Lambda(\\cdot)\\left(\\omega_{s}^{i}\\right)$ and $\\mathbb{1}_{A}\\left(\\omega_{s}^{i}\\right)$, see (4.9). So for $A \\in \\sigma(Z(s): s \\geqslant t)$, the mapping $\\omega \\mapsto \\mathbb{P}_{s}^{i}[A](\\omega)$ is constant if $\\omega \\mapsto \\Lambda(\\cdot)(\\omega)$ is constant, which means it is deterministic. Moreover, the latter fact and Equation 4.2 imply that $Z$ satisfies the Markov property.\n\nSuppose that $Z$ is a Markov process. Then for each $A \\in \\mathcal{F}_{s}, s \\in[0, \\infty)$ and $i \\in \\mathcal{Z}$ we almost surely have\n\n$$\nI^{i}(s) \\mathbb{P}_{s}^{i}[A]=I^{i}(s) \\mathbb{P}[A \\mid\\{Z(s)=i\\}]\n$$\n\nsee Equation (4.2). By the dominated convergence theorem, for each $s \\in[0, \\infty)$ and $i \\in \\mathcal{Z}$, the processes $t \\mapsto \\mathbb{E}_{s}^{i}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} N^{i j}(\\mathrm{~d} t)\\right]$ and $t \\mapsto \\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} N^{i j}(\\mathrm{~d} t) \\mid\\{Z(s)=i\\}\\right\\}$ ] are right-continuous and the processes $t \\mapsto \\mathbb{E}_{s}^{i}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}}\\right]$ and $t \\mapsto \\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} \\mid\\{Z(s)=i\\}\\right]$ ] are left-continuous. Therefore, we can conclude that simultaneously for all $t \\in[0, \\infty), s \\in[0, \\infty) \\cap \\mathbb{Q}, i \\in \\mathbb{Z}$ we almost surely have\n\n$$\n\\begin{aligned}\nI^{i}(s) \\frac{\\mathbb{E}_{s}^{i}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}_{s}^{i}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}}\\right]} & =I^{i}(s) \\frac{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} N^{i j}(\\mathrm{~d} t) \\mid\\{Z(s)=i\\}\\right]}{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} \\mid\\{Z(s)=i\\}\\right]} \\\\\n& =I^{i}(s) \\frac{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} I^{i}(s) N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} I^{i}(s)\\right]} \\\\\n& =I^{i}(s) \\frac{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} I^{i}(t-) N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} I^{i}(t-) \\mid\\right.}\n\\end{aligned}\n$$\n\nFrom this equation combined with Theorem 4.1(i) we obtain\n\n$$\n\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(s) \\Lambda^{i j}(\\mathrm{~d} t)=\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(s) \\frac{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant t\\}} I^{i}(t-)\\right]}, \\quad s<t \\leqslant \\tau(s)\n$$\n\nalmost surely for all $s \\in[0, \\infty) \\cap \\mathbb{Q}, i \\in \\mathbb{Z}$. As a consequence, for any rational partition $\\mathcal{T}$ of $[0, \\infty)$ we have\n\n$$\n\\begin{aligned}\n& \\int_{[0, u] \\cap(s, \\tau(s)]} \\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(s) \\Lambda^{i j}(\\mathrm{~d} t) \\\\\n& =\\sum_{\\mathcal{T}} \\int_{[0, u] \\cap(s, \\tau(s)] \\cap\\left(t_{k}, t_{k+1}\\right]} \\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(s) \\frac{\\mathbb{E}\\left[\\mathbb{1}_{\\left\\{\\tau\\left(s \\vee t_{k}\\right) \\geqslant t\\right\\}} N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}\\left[\\mathbb{1}_{\\left\\{\\tau\\left(s \\vee t_{k}\\right) \\geqslant t\\right\\}} I^{i}(t-)\\right]}\n\\end{aligned}\n$$\n\nalmost surely for all $u>0$. Let $\\left(\\mathcal{T}_{m}\\right)_{m \\in \\mathbb{N}}$ be a sequence of rational partitions of $[0, \\infty)$ with vanishing maximum step length. Then the latter line has an upper bound of\n\n$$\n\\begin{aligned}\n& \\lim _{m \\rightarrow \\infty} \\sum_{\\mathcal{T}_{m}} \\int_{[0, u] \\cap(s, \\tau(s)] \\cap\\left(t_{k}, t_{k+1}\\right]} \\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(s) \\frac{\\mathbb{E}\\left[N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}\\left[\\mathbb{1}_{\\left\\{\\tau\\left(s \\vee t_{k}\\right) \\geqslant t\\right\\}} I^{i}(t-)\\right]} \\\\\n& =\\int_{[0, u] \\cap(s, \\tau(s)]} \\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(s) \\frac{\\mathbb{E}\\left[N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}\\left[I^{i}(t-)\\right]}\n\\end{aligned}\n$$\n\nsince $\\mathbb{1}_{\\left\\{\\tau\\left(s \\vee t_{k}\\right) \\geqslant t\\right\\}} N^{i j}(\\mathrm{~d} t) \\leqslant N^{i j}(\\mathrm{~d} t)$ and $\\left\\{\\tau\\left(s \\vee t_{k}\\right) \\geqslant t\\right\\} \\uparrow \\Omega$ and by monotone convergence, and a lower bound of\n\n$$\n\\begin{aligned}\n& \\lim _{m \\rightarrow \\infty} \\sum_{\\mathcal{T}_{m}} \\int_{[0, u] \\cap(s, \\tau(s)] \\cap\\left(t_{k}, t_{k+1}\\right]} \\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(s) \\frac{\\mathbb{E}\\left[\\mathbb{1}_{\\left\\{\\tau\\left(s \\vee t_{k}\\right) \\geq t\\right\\}} N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}\\left[I^{i}(t-)\\right]} \\\\\n& =\\int_{[0, u] \\cap(s, \\tau(s)]} \\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(s) \\frac{\\mathbb{E}\\left[N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}\\left[I^{i}(t-)\\right]}\n\\end{aligned}\n$$\n\nsince $\\mathbb{1}_{\\left\\{\\tau\\left(s \\vee t_{k}\\right) \\geqslant t\\right\\}} N^{i j}(\\mathrm{~d} t) \\uparrow \\mathbb{1}_{\\Omega} N^{i j}(\\mathrm{~d} t)$. Since the upper and lower bound are equal, we can conclude that\n\n$$\n\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-) \\Lambda^{i j}(\\mathrm{~d} t)=\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-) \\frac{\\mathbb{E}\\left[N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}\\left[I^{i}(t-)\\right]}, \\quad t>0\n$$\n\nalmost surely, and because of the assumption (3.6) we even have\n\n$$\n\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} \\Lambda^{i j}(\\mathrm{~d} t)=\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} \\frac{\\mathbb{E}\\left[N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}\\left[I^{i}(t-)\\right]}, \\quad t>0\n$$\n\nalmost surely. Therefore, for the deterministic transition rates $\\tilde{\\Lambda}$ defined by\n\n$$\n\\tilde{\\Lambda}^{i j}(\\mathrm{~d} t)=\\frac{\\mathbb{E}\\left[N^{i j}(\\mathrm{~d} t)\\right]}{\\mathbb{E}\\left[I^{i}(t-)\\right]}, \\quad i, j \\in \\mathcal{Z}, i \\neq j\n$$\n\nand $\\tilde{\\Lambda}^{i j}(r):=0$ for $r=0$ and all time points that are poles of this function, we have that $\\tilde{\\Lambda}-\\tilde{\\Lambda}(0)=\\Lambda-\\Lambda(0) \\mathbb{P}$-almost surely. So there exist an $\\Omega^{\\prime} \\in \\mathcal{F}_{\\infty}$ with $\\mathbb{P}\\left[\\Omega^{\\prime}\\right]=1$ such that $\\tilde{\\Lambda}-\\tilde{\\Lambda}(0)=\\Lambda-\\Lambda(0)$ everywhere on $\\Omega^{\\prime}$. According to the explicit construction of $\\mathbb{P}$ in the proof of Theorem 4.1, the restricted measures $\\left.\\mathbb{P}\\right|_{\\Omega^{\\prime}}$ and $\\left.\\tilde{\\mathbb{P}}\\right|_{\\Omega^{\\prime}}$ generated by $(\\alpha, \\Lambda)$ and $(\\alpha, \\tilde{\\Lambda})$ are equal, see (4.8). In particular, we have $\\tilde{\\mathbb{P}}\\left[\\Omega^{\\prime}\\right]=\\mathbb{P}[\\Omega]=1$ so that\n\n$$\n\\tilde{\\mathbb{P}}[A]=\\tilde{\\mathbb{P}}\\left[A \\cap \\Omega^{\\prime}\\right]=\\mathbb{P}\\left[A \\cap \\Omega^{\\prime}\\right]=\\mathbb{P}[A], \\quad A \\in \\mathcal{F}_{\\infty}\n$$\n\nProposition 4.6 (Absolutely continuous modeling). Let $i, j \\in \\mathcal{Z}, j \\neq i$. The following conditions are equivalent:\n(a) $\\Lambda^{i j}$ is left-differentiable everywhere and continuously differentiable in between jump times of $Z$.\n(b) The process $\\mu^{i j}$ defined by\n\n$$\n\\mu^{i j}(t):=\\lim _{s \\uparrow t} \\frac{\\mathbb{P}_{s}^{i}[Z(t)=j]}{t-s}, \\quad t \\in(0, \\infty)\n$$\n\nexists, is continuous in between jump times of $Z$, and satisfies the equation\n\n$$\n\\mu^{i j}(t)=\\lim _{u \\downarrow t} \\frac{\\mathbb{P}_{t}^{i}[Z(u)=j]}{u-t}, \\quad Z(t-)=Z(t)\n$$\n\nassuming that this limit exists.\nUnder both conditions, we moreover have\n\n$$\n\\Lambda^{i j}(\\mathrm{~d} t)=\\mu^{i j}(t) \\mathrm{d} t, \\quad t \\in[0, \\infty)\n$$\n\nProof. The property (i) of Theorem 4.1 and the construction (4.5) imply that\n\n$$\n\\begin{aligned}\n\\lim _{t \\downarrow s} \\frac{\\mathbb{P}_{s}^{i}[Z(t \\wedge \\tau(s))=j](\\omega)}{t-s} & =\\lim _{t \\downarrow s} \\frac{1}{t-s} \\int_{(s, t]} p_{s}^{i}(u-)(\\omega) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\\\\n& =\\lim _{t \\downarrow s} \\frac{\\Lambda^{i j}(t)\\left(\\omega_{s}^{i}\\right)-\\Lambda^{i j}(s)\\left(\\omega_{s}^{i}\\right)}{t-s}\n\\end{aligned}\n$$\n\nsince the integrand converges to 1 for $t \\downarrow s$, uniformly for sufficiently small $t$. By similar arguments and Proposition 4.4, we get\n\n$$\n\\begin{aligned}\n\\lim _{t \\downarrow s} \\frac{1}{t-s} \\mathbb{P}_{s}^{i}[\\tau(\\tau(s)) \\leqslant t](\\omega) & =\\lim _{t \\downarrow s} \\frac{1}{t-s} \\mathbb{E}_{s}^{i}\\left[\\mathbb{P}_{\\tau(s)}^{Z(\\tau(s))}[\\tau(\\tau(s)) \\leqslant t](\\omega)\\right. \\\\\n& =\\lim _{t \\downarrow s} \\frac{1}{t-s} \\sum_{j: j \\neq i} \\int_{(s, t]} \\mathbb{P}_{u}^{j}[\\tau(u) \\leqslant t]\\left(\\omega_{s}^{i}\\right) p_{s}^{i}(u-)(\\omega) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\\\\n& =\\lim _{t \\downarrow s} \\frac{1}{t-s} \\sum_{j: j \\neq i} \\int_{(s, t]}\\left(1-p_{s}^{i}(u-)\\left(\\omega_{s}^{i}\\right)\\right) p_{s}^{i}(u-)(\\omega) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\\\\n& =0\n\\end{aligned}\n$$\n\nsince the integrand converges to 0 for $t \\downarrow s$, uniformly for sufficiently small $t$. Combining both results yields that\n\n$$\n\\begin{aligned}\n\\lim _{t \\downarrow s} \\frac{\\mathbb{P}_{s}^{i}[Z(t)=j](\\omega)}{t-s} & =\\lim _{t \\downarrow s} \\frac{\\Lambda^{i j}(t)\\left(\\omega_{s}^{i}\\right)-\\Lambda^{i j}(s)\\left(\\omega_{s}^{i}\\right)}{t-s} \\\\\n& =\\lim _{t \\downarrow s} \\frac{\\Lambda^{i j}(t)(\\omega)-\\Lambda^{i j}(s)(\\omega)}{t-s}, \\quad Z(s-)=Z(s)\n\\end{aligned}\n$$\n\nwhere the last equation uses the right-continuity of $Z$ and the Assumption 3.1(a). Since $Z$ is a c\u00e0dl\u00e0g process, for each $\\omega \\in \\Omega$ there exists an $\\varepsilon_{\\omega}>0$ such that $\\omega_{s}^{i}=\\omega_{t}^{i}$ for $s \\in\\left(t-\\varepsilon_{\\omega}, t\\right]$. By\n\nusing the same asymptotic arguments as above, we get\n\n$$\n\\begin{aligned}\n\\lim _{s \\uparrow t} \\frac{\\mathbb{P}_{s}^{i}[Z(t)=j](\\omega)}{t-s} & =\\lim _{t \\uparrow s} \\frac{\\Lambda^{i j}(t)\\left(\\omega_{t}^{j}\\right)-\\Lambda^{i j}(s)\\left(\\omega_{t}^{j}\\right)}{t-s} \\\\\n& =\\lim _{t \\uparrow s} \\frac{\\Lambda^{i j}(t)(\\omega)-\\Lambda^{i j}(s)(\\omega)}{t-s}\n\\end{aligned}\n$$\n\nwhere the second equation uses the Assumption 3.1(a).\nNow, if statement (a) holds, then $\\mu^{i j}$ exists and is continuous in between jump times because of (4.17). Moreover, in between jump times it equals $\\lim _{h \\downarrow 0} \\frac{\\mathbb{P}_{t-n}^{i}[Z(t)=j]}{h}$ because of (4.16) and the differentiability of $\\Lambda^{i j}$. In particular, we have $\\Lambda^{i j}(\\mathrm{~d} t)=\\mu^{i j}(t) \\mathrm{d} t$ since $\\mu^{i j}$ is the derivative of $\\Lambda^{i j}$ in between jump times and since there are at most countably many jump times.\n\nIf statement (b) holds, then $\\Lambda^{i j}$ is left-differentiable because of (4.17), and the left-derivative is continuous in between jump times. Moreover, in between jump times, $\\Lambda^{i j}$ has a right-derivative that equals the left-derivative because of (4.16).\n\nProposition 4.7 (Discrete modeling). The two following conditions are equivalent:\n(a) $\\Lambda$ has pure jump paths with jumps only at integer times.\n(b) $\\mathbb{E}_{s}^{i}\\left[N^{i j}(\\mathrm{~d} t)\\right]=0$ for $n \\leqslant s \\leqslant t<n+1, i, j \\in \\mathcal{Z}, i \\neq j, n \\in \\mathbb{N}_{0}$.\n\nMoreover, for $\\Omega_{d}:=\\left\\{\\left(t_{k}, z_{k}\\right)_{k \\in \\mathbb{N}_{0}} \\in \\Omega: t_{k} \\in \\mathbb{N}_{0} \\cup\\{\\infty\\}, k \\in \\mathbb{N}_{0}\\right\\}$ the conditions imply that $\\mathbb{P}\\left[\\Omega_{d}\\right]=1$ as well as\n\n$$\n\\Delta \\Lambda^{i j}(n+1)(\\omega)=\\mathbb{P}_{n}^{i}[Z(n+1)=j](\\omega), \\quad \\omega \\in \\Omega_{d}\n$$\n\nfor $i, j \\in \\mathcal{Z}, i \\neq j, n \\in \\mathbb{N}_{0}$.\nProof. For $n \\leqslant s<n+1$, Theorem 4.1(i) implies that\n\n$$\n\\begin{aligned}\n\\mathbb{P}_{s}^{i}[\\tau(s) \\geqslant n+1] & =1-\\sum_{j: j \\neq i} \\int_{(s, n+1)} \\mathbb{E}_{s}^{i}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant u\\}} N^{i j}(\\mathrm{~d} u)\\right] \\\\\n& =1-\\sum_{j: j \\neq i} \\int_{(s, n+1)} \\mathbb{P}_{s}^{i}[\\tau(s) \\geqslant u] \\Lambda^{i j}(\\mathrm{~d} u)\n\\end{aligned}\n$$\n\nNote that if the interval $(s, n+1)$ contains reset points of $\\Lambda^{i *}$, then $\\mathbb{P}_{s}^{i}[\\tau(s) \\geqslant u]$ is nonzero only strictly before the smallest of these reset points. If condition (a) holds, then from the latter equation we can conclude that $\\mathbb{P}_{s}^{i}[\\tau(s) \\geqslant n+1]=1$, which implies (b). If condition (b) holds, then we can conclude that\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{s}^{i}\\left[\\mathbb{1}_{\\{\\tau(s) \\geqslant u\\}} N^{i j}(\\mathrm{~d} u)\\right] & =0 \\\\\n\\mathbb{P}_{s}^{i}[\\tau(s) \\geqslant u] \\geqslant \\mathbb{P}_{s}^{i}[\\tau(s) \\geqslant n+1] & =1, \\quad s<u<n+1\n\\end{aligned}\n$$\n\nThis implies that $\\Lambda^{i j}(\\mathrm{~d} u)=0$ for $s<u<n+1$ and $u$ smaller than any reset point of $\\Lambda^{i *}$ in $(s, n+1)$. In particular, $\\Lambda^{i j}$ is constant immediately before any reset point, which is impossible, so there are no reset points. That means that (a) holds.\n\nSuppose that the equivalent conditions (a) and (b) hold. From the measurability assumption (3.6) and Theorem 4.1(i) we get\n\n$$\n\\begin{aligned}\n\\Delta \\Lambda^{i j}(n+1)(\\omega) & =\\Delta \\Lambda^{i j}(n+1)\\left(\\omega_{n}^{i}\\right) \\\\\n& =\\frac{\\mathbb{E}_{n}^{i}\\left[\\mathbb{1}_{\\{\\tau(n) \\geqslant n+1\\}}\\left(N^{i j}(n+1)-N^{i j}(n)\\right)\\right](\\omega)}{\\mathbb{E}_{n}^{i}\\left[\\mathbb{1}_{\\{\\tau(n) \\geqslant n+1\\}}\\right](\\omega)} \\\\\n& =\\mathbb{P}_{n}^{i}[Z(n+1)=j](\\omega), \\quad \\omega \\in \\Omega_{d}\n\\end{aligned}\n$$\n\nMoreover, Proposition 4.4(b) together with condition (b) implies that\n\n$$\n\\mathbb{E}\\left[N^{i j}(\\mathrm{~d} t)\\right]=0, \\quad n \\leqslant t<n+1, i, j \\in \\mathcal{Z}, i \\neq j, n \\in \\mathbb{N}_{0}\n$$\n\nfrom which we can conclude that $\\mathbb{P}\\left[\\tau_{n} \\in(0, \\infty) \\backslash \\mathbb{N}\\right]=0, n \\in \\mathbb{N}_{0}$. Thus,\n\n$$\n\\mathbb{P}\\left[\\Omega \\backslash \\Omega_{d}\\right] \\leqslant \\sum_{n=0}^{\\infty} \\mathbb{P}\\left[\\tau_{n} \\in(0, \\infty) \\backslash \\mathbb{N}\\right]=0\n$$\n\nwhich completes the proof.", "tables": {}, "images": {}}, {"section_id": 6, "text": "# 5 Stochastic Kolmogorov backward equation \n\nThis section studies the time-dynamics of\n\n$$\ns \\mapsto \\mathbb{P}_{s}^{i}[A]\n$$\n\nfor any state $i \\in \\mathcal{Z}$ and events $A$ that can be observed in finite time. Recall that $\\mathbb{P}_{s}^{i}[A]$ can be interpreted as a version of the statewise conditional probability $\\mathbb{P}[A \\mid \\mathcal{F}_{s-}, Z(s)=i]$, see Theorem 4.1(i).\n\nWe say that a process $Y$ is bounded on finite intervals if for each finite interval $I \\subset[0, \\infty)$ the mapping $Y: I \\times \\Omega \\rightarrow \\mathbb{R}$ is bounded.\n\nDefinition 5.1. Let $\\mathcal{Y}(\\Lambda)$ denote the set of all $\\mathcal{F}^{-}$-adapted, jointly measurable, multivariate processes $\\left(Y^{i}\\right)_{i \\in \\mathcal{Z}}$ that are bounded on finite intervals, and such that the paths of $I^{i}(t-) Y^{i}(\\mathrm{~d} t)$ are c\u00e0dl\u00e0g and of finite variation on each compact interval that contains no reset points of $\\Lambda^{i^{*}}$.\n\nTheorem 5.2 (stochastic Kolmogorov backward equation). Let $A \\in \\mathcal{F}_{T}$ for $T<\\infty$, and let $P^{i}$, $i \\in \\mathcal{Z}$, be given stochastic processes. The two following statements are equivalent:\n(i) The multivariate process $\\left(P^{i}\\right)_{i \\in \\mathcal{Z}}$ satisfies $P^{i}(t)=\\mathbb{P}_{t}^{i}[A], t \\in[0, T]$.\n(ii) The multivariate process $\\left(P^{i}\\right)_{i \\in \\mathcal{Z}}$ is a solution in $\\mathcal{Y}(\\Lambda)$ for the backward equation\n\n$$\n0=\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-)\\left(P^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(P^{j}(t)-P^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\\right)\n$$\n\nwith terminal value $P^{i}(T)=\\mathbb{P}_{T}^{i}[A]$.\nIf for a subset $\\mathcal{Z}_{0} \\subset \\mathcal{Z}$ we have $\\Lambda^{i j}=0$ for all $i \\in \\mathcal{Z}_{0}$ and $j \\notin \\mathcal{Z}_{0}$, then the equivalence is also true for the sub-process $\\left(P^{i}\\right)_{i \\in \\mathcal{Z}_{0}}$ only.\n\nWe interpret the right hand side of Equation (5.1) as a $\\sigma$-finite measure, and the equation tells us that this measure is zero on the set of reset points, and it is zero on any compact interval that does not contain reset points. There exists a countable number of such compact intervals that covers the whole set $\\left\\{t \\in[0, \\infty): \\Delta \\Lambda^{i^{*}}(t) \\geqslant 0\\right\\}$. So the measure is zero everywhere on $[0, \\infty)$.\n\nExample 5.3 (Markov process). By Proposition 4.5, a deterministic $\\Lambda$ corresponds to a Markov model. In that case, the canonical probability kernels restricted to future events are also deterministic. Thus if $A \\in \\sigma\\left(Z_{T}\\right)$, Equation (5.1) can be simplified to\n\n$$\n0=\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}}\\left(P^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(P^{j}(t)-P^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\\right)\n$$\n\nIf there are also no reset points, we conclude that\n\n$$\nP^{i}(\\mathrm{~d} t)=-\\sum_{j: j \\neq i}\\left(P^{j}(t)-P^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\n$$\n\nwhich recovers the classic Kolmogorov backward equation.\nProof of Theorem 5.2. At first we show that (i) implies (ii). The boundedness of $P^{i}$ follows directly from the fact that probabilities cannot be greater than one. In the proof of Theorem 4.1 we already showed that the probability kernels $p_{s}^{i j}(t)(\\omega)$ are jointly measurable as mappings of $(s, \\omega, t)$, see the arguments below (4.7). For each $A \\in \\mathcal{F}_{\\tau_{n}}$ and $n \\in \\mathbb{N}$, the mapping $(s, i, \\omega) \\mapsto$ $\\mathbb{P}_{s}^{i}[A](\\omega)$ is defined by repeated Lebesgue-Stieltjes integration of the probability kernels with respect to the argument $t$ and summation over $i$, see (4.9), so Fubini's theorem yields joint measurability with respect to $(s, \\omega)$. Since $\\bigcup_{n \\in \\mathbb{N}_{0}} \\mathcal{F}_{\\tau_{n}}$ contains a generator of $\\mathcal{F}_{T}$, we also have the joint measurability property for any $A \\in \\mathcal{F}_{T}$. The constructions (4.5) and (4.9) imply that $\\mathbb{P}_{s}^{i}[A](\\omega)=\\mathbb{P}_{s}^{i}[A]\\left(\\omega_{s}^{i}\\right), \\omega \\in \\Omega$, which means that $\\mathbb{P}_{s}^{i}[A]$ is $\\mathcal{F}_{s-}$-measurable. Proposition 4.4(i) yields that $P^{i}(T)=\\mathbb{1}_{A}, i \\in \\mathcal{Z}$. It remains to show that (5.1) holds. Let $\\omega=\\left(\\left(t_{l}, z_{l}\\right)\\right)_{l \\in \\mathbb{N}_{0}} \\in \\Omega$ be arbitrary but fixed. The definition of $p_{s}^{i}$ implies that\n\n$$\np_{s}^{i}(u-)\\left(\\omega_{s}^{i}\\right)=1-\\sum_{k: k \\neq i} \\int_{(s, u)} p_{v}^{i}(u-)\\left(\\omega_{s}^{i}\\right) \\Lambda^{i k}(\\mathrm{~d} v)\\left(\\omega_{s}^{i}\\right), \\quad s<u<\\rho_{s}^{i}(\\omega)\n$$\n\nFrom (4.10) and the definitions (4.9) and (4.5), we obtain the equation\n\n$$\n\\begin{aligned}\n\\mathbb{P}_{s}^{i}[A](\\omega) & =\\mathbb{E}_{s}^{i}\\left[\\mathbb{P}_{\\tau(s)}^{Z(\\tau(s))}[A]\\right](\\omega) \\\\\n& =\\sum_{j: j \\neq i} \\int_{(s, \\infty]} \\mathbb{P}_{u}^{j}[A]\\left(\\omega_{s}^{i}\\right) p_{s}^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\\\\n& =\\sum_{j: j \\neq i} \\int_{(s, \\infty]} \\mathbb{P}_{u}^{j}[A]\\left(\\omega_{s}^{i}\\right) p_{s}^{i}(u-)\\left(\\omega_{s}^{i}\\right) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right)\n\\end{aligned}\n$$\n\nBy replacing $p_{s}^{i}(u-)\\left(\\omega_{s}^{i}\\right)$ by (5.2) and applying Tonelli's theorem, we obtain\n\n$$\n\\begin{aligned}\n& \\mathbb{P}_{s}^{i}[A](\\omega)-\\mathbb{P}_{t}^{i}[A](\\omega) \\\\\n& =\\sum_{j: j \\neq i} \\int_{(s, \\infty]} \\mathbb{1}_{s<u \\leqslant t} \\mathbb{P}_{u}^{j}[A]\\left(\\omega_{s}^{i}\\right) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\\\\n& \\quad-\\sum_{j: j \\neq i} \\int_{(s, \\infty]} \\mathbb{P}_{u}^{j}[A]\\left(\\omega_{s}^{i}\\right) \\sum_{k: k \\neq i} \\int_{(s, \\infty)}\\left(\\mathbb{1}_{s<v<u}-\\mathbb{1}_{t<v<u}\\right) p_{v}^{i}(u-)\\left(\\omega_{s}^{i}\\right) \\Lambda^{i k}(\\mathrm{~d} v)\\left(\\omega_{s}^{i}\\right) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\\\\n& =\\sum_{j: j \\neq i} \\int_{[0, \\infty]} \\mathbb{1}_{s<u \\leqslant t} \\mathbb{P}_{u}^{j}[A]\\left(\\omega_{s}^{i}\\right) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\\\\n& \\quad-\\sum_{k: k \\neq i} \\int_{[0, \\infty]} \\mathbb{1}_{s<v \\leqslant t} \\sum_{j: j \\neq i} \\int_{[0, \\infty]} \\mathbb{1}_{v<u} \\mathbb{P}_{u}^{j}[A]\\left(\\omega_{s}^{i}\\right) p_{v}^{i}(u-)\\left(\\omega_{s}^{i}\\right) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\Lambda^{i k}(\\mathrm{~d} v)\\left(\\omega_{s}^{i}\\right)\n\\end{aligned}\n$$\n\nfor $s<t \\leqslant \\tau(s)(\\omega)$ and $t<\\rho_{s}^{i}(\\omega)$. Since $\\left(\\omega_{s}^{i}\\right)_{v}^{i}=\\omega_{s}^{i}$ for $v>s$, the inner integral in the latter line equals $\\mathbb{P}_{v}^{i}[A]\\left(\\omega_{s}^{i}\\right)$, see (5.3), so that we can conclude that\n\n$$\n\\begin{aligned}\n& \\mathbb{P}_{s}^{i}[A](\\omega)-\\mathbb{P}_{t}^{j}[A](\\omega) \\\\\n& =\\sum_{j: j \\neq i} \\int_{(s, t]} \\mathbb{P}_{u}^{j}[A]\\left(\\omega_{s}^{i}\\right) \\Lambda^{i j}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right)-\\sum_{k: k \\neq i} \\int_{(s, t]} \\mathbb{P}_{u}^{i}[A]\\left(\\omega_{s}^{i}\\right) \\Lambda^{i k}(\\mathrm{~d} u)\\left(\\omega_{s}^{i}\\right) \\\\\n& =\\sum_{j: j \\neq i} \\int_{(s, t]}\\left(\\mathbb{P}_{u}^{j}[A](\\omega)-\\mathbb{P}_{u}^{i}[A](\\omega)\\right) \\Lambda^{i j}(\\mathrm{~d} u)(\\omega)\n\\end{aligned}\n$$\n\nfor $s<t \\leqslant \\tau(s)(\\omega)$ and $t<\\rho_{s}^{i}(\\omega)$, using the fact that $\\mathbb{P}_{u}^{i}[A]\\left(\\omega_{s}^{i}\\right)=\\mathbb{P}_{u}^{i}[A](\\omega)$ and $\\Lambda^{i k}(u)\\left(\\omega_{s}^{i}\\right)=$ $\\Lambda^{i k}(u)(\\omega)$ for $u \\in(s, t]$ and $\\omega \\in\\left\\{\\tau_{n} \\leqslant s<t \\leqslant \\tau_{n+1}\\right\\}$ due to their $\\mathcal{F}$-adaptedness and (2.2). All in all, this verifies that (a) implies (b). If $\\Lambda^{i j}=0$ for all $i \\in \\mathcal{Z}_{0}$ and $j \\notin \\mathcal{Z}_{0}$ for a subset $\\mathcal{Z}_{0} \\subset \\mathcal{Z}$, then the subset of equations (5.1) on $\\mathcal{Z}_{0}$ depends only on the sub-process $\\left(P^{i}\\right)_{i \\in \\mathcal{Z}_{0}}$.\n\nNow we show that (i) implies (ii). Integration by parts yields that\n\n$$\n\\begin{aligned}\n& \\sum_{i} I^{i}(s) P^{i}(s)-\\sum_{i} I^{i}(t) P^{i}(t) \\\\\n& =\\sum_{i, j: j \\neq i} \\int_{(s, t]}\\left(P^{j}(u)-P^{i}(u)\\right) N^{i j}(\\mathrm{~d} u)+\\sum_{i} \\int_{(s, t]} I^{i}(u-) P^{i}(\\mathrm{~d} u)\n\\end{aligned}\n$$\n\nfor $s<t \\leqslant \\tau(s)(\\omega)$ and $t<\\rho_{s}^{i}(\\omega)$. We subtract the equation (5.1) and rearrange the terms in order to arrive at the equation\n\n$$\n\\begin{aligned}\n& \\sum_{i} I^{i}(s) P^{i}(s)-\\sum_{i} I^{i}(t) P^{i}(t) \\\\\n& =\\sum_{j, j: j \\neq i} \\int_{(s, t]}\\left(P^{j}(u)-P^{i}(u)\\right)\\left(N^{i j}(\\mathrm{~d} u)-I^{i}(u-) \\Lambda^{i j}(\\mathrm{~d} u)\\right)\n\\end{aligned}\n$$\n\nfor $s<t \\leqslant \\tau(s)(\\omega)$ and $t<\\rho_{s}^{i}(\\omega)$. By taking the expectation $\\mathbb{E}_{s}^{i}[\\cdot]$ on both sides, applying Proposition 4.2, and using the fact that $\\mathbb{P}_{s}^{i}\\left[\\tau(s)<\\rho_{s}^{i}\\right]=1$, we obtain\n\n$$\n\\mathbb{E}_{s}^{i}\\left[\\sum_{j} I^{j}(s) P^{j}(s)-\\sum_{j} I^{j}(\\tau(s)) P^{j}(\\tau(s))\\right]=0\n$$\n\nBy repeating this argument along the sequence of jump times $\\left(\\tau_{n}\\right)_{n \\in \\mathbb{N}_{0}}$, which converges to $\\lim _{n \\rightarrow \\infty} \\tau_{n}=\\infty>T$ by the definition of $\\Omega$, and using the tower property of conditional expectations according to Proposition 4.4(b), we even get\n\n$$\n\\mathbb{E}_{s}^{i}\\left[\\sum_{j} I^{j}(s) P^{j}(s)-\\sum_{j} I^{j}(T) P^{j}(T)\\right]=0, \\quad s \\leqslant T\n$$\n\nBy applying Proposition 4.4(i) and using the equation $\\sum_{j} I^{j}(T) P^{j}(T)=\\mathbb{1}_{A}$, we can simplify the latter equation as\n\n$$\nP^{i}(s)-\\mathbb{E}_{s}^{i}\\left[\\mathbb{1}_{A}\\right], \\quad s \\leqslant T\n$$\n\nwhich verifies (i). If $\\Lambda^{i j}=0$ for all $i \\in \\mathcal{Z}_{0}$ and $j \\notin \\mathcal{Z}_{0}$ for a subset $\\mathcal{Z}_{0} \\subset \\mathcal{Z}$, then we necessarily have $\\mathbb{P}_{s}^{i}[Z(t)=j]=0, i \\in \\mathcal{Z}_{0}, j \\in \\mathcal{Z} \\backslash \\mathcal{Z}_{0}, 0 \\leqslant s \\leqslant t$, according to the definition of $\\mathbb{P}_{s}^{i}$ in (4.5) and (4.9). Therefore, in case of $i \\in \\mathcal{Z}_{0}$, in equation (5.4) we can restrict the sums over $j$ to the subset $\\mathcal{Z}_{0}$. This means that the $\\mathcal{Z}_{0}$-subset of equations (5.1) already suffices to obtain $P^{i}(s)-\\mathbb{E}_{s}^{i}\\left[\\mathbb{1}_{A}\\right]$, $i \\in \\mathcal{Z}_{0}$.\n\nExample 5.4. In the setting of Proposition 4.6, Equation (5.1) almost surely corresponds to the differential equation\n\n$$\n0=I^{i}(t-)\\left(\\frac{\\mathrm{d}}{\\mathrm{~d} t} P^{i}(t)+\\sum_{j: j \\neq i}\\left(P^{j}(t)-P^{i}(t)\\right) \\mu^{i j}(t)\\right)\n$$\n\nExample 5.5. In the setting of Proposition 4.7, Equation (5.1) almost surely corresponds to the backward recursion equation\n\n$$\n{ }_{T-(n-1)} p_{n-1}^{i k}={ }_{T-n} p_{n}^{i k}+\\sum_{j: j \\neq i}\\left({ }_{T-n} p_{n}^{j k}-{ }_{T-n} p_{n}^{j k}\\right) q_{n-1}^{i j}, \\quad Z(n-1)=i\n$$\n\nfor $n \\in\\{0,1, \\ldots, T-1\\}$ with terminal condition ${ }_{0} p_{T}^{i k}=\\mathbb{1}_{i=k}$, where\n\n$$\n{ }_{T-n} p_{n}^{i k}:=\\mathbb{P}_{n}^{i}[Z(T)=k]\n$$", "tables": {}, "images": {}}, {"section_id": 7, "text": "# 6 State-wise conditional expectation processes \n\nThis section studies the time-dynamics of\n\n$$\ns \\mapsto \\mathbb{E}_{s}^{i}[Y(T)-Y(s)]\n$$\n\nfor any state $i \\in \\mathcal{Z}$ and an $\\mathcal{F}$-adapted c\u00e0dl\u00e0g process $Y$ that is sufficiently integrable. We first introduce a large class of integrable processes $Y$, and then we study the path properties of the above expectation process.\nDefinition 6.1. Let $\\mathbb{Y}^{+}$denote the set of all $\\mathcal{F}$-adapted, nonnegative, nondecreasing, univariate c\u00e0dl\u00e0g processes $Y$ for which there exists a growth bound\n\n$$\nY(t) \\leqslant g(t)\\left(1+\\sum_{i, j: i \\neq j} N^{i j}(t)\\right)^{n}, \\quad t \\geqslant 0\n$$\n\nfor some function $g:[0, \\infty) \\rightarrow[0, \\infty)$ and a positive integer $n \\in \\mathbb{N}$; both $g$ and $n$ may depend on $Y$. By $\\mathbb{Y}$ we denote the set of all processes that can be generated as a difference of processes from $\\mathbb{Y}^{+}$.\n\nNote that $Y \\in \\mathbb{Y}$ has paths of finite variation on finite intervals since it equals the difference of monotone processes.\n\nProposition 6.2. For $i, j \\in \\mathcal{Z}, i \\neq j, T \\in[0, \\infty)$, and $n \\in \\mathbb{N}$, it holds that\n\n$$\n\\sup _{0 \\leqslant s \\leqslant t \\leqslant T} \\sup _{\\omega \\in \\Omega} \\mathbb{E}_{s}^{i}\\left[\\left(N^{i j}(t)-N^{i j}(s)\\right)^{n}\\right](\\omega)<\\infty\n$$\n\nIn particular, for $Y \\in \\mathbb{Y}$ we have\n\n$$\n\\sup _{0 \\leqslant s \\leqslant t \\leqslant T} \\sup _{\\omega \\in \\Omega} \\mathbb{E}_{s}^{i}[|Y(t)-Y(s)|](\\omega)<\\infty\n$$\n\nProof. Let $J \\subset\\left\\{(j, k) \\in \\mathcal{Z}^{2}: j \\neq k\\right\\}$ be the subset of transitions for which the corresponding transition rates are bounded on finite intervals, i.e.\n\n$$\n\\sup _{0 \\leqslant s \\leqslant t \\leqslant T}\\left|\\Lambda^{j k}(t)-\\Lambda^{j k}(s)\\right| \\leqslant\\left|\\Lambda^{j k}(T)-\\Lambda^{j k}(0)\\right| \\leqslant C<\\infty, \\quad(j, k) \\in J\n$$\n\nfor a deterministic constant $C$. Thus, by equation (4.14) and (4.13) we get the finite upper bound\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{s}^{i}\\left[\\sum_{j, k: j \\neq k}\\left(N_{j k}(t)-N_{j k}(s)\\right)\\right] & \\leqslant|\\mathcal{Z}|-1+|\\mathcal{Z}| \\mathbb{E}_{s}^{i}\\left[\\sum_{(j, k) \\in J}\\left(\\Lambda^{j k}(t)-\\Lambda^{j k}(s)\\right)\\right] \\\\\n& \\leqslant|\\mathcal{Z}|-1+|\\mathcal{Z}||\\mathcal{Z}|(|\\mathcal{Z}|-1) C\n\\end{aligned}\n$$\n\nuniformly for all $\\omega \\in \\Omega$ and all $0 \\leqslant s \\leqslant t \\leqslant T$. Since the addends on the left hand side are all non-negative, the first assertion follows for $n=1$. We generalize the result to any $n \\in \\mathbb{N}$ by induction. Suppose that the statement of the proposition is true for all $n \\leqslant m \\in \\mathbb{N}$. Since $(a+1)^{m+1}-a^{m+1}=\\sum_{l=0}^{m}\\binom{m+1}{l} a^{l}$ for any $a \\in[0, \\infty)$, we have\n\n$$\n\\left(N^{j k}(t)-N^{j k}(s)\\right)^{m+1}=\\sum_{l=0}^{m}\\binom{m+1}{l} \\int_{(s, t)}\\left(N^{j k}(u)-N^{j k}(s)\\right)^{l} N^{j k}(\\mathrm{~d} u)\n$$\n\nFrom Proposition 4.2, the monotone convergence theorem, and the monotony of $\\mathbb{E}_{s}^{i}[\\cdot]$, we can conclude that\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{s}^{i}\\left[\\left(N^{j k}(t)-N^{j k}(s)\\right)^{m+1}\\right] & =\\sum_{l=0}^{m}\\binom{m+1}{l} \\mathbb{E}_{s}^{i}\\left[\\int_{(s, t)}\\left(N^{j k}(u)-N^{j k}(s)\\right)^{l} I^{j}(u-) \\Lambda^{j k}(\\mathrm{~d} u)\\right] \\\\\n& \\leqslant C \\sum_{l=0}^{m}\\binom{m+1}{l} \\mathbb{E}_{s}^{i}\\left[\\left(N^{j k}(t)-N^{j k}(s)\\right)^{l}\\right], \\quad(j, k) \\in J\n\\end{aligned}\n$$\n\nBecause of the induction assumption, the latter term has an upper bound, uniformly in the parameters $\\omega \\in \\Omega$ and $0 \\leqslant s \\leqslant t \\leqslant T$. By applying (4.14) and using the fact that $\\left(a_{1}+\\cdots+\\right.$ $\\left.a_{r}\\right)^{m+1} \\leqslant r^{m}\\left(a_{1}^{m+1}+\\cdots+a_{r}^{m+1}\\right)$ for any $a_{1}, \\ldots, a_{r} \\in[0, \\infty)$ and $r \\in \\mathbb{N}$, we also get a uniform finite upper bound for $\\sum_{j, k: j \\neq k} \\mathbb{E}_{s}^{i}\\left[\\left(N^{j k}(t)-N^{j k}(s)\\right)^{m+1}\\right]$. The non-negativity of the addends implies that the upper bound applies also for the individual addends $\\mathbb{E}_{s}^{i}\\left[\\left(N^{j k}(t)-N^{j k}(s)\\right)^{m+1}\\right], j, k \\in \\mathcal{Z}$, $j \\neq k$. This completes the induction, so the first assertion is verified for all $n \\in \\mathbb{N}$.\n\nThe second assertion follows directly from the first assertion by applying assumption (6.1).\n\nProposition 6.3. For $Y \\in \\mathbb{Y}$, the processes $Y^{i}, i \\in \\mathcal{Z}$, defined by\n\n$$\nY^{i}(t)(\\omega):=Y(t)\\left(\\omega_{t}^{i}\\right), \\quad t \\geqslant 0, \\omega \\in \\Omega\n$$\n\nare $\\mathcal{F}^{-}$-adapted and jointly measurable, and the paths of $I^{i}(t-) Y^{i}(\\mathrm{~d} t)$ are c\u00e0dl\u00e0g and of finite variation on finite intervals. It holds that\n\n$$\nY(\\mathrm{~d} t)=\\sum_{i} I^{i}(t-) Y^{i}(\\mathrm{~d} t)+\\sum_{i, j: i \\neq j}\\left(Y^{j}(t)-Y^{i}(t)\\right) N^{i j}(\\mathrm{~d} t)\n$$\n\nProof. By the definition (2.4), the mapping $\\omega \\rightarrow \\omega_{t}^{i}$ is $\\mathcal{F}_{t-}$-measurable, so the process $Y^{i}$ is $\\mathcal{F}^{-}$ adapted. The mapping $(t, \\omega) \\mapsto Y(t)(\\omega)$ is measurable since the process $Y$ has c\u00e0dl\u00e0g paths. The mapping $(t, \\omega) \\mapsto\\left(t, \\omega_{t}^{i}\\right)$ is measurable as a mapping from the measurable space $([0, \\infty) \\times$ $\\Omega, \\mathcal{B}([0, \\infty)) \\otimes \\mathcal{F}_{\\infty}$ ) to the same space, since it is composed of simple functions and countably many case differentiations, see (2.4). Since $Y^{i}$ is a composition of the latter two mappings, it is also measurable as a mapping of $(t, \\omega)$. Since $I^{i}(t-) Y^{i}(\\mathrm{~d} t)=I^{i}(t-) Y(\\mathrm{~d} t)$, the paths of $I^{i}(t-) Y^{i}(\\mathrm{~d} t)=I^{i}(t-) Y(\\mathrm{~d} t)$ are c\u00e0dl\u00e0g and of finite variation on finite intervals. Since $Y$ is $\\mathcal{F}$-adapted, we have that\n\n$$\nY(t)=\\sum_{i} I^{i}(t) Y^{i}(t), \\quad t \\geqslant 0\n$$\n\nBy applying integration by parts, we obtain (6.3).\nTheorem 6.4. For $Y \\in \\mathbb{Y}$, let $Y^{i}, i \\in \\mathcal{Z}$, be defined by (6.2). For given stochastic processes $E^{i}$, $i \\in \\mathcal{Z}$, the two following statements are equivalent:\n(i) The multivariate process $\\left(E^{i}\\right)_{i \\in \\mathcal{Z}}$ satisfies $E^{i}(t)=\\mathbb{E}_{t}^{i}[Y(T)-Y(t)]$ for $t \\in[0, T]$.\n(ii) The multivariate process $\\left(E^{i}\\right)_{i \\in \\mathcal{Z}}$ is a solution of $\\mathcal{Y}(\\Lambda)$ for the backward equation\n\n$$\n0=\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-)\\left(E^{i}(\\mathrm{~d} t)+Y^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(Y^{j}(t)-Y^{i}(t)+E^{j}(t)-E^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\\right)\n$$\n\nwith terminal value $E^{i}(T)=0$.\nIf for a subset $\\mathcal{Z}_{0} \\subset \\mathcal{Z}$ we have $\\Lambda^{i j}=0$ for all $i \\in \\mathcal{Z}_{0}$ and $j \\notin \\mathcal{Z}_{0}$, then the equivalence is also true for the sub-process $\\left(E^{i}\\right)_{i \\in \\mathcal{Z}_{0}}$ only.\n\nWe interpret the right hand side of Equation (6.5) as a $\\sigma$-finite measure, and the equation tells us that this measure is zero on the set of reset points, and it is zero on any compact interval that does not contain reset points. There exists a countable number of such compact intervals that covers the whole set $\\left\\{t \\in[0, \\infty): \\Delta \\Lambda^{i^{*}}(t) \\geqslant 0\\right\\}$. So the measure is zero everywhere on $[0, \\infty)$.\n\nProof. At first, we show that (i) implies (ii). Proposition 6.2 yields that $E^{i}$ is bounded on finite intervals. For each $u \\in[0, \\infty)$, we define a stochastic process $E_{u}^{i}$ by\n\n$$\nE_{u}^{i}(t):=\\mathbb{E}_{t}^{i}[Y(T)-Y(u)], \\quad t \\in[0, \\infty)\n$$\n\nSince the random variable $Y(T)-Y(u)$ can be represented as a limit of linear combinations of indicator random variables $\\mathbb{1}_{A}, A \\in \\mathcal{F}_{\\infty}$, the joint measurability of $\\mathbb{E}_{t}^{i}\\left[\\mathbb{1}_{A}\\right]$ according to Theorem\n\n5.2 yields also the joint measurability of each process $E_{u}^{i}, u \\geqslant 0$. The right-continuity of $Y$ and the dominated convergence theorem imply that\n\n$$\n\\lim _{u \\downarrow t} E_{u}^{i}(t)=E^{i}(t)\n$$\n\nSo, for any sequence $\\mathcal{T}_{n}, n \\in \\mathbb{N}$, of partitions of $[0, t]$ with vanishing maximum step length for $n$ to infinity, we have\n\n$$\nE^{i}=\\lim _{n \\rightarrow 0} \\sum_{\\mathcal{T}_{n}} \\mathbb{1}_{\\left[t_{l}, t_{l+1}\\right)} E_{t_{l+1}}^{i}\n$$\n\nBecause of the latter limit representation, the joint measurability of the processes $E_{u}^{i}, u \\geqslant 0$, is inherited by $E^{i}$. Since $E_{u}^{i}$ is $\\mathcal{F}^{-}$-adapted for each $u \\in[0, \\infty)$, see Theorem 5.2 and definition (4.3), we have that $E^{i}(t)=E_{t}^{i}(t)$ is $\\mathcal{F}_{t-}$-measurable for each $t \\in[0, \\infty)$, which means that $E^{i}$ is $\\mathcal{F}^{-}$-adapted. By using the fact that any random variable can be asymptotically approximated from below by simple random variables, the dominated convergence theorem and Theorem 5.2 yield that\n\n$$\n\\begin{aligned}\n& E^{i}(t)-E^{i}(s)=\\mathbb{E}_{t}^{i}[Y(T)-Y(s)]-\\mathbb{E}_{s}^{i}[Y(T)-Y(s)]+\\mathbb{E}_{t}^{i}[Y(s)-Y(t)] \\\\\n& =\\sum_{j: j \\neq i} \\int_{(s, t]}\\left(\\mathbb{E}_{u}^{j}[Y(T)-Y(s)]-\\mathbb{E}_{u}^{i}[Y(T)-Y(s)]\\right) \\Lambda^{i j}(\\mathrm{~d} u)+\\mathbb{E}_{t}^{i}[Y(s)-Y(t)] \\\\\n& t \\in(s, \\tau(s)] \\cap\\left(0, \\rho_{s}^{i}\\right), Z(s)=i\n\\end{aligned}\n$$\n\nIf we read the latter integral as a stochastic process in $t$, then this process has c\u00e0dl\u00e0g paths of finite variation on each compact interval that contains no reset points of $\\Lambda^{i^{*}}$. On the same intervals, the process $t \\mapsto \\mathbb{E}_{t}^{i}[Y(s)-Y(t)]$ has c\u00e0dl\u00e0g paths due to the dominated convergence theorem, and finite variation due to the triangle inequality for the conditional expectations and by employing the representation of $Y$ as a difference of two monotone processes from $\\mathbb{Y}^{+}$. This proves that $\\left(E^{i}\\right)_{i \\in \\mathcal{Z}} \\in \\mathcal{Y}(\\Lambda)$.\n\nBy applying Proposition 4.4(i) and (6.3) and using adaptedness properties, from equation (6.6) we can conclude that\n\n$$\n\\begin{aligned}\n& \\mathbb{E}_{t}^{i}[Y(T)-Y(t)]-\\mathbb{E}_{s}^{i}[Y(T)-Y(s)]-\\int_{(s, t]} I^{i}(u-) Y^{i}(\\mathrm{~d} u) \\\\\n& =\\sum_{j: j \\neq i} \\int_{(s, t]}\\left(\\mathbb{E}_{u}^{j}[Y(T)-Y(s)]-\\mathbb{E}_{u}^{i}[Y(T)-Y(s)]\\right) \\Lambda^{i j}(\\mathrm{~d} u) \\\\\n& =\\sum_{j: j \\neq i} \\int_{(s, t]}\\left(Y^{j}(u)-Y^{i}(u)+\\mathbb{E}_{u}^{j}[Y(T)-Y(u)]-\\mathbb{E}_{u}^{i}[Y(T)-Y(u)]\\right) \\Lambda^{i j}(\\mathrm{~d} u) \\\\\n& t \\in(s, \\tau(s)] \\cap\\left(s, \\rho_{s}^{i}\\right), Z(s)=i\n\\end{aligned}\n$$\n\nThis implies equation (7.4), but only on compact intervals that contain not reset points of $\\Lambda^{i^{*}}$. There exists a countable number of these compact intervals that cover the whole set $\\{t \\in[0, \\infty)$ : $\\Delta \\Lambda^{i^{*}}(t) \\geqslant 0\\}$. This verifies (7.4). If $\\Lambda^{i j}=0$ for all $i \\in \\mathcal{Z}_{0}$ and $j \\notin \\mathcal{Z}_{0}$ for a subset $\\mathcal{Z}_{0} \\subset \\mathcal{Z}$, then the subset of equations (6.5) on $\\mathcal{Z}_{0}$ depends only on the sub-process $\\left(E^{i}\\right)_{i \\in \\mathcal{Z}_{0}}$.\n\nNow we show that (ii) implies (i). Integration by parts yields that\n\n$$\n\\begin{aligned}\n& \\sum_{i} I^{i}(s) E^{i}(s)-\\sum_{i} I^{i}(t) E^{i}(t) \\\\\n& =\\sum_{i, j: j \\neq i} \\int_{(s, t]}\\left(E^{j}(u)-E^{i}(u)\\right) N^{i j}(\\mathrm{~d} u)+\\sum_{i} \\int_{(s, t]} I^{i}(u-) E^{i}(\\mathrm{~d} u)\n\\end{aligned}\n$$\n\nfor $t \\in(s, \\tau(s)] \\cap\\left(s, \\rho_{s}^{i}\\right), i \\in \\mathcal{Z}$. We subtract the equation (7.4) for all $i \\in \\mathcal{Z}$ and rearrange the terms in order to arrive at the equation\n\n$$\n\\begin{aligned}\n& \\sum_{i} I^{i}(s) E^{i}(s)-\\sum_{i} I^{i}(t) E^{i}(t) \\\\\n& =-\\sum_{i} \\int_{(s, t]} I^{i}(u-) B(\\mathrm{~d} u)+\\sum_{j, j: j \\neq i} \\int_{(s, t]}\\left(Y^{j}(u)-Y^{i}(u)+E^{j}(u)-E^{i}(u)\\right)\\left(N^{i j}(\\mathrm{~d} u)-I^{i}(u-) \\Lambda^{i j}(\\mathrm{~d} u)\\right)\n\\end{aligned}\n$$\n\nfor $t \\in(s, \\tau(s)] \\cap\\left(s, \\rho_{s}^{i}\\right), i \\in \\mathcal{Z}$. By setting $t=\\tau_{n+1}$, taking the expectation $\\mathbb{E}_{s}^{i}[\\cdot]$ on both sides, applying Proposition 4.2, and using the fact that\n\n$$\n\\mathbb{P}_{s}^{i}\\left[\\tau_{n+1} \\geqslant \\rho_{s}^{i}\\right]=p_{s}^{i}\\left(\\rho_{s}^{i}-\\right)=0 \\quad \\tau_{n} \\leqslant s<\\tau_{n+1}, \\zeta_{n}=i\n$$\n\nsee definition (4.9), we obtain\n\n$$\n\\mathbb{E}_{s}^{i}\\left[\\sum_{j} I^{j}(s) E^{j}(s)-\\sum_{j} I^{j}\\left(\\tau_{n+1}\\right) E^{j}\\left(\\tau_{n+1}\\right)\\right]=-\\mathbb{E}_{s}^{i}\\left[Y\\left(\\tau_{n+1}\\right)-Y(s)\\right], \\quad \\tau_{n} \\leqslant s<\\tau_{n+1}, \\zeta_{n}=i\n$$\n\nBy applying the tower property of conditional expectations according to Proposition 4.4(b), we moreover get\n\n$$\n\\mathbb{E}_{s}^{i}\\left[\\sum_{j} I^{j}\\left(\\tau_{n}\\right) E^{j}\\left(\\tau_{n}\\right)-\\sum_{j} I^{j}\\left(\\tau_{n+1}\\right) E^{j}\\left(\\tau_{n+1}\\right)\\right]=-\\mathbb{E}_{s}^{i}\\left[Y\\left(\\tau_{n+1}\\right)-Y\\left(\\tau_{n}\\right)\\right], \\quad s<\\tau_{n}\n$$\n\nAll in all, by using Proposition 4.4(a) and the assumption $E^{j}(T)=0, j \\in \\mathcal{Z}$, the two latter equations, and the fact that $\\lim _{n \\rightarrow \\infty} \\tau_{n}=\\infty>T$ according to the definition of $\\Omega$, we obtain\n\n$$\n\\begin{aligned}\nE^{i}(s) & =\\mathbb{E}_{s}^{i}\\left[\\sum_{j} I^{j}(s) E^{j}(s)-\\sum_{j} I^{j}(T) E^{j}(T)\\right] \\\\\n& =\\mathbb{E}_{s}^{i}\\left[\\sum_{j} \\int_{(s, T] \\cap\\left(\\tau_{l}, \\tau_{l+1}\\right]} Y(\\mathrm{~d} u)\\right] \\\\\n& =\\mathbb{E}_{s}^{i}[Y(T)-Y(s)]\n\\end{aligned}\n$$\n\nfor all $s \\leqslant T$. If $\\Lambda^{i j}=0$ for all $i \\in \\mathcal{Z}_{0}$ and $j \\notin \\mathcal{Z}_{0}$ for a subset $\\mathcal{Z}_{0} \\subset \\mathcal{Z}$, then we necessarily have $\\mathbb{P}_{s}^{i}[Z(t)=j]=0, i \\in \\mathcal{Z}_{0}, j \\in \\mathcal{Z} \\backslash \\mathcal{Z}_{0}, 0 \\leqslant s \\leqslant t$, according to the definition of $\\mathbb{P}_{s}^{i}$ in (4.5) and (4.9). Therefore, in case of $i \\in \\mathcal{Z}_{0}$, in the latter equation we can restrict the sums over $j$ to the subset $\\mathcal{Z}_{0}$. This means that the $\\mathcal{Z}_{0}$-subset of equations (5.1) already suffices to obtain $E^{i}(s)=\\mathbb{E}_{s}^{i}[Y(T)-Y(s)], i \\in \\mathcal{Z}_{0}$.\n\nRemark 6.5 (Martingale representation). We consider the martingale\n\n$$\nX(t)=\\mathbb{E}\\left[Y(T) \\mid \\mathcal{F}_{t}\\right], \\quad t \\in[0, T]\n$$\n\nAs we do not use the usual hypotheses for our filtered probability space, we cannot use the standard arguments that ensure that any martingale has a c\u00e0dl\u00e0g modification, but based on our canonical probability kernels we can define a c\u00e0dl\u00e0g modification by $X:=\\sum_{i} I^{i} X^{i}$ for\n\n$$\nX^{i}(t):=\\mathbb{E}_{t}^{i}[Y(T)], \\quad t \\in[0, T]\n$$\n\nSuppose there are no reset points. Integration by parts, the relation $X^{i}=E^{i}+Y^{i}, i \\in \\mathcal{Z}$, and (6.5) yield the martingale representation\n\n$$\nX(t)=Y(T)-\\sum_{i, j: i \\neq j} \\int_{(t, T)}\\left(X^{j}(u)-X^{i}(u)\\right) M^{i j}(\\mathrm{~d} t), \\quad t \\in[0, T]\n$$\n\nwhere $M=\\left(M^{i j}\\right)_{i \\neq j}$ is the collection of martingales given by\n\n$$\nM^{i j}(\\mathrm{~d} t):=N^{i j}(\\mathrm{~d} t)-I^{i}(t-) \\Lambda^{i j}(\\mathrm{~d} t), \\quad t \\geqslant 0\n$$\n\nconfer with Proposition 4.2. Unlike what we usually find in the literature, our martingale representation holds surely. In [Jacobsen, 2006] a sure martingale representation is also presented, but a c\u00e0dl\u00e0g modification of $X$ is presumed already given, whereas we offer a construction of such a modification.", "tables": {}, "images": {}}, {"section_id": 8, "text": "# 7 Stochastic Thiele equation \n\nAn insurance cash flow $C$ is a bidirectional cash flow that gives the difference of the cumulative benefits cash flow and the cumulative premiums cash flow. We generally assume that the cumulative benefits cash flow and the cumulative premiums cash flow are processes from $\\mathbb{Y}^{+}$, so that $C$ is an element of $\\mathbb{Y}$. According to Proposition 6.3, the insurance cash flow can be represented as\n\n$$\nC(t)=\\sum_{i} \\int_{[0, t]} I^{i}(u-) B^{i}(\\mathrm{~d} u)+\\sum_{i, j: i \\neq j} b^{i j}(u) N^{i j}(\\mathrm{~d} u), \\quad t \\geqslant 0\n$$\n\nfor $B^{i}(u)(\\omega):=C(u)\\left(\\omega_{u}^{i}\\right)$ and $b^{i j}(u)(\\omega):=C(u)\\left(\\omega_{u}^{j}\\right)-C(u)\\left(\\omega_{u}^{i}\\right)$. We call\n\n$$\n(B, b)=\\left(\\left(B^{i}\\right)_{i \\in \\mathcal{Z}},\\left(b^{i j}\\right)_{i, j \\in \\mathcal{Z}: i \\neq j}\\right)\\right)\n$$\n\nthe canonical representation of $C$ and interpret $B^{i}(u)$ as the aggregated sojourn payments on $[0, u]$ in state $i$ and $b^{i j}(u)$ as the transition payments for a transition from $i$ to $j$ at time $u$.\n\nThe accumulation of wealth is described through a cumulative interest rate $R$, which we assume is an $\\mathcal{F}^{-}$-adapted element of $\\mathbb{Y}$ such that $\\Delta R>-1$ and such that $\\inf _{\\omega \\in \\Omega} R(\\omega)$ is bounded on compacts. Based hereon, we define an $\\mathcal{F}^{-}$-adapted c\u00e0dl\u00e0g and strictly positive process $\\kappa$ with paths of finite variation on compact intervals and the property that not only $\\kappa$ itself but also its reciprocal $1 / \\kappa$ is bounded on finite intervals via\n\n$$\n\\kappa(t)=e^{R_{c}(t)-R_{c}(0)} \\prod_{0<s \\leqslant t}(1+\\Delta R(s)), \\quad t \\geqslant 0\n$$\n\nwhere $R_{c}$ denotes the continuous part of $R$. The interpretation of $\\kappa$ is that of a savings account. Note that since the cumulative interest rate $R$ is an $\\mathcal{F}^{-}$-adapted element of $\\mathbb{Y}$, specializing Proposition 6.3 it can be represented as\n\n$$\nR(t)=\\sum_{i} \\int_{[0, t]} I^{i}(u-) \\Phi^{i}(\\mathrm{~d} u), \\quad t \\geqslant 0\n$$\n\nfor $\\Phi^{i}(u)(\\omega):=R(u)\\left(\\omega_{u}^{i}\\right)$. We call\n\n$$\n\\Phi=\\left(\\left(\\Phi^{i}\\right)_{i \\in \\mathcal{Z}}\\right)\n$$\n\nthe canonical representation of $R$ and interpret $\\Phi^{i}(u)$ as the total sojourn accumulation of wealth on $[0, u]$ in state $i$.\n\nThe future discounted liabilities of the insurer at time $t$ and up until some finite horizon $T<\\infty$ are given by\n\n$$\nL(t, T):=\\int_{(t, T]} \\frac{\\kappa(t)}{\\kappa(u)} B(\\mathrm{~d} u), \\quad 0 \\leqslant t \\leqslant T\n$$\n\nThe-state-wise prospective reserves are introduced in [Norberg, 1992], with\n\n$$\n\\mathbb{E}\\left[L(t, T) \\mid Z(t)=i, \\mathcal{F}_{t-}\\right], \\quad t \\in[0, T], i \\in \\mathcal{Z}\n$$\n\nas the state-wise prospective reserve in state $i$ at time $t$. This definition, however, has its flaws: it is pointwise almost surely only and its path properties are unclear, confer also with [Christiansen and Furrer, 2021]. This was already noted in [Norberg, 1996], but not rigorously resolved. The problem can be overcome by choosing for (7.2) the unique version\n\n$$\n\\mathbb{E}_{t}^{i}[L(t, T)], \\quad t \\in[0, T], i \\in \\mathcal{Z}\n$$\n\nwhich makes the definition of state-wise prospective reserves surely unique and comes with nice path properties.\n\nIn the following, we generally suppress the dependence of $L$ and derived quantities on $T$; that is, we write $L(t)$ in place of $L(t, T)$. This is solely to lessen the notational burden.\n\nDefinition 7.1. The tuple $(\\alpha, \\Lambda, \\Phi, B, b)$, consisting of the generator $(\\alpha, \\Lambda)$ for the probability space $\\left(\\Omega, \\mathcal{F}_{\\infty}, \\mathbb{P}\\right)$, the canonical interest rate representation $\\Phi$, and the canonical insurance cash flow representation $(B, b)$ is called a canonical insurance model.\n\nTheorem 7.2 (Stochastic Thiele equation). Let a canonical insurance model $(\\alpha, \\Lambda, \\Phi, B, b)$ be given. For given stochastic processes $V^{i}, i \\in \\mathcal{Z}$, the two following statements are equivalent:\n(a) The process $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}}$ satisfies $V^{i}(t)=\\mathbb{E}_{t}^{i}[L(t)], t \\in[0, T]$.\n(b) The process $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}}$ is a solution in $\\mathcal{Y}(\\Lambda)$ for the backward equation\n\n$$\n\\begin{aligned}\n0=\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-)( & V^{i}(\\mathrm{~d} t)+B^{i}(\\mathrm{~d} t)-V^{i}(t-) \\Phi^{i}(\\mathrm{~d} t) \\\\\n& \\left.+\\sum_{j: j \\neq i}\\left(b^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\\right)\n\\end{aligned}\n$$\n\nwith terminal value $V^{i}(T)=0$.\nIf for a subset $\\mathcal{Z}_{0} \\subset \\mathcal{Z}$ we have $\\Lambda^{i j}=0$ for all $i \\in \\mathcal{Z}_{0}$ and $j \\notin \\mathcal{Z}_{0}$, then the equivalence is also true for the sub-process $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}_{0}}$ only.\n\nExample 7.3 (Markov model). In continuation of Example 5.3, suppose that $\\Lambda, \\Phi, B$, and $b$ are deterministic. In that case, the state-wise prospective reserves are also deterministic, and Equation (7.4) reads\n\n$$\n0=\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}}\\left(V^{i}(\\mathrm{~d} t)+B^{i}(\\mathrm{~d} t)-V^{i}(t-) \\Phi^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(b^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\\right)\n$$\n\nIf there are no reset points, we recover the classic Thiele equation:\n\n$$\nV^{i}(\\mathrm{~d} t)=V^{i}(t-) \\Phi^{i}(\\mathrm{~d} t)-B^{i}(\\mathrm{~d} t)-\\sum_{j: j \\neq i}\\left(b^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\n$$\n\nProof. Theorem 6.4 yields for $W^{i}(t):=V^{i}(t) / \\kappa(t)$ the equivalence of $W^{i}(t)=\\mathbb{E}_{t}^{i}[L(t) / \\kappa(t)]$ and the backward equation\n\n$$\n0=\\mathbb{1}_{\\left\\{\\Lambda^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-)\\left(W^{i}(\\mathrm{~d} t)+\\frac{1}{\\kappa(t)} B^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(\\frac{1}{\\kappa(t)} b^{i j}(t)+W^{j}(t)-W^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\\right)\n$$\n\nIntegration by parts yields\n\n$$\n\\begin{aligned}\nI^{i}(t-) V^{i}(\\mathrm{~d} t) & =I^{i}(t-) \\kappa(t) W^{i}(\\mathrm{~d} t)+I^{i}(t-) W^{i}(t-) \\kappa(\\mathrm{d} t) \\\\\n& =I^{i}(t-) \\kappa(t) W^{i}(\\mathrm{~d} t)+I^{i}(t-) V^{i}(t-) \\Phi^{i}(\\mathrm{~d} t)\n\\end{aligned}\n$$\n\nand by multiplying this equation with $1 / \\kappa(t)$ based on the Radon-Nikodym theorem, we obtain\n\n$$\nI^{i}(t-) W^{i}(\\mathrm{~d} t)=I^{i}(t-) \\frac{1}{\\kappa(t)} V^{i}(\\mathrm{~d} t)-I^{i}(t-) \\frac{1}{\\kappa(t)} V^{i}(t-) \\Phi^{i}(\\mathrm{~d} t)\n$$\n\nTherefore, the backward equation for $W^{i}$ is equivalent to (7.4). This proves the equivalence of (a) and (b), since the transformation $W^{i}(t):=V^{i}(t) / \\kappa(t), i \\in \\mathcal{Z}$, stays in $\\mathcal{Y}(\\Lambda)$ due to the boundedness assumptions for $\\kappa$ and $1 / \\kappa$ on $[0, T]$.\n\nRemark 7.4 (Backward stochastic differential equation). Suppose there are no reset points, and let $V:=\\sum_{i} I^{i} V^{i}$. Integration by parts and (7.4) then yield the backward stochastic (differential) equation\n\n$$\nV(\\mathrm{~d} t)=V(t-) \\Phi(\\mathrm{d} t)-C(\\mathrm{~d} t)+\\sum_{i, j: i \\neq j}\\left(b^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) M^{i j}(\\mathrm{~d} t), \\quad V(T)=0\n$$\n\nwhere $M=\\left(M^{i j}\\right)_{i \\neq j}$ is the collection of martingales given by\n\n$$\nM^{i j}(\\mathrm{~d} t):=N^{i j}(\\mathrm{~d} t)-I^{i}(t-) \\Lambda^{i j}(\\mathrm{~d} t), \\quad t \\geqslant 0\n$$\n\nconfer with Proposition 4.2. In the absolutely continuous case, this can be compared with Equations (3.4)-(3.5) in [Christiansen and Djehiche, 2020], the main difference being that our equation holds surely.", "tables": {}, "images": {}}, {"section_id": 9, "text": "# 8 Comparison theorems \n\nWe say that $\\Lambda$ and $\\bar{\\Lambda}$ have identical reset points if\n\n$$\n\\left\\{(t, \\omega, i): \\Lambda^{i^{*}}(t-)(\\omega)=\\infty\\right\\}=\\left\\{(t, \\omega, i): \\bar{\\Lambda}^{i^{*}}(t-)(\\omega)=\\infty\\right\\}\n$$\n\nCorollary 8.1 (Stochastic Cantelli theorem). Let two canonical insurance models $(\\alpha, \\Lambda, \\Phi, B, b)$ and $(\\bar{\\alpha}, \\bar{\\Lambda}, \\Phi, \\bar{B}, \\bar{b})$ be given. Let $\\Lambda$ and $\\bar{\\Lambda}$ have identical reset points. Suppose that the state-wise prospective reserves $\\left(V^{i}\\right)$ of the first model satisfy\n\n$$\n\\begin{aligned}\n& \\mathbb{1}_{\\left\\{\\bar{\\Lambda}^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-)\\left(B^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(b^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\\right) \\\\\n& =\\mathbb{1}_{\\left\\{\\bar{\\Lambda}^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-)\\left(\\bar{B}^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(\\bar{b}^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\bar{\\Lambda}^{i j}(\\mathrm{~d} t)\\right)\n\\end{aligned}\n$$\n\nThen the two models have identical state-wise prospective reserves:\n\n$$\n\\left(V^{i}\\right)_{i \\in \\mathcal{Z}}=\\left(\\bar{V}^{i}\\right)_{i \\in \\mathcal{Z}}\n$$\n\nRemark 8.2. In line with actuarial tradition, see also below, Corollary 8.1 is stated for nondiffering interest rates. If instead $\\bar{\\Phi} \\neq \\Phi$, we could replace (8.1) by\n\n$$\n\\begin{aligned}\n& \\mathbb{1}_{\\left\\{\\bar{\\Lambda}^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-)\\left(B^{i}(\\mathrm{~d} t)-V^{i}(t-) \\Phi^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(b^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\\right) \\\\\n& =\\mathbb{1}_{\\left\\{\\bar{\\Lambda}^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-)\\left(\\bar{B}^{i}(\\mathrm{~d} t)-V^{i}(t-) \\bar{\\Phi}^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(\\bar{b}^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\bar{\\Lambda}^{i j}(\\mathrm{~d} t)\\right)\n\\end{aligned}\n$$\n\nand still obtain the same conclusion.\nExample 8.3 (Markov model). In continuation of Example 7.3, suppose that $\\Lambda, \\Phi, B$, and $b$ as well as $\\bar{\\Lambda}, \\bar{B}$, and $\\bar{b}$ are deterministic. In that case, the state-wise prospective reserves are also deterministic, and Equation 8.1 reads\n\n$$\n\\begin{aligned}\n& \\mathbb{1}_{\\left\\{\\bar{\\Lambda}^{i^{*}}(t-)<\\infty\\right\\}}\\left(B^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(b^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)\\right) \\\\\n& =\\mathbb{1}_{\\left\\{\\bar{\\Lambda}^{i^{*}}(t-)<\\infty\\right\\}}\\left(\\bar{B}^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(\\bar{b}^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\bar{\\Lambda}^{i j}(\\mathrm{~d} t)\\right)\n\\end{aligned}\n$$\n\nIf there are no reset points, this reduces to\n\n$$\nB^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(b^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\Lambda^{i j}(\\mathrm{~d} t)=\\bar{B}^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(\\bar{b}^{i j}(t)+V^{j}(t)-V^{i}(t)\\right) \\bar{\\Lambda}^{i j}(\\mathrm{~d} t)\n$$\n\ncompare with Theorem 6.2 in [Milbrodt and Stracke, 1997] and Satz 10.29 in [Milbrodt and Helbig, 2008].\n\nProof. The assumption that $\\Lambda$ and $\\bar{\\Lambda}$ have identical reset points implies that $\\mathcal{Y}(\\Lambda)=\\mathcal{Y}(\\bar{\\Lambda})$. The equation for $\\left(V^{i}\\right)$ implies that $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}}$ solves the stochastic Thiele equation of $\\left(\\bar{V}^{i}\\right)_{i \\in \\mathcal{Z}}$, so that Theorem 7.2 yields that $V^{i}(t)=\\overline{\\mathbb{E}}_{t}^{i}[L(t)]=\\bar{V}^{i}(t)$ for all $t \\geqslant 0, i \\in \\mathcal{Z}$.\n\nThe next result provides sufficient conditions on the transition and interest rates to ensure that the state-wise prospective reserves are on the safe side. Safe-side calculations have hitherto been explored in survival models [Lidstone, 1905, Norberg, 1985], Markov models [Hoem, 1988, Ramlau-Hansen, 1988, Linnemann, 1993], and semi-Markov models [Niemeyer, 2015].\nTheorem 8.4. Let $\\left(V^{i}\\right)$ and $\\left(\\bar{V}^{i}\\right)$ be the state-wise prospective reserves of canonical insurance models $(\\alpha, \\Lambda, \\Phi, B, b)$ and $(\\bar{\\alpha}, \\bar{\\Lambda}, \\bar{\\Phi}, B, b)$, where on each compact interval the differences $\\bar{\\Lambda}-\\Lambda$ shall have finite variation. Let $V:=\\sum_{i} I^{i} V^{i}$, and let $R^{i j}:=b^{i j}+V^{j}-V^{i}$.\n(a) Pessimistic actuarial basis: If the differences $\\bar{\\Lambda}-\\Lambda$ and $\\bar{\\Phi}-\\Phi$ satisfy\n\n$$\n\\begin{aligned}\n& \\mathbb{1}_{\\left\\{R^{i j}(t) \\geqslant 0\\right\\}}\\left(\\bar{\\Lambda}^{i j}-\\Lambda^{i j}\\right)(\\mathrm{d} t) \\geqslant 0 \\\\\n& \\mathbb{1}_{\\left\\{R^{i j}(t) \\leqslant 0\\right\\}}\\left(\\bar{\\Lambda}^{i j}-\\Lambda^{i j}\\right)(\\mathrm{d} t) \\leqslant 0 \\\\\n& \\quad \\mathbb{1}_{\\left\\{V^{i}(t) \\geqslant 0\\right\\}}\\left(\\bar{\\Phi}^{i}-\\Phi^{i}\\right)(\\mathrm{d} t) \\leqslant 0 \\\\\n& \\quad \\mathbb{1}_{\\left\\{V^{i}(t) \\leqslant 0\\right\\}}\\left(\\bar{\\Phi}^{i}-\\Phi^{i}\\right)(\\mathrm{d} t) \\geqslant 0\n\\end{aligned}\n$$\n\nfor $t \\geqslant 0, i, j \\in \\mathcal{Z}, i \\neq j$, then it holds that\n\n$$\n\\bar{V}^{i}(t) \\geqslant V^{i}(t), \\quad t \\geqslant 0, i \\in \\mathcal{Z}\n$$\n\n(b) Optimistic actuarial basis: If the differences $\\bar{\\Lambda}-\\Lambda$ and $\\bar{\\Phi}-\\Phi$ satisfy\n\n$$\n\\begin{aligned}\n\\mathbb{1}_{\\left\\{R^{i j}(t) \\geqslant 0\\right\\}}\\left(\\bar{\\Lambda}^{i j}-\\Lambda^{i j}\\right)(\\mathrm{d} t) & \\leqslant 0 \\\\\n\\mathbb{1}_{\\left\\{R^{i j}(t) \\leqslant 0\\right\\}}\\left(\\bar{\\Lambda}^{i j}-\\Lambda^{i j}\\right)(\\mathrm{d} t) & \\geqslant 0 \\\\\n\\mathbb{1}_{\\left\\{V^{i}(t) \\geqslant 0\\right\\}}\\left(\\bar{\\Phi}^{i}-\\Phi^{i}\\right)(\\mathrm{d} t) & \\geqslant 0 \\\\\n\\mathbb{1}_{\\left\\{V^{i}(t) \\leqslant 0\\right\\}}\\left(\\bar{\\Phi}^{i}-\\Phi^{i}\\right)(\\mathrm{d} t) & \\leqslant 0\n\\end{aligned}\n$$\n\nfor $t \\geqslant 0, i, j \\in \\mathcal{Z}, i \\neq j$, then it holds that\n\n$$\n\\bar{V}^{i}(t) \\leqslant V^{i}(t), \\quad t \\geqslant 0, i \\in \\mathcal{Z}\n$$\n\nRemark 8.5. Loosely speaking, the differences $\\bar{\\Lambda}-\\Lambda$ have finite variation on compact intervals if the transition rates not only have identical reset points, but if also their difference locally around each reset point is bounded.\n\nProof. Let $W^{i}:=V^{i}-\\bar{V}^{i}, i \\in \\mathcal{Z}$. By taking the difference of the stochastic Thiele equations of $\\bar{V}^{i}$ and $V^{i}$, we obtain\n\n$$\n\\begin{aligned}\n0=\\mathbb{1}_{\\left\\{\\bar{\\Lambda}^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-)( & W^{i}(\\mathrm{~d} t)-W^{i}(t) \\bar{\\Phi}^{i}(\\mathrm{~d} t)+\\bar{V}^{i}(t-) \\left(\\bar{\\Phi}^{i}-\\Phi^{i}\\right)(\\mathrm{d} t) \\\\\n& \\left.+\\sum_{j: j \\neq i}\\left(W^{j}(t)-W^{i}(t)\\right) \\bar{\\Lambda}^{i j}(\\mathrm{~d} t)+\\sum_{j: j \\neq i} R^{i j}(t)\\left(\\Lambda^{i j}-\\bar{\\Lambda}^{i j}\\right)(\\mathrm{d} t)\\right)\n\\end{aligned}\n$$\n\nusing the fact that $\\Lambda$ and $\\bar{\\Lambda}$ have identical reset points. We can rewrite the latter equation as\n\n$$\n0=\\mathbb{1}_{\\left\\{\\bar{\\Lambda}^{i^{*}}(t-)<\\infty\\right\\}} I^{i}(t-)\\left(W^{i}(\\mathrm{~d} t)+A^{i}(\\mathrm{~d} t)-W^{i}(t) \\Phi^{i}(\\mathrm{~d} t)+\\sum_{j: j \\neq i}\\left(W^{j}(t)-W^{i}(t)\\right) \\bar{\\Lambda}^{i j}(\\mathrm{~d} t),\\right)\n$$\n\nfor\n\n$$\nA^{i}(t):=V^{i}(t-)\\left(\\bar{\\Phi}^{i}-\\Phi^{i}\\right)(\\mathrm{d} t)+\\sum_{j: j \\neq i} R^{i j}(t)\\left(\\Lambda^{i j}-\\bar{\\Lambda}^{i j}\\right)(\\mathrm{d} t)\n$$\n\nwhich, according to Theorem 7.2 , has the unique solution\n\n$$\nW^{i}(t)=\\overline{\\mathbb{E}}_{t}^{i}\\left[\\sum_{j} \\int_{(t, T]} \\frac{\\kappa(t)}{\\kappa(u)} I^{j}(u) A^{j}(\\mathrm{~d} u)\\right]\n$$\n\nNote here that $C(t):=\\sum_{i} I^{i}(t-) A^{i}(\\mathrm{~d} t)$ is an element of $\\mathbb{Y}$, since $V^{i}$ and $R^{i j}$ are bounded on finite intervals, see Theorem $7.2(\\mathrm{~b})$, and since the variations of $\\bar{\\Phi}^{i}-\\Phi^{i}$ and $\\Lambda^{i j}-\\bar{\\Lambda}^{i j}$ are bounded on finite intervals by assumption.\n\nUnder the assumptions in part (a) of the theorem, we have\n\n$$\n\\sum_{j} \\int_{(t, T]} \\frac{\\kappa(t)}{\\kappa(u)} I^{j}(u) A^{j}(\\mathrm{~d} u) \\geqslant 0\n$$\n\nso that $W^{i}(t) \\geqslant 0$, which means that $\\bar{V}^{i}(t) \\geqslant V^{i}(t)$. This argument applies for any $t \\in[0, T]$ and $i \\in \\mathcal{Z}$. For $t>T$, both prospective reserves are simply zero because of $L(t)=0$, so that the inequality still applies. This verifies statement (a). The proof of statement (b) is analogous.\n\nInvariances of state-wise prospective reserves w.r.t. changes in the insurance model are important for various reasons. This includes the development of efficient computational schemes, but perhaps plays an even more fundamental role in resolving circular model definitions arising from the specification of cash flows in terms of state-wise prospective reserves. Implicit policyholder options such as the free-policy option or the surrender (lapse) option are typical features in the design of life insurance products [Gatzert, 2009] that lead to such reserve dependence.\n\nThe next result provides a collection of important invariances related to, among other things, linearly reserve-dependent and shortened cash flows. Even for Markov models, such invariances are part of the actuarial folklore and rarely given a rigorous treatment; linearly reservedependent and scaled cash flows constitute an exception, confer with [Christiansen et al., 2014] and [Furrer, 2022], respectively.\n\nTheorem 8.6. Let $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}}$ be the state-wise prospective reserves of a canonical insurance model $(\\alpha, \\Lambda, \\Phi, B, b)$. Let $\\mathcal{Z}_{0} \\subset \\mathcal{Z}$ and $\\mathcal{Z}_{1}=\\mathcal{Z} \\backslash \\mathcal{Z}_{0}$ be any decomposition of the state space.\n(a) Irrelevant initial distribution: $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}}$ is invariant with respect to $\\alpha$.\n(b) Irrelevant states: Suppose that $\\Lambda^{i j}=0$ for all $i \\in \\mathcal{Z}_{0}, j \\in \\mathcal{Z}_{1}$. Then $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}_{0}}$ is invariant with respect to $b^{i j}, i \\in \\mathcal{Z}_{0}, j \\in \\mathcal{Z}_{1}$, and $B^{i}, b^{i j}, \\Lambda^{i j}, i \\in \\mathcal{Z}_{1}, j \\in \\mathcal{Z}, i \\neq j$.\n(c) Irrelevant transition rate: Suppose that $b^{k l}+V^{k}-V^{l}=0$. Then $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}}$ is invariant with respect to any changes of $\\Lambda^{k l}$ that preserve the reset points of $\\Lambda^{k \\cdot}$.\n(d) Shortened cash-flow: Suppose that $\\Lambda^{j i}=0$ for all $i \\in \\mathcal{Z}_{0}, j \\in \\mathcal{Z}_{1}$. Then $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}_{0}}$ is invariant with respect to the modification\n\n$$\n\\begin{aligned}\n& \\bar{b}^{i j}=b^{i j}+V^{j}, \\quad i \\in \\mathcal{Z}_{0}, j \\in \\mathcal{Z}_{1} \\\\\n& \\bar{B}^{j}=0, \\quad j \\in \\mathcal{Z}_{1} \\\\\n& \\bar{b}^{i j}=0, \\quad i, j \\in \\mathcal{Z}_{1}, i \\neq j\n\\end{aligned}\n$$\n\n(e) Cemeteries: Suppose that $\\Lambda^{j i}=0, b^{i j}=0, B^{j}=0$, and $b^{j k}=0$ for all $i \\in \\mathcal{Z}_{0}, j, k \\in \\mathcal{Z}_{1}$, $k \\neq j$. Further, suppose that $\\Delta \\Lambda^{i \\ell} \\leqslant 0$ for all $i, \\ell \\in \\mathcal{Z}_{0}, \\ell \\neq i$, and $\\Delta \\Lambda^{i j} \\geqslant 0$ for all $i \\in \\mathcal{Z}_{0}$,\n\n$j \\in \\mathcal{Z}_{1}$. Then $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}_{0}}$ is invariant with respect to the changes\n\n$$\n\\begin{aligned}\n\\bar{\\Phi}^{i}(\\mathrm{~d} t) & =\\Phi^{i}(\\mathrm{~d} t)+\\left(1+\\Delta R^{i}(t)\\right) \\sum_{j \\in \\mathcal{Z}_{1}} \\Lambda^{i j}(\\mathrm{~d} t), \\quad i \\in \\mathcal{Z}_{0} \\\\\n\\bar{\\Lambda}^{i j} & =0, \\quad j \\in \\mathcal{Z}_{1}, \\quad i \\in \\mathcal{Z}_{0} \\\\\n\\bar{B}^{i}(\\mathrm{~d} t) & =B^{i}(\\mathrm{~d} t)-\\Delta B^{i}(t) \\sum_{j \\in \\mathcal{Z}_{1}} \\Lambda^{i j}(\\mathrm{~d} t), \\quad i \\in \\mathcal{Z}_{0}\n\\end{aligned}\n$$\n\n(f) Reserve-dependent payments: Suppose for $k, l \\in \\mathcal{Z}, k \\neq l$, that\n\n$$\n\\begin{aligned}\nb^{k l} & =a_{0}+a_{1}\\left(V^{k}-V^{l}\\right) \\\\\nB^{k}(\\mathrm{~d} t) & =A_{0}(\\mathrm{~d} t)+V^{k}(t-) A_{1}(\\mathrm{~d} t)\n\\end{aligned}\n$$\n\nfor $\\mathcal{F}^{-}$-adapted, jointly measurable processes $a_{0}, a_{1}, A_{0}, A_{1}$ such that\n$-0 \\leqslant a_{1} \\leqslant c_{1}<1$ and $0 \\leqslant a_{0} \\leqslant c_{2}$ for deterministic constants $c_{1}$ and $c_{2}$,\n$-A_{0}, A_{1} \\in \\mathbb{Y}, \\Delta\\left(\\Phi-A_{1}\\right)>-1$, and $\\inf _{\\omega \\in \\Omega}\\left(R(\\omega)-A_{1}(\\omega)\\right)$ is bounded on compacts.\nThen $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}}$ is invariant with respect to the changes\n\n$$\n\\begin{aligned}\n\\bar{b}^{k l} & =a_{0} /\\left(1-a_{1}\\right) \\\\\n\\bar{B}^{k} & =A_{0} \\\\\n\\bar{\\Lambda}^{k l}(\\mathrm{~d} t) & =\\left(1-a_{1}(t)\\right) \\Lambda^{k l}(\\mathrm{~d} t) \\\\\n\\bar{\\Phi}^{k} & =\\Phi^{k}-A_{1}\n\\end{aligned}\n$$\n\nProof.\n(a) The initial distribution $\\alpha$ is not needed in Theorem 7.2(b), so it is irrelevant.\n(b) For the sub-process $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}_{0}}$, the equation in Theorem 7.2(b) does not depend on $b^{i j}, i \\in \\mathcal{Z}_{0}$, $j \\in \\mathcal{Z}_{1}$, and $B^{i}, b^{i j}, \\Lambda^{i j}, i \\in \\mathcal{Z}_{1}, j \\in \\mathcal{Z}, i \\neq j$. These parameters are therefore irrelevant.\n(c) If $\\Lambda^{k l}$ is changed in a way that preserves the reset points of $\\Lambda^{k \\star}$, we still have $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}}$ as a solution of the stochastic Thiele equation. Since solutions are unique, see Theorem 7.2, we obtain the assertion.\n(d) By applying statement (b), we can show that $\\bar{V}^{i}(t)=\\overline{\\mathbb{E}}_{t}^{i}[L(t)]=0$ for $i \\in \\mathcal{Z}_{1}, t \\geqslant 0$, since only the payment processes $\\bar{B}^{j}=0$ and $\\bar{b}^{i j}=0, i, j \\in \\mathcal{Z}_{1}, i \\neq j$, are of relevance here. In particular, we get $\\bar{b}^{i j}+\\bar{V}^{j}-V^{i}=b^{i j}+V^{j}-V^{i}$ for $i \\in \\mathcal{Z}_{0}, j \\in \\mathcal{Z}_{1}$, so that $\\left(\\left(V^{i}\\right)_{i \\in \\mathcal{Z}_{0}},\\left(\\bar{V}^{i}\\right)_{i \\in \\mathcal{Z}_{1}}\\right)$ solves the stochastic Thiele equation of $\\left(\\bar{V}^{i}\\right)_{i \\in \\mathcal{Z}}$. Since solutions are unique, see Theorem 7.2 , we obtain the assertion.\n(e) The assumptions imply that $b^{i j}+V^{j}-V^{i}=-V^{i}$ for $j \\in \\mathcal{Z}_{1}$ and that\n\n$$\n\\mathbb{1}_{\\left\\{\\Lambda^{i \\star}(t-)<\\infty\\right\\}} I^{i}(t-) V^{i}(t)=\\mathbb{1}_{\\left\\{\\Lambda^{i \\star}(t-)<\\infty\\right\\}} I^{i}(t-)\\left(\\left(1+\\Delta R^{i}(t)\\right) V^{i}(t-)+\\Delta B^{i}(t)\\right)\n$$\n\nTherefore, under the described changes, we still have $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}_{0}}$ as a solution of the stochastic Thiele equation. The assertion follows by uniqueness in accordance with Theorem 7.2.\n(f) Under the described changes, we still have $\\left(V^{i}\\right)_{i \\in \\mathcal{Z}}$ as a solution of the stochastic Thiele equation. Since solutions are unique, see Theorem 7.2, we obtain the assertion.\n\nRemark 8.7. The invariance of Theorem 8.6(f) has also been verified for absolutely continuous models in [Christiansen and Djehiche, 2020], but under the requirement of domination between probability measures. While our approach here is based on canonical constructions and elementary techniques, the approach in [Christiansen and Djehiche, 2020] is based on backward stochastic differential equations.\n\nExample 8.8. In [Furrer, 2022], the representation and computation of so-called scaled cash flows is studied. The basic setup is as follows. Consider $\\mathcal{Z}_{0} \\subset \\mathcal{Z}$, let $\\mathcal{Z}_{1}=\\mathcal{Z} \\backslash \\mathcal{Z}_{0}$, and suppose both $\\mathcal{Z}_{0}$ and $\\mathcal{Z}_{1}$ are non-empty. Further, suppose that $\\Lambda^{j i}=0$ for all $i \\in \\mathcal{Z}_{0}, j \\in \\mathcal{Z}_{1}$, so that $\\mathcal{Z}_{1}$ is absorbing. Let $\\tilde{C} \\in \\mathbb{Y}$ with canonical representation $(\\tilde{B}, \\tilde{b})$. Denote by $\\tau$ the first hitting time of $\\mathcal{Z}_{1}$ by $Z$. The scaled payments of interest are given by\n\n$$\nC(\\mathrm{~d} t)=\\rho\\left(\\tau, Z_{\\tau}\\right)^{\\mathbb{1}_{(\\tau \\leqslant t)}} \\tilde{C}(\\mathrm{~d} t)\n$$\n\nwhere each factor $t \\mapsto \\rho(t, j), j \\in \\mathcal{Z}_{1}$, is assumed to be $\\mathcal{F}^{-}$-adapted, strictly positive, and below one. The main result of [Furrer, 2022] is an invariance result for $\\left(V_{i}\\right)_{i \\in \\mathcal{Z}_{0}}$, which retains the canonical payments $(\\tilde{B}, \\tilde{b})$ at the cost of an adjustment to the (cumulative) transition rates and the introduction of an artificial cemetery state.\n\nThis invariance could also have been derived based on the present results, namely the uniqueness of the stochastic Thiele equation. The details of the argument uses similar techniques as the proof of Theorem 8.6 and is therefore omitted. However, at least under absolutely continuous modeling, the introduction of an artificial cemetery state in [Furrer, 2022] may be avoided; this is directly related to Theorem 8.6(d). Consequently, the assumption that the scaling factors be bounded by one is obsolete.", "tables": {}, "images": {}}, {"section_id": 10, "text": "# Acknowledgements \n\nParts of the research presented in this paper were carried out while Christian Furrer was a Junior Fellow at the Hanse-Wissenschaftskolleg Institute for Advanced Study in Delmenhorst, Germany.", "tables": {}, "images": {}}, {"section_id": 11, "text": "## References\n\n[Ahmad et al., 2023] Ahmad, J., Bladt, M., and Furrer, C. (2023). Aggregate Markov models in life insurance: Properties and valuation. Insurance: Mathematics and Economics, 113:50-69.\n[Bathke and Furrer, 2024] Bathke, T. and Furrer, C. (2024). Non-parametric estimators of scaled cash flows. Preprint, arXiv:2408.13176.\n[Bladt et al., 2023] Bladt, M., Minca, A., and Peralta, O. (2023). Pathwise and distributional approximations of semi-Markov processes. Preprint, arXiv:2312.06784.\n[Buchardt et al., 2015] Buchardt, K., M\u00f8ller, T., and Schmidt, K. (2015). Cash flows and policyholder behaviour in the semi-Markov life insurance setup. Scandinavian Actuarial Journal, 2015(8):660-688.\n[Cantelli, 1914] Cantelli, F. (1914). Genesi e costruzione delle tavole di mutualit\u00e0. Bolletino di Notizie sul Credito e sulla Previdenza, 3/4:247-303.\n[Christiansen, 2012] Christiansen, M. (2012). Multistate models in health insurance. Advances in Statistical Analysis, 96:155-186.\n\n[Christiansen, 2021] Christiansen, M. (2021). On the calculation of prospective and retrospective reserves in non-Markov models. European Actuarial Journal, 11(2):441-462.\n[Christiansen et al., 2014] Christiansen, M., Denuit, M., and Dhaene, J. (2014). Reservedependent benefits and costs in life and health insurance contracts. Insurance: Mathematics and Economics, 57:132-137.\n[Christiansen and Djehiche, 2020] Christiansen, M. and Djehiche, B. (2020). Nonlinear reserving and multiple contract modifications in life insurance. Insurance: Mathematics and Economics, $93: 187-195$.\n[Christiansen and Furrer, 2021] Christiansen, M. and Furrer, C. (2021). Dynamics of state-wise prospective reserves in the presence of non-monotone information. Insurance: Mathematics and Economics, 97:81-98.\n[Cohen and Elliott, 2012] Cohen, S. and Elliott, R. (2012). Existence, uniqueness and comparisons for BSDEs in general spaces. The Annals of Probability, 40(5):2264-2297.\n[Furrer, 2022] Furrer, C. (2022). Scaled insurance cash flows: representation and computation via change of measure techniques. Finance and Stochastics, 26(2):359-382.\n[Gatzert, 2009] Gatzert, N. (2009). Implicit options in life insurance: An overview. Zeitschrift f\u00fcr die gesamte Versicherungswissenschaft, 98(2):141-164.\n[Hoem, 1988] Hoem, J. (1988). The versatility of the Markov chain as a tool in the mathematics of life insurance. In Transactions of the 23rd International Congress of Actuaries, pages 171-202, Helsinki, Finland.\n[Jacobsen, 2006] Jacobsen, M. (2006). Point process theory and applications: Marked point and piecewise deterministic processes. Probability and its Applications. Birkh\u00e4user, Boston.\n[Lidstone, 1905] Lidstone, G. (1905). Changes in pure premium values consequent upon variations in the rate of interest or rate of mortality. Journal of the Institute of Actuaries, 3.\n[Linnemann, 1993] Linnemann, P. (1993). On the application of Thiele's differential equation in life insurance. Insurance: Mathematics and Economics, 13:63-74.\n[Maltzhan et al., 2021] Maltzhan, N., Hoff, R., Aalen, O., Mehlum, I., Putter, H., and Gran, J. (2021). A hybrid landmark Aalen-Johansen estimator for transition probabilities in partially non-Markov multi-state models. Lifetime Data Analysis, 27(4):737-760.\n[Milbrodt and Helbig, 2008] Milbrodt, H. and Helbig, M. (2008). Mathematische Methoden der Personenversicherung. De Gruyter, Berlin, New York.\n[Milbrodt and Stracke, 1997] Milbrodt, H. and Stracke, A. (1997). Markov models and Thiele's integral equations for the prospective reserve. Insurance: Mathematics and Economics, 19(3):187235 .\n[Neveu, 1965] Neveu, J. (1965). Mathematical Foundations of the Calculus of Probability. HoldenDay Series in Probability and Statistics. Holden-Day, California.\n[Niemeyer, 2015] Niemeyer, A. (2015). Safety margins for systematic biometric and financial risk in a semi-Markov life insurance framework. Risks, 3:35-60.\n\n[Nie\u00df1 et al., 2023] Nie\u00df1, A., Allignol, A., Beyersmann, J., and Mueller, C. (2023). Statistical inference for state occupation and transition probabilities in non-Markov multi-state models subject to both random left-truncation and right-censoring. Econometrics and Statistics, $25: 110-124$.\n[Norberg, 1985] Norberg, R. (1985). Lidstone in the continuous case. Scandinavian Actuarial Journal, 1985:27-34.\n[Norberg, 1991] Norberg, R. (1991). Reserves in life and pension insurance. Scandinavian Actuarial Journal, 1991:3-24.\n[Norberg, 1992] Norberg, R. (1992). Hattendorff's theorem and Thiele's differential equation generalized. Scandinavian Actuarial Journal, 1992:2-14.\n[Norberg, 1996] Norberg, R. (1996). Addendum to Hattendorff's Theorem and Thiele's Differential Equation Generalized, SAJ 1992, 2-14. Scandinavian Actuarial Journal, 1996:50-53.\n[Overgaard, 2019] Overgaard, M. (2019). State Occupation Probabilities in Non-Markov Models. Mathematical Methods of Statistics, 28(4):279-290.\n[Putter and Spitoni, 2018] Putter, H. and Spitoni, C. (2018). Non-parametric estimation of transition probabilities in non-Markov multi-state models: The landmark Aalen-Johansen estimator. Statistical Methods in Medical Research, 27(7):2081-2092.\n[Ramlau-Hansen, 1988] Ramlau-Hansen, H. (1988). The emergence of profit in life insurance. Insurance: Mathematics and Economics, 7(4):225-236.", "tables": {}, "images": {}}], "id": "2411.12522v1", "authors": ["Marcus C. Christiansen", "Christian Furrer"], "categories": ["math.PR", "q-fin.RM"], "abstract": "Thiele's differential equation explains the change in prospective reserve and\nplays a fundamental role in safe-side calculations and other types of actuarial\nmodel comparisons. This paper presents a `model lean' version of Thiele's\nequation with the novel feature that it supports any canonical insurance model,\nirrespective of the model's intertemporal dependence structure. The basis for\nthis is a canonical and path-wise model construction that simultaneously\nhandles discrete and absolutely continuous modeling regimes. Comparison\ntheorems for differing canonical insurance models follow directly from the\nresulting stochastic backward equations. The elegance with which these\ncomparison theorems handle non-equivalence of probability measures is one of\ntheir major advantages over previous results.", "updated": "2024-11-19T14:10:01Z", "published": "2024-11-19T14:10:01Z"}