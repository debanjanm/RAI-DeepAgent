{"title": "An informal introduction to the Parisi formula", "sections": [{"section_id": 0, "text": "#### Abstract\n\nThis note is an informal presentation of spin glasses and of the Parisi formula. We also discuss some models for which the Parisi formula is not well-understood, and some partial progress that relies upon a connection with partial differential equations.\n\n\nStatistical mechanics aims to model the emergent properties of systems that are made of a large number of elements. One can think of a gas made of many small particles, which gives rise to macroscopic concepts such as the density, the pressure, or the temperature of the gas. Here we will focus on a class of models of statistical mechanics called spin glasses. The critical feature of these models is that there is a lot of \"disagreement\" between the elementary units of the system, as these models aim to capture features of \"complex\" systems. Spin glasses have inspired many developments in a variety of topics including statistics, computer science, high-dimensional geometry, or combinatorics, and many facets of these models have been studied. Our main goal here is to discuss some of the ideas surrounding a fundamental result called the Parisi formula, which identifies the limit free energy of some of these models. The free energy is a natural quantity from a physicist's perspective, and can be thought of as a Laplace transform of the variables of interest, so the identification of its limit yields rich insight into the behavior of the model. We will also discuss an intriguing connection between the Parisi formula and certain partial differential equations, and how this may help to address some open problems.\n\nThe outline of this note is as follows. In the first section, we introduce one of the most basic models of a spin glass called the Sherrington-Kirkpatrick model, and explain what features of this model make it indeed a spin glass. Section 2 presents the Parisi formula per se; we also discuss the crucial insight that the support of the associated Gibbs measure is approximately ultrametric. In Section 3, we discuss extensions to more general models, and showcase one example called the bipartite model that is currently less well-understood. In Section 4, we sketch how to rephrase the Parisi formula using certain partial differential equations, as well as some partial results concerning the bipartite model.\n\nThis note has a number of footnotes and of pieces of text that are within colored boxes. These are asides or more technical discussions that you can freely skip if you so wish. Reading up until the end of Section 2 should give you a good idea of what the Parisi formula is about, and you may decide to stop there. The remaining sections relate more directly to my recent research activity.", "tables": {}, "images": {}}, {"section_id": 1, "text": "## 1. The Sherrington-Kirkpatrick model\n\nTo get a clearer sense of what spin glasses are, let us introduce a paradigmatic example called the Sherrington-Kirkpatrick (SK) model [72]. It may help to imagine ourselves being confronted with the following situation. Suppose that we have $N$ individuals $\\{1, \\ldots, N\\}$ that we need to split into two groups. We can represent an assignment into two groups as a vector $\\sigma \\in\\{ \\pm 1\\}^{N}:=\\{-1,1\\}^{N}$, where $\\sigma_{i}$ indicates to which group the\n\nindividual indexed by $i$ is assigned. For each pair $(i, j)$, we are given a number $W_{i j}$ which represents how much the individual $i$ likes the individual $j$; it is positive and very large if the individual $i$ really likes the individual $j$, while it is very negative if the individual $i$ really dislikes the individual $j$. We want to look for an assignment $\\sigma \\in\\{ \\pm 1\\}^{N}$ that makes the following quantity as large as possible:\n\n$$\nH_{N}(\\sigma):=\\frac{1}{\\sqrt{N}} \\sum_{i, j=1}^{N} W_{i j} \\sigma_{i} \\sigma_{j}\n$$\n\nIt might have been more natural to write $\\mathbf{1}_{\\left\\{\\sigma_{i}=\\sigma_{j}\\right\\}}$ in place of $\\sigma_{i} \\sigma_{j}$, but since $\\mathbf{1}_{\\left\\{\\sigma_{i}=\\sigma_{j}\\right\\}}=$ $\\frac{1}{2}\\left(\\sigma_{i} \\sigma_{j}+1\\right)$, this is inconsequential ${ }^{1}$. The normalization $\\frac{1}{\\sqrt{N}}$ will be convenient later on.\n\nOne quickly realizes that finding the configuration $\\sigma \\in\\{ \\pm 1\\}^{N}$ that realizes the maximum of $H_{N}$ is not going to be straightforward. Even when only three individuals $i, j$ and $k$ are involved, we may be in a situation as depicted in Figure 1.1: maybe $W_{i j}+W_{j i}>0$ and $W_{i k}+W_{k i}>0$, which would suggest to assign $i, j$ and $k$ to the same group; but if $W_{j k}+W_{k j}<0$, then the individuals $j$ and $k$ would rather be in different groups, and there is no way to reconcile each of the pairwise preferences.\n\nIn other words, certain pairs will typically end up being frustrated. In order to find the optimal configuration, some compromises need to be made, and a close inspection of the coefficients $\\left(W_{i j}\\right)$ is required. More generally, for $N$ large, naive quick strategies ${ }^{2}$ for finding a configuration $\\sigma$ such that $H_{N}(\\sigma)$ is large will typically get stuck at a local maximum of the mapping $H_{N}$, and will fail to reach the true maximizer. The presence of these frustrations, and the related fact that simple methods typically do not succeed in finding the maximizing configuration, are the defining features of glassy systems. How this relates to the glass of our daily lives is discussed in Box 1.1. The variables $\\sigma_{1}, \\ldots, \\sigma_{N}$ are often called spins, because much of statistical mechanics has focused on the modeling of magnetic materials, and the model is therefore called a spin glass.\n![img-0.jpeg](img-0.jpeg)\n\nFigure 1.1. A simple situation with frustration. Here the coefficients $\\left(W_{i j}\\right)$ suggest to set $\\sigma_{i}=\\sigma_{j}, \\sigma_{i}=$ $\\sigma_{k}$, and $\\sigma_{j}=-\\sigma_{k}$, but we cannot realize these three conditions simultaneously.", "tables": {}, "images": {"img-0.jpeg": "data:image/jpeg;base64,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"}}, {"section_id": 2, "text": "# Box 1.1. Why the word \"glass\" for these models? \n\nIn order to create glass, one starts by heating up silica (i.e. sand) and a bit of calcium and sodium carbonates (i.e. lime and soda) until they melt. One key aspect of the fabrication of glass is that the liquid mixture then needs to be cooled rapidly (\"quenched\" is the technical term), so as to \"trap\" the microscopic configuration into a disordered state inherited from the liquid phase. After the rapid quench, the material is forever trying to slowly evolve towards its energetically-preferred organized state, but encounters locally frustrated configurations that are increasingly difficult to overcome. So in this case the frustrations and slow dynamics emerge from the intricate geometry of the\n\n[^0]\n[^0]:    ${ }^{1}$ One reason for defining the model using $\\sigma_{i} \\sigma_{j}$ in place of $\\mathbf{1}_{\\left\\{\\sigma_{i}=\\sigma_{j}\\right\\}}$ has to do with other motivations coming from the modelling of magnetic alloys. From a purely mathematical perspective, it is also more pleasant to think of $H_{N}$ as a polynomial function of $\\sigma$, which we can think of as being defined everywhere in $\\mathbb{R}^{N}$ instead of just on $\\{ \\pm 1\\}^{N}$. Another small point is that I find it slightly more convenient not to assume that $W_{i j}$ equals $W_{j i}$, but this is also a detail.\n    ${ }^{2}$ For example, as long as there exists an index $i$ such that changing $\\sigma_{i}$ to $-\\sigma_{i}$ increases $H_{N}$, we look for the index that produces the greatest difference, and we iterate.\n\nconfiguration of particles. The conflicting coefficients $\\left(W_{i j}\\right)$ 's in the SK model make it much more analytically tractable than any model that would really try to be faithful to the \"geometric disorder\" of a true glass, but one hopes that the two settings share certain qualitative properties.\n\nIn line with the necessary presence of these frustrations, one can show that the problem, given the coefficients $\\left(W_{i j}\\right)$, of finding a configuration $\\sigma \\in\\{ \\pm 1\\}^{N}$ that maximizes $H_{N}$, is NP-hard in general. In fact, the problem is NP-hard even if we only aim to find a configuration $\\sigma \\in\\{ \\pm 1\\}^{N}$ such that $H_{N}(\\sigma)$ is at least a fixed positive fraction of the maximal value, no matter how small we allow the ratio to be [8]. We will however depart from this worst-case sort of analysis, by focusing instead on what a \"typical\" instance of the problem looks like. There are surely different possible ways to clarify what \"typical\" means here, but we choose to postulate that the coefficients $\\left(W_{i j}\\right)_{i, j \\in N}$ are independent Gaussian random variables with mean zero and unit variance. The key hypothesis here is that these are independent and all have the same mean and variance; the hypothesis that they are Gaussian is a convenience but would not change the fundamental properties that will be discussed below.\n\nTo sum up, we let $\\left(W_{i j}\\right)_{i, j \\geqslant 1}$ be independent centered Gaussian random variables with unit variance, we define $H_{N}$ according to (1.1), and we aim to study quantities such as\n\n$$\n\\frac{1}{N} \\max _{\\sigma \\in\\{ \\pm 1\\}^{N}} H_{N}(\\sigma)\n$$\n\nin the limit of large $N$. More generally, we would be interested in understanding the geometry of the function $H_{N}$, for instance with a view towards finding configurations $\\sigma$ that essentially realize the maximum in (1.2). A particularly fruitful way to probe this is to consider a family of probability measures associated with $H_{N}$ called Gibbs measures; see also Box 1.2. In our context, given a parameter $\\beta \\geqslant 0$, the Gibbs measure at \"inverse temperature\" $\\beta$ is the probability measure that attributes to each $\\sigma \\in\\{ \\pm 1\\}^{N}$ a probability proportional to $\\exp \\left(\\beta H_{N}(\\sigma)\\right) .{ }^{3}$ For each value of $\\beta \\geqslant 0$, this probability measure essentially concentrates on a level set of $H_{N}$, in the sense that $H_{N} / N$ is essentially constant under the Gibbs measure; and as $\\beta$ is taken larger and larger, the measure becomes concentrated on near-maximizers of $H_{N}$. In order to understand this family of Gibbs measures, it is very fruitful to elucidate the behavior of the quantity\n\n$$\nF_{N}(\\beta):=\\frac{1}{N} \\mathbb{E} \\log \\sum_{\\sigma \\in\\{ \\pm 1\\}^{N}} \\exp \\left(\\beta H_{N}(\\sigma)\\right)\n$$\n\nThe expectation $\\mathbb{E}$ is with respect to the randomness coming from the coefficients $\\left(W_{i j}\\right)$. The quantity $F_{N}(\\beta)$ is usually called the free energy of the system ${ }^{4}$. Understanding this quantity or generalizations of it is very rich in insight concerning the associated Gibbs measure ${ }^{5}$. For mathematicians, this makes intuitive sense if we think of it as a sort of log-Laplace transform of the function $H_{N}$; we can also see for instance that the derivative\n\n[^0]\n[^0]:    ${ }^{3}$ Physicists prefer to add a minus sign here, writing $\\exp \\left(-\\beta H_{N}(\\sigma)\\right)$ in place of $\\exp \\left(\\beta H_{N}(\\sigma)\\right)$, but since the laws of $H_{N}$ and $-H_{N}$ are identical, this does not really matter and I prefer to avoid the proliferation of minus signs. The slight drawback of this convention is that the system now has a preference for large values of $H_{N}$, while physicists prefer to think that the energy function $H_{N}$ ought to be minimized.\n    ${ }^{4}$ even though physicists would rather divide $F_{N}$ by $\\beta$ and add a minus sign (to match the one they would have in the exponential) before calling it that.\n    ${ }^{5}$ The Gibbs measure depends itself on the sampling of the random coefficients $\\left(W_{i j}\\right)$, and we hope to describe typical properties with respect to this sorting, or average properties.\n\nin $\\beta$ of $F_{N}$ gives us access to the average of $H_{N}$ under the Gibbs measure, averaged also over the coefficients $\\left(W_{i j}\\right)$. We can alternatively think of $F_{N}(\\beta)$ as a soft version of the maximum in (1.2), so that this maximum is approximately $F_{N}(\\beta) / \\beta$ if we take $\\beta$ sufficiently large ${ }^{6}$.", "tables": {}, "images": {}}, {"section_id": 3, "text": "# Box 1.2. Gibbs measures \n\nWe may as well just think of Gibbs measures as useful mathematical tools to probe the level sets of $H_{N}$, but when $H_{N}$ represents the energy function of a real physical system, one can argue from first principles that at equilibrium in an environment at inverse temperature $\\beta$, the system will indeed be distributed according to this measure. In fact, this is a general phenomenon that can also show up in purely mathematical contexts. For intance, suppose that there are variables $x_{1}, \\ldots, x_{N}$ taking values in a finite set $\\left\\{e_{1}, \\ldots, e_{K}\\right\\}$, say with $e_{1}<\\ldots<e_{K}$, and let $\\widetilde{e} \\in\\left(e_{1}, e_{K}\\right)$. How does one of the variables, say $x_{1}$, look like if we pick the whole vector $\\left(x_{1}, \\ldots, x_{N}\\right)$ uniformly at random among all those that satisfy $N^{-1} \\sum_{i=1}^{N} x_{i} \\simeq \\widetilde{e}$ ? (Here we write $\\simeq$ to allow for some wiggle room so as to make sure that there exist such vectors, for instance we can ask that the difference between the terms on the two sides of $\\simeq$ is at most $\\varepsilon_{N}$, with $\\varepsilon_{N} \\rightarrow 0$ and $N \\varepsilon_{N} \\rightarrow+\\infty$ as $N$ tends to infinity.) One can show that as $N$ tends to infinity, the probability that $x_{1}=e_{k}$ is proportional to $\\exp \\left(-\\beta e_{k}\\right)$, where $\\beta$ is such that\n\n$$\n\\frac{\\sum_{k=1}^{K} e_{k} \\exp \\left(-\\beta e_{k}\\right)}{\\sum_{k=1}^{K} \\exp \\left(-\\beta e_{k}\\right)}=\\widetilde{e}\n$$\n\nIn other words, asymptotically as $N$ tends to infinity, the law of $x_{1}$ converges weakly to the Gibbs measure at inverse temperature $\\beta$, where $\\beta$ is defined by (1.4). One may for instance consult [29, Section 1.1] for more on this and on the relationship between the Gibbs measure, the free energy, and the entropy of the Gibbs measure.\n\nIt is not very difficult to show that the quantity in (1.2), and then also that in (1.3), stay away from zero and infinity as $N$ tends to infinity ${ }^{7}$. Can we determine the limits of these quantities? Despite a somewhat lengthy introduction, I hope that you can appreciate the simplicity of the question. And yet, something I find fascinating is that the answer to this question is incredibly rich and complex.", "tables": {}, "images": {}}, {"section_id": 4, "text": "## 2. The PARisi formula\n\nAn initial guess for the limit of the free energy $F_{N}(\\beta)$ in (1.3) was proposed by physicists in the paper that introduced the model [72], but it was already understood there that the proposed answer could not be valid for large values of $\\beta$, i.e. at low temperature. In one of his most celebrated contributions, Giorgio Parisi then came up with a sophisticated non-rigorous procedure, called the replica method, that led to what is now called the Parisi formula $[65,66,67,68]$. This formula is described in full in Box 2.1; here we content ourselves with the fact that it takes the form\n\n$$\n\\lim _{N \\rightarrow \\infty} F_{N}(\\beta)=\\inf _{\\mu \\in \\operatorname{Pr}([0,1])} \\mathcal{P}(\\mu)\n$$\n\n[^0]\n[^0]:    ${ }^{6}$ The key step to justify this point is to show that this maximum is close to its expectation; see for example [29, Exercises 6.2 and 6.3].\n    ${ }^{7}$ You can try! Here are some hints. For the upper bound, observe that for each $\\sigma \\in\\{\\pm 1\\}^{N}$, the random variable $H_{N}(\\sigma)$ is a centered Gaussian with variance $N$, so we can easily estimate the probability that $H_{N}(\\sigma)$ is above $C N$ for each $\\sigma$ individually. For the lower bound, one can rely on a naive greedy procedure in which, assuming we have already commited to a choice of $\\sigma_{1}, \\ldots, \\sigma_{i}$, we pick the choice of $\\sigma_{i+1}$ that maximizes that part of $H_{N}$ that only involves $\\sigma_{1}, \\ldots, \\sigma_{i+1}$, and we iterate over $i$.\n\nfor some functional $\\mathcal{P}$, where $\\operatorname{Pr}([0,1])$ denotes the space of probability measures on $[0,1]$.", "tables": {}, "images": {}}, {"section_id": 5, "text": "# Box 2.1. The Parisi formula in full \n\nThe Parisi formula states that\n\n$$\n\\lim _{N \\rightarrow+\\infty} F_{N}(\\beta)=\\inf _{\\mu \\in \\operatorname{Pr}([0,1])}\\left(\\Phi_{\\mu}(0,0)-\\beta^{2} \\int_{0}^{1} t \\mu([0, t]) \\mathrm{d} t+\\log (2)\\right)\n$$\n\nwhere $\\Phi_{\\mu}:[0,1] \\times \\mathbb{R} \\rightarrow \\mathbb{R}$ is the solution to the backwards parabolic equation\n\n$$\n\\begin{cases}-\\partial_{t} \\Phi_{\\mu}(t, x)=\\beta^{2}\\left(\\partial_{x}^{2} \\Phi_{\\mu}(t, x)+\\mu([0, t])\\left(\\partial_{x} \\Phi_{\\mu}(t, x)\\right)^{2}\\right) & \\text { for }(t, x) \\in[0,1] \\times \\mathbb{R} \\\\ \\Phi_{\\mu}(1, x)=\\log \\cosh (x) & \\text { for } x \\in \\mathbb{R}\\end{cases}\n$$\n\nThere are many shades of non-rigorous arguments. Some do not have all the $\\varepsilon$ 's and $\\delta$ 's or discard some annoying but plausibly negligible terms, yet most mathematicians would feel rather convinced by them. Giorgio Parisi's techniques were of a different sort though, see Box 2.2. In fact, the opinions on the validity of his prediction initially varied in the physics community. Besides the rather creative nature of the arguments involved, part of the initial skepticism may have come from the fact that the Parisi formula is a minimization problem, as displayed in (2.1). For each fixed $N$, the free energy can be rewritten as a supremum over probability measures of an \"energy\" term and an \"entropy\" term $^{8}$; once one gets familiar with it, this formulation feels very intuitive and appealing. One could then expect that the task of identifying the limit of the free energy boils down to understanding how to simplify this representation in the limit of large $N$, while preserving the main structure as a supremum. And yet the formula in (2.1) displays an infimum instead ${ }^{9}$.", "tables": {}, "images": {}}, {"section_id": 6, "text": "## Box 2.2. The replica method\n\nThe replica trick aims to exploit the fact that $\\log x=\\lim _{n \\rightarrow 0}\\left(x^{n}-1\\right) / n$ together with the calculation of what in our context would read as\n\n$$\n\\mathbb{E}\\left[\\left(\\sum_{\\sigma \\in\\{ \\pm 1\\}^{N}} \\exp \\left(\\beta H_{N}(\\sigma)\\right)\\right)^{n}\\right]\n$$\n\nwhere $n$ is a positive integer. The advantage of working with an integer $n$ is that we can then expand the power and rewrite the expression in (2.4) as a sum over $n$ copies of the variable $\\sigma$ of some expected value we can compute; the $n$ variables ranging in $\\{ \\pm 1\\}^{N}$ are usually called \"replicas\" (although we will use this word in a slightly different sense further below). This replica trick was already used in the paper that introduced the model [72] and earlier for other models; a short survey of it is in [69, Appendix]. Giorgio Parisi created the art of sending $n$ to zero in just the right way as one goes along the calculation so as to arrive at the correct answer for the limit of the free energy. To give a flavor of the manipulations involved, here is a quote from his Nobel lecture [69]. \"After many trials I had an intuition: in other papers the $n$ indices were divided into $n / m$ groups of $m$ elements each [...]. Everybody was assuming that $m$ was an integer\n\n[^0]\n[^0]:    ${ }^{8}$ While we did not proceed to fully explain this in Box 2.2, the free energy and the entropy are in a convex duality relationship; see also [29, (1.14)] and [16, Corollaries 4.14 and 4.15] for more on this.\n    ${ }^{9}$ It does not help that in the replica calculation as explained in Box 2.2, a maximization problem appears that is then flipped into a minimization problem as the positive integer $n$ becomes smaller than 1 , with not much of an explanation besides the fact that one would otherwise end up with something nonsensical. I cannot help pointing out that a rewriting of the Parisi formula that takes the form of a supremum was recently found in [54].\n\n[...]. I made the bold assumption that $m$ could be a noninteger number, more precisely a number in the interval $[0,1]$. For example, I was dividing the $n$ replicas into $2 n$ groups of $1 / 2$ replicas each. Of course, that is crazy, but my viewpoint was I should first check if this crazy idea was leading to correct results and postpone other questions to a later stage. [...] At the end of the paper, I added the observation that one could improve the theory by dividing the $n / m$ groups into $(n / m) / m_{1}$ groups of replicas, where $m_{1}$ was a new variational parameter. I was also conjecturing the correct solution was obtained when the procedure was repeated an infinite number of times. Some fancy group theory arguments also were added, arguing the permutation group of zero objects is an infinite group because it contains itself as a proper subgroup. [...] The response of the referee was remarkable. In a nutshell: The approach does not make sense, but the numbers coming from the formulae are reasonable, so it can be published. The last observation is not worth the paper on which it is written and it should be removed. I laughed because in the meanwhile I extended the computation to an infinite number of subdivisions\". That latter calculation led to what we now call the Parisi formula.\n\nFurther work by physicists later elucidated a wealth of new information that was consistent with the formula in (2.1) [45, 46, 47]. They discovered that, as $N$ tends to infinity (and except for some choices of $\\left(W_{i j}\\right)$ of small probability), the associated Gibbs measure has a very complex and yet also very precise hierarchical structure, and that the minimizing measure in (2.1) fully describes it. One key aspect of this description is that as $N$ becomes very large, the Gibbs measure is essentially supported on an ultrametric set; see Figure 2.1 and Box 2.3 for more on this.\n![img-1.jpeg](img-1.jpeg)\n\nFigure 2.1. Except for some choices of $\\left(W_{i j}\\right)$ of small probability and for large $N$, samples from the Gibbs measure essentially behave as if they were sampled from an ultrametric space. An ultrametric space can be encoded on the leaves of a tree as in the picture above, where the blue points are at the same distance from one another; they are themselves all at the same distance from any green point; the blue, green and orange points are all at the same distance from any red point, etc.", "tables": {}, "images": {"img-1.jpeg": "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAEKApkDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAopNwqjqOt6ZpERl1G/trRByTNKFoAv0V5zefHDwPaXotxfzzj+KaG3ZkX6nj9K7XRtd03xBp63+lXcd1asSokjORkdR7UAaNFNDA0ufagBaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAopCcUbvagBaCcVS1DWNO0mAz6jf21pEOrzyhB+ZrhdQ+NPhiKf7NpCXutXXRY7G3Zs/iR/KgD0bPrSM4VSzEBRySTxivLjr3xT8RDGleHbPQLdzxPqDb5QPXb2/EUL8J9T1txL4v8ZanqAPLW9sRDF9Mf4AUAdTrfxI8I+H9y32t23mj/AJYwHzZM+m1cmuVb4q6zrrGPwh4L1G+BOBcXgEUX164/Wur0b4d+EvD6qbHQ7VXHPmyr5j5/3myazPF3xI03w5crpGmW76trz/LFp9oCxU9t2On060Ac3qtl8QLiwe98VeMLHwzpw5ZLAfOPbf1z7AnNcBp3w/fx9qBOiR350oOfN1vVnYvMf+madPX198V6XpXw61TxRqEetfEO6+0yId8GkRHFvB6BgPvH9PUmvT4beK3hSGGNI40G1ERQoUegA6CgDlvC/wAOfDfhbSnsbWxjmMybLia4QO8wPUHPb26Vyer/AA61fwpNdal4DnP2abP2rRJpD5UqkYPlkn5T6cg+h7V6yBQVBOaAPMfhl4j0SeS405LzVLPUlwj6Rqly0nkkdfKL8ke2c+3euws7jxKutyQX1hYPpjFilzbzkOo6gMhHX6GqXjD4f6P4ujWa4V7XUocG31C3O2WMjpz3HtXIW3jHxH8O7qPTfHED3ulFgkGt26k8dhKPX/PNAHoF14t0Ow1kaTe36W14wXakysitu6AORtJ9gc1tbqpWlzp2tWMN3ay295bOBJFIpDA+hHvVPXfDsOvLCTf6hY3EBJjnsbgxMucZyPusOB1BoA2d2e1ANZV6mq2GhpHpgivr6JVUG8k8sS4wCSQOCevSl0/U7s6PJe6xYf2dJFuMsfmCUBR/ECo5H4UAatFZWj+JNH8QQtLpOoW92ExvEb5ZM/3l6j8RWpn2oAWikBzS0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFH4UAFFJnjNU9Q1bT9KhM2oXtvax4zumkC5/OgC4TijNed6j8aPC1vP9m0z7ZrN30WGwhL5P1OP0zWf/AMJF8UfEhI0fw1Z6HbN0n1GXe4HrjH9DQB6pnGc9q5bW/iP4S8P71v8AW7YSr1hibzHz6YXOPxrl1+FWr64N3i/xpqN+p5a0tP3MX09/yFdPonw18I+Hyj2OiWpmXpNMvmvn1y2cfhQBzB+LGp64NvhDwbqWog8LdXI8mH657/mKZ/wj/wAUvEjZ1bxDY6DbN1g0+Le4H1P/AMVXqgGAAOAO1GKAPO9P+C/hiGYXOrNe61d95b+cvk/7o4/PNdvp+j6bpMIi0+xt7WMdoYgufyFXelGfagANU9T1aw0awlvdRu4ra2jHzSSNgD29z7Vyfi/4k6d4fuBpVhDJq2vSnZFp9t8xyf75H3R+tYml/DzV/Fd9HrfxCu/PYHfb6RCcQQ+gb+8fUfqaAK03ifxT8SrhrPwhHJpOg7ikusTKQ8g7iMf1/lXaeEPAeieDrYiwhMl24/fXkx3SyHvk9voK6SC3itoUhgjWOKMBURBgKPQe1SAY70AKBiiiigAooooAKgubO3vbWS2uoY5oJFKvHIu5WHuDU9FAHlGoeA9c8EXkur/D+6LWztvuNEnJMT+vl+h9v510nhD4j6V4pkexkR9O1mH5Z9PuvldWHXbnrXZEZrkvGHw90fxcizSh7PU4uYL+2+WWMjpkjqPb+VAHWZySPSjbmvJ7Pxn4j+H13HpnjqBrzTC2yDW7dCRjsJR/Xr1616jY39pqVnHd2NxHc20o3JLG25WH1oAWKytoJpJoreKOWXHmOiAF8dMnvWTZ+HJbDWnvoda1JreQsz2U0iyRZP8AdJG5R7ZxW6DmloAwL7VNcstZSGHQvtmmyFR9oiugJEJ4OUYdB6g1b1TxFo+iTW8Oqajb2b3G7yhM4UNjGeTwOorTxUF1ZW19A1vdwRXEDDBjlQOp/A0ASxypLGskbB0YAqynIIPQj2pwYEZFZ2o6Ot7pI0+3urjT1XaI5LNgjIF6AcYx7U2xtdQ0vRmilvX1W7jDFJJQsRk/uqSOB6ZoA1KKxNB1jUtS86LVNCuNLuItud8ySxvn+6ynJxjnIHarVjr2lalcS29lqFtPNExWSOOQFlI65FAGjRSBgenP0pc0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFJmgBaCcVVvtTsdMgae+vLe1iXq80oRR+JrhNT+NHhS1mNvpz3WsXQ4EdhAzgn/eOAfqM0AeiZpC20EngDua8tHiX4m+I+NF8L22i278C41ST5wPXZ1/SgfCzXdfbf4v8a6jdqettZ4hj/LGPx25oA67WviH4T8PhhqGuWiSL/wAso28yT/vlcmuSf4t3+sv5XhDwfqepE8LcXC+TF9c+n1Irp9E+GnhDw/tay0S2Mw/5bXAMrk+uWzj8K6pUVFCoAqgYAAwBQB5cNE+KniMZ1PXbHw/bN1hsU8yYD03dvwNWtP8Agp4aSf7TrM1/rd0eWe9nYgn6D/GvSMUtAFHTdG03R4BBpthbWcQ/gt4ggP1x1q7t4weR70tFACAYpaKKACkJxjjNBOO1cT4w+JOmeG510y0ifVdcl4hsLYbmyem4jp9OtAHV6lqtjpFjJe6jdRWttGMtLK2AP/r+1eXz+KfE/wASZ3svBsT6ZoeSsus3ClWcdxGOuff+VT6Z8PdZ8W38es/EO683aQ8OjQt+5i9N+OGPT1zXqEFtFbQJDBGkUSDaqIuAo9AB0FAHNeEPAOi+D7ZvsUTTXkv+vvZ/mllPfJ7D2rqQMUAYpaACiiigAooooAKKKKACiiigApCM0tFAEF3Z29/ayWt3DHPbyrteORdysPcV5dfeBte8C3cureALhpLRm3z6JO5MbDuYyeh/X616xSEZoA47wf8AEbSfFRazYSWGrw8T6fcja6kdcE/eFdjmuQ8YfDzSPFoW5kD2eqxcwahb/LIhHTOOo/zxXK2njbxD4Au49L8ewPdaezbINbgQspHYSD16e/XrQB61RVeyvrXULOO6sriK4t5BlJI23Kw+oqcHNAC0hGaWigBMHPWqJ0XTP7SXUv7PtRfKCBciFfMAPX5sZq/RQBg3+jatLrKX1j4gnt4cqJLN4UkiYDrjIyCfUGn69rGo6MIZLPQbnVLc58420qB4gMYwjEbs89D2rbpMUAUpdWtLXT4r29kWyikC/wDHywQqW6A9gc1ainjuIllhdZI26MpyDTLqztr63a3u4Ip4X+9HKgZT+Bqpb6LaafpMun6VGmnxMH2fZ0A8tmz8wHTOeaANHPalrE0Kx1rThNFqusrqkfy+TIbZYpAOc7tvB7dAO9R2HiK6uNak0y78P6lZnLeXcsqyQOoPB3qTtJ9DzQBv0VXF/atcta/aIvtCAFovMG4A9Mipt3tQA6ikBz2paACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAoopCaAFopM1WvdSsdNtzcX13BbQj+OaQIPzJoAtUma891T4zeErOY21jPcatddBDYQmQk+x4FZzeKviV4jbGheFINHt36XOpybmx67QBj8jQB6mWA68Vzet/EDwr4e3LqWtWscq/8sUffJ/3yuT+dcinwv8AEOu/P4u8a31wjctaWH7qP6Z7j8BXR6L8L/B+g7WtdFt5JV/5a3A81s/8CzQBzx+Ll3rTmLwh4R1TVuwuJV8mEfViD/So/wCyfit4l/5CGtaf4dtm/wCWVlGJJAP97J/mK9TWNURVUBVUYCgYApcUAeb2HwV8OJMLnW7nUNcu+pe9uDtz7KMcexJrudN0LStHiEWm6fbWiDoIYgv9K0KKAExSgYoooAKKKKACiiigAoopCcUABODVTUdTstJsZb3ULiO2tYhl5ZWCgCuV8YfEjTPDU66baxyanrkp2w6fa/MxY9N2On061z+mfD/WvGN7HrXxBut0anfb6NAxEMXpv9T04oAhuPFnif4jTyWHgqF9N0UMY59anUhmHcRDr+PX6V2Pg/wBo3g6Fms42nvpOZr24+aWUnrz2HtXS29rDaW8dvbxpFDGu1I0UKqj0AHSpgMUAGMUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABjNV7yytr+1ktbuCOeCQbXjkUMrD3BqxRQB5Ne+B/EHgO8k1XwDO89kzb59DnbKN6+WSevX36de3UeDviLpHizdaLvsdWiGJtPuflkUjrgHqP8AJxXY9a47xh8O9I8V7bol7HVovmg1C3+WRGHTPqKAOwDZzxjFLXk1l441/wAB3cWlePrdprIsEg1u3UlG9PMHY/r9a9Rs7611C0ju7OeOe3lAZJI23Kw9iKALFFIDmloAKKKKACiiigBMc5zSbeMHmnUUAZN94Z0XUb6G+u9Ogku4WDRz7cOpHT5hzUWvadrl15EuiaylhLFndHNbLNHNns3IYfga26KAMq+1C90vSEuG0+bUbldolisgAf8AaKhjyB6ZzUmmaxDqWlDUPIubSLDbkvIWhdNvXcGxgcda0CM1HPbxXNvLbzxrJDKhR0cZDKRgg+1ADklSUBkYMp6MpBFKGzWVo3hrSvDzXB0q1Fsk5BeNCdmRnoucDqelVtPtPEtrrUhvNUsr3S3LsoNsY5ou6qCGIYDpyBQB0FFYN54oh0/Wk0650/UlEhVY7pLYvCzHtuXOPxxW2ZUEgjLLvIyFzzj6UAPopN1AOaAFooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACikJxiuf8AF3jLSvBmkHUNTkPJ2xQpy8regH9aAOgzSFgM+3WvLF8XfEfxIf8AiQ+EodLt3HFzqz4OP93gn8iKX/hWfiXxAd3i3xtfTI33rSwHkR/TjAP5UAdjrXjzwv4fDf2nrVpC4/5Zh97n/gK5NchL8YJtWYxeEfCmqaux4E8ieVD9c8k/pXQ6H8LfB2gFXttFgmnHPnXQ818+vzcD8BXXJGkahUUKo4AUYFAHlo0z4r+JP+P/AFbT/Dls/wDyytV82YD69M/jVuz+C2gPcC61691HXLvu97cMQfwB/rXpOKWgDO0rQNJ0OEQ6Xp1rZxjjEEQXP1I5P41obRS0UAFFFFABRRRQAUUUUAFFFFABRRRQAUhOKCcVyPjzx/pngbSvPuiJryTiC0VgGftk+i+/5UAdJqGpWel2cl5f3EdtbxjLSSsFUf59OteX3PjDxN8RLqTTvA8Umn6QCUm1q4UqT6+WPX9enTuuleBtX8d3EGuePL0SWpxJbaPbSfuUHUbyDyen+eK9Ut7WG0to7e2iSGGNQqRxrtVR6ADpQBzPg/4faN4PhZ7WNrjUJR+/vrj5pZc9eewz2/OurAxSiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKQjNLRQBXvbG11GzltL23juLeVdrxyLuVh7ivLb3wT4i8AXcmqeA52udOJL3GiTtlT6mMnoevHXp17etUhGaAOQ8H/EPR/FqtbpvstVi+WewuRtkQjrj1H+cV2FcZ4x+HWkeKmW83SWGsRcw6hbHbIpHTPqP85Fc1o/j3V/CXiKDwv48e3LTD/RtVjkASQdB5g/hPTk459aAPWKKajh1DKQQRkEHqKdQAUUUUAFFFFABRRRQAUUUUAFGKKKAEI96xtd8K6P4jWH+07QSvDnyZVdkePP91lIIraooAytSsdSGkx22i36WtzHtCy3MZmBUDoeQefWksrnVLTQXuNYhhmvYUdnTTwzCQDONobnJA6e9a2Oabs9+fXFAGTofiWw8QJObNbhJICBLFcQNE6E5wCGA9D0JrWDhuhB+hoCYOe561hWHg/SNJ1iTU9PS4t5ZdxlijuX8qQnuUJ25oA3t1LWBdjxPFrSPZHTJtMYqGilDJLGO5DDIb6YFazXirfJaeVKWeMyBwvyAA4wT689KALNFA5ooAKKKKACiiigAooooAKKKKACkJx2oJwOmaxfEfiS18PWKySo893M/lWtpFzJPIeiqP5ntQAeJPEdr4esUkkRp7uZvKtbSLmSeQ9FA/me1eb6j4Rk17xpolv4mZbrULuOa7u44z+7tIEXakUftvfk9yK7fw54cuUvm8Qa+yTa3MNqovMdnGekUf8AVu9RaCP7Q+IfiLUjylmkOnRH0wPMf9WX8qAOh02KCws4dLiujM9pCiHzJA0mAMAtj1x6c4q+PpWLLoIXxXDr0FwYmFs1vcxbQROucoSc8FTn161tKcj/ABoAWiiigAooooAKKKKACiiigAooooAKKKKACiiigApCcU2SVIo2kkZURRuZmOAB3JPauIn1jUvG8r2Ph6R7LRlYpc6vj5pfVIM/+h/kKALus+K7ibUn0HwzCl5qy/6+VuYLMeshHVv9gc/SuK8PeBLDxPrOu3upSyalCsb6cL6Y5a4mx+9kXsFU4VQOBg+9dZriW/grwmmleHrdUv76QWlmp5Z5n6yMerEDLEn0rpNB0eDQdEtNMt8+XbxhQx6se7H3JyfxoA47whqj6D4EksoNLkuL7RZja3dpbt85wdxdQx5yp3ADr0FdrpOr2et6ZBqFhIZLeZcqSpU9cEEHkEHtXL66o8M+NLDxCny2WpbdP1HHAVs/uZD9CSpPoRXQ62urLpb/ANhm1W9Rg6pcKdjgHJXI+7n15+lAGqKKo6VeXF7pkFzdWUllcSLmS3kYMYznpkcVdBz2xQAtFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUhOKCcds1znibxM2lNBp2nWwvdcuwRbWoPAHeSQ/woO5oAPEvid9KaDTtNt1vdcvOLa1B4A7yOeyDue/SuG1/wJZG58O2+sudRvtUv3F/dvwz5hkwF/uquflA9q7vwz4YXRo5ry7nN7rN2Q93euOXPZV/uoOgUVS8XDHiTwf3/AOJk/wD6JegDP8M6jqOhWs3hKS3jm1TTUDWqs4jF5bZ4cE5G4dCOmcdM8dnp9+L+zjuPs89uX6xToUdDnHI/DqOD2rH8W+HpNYtYbywkWHWbF/Ospz2buh/2WHB/PtSaPqqeL/DrlJbjTr1WMNzGjbZbWdTyvOe4+hB96AOkBz2I+tLWZb3Eul6QJdbvLXdFxJcgeUhGcKSCeCcjvjPStFWDjIII9jQA6iiigAooooAKKKKACiiigAooooAKKKKACgjNFFACY96Nv5UtFABRRRQAUUUUAFFFFABRRRQAUhOKCcVi+JPEdp4dsFmmV5rmVvLtbWHmSeQ9FUfzPYZoAXxH4jtfDtik0yPPczN5draQ8yTyHoqj+Z6AVm+G/Dl0t63iDxAyTa3Km1FXmOzjP/LOP+p70eG/Dl39ubxB4gZJtamXaiLzHZRn/llH/U966sDGaAIriaO1tpZ5mCxxqXdsdABk/wAq5f4bxSN4Rj1Kddtxqs8t/Jn/AKaOWX/x3bUnxEuZIfBV7bwMRcX22yix13SsE/kTXRWNrHY2FvZwqFigiWJAOyqMD9BQAmoWkd/p9xZzZEc8bRsVOCARjiqPhqzv9N0C1sdSnS4urdfLaVCTvUH5Sc99uM++a1iM1g6ra6sviTSL6wkaSyG+C+ti4C7CMrIAerKwHTnBoA3gc0tNU5z9adQAUUUUAFFFFABRRRQAUUUUAFFFITigAJxVHV9YsND06S/1G4SC2j6u3cnoAO5PYCqPiLxTaeH44ozHJd39xxa2VvzLMfYdh6seBWXpHhW7v9Qj13xVIlxfpzbWSHdBZ/7oP3n6fN7cUAVI9N1Tx3KLjWY5tP8ADwIaHTj8st0OzTei/wCx78120MEVrBHBBEkUMYCoiDAUDoAPSpcYrnPG2sS6XoXk2Rzqd/ILSyQdTI/Gfooyx9loAzdIP/CT+OLvWvvafpG6xsiejzf8tpB9Pufga7VRgVm6Bo8Gg6FZ6Xbj5LaMKWPVm6sx9ySSfrWnQBn65pFtr2i3el3YJhuYyhI6qezD3BwR9KyPBOq3N/orWepMDqumyGzvf9p16P8A8CXDfjXTEZritcQ+GfGtjr8fy2Op7dP1ADgK+T5Mh/ElD9V9KAOh17SZNY01reHULiwnRxJFcW5wUYdMjuPUd6dZ3UtjptlHrV5am+kxEzp+7SWXB4UE9TjpWivI4qhrOiWGv6bJYalAs9u/Y8FT2ZT1DD1FAGgDmlrCvNUsPB2j2S6hPdPbKVgN1Ipk28YDSMBwOg3H1Ga2opo5olkidXRgGVlOQR6g96AH0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUhOO2aWuc8T+Jv7J8nT9Pg+263d8Wtop/N3P8KDPJoATxN4mOlGHTtPg+2a5d5Fraqen/TRz/Cg7n8PeneGfDI0ZZr29n+26zd4a7vHHJPZFH8KDOAKPDPhgaOk97e3H23Wrz5ru8cdT2RR2RegFdCBjvmgAAx3zXJeL/wDkZPB3/YSf/wBEvXXVyPi//kZPB3/YSf8A9EvQB1tcV4ls7jw1q48XaZG0kOwR6taoMmWEdJQO7p+ozXbCmuodSrAFTwQR1FAFeCa11OxSeJo57W4jDKeCrqR+oNVobOLQdJki0uzeRI8vHbLJ6n7q7jgD0HArlrFv+EE8QrpUrFfDupSn7C5Py2k7HJhJ7KxyV9+K7ofN3oAp6bqkOqWhnijmiKsUeKZCjow6gg/z6VdBzUNzE8tvJFFM0MjqQsqgEq2OuDxVPTH1C2spP7YmtWMTHFxGSodMfeYEfKfUZxQBp0UisHUMpBUjIIPWloAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKQnFLnpWN4i8RWvh7T1nnR5Z5nEVtaxcyTyHoqj+vQUAJ4j8R2nh6wWadXluJX8q2tYuZJ5D0VR/M9BWb4b8O3Zv28Q+IWSbW5V2pGvMdlGf+Wcf9W70eHPDl0183iLxCUl1mZdscS8x2UZ/5Zx+/qe5zXVgYoAAMZ5pTRSHtQBx3idv7S8aeF9GHKJLLqMwHZY12pn2LP+ldiK47Ql/tP4i+ItUPMdnFDpsJ9ODJJ+rJXZAYoAKZICVwDgnIBxnFPpCKAMHwpdatNpk0Wtwst9bXDwtMU2pcKOVkTHGCCPTkGt8VgeJdZutCbTblIFlsZLtYLxsEtGr/ACqwx23EZ+tby+9AC0UUUAFFFFABRRRQAUUUx5EjUs7BVUZLMcAD1NADicVymueKpm1E6F4cgS+1j/lqzH9xaKf4pWHf/ZHJx+dG41vUvGk8lh4Zle00pHMdzrO3lsdVgB6n/b6Dtnt0+i6Dp+gaetlp0AijHLMeXdj1Zj3Y+poAoeHfCkGivLfXMz3+s3PNzfzgFm/2VHRUHZR+NdCBjvQBjvS0AIa4rSQPE3ju81gjfYaMWsbI/wALTf8ALZx9PuZ/3q0/GmszaVoXl2JB1K/kFpZL/wBNH7/RQCT9K0PD+jW/h/QbPSrYfu7aMLuPV26sx9ySSfrQBpAUtFFABWdrukW+vaLd6XdA+TcxlCR1U9mHuDzWjSHtQBzXgnV7nUNEa01Jh/aumyGzvR/edeA/0YYb8a6auJ1sHwx41steUY0/U9thf+iP/wAsZD7dUP1Wu1FADJoY7iF4ZkV4nUq6OMqwPUEHqKxdcvLrw3pcE2l6P9rs7cgTW9tgSRxAdY1/iI9OK3qQjOOaAILS6ju7WG4iDeXKgZd42nB9QeRU4Oe2KxPEcGuNbQXGg3US3Nu+9radf3dyuPuE9VPoR+RrWt3ka3iaaMRysoLoDkK2OQD3oAmopAc0tABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRXOeJ/E39jrDY2EH23WrzK2top/N3/uoMjJoAPE3ib+yfI0+whF5rd5lbW0U/m7n+FBxk0eGfDH9jrPfX0/23Wrz5rq7YfkiD+FBzgUeGPDH9jia/v5/tutXeGurth+SJ/dQZOBXRjigAooooAK5Hxf/AMjJ4O/7CT/+iXrrq5Hxf/yMng7/ALCT/wDol6AOuFIRmlFFAGfrWj2mu6Rcabex+ZBOu1h3B7MD2IOCD2IrB8JaveQXM/hnW2zqtioMc7cC8g/hlHqeMN7iutIzXOeLPD0+qWsF7pkog1vT2M1lMehPeNvVWHBH40AdH94elNeJZVZHAZWBDKRkEVk+GvEEPiHSVukjaGdGMVzbN96CVfvKf88gg1sA5oAzbDS7fQbW4SxWdoCTIltvysfH3Y8/dB9M4HtzTtJ1q01mB3t/MSSJtk0EyFJIW/usp6H9D1BIrQIzio2jChzGFWRlxu2jr2z69aAJRRWXpMmqr5sGqwwFozhLiBsLMPXaeVPqMn61p5+lAC0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFITign2rH8ReIrTw7YLcXCvLNI3l21tEMyTyHoij1/QUAHiLxFa+HbBZ51eWeZvLtrWPmSeQ9FUfzPasvw54cumvv+Ei8QlZdZlXbHEOY7KM/8s09/Vupx+Z4c8O3Ul+fEXiErLrEi4ihBzHZRn/lmnv0y3t+fWAYzzQAAYNLRRQAVHPKkELzSsFjRSzsewHJqSuV+I13Lb+CL+C2P+lXwWxgHq8rBP5E0AR/DeN38JrqUqkTapcS3z56/OxI/wDHcV11VrCzi0+wt7KEYit41iQeygAfyqzQAUUUUANYZ4NY+ha8mr3OqWj25trvT7kwyxFt3ykZRwcDhhz+Y7VskZxWRrOqWHhuH+0rqEhZ5ooJZ44xlcnarOf7oz15xQBsUUgbdS0AFFFFABSE4oJxx3NYniHxRY+H4ohKslzeznba2duN0s7egHp7ngUAX9V1ax0XT5b/AFG4S3toRlpHPH0HqT6CuQjstU8eyCfU459N8ODBisT8s14OzS91Q/3Byc8mrOleF7zVb6HXPFjRy3cR3WunxndBZ+n++4/vflXZYxQBFbW0Npbpb28aRQxqFREGAo7ACpQMUtFABSE4pa5zxprM+k6CVscHU72RbSyX1lfgH6AZJ+lAGZpaf8JN48vNYb5tP0bdY2Q7NOf9c/4cKP8AgVdqBWZ4d0WDw9oNnpVuSyW8YVnbq7dWY+5OT+NalABRRRQAUUUUAZ2u6RBr2iXemXI/dXCFCR1U9mHuDz+FZXgjWLjUdEa11DjVdNkNneqT1dOA/uGXDZ966UiuK1k/8Ix43stdAxp+qbbC+I6JJ0hf8/kP1FAHbUUg+tLQAVh+I/Dia9DA0d7PY31qxe1uoScxsRg5XOGB7g1uUUAZ8uq2Wn3NlYXt7El3dAiIP8vmsoGcds8jj3q+Dms/WtD0/X7E2epW6zRZDDPBRh0ZSOQfcVS1jxJa+GprKO+guFspz5f2wLujibjaHPUZ9fbmgDeopquHUMvKnkEEGnA5oAKKKKACiiigAooooAKKKKACikJxXPeJvE40ZYbKygN7rV58tpaIep7ux/hQdzQAeJvE40cQ2Njbm91m8BFpaKevq7n+FB3NN8MeGf7I87UL+YXut3eDdXbD8kQfwoM8Cjwz4Y/skz6hfz/bNbu8G6u2HTuI0/uoMnArowMd6AFFFFFABRRRQAVyPi//AJGTwd/2En/9EvXXVyPi/wD5GTwd/wBhJ/8A0S9AHXCigUUAFIRkYpaKAOI8SWk3hjWD4u06J5LZgE1e1jGfMjB4mA/vpz9R9K7C0uoLy1iubaVJYJVDpIhyrA8gipXUOpVgCpGCCK4bTmbwN4gTR5c/8I/qMpOnydrWY8mA+inqv4igDu6CM0inIpaAGGNWBBAIIxg85Hv61m6do8ejyzG3ubg2r/MttI+5Ij32k8gHPTOPTFatIRnvQBR07WLLVPOW1l3SwPsliYFXjP8AtKeR7HoavBg3SoDZ2/2v7X5Ef2kp5fnbRv25zjPXHtVHT77UjfzWeoWOAoLw3cBzFIueBzyrYPTkccGgDWopA2TiloAKKKKACiiigAooooAKKKKACkJwKWqeqXb2GnT3cdtNdPEhZYIBl5D6AetAFLxF4itPDuni5uA8k0jeXb2sQ3S3Eh6Ig9f5Csvw74du5b8+IvERWTWJF2wwqcx2UZ/gT/a6ZbjJH5p4d8O3k1+3iPxEVk1eVdsEA5jsYz/An+16t3rrQME89aAADGfeloooAKKKKAEJwM1x/ic/2h4y8L6QOVSaXUJR2AiXC5/4E4x9K7A57VxeiOuqfEzxFf7lK6fBBp0QzyCcyOcfUgfhQB2g6UtItLQAUUUUAFVdQsLXVLCaxvoFntZ0KSxt0YHtVqkIzQBn6fqVjcXN3p9pKGlsGSKWM5ymVyvXqCO/sa0azU0O0j8QS62nmLdzW4t5MN8rqDkEj1HTPpWiBigBaQnFBOK5TXbjxBqupvomjxyadbqAbnVpFBwD/DCO74/iPT0oAXXfFciX50Pw/bpqGtMPnBOIbRf78rdv93qaseHfCkOkzTaje3D6hrNwMT3so5x/cQfwIOwH41e0Lw/p/h7T1s9Oh8tM7ndjueRu7Ox5JNagGBigAAxS0UUAFFFFACHpXFaYp8T+O7rV2O7T9F3WVmOzTn/WyfgMKP8AgVafjbW59E8NyyWe37fdSJaWm44HnSEKpPsCc/hV/wAO6LB4f0G00yAllgjCtI3WRjyzH3JJNAGmKWiigAooooAKKKKACs7XtIg13RLvS7kHy7mMoSOqnsw9wcEfStGkNAHNeCNYm1PQjbX5A1TTZDZ3q/8ATROA30YYYfWumridXK+GvH2naspC2mtsunXS5/5bDPktj35U/hXajNAC0UUUAGKjkiSWNkdVdWGCrDII9xUlFAHP6/f61pVxaXVhp66hp4O25gi4nUHGHTJwQOcjit4NSlc/WsDXNL1eXUbTUtH1IxSQ/JNaT8wTRlhnPcMOx/CgDfBzS0i0tABRRRQAUUUUAFITjFLXP+K/EX9gafCYYBc395MLW0tywUPK3TJPRRg5NADfE3iYaMkNlZwG81m8ylpZqfvHu7H+FB1Jpvhnwy2lGfUdQn+2a5eYN1dMOB6RoP4UHYfjR4Z8MtpbTalqVx9s1y7INzdMOFHaNB/CgrowMd80AAGO9LRRQAUUUUAFFFFABXI+L/8AkZPB3/YSf/0S9dcTiuO8YSKPEvg4MygnU3GCf+mL0AdiKKQUtABRRRQAhGaz9b0az17SJ9NvkLQzrtypwynsynsR1B9q0aQjNAHKeEtZu1nuPDmuSBtXsQCJjwLuE/dlX1OBhvQiurBzXN+LPD8+pQW+oaW6w63p7mWzm6Bv70b+qN0Pvg1r6Pey6hpFrdz2ktnNLGrPbyjDRtjlTQBeooooAQjNJs755NOooAyrTS7iw1OeaPUZpLOfc5tp/n2OTnKMeQOT8vI9MVattSs7ueeGC4SSWBykiA4ZD7g81aIz+FVDptn/AGgl/wDZ0+1qhjEoGGwe3v8AjQBcBorNgv7s6rNZXGnSRx4Lw3KENG6jHB7q3PTFaQoAKKKKACiiigAooooAKQjI60tFACAY+lLRRQAUUUUAFFFBoAqapfw6Xpd1f3BxFbxNI30Azj615h8KrS5t/EevXl/Owub5UuJEz8jMZZV/MFMD/ertvEjC+1DTNHIzFJL9ruR6xxEMAfYvs/I1ydnpUl9HpfkyCK6vdOmnilOdqypOksZOOo+c5HpmgD08etLTUzsGeuOadQAUUUUAFFFFABRRRQAhGce1AXFLRQAAYooooAKKKKACkNLUVzPHbW8k8rBI41LuxOMADJP5CgDyD4vO+tajZack0kVrprpcTyRNgq5G7j3VFJ/4GK9hi+4Bu3EcE8cnvnFeYyadJqluFlQi51HS7++kBHKmVUSMfgpAx/s12HhSFxZvfiUNbakkN5GhJLIzxjd+BIB/E0AdDRSA5GaWgAooooAKKKKACkNLVe+uo7GymupW2xwxtIx9ABmgDyT4q+brfiLT7KOeSK20t455ZIzgq+5SfyQg5/2hXsEf3fvbvf1rzGXTJLm0uVnXN3daNeXs/qHmYFV/4CFUf8AFdp4ZtZILe4uRKHtb5ku4U5zGXRS4+hbLf8CNAG7RSA5paACiiigApCM0tFACAYpaKKACiiigAooooARu1eO/EHzdd8e6TCk8kVvpUyuHj6h98Qc+nSWMfnXrGp38Wl6Zc38/+rt4mkYDqcDoPrXm0+mTRWmoNdDN7Do/2u5OM4mlm81h9B5QH0AoA9RjIK8HPbNPrH0DT306O7VZFa1uJ2uIFHVN43MP++yxH1xWuDnNAC0UUUAFFFFABRRRQAhrx3xp5uu/E3RGWd47XTLlVRozg7w8XmH8TJGv/ATXq2sajFpOkXWoTcpbxNJtHViBwB7k4H415vc6fJZW+oPPg3OnaXb3U7Dn99JO80n4fux+GKAPU0IYZByKdWVomnPpUN1DvDwSXDzQKM5UN8xXn/a3VqA5oAWiiigAooooAQjNAGKWigAooooAKKKKACkIzS0UAJt5z3pQMUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFITS1keJtRfTNAuZ4Rm5cCG3X+9K5CoP++iPwyaAML7UWtPFPiZziOKGW3tT2EUKtuYf70m/wDACpRaf2Y3g5duDCv2Y/jCe31UUviKwTTvh9/ZER3CQQWPu3mSJG357iau+LPktdNuR1g1K3OfTc+z+T0AXNKjv4LzUorstJbtP5ltIWB+VgCV/A5/MVqA5rL1m7urH7FPbxiSI3SR3I25YRt8uR9GKmtQUALRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXOeLM30NloSE51KYJNjr5C/NJ+YG3/gVdExxXO6af7T8V6lqHWCxAsLc+rcNKR+O1f+AGgAtFE/jzVCANltp1tAvpl3lY/oErP0SK+/4Q/Qxp5bfYziGWINgNGjNGwOfQc/hWl4dXzdX8R3Z6vfrEP91IYx/6Fu/Ojwt8tvqdscZg1GcY+rb/AP2agDfXqfrTqy9CvLu6tZ1v49tzBcSQsQuFcA/Kw9ipFalABRRRQAUUUUAFc54pJv307QU638+Z8dreP53/ADIVP+BV0Tf/AF653SMah4l1XUwMxWxGnwN/u/NIR/wI7fqlADbaP7X4v1zgbY7KC39st5jH9CtVNH+3y+F/DtxYlmNu6RzwggBo+Ubr3Xhvwq94azNqHiK8PPm6kY1+kcUceP8AvpWpfCQ2aVc2uebW+uYv/IrEfowoA31OSadWXoN5dXmnMb2PZdQyvDIAu1SVYgMB6EYNalABRRRQAUUUUAFFFFABRRRQAUE4opDQBzviNvt2oaVoi8/aJvtM4H/PGIgnP1YoPxPpUENt/aGq+K06h447Ud+BFn+b1PoQGoa1qusnkNILK2PYRxZ3EfVy/wD3yKf4Y/e/2xc95dSmH4JiP/2WgCnpst/eaF4V1KzZnQxRLdw7sB43jAJ+qtg/TNdWDnNc34NVl8M/ZVO17W5ubYEjO0JM4Xj6AVpaBe3GoaPFNeReVdKWimQDADoxUkexIyPYigDTooooAKKKKACiikNAHPa8RqOs6To3VGk+2XAH/POIgqD9XK/kapLZf2s/jNMZ+0/6GPoIAP5saueHB/aOo6prrHK3Ev2a1z0EMWRkfVzIfy9Kf4T+exvrnHNxqFw/5OVH/oNAFewn1DUdM8L6taSM8csC/aot3DLJGDu+qsF/M104rnPB6svhGG1jIWS1ea1UkZA2SMo49OBWjoF7cahotvcXcJhu8FLiPGAJFJVse2VOPbFAGnRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAhOK529xqfjGxtCCYdOjN7IO3mNlI/yHmH64roJXWONnchVUEknoKwfCcb3Flc6zMD52qTGdQeqxD5Yl/74AJ92NAB4mHnXGhWv/PTU43P0jVpP5qKXxsrf8IXqsqj54IftA9jGQ//ALLSapmbxfocPaNLic/gqr/7Ma1tStRfaXd2jYxPC8R9wwIoAsKwkRXXBBAIqjomqf2tYGdovJmjlkhmi3btjoxUjPfpkH0Iqv4WuWvfCWkXDH53s4i/+9tGf1q0b20tNVi0/aEuLtHmXC4Dldobn1+YfkfSgC/RSA5paACiiigAooooAKKKKACiiigAooooAoa1qC6Vo91ft/ywjLKv95uij8SQPxqLw9p7aXoVpayYMwTfKfWRvmc/99FjVDWh/aev6TpH/LGNvt9yPURn92D9ZMH/AIBW7cyCG1lkYhQkZbPpgUAYvhH95o81z1NxeXEufXMrY/QCk0X914k8RWpxjzoZwPZ4wP5oam8IxmPwhpeRgtbrJj3Ybv61BH+4+IdwvQXelxt9TFKwP/o0UAX7vVPsWs6fZSRHy73zFWbdwJFG4KR7jcf+A1pCq94YUga4mi8wW4MqgLuIIB5A9cEj8aWxu4b+yhvLd98E8ayRt6qRkH8jQBYooooAKKKCcUAZuvaidK0S6vFXdJGn7tf7zk4UfiSKNC01dI0O0sQdzRR/vH/vueXb8WJP41m6xnVPE2l6Uv8AqbUm/uf+A/LEp+rZb/gHvxsajP8AZdKu5+nlQu/0wpoAyvBgz4bS46m5ubi4z6h5nYfoRSaBmHX/ABLacAC9jnUezwR/1VqueGIPs/hfS4sY22sfH/AQaqQDyPH98o4F1psD/UxySAn8nWgC9c6p9k1qxsJIjsvEk2S7uA64O0j3G45/2a06qX7wwWkl3PCZRbK0oVU3MCB/CPXGaltbmG8tYrq3kEkMyCSN16MpGQfyoAmooooAKKKKACiiigAooooAKyfEmoy6ZoVxPbANdsBFbKf4pnO1P/HiPwzWtXO6g39p+LrHT15j0+M303s5ykQP/kQ/gKANTSNNi0jR7WwibKW8QTcerEDlj9Tk/jWZ4IzJ4Qsrg9bvzLrPr5rtID/49V7xBd/YfDep3YODDayuPqFOKfodp/Z+gadZYwLe1iix6bUA/pQBm+Hf3WpeIbUdE1HzAPaSNGP/AI8WrQk1QQa9BpjxYFxA0scueCykArjHoQfwqjYfufGusRjgTW9vN+Pzr/QVqahNb2dnJqFxFvW1jaX5U3MABzigC2DmlqOCVJ4UljYNHIoZWHQgjrUlABRRRQAVjeJ9QksNCna2/wCPuci2th6yyEKv5E5PsDWwa566P9p+M7S2HMWmRG6k9BK4KIPrt3n8RQBq6fZw6VpMFpFxFbxBQT7Dqf51neDAf+EP02QjmaLzj/wMlv61N4oujY+EtYugfmhs5nX6hDj9auaZa/YdJs7MDAggjiH/AAFQP6UAZXhj93JrVr/zy1GQjHo4V/5savnVBH4gXS5ItpltzPFJn7+1gGGMdsr+dUdJPleLNetxwHFvcAf7yFSfzStPUri1sLV9SuY8raozFguWUd8UAXAc0tMjdZEV1IKkAgg9afQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRSUhoAwvFszPpkWlwki41OZbRNvUKeZG/BFf8cVtQxLDCkUYCpGAqgdgO1YNvjU/GdzccmLS4fs0fp5kmGc/XaEH4muiz60AYGfO8fYP/AC66YGx6GSQj/wBpmt+ue0bM/i7xHcHkRtb2gP8Aux+YR/5FroaAMDwb8nh5bf8A59rieED2WVsfpitLULW0dre9usL9hZp0kJxs+RlJPttJ/Ss3wz+6udctu0WouwHoHVX/APZq3ZY0ljaORQyMCrKRwQexoAI5FljWRGDIwDKR3B70+qGkWA0rSrbTxO0wt4xGryfeKj7ufw4/Cr4OaACiiigAooooAKKKKACiig0AFI1GaxfFN5Ja6FLHA2Lq6ZbWDHXzJDtH5ZJ+gNAFfwznUrjUteP3byYxW2f+eEeUU/Rm3t9CKseL5/sng7WJV+8LOUJ/vFSB+pFaVhaR6fYW9nCMRQRrGo9gMD+VY/jL95osFp/z9X9rCR6qZkLD/vkNQBtWVuLWxt7YdIY1QfgMVi6qPJ8ZeH7jpvjubYn/AHlVx/6LroB0rA8Tny5tEue0WpRgn2ZWT/2agDeP9ao6ZDYadENLsyqiBdwizyisxI/DOcVf5rPk02Ma1HqolKOsDQOv8LgkEE/TBx/vUAaOaKRenSloAKQnGKXNYXiy5lj0Rra3YpdXzraQkdQX4J/AZP4UAReFsX/9oa4eRqE58k+sKZRD+OC3/Aqm8YSGLwjqePvPAY19y3yj9TWraWsNlaQ2tugSGFFjRR/CoAAH5AVi+MD5mmWVoOt1qNrF9QJVdv8Ax1WoA3IIvIto4h0jQKPwGKw7/wDc+N9Hk6edbXEJ9/uP/wCy10AFYHiH91qnh+5PAW+MZP8AvxuB+uKAN7tVLTYrKwhGlWRVVtVUeUDny1Odv4cHH0q9jNZz6ZGmuf2sszIxtvs8sf8ADIA2VJ91ywH+9QBog5paSloAKKKKACiiigAoooJoAa7BELMQFAySfSsDwmhubO61hxiXU5zOCeojACxj/vlQfxNL4tllk0pNLt2K3OpyC0Vh1RGH7xh9EDfjityCJLeFIYlCxxqFVR2AGBQBieM/m8L3UHe4aOAf8DdVP6E1uj0rB8UnzBpFt/z21KHI9ly5/wDQa3hQBgykxePbU9PtOmyD/viRD/7PW66B1KsMqRgisDXsweJfDVz0DXE1sx9A8Lt/ONa6HGfagClpos7WH+zbR122apGY85KKR8ufwq9WeNMji1yTVEkKvNAsEkf8L7WJUn3G5h+NX170ALRRRQAyaRIomkkbaiDcSewFYXhGFpNNm1aYEXGqTG6bPUIfljX8EC/iTSeLZmm0+30iAkT6pMLYEdVjwWkb8EVvxIreiRIo1jQAIg2qB2AoAwfGY8zw6bX/AJ+7q3tyPUPMgb9Ca6CsHxJ+8vdBtv8AnpqAc/8AAEZv5gVvD2oA50kwfEIAdLvSjj3MUo/+PVvTRLNC8Uiho3BVgehBHNYetDyfFnhu66BnuLUn/fj3/wA4hXQEZFAFTT/skEI0+2kBFmqRFCcsg2jAP4Yq5Wemmpb61PqSSlWuIkikTsxUnDfXBI+lXx3oAWiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAoopCcGgAJqpqV/Dpum3N7OT5UEbSNxyQB0FWieD24rxrxZ8Q7iTWptLNlEdPt7pVlBz5kmxwTzngZHpWdSrGCvI68Hga2Lk40ldrU9N8L2MtloUBuv+Py5Juro/8ATWQ7mH0GcD2ArXJ/WmQSiaBJAOGANc7448SyeGNDW6hgWaaWQRRq+doJBOTj6VUpqMeZmNKjOtVVKG7dibwn88GrXmP+PrVJ3564UiIfpGK6A9q89+F3iV9WsLmwlgVJLdjLvTOH3sWP0OSa9BzRCanHmRWKw1TDVnSqaNGDph8nxnrsHTzIbW4A9ch0J/8AIYrfBz0rxrVfiLNYeO7m5is4zBEv2KQOTllVyc/XJOOvWvY4W3xq/PzDPNRTqxm2l0NcVgK+FjCVVWUtUZ40+ePxIb+OQeRLbeVLGSfvK2VYfgWz+FaY9aoa3Fdy6NdLp8jJeeWWhK9dw5A/HFWrZ5JLeN5Y/LkZAWQn7px0/PNanGTUUUUAFFFFABRRRQAUhpaQ0AITXOzD+1PGkMXWDSYTMR28+QbV/EJu/wC+6s+JNYfR7NJIkDu7bQG6Dis7wZdLdf2hK4JuZp/Nlc98gAAegAGMVzPFUvbewv7xyPG0liPq1/eOqB5xWB4gxNrPh627G9aYg/7ET4/Uit122qcCvPrnxK03iK1vDD+7td6Ivf5sAk+/A/WjEYqnh7c73DFY2lhre0drnogrB8Y/J4dlnAJ+zTQz8eiyKT+ma2423Irc8jNc544uFXQJbN0JW8VoWIOCoIPIPrWtWrGlB1JbI1rV4Uabqz2R0qnIz688VS1ix/tLSLqyVyjTRlVcHG09j+eKzvDOuS6vbyeeirJEQCV4De+O1b3XjpSo1o1oKcNmFCtCvTVSnsyK084WsQuCpnCASFehbHOPbNT1lWQv4dd1FZt8ljL5ctuxP+rO3a6fTKg/8CNalamwN2rm+dU8ag4P2XSIc+zTyj/2VB/5E9ucv4meOZ/BGj209pbRzXVzKY083OxcDJJAIJqh8IvE7+JdK1Sa5gVL1bsyTspO1y4yMZ6YAxj2rrWBr/VvrVvcvYnmV7Ho/Qmue139/wCI/DVt1C3Utywx2SF1H6yLW+xwucc/rXgcnxhup/iFbTnTYTYQPJaIBu8za7qC2emflBxj8aMJga2L5vZK/LqwlJR3PfhXP+Mj5WiRXX/Pre20x+gmTd/46TW8h449K86+MfihtC8Kizjt1kl1LdAGYkCMYyW479MVlhqFTEVVSp7sbaSuz0ZTkZ9aoa7p76po1zaRSGKZ1zFJnG1xypPtkCuX+GXjifxto9zNd26Q3drII5PKzsbIyCAeldwaVehOhUdKotUCaeqGQ+Z5KebjzNo3beme9SVlaeL+LV9Sjudz2jMklu5PTIwy/gQD/wACrVrIYUUUUAFFFFABSN0pScVja7qz6asaxRqzuf4ugrGvXhQpupPZF06cqklGO5VgP9qeNLibkwaTEIFPYzSAM+Pouwf8CNdD3rnvCLJ9guFAJlad5pXb+N3JJP8AT8K6BmwCcdBTpVYVYKpHZhOm4S5HuYGsHz/Ffh22I4Vri5I/3Y9n85RXQjvXEpq3n+J7fUGi+5E9rGM9FdkJJ9/kFdqDWWGxdLEpun00LrUJ0rc3UwPGA2adY3Y62upWsv4GQI3/AI67V0AOa5vxfOsmnfYHTKz4JYHBXBB4/ECtDQtTfUrZ2kQLIhw2Oh96FjKTr+wT94HQmqftegviHTpdU0ae2t5fKuRiS3kzwsqkMmfbIAI9M1pRligLY3Y5x0/ClPasvShfx32pw3e54BOJLWUkYKMOV/4CwI/EV1GJq0hpagvJ2trOaZI2leNGcRr1YgdBQBiWY/tLxle3f3otNiFnGewkbDyY98eWPzFdAMj3rK8NadJpuhQRXHN3Junum/vTOSzn8ycewFaxOBmgDA1Ied4y0SHqI4bif6YCqD/49W+KxBbXD+NpLpom+zxacsaOehdpCWA+gRfzFbYoAwfFX7uLS7r/AJ99RhY/RiUP6Oa3hWN4qtZrvw9cJbxmSdWSRFXqSrq39K2VJIBIwcdKAMzxBp02p6S8NtMIbqN0mgkJICyIwZc4/hyMH2JrSTO3kY9qVhnFZejjUIrjUoL3dJClyXtZyQd8TANt/wCAtuX6AUAatFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABSGlooAaRzXNXngXQb7WP7TuLMNcE7jg4DH3FdL2pe9KUVLRmlKtUpO9N2v2GoAi4AAA4AFUtX0ey1ywayv4RLAxzg9j61eH3aP4aGk9GTGUoSUovXuZGh+G9M8OwSRabb+UJDlmJyT+Na23jrQvQ07tQoqKsh1Kk5ycpu77nM3fgXQL3V/7TnslNyTuPPBPqRXSqABgUh6ilXpQopO6HUrVKiSnJu2wpGaAMUtFMzCiiigAooooAKKKKACkNLSd6AKeoadb6nB5N0m5Acj2NN03S7XS4TFax7VPJOck1dHWheprLkh7Tntr3MvZU+f2nKubuGMjBrIfw1pz3/2tosybt3Xgn6Vs0h61U6cZ/ErhUpQqJc6vYaAVXiqmo6fb6nb+RcpuTOcg4INXaaeopyScWmroucIzi1JXRT07TLbS4PKtY9qk5J7mrwo70CiEYxXLFWSFThGEVGKskGKKWg1RZkeIPDel+J9P+xarbCeENuXkgqfUEdKTw94a0vwvp5stJthBEW3NySWPqSeta9FX7ap7P2fM+Xt0FZCEZFcmfhr4W/t/wDtr+zV+17/ADcZOzf67eldb2o7UUq1Sndwk1cbSe4gXArJ8Q+GtL8UWAstVthPEG3LyQVPqCK1+1FRCcqc04OzXUGjJ8P+G9M8Maf9h0q2EMJbc3JJY+pJ61rUUoqpzlOTnN3bAQClooqQCiiigAooooAKp3+nW+oRhLhNwB4PcVcpDUVIRnFxkrocZOLuitZ2UNjB5UC7VqwRxS9qKIQjGKjFWSBtt3ZmJoVlHd/aVj+fOcZ4zWlilo71FKnThdQjYcpSluynfadb6hGqzpu2nIPcVJZWUNjCYoF2rnNWKB1o9nTVTnUVfuHPLl5b6ARmgDGfelorYkKCM4oooAQDFBGaWigBAMUtFFAARmkAxS0UAIRmgDGec0tFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAH//2Q=="}}, {"section_id": 7, "text": "# Box 2.3. Ultrametricity of the Gibbs measure \n\nWe wish to discuss the behavior of a probability measure (the Gibbs measure) defined on $\\{ \\pm 1\\}^{N}$, or more generally on $\\mathbb{R}^{N}$, in the limit of large $N$. Since the space over which this probability measure is defined changes with $N$, one cannot simply ask whether the sequence converges weakly for instance. There is also a lot of invariance in the model, such as by permutations of the coordinates, so we may want to discard these symmetries while keeping interesting information. In a sense, we aim to retain information about the Gibbs measure as an abstract random metric space, ignoring how it is embedded into $\\mathbb{R}^{N}$ and discarding small-probability parts. One very convenient way to do this is\n\nto study the convergence of the joint law of the relative distances between finitely many independent samples from the measure ${ }^{a}$; these independent samples are called replicas. Recall that, for each choice of the parameters $\\left(W_{i j}\\right)$ and each $\\beta \\geqslant 0$, the Gibbs measure at inverse temperature $\\beta$ is the probability measure that attributes to the configuration $\\sigma \\in\\{ \\pm 1\\}^{N}$ a weight proportional to $\\exp \\left(\\beta H_{N}(\\sigma)\\right)$. It is thus a random probability measure, as it depends on our choice of the coefficients $\\left(W_{i j}\\right)$, and we are going to discuss properties of this probability measure that occur with high probability over the choice of these coefficients $\\left(W_{i j}\\right)$ and for large $N$. What physicists discovered, and was later proved rigorously (up to allowing ourselves a small perturbation of the energy function that does not change the value of the limit free energy), is that the Gibbs measure is asymptotically ultrametric. In Euclidean space, a set $S$ is ultrametric if it satisfies the following stronger form of the triangle inequality: for every $x, y, z \\in S$, we have\n\n$$\n|x-y| \\leqslant \\max (|x-z|,|y-z|)\n$$\n\nThis can be rephrased as the fact that whenever we draw a triangle with endpoints in $S$, the two largest sides of the triangle have the same length. In our context, the approximate ultrametricity of the Gibbs measure means that the following holds for every $\\varepsilon>0$ and $\\beta \\geqslant 0$ with probability tending to 1 in the $W$ 's as $N$ tends to infinity: if we pick three independent samples (\"replicas\") $\\sigma, \\sigma^{\\prime}$, and $\\sigma^{\\prime \\prime}$ from the Gibbs measure at inverse temperature $\\beta$, then with Gibbs probability tending to 1 as $N$ tends to infinity, we have\n\n$$\n\\left|\\sigma-\\sigma^{\\prime}\\right| \\leqslant \\max \\left(\\left|\\sigma-\\sigma^{\\prime \\prime}\\right|,\\left|\\sigma^{\\prime}-\\sigma^{\\prime \\prime}\\right|\\right)+\\varepsilon \\sqrt{N}\n$$\n\n(where $|\\cdot|$ is the Euclidean distance in $\\mathbb{R}^{N}$, and there is a natural $\\sqrt{N}$ scaling factor since $|\\sigma|=\\sqrt{N}$ ). Any ultrametric set can be represented as the leaves of a tree, with the distance between two leaves being only allowed to depend on the depth of the most recent common ancestor of the two leaves; see Figure 2.1 (or e.g. [21, Lemma 4.2]). The Gibbs measure thus splits into a number of \"pure states\" ${ }^{b}$ represented by the leaves of the tree; any two configurations sampled from a pure state are at a fixed distance from one another (with high probability). These pure states organize themselves into clusters, so that the distance between two configurations sampled from two different pure states in the same cluster is essentially constant; these clusters organize themselves into super-clusters; and so on, over a potentially infinite hierarchy of clusters and super-clusters. The exact number of hierarchies depends on the specifics of the problem. There will be no such hierarchy at high temperature (low $\\beta$ ), in some sense the tree collapses into a single point in this case. At low temperature (high $\\beta$ ), physicists seem to expect that most \"natural\" problems display either one or an infinite number of levels of hierarchy, although we know how to engineer spin-glass models with an arbitrary number of them.\nBeyond the fact that the asymptotic structure is ultrametric, in fact the full metric structure as well as the probability weights that the Gibbs measure attributes to each leaf are completely characterized in terms of the minimizer in (2.1). It would be too long to describe this structure precisely here (see for instance [61] or [29], including [29, Section 6.3] which explains how a 1-level hierarchy emerges from a much simpler toy model). I do want to stress though that I find this rigidity really remarkable. In particular, up to some technical caveats, we have that the hierarchical structure has depth $K$ if and only if the support of the measure $\\mu$ that minimizes the Parisi formula in (2.1) contains exactly $K+1$ points. Moreover, if we pick two independent samples $\\sigma$ and $\\sigma^{\\prime}$ from the Gibbs measure, then the law of their \"overlap\" $\\sigma \\cdot \\sigma^{\\prime} / N$ converges weakly to $\\mu$.\nWhenever a non-trivial hierarchical structure appears, physicists say that there is replicasymmetry breaking; and if there are $K$ levels to the hierarchy, they would say that the system has $K$ levels of replica-symmetry breaking.\n\nTo explain the choice of language, it is useful to ask ourselves first what physicists mean when they say that a symmetry is broken. Suppose that I try to balance a pencil that I place vertically on the tip of my finger. By symmetry, the only thing that can happen is that the pencil stays perfectly vertical, right? Well, my experiments do not match this prediction, as the pencil actually quickly falls in some direction. So one could say that the rotation symmetry is broken. Of course, if I try to be a bit diligent in my attempts at balancing the pencil, then the direction in which the pencil falls will be essentially uniformly random among all possible directions. The symmetry is therefore not really broken in a mathematical sense. The correct mathematical model of the outcome is probabilistic, but we have the impression that the symmetry is broken if we ignore this and only do one experiment.\nComing back to spin glasses and their ultrametric structure: suppose that we pick three independent samples $\\sigma, \\sigma^{\\prime}$ and $\\sigma^{\\prime \\prime}$ according to the Gibbs measure. Of course there is perfect permutation symmetry between these samples, so surely the distance between $\\sigma$ and $\\sigma^{\\prime}$ should be the same as that between $\\sigma$ and $\\sigma^{\\prime \\prime}$ ? Well, this is in fact not the case (see Figure 2.1), so the permutation symmetry between the replicas is broken. The key surprising thing here is that these relative distances remain random even in the limit of large $N$, even though one may have thought otherwise at first, because many quantities become essentially deterministic (\"self-averaging\" as physicists would say) in the high-dimensional regime.\n\n[^0]This series of discoveries generated a lot of excitement; people had identified a toy model of a \"complex\" system, with a very rich and rugged energy landscape, that they could study with great precision using analytical methods. Yet, says Giorgio Parisi [69], \"it was possible that the correct [solution] was different and more complex [...]. It was difficult to conclude in a definite way.\" The validity of the Parisi formula then became a certainty with a series of rigorous mathematical contributions, starting with Francesco Guerra [36] who proved that $\\lim \\sup _{N \\rightarrow \\infty} F_{N}(\\beta) \\leqslant \\inf _{\\mu \\in \\operatorname{Pr}([0,1])} \\mathcal{P}(\\mu)$. In a mathematical tour de force, Michel Talagrand [76] then managed to prove the converse bound and therefore give a complete justification to Parisi's formula ${ }^{10}$. An alternative proof that covers a broader class of models was later developed by Dmitry Panchenko [60, 61]. Besides its greater generality, this alternative proof is also more conceptual, and its key step is very interesting on its own, as it consists in justifying the ultrametricity of the underlying Gibbs measure (up to a small perturbation of the energy function).", "tables": {}, "images": {}}, {"section_id": 8, "text": "# 3. Towards MORE GENERAL MODELS \n\nThanks to the insights coming from the Parisi formula and its proof, as well as further developments, we now understand many aspects of the Sherrington-Kirkpatrick model and the structure of its Gibbs measures. To give just one example, there has been much recent progress on whether one can find a polynomial-time algorithm that\n\n[^1]\n[^0]:    ${ }^{a}$ This idea defines a topology on the space of (isometry classes of) random measure spaces called the Gromov-weak topology, and this topology is equivalent to that induced by the Gromov-Prokhorov metric [34].\n    ${ }^{b}$ This is vaguely analogous to the decomposition of a probability measure into its ergodic components in the theory of dynamical systems.\n\n[^1]:    ${ }^{10}$ This is one of the key results celebrated in the citation for Michel Talagrand's 2024 Abel prize.\n\nidentifies a configuration $\\sigma \\in\\{ \\pm 1\\}^{N}$ that essentially maximizes the function $H_{N}$ (see $[30,31,32,33,39,40,50,71,75])^{11}$.\n\nThe insights that were gained for the SK model have allowed us to make progress on a large variety of other \"complex\" problems that share similar features with \"frustrations\", from statistics and high-dimensional geometry to computer science and combinatorics. Examples include random constraint satisfaction problems [26, 28, 41, 43, 48, 49], the random assignment and traveling salesman problems [3, 4, 44], community detection and more general problems of large-scale statistical learning [1, 81] (see also [29, Section 4]), error correcting codes in information theory [70], and combinatorial problems such as graph coloring $[23,27,56]$.\n\nIn this presentation, I will single out a seemingly modest generalization of the SK model in which the variables are of two different types. We can visualize this by thinking of the variables as being organized into two layers as depicted in Figure 3.1, with each layer being made of variables of a single type; we now postulate that there are direct interactions between variables of different types only. I find this model interesting because it is closely related to several classical models of artificial neural networks. One is the Hopfield model, which is a model of memory storage and retrieval with a long history $[5,6,7,9,38,42,78]$. Another one is the\n![img-2.jpeg](img-2.jpeg)\n\nFigure 3.1. Elementary units are organized into two layers and only interact across layers.\nso-called restricted Boltzmann machine, which is an artificial neural-network architecture that was popular until around ten years ago for learning data distributions and then generating new samples [37, 73]; in this case our model is only capturing the initial stage of the network before any learning occurs, but physicists have already managed to gain very interesting insight from there $[13,79,80]^{12}$.\n\nTo formalize the model precisely, we can represent the variables as a pair $\\sigma=\\left(\\sigma_{1}, \\sigma_{2}\\right)=$ $\\left(\\sigma_{1,1}, \\ldots, \\sigma_{1, N}, \\sigma_{2,1}, \\ldots, \\sigma_{2, N}\\right) \\in\\{ \\pm 1\\}^{N} \\times\\{ \\pm 1\\}^{N}$, and we set\n\n$$\nH_{N}^{\\mathrm{hip}}(\\sigma):=\\frac{1}{\\sqrt{N}} \\sum_{i, j=1}^{N} W_{i, j} \\sigma_{1, i} \\sigma_{2, j}\n$$\n\nFor simplicity we have imposed $\\sigma_{1}$ and $\\sigma_{2}$ to be vectors of the same length $N$, but this is not fundamental; the important point is to make sure that the respective sizes of the two layers remain proportional to one another as we consider larger and larger systems. We have also retained the idea that each of the variables takes values in $\\{ \\pm 1\\}$, but this can also be relaxed ${ }^{13}$. We will call this model the bipartite model.\n\nThis model may seem barely distinguishable from the SK model at first sight. Yet, to this day, we do not know what the limit of the free energy is in this case; in fact, even the fact that the free energy converges as $N$ tends to infinity is not known. To be clear,\n\n[^0]\n[^0]:    ${ }^{11}$ Roughly speaking, the general criterion is that this is possible if and only if the support of the minimizer $\\mu \\in \\operatorname{Pr}([0,1])$ in the Parisi formula (2.1) is connected for all $\\beta$ sufficiently large.\n    ${ }^{12}$ In the time since this paragraph was written, the Nobel committee awarded the 2024 Physics prize to John Hopfield and Geoffrey Hinton, citing in particular their works on these models.\n    ${ }^{13}$ By sticking with the simplest possible version of the model, we have artificially introduced a symmetry between the two layers, but we want to insist on devising analysis techniques that do not rely on this symmetry; a simple way to break the symmetry while staying within our context and notation is to add a term $h \\sum_{i=1}^{N} \\sigma_{1, i}$ into the definition of $H_{N}^{\\text {hip }}(\\sigma)$, for some parameter $h \\neq 0$.\n\nthe free energy here is\n\n$$\n\\frac{1}{N} \\mathbb{E} \\log \\sum_{\\sigma \\in\\{ \\pm 1\\}^{N} \\times\\{ \\pm 1\\}^{N}} \\exp \\left(\\beta H_{N}^{\\mathrm{hip}}(\\sigma)\\right)\n$$\n\nThe asymptotic behavior of the maximum\n\n$$\n\\frac{1}{N} \\max _{\\sigma \\in\\{ \\pm 1\\}^{N} \\times\\{ \\pm 1\\}^{N}} H_{N}^{\\mathrm{hip}}(\\sigma)\n$$\n\nis also poorly understood. The problem here goes beyond that of fixing some technical part in the proof of the Parisi formula. Indeed, one may imagine several possible ways for the Parisi formula to generalize to this bipartite model, however it can be shown that none of those candidates for the limit are valid [51, Section 6].\n\nIn order to clarify what distinguishes the bipartite model from the SK model at the technical level, it is best to change a bit our viewpoint on the definition of these random fields $H_{N}$ and $H_{N}^{\\text {hip }}$. Instead of writing them down explicitly as in (1.1) and (3.1), an equivalent way to define them is to specify that they are centered Gaussian fields, and to display their covariance. For the SK model, we have for every $\\sigma, \\tau \\in\\{ \\pm 1\\}^{N}$ that\n\n$$\n\\mathbb{E}\\left[H_{N}(\\sigma) H_{N}(\\tau)\\right]=N\\left(\\frac{\\sigma \\cdot \\tau}{N}\\right)^{2}\n$$\n\nwhere the dot in $\\sigma \\cdot \\tau$ denotes the usual scalar product in $\\mathbb{R}^{N}$. So instead of writing the formula in (1.1), we could also have said \"let $\\left(H_{N}(\\sigma)\\right)_{\\sigma \\in\\{ \\pm 1\\}^{N}}$ be the centered Gaussian vector whose covariance is given by (3.2)\". The one advantage of the explicit formula, besides its possibly more intuitive appeal, is that it makes it transparent that such a random vector exists. More generally, one could consider centered Gaussian fields $\\left(H_{N}(\\sigma)\\right)_{\\sigma \\in \\mathbb{R}^{N}}$ such that, for some smooth function $\\xi: \\mathbb{R} \\rightarrow \\mathbb{R}$, we have for every $\\sigma, \\tau \\in \\mathbb{R}^{N}$ that\n\n$$\n\\mathbb{E}\\left[H_{N}(\\sigma) H_{N}(\\tau)\\right]=N \\xi\\left(\\frac{\\sigma \\cdot \\tau}{N}\\right)\n$$\n\nthe SK model corresponds to the case when $\\xi(r)=r^{2}$. For the choice of $\\xi(r)=r^{3}$, we can find a Gaussian field that satisfies (3.3) by setting\n\n$$\nH_{N}(\\sigma):=\\frac{1}{N} \\sum_{i, j, k=1}^{N} J_{i, j, k} \\sigma_{i} \\sigma_{j} \\sigma_{k}\n$$\n\nwhere $\\left(J_{i, j, k}\\right)$ are independent centered Gaussians with unit variance. One can realize $\\xi(r)=r^{p}$ for any positive integer $p$ by proceeding similarly. Multiplying a random field by a factor of $\\lambda$ transforms the function $\\xi$ into $\\lambda^{2} \\xi$. And by adding independent versions of fields with possibly different functions $\\xi$, we can also create a new field whose covariance is the sum of those functions $\\xi$. So we see that any function $\\xi$ that can be written in the form\n\n$$\n\\xi(r)=\\sum_{p=0}^{+\\infty} a_{p} r^{p}\n$$\n\nwith $a_{p} \\geqslant 0$ going to zero sufficiently rapidly as $p$ tends to infinity, will be a valid covariance function. One can show that these are all the admissible functions (see [53, Proposition 6.6] for a statement that also covers the case of models with multiple types of spins).\n\nFor the bipartite model, we have instead that, for every $\\sigma, \\tau \\in\\{ \\pm 1\\}^{N} \\times\\{ \\pm 1\\}^{N}$,\n\n$$\n\\mathbb{E}\\left[H_{N}^{\\mathrm{hip}}(\\sigma) H_{N}^{\\mathrm{hip}}(\\tau)\\right]=N\\left(\\frac{\\sigma_{1} \\cdot \\tau_{1}}{N}\\right)\\left(\\frac{\\sigma_{2} \\cdot \\tau_{2}}{N}\\right)\n$$\n\nThe key technical difference between the SK and the bipartite models is that here the relevant function that shows up on the right side of (3.5) is the mapping $(x, y) \\mapsto x y$, which is not convex. To be precise, for models with only one type of spins, i.e. of the form in (3.3), what is crucial is that the function $\\xi$ is convex over $\\mathbb{R}_{+}$; as one can see from (3.4), this is in fact always true! This convexity property can however break down as soon as we consider models with two or more types of spins. In general, we may consider models with a fixed number $D$ of types of spins, say $\\sigma=\\left(\\sigma_{1}, \\ldots, \\sigma_{D}\\right) \\in\\left(\\mathbb{R}^{N}\\right)^{D}$, with a covariance such that, for every $\\sigma, \\tau \\in\\left(\\mathbb{R}^{N}\\right)^{D}$,\n\n$$\n\\mathbb{E}\\left[H_{N}(\\sigma) H_{N}(\\tau)\\right]=N \\xi\\left(\\left(\\frac{\\sigma_{d} \\cdot \\sigma_{d^{\\prime}}}{N}\\right)_{1 \\leqslant d, d^{\\prime} \\leqslant D}\\right)\n$$\n\nwhere $\\xi$ is some (admissible) function from $\\mathbb{R}^{D \\times D}$ to $\\mathbb{R}$. Those models for which we can write down and rigorously prove a Parisi formula for the limit free energy are exactly those for which the function $\\xi$ is convex over the space of symmetric positive semidefinite matrices (see [21, Theorem 1], which crucially builds upon $[10,60,62,63,64]$ ).", "tables": {}, "images": {"img-2.jpeg": "data:image/jpeg;base64,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"}}, {"section_id": 9, "text": "# 4. A CONNECTION WITH PARTIAL DIfFERENTIAL EQUATIONS \n\nSo what can we do for the bipartite model? As discussed in the previous section, in this case it is not even clear what one is supposed to show, as there is no clear way to extend the Parisi formula into some reasonable candidate for the limit free energy. I will explain one possible route which my collaborators and I have been exploring. The idea is in two steps. First, we enrich the free energy, adding some (hopefully not too complicated) terms to the energy function, so that we end up with a free energy that depends on additional parameters besides the inverse temperature. Next, one hopes to find a partial differential equation that this free energy solves approximately, and to characterize the limit free energy as the unique solution to this equation. This approach works well for simpler models such as the Curie-Weiss model and its generalizations, or for some problems of statistical inference such as community detection, see [29, Chapters 1 to 4] for a detailed presentation. Perhaps good pedagogic practice would require that I discuss these models first. Instead I will try to directly address the more complicated case of spin glasses, but some aspects of the discussion will then be rather sketchy.\n\nThe fact that the limit free energy of a model of statistical mechanics may solve a partial differential equation is an old observation going back at least to [19, 57] (see also [14] for a recent survey on related topics). In the context of spin glasses, these connections were first explored in $[2,11,12,35]$ under simplifying assumptions. The fact that the Parisi formula can be recast as the value of the solution to some partial differential equation is from $[22,52,55]$ (see also [29]).\n\nIn order to keep the notation simple, we will first discuss the approach in the case of the SK model. Let us start by defining a new free energy with an additional parameter, and then discuss motivations for this choice. For every $t \\geqslant 0$ and $h \\geqslant 0$, we set\n\n$$\nF_{N}(t, h):=-\\frac{1}{N} \\mathbb{E} \\log \\sum_{\\sigma \\in\\{\\pm 1\\}^{N}} \\exp \\left(\\sqrt{2 t} H_{N}(\\sigma)-N t+\\sqrt{2 h} z \\cdot \\sigma-N h\\right)\n$$\n\nwhere $z=\\left(z_{1}, \\ldots, z_{N}\\right)$ is a vector of independent centered Gaussians with unit variance, independent of $H_{N}$, and we recall that the function $H_{N}$ for the SK model is defined in (1.1).\n\nSeveral comments need to be made to explain some of the choices that have been made in this new definition of $F_{N}$. First, we replaced $\\beta$ with $\\sqrt{2 t}$. The ultimate reason for this is that the subsequent formulas will look nicer in this way, but one way to\n\nsense that this may be so is to recall that $H_{N}(\\sigma)$ is a Gaussian random variable, and so the scaling $\\sqrt{2 t} H_{N}(\\sigma)$ is such that the variance of the Gaussian scales linearly, as with Brownian motion; it is as if we were continuously adding new independent copies of $H_{N}(\\sigma)$ homogeneously in time. The same goes for $\\sqrt{2 h}$ in front of $z \\cdot \\sigma$. The factor $-N t$ is also ultimately here just to make the subesquent formulas a bit nicer; it is half the variance of the Gaussian random variable $\\sqrt{2 t} H_{N}(\\sigma)$. People who are familiar with stochastic calculus will recognize a stochastic exponential here: in particular, we have that $\\mathbb{E}\\left[\\exp \\left(\\sqrt{2 t} H_{N}(\\sigma)-N t\\right)\\right]=1$. So if we were to exchange the expectation and the logarithm in (4.1), we would end up with summands that are all equal to 1. By Jensen's inequality, the quantity with expectation and logarithm interchanged is smaller than the original one, and we set things up so as to monitor the defect in this Jensen's inequality ${ }^{14}$.\n\nFrom the formula (4.1) we have so far mostly discussed simple changes of variables, or tried to give some excuse for the presence of the silly-looking terms $N t$ or $N h$, but the important part is to get a feeling as to why we are adding this term $\\sqrt{2 h} z \\cdot \\sigma$. That we are looking for a partial differential equation for $F_{N}$ means that we hope to be able to compensate small variations of $t$ with small variations in $h$. So we aim to find some term that looks like $H_{N}(\\sigma)$ in some sense, while being also simpler to analyse. Perhaps one way to think that the term $\\sqrt{2 h} z \\cdot \\sigma$ is not an unreasonable choice is to write\n\n$$\nH_{N}(\\sigma)=\\frac{1}{\\sqrt{N}} \\sum_{i=1}^{N}\\left(\\sum_{j=1}^{N} J_{i j} \\sigma_{j}\\right) \\sigma_{i}\n$$\n\nand to venture the guess that maybe the random variables $\\left(\\sum_{j=1}^{N} J_{i j} \\sigma_{j}\\right)$ could be substituted with equivalent independent Gaussians, because, well, at least for each fixed $\\sigma$ they are Gaussian after all. A more detailed explanation is beyond the scope of this note; for me the best heuristic is that discussed in [29, Exercise 6.5 and solution].\n\nLet us be pragmatic here and just calculate the derivatives of $F_{N}$ to see if something interesting happens. In order to express these derivatives nicely, we introduce some notation for the Gibbs measure. For any function $f$, we write\n\n$$\n\\langle f(\\sigma)\\rangle:=\\frac{\\sum_{\\sigma \\in\\{ \\pm 1\\}^{N}} f(\\sigma) \\exp \\left(H_{N}(t, h, \\sigma)\\right)}{\\sum_{\\sigma \\in\\{ \\pm 1\\}^{N}} \\exp \\left(H_{N}(t, h, \\sigma)\\right)}\n$$\n\nwhere we have set $H_{N}(t, h, \\sigma):=\\sqrt{2 t} H_{N}(\\sigma)-N t+\\sqrt{2 h} z \\cdot \\sigma-N h$. In the notation on the left side of (4.2), the bracket $\\langle\\cdot\\rangle$ thus stands for the expectation with respect to the Gibbs measure, and we think of $\\sigma$ as a random variable that is sampled accordingly. We also write $\\sigma^{\\prime}$ to denote an independent copy of $\\sigma$ under the Gibbs measure, that is, we write\n\n$$\n\\left\\langle f\\left(\\sigma, \\sigma^{\\prime}\\right)\\right\\rangle:=\\frac{\\sum_{\\sigma, \\sigma^{\\prime} \\in\\{ \\pm 1\\}^{N}} f\\left(\\sigma, \\sigma^{\\prime}\\right) \\exp \\left(H_{N}(t, h, \\sigma)+H_{N}\\left(t, h, \\sigma^{\\prime}\\right)\\right)}{\\sum_{\\sigma, \\sigma^{\\prime} \\in\\{ \\pm 1\\}^{N}} \\exp \\left(H_{N}(t, h, \\sigma)+H_{N}\\left(t, h, \\sigma^{\\prime}\\right)\\right)}\n$$\n\n[^0]\n[^0]:    ${ }^{14}$ In general, we also do not restrict ourselves to models defined on $\\{ \\pm 1\\}^{N}$. For a model whose covariance is given by (3.3), we thus write\n\n    $$\n    F_{N}(t, h):=-\\frac{1}{N} \\mathbb{E} \\log \\int \\exp \\left(\\sqrt{2 t} H_{N}(\\sigma)-N t \\xi\\left(|\\sigma|^{2} / N\\right)+\\sqrt{2 h} z \\cdot \\sigma-h|\\sigma|^{2}\\right) \\mathrm{d} P_{N}(\\sigma)\n    $$\n\n    where $P_{N}=P_{1}^{\\otimes N}$ is the $N$-fold tensor product of a probability measure $P_{1}$ on $\\mathbb{R}$ with compact support. We recover the SK model by choosing $\\xi(r)=r^{2}$ and $P_{1}=\\left(\\delta_{1}+\\delta_{-1}\\right) / 2$, up to the addition of a trivial factor of $\\log 2$. Notice that with this definition, Jensen's inequality tells us that $F_{N} \\geqslant 0$, thanks to the extra minus sign that we added there.\n\nA calculation ${ }^{15}$ gives us that\n\n$$\n\\partial_{t} F_{N}(t, h)=\\mathbb{E}\\left\\{\\left(\\frac{\\sigma \\cdot \\sigma^{\\prime}}{N}\\right)^{2}\\right\\} \\quad \\text { and } \\quad \\partial_{h} F_{N}(t, h)=\\mathbb{E}\\left\\{\\frac{\\sigma \\cdot \\sigma^{\\prime}}{N}\\right\\}\n$$\n\nThe dependence on $t$ and $h$ in the right-hand sides of the identities above is hidden in the definition of the Gibbs average $(\\cdot)$. For more general models as in (3.3), we would find the exact same expression for $\\partial_{h} F_{N}$ as in (4.3) (for the corresponding definition of the Gibbs measure), while for the derivative in $t$, we would find that\n\n$$\n\\partial_{t} F_{N}(t, h)=\\mathbb{E}\\left\\{\\xi\\left(\\frac{\\sigma \\cdot \\sigma^{\\prime}}{N}\\right)\\right\\}\n$$\n\nContinuing with the SK model for now, we thus obtain that\n\n$$\n\\partial_{t} F_{N}-\\left(\\partial_{h} F_{N}\\right)^{2}=\\mathbb{E}\\left\\{\\left(\\frac{\\sigma \\cdot \\sigma^{\\prime}}{N}\\right)^{2}\\right\\}-\\left(\\mathbb{E}\\left\\{\\frac{\\sigma \\cdot \\sigma^{\\prime}}{N}\\right\\}\\right)^{2}\n$$\n\nThe right-hand side of this identity is the variance of the random variable $\\sigma \\cdot \\sigma^{\\prime} / N$ under $\\mathbb{E}(\\cdot)$. Since $\\sigma \\cdot \\sigma^{\\prime} / N$ is a sum of a large number of terms, we could at first anticipate that it will have small fluctuations - and in fact, this intuition turns out to be valid as long as $t$ is small. Just to see what happens (or by deciding that we restrict to small $t$ ), let us get along a little with this hypothesis that the variance of $\\sigma \\cdot \\sigma^{\\prime} / N$ tends to zero as $N$ tends to infinity. We are then led to the expectation that $F_{N}$ may converge to a limit function $f$ that solves the equation\n\n$$\n\\partial_{t} f-\\left(\\partial_{h} f\\right)^{2}=0\n$$\n\nMoreover, as we set $t=0$ in the definition of $F_{N}$ in (4.1), we find that we can easily calculate the result by writing $z \\cdot \\sigma=\\sum_{i=1}^{N} z_{i} \\sigma_{i}$, writing the exponential of the sum as a product of exponentials, and realizing that we can then factorize the summation into a product of $N$ simple sums over $\\{ \\pm 1\\}$. In short, we see that\n\n$$\nF_{N}(0, h)=F_{1}(0, h)\n$$\n\nSo if we believe that the random variable $\\sigma \\cdot \\sigma^{\\prime} / N$ has vanishingly small fluctuations in the limit of large $N$, then we are tempted towards the conjecture that $F_{N}$ converges to the function $f$ that solves (4.6) with initial condition $f(0, \\cdot)=F_{1}(0, h)$. In fact, this guess for the limit free energy that we thus obtain is exactly the one that was proposed (using other arguments) in the paper that introduced the SK model [72]. For the model with the covariance as in (3.3), we would instead have guessed the partial differential equation\n\n$$\n\\partial_{t} f-\\xi\\left(\\partial_{h} f\\right)=0\n$$\n\nPartial differential equations of this sort are called Hamilton-Jacobi equations.\nThe hypothesis that the random variable $\\sigma \\cdot \\sigma^{\\prime} / N$ has vanishingly small fluctuations in the limit of large $N$ is just of the sort that works very well for simpler models, but here it is only valid at high temperature, that is for small values of $t$. To see why, notice first that since $|\\sigma|=\\left|\\sigma^{\\prime}\\right|=\\sqrt{N}$, the fluctuations of $\\sigma \\cdot \\sigma^{\\prime} / N$ are the same as those of $\\left|\\sigma-\\sigma^{\\prime}\\right|^{2} /(2 N)$. The point then is that for sufficiently large values of $t$, the Gibbs measure starts to look like the ultrametric tree appearing on Figure 2.1, with each leaf vertex endowed with a\n\n[^0]\n[^0]:    ${ }^{15}$ You can try! The only thing to have in mind is that if $G$ is a centered Gaussian of unit variance and $f$ is a nice enough function (say $C^{1}$ with reasonable growth of $f$ and $f^{\\prime}$ at infinity), then\n\n    $$\n    \\mathbb{E}[G f(G)]=\\mathbb{E}\\left[f^{\\prime}(G)\\right]\n    $$\n\n    To see this, you just need to write the expectation explicitly as an integral against the Gaussian density, and integrate by parts.\n\nfixed probability weight. As long as this tree is not reduced to a single vertex (which does happen for large $t$ ), we see that the distance between two points taken at random on the leaves of the tree will fluctuate.\n\nEven though our first attempt at analyzing the model did not really work out, the idea we have explored here seems promising, so we are going to build upon it. The point is that we have not fully succeeded in \"closing the equation\" with the introduction of this parameter $h$; but maybe if we were introducing more parameters, then we would be able to do better.\n\nThe full construction of the free energy that incorporates these additional parameters would take too much space to explain here (one can consult [29, Section 6.4]), but the basic idea is that, since we anticipate that the true system may have a complicated ultrametric structure as discussed in the previous section, we want to replace our naive \"external field\" $\\sqrt{2 h} z$, which we were \"dotting\" against $\\sigma$, with a more refined object that has such an ultrametric structure embedded into it. This ultrametric structure is encoded using a non-decreasing function $q:[0,1] \\rightarrow[0, \\infty)$.\n\nSo this construction leads us to a new definition of the free energy $F_{N}$, which we now think of as a function of $t$ and $q$ in place of $t$ and $h$. We may call this extended function $F_{N}(t, q)$ the \"enriched\" free energy. The version in (4.1) corresponds to the choice of the constant function $q=h$ in this new definition; in particular, we are computing the free energy of the \"vanilla\" model when we compute $F_{N}\\left(\\beta^{2} / 2,0\\right)$, up to remembering the extra minus sign and the term $N t$ in (4.1).\n\nLet us denote by $\\mathcal{Q}$ the space of non-decreasing functions $q:[0,1] \\rightarrow[0, \\infty)$. The notion of differentiation for functions $g: \\mathcal{Q} \\rightarrow \\mathbb{R}$ that we use is as follows. We say that $g$ is differentiable at $q \\in \\mathcal{Q}$, and in this case denote by $\\partial_{q} g(q, \\cdot) \\in L^{2}([0,1] ; \\mathbb{R})$ the derivative at $q$, if for every $q^{\\prime} \\in \\mathcal{Q}$, we have\n\n$$\ng\\left((1-\\varepsilon) q+\\varepsilon q^{\\prime}\\right)=g(q)+\\varepsilon \\int_{0}^{1}\\left(q^{\\prime}-q\\right)(u) \\partial_{q} g(q, u) \\mathrm{d} u+o(\\varepsilon) \\quad(\\varepsilon \\rightarrow 0)\n$$\n\nEquipped with this, one can find a nice expression for the derivative of $F_{N}$ with respect to $q$, which resembles what we have found in the second part of (4.3) but also involves some other variables that play a role in the ultrametric structure of the new external field. One is then led to form the quantity\n\n$$\n\\partial_{t} F_{N}(t, q)-\\int_{0}^{1}\\left(\\partial_{q} F_{N}(t, q, u)\\right)^{2} \\mathrm{~d} u=\\text { small? }\n$$\n\nWhat replaces the \"small\" right-hand side above is a conditional variance of $\\sigma \\cdot \\sigma^{\\prime} / N$, in particular it is indeed smaller than the variance of $\\sigma \\cdot \\sigma^{\\prime} / N$, so we are indeed making progress. For the model with the covariance as in (3.3), we are led to hope that\n\n$$\n\\partial_{t} F_{N}(t, q)-\\int_{0}^{1} \\xi\\left(\\partial_{q} F_{N}(t, q, u)\\right) \\mathrm{d} u=\\text { small? }\n$$\n\nWhile we did not explain the construction of this new external field with an ultrametric structure, it turns out that it is still \"factorizable\" in the sense that the nice property that we had in (4.7) is still valid in this more general setting, that is, we have for every $q \\in \\mathcal{Q}$ that\n\n$$\nF_{N}(0, q)=F_{1}(0, q)\n$$\n\nIt turns out that our more sophisticated hopes are now correct. For notational convenience, we define $\\psi(q):=F_{1}(0, q)$.\n\nTheorem 4.1 (The Parisi formula as a Hamilton-Jacobi equation [22, 52, 55]). The enriched free energy $F_{N}: \\mathbb{R}_{+} \\times \\mathcal{Q} \\rightarrow \\mathbb{R}$ for the SK model converges pointwise to the function $f: \\mathbb{R}_{+} \\times \\mathcal{Q} \\rightarrow \\mathbb{R}$ that solves\n\n$$\n\\begin{cases}\\partial_{t} f-\\int_{0}^{1}\\left(\\partial_{q} f\\right)^{2}=0 & \\text { on } \\mathbb{R}_{+} \\times \\mathcal{Q} \\\\ f(0, \\cdot)=\\psi & \\text { on } \\mathcal{Q}\\end{cases}\n$$\n\nMore generally, if $F_{N}: \\mathbb{R}_{+} \\times \\mathcal{Q} \\rightarrow \\mathbb{R}$ now stands for the enriched free energy associated with a model whose covariance is given by (3.3), then $F_{N}$ converges to the function $f$ that solves\n\n$$\n\\begin{cases}\\partial_{t} f-\\int_{0}^{1} \\xi\\left(\\partial_{q} f\\right)=0 & \\text { on } \\mathbb{R}_{+} \\times \\mathcal{Q} \\\\ f(0, \\cdot)=\\psi & \\text { on } \\mathcal{Q}\\end{cases}\n$$\n\nPart of the task of making sense of this theorem is that one needs to find a good notion of solution for the Hamilton-Jacobi equations in (4.10) and (4.11). This is based on the notion of viscosity solutions (see [29, Chapter 3] for an introduction that is tailored to our context).\n\nHow does this formulation relate to the Parisi formula? The key point is that when the non-linearity (the square function in (4.10)) is convex, the solution admits a variational representation known as the Hopf-Lax formula. The solution to (4.10) can be written as\n\n$$\nf(t, q)=\\sup _{q^{\\prime} \\in \\mathcal{Q}}\\left(\\psi\\left(q+q^{\\prime}\\right)-\\frac{1}{4 t} \\int_{0}^{1}\\left(q^{\\prime}\\right)^{2}\\right)\n$$\n\nFor the solution to the more general equation in (4.11), we have\n\n$$\nf(t, q)=\\sup _{q^{\\prime} \\in \\mathcal{Q}}\\left(\\psi\\left(q+q^{\\prime}\\right)-t \\int_{0}^{1} \\xi^{*}\\left(\\frac{q^{\\prime}}{t}\\right)\\right)\n$$\n\nwhere $\\xi^{*}$ is the convex dual of $\\xi$ defined, for every $s \\in \\mathbb{R}$, by\n\n$$\n\\xi^{*}(s):=\\sup _{r \\geqslant 0}(r s-\\xi(r))\n$$\n\nOne can then bridge this representation back to the Parisi formula by setting $q=0$ in (4.12), making a change of variables, and doing some explicit calculations involving the function $\\psi .^{16}$\n\nAll this is nice, but we already knew the answer in these cases. The really interesting things come about when we consider models with different types of spins such as the bipartite model. Recall that in this case the energy function $H_{N}^{\\text {bip }}$ is defined in (3.1). Let us first see how a simpler guess analogous to (4.6) or (4.8) would look like then. The important point is that since there are now two types of spins, we would like to make sure that we have one additional variable (one additional \"external field\") to act upon each of these two types. So we set, for every $t \\geqslant 0, h=\\left(h_{1}, h_{2}\\right) \\in \\mathbb{R}_{+}^{2}$, and $\\sigma=\\left(\\sigma_{1}, \\sigma_{2}\\right) \\in\\{ \\pm 1\\}^{N} \\times\\{ \\pm 1\\}^{N}$\n\n$$\nH_{N}(t, h, \\sigma):=\\sqrt{2 t} H_{N}^{\\mathrm{bip}}(\\sigma)-N t+\\sqrt{2 h_{1}} z_{1} \\cdot \\sigma_{1}-N h_{1}+\\sqrt{2 h_{2}} z_{2} \\cdot \\sigma_{2}-N h_{2}\n$$\n\n(we drop the superscript ${ }^{\\text {bip }}$ from now on for ease of notation), and then for every $t \\geqslant 0$ and $h=\\left(h_{1}, h_{2}\\right) \\in \\mathbb{R}_{+}^{2}$, we set the new free energy to be\n\n$$\nF_{N}(t, h):=-\\frac{1}{N} \\mathbb{E} \\log \\sum_{\\sigma \\in\\{ \\pm 1\\}^{N} \\times\\{ \\pm 1\\}^{N}} \\exp \\left(H_{N}(t, h, \\sigma)\\right)\n$$\n\n[^0]\n[^0]:    ${ }^{16}$ Our formulas here are with a supremum, unlike in (2.1), but this is only for the trivial reason that we have added a minus sign in the definition in (4.1).\n\nThe definition of the Gibbs average $\\langle\\cdot\\rangle$ is hopefully clear, it is essentially as in the formula in (4.2), except that now the variable $h$ is in $\\mathbb{R}_{+}^{2}$ and the summation variable $\\sigma$ ranges in $\\{ \\pm 1\\}^{N} \\times\\{ \\pm 1\\}^{N}$. In place of (4.3) or (4.4), we obtain that\n\n$$\n\\partial_{t} F_{N}(t, h)=\\mathbb{E}\\left\\{\\left(\\frac{\\sigma_{1} \\cdot \\sigma_{1}^{\\prime}}{N}\\right),\\left(\\frac{\\sigma_{2} \\cdot \\sigma_{2}^{\\prime}}{N}\\right)\\right\\}\n$$\n\nwith still\n\n$$\n\\partial_{h_{1}} F_{N}(t, h)=\\mathbb{E}\\left\\{\\frac{\\sigma_{1} \\cdot \\sigma_{1}^{\\prime}}{N}\\right\\} \\quad \\text { and } \\quad \\partial_{h_{2}} F_{N}(t, h)=\\mathbb{E}\\left\\{\\frac{\\sigma_{2} \\cdot \\sigma_{2}^{\\prime}}{N}\\right\\}\n$$\n\nSo now if we expect that the random variables $\\sigma_{1} \\cdot \\sigma_{1}^{\\prime} / N$ and $\\sigma_{2} \\cdot \\sigma_{2}^{\\prime} / N$ do not fluctuate much in the limit of large $N$, we are led to the belief that $F_{N}$ converges to $f$ solving\n\n$$\n\\partial_{t} f-\\partial_{h_{1}} f \\partial_{h_{2}} f=0\n$$\n\nThe initial condition $f(0, \\cdot)$ is easy to compute as it satisfies (4.7) again.\nThe problem is that this guess is too naive again of course, so instead we need to replace our pair of simple variables $h=\\left(h_{1}, h_{2}\\right) \\in \\mathbb{R}_{+}^{2}$ by a pair of functions $q=\\left(q_{1}, q_{2}\\right) \\in \\mathcal{Q}^{2}$ that encodes the ultrametric structure of the external fields that act upon $\\sigma_{1}$ and $\\sigma_{2}$ respectively. This defines for us a more sophisticated free energy $F_{N}$, now defined on $\\mathbb{R}_{+} \\times \\mathcal{Q}^{2}$ in place of $\\mathbb{R}_{+} \\times \\mathbb{R}_{+}^{2}$. Again we have that (4.9) holds (now with $q$ ranging in $\\mathcal{Q}^{2}$ ); let us set $\\psi:=F_{1}(0, \\cdot)$ for convenience. By going through similar calculations as for the SK model, one thus ends up expecting that:\nConjecture 4.2. Maybe the enriched free energy $F_{N}: \\mathbb{R}_{+} \\times \\mathcal{Q}^{2} \\rightarrow \\mathbb{R}$ for the bipartite model converges to the function $f: \\mathbb{R}_{+} \\times \\mathcal{Q}^{2} \\rightarrow \\mathbb{R}$ that solves\n\n$$\n\\begin{cases}\\partial_{t} f-\\int_{0}^{1} \\partial_{q_{1}} f \\partial_{q_{2}} f=0 & \\text { on } \\mathbb{R}_{+} \\times \\mathcal{Q}^{2} \\\\ f(0, \\cdot)=\\psi & \\text { on } \\mathcal{Q}^{2} \\quad ?\\end{cases}\n$$\n\nIn this case, since the non-linearity in the equation (4.14) (i.e. the mapping $(x, y) \\mapsto x y$ ) is neither convex nor concave, there is no standard way to represent the solution to (4.14) variationally. So there is no clear way to rewrite this candidate for the limit free energy into a form that would resemble the Parisi formula for the SK model.\n\nAs was said already, we do not know if Conjecture 4.2 is valid or not. One thing we know is that any subsequential limit of $F_{N}$ must satisfy the equation in (4.14) \"almost everywhere\" in $\\mathbb{R}_{+} \\times \\mathcal{Q}^{2}$, for a suitable interpretation of \"almost everywhere\" [21]. This is not sufficient to fully characterize the solution to (4.14) though; even in finite dimensions, there may be many functions that solve a Hamilton-Jacobi equation almost everywhere. Another thing that we know is that the solution to (4.14) is a lower bound [22, 51], that is, for every $t \\geqslant 0$ and $q \\in \\mathcal{Q}^{2}$, we have\n\n$$\n\\liminf _{N \\rightarrow \\infty} F_{N}(t, q) \\geqslant f(t, q)\n$$\n\nwhere $f$ denotes the unique viscosity solution to (4.14). The result that I find most interesting, and which essentially matches what the physicists say using other language, is one that I will only describe informally. In order to do so, let us first discuss a classical method to solve (4.14) for short times called the method of characteristics (see [29, Section 3.5] for more precision). It turns out that if one does some formal calculations assuming that the solution to (4.14) is twice differentiable, one can guess a simple formula for what the value of the solution ought to be along each of a spanning family of lines called the characteristics. In our case the characteristic that starts at $q$ is the straight line\n\n$$\nt \\mapsto q-t \\nabla \\xi\\left(\\partial_{q} \\psi(q)\\right)\n$$\n\n![img-3.jpeg](img-3.jpeg)\n\nFigure 4.1. Each characteristic line offers us a \"prediction\" for what the limit free energy is. For small $t$, each point $(t, q)$ (e.g. the orange point) is reached by exactly one characteristic line, so we know the value of the free energy then. For large $t$, it could happen that multiple characteristics reach a point, as happens for the black point. We know that the limit free energy must be as prescribed by one of those characteristics, but we do not know which one.\nwhere we denoted by $\\nabla \\xi: \\mathbb{R}_{+}^{2} \\rightarrow \\mathbb{R}_{+}^{2}$ the function mapping $(x, y)$ to $(y, x)$ (in line with the idea that the relevant \"function $\\xi$ \" for the bipartite model is $(x, y) \\mapsto x y$ ), and $\\partial_{q} \\psi=\\left(\\partial_{q_{1}} \\psi, \\partial_{q_{2}} \\psi\\right)$. This guess provided by characteristics is actually really valid for short times, in the sense that it really gives us the value of the viscosity solution there. The problem is that for large times, these lines may start to intersect each other, and they do not agree on what they predict (and the viscosity solution may then take a value that is not even among those multiple options). One of the main results of [21] is that if one assumes that the enriched free energy $F_{N}: \\mathbb{R}_{+} \\times \\mathcal{Q}^{2} \\rightarrow \\mathbb{R}$ of the bipartite model converges to some limit function $f$, then there is always at least one characteristic line that prescribes the correct value for $f$. The only remaining source of ambiguity is that we are not able to say which of the characteristic lines is the correct one, in case multiple lines arrive at a given point. See also Figure 4.1 for an illustration.", "tables": {}, "images": {"img-3.jpeg": "data:image/jpeg;base64,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"}}, {"section_id": 10, "text": "# 5. Closing thoughts \n\nSpin glasses are models of statistical mechanics that are relatively simple to define. Yet, one aspect I find striking about them is that they display a very rich and interesting mathematical structure. Despite their apparent simplicity, they may give us some insight into the behavior of various \"complex\" systems across disciplines.\n\nI hope that this informal overview of the Parisi formula and of some related open questions has piqued your interest. I want to stress though that this is only one facet of the study of spin glasses, and there surely is something for everyone there! Books on spin glasses include $[15,17,18,20,24,25,29,47,58,59,61,74,77,78]$. The book [29] puts particular emphasis on the PDE point of view discussed here in Section 4 (and contains an overview of the research literature). For a multi-disciplinary perspective and applications of spin glasses to other areas, one can consult the recent book [20] on \"spin glass theory and far beyond\".", "tables": {}, "images": {}}, {"section_id": 11, "text": "# REFERENCES \n\n[1] Emmanuel Abbe. Community detection and stochastic block models: recent developments. J. Mach. Learn. Res., 18(1):6446-6531, 2017.\n[2] Elena Agliari, Adriano Barra, Raffaella Burioni, and Aldo Di Biasio. Notes on the p-spin glass studied via Hamilton-Jacobi and smooth-cavity techniques. J. Math. Phys., 53(6):063304, 29, 2012.\n[3] David Aldous. Asymptotics in the random assignment problem. Probab. Theory Related Fields, 93(4):507-534, 1992.\n[4] David J. Aldous. The $\\zeta(2)$ limit in the random assignment problem. Random Structures Algorithms, $18(4): 381-418,2001$.\n[5] Shun'ichi Amari. Learning patterns and pattern sequences by self-organizing nets of threshold elements. IEEE Transactions on computers, 100(11):1197-1206, 1972.\n[6] Daniel J. Amit, Hanoch Gutfreund, and Haim Sompolinsky. Spin-glass models of neural networks. Phys. Rev. A, 32(2):1007, 1985.\n[7] Daniel J. Amit, Hanoch Gutfreund, and Haim Sompolinsky. Statistical mechanics of neural networks near saturation. Annals of Physics, 173(1):30-67, 1987.\n[8] Sanjeev Arora, Eli Berger, Hazan Elad, Guy Kindler, and Muli Safra. On non-approximability for quadratic programs. In 46th Annual IEEE Symposium on Foundations of Computer Science (FOCS'05), pages 206-215. IEEE, 2005.\n[9] Adriano Barra, Alberto Bernacchia, Enrica Santucci, and Pierluigi Contucci. On the equivalence of Hopfield networks and Boltzmann machines. Neural Networks, 34:1-9, 2012.\n[10] Adriano Barra, Pierluigi Contucci, Emanuele Mingione, and Daniele Tantari. Multi-species mean field spin glasses. Rigorous results. Ann. Henri Poincar\u00e9, 16(3):691-708, 2015.\n[11] Adriano Barra, Gino Del Ferraro, and Daniele Tantari. Mean field spin glasses treated with PDE techniques. Eur. Phys. J. B, 86(7):Art. 332, 10, 2013.\n[12] Adriano Barra, Aldo Di Biasio, and Francesco Guerra. Replica symmetry breaking in mean-field spin glasses through the Hamilton-Jacobi technique. J. Stat. Mech. Theory Exp., (9):P09006, 22, 2010.\n[13] Adriano Barra, Giuseppe Genovese, Peter Sollich, and Daniele Tantari. Phase diagram of restricted Boltzmann machines and generalized Hopfield networks with arbitrary priors. Phys. Rev. E, $97(2): 022310,2018$.\n[14] Roland Bauerschmidt, Thierry Bodineau, and Benoit Dagallier. Stochastic dynamics and the Polchinski equation: an introduction. Preprint, arXiv:2307.07619, 2023.\n[15] Erwin Bolthausen and Anton Bovier, editors. Spin glasses, volume 1900 of Lecture Notes in Mathematics. Springer, Berlin, 2007.\n[16] St\u00e9phane Boucheron, G\u00e1bor Lugosi, and Pascal Massart. Concentration inequalities. Oxford University Press, Oxford, 2013.\n[17] Anton Bovier. Statistical mechanics of disordered systems: a mathematical perspective, volume 18 of Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, Cambridge, 2006.\n[18] Anton Bovier and Pierre Picco, editors. Mathematical aspects of spin glasses and neural networks, volume 41 of Progress in Probability. Birkh\u00e4user Boston, Inc., Boston, MA, 1998.\n[19] J. G. Brankov and V. A. Zagrebnov. On the description of the phase transition in the HusimiTemperley model. J. Phys. A, 16(10):2217-2224, 1983.\n[20] Patrick Charbonneau, Enzo Marinari, Marc M\u00e9zard, Giorgio Parisi, Federico Ricci-Tersenghi, Gabriele Sicuro, and Francesco Zamponi. Spin glass theory and far beyond. World Scientific, 2023.\n[21] Hong-Bin Chen and Jean-Christophe Mourrat. On the free energy of vector spin glasses with non-convex interactions. Probab. Math. Phys., to appear.\n[22] Hong-Bin Chen and Jiaming Xia. Hamilton-Jacobi equations from mean-field spin glasses. arXiv preprint arXiv:2201.12732, 2022.\n[23] Amin Coja-Oghlan. Phase transitions in discrete structures. In European Congress of Mathematics, pages 599-618. Eur. Math. Soc., Z\u00fcrich, 2018.\n[24] Pierluigi Contucci and Cristian Giardin\u00e0. Perspectives on spin glasses. Cambridge University Press, Cambridge, 2013.\n[25] Cirano De Dominicis and Irene Giardina. Random fields and spin glasses: a field theory approach. Cambridge University Press, New York, 2006.\n[26] Jian Ding, Allan Sly, and Nike Sun. Proof of the satisfiability conjecture for large k. In Proceedings of the forty-seventh annual ACM symposium on Theory of computing, pages 59-68, 2015.\n[27] Jian Ding, Allan Sly, and Nike Sun. Maximum independent sets on random regular graphs. Acta Math., 217(2):263-340, 2016.\n\n[28] Jian Ding, Allan Sly, and Nike Sun. Satisfiability threshold for random regular NAE-SAT. Comm. Math. Phys., 341(2):435-489, 2016.\n[29] Tomas Dominguez and Jean-Christophe Mourrat. Statistical mechanics of mean-field disordered systems: a Hamilton-Jacobi approach. Zurich Lectures in Advanced Mathematics. European Mathematical Society, Z\u00fcrich, 2024.\n[30] Ahmed El Alaoui, Andrea Montanari, and Mark Sellke. Optimization of mean-field spin glasses. Ann. Probab., 49(6):2922-2960, 2021.\n[31] David Gamarnik. The overlap gap property: a topological barrier to optimizing over random structures. Proc. Natl. Acad. Sci. USA, 118(41):e2108492118, 2021.\n[32] David Gamarnik and Aukosh Jagannath. The overlap gap property and approximate message passing algorithms for $p$-spin models. Ann. Probab., 49(1):180-205, 2021.\n[33] David Gamarnik, Cristopher Moore, and Lenka Zdeborov\u00e1. Disordered systems insights on computational hardness. J. Stat. Mech. Theory Exp., (11):Paper No. 114015, 41, 2022.\n[34] Andreas Greven, Peter Pfaffelhuber, and Anita Winter. Convergence in distribution of random metric measure spaces (A-coalescent measure trees). Probab. Theory Related Fields, 145(1-2):285-322, 2009.\n[35] Francesco Guerra. Sum rules for the free energy in the mean field spin glass model. Fields Institute Communications, 30(11), 2001.\n[36] Francesco Guerra. Broken replica symmetry bounds in the mean field spin glass model. Comm. Math. Phys., 233(1):1-12, 2003.\n[37] Geoffrey E. Hinton. A practical guide to training restricted Boltzmann machines. In Neural networks: Tricks of the trade, pages 599-619. Springer, 2012.\n[38] John J. Hopfield. Neural networks and physical systems with emergent collective computational abilities. Proc. Natl. Acad. Sci. USA, 79(8):2554-2558, 1982.\n[39] Brice Huang and Mark Sellke. Tight Lipschitz hardness for optimizing mean field spin glasses. In 2022 IEEE 63rd Annual Symposium on Foundations of Computer Science-FOCS 2022, pages 312-322. IEEE Computer Soc., Los Alamitos, CA, 2022.\n[40] David Jekel, Juspreet Singh Sandhu, and Jonathan Shi. Potential Hessian ascent: The SherringtonKirkpatrick model. Preprint, arXiv:2408.02360, 2024.\n[41] Florent Krzakala, Andrea Montanari, Federico Ricci-Tersenghi, Guilhem Semerjian, and Lenka Zdeborov\u00e1. Gibbs states and the set of solutions of random constraint satisfaction problems. Proc. Natl. Acad. Sci. USA, 104(25):10318-10323, 2007.\n[42] William A Little. The existence of persistent states in the brain. Mathematical biosciences, 19(12):101-120, 1974.\n[43] Marc M\u00e9zard and Andrea Montanari. Information, physics, and computation. Oxford Graduate Texts. Oxford University Press, Oxford, 2009.\n[44] Marc M\u00e9zard and Giorgio Parisi. A replica analysis of the travelling salesman problem. Journal de physique, 47(8):1285-1296, 1986.\n[45] Marc M\u00e9zard, Giorgio Parisi, Nicolas Sourlas, G\u00e9rard Toulouse, and Miguel Virasoro. Replica symmetry breaking and the nature of the spin glass phase. Journal de Physique, 45(5):843-854, 1984.\n[46] Marc M\u00e9zard, Giorgio Parisi, Nicolas Sourlas, G\u00e9rard Toulouse, and Miguel Virasoro. Nature of the spin-glass phase. Phys. Rev. Lett., 52(13):1156, 1984.\n[47] Marc M\u00e9zard, Giorgio Parisi, and Miguel Virasoro. Spin glass theory and beyond, volume 9 of World Scientific Lecture Notes in Physics. World Scientific Publishing Co., Inc., Teaneck, NJ, 1987.\n[48] Marc M\u00e9zard, Giorgio Parisi, and Riccardo Zecchina. Analytic and algorithmic solution of random satisfiability problems. Science, 297(5582):812-815, 2002.\n[49] R\u00e9mi Monasson, Riccardo Zecchina, Scott Kirkpatrick, Bart Selman, and Lidror Troyansky. Determining computational complexity from characteristic 'phase transitions'. Nature, 400(6740):133-137, 1999.\n[50] Andrea Montanari. Optimization of the Sherrington-Kirkpatrick Hamiltonian. SIAM Journal on Computing, (0):FOCS19-1, 2021.\n[51] Jean-Christophe Mourrat. Nonconvex interactions in mean-field spin glasses. Probab. Math. Phys., 2(2):281-339, 2021.\n[52] Jean-Christophe Mourrat. The Parisi formula is a Hamilton-Jacobi equation in Wasserstein space. Canad. J. Math., 74(3):607-629, 2022.\n[53] Jean-Christophe Mourrat. Free energy upper bound for mean-field vector spin glasses. Ann. Inst. Henri Poincar\u00e9 Probab. Stat., 59(3):1143-1182, 2023.\n[54] Jean-Christophe Mourrat. Un-inverting the Parisi formula. Ann. Inst. H. Poincar\u00e9 Probab. Statist., to appear.\n\n[55] Jean-Christophe Mourrat and Dmitry Panchenko. Extending the Parisi formula along a HamiltonJacobi equation. Electron. J. Probab., 25:Paper No. 23, 17, 2020.\n[56] Roberto Mulet, Andrea Pagnani, Martin Weigt, and Riccardo Zecchina. Coloring random graphs. Phys. Rev. Lett., 89(26):268701, 2002.\n[57] Charles Newman. Percolation theory: A selective survey of rigorous results. In Advances in multiphase flow and related problems. SIAM, 1986.\n[58] Hidetoshi Nishimori. Statistical physics of spin glasses and information processing, volume 111 of International Series of Monographs on Physics. Oxford University Press, New York, 2001.\n[59] Manfred Opper and David Saad, editors. Advanced mean field methods. Neural Information Processing Series. MIT Press, Cambridge, MA, 2001.\n[60] Dmitry Panchenko. The Parisi ultrametricity conjecture. Ann. of Math. (2), 177(1):383-393, 2013.\n[61] Dmitry Panchenko. The Sherrington-Kirkpatrick model. Springer Monographs in Mathematics. Springer, New York, 2013.\n[62] Dmitry Panchenko. The free energy in a multi-species Sherrington-Kirkpatrick model. Ann. Probab., 43(6):3494-3513, 2015.\n[63] Dmitry Panchenko. Free energy in the Potts spin glass. Ann. Probab., 46(2):829-864, 2018.\n[64] Dmitry Panchenko. Free energy in the mixed p-spin models with vector spins. Ann. Probab., 46(2):865896, 2018.\n[65] Giorgio Parisi. Infinite number of order parameters for spin-glasses. Phys. Rev. Lett., 43(23):1754, 1979.\n[66] Giorgio Parisi. The order parameter for spin glasses: a function on the interval 0-1. J. Phys. A, 13(3):1101, 1980.\n[67] Giorgio Parisi. A sequence of approximated solutions to the S-K model for spin glasses. J. Phys. A, 13(4):L115-L121, 1980.\n[68] Giorgio Parisi. Order parameter for spin-glasses. Phys. Rev. Lett., 50(24):1946, 1983.\n[69] Giorgio Parisi. Nobel lecture: Multiple equilibria. Reviews of Modern Physics, 95(3):030501, 2023.\n[70] Tom Richardson and Ruediger Urbanke. Modern coding theory. Cambridge university press, 2008.\n[71] Mark Sellke. Optimizing mean field spin glasses with external field. Electron. J. Probab., 29:Paper No. 4, 47, 2024.\n[72] David Sherrington and Scott Kirkpatrick. Solvable model of a spin-glass. Phys. Rev. Lett., 35(26):1792, 1975.\n[73] Paul Smolensky. Information processing in dynamical systems: foundations of harmony theory. In Parallel distributed processing: explorations in the microstructure of cognition, volume 1, pages 194-281. MIT Press, 1986.\n[74] Daniel L. Stein and Charles M. Newman. Spin glasses and complexity. Primers in Complex Systems. Princeton University Press, Princeton, NJ, 2013.\n[75] Eliran Subag. Following the ground states of full-RSB spherical spin glasses. Comm. Pure Appl. Math., 74(5):1021-1044, 2021.\n[76] Michel Talagrand. The Parisi formula. Ann. of Math. (2), 163(1):221-263, 2006.\n[77] Michel Talagrand. Mean field models for spin glasses. Volume I, volume 54 of Ergebnisse der Mathematik und ihrer Grenzgebiete. Springer-Verlag, Berlin, 2011.\n[78] Michel Talagrand. Mean field models for spin glasses. Volume II, volume 55 of Ergebnisse der Mathematik und ihrer Grenzgebiete. Springer, Heidelberg, 2011.\n[79] J\u00e9r\u00f4me Tubiana. Restricted Boltzmann machines: from compositional representations to protein sequence analysis. PhD thesis, Universit\u00e9 Paris Sciences et Lettres, 2018.\n[80] J\u00e9r\u00f4me Tubiana and R\u00e9mi Monasson. Emergence of compositional representations in restricted boltzmann machines. Phys. Rev. Lett., 118(13):138301, 2017.\n[81] Lenka Zdeborov\u00e1 and Florent Krzakala. Statistical physics of inference: Thresholds and algorithms. Advances in Physics, 65(5):453-552, 2016.", "tables": {}, "images": {}}], "id": "2410.12364v2", "authors": ["Jean-Christophe Mourrat"], "categories": ["math.PR", "cond-mat.dis-nn", "math-ph", "math.MP"], "abstract": "This note is an informal presentation of spin glasses and of the Parisi\nformula. We also discuss some models for which the Parisi formula is not\nwell-understood, and some partial progress that relies upon a connection with\npartial differential equations.", "updated": "2025-04-04T13:25:15Z", "published": "2024-10-16T08:29:47Z"}