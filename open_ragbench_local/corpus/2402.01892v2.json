{"title": "Censored Beliefs and Wishful Thinking", "sections": [{"section_id": 0, "text": "#### Abstract\n\nWe present a model elucidating wishful thinking, which comprehensively incorporates both the costs and benefits associated with biased beliefs. Our findings reveal that wishful thinking behavior can be characterized as equivalent to superquantile-utility maximization within the domain of threshold beliefs distortion cost functions. By leveraging this equivalence, we establish WT as driving decision-makers to exhibit a preference for choices characterized by skewness and increased risk. Furthermore, we discuss how our framework facilitates the study of optimistic stochastic choice and optimistic risk aversion.\n\n\nJEL classification: D01, D80, D84\nKeywords: wishful thinking, risk, optimism, quantile maximization, preference for skewness\n\n[^0]\n[^0]:    Date: January 29, 2025.\n    Department of Economics, Indiana University, Bloomington, IN 47408, USA. Email: \\{jburgh,emelo\\}@iu.edu. We are very grateful to Duarte Goncalves, Marco Acosta, Jack Berger, Collin Raymond, Ben Bushong, and participants at SAET 2023 and Georgia-Tech MWET 2023, for their valuable comments and suggestions that have greatly improved the paper. This paper, previously circulated under the title \"Wishful Thinking is Risky Thinking: A Statistical-Distance Based Approach,\" has been divided into two separate and complementary works: \"Wishful Thinking is Risky Thinking\" and \"Censored Beliefs and Wishful Thinking.\" Emerson Melo thanks the funding provided by the Institute for Advanced Studies (IAS) at Indiana University-Bloomington through the \"Recently Tenured Working Group\" internal grant.", "tables": {}, "images": {}}, {"section_id": 1, "text": "# 1. InTRODUCTION \n\nWishful thinking (WT) behavior refers to the inclination to overestimate the probability of favorable events while underestimating the likelihood of unfavorable events (Aue et al. [2012]).\n\nThere is substantial evidence of WT behavior in economic decision-making, with studies spanning various domains to illustrate this phenomenon. For instance, Oster et al. [2013] demonstrate how individuals at risk for Huntington's disease display optimism by deciding not to undergo genetic testing for early detection. This decision reflects a form of optimistic bias, where individuals may avoid information that could potentially challenge their desired outcomes or beliefs. Similarly, Engelmann et al. [Forthcoming] provides evidence that people engage in WT to alleviate anxiety about adverse future outcomes. Orhun et al. [2021] analyze beliefs about the risks of returning to work during a pandemic, and Seaward and Kemp [2000] investigate WT behavior concerning the repayment time for student loan debt.\n\nIn the context of markets, Grubb [2015] and Stone and Wood [2018] provide theoretical and empirical evidence of consumer and firm over-optimism, respectively. Malmendier and Tate [2015] offer insights into CEOs' overconfidence, while Daniel and Hirshleifer [2015] discuss WT's role in explaining investors' optimistic behavior in financial markets. Furthermore, Lovallo and Kahneman [2003] delve into the optimistic tendencies and overconfidence of business executives and entrepreneurs in their decision-making processes. ${ }^{1}$ Works such as Taylor [1991] and Baumeister et al. [2001] study the tendency to focus on bad outcomes and ignore good outcomes. However, works in psychology have provided robust foundations and explanations for the prevalence of optimistic biases. In fact, Korn et al. [2014] find that it is primarily depressed subjects who seem to follow objective probabilities, while most psychologically \"healthy\" individuals display some degree of optimism and biased updating. As such, similar mechanisms that push pessimists to ignore good outcomes likewise push optimists to downplay bad outcomes in their analysis. A recurrent theme throughout the literature is the fact that the relevance of optimism vs. pessimism is both individual-specific (Hecht [2013]) and context-specific (Menon et al. [2009]). ${ }^{2}$\n\n[^0]\n[^0]:    ${ }^{1}$ B\u00e9nabou and Tirole [2016] provide an in-depth summary of the evidence regarding optimism in economic decisions.\n    ${ }^{2}$ With this in mind, we note that our analysis is easily extended to a pessimistic environment, and this may prove a fruitful direction for future research\n\nIn this paper, we develop a model of WT that considers both the benefits and costs associated with biased beliefs and optimistic behavior. Drawing on the framework established by Bracha and Brown [2012] and Caplin and Leahy [2019], we study a two-stage model where a decision-maker (DM) confronts uncertainty about future events and makes choices involving actions and belief structures. By actively selecting their beliefs, the DM aims to maximize her subjective expected utility (SEU) for a given alternative, considering the cost of deviating from prior beliefs. To quantify this cost, we introduce the threshold beliefs distortion cost function, which penalizes deviations from prior beliefs in a binary fashion. Formally, our cost function is a convex (not strictly convex) non-smooth statistical distance (in the sense of Csiszar [1967]) between the prior and subjective beliefs. ${ }^{3}$\n\nWe make multiple contributions to the literature on WT. First, our model uncovers a connection between WT behavior and the notion of superquantile optimization (Rockafellar and Uryasev [2000], Rockafellar and Uryasev [2002], and Rockafellar and Royset [2014]). Intuitively, the superquantile of a random variable corresponds to the average of the top $(1-\\alpha) 100 \\%$ outcomes, where $\\alpha$ is a parameter between 0 and 1 . Furthermore, this connection can be used to analyze median WT behavior, i.e., $\\alpha=0.5$, the traditional expected utility case, $\\alpha=0$, and extreme optimism with $\\alpha=1$, a situation where the DM only looks at the highest utility level of each alternative. Accordingly, we interpret $\\alpha$ as the degree of optimism.\n\nOur analysis reveals that an optimistic DM focuses on the upper tail of utility outcomes associated with each alternative. Subsequently, the DM selects the option with the highest superquantile. As a result, an optimistic DM concentrates solely on favorable outcomes, which are those in the upper tail of the distribution of utility realizations for a given alternative. The critical driver behind this result is that optimism distorts the belief distribution by placing additional weight on the probability of good outcomes by reassigning weight from undesirable outcomes, a concept we refer to as censorship. Notably, we will demonstrate that this subjective probability assigns undesirable states probability zero.\n\nThis finding establishes a formal connection between WT and models of quantile-utility maximization, such as those found in Chambers [2009], Manski [1988], de Castro and Galvao [2019, 2022], and Rostek [2010]. However, our approach differs from this literature in two key aspects. First, the connection\n\n[^0]\n[^0]:    ${ }^{3}$ Burgh and Melo [2024] study a model similar to the one studied in this paper, but with a belief distortion cost which is assumed to be strictly convex and twice differentiable.\n\nbetween WT and quantile-utility maximization arises as a consequence of distorted beliefs due to optimism and not as a consequence of the primitives (or axioms) of the model. Second, our analysis demonstrates that an optimistic DM is not solely concerned with the utility associated with a specific quantile but also the conditional average utility related to the upper tail defined by the specific quantile. In other words, our analysis accounts for low-probability large-utility tail events, while the quantile approach does not account for this information. It is important to note that, as decision criteria, quantile preferences and our superquantile approach do not necessarily generate the same predictions.\n\nIn our second contribution, we leverage the connection between superquantileutility maximization and WT behavior to shed light on DM's preference for skewness. Specifically, when the utility of different alternatives follows a Pareto distribution, we demonstrate that the optimal choice of a WT agent depends on the shape of the right tail or degree of positive skewness. The shape parameter, which determines the tail behavior, is crucial in determining the DM's optimal action.\n\nOur third contribution is the development of an optimistic stochastic choice framework. Superquantiles have a monotonicity property that extends naturally to a notion of monotone stochastic choice. We achieve this by making use of results from Apesteguia and Ballester [2018]. The monotonicity of stochastic choice probabilities in the degree of optimism provides testable implications for changes in DM's optimism levels.\n\nFinally, we present an application of WT in a market entry decision. We explore how the shape of potential profit realization influences an optimistic entrepreneur's choice to enter a market. Moreover, noting that both risk aversion and optimism play a role in entrepreneurial endeavors (\u00c5stebro et al. [2014]), we demonstrate a choice criterion that accounts for both optimism and risk aversion.\n1.1. Related Literature. Our paper is situated within several strands of literature. Primarily, it aligns with the literature on WT and motivated reasoning within economic decision-making, as discussed by B\u00e9nabou and Tirole [2016]. Notably, our work shares similarities with the studies by Bracha and Brown [2012], Caplin and Leahy [2019], and Burgh and Melo [2024]. These papers explore decision-making models where a DM selects a probability distribution over states to maximize the difference between SEU and the cost of distorting beliefs. Caplin and Leahy [2019] focus on a cost function proportional to the Kullback-Leibler distance between subjective and prior beliefs,\n\nwhile Burgh and Melo [2024] concentrate on strictly convex twice-differentiable cost functions, where the Kullback-Leibler divergence is a particular instance. Bracha and Brown [2012] focus on general convex and smooth cost functions.\n\nThe paper at hand introduces the threshold beliefs distortion cost function, distinct for not assuming strict convexity or smoothness as seen in Bracha and Brown [2012], Caplin and Leahy [2019], and Burgh and Melo [2024]. We leverage our cost function to establish the equivalence between WT behavior and superquantile optimization. Another crucial distinction between these results and those at hand is a formal connection between WT behavior and a preference for positive skewness. Notably, neither the superquantile connection nor the preference for skewness result can be derived from the findings of Bracha and Brown [2012], Caplin and Leahy [2019], Burgh and Melo [2024].\n\nIn a distinct line of work, the papers by Mayraz [2019] and Kovach [2020] offer an axiomatic foundation for WT behavior. These papers contribute to understanding WT behavior through the lens of behavioral axioms. However, it is essential to highlight that neither of these papers incorporates the cost associated with belief distortion into their respective frameworks. Bracha and Brown [2012] presents an axiomatic foundation for WT behavior that incorporates this cost by amending the axiomatic characterization of variational preferences in Maccheroni et al. [2006].\n\nSecondly, our research contributes to the literature on optimal expectations, specifically referring to the work of Brunnermeier and Parker [2005]. Their study focuses on a dynamic model of belief choice, albeit without including the cost associated with maintaining optimistic beliefs. In contrast to our approach, the model of Brunnermeier and Parker [2005] explores the dynamics of belief choice in generating a preference for skewness in a portfolio allocation problem. It is crucial to highlight that our model's preference for skewness results does not imply their result, and vice versa. This distinction arises from fundamental differences in the nature and structure of the two models, emphasizing the unique contributions of each to the understanding of optimal expectations. ${ }^{4}$\n\nFinally, our paper is also related to the literature on robustness in economic models. Specifically, Hansen and Sargent [2001, 2008] introduce the idea of robust optimization to address the concern of model misspecification. They adopt a max-min approach, akin to multiple priors models as in Gilboa and\n\n[^0]\n[^0]:    ${ }^{4}$ For an empirical test of optimal expectation models, we refer the reader to Oster et al. [2013].\n\nSchmeidler [1989] and Maccheroni et al. [2006], to make decisions under ambiguity. While robustness and ambiguity models typically take a pessimistic approach to decision-making, our paper focuses on WT behavior and adopts an optimistic approach by studying a max-max problem. By doing so, our paper draws on the active and rapidly growing literature on distributionally robust optimization problems (Shapiro [2017] and Kuhn et al. [2019]). We leverage this mathematical framework to model WT behavior and derive its implications for economic decision-making. Thus, while our paper is related to the robustness literature, it differs in terms of its focus on WT, adopting an optimistic approach, and using distributionally robust optimization techniques.\n\nThe remainder of the paper is structured as follows: in Section 2, we introduce the model and characterize optimal beliefs. Section 3 explores the connection between WT behavior and superquantiles and discusses the relationship and distinctions with the quantile utility maximization approach. Section 4 delves into the connection between WT behavior and positive skewness. Section 5 provides the concluding remarks.", "tables": {}, "images": {}}, {"section_id": 2, "text": "# 2. The Model \n\nIn this section, we develop a WT model that incorporates the benefits and costs of distorted beliefs. As the introduction section mentioned, we build upon Bracha and Brown [2012] and Caplin and Leahy [2019]'s framework. In particular, we follow their idea that the DM maximizes her current subjective expected utility, which incorporates utility from current experience (assumed zero) and utility from the DM's anticipated future realization. This relies on the view that an agent's subjective utility depends on beliefs regarding future outcomes.\n\nFormally, we consider an environment where the DM is confronted with the task of selecting an action $a$ from a set $A=\\left\\{a_{1}, \\ldots, a_{n}\\right\\}$ in the presence of uncertainty regarding a utility-relevant state $\\omega \\in \\Omega$. We assume that $\\Omega \\subseteq \\mathbb{R}^{n}$ is a continuous set of states. Accordingly $\\omega$ is a $n$-dimensional vector. The DM's utility function is defined as $u: A \\times \\Omega \\longrightarrow \\mathbb{R}$, which assigns a real-valued number to each pair consisting of an action and a state. The DM is endowed with an exogenous prior belief $F$, representing a probability distribution over $\\Omega$. We assume that $F$ has a well-defined density denoted by $f$. The prior belief $F$ can represent an objective likelihood of a state occurring, a datadriven probability based on similar (or previous) experiences, or the beliefs\n\nof an expert. For each $a \\in A, \\mathbb{E}_{F}(u(a, \\omega))$ denotes the (objective) expected utility. It is assumed that $\\mathbb{E}_{F}(|u(a, \\omega)|)<\\infty$ for all $a \\in A$.\n\nThe DM forms a subjective belief represented by the probability distribution $G$ over $\\Omega$. Intuitively, $G$ can be interpreted as a distortion of $F .{ }^{5}$ Accordingly, the subjective expected utility (SEU) of alternative $a \\in A$ for the DM is given by $\\mathbb{E}_{G}(u(a, \\omega))$. This expected payoff makes explicit that the DM uses her subjective beliefs $G$ to evaluate utility-maximizing actions.\n\nFollowing Bracha and Brown [2012] and Caplin and Leahy [2019], deviating from $F$ induces a cost for the DM. This cost reflects the DM's taste for accuracy and reflects a cognitive cost of distorting holding beliefs away from priors. These can reflect the internal cost of processing information (Trimmer [2016]) or future material costs of behavior under inaccurate beliefs (Akerlof and Dickens [1982]). We introduce a novel belief distortion cost function, highlighting that large distortions from reality are highly costly. Formally, we model the cost of belief distortion $C_{\\alpha}(G \\| F)$ by leveraging the concept of $\\phi$-divergence between the subjective belief $G$ and the prior $F$. For a given convex function $\\phi$, Csiszar [1967] defines the $\\phi$ divergence as $C(G \\| F)=\\int_{\\Omega} f(\\omega) \\phi(g(\\omega) / f(\\omega)) d \\omega$. This cost $C(G \\| F)$ captures a notion of statistical distance between subjective and prior beliefs. ${ }^{6}$\n\nAccordingly, given the cost $C_{\\alpha}(G \\| F)$, the WT agent chooses an optimal pair $\\left(a^{\\star}, G^{\\star}\\right)$ that maximizes:\n\n$$\n\\max _{a \\in A} \\max _{G \\in \\mathcal{M}(F)}\\left\\{\\mathbb{E}_{G}(u(a, \\omega))-\\delta C_{\\alpha}(G \\| F)\\right\\}\n$$\n\nwhere $\\mathcal{M}(F)$ is a set of absolutely continuous distributions with respect to $F$.\n\nThe infinite-dimensional problem (1) presents a framework in which the agent simultaneously chooses both an action and a belief structure. From a behavioral standpoint, this framework considers the subjective beliefs to be contingent on the chosen action. In other words, the DM assigns a specific belief structure to each possible action, allowing for the possibility of holding seemingly contradictory beliefs. This notion of beliefs being action-contingent resembles the concept of cognitive dissonance, as discussed in Akerlof and\n\n[^0]\n[^0]:    ${ }^{5}$ As we shall see, in general the subjective belief $G$ will depend in the optimal action $a \\in A$.\n    ${ }^{6}$ Burgh and Melo [2024] study a WT model focusing on the class of strictly increasing, strictly convex, and smooth $\\phi$-divergence functions. All of these properties are violated by the $\\phi$ function defined in (2). However, as we shall see, none of those assumptions are required in our analysis.\n\nDickens [1982] and relates to situations where agents may hold contradictory beliefs.\n\nIt is worth pointing out that our way of modeling WT behavior is closely connected to motivated reasoning, as discussed in studies such as Kunda [1990] and B\u00e9nabou and Tirole [2016]. According to this theory, when choosing their optimal beliefs, a motivated DM is driven by the $\\operatorname{SEU} \\mathbb{E}_{G}(u(a, \\omega))$, representing the anticipated utility associated with different actions and outcomes. However, in addition to the utility, a motivated DM also considers the importance of accuracy. This latter aspect is captured by our cost function $C_{\\alpha}(G \\| F)$. Thus, our model incorporates the motivational aspect of maximizing SEU and considering accuracy in belief choice.\n\nNow, we turn our attention to modeling the cost $C_{\\alpha}(G \\| F)$. In this regard, we specifically focus on the following $\\phi$-divergence function:\n\n$$\n\\phi(t)= \\begin{cases}0, & 0 \\leq t \\leq \\frac{1}{1-\\alpha} \\\\ +\\infty & \\text { otherwise }\\end{cases}\n$$\n\nwith $\\alpha \\in(0,1)$.\nUsing $\\phi$-function (2), we define $C_{\\alpha}(G \\| F)$ as the corresponding $\\phi$ divergence between G and F . This yields a cost of distorting beliefs about state $\\omega$ such that the cost is zero whenever the ratio $g(\\omega) / f(\\omega)$ is between 0 and $(1-\\alpha)^{-1}$. Conversely, if $g(\\omega) / f(\\omega)$ lies outside this range, then $C_{\\alpha}(G \\| F)=$ $+\\infty$. Formally, (2) induces the cost of belief distortion:\n\n$$\nC_{\\alpha}(G \\| F)= \\begin{cases}0, & 0 \\leq \\frac{g(\\omega)}{f(\\omega)} \\leq \\frac{1}{1-\\alpha}, \\forall \\omega \\in \\Omega \\\\ +\\infty & \\text { otherwise }\\end{cases}\n$$\n\nwith $\\alpha \\in(0,1)$.\nThe cost function (5) models a situation where the DM is allowed to pick any probability distribution $G$ as long as the likelihood ratio $g(\\omega) / f(\\omega)$ is in the range of 0 and $(1-\\alpha)^{-1}$. Similar to Akerlof and Dickens [1982], our cost function captures the role of cognitive dissonance in the decision-making process.\n\nGiven the structure of (5), we refer to $C_{\\alpha}(G \\| F)$ as the threshold beliefs distortion cost induced by $\\phi$-divergence function (2). We note that the parameter $\\alpha$ is key in defining $\\phi$ and $C_{\\alpha}(G \\| F)$, respectively. In fact, as we will see, $\\alpha$ captures the DM's degree of optimism.\n\nThe simplicity of the cost (5) allows us to express the inner maximization problem in (1) in an alternative and more tractable way.\n\nProposition 1. Let $V_{\\alpha}(a) \\triangleq \\max _{G \\in \\mathcal{M}(F)}\\left\\{\\mathbb{E}_{G}(u(a, \\omega))-C_{\\alpha}(G\\|F)\\right\\}$ for all $a \\in A$. Then, the following holds:\n\n$$\nV_{\\alpha}(a)=\\min _{\\lambda_{a} \\in \\mathbb{R}}\\left\\{\\lambda_{a}+\\frac{1}{1-\\alpha} \\mathbb{E}_{F}\\left(\\max \\left\\{u(a, \\omega)-\\lambda_{a}, 0\\right\\}\\right)\\right\\}\n$$\n\nProof. All proofs are collected in the appendix\nThe previous proposition establishes that the infinite-dimensional problem of finding an optimal belief $G$ can be equivalently expressed as a simpler onedimensional optimization program. This equivalence dramatically simplifies the analysis of (1) because the problem (1) can be expressed only in terms of the prior distribution $F$. More importantly, the equivalence (4) allows us to express our WT model in terms of a superquantile optimization problem (Rockafellar and Uryasev [2000], Rockafellar and Uryasev [2002], and Rockafellar and Royset [2014]). We will exploit this fact to show how a WT agent will look at the upper quantiles of the outcome distribution censoring other sections of the distribution associated with less desirable outcomes. In addition, we will use (4) to characterize optimistic decision-making in terms of risk and skewness.\n\nFinally, we note that the Proposition 1 follows from a direct application of Lemma 1 in Burgh and Melo [2024]. Furthermore, leveraging their Proposition 2 , we can interpret $V_{\\alpha}$ as a risk measure. From a behavioral standpoint, this fact implies that WT agents behave as risk seekers. ${ }^{7}$", "tables": {}, "images": {}}, {"section_id": 3, "text": "# 3. Optimal Choice and Superquantile MAximization \n\nIn this section, we show that WT behavior corresponds to superquantileutility maximization and preference for skewness.\n\nRecall that the prior distribution over states is given by $F$ with density function $f$. For each $a \\in A$, we define a cumulative distribution function of the utility $u(a, \\omega)$ it yields. Define the distribution corresponding with action $a$ as:\n\n$$\nF_{a}(z) \\triangleq \\mathbb{P}(\\{\\omega \\in \\Omega: u(a, \\omega) \\leq z\\})\n$$\n\n[^0]\n[^0]:    ${ }^{7}$ In particular, we note that in the portfolio optimization literature, $V_{\\alpha}$ is known as conditional value-at-risk (CVaR) (Rockafellar and Uryasev [2000]).\n\nWe assume that $F_{a}(z)$ is strictly increasing and continuous on the interior of its domain. We make this assumption for the sake of simplicity. ${ }^{8}$ We now introduce the familiar notion of quantile.\n\nDefinition 1. For $a \\in A$, the $\\alpha$-quantile of the random variable $u(a, \\omega)$ is given by:\n\n$$\nQ_{\\alpha}(a) \\triangleq \\min \\left\\{z \\in \\mathbb{R} \\mid F_{a}(z) \\geqslant \\alpha\\right\\}, \\alpha \\in(0,1)\n$$\n\nIn the preceding definition, note that the assumption stipulating $F_{a}(z)$ as strictly increasing and continuous on the interior of its domain implies that the quantile $Q_{\\alpha}(a)$ is uniquely defined.\n\nNext, we introduce the concept of superquantile as follows:\nDefinition 2 (Rockafellar and Royset [2014]). For $a \\in A$, the $\\alpha$-superquantile of the random variable $u(a, \\omega)$ is given by:\n\n$$\n\\bar{Q}_{\\alpha}(a) \\triangleq Q_{\\alpha}(a)+\\frac{1}{1-\\alpha} \\mathbb{E}_{F}\\left(\\max \\left\\{u(a, \\omega)-Q_{\\alpha}(a), 0\\right\\}\\right) \\quad \\alpha \\in(0,1)\n$$\n\nwhere $Q_{\\alpha}(a)$ is the $\\alpha$-quantile defined in (5).\nIntuitively, the notion of $\\alpha$-superquantile corresponds to the average of outcomes beyond the specified $\\alpha$-quantile $Q_{\\alpha}(a)$. As such, we also can make use of equivalent definitions of the superquantile throughout the paper:\n\n$$\n\\bar{Q}_{\\alpha}(a)=\\frac{1}{1-\\alpha} \\int_{\\alpha}^{1} Q_{\\theta}(a) d \\theta=\\frac{1}{1-\\alpha} \\int_{\\left\\{\\omega \\in \\Omega: u(a, \\omega) \\geq Q_{\\alpha}(a)\\right\\}} f(\\omega) u(a, \\omega) d \\omega\n$$\n\nWith Definitions 1 and 2 in place, we are ready to establish the main result of this section.\n\nProposition 2. Consider the WT problem (1) with $C_{\\alpha}(G \\| F)$ given by threshold beliefs distortion cost function (5). Then, for $\\alpha \\in(0,1)$ an optimal solution pair $\\left(a^{\\star}, G_{a^{\\star}}^{\\star}\\right)$ satisfies the following:\n(i) The optimal $\\lambda_{a^{\\star}}^{\\star}$ in (4) satisfies $\\lambda_{a^{\\star}}^{\\star}=Q_{\\alpha}\\left(a^{\\star}\\right)$.\n(ii) $V_{\\alpha}\\left(a^{\\star}\\right)=\\bar{Q}_{\\alpha}\\left(a^{\\star}\\right)$\n(iii) $a^{\\star}$ satisfies:\n\n$$\na^{\\star}=\\arg \\max _{a \\in A}\\left\\{\\mathbb{E}_{F}(u(a, \\omega) \\mid u(a, \\omega) \\geq Q_{\\alpha}(a))\\right\\}\n$$\n\nwhere $\\bar{Q}_{\\alpha}(a)=\\mathbb{E}_{F}(u(a, \\omega) \\mid u(a, \\omega) \\geq Q_{\\alpha}(a))\\}$ for all $a \\in A$.\n\n[^0]\n[^0]:    ${ }^{8}$ Our results naturally extend to the case where $F_{a}(z)$ is not strictly increasing and to the case where atoms are allowed.\n\n(iv) The distorted belief $G_{\\alpha}\\left(a^{\\star}\\right)$ corresponds to:\n\n$$\nG_{\\alpha}\\left(a^{\\star}, \\omega\\right) \\triangleq \\begin{cases}\\frac{F_{a^{\\star}}(\\omega)-\\alpha}{1-\\alpha} & \\text { if } u\\left(a^{\\star}, \\omega\\right) \\geq Q_{\\alpha}\\left(a^{\\star}\\right) \\\\ 0 & \\text { if } u\\left(a^{\\star}, \\omega\\right)<Q_{\\alpha}\\left(a^{\\star}\\right)\\end{cases}\n$$\n\nThe previous proposition fully characterizes WT behavior in terms of $u(a, \\omega)$, $Q_{\\alpha}(a)$, and $\\bar{Q}_{\\alpha}(a)$. Parts (i) and (ii) establish that the optimal $\\lambda_{a^{\\star}}^{\\star}$ corresponds to the $\\alpha$-quantile, and $V_{\\alpha}(a)$ is the $\\alpha$-superquantile, respectively. These two facts allow us to formalize the observation that, in our model, WT behavior is tailored around a specific segment of the prior distribution $F$. This behavioral implication is captured in part (iii), which establishes that the WT problem boils down to selecting the action with the highest $\\alpha$-superquantile, as measured by $\\mathbb{E}_{F}\\left(u(a, \\omega) \\mid u(a, \\omega) \\geq Q_{\\alpha}(a)\\right)$. This implies that a WT agent focuses exclusively on the upper quantiles of the distribution associated with each random variable $u(a, \\omega)$. Thus the DM censors the bottom portion of the distribution of $u(a, \\omega)$. Consequently, the DM faces a cognitive bias that leads her to rely on a truncated distribution, effectively disregarding outcomes below the $\\alpha$-quantile $Q_{\\alpha}\\left(a^{\\star}\\right)$. As a result, WT behavior implies that the DM concentrates exclusively on the tail segment and chooses the action with the highest expected upper-tail utility. Truncated subjective beliefs are noted as an explanation for the entrepreneurial puzzle by Deligonul et al. [2008]. ${ }^{9}$\n\nTo our knowledge, Proposition 2(iv) constitutes the first formalization of this type of censored belief cognitive bias in economic behavior. ${ }^{10}$ Moreover, this characterization formalizes the connection between WT behavior and the notion of a preference for skewness. This preference becomes evident when examining the expression in part (iii), which captures the behavior of a WT agent favoring alternatives with high utility levels even if they have a low probability of occurrence. The DM overemphasizes these high payoff outcomes, focusing on expected upper-tail utility, while parameter $\\alpha$ determines how much extra weight is placed on the tails. In other words, Proposition 2(iii)(iv) elucidates the decision-maker's inclination towards skewness by explicitly addressing considerations regarding tail performance comparisons. In Section 4 , we further discuss this result, providing closed-form expressions that assist\n\n[^0]\n[^0]:    ${ }^{9}$ Here, the entrepreneurial puzzle refers to observations of entrepreneurial activity in situations where risk-return levels are significantly lower than those of private and public equity indexes\n    ${ }^{10}$ It is worth noting that in a different setting, Benabou [2013] examines a model where a decision-maker censors bad states, inducing optimistic behavior. Our characterization differs from his in that we consider both the benefits and costs of holding optimistic beliefs.\n\nin understanding WT behavior in terms of tail distributions and a preference for skewness.\n\nIt is worth pointing out Proposition 2 establishes that WT behavior is intimately related to quantile-utility maximization (Chambers [2009], de Castro and Galvao [2019, 2022], Rostek [2010], and Manski [1988]). However, unlike quantile preference models, the result in Proposition 2 indicates that an optimistic DM considers not only the utility at the quantile level but also the average expected tail utility associated with it. More importantly, the characterization in Proposition 2 makes transparent the fact that WT behavior leads a DM to consider a distorted belief distribution over the set of states. Furthermore, quantiles and superquantiles models do not necessarily agree on the prescribed optimal solutions. The following example, based on Royset [2023] illustrates this point.\n\nExample 1. Let $A=\\{-1,1\\}$. Assume that $\\omega$ follows a triangular distribution in $[0,2]$ with mode at 0 The utility associated with each alternative a is given by $u(a, \\omega)=(\\omega-2 / 3) a-1 / 3$. Using the distributional assumption on it is easy to see that $\\mathbb{E}_{F}(u(1, \\omega))=\\mathbb{E}_{F}(u(-1, \\omega))=-1 / 3$. Now, if we use a quantile utility-maximization approach, we get $Q_{0.8}(1)=0.106$ and $Q_{0.8}(-1)=$ 0.122. According to this approach, the alternative $a=-1$ is selected. Now, we can compute $\\bar{Q}_{0.8}(1)=0.404$ and $\\bar{Q}_{0.8}(-1)=0.230$. Using the superquantile criterion, the decision is reversed, implying that a DM will choose $a=1$. The reason for this reversal comes from the fact that the quantile approach ignores the magnitude of outcomes above $Q_{0.8}(1)$ and $Q_{0.8}(-1)$ and thus fails to reflect the difference of the average utility levels beyond the 0.80 -quantile.\n\nFrom a behavioral perspective, Proposition 2 underscores the significance of $\\alpha$ in reflecting the DM's degree of optimism. Specifically, $\\alpha$ represents the weight assigned by the DM to events in the upper tail of the distribution. More critically, $\\alpha$ can be interpreted as the degree of selectivity or \"censorship\" exercised by the DM when evaluating and choosing between alternatives. The following result formalizes the relationship between $\\alpha$ and the behavior of $V_{\\alpha}(a)$.\n\nCorollary 1. Consider the WT problem (1) with $C_{\\alpha}(G \\| F)$ given by threshold beliefs distortion cost function (5). Then for all $a \\in A$ :\n(i) $V_{\\alpha}(a)$ is continuous in $\\alpha$.\n(ii) $\\frac{\\partial V_{\\alpha}(a)}{\\partial \\alpha}=(1-\\alpha)^{-1} \\mathbb{E}_{F}\\left(\\max \\left\\{u(a, \\omega)-\\lambda_{a}^{*}, 0\\right\\}\\right)$.\n(iii) $V_{\\alpha}(a)$ is monotone non-decreasing in $\\alpha$. In particular, for $\\alpha_{1} \\leq \\alpha_{2}$ we get $V_{\\alpha_{1}}(a) \\leq V_{\\alpha_{2}}(a)$.\n\n(iv) When $\\alpha \\longrightarrow 0$ we get\n\n$$\nV_{\\alpha}(a) \\longrightarrow \\mathbb{E}_{F}(u(a, \\omega))\n$$\n\n(v) When $\\alpha \\longrightarrow 1$ we get:\n\n$$\nV_{\\alpha}(a) \\longrightarrow \\sup _{\\omega \\in \\Omega} u(a, \\omega)\n$$\n\nwhere $\\sup _{\\omega \\in \\Omega} u(a, \\omega)$ refers to the essential supremum of the random variable $u(a, \\omega)$.\n\nPart (i) establishes the distorted utility $V_{\\alpha}(a)$ varies continuously with respect to the degree of optimism $\\alpha$. (ii) provides a simple formula that characterizes how the $V_{\\alpha}(a)$ responds to changes on $\\alpha$. This result is complemented by (iii). Finally, parts (iv) and (v) formalize s the limiting cases for $\\alpha \\longrightarrow 0$ and $\\alpha \\longrightarrow 1$, respectively.\n\nWe close this section pointing out that our WT can be shown to be behaviorally equivalent to EU maximization. Specifically, Proposition 3 in the work by Burgh and Melo [2024] allows us to assert that WT behavior can always be interpreted as the outcome of EU maximization under a distorted utility function. An important implication of this finding is that, based on choice data alone, we cannot distinguish between decisions made under the WT model and those made under the traditional EU model.", "tables": {}, "images": {}}, {"section_id": 4, "text": "# 4. Optimistic Discrete Choice \n\nIn this section, we develop a simple discrete choice model with WT behavior. We consider a choice set $A=\\left\\{a_{1}, \\ldots, a_{n}\\right\\}$ and assume that the outcome space $\\Omega=\\mathbb{R}^{n}$. In this context, each $\\omega$ corresponds to an $n$-dimensional vector $\\omega=$ $\\left(\\omega_{a_{1}}, \\ldots, \\omega_{a_{n}}\\right)$, where $\\omega_{a}$ represents the realization associated with alternative $a$. The prior belief is represented by a distribution $F$ that is fully over $\\Omega$. Let $F_{a}\\left(\\omega_{a}\\right)$ denote the marginal distribution governing realizations of $\\omega_{a}$. Without loss of generality, for all $a \\in A$ we assume that $\\mathbb{E}_{F_{a}}\\left(\\omega_{a}\\right)=0$. With a slight abuse of notation, we denote the $\\alpha$-quantile of random variable $\\omega_{a}$ as $Q_{\\alpha}\\left(\\omega_{a}\\right)$ and the corresponding superquantile $\\bar{Q}_{\\alpha}\\left(\\omega_{a}\\right)=\\mathbb{E}_{F_{a}}\\left(\\omega_{a} \\mid \\omega_{a} \\geq Q_{\\alpha}\\left(\\omega_{a}\\right)\\right)$.\n\nThe utility associated with alternative $a$ is defined as ${ }^{11}$\n\n$$\nu(a, \\omega)=u(a)+\\omega_{a}\n$$\n\n[^0]\n[^0]:    ${ }^{11}$ The additive structure is assumed for simplicity. However, our analysis and results hold for the general case where the utility associated with each alternative $a \\in A$ takes the general non-additive form $u\\left(a, \\omega_{a}\\right)$.\n\nThe DM has optimistic beliefs with respect to the realizations of $\\omega$. In particular, the DM solves the optimistic optimization problem (1). Accordingly, from Proposition 2(i), we know that for each alternative $a \\in A$, the $\\alpha$-quantile corresponds to\n\n$$\n\\lambda_{a}^{*}=Q_{\\alpha}(a)=u(a)+Q_{\\alpha}\\left(\\omega_{a}\\right)\n$$\n\nThe previous equality follows from the translation invariance of quantiles, a feature shared by superquantiles. In particular, it follows that $\\bar{Q}_{\\alpha}(a)=$ $u(a)+\\bar{Q}_{\\alpha}\\left(\\omega_{a}\\right)$. Then, from Proposition 2, we know that a WT agent's optimal action is the solution to the following discrete choice problem:\n\n$$\n\\max _{a \\in A}\\left\\{u(a)+\\bar{Q}_{\\alpha}\\left(\\omega_{a}\\right)\\right\\}\n$$\n\nIn the latter expression, the WT agent considers both the deterministic utility $u(a)$ and the average upper tail utility associated with $\\omega_{a}$ as measured by $\\bar{Q}_{\\alpha}\\left(\\omega_{a}\\right)$. Specifically, in equation (8), the $\\alpha$-superquantile $\\bar{Q}_{\\alpha}(\\omega)$ reflects the level of optimism associated with alternative $a$. From a behavioral perspective, this implies that the WT agent overestimates the utility of each alternative.\n\nThis upward bias arises because $\\bar{Q}_{\\alpha}\\left(\\omega_{a}\\right) \\geq \\mathbb{E}_{F_{a}}\\left(\\omega_{a}\\right)=0$, indicating that the WT agent assigns higher perceived utility to the alternative $a$ by focusing on the positive upper tail outcomes of $\\omega_{a}$. By selectively considering the upper tail realizations and censoring the lower tail or average outcomes, the WT agent exhibits a biased perception of the actual utility of each alternative. This bias reflects the optimistic belief that the upper tail outcomes will occur more frequently or have a more significant impact than they do in reality.\n\nIt is important to note that the additive utility structure presented in equation (4.2) bears similarities to the well-known additive random utility model (ARUM) (McFadden [1978, 1981]). However, there are two significant differences between the two approaches. First, the ARUM framework does not explicitly incorporate optimistic behavior. In contrast, our model allows for WT by considering each alternative's average upper tail utility values. This introduces an element of optimism into the decision-making process, leading to potentially different choice outcomes compared to the ARUM. Second, the ARUM approach provides an optimal stochastic choice rule describing the probabilities of each alternative $a \\in A$. In contrast, our discrete choice model provides a deterministic choice rule specifying how the DM selects a particular alternative based on WT behavior. The expression (8) serves as a prescription for decision-making under wishful thinking.\n\nIn Section 4.2, we discuss the implications of incorporating censored beliefs and optimistic behavior into a stochastic choice framework. Specifically, we demonstrate how our model provides a more nuanced understanding of decision-making by accounting for the influence of optimistic beliefs in deriving an optimal stochastic choice rule consistent with ARUM.\n\nExample 2. To see how the previous model provides new insights let us assume that for each $a \\in A$, the random variable $\\omega_{a}$ follows a normal distribution with mean zero and variance $\\sigma_{a}^{2}$. Using the results in Norton et al. [2018], the problem (8) can be expressed as:\n\n$$\n\\max _{a \\in A}\\left\\{u(a)+\\sigma_{a} \\frac{f\\left(Q_{\\alpha}\\left(\\omega_{a}\\right)\\right)}{1-\\alpha}\\right\\}\n$$\n\nThus, when the $\\omega_{a} s$ are normally distributed, the distorted utilities can be interpreted as a mean-variance term. Specifically, for each alternative a, the distorted utility increases with the standard deviation $\\sigma_{a}$. Consequently, in this environment, the WT agent assigns value to the risk associated with each alternative. This example highlights that a WT agent, prefers taking more risks than a traditional rational DM.\n4.1. Skewed discrete choice. Our next goal is to understand the factors shaping $\\bar{Q}_{\\alpha}(a)$ and consequently influencing the choice process. To this end, we focus on the Pareto distribution family. The Pareto distribution is characterized by two parameters: $\\bar{\\omega}_{a} \\in \\mathbb{R}$ and $\\beta_{a}>0$. The Pareto density function can be expressed as follows:\n\n$$\nF\\left(\\omega_{a}\\right)=1-\\left(\\frac{\\bar{\\omega}_{a}}{\\omega_{a}}\\right)^{\\beta_{a}}\n$$\n\nwhere $\\omega_{a} \\in\\left[\\bar{\\omega}_{a}, \\infty\\right)$ is a scale parameter, and $\\beta_{a}>0$ is a shape parameter.\nThe shape parameter is of particular interest to us as it captures the thinness/thickness of the tail. It is important to note that for $\\beta_{a} \\leq 1, \\mathbb{E}\\left(\\omega_{a}\\right)=\\infty$, which implies the superquantile is not well defined $\\left(\\bar{Q}_{\\alpha}\\left(\\omega_{a}\\right)=\\infty\\right)$. As such, we focus on the case where $\\beta_{a}>1$. This environment provides a closed-form expression for the superquantile $\\bar{Q}_{\\alpha}\\left(\\omega_{a}\\right)$, allowing us to uncover the direct role of the quantile in WT decision-making. Furthermore, the Pareto distribution yields an environment with positive skewness in the utility, allowing for insights into the value of the shape of tails. To analyze this case, we compute the value associated with the quantile $Q_{\\alpha}\\left(\\omega_{a}\\right)$. Making use of the expression for the density $F\\left(\\omega_{a}\\right)$, we see:\n\n$$\nQ_{\\alpha}\\left(\\omega_{a}\\right)=\\lambda_{a}^{\\star}=\\bar{\\omega}_{a}(1-\\alpha)^{-1 / \\beta_{a}}\n$$\n\nDirect computation yields the superquantile:\n\n$$\n\\bar{Q}_{\\alpha}\\left(\\omega_{a}\\right)=\\left(1-\\frac{1}{\\beta_{a}}\\right) Q_{\\alpha}\\left(\\omega_{a}\\right)\n$$\n\nThe following proposition formalizes the previous analysis\nProposition 3. Consider a WT problem with the additive payoff structure (4.2). Assume that $\\omega_{a}$ follows a Pareto distribution with parameters $\\bar{\\omega}_{a} \\in \\mathbb{R}$ and $\\beta_{a}>1$ for each $a \\in A$. Then the WT agent solves the following problem\n\n$$\n\\max _{a \\in A}\\left\\{u(a)+\\left(1-\\frac{1}{\\beta_{a}}\\right) Q_{\\alpha}\\left(\\omega_{a}\\right)\\right\\}\n$$\n\nThis expression reveals that an optimistic DM will modify her utilities by incorporating a term that depends on the quantile $Q_{\\alpha}\\left(\\omega_{a}\\right)$ and the shape. Note that a higher $\\beta_{a}$ value indicates a thin long tail, meaning fewer extreme values. This raises the term $\\left(1-\\frac{1}{\\beta_{a}}\\right)$, reflecting the ability of the WT DM to overweigh these limited extreme value outcomes. This modification allows the DM to capture the effects of WT and tailor her preferences based on the specific characteristics of each alternative's positive skewness. ${ }^{12}$\n4.2. Optimistic stochastic choice. We now discuss how our model can be embedded within the framework of stochastic choice. Specifically, we consider the case where the DM faces a binary choice set $A=\\left\\{a_{1}, a_{2}\\right\\}$. For simplicity, assume that the utility associated with $a_{1}$ is state-contingent, given by $u\\left(a_{1}, \\omega\\right)=u\\left(a_{1}\\right)+\\omega$, while the utility associated with $a_{2}$ is deterministic, given by $u\\left(a_{2}, \\omega\\right)=u\\left(a_{2}\\right)$, where $u\\left(a_{1}\\right)<u\\left(a_{2}\\right)$. According to our censored belief model, the DM distorts the expected utility of $a_{1}$ by evaluating the $\\alpha$ superquantile. When comparing $a_{1}$ and $a_{2}$, the DM analyzes the difference between $V_{\\alpha}\\left(a_{1}\\right)=u\\left(a_{1}\\right)+\\mathbb{E}\\left(\\omega_{a_{1}} \\mid \\omega_{a_{1}} \\geq Q_{\\alpha}\\left(a_{1}\\right)\\right)$ and $V_{\\alpha}\\left(a_{2}\\right)=u\\left(a_{2}\\right)$ for all $\\alpha \\in[0,1)$.\n\nFollowing the literature on random utility and risk (e.g., Apesteguia and Ballester [2018]), we consider an environment where the valuation of an action $a \\in A$ is determined by the additive combination of $V_{a}(a)$ and a random, i.i.d., unobserved term $\\epsilon_{a}$ that follows a continuous cumulative distribution $H$. Accordingly, we define the probability of selecting action $a_{1}$ over $a_{2}$ as\n\n$$\n\\rho_{\\alpha}^{R U M}\\left(a_{1}, a_{2}\\right)=\\mathbb{P}\\left(V_{\\alpha}\\left(a_{1}\\right)+\\epsilon_{a_{1}} \\geq V_{\\alpha}\\left(a_{2}\\right)+\\epsilon_{a_{2}}\\right)\n$$\n\n[^0]\n[^0]:    ${ }^{12}$ In the online appendix, we discuss several other distributions that yield closed-form formulas for $\\mathbb{E}_{Q_{a}}\\left(\\omega_{a} \\mid \\omega_{a} \\geq Q_{a}^{-1}(\\alpha)\\right)$, including the logistic distribution, GPD, and GEV.\n\nTo specify $\\rho_{\\alpha}^{R U M}\\left(a_{1}, a_{2}\\right)$, we adopt the widely used Gumbel (extreme value type 1) distribution for the unobserved terms. This assumption yields the popular Luce model (i.e., logit model). A key feature of the Luce model is that it provides closed-form expressions for the choice probabilities $\\rho_{\\alpha}^{\\text {Luce }}\\left(a_{1}, a_{2}\\right)$ and $\\rho_{\\alpha}^{\\text {Luce }}\\left(a_{2}, a_{1}\\right)$, respectively. Specifically, the Luce model yields the following stochastic choice rule:\n\n$$\n\\rho_{\\alpha}^{\\text {Luce }}\\left(a_{1}, a_{2}\\right)=\\frac{e^{V_{\\alpha}\\left(a_{1}\\right)}}{e^{V_{\\alpha}\\left(a_{1}\\right)}+e^{u\\left(a_{2}\\right)}}\n$$\n\nwhere $\\rho_{\\alpha}^{\\text {Luce }}\\left(a_{2}, a_{1}\\right)=1-\\rho_{\\alpha}^{\\text {Luce }}\\left(a_{1}, a_{2}\\right)$.\nTo illustrate the role of censored beliefs in shaping the stochastic choice rule (10), consider that $\\omega_{a_{1}}$ follows a standard normal distribution. From Example 2 , we know that $V_{\\alpha}\\left(a_{1}\\right)=u\\left(a_{1}\\right)+\\frac{f\\left(Q_{\\alpha}\\left(\\omega_{a_{1}}\\right)\\right)}{1-\\alpha}$. Furthermore, from Corollary 1, we know that as $\\alpha \\rightarrow 0$, we recover $V_{0}\\left(a_{1}\\right)=u\\left(a_{1}\\right)$. By assumption, $u\\left(a_{1}\\right)<u\\left(a_{2}\\right)$, so $\\rho_{0}^{\\text {Luce }}\\left(a_{1}, a_{2}\\right)<\\rho_{0}^{\\text {Luce }}\\left(a_{2}, a_{1}\\right)$. Thus, when the DM does not censor outcomes, the choice probability of the riskless option is higher.\n\nAs $\\alpha$ increases, the value of $V_{\\alpha}\\left(a_{1}\\right)$ also increases (Corollary 1(iii)), leading to an increase in $\\rho_{\\alpha}^{\\text {Luce }}\\left(a_{1}, a_{2}\\right)$. More importantly, it is not difficult to find a threshold $\\hat{\\alpha}$ such that $V_{\\hat{\\alpha}}\\left(a_{1}\\right)>u\\left(a_{2}\\right)$, implying that the stochastic choice behavior reverses to $\\rho_{\\alpha}^{\\text {Luce }}\\left(a_{1}, a_{2}\\right)>\\rho_{\\alpha}^{\\text {Luce }}\\left(a_{2}, a_{1}\\right)$, and furthermore $\\rho_{\\alpha}^{\\text {Luce }}\\left(a_{1}, a_{2}\\right) \\rightarrow 1$ as $\\alpha \\rightarrow 1$. Put formally, the difference $V_{\\alpha}\\left(a_{1}\\right)-u\\left(a_{2}\\right)$ is monotone increasing in $\\alpha .{ }^{13}$ Figure 1 demonstrates this monotonicity of stochastic choice behavior for the case of the normal and Pareto distributions, respectively.\n\nThe previous monotonicity pattern can be extended to the class of additive RUMs, where the discrete choice sets may contain more than two alternatives. Accordingly, let $\\rho_{\\alpha}^{R U M}$ denote the stochastic choice rule (choice probabilities) induced by an additive RUM, where the DM evaluates the utilities $V_{\\alpha}(a)+\\epsilon_{a}$ for all $a \\in A, \\alpha \\in[0,1)$, and $\\epsilon_{a}$ that is a continuous random variable. Next, we adapt Apesteguia and Ballester [2018]'s monotonicity notion. Formally, for a pair of actions $\\left(a, a^{\\prime}\\right) \\in A$, let $\\rho_{\\alpha}^{R U M}\\left(a, a^{\\prime}\\right)$ denote the probability of preferring $a$ over $a^{\\prime}$ for all $\\alpha \\in[0,1)$. We say that $\\rho^{R U M}$ is monotonically increasing for a pair of actions $\\left(a, a^{\\prime}\\right)$ when $\\rho^{R U M}\\left(a, a^{\\prime}\\right)$ increases in $\\alpha$ for all $\\alpha \\in(0,1)$. We can now demonstrate a tight condition for the monotonicity of $\\rho^{R U M}$.\n\n[^0]\n[^0]:    ${ }^{13}$ The stochastic choice pattern described extends beyond the normal distribution case. For example, $\\omega_{a_{1}}$ could follow a Pareto distribution, as in section 4.1 or any of the distributions in the online appendix.\n\nProposition 4. $\\rho^{R U M}$ is monotonically increasing for the pair of actions $\\left(a, a^{\\prime}\\right)$ if and only if for all $\\alpha \\in(0,1)$ the following inequality holds\n\n$$\n\\mathbb{E}_{F}\\left(\\max \\left\\{u(a, \\omega)-Q_{\\alpha}(a), 0\\right\\}\\right) \\geq \\mathbb{E}_{F}\\left(\\max \\left\\{u\\left(a^{\\prime}, \\omega\\right)-Q_{\\alpha}\\left(a^{\\prime}\\right), 0\\right\\}\\right)\n$$", "tables": {}, "images": {}}, {"section_id": 5, "text": "# Stochastic Choice and Degree of Optimism \n\n![img-0.jpeg](img-0.jpeg)\n\nFigure (1) Choice probabilities $\\rho_{\\alpha}^{\\text {Luce }}\\left(a_{1}, a_{2}\\right)$\nThis figure demonstrates how the level of optimism shapes stochastic choice behavior, where $\\mathbb{E}_{F}\\left(u\\left(a_{1}, \\omega\\right)\\right)=0$ and $u\\left(a_{2}\\right)=1$\n\nMultiple remarks are in order. First, Proposition 4 builds off of results from Proposition 1 of Apesteguia and Ballester [2018]. Our result establishes that when embedded into a RUM, our censored beliefs model can yield a monotone stochastic choice rule. This result provides a simple, testable implication of our optimistic RUM. Namely, policies targeted at increasing optimism may be tested directly through stochastic choice data. Second, we note that the degree of optimism, $\\alpha$, can be treated as a random parameter representing different \"optimistic attitudes\" within a population of DMs. This approach aligns with the random preference model discussed in Apesteguia and Ballester [2018] in the context of risk aversion in stochastic choice models. A full exploration of this extension is left for future research.\n\nFinally, we note that the monotonicity condition (11) does not rely on the additively separable specification (7). The condition is derived for a general case. For additive separable utility, condition (11) simplifies to:\n\n$$\n\\mathbb{E}_{F_{a}}\\left(\\max \\left\\{u(a)-Q_{\\alpha}\\left(\\omega_{a}\\right), 0\\right\\}\\right) \\geq \\mathbb{E}_{F_{a^{\\prime}}}\\left(\\max \\left\\{u\\left(a^{\\prime}\\right)-Q_{\\alpha}\\left(\\omega_{a^{\\prime}}\\right), 0\\right\\}\\right)\n$$\n\nfor all $\\alpha \\in(0,1)$.\n4.3. Market entry decisions. We now apply the previous analysis to study a variant of the entry decision problem studied by Bresnahan and Reiss [1991]. Suppose a firm seeks to decide whether to enter a particular market. The action set is $A=\\{$ enter, out $\\}$, where enter represents the choice of entering the market, while out represents staying out of the market. The firm faces uncertainty about this market's demand/competition captured by additive profit shock $\\pi$. Staying out of the market yields profit $u($ out, $\\pi)=0$, independent of the profit shock. Entering the market requires entry cost $k>0$, so the profit associated with entry is given by $u($ enter, $\\pi)=\\pi-k$. We assume that the profit shock $\\pi$ follows a continuous distribution $F$ with $\\mathbb{E}_{F}(\\pi)=0$.\n\nIn this setting, a firm that seeks to maximize its expected profit would never choose to enter the market. This is because $\\mathbb{E}_{F}(u($ out, $\\pi))=0>-k=\\mathbb{E}(\\pi-$ $k)>\\mathbb{E}_{F}(u($ enter, $\\pi))$. However, by applying the insights from Proposition 2, we see that an optimistic firm may choose to enter. Concretely, the firm will enter the market under specific parametric configurations, driving optimistic beliefs. To demonstrate, consider that choice is driven by optimistic beliefs as specified in Problem (1). For action enter, the optimal multiplier $\\lambda_{\\text {Enter }}^{*}$ is given by $\\lambda_{\\text {Enter }}^{*}=Q_{\\alpha}($ Enter $)=Q_{\\alpha}(\\pi)-k$. Therefore, the firm chooses to enter if and only if the following condition holds:\n\n$$\n\\bar{Q}_{\\alpha}(\\pi)>k\n$$\n\nwhere $\\bar{Q}_{\\alpha}(\\pi)=\\mathbb{E}_{F}\\left(\\pi \\mid \\pi \\geq Q_{\\alpha}(\\pi)\\right)$.\nTherefore, while the true mean of the profit shock distribution is zero, an optimistic disposition can lead it to instead rely on its subjective mean, captured by $\\bar{Q}_{\\alpha}(\\pi)$. Furthermore, by defining $\\hat{\\alpha}$ such that $\\bar{Q}_{\\hat{\\alpha}}(\\pi)=k$, we note that the firm enters the market for all $\\alpha \\geq \\hat{\\alpha}$. The fact that only sufficiently optimistic firms choose to enter this market highlights the impact of WT on market entry, and aligns well with the well-documented connection between optimism and entrepreneurial endeavors (Seaward and Kemp [2000]).\n\nUsing the result in the Proposition 3, we gain economic insights about how the skewness of distribution $F$ determines the firm's decision. Let us consider the case where the profit shock $\\pi$ follows a Pareto distribution with density $F$ and shape parameter $\\beta$. Using Proposition (3), we see that the WT firm will choose to enter the market if and only if the following condition is satisfied:\n\n$$\nQ_{\\alpha}(\\pi) \\geq \\frac{\\beta}{\\beta-1} k\n$$\n\nThis entry rule provides a specific cutoff value determining the firm's decision to enter the market. This cutoff value depends on the shape $\\beta$ and $\\alpha$-quantile of the profit shock distribution along with the fixed entry cost.\n\nThe parameter $\\beta$ is of particular interest, capturing a notion of skewness in the distribution. For high values of $\\beta$, the distribution is characterized by long skinny tails. This parameter has a significant influence on the firm's decisionmaking process, as an optimistic firm will be more inclined to enter the market when there is even a slim chance of extremely high profits.\n4.4. Optimism and Risk Preferences. In the previous section, we discussed the role of optimism on market entry. However, in the study of entrepreneurial endeavors, both risk preferences and optimism have received extensive attention. While optimism leads DMs to overweight the positive aspects of risk by focusing on high payoff outcomes, risk aversion reflects a tendency to prefer riskless prospects to risky ones. In this section, we demonstrate that our WT model can be extended to capture the separate effects of optimism and risk aversion, reflecting the complex interrelationship between these two.\n\nMany studies have tested whether individual differences in risk aversion explain entrepreneurial endeavors, and Parker [2009] provides a systematic review of these studies. The findings are inconclusive, with some finding risk tolerance to drive entrepreneurship (Ahn [2010]) while others do not (Holm et al. [2013]). Optimistic beliefs provide another plausible explanation for entrepreneurship (Puri and Robinson [2007]; Bengtsson and Ekeblom [2014]). \u00c5stebro et al. [2014] note that \"much of the research on entry into entrepreneurship has tended to focus on single factors... (but) the time is ripe to compare and contrast these factors.\" With this in mind, we present a decision criterion that reflects both WT and risk aversion.\n\nSimilar to the utility function in Equation (4.2), the DM's utility for actions $a \\in A$ depends on a deterministic value $u(a)$ and an additively separable term dependent of random variable $\\omega_{a}$. Let the random variable $\\omega_{a}$ be defined by $\\omega_{a} \\sim N\\left(0, \\omega_{a}^{2}\\right)$. To capture risk aversion, we consider our DM to have an exponential utility function\n\n$$\nu\\left(a, \\omega_{a}\\right)=u(a)-e^{-r \\omega_{a}}\n$$\n\nwhich exhibits constant absolute risk aversion with corresponding risk-aversion parameter $r$. To focus on the case where the DM is risk averse, we restrict\n\nconsideration to $r>0$. We can formalize a decision rule for a DM who is both risk-averse and optimistic.\n\nCorollary 2. Consider a WT problem with the payoff structure as defined by Equation (12) with optimism level $\\alpha$ and risk aversion parameter $r$. Then the WT agent solves the following problem:\n\n$$\n\\max _{a \\in A}\\left\\{u(a)-\\frac{1}{(1-\\alpha)} \\exp \\left(\\frac{1}{2} r^{2} \\sigma^{2}\\right)\\left(1-\\Phi\\left(r \\sigma+\\frac{1}{\\sigma} Q_{\\alpha}\\left(\\omega_{a}\\right)\\right)\\right)\\right\\}\n$$\n\nwhere $\\Phi$ denotes the CDF function for the standard normal function\nThe decision-making criterion laid out in Corollary 2 separately captures the effects of optimistic beliefs and risk aversion, highlighting each factor's role in shaping choice. A few points are in order on this criterion. Firstly, we see that the $\\alpha$-quantile again plays a critical role in decision-making. As we have previously demonstrated, it captures a DM's degree of optimism, and this fact holds true under risk aversion.\n\nSecond, by applying Corollary 1, we see that for $\\alpha \\rightarrow 0$, the criterion tends toward $\\max _{a \\in A}\\left\\{u(a)-\\exp \\left(\\frac{1}{2} r^{2} \\sigma^{2}\\right)\\right\\}$. Similarly, for $\\alpha \\rightarrow 1$, the criterion tends toward maximization of the deterministic portion: $\\max _{a \\in A}\\{u(a)\\}$. Taken together, these facts highlight that as a dm becomes more optimistic, the influence of risk aversion diminishes, reducing the tendency to favor less risky actions. In the context of capital budgeting, Gervais et al. [2002] similarly notes optimism's ability to offset risk aversion.\n\nFinally, note that the formulation with normal error terms and CRRA utility allows us to yield a closed-form expression for the decision-making criterion. However, similar analysis is possible using numerical integration for other notions of risk aversion and random variables drawn from different distributions.", "tables": {}, "images": {"img-0.jpeg": "data:image/jpeg;base64,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"}}, {"section_id": 6, "text": "# 5. Conclusions \n\nIn this paper, we have developed a model of WT and optimism. Our key finding is that WT behavior can be expressed as equivalent to superquantile utility maximization. We achieve this by introducing the threshold beliefs distortion cost. From a behavioral perspective, this implies that an optimistic agent relies on the upper tail of the utility distribution and assesses the expected utility conditional on being above a specific quantile. Moreover, our analysis reveals that a WT agent's distorted beliefs overweight the probability associated with desirable outcomes by underweighting the probability of less desirable ones. Unlike wishful thinking based on the Kullback-Leibler divergence, this reweighting is done in a binary fashion.\n\nOur model of optimistic decision-making based on censored beliefs yields numerous insights into the effects of WT. We formalize a connection between WT behavior and a preference for skewness, demonstrating that optimists focus on the shape of the right tail in their analysis. Furthermore, we demonstrate that optimistic beliefs can be easily implemented into random utility models. In particular, we provide a condition that ensures that stochastic choice is monotone, allowing one to test for changes in decision-making optimism levels. We then discuss how optimism can drive market entry and present a decision criterion that captures the complex relationship between optimistic beliefs and risk aversion.\n\nLooking ahead, there are several avenues for extending and enriching our model, many involving the incorporation of WT into environments of information acquisition and stochastic choice. ${ }^{14}$ One direction involves investigating how WT behavior unfolds in a dynamic environment, potentially yielding new insights into the development of sentiments. Another involves embedding the censored beliefs model into a persuasion problem, as studied by Augias and Barreto [2020] with KL-based wishful thinking. Finally, a revealed-preferences approach may offer valuable perspectives on the choice data arising from censored beliefs, and the data-driven framework of Caplin and Martin [2015] could provide a promising direction for this work.", "tables": {}, "images": {}}, {"section_id": 7, "text": "# REFERENCES \n\nTaehyun Ahn. Attitudes toward risk and self-employment of young workers. Labour Economics, 17(2):434-442, 2010.\nGeorge A Akerlof and William T Dickens. The economic consequences of cognitive dissonance. The American economic review, 72(3):307-319, 1982.\nJose Apesteguia and Miguel A. Ballester. Monotone stochastic choice models: The case of risk and time preferences. Journal of Political Economy, 126 (1):74-106, 2018. doi: 10.1086/695504. URL https://doi.org/10.1086/ 695504.\n\nThomas \u00c5stebro, Holger Herz, Ramana Nanda, and Roberto A Weber. Seeking the roots of entrepreneurship: Insights from behavioral economics. Journal of Economic Perspectives, 28(3):49-70, 2014.\nTatjana Aue, Howard C. Nusbaum, and John T. Cacioppo. Neural correlates of wishful thinking. Social Cognitive Affective Neuroscience, 7(8):991-1000, 2012. ISSN 0378-4266.\n\n[^0]\n[^0]:    ${ }^{14}$ Strzalecki [2025] presents a comprehensive study of information acquisition models and stochastic choice.\n\nVictor Augias and Daniel Barreto. Persuading a wishful thinker. arXiv preprint arXiv:2011.13846, 2020.\nRoy F Baumeister, Ellen Bratslavsky, Catrin Finkenauer, and Kathleen D Vohs. Bad is stronger than good. Review of general psychology, 5(4):323370, 2001.\nRoland Benabou. Groupthink: Collective delusions in organizations and markets. The Review of Economic Studies, 80(2 (283)):429-462, 2013. ISSN 00346527, 1467937X. URL http://www.jstor.org/stable/43551491.\nOla Bengtsson and Daniel Ekeblom. The bright but right view? a new type of evidence on entrepreneurial optimism. 2014.\nAnat Bracha and Donald J Brown. Affective decision making: A theory of optimism bias. Games and Economic Behavior, 75(1):67-80, 2012.\nTimothy F. Bresnahan and Peter C. Reiss. Empirical models of discrete games. Journal of Econometrics, 48(1):57-81, 1991. ISSN 0304-4076. doi: https://doi.org/10.1016/0304-4076(91)90032-9. URL https://www. sciencedirect.com/science/article/pii/0304407691900329.\nMarkus K. Brunnermeier and Jonathan A. Parker. Optimal expectations. American Economic Review, 95(4):1092-1118, September 2005. doi: 10. 1257/0002828054825493. URL https://www.aeaweb.org/articles?id= 10.1257/0002828054825493.\n\nJarrod Burgh and Emerson Melo. Wishful thinking is risky thinking. Working Paper, 2024.\nRoland B\u00e9nabou and Jean Tirole. Mindful economics: The production, consumption, and value of beliefs. Journal of Economic Perspectives, 30 (3):141-64, September 2016. doi: 10.1257/jep.30.3.141. URL https: //www.aeaweb.org/articles?id=10.1257/jep.30.3.141.\nAndrew Caplin and John V Leahy. Wishful thinking. Working Paper 25707, National Bureau of Economic Research, March 2019. URL http://www. nber.org/papers/w25707.\nAndrew Caplin and Daniel Martin. A testable theory of imperfect perception. The Economic Journal, 125(582):184-202, 2015.\nChristopher P. Chambers. An axiomatization of quantiles on the domain of distribution functions. Mathematical Finance, 19(2): 335-342, 2009. doi: https://doi.org/10.1111/j.1467-9965.2009.00369. x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j. 1467-9965.2009.00369.x.\nI. Csiszar. Information-type measures of difference of probability distributions and indirect observation. Studia Scientiarum Mathematicarum Hungarica, 2:229-318, 1967. URL https://cir.nii.ac.jp/crid/\n\n1571417125811646464.\nKent Daniel and David Hirshleifer. Overconfident investors, predictable returns, and excessive trading. Journal of Economic Perspectives, 29(4):6188, November 2015. doi: 10.1257/jep.29.4.61. URL https://www.aeaweb. org/articles?id=10.1257/jep.29.4.61.\nLuciano de Castro and Antonio F. Galvao. Dynamic quantile models of rational behavior. Econometrica, 87(6):1893-1939, 2019. ISSN 00129682, 14680262. URL http://www.jstor.org/stable/45238026.\nLuciano de Castro and Antonio F. Galvao. Static and dynamic quantile preferences. Economic Theory, 73:747-779, 2022. URL https://link.springer. com/article/10.1007/s00199-021-01355-8.\nZ Seyda Deligonul, G Tomas M Hult, and S Tamer Cavusgil. Entrepreneuring as a puzzle: an attempt to its explanation with truncation of subjective probability distribution of prospects. Strategic Entrepreneurship Journal, 2 (2):155-167, 2008.\n\nJan B. Engelmann, Ma\u00ebl Lebreton, Nahuel A. Salem-Garcia, Peter Schwardmann, and Jo\u00ebl J. van der Weele. Anticipatory anxiety and wishful thinking. American Economic Review, Forthcoming.\nSimon Gervais, JB Heaton, and Terrance Odean. The positive role of overconfidence and optimism in investment policy. 2002.\nItzhak Gilboa and David Schmeidler. Maxmin expected utility with non-unique prior. Journal of Mathematical Economics, 18(2):141-153, 1989. ISSN 0304-4068. doi: https://doi.org/10.1016/0304-4068(89) 90018-9. URL https://www.sciencedirect.com/science/article/pii/ 0304406889900189.\n\nMichael D. Grubb. Overconfident consumers in the marketplace. Journal of Economic Perspectives, 29(4):9-36, November 2015. doi: 10.1257/jep.29.4.9. URL https://www.aeaweb.org/articles?id=10.1257/jep.29.4.9.\nLars Peter Hansen and Thomas J. Sargent. Robust control and model uncertainty. The American Economic Review, 91(2):60-66, 2001. ISSN 00028282. URL http://www.jstor.org/stable/2677734.\nLars Peter Hansen and Thomas J. Sargent. Robustness. Princeton University Press, stu - student edition edition, 2008. URL http://www.jstor.org/ stable/j.ctt1dr35gx.\nDavid Hecht. The neural basis of optimism and pessimism. Experimental neurobiology, 22(3):173, 2013.\nHakan J Holm, Sonja Opper, and Victor Nee. Entrepreneurs under uncertainty: An economic experiment in china. Management Science, 59(7): $1671-1687,2013$.\n\nChristoph W Korn, Tali Sharot, Hendrik Walter, Hauke R Heekeren, and Raymond J Dolan. Depression is related to an absence of optimistically biased belief updating about future life events. Psychological medicine, 44 (3):579-592, 2014.\n\nMatthew Kovach. Twisting the truth: Foundations of wishful thinking. Theoretical Economics, 15(3):989-1022, 2020.\nDaniel Kuhn, Peyman Mohajerin Esfahani, Viet Anh Nguyen, and Soroosh Shafieezadeh-Abadeh. Wasserstein Distributionally Robust Optimization: Theory and Applications in Machine Learning, chapter 6, pages 130-166. 2019. doi: 10.1287/educ.2019.0198. URL https://pubsonline.informs. org/doi/abs/10.1287/educ.2019.0198.\nZiva Kunda. The case for motivated reasoning. Psychological bulletin, 108 3: $480-98,1990$.\nDan Lovallo and Daniel Kahneman. Delusions of success. Harvard business review, 81(7):56-63, 2003.\nFabio Maccheroni, Massimo Marinacci, and Aldo Rustichini. Ambiguity aversion, robustness, and the variational representation of preferences. Econometrica, 74(6):1447-1498, 2006.\nUlrike Malmendier and Geoffrey Tate. Behavioral ceos: The role of managerial overconfidence. Journal of Economic Perspectives, 29(4):37-60, November 2015. doi: 10.1257/jep.29.4.37. URL https://www.aeaweb.org/articles? id=10.1257/jep.29.4.37.\nCharles F. Manski. Ordinal utility models of decision making under uncertainty. Theory and Decision, 25:79-104, 1988. URL https://doi.org/10. 1007/BF00129169.\nGuy Mayraz. Priors and desires: A bayesian model of wishful thinking and cognitive dissonance. Unpublished Manuscript. University of Sydney. http://mayraz. com/papers/PriorsAndDesires. pdf, 2019.\nD. McFadden. Modeling the choice of residential location. in A. Karlqvis, A., Lundqvist, L., Snickars, L., Weibull, J. (eds.), Spatial Intearction Theory and Planning Models (North Holland, Amsterdam), pages 531-551, 1978.\nD. McFadden. Structural Analysis of Discrete Data with Econometric Applications, chapter Econometric Models of Probabilistic Choice, pages 198-272. Cambridge: MIT, 1981.\nGeeta Menon, Ellie J Kyung, and Nidhi Agrawal. Biases in social comparisons: Optimism or pessimism? Organizational Behavior and Human Decision Processes, 108(1):39-52, 2009.\nMatthew Norton, Valentyn Khokhlov, and Stan Uryasev. Calculating cvar and bpoe for common probability distributions with application to portfolio\n\noptimization and density estimation. Ann Oper Res, 299:1281-1315, 2018. ISSN 0304-4076. doi: https://doi.org/10.1007/s10479-019-03373-1. URL https://link.springer.com/article/10.1007/s10479-019-03373-1.\nA Yesim Orhun, Alain Cohn, and Collin Raymond. Motivated optimism and workplace risk. Available at SSRN 3966686, 2021.\nEmily Oster, Ira Shoulson, and E. Ray Dorsey. Optimal expectations and limited medical testing: Evidence from huntington disease. American Economic Review, 103(2):804-30, April 2013. doi: 10.1257/aer.103.2.804. URL https://www.aeaweb.org/articles?id=10.1257/aer.103.2.804.\nSimon C. Parker. The Economics of Entrepreneurship. Cambridge University Press, 2009.\nManju Puri and David T Robinson. Optimism and economic choice. Journal of financial economics, 86(1):71-99, 2007.\nR. Tyrrell Rockafellar and Stanislav Uryasev. Optimization of conditional value-at risk. Journal of Risk, 3:21-41, 2000.\nR.T. Rockafellar and J.O. Royset. Random variables, monotone relations, and convex analysis. Mathematical Programming, 148:297-331, 2014. doi: https: //doi.org/10.1007/s10107-014-0801-1. URL https://onlinelibrary. wiley.com/doi/abs/10.1111/j.0960-1627.2004.00184.x.\nR.Tyrrell Rockafellar and Stanislav Uryasev. Conditional value-at-risk for general loss distributions. Journal of Banking $\\mathcal{E}$ Finance, 26(7):14431471, 2002. ISSN 0378-4266. doi: https://doi.org/10.1016/S0378-4266(02) 00271-6. URL https://www.sciencedirect.com/science/article/pii/ S0378426602002716.\nMarzena Rostek. Quantile maximization in decision theory. The Review of Economic Studies, 77(1):339-371, 2010.\nJohannes O. Royset. Risk-adaptive approaches to learning and decision making: A survey, 2023.\nHamish GW Seaward and Simon Kemp. Optimism bias and student debt. New Zealand Journal of Psychology, 29(1):17-19, 2000.\nAlexander Shapiro. Distributionally robust stochastic programming. SIAM Journal on Optimization, 27(4):2258-2275, 2017. doi: 10.1137/16M1058297. URL https://doi.org/10.1137/16M1058297.\nDaniel F Stone and Daniel H Wood. Cognitive dissonance, motivated reasoning, and confirmation bias: applications in industrial organization. In Handbook of behavioral industrial organization, pages 114-137. Edward Elgar Publishing, 2018.\nTomasz Strzalecki. Stochastic Choice Theory. Econometric Society Monographs. Cambridge University Press, 2025. URL\n\nhttps://www.cambridge.org/core/books/stochastic-choice-theory/ 12B749A5F76C66C8B9D2EB3279181B77. Forthcoming.\nShelley E Taylor. Asymmetrical effects of positive and negative events: the mobilization-minimization hypothesis. Psychological bulletin, 110(1):67, 1991.\n\nPete C Trimmer. Optimistic and realistic perspectives on cognitive biases. Current opinion in behavioral sciences, 12:37-43, 2016.", "tables": {}, "images": {}}, {"section_id": 8, "text": "# Appendix: Proofs \n\nProof of Proposition 1. We offer two proofs of this result. First, we prove Proposition 1 using an argument that exploits the properties of the threshold beliefs distortion cost function without invoking convex duality. ${ }^{15}$ A subjective belief has cost zero if it is not too far from the prior; otherwise, it is infinity. To formalize this, notice that the cost can be slightly rewritten as:\n\n$$\nC_{\\alpha}(G\\|F)= \\begin{cases}0, & 0 \\leq g(\\omega) \\leq \\frac{f(\\omega)}{1-\\alpha}, \\forall \\omega \\in \\Omega \\\\ +\\infty & \\text { otherwise }\\end{cases}\n$$\n\nAs such, the subjective density can be at most $\\frac{1}{1-\\alpha}$ times larger than the prior. Then the interior maximization problem for action $a$ multiplying the density function $f$ of $(F)$ by $\\frac{1}{1-\\alpha}$ and selecting cutoff $\\omega^{*}$ such that\n\n$$\n\\int_{\\{\\omega: u(a, \\omega) \\geq u\\left(a, \\omega^{*}\\right)\\}} \\frac{1}{1-\\alpha} d f=1\n$$\n\nIn this way, the DM maximizes her SEU by choosing an optimistic subjective belief, which assigns probability zero to states with utility lower than $\\omega^{*}$, without suffering any cost $\\left(C_{\\phi}=0.\\right)$ Formalized, this yields expression (4).\n\nOur second proof relies on convex duality arguments used in Burgh and Melo [2024]. In particular, from Lemma 1 in Burgh and Melo [2024], the function $V_{\\alpha}$ can be rewritten as:\n\n$$\nV_{\\alpha}(a)=\\min _{\\lambda_{a} \\in\\left[g_{a}, \\bar{a}_{a}\\right]}\\left\\{\\lambda_{a}+\\mathbb{E}_{F}\\left(\\phi^{*}\\left(u(a, \\omega)-\\lambda_{a}\\right)\\right)\\right\\}\n$$\n\nwhere $\\phi^{*}(s)=\\sup _{t \\in \\text { int dom } \\phi} s t-\\phi(t)$ is the convex conjugate of function $\\phi$. It is straightforward to see that the convex conjugate of the function $\\phi$ defined by Equation (2) is given by $\\phi^{*}(s)=\\frac{1}{1-\\alpha} \\max \\{s, 0\\}$. Defining $s_{a}=u(a, \\omega)-\\lambda_{a}$ and plugging in the convex conjugate $\\phi^{*}$ we get:\n\n$$\nV_{\\alpha}(a)=\\min _{\\lambda_{a} \\in\\left[g_{a}, \\bar{a}_{a}\\right]}\\left\\{\\lambda_{a}+\\frac{1}{1-\\alpha} \\mathbb{E}_{F}\\left(\\max \\left\\{u(a, \\omega)-\\lambda_{a}, 0\\right\\}\\right)\\right\\}\n$$\n\nProof of Proposition 2. Let $F\\left(a, \\lambda_{a}\\right) \\triangleq \\lambda_{a}+\\frac{1}{1-\\alpha} \\mathbb{E}_{F}\\left(\\max \\left\\{u(a, \\omega)-\\lambda_{a}, 0\\right\\}\\right)$. Then expression (4) can be rewritten as\n\n$$\nV_{\\alpha}(a)=\\min _{\\lambda_{a} \\in \\Lambda(a)} F\\left(a, \\lambda_{a}\\right)\n$$\n\n[^0]\n[^0]:    ${ }^{15} \\mathrm{We}$ are very grateful to the AE for suggesting this simpler proof.\n\nBy [Rockafellar and Uryasev, 2000, Thm. 1], we know that $F\\left(a, \\lambda_{a}\\right)$ is convex and continuously differentiable with respect to $\\lambda_{a}$. Thus the optimal $\\lambda_{a}^{*}$ satisfies the necessary and sufficient first-order condition:\n\n$$\n1-\\frac{1}{1-\\alpha} \\mathbb{P}\\left(u(a, \\omega) \\geq \\lambda_{a}^{*}\\right)=0\n$$\n\nRewriting the previous expression, we get $\\alpha=\\mathbb{P}\\left(u(a, \\omega) \\leq \\lambda_{a}^{*}\\right)$. Then from Definition 1 it follows that $\\lambda_{a}^{*}=Q_{\\alpha}(a)$. This proves part (i). Part (ii) follows from using (i) combined with expression (4). To show (iii), we combine Definition 2 with the fact that $1-\\alpha=\\mathbb{P}\\left(u(a, \\omega) \\geq Q_{\\alpha}(a)\\right)$. In particular, we can write the following:\n\n$$\n\\begin{aligned}\n\\bar{Q}_{\\alpha}(a) & =Q_{\\alpha}(a)+\\frac{1}{1-\\alpha} \\int_{\\Omega} \\max \\left\\{u(a, \\omega)-Q_{\\alpha}(a), 0\\right\\} f(\\omega) d \\omega \\\\\n& =Q_{\\alpha}(a)+\\frac{1}{1-\\alpha} \\int_{\\left\\{\\omega: u(a, \\omega) \\geq Q_{\\alpha}(a)\\right\\}} u(a, \\omega) f(\\omega) d \\omega-\\frac{Q_{\\alpha}(a)}{1-\\alpha} \\int_{\\left\\{\\omega: u(a, \\omega) \\geq Q_{\\alpha}(a)\\right\\}} f(\\omega) d \\omega \\\\\n& =\\frac{1}{1-\\alpha} \\int_{\\left\\{\\omega: u(a, \\omega) \\geq Q_{\\alpha}(a)\\right\\}} u(a, \\omega) f(\\omega) d \\omega \\\\\n& =\\mathbb{E}_{F}(u(a, \\omega) \\mid u(a, \\omega) \\geq Q_{\\alpha}(a))\n\\end{aligned}\n$$\n\nFinally, part (iv) follows from the using the fact that $1-\\alpha=\\mathbb{P}(u(a, \\omega) \\geq$ $\\left.Q_{\\alpha}(a)\\right)$. Then, by using the definition of conditional distribution, the expression for $G_{\\alpha}(a)$ follows at once.\n\nProof of Corollary 1. Part (i) is a direct application of Proposition 13 in Rockafellar and Uryasev [2002]. To show (ii), we note that under the assumption that $F_{a}$ is continuous and strictly increasing, we know that $Q_{\\alpha}(a)$ is uniquely defined. Then, by using the envelope theorem, we differentiate with respect to $\\alpha$ to obtain the desired result. Part (iii) follows immediately from the (ii) which implies $\\frac{\\partial V_{\\alpha}(a)}{\\partial \\alpha} \\geq 0$. Part (iv) and (v) follows from the definition of the superquantile.\n5.1. Proof of Proposition 3. The density function of the Pareto distribution is given by:\n\n$$\nF\\left(\\omega_{a}\\right)=1-\\left(\\frac{\\bar{\\omega}_{a}}{\\omega_{a}}\\right)^{\\beta_{a}}\n$$\n\nBecause $F$ is a continuous distribution, the $\\alpha$-quantile $Q_{\\alpha}(a)$ must satisfy\n\n$$\n\\alpha=1-\\left(\\frac{\\bar{\\omega}_{a}}{Q_{\\alpha}(a)}\\right)^{\\beta_{a}}\n$$\n\nAlgebra along with Proposition 2 (i) yields:\n\n$$\nQ_{\\alpha}\\left(\\omega_{a}\\right)=\\lambda_{a}^{\\star}=\\bar{\\omega}_{a}(1-\\alpha)^{-1 / \\beta_{a}}\n$$\n\nNow, we know that $\\bar{Q}_{\\alpha}\\left(\\omega_{a}\\right)=(1-\\alpha)^{-1} \\int_{\\alpha}^{1} Q_{\\theta}\\left(\\omega_{a}\\right) d \\theta$, and direct computation yields:\n\n$$\n\\bar{Q}_{\\alpha}\\left(\\omega_{a}\\right)=\\left(1-\\frac{1}{\\beta_{a}}\\right) Q_{\\alpha}\\left(\\omega_{a}\\right)\n$$\n\nIn this case, problem (1) can be expressed as:\n\n$$\n\\max _{a \\in A}\\left\\{u(a)+\\left(1-\\frac{1}{\\beta_{a}}\\right) Q_{\\alpha}\\left(\\omega_{a}\\right)\\right\\}\n$$\n\n5.2. Proof of Proposition 4. $\\rho^{R U M}$ increasing $\\Longrightarrow$ Eq. (11). Assume $\\rho^{R U M}$ is increasing in $\\alpha$ for pair $\\left(a, a^{\\prime}\\right)$. By definition, the probability of choosing $a$ over $a^{\\prime}$ corresponds to $\\rho_{\\alpha}^{R U M}\\left(a, a^{\\prime}\\right)=\\mathbb{P}\\left(V_{\\alpha}(a)+\\epsilon_{a} \\geq V_{\\alpha}\\left(a^{\\prime}\\right)+\\epsilon_{a^{\\prime}}\\right)=\\mathbb{P}\\left(V_{\\alpha}(a)-\\right.$ $\\left.V_{\\alpha}\\left(a^{\\prime}\\right) \\geq \\epsilon_{a}-\\epsilon_{a^{\\prime}}\\right)$.\n\nWe note that distribution of the difference $\\epsilon_{a}-\\epsilon_{a^{\\prime}}$ is a continuous random variable with corresponding CDF $\\Psi$ and density function $\\psi$. In particular, we can write $\\rho_{\\alpha}^{R U M}\\left(a, a^{\\prime}\\right)=\\Psi\\left(V_{\\alpha}(a)-V_{\\alpha}\\left(a^{\\prime}\\right)\\right)$. Then, using Corollary 1(ii) yields: $\\frac{\\partial \\rho_{\\alpha}^{R U M}\\left(a, a^{\\prime}\\right)}{\\partial \\alpha}=\\frac{\\psi\\left(\\Delta V_{\\alpha}\\left(a, a^{\\prime}\\right)\\right)}{(1-\\alpha)^{2}}\\left(\\mathbb{E}_{F}\\left(\\max \\left\\{u(a, \\omega)-Q_{\\alpha}(a), 0\\right\\}\\right)-\\mathbb{E}_{F}\\left(\\max \\left\\{u\\left(a^{\\prime}, \\omega\\right)-Q_{\\alpha}\\left(a^{\\prime}\\right), 0\\right\\}\\right) \\geq 0\\right.$, where $\\Delta V_{\\alpha}\\left(a, a^{\\prime}\\right) \\triangleq V_{\\alpha}(a)-V_{\\alpha}\\left(a^{\\prime}\\right)$. Given that $\\psi$ is a positive density, we know $\\mathrm{t} \\frac{\\psi\\left(V_{\\alpha}(a)-V_{\\alpha}\\left(a^{\\prime}\\right)\\right)}{(1-\\alpha)^{2}}>0$ must hold:\n\n$$\n\\mathbb{E}_{F}\\left(\\max \\left\\{u(a, \\omega)-Q_{\\alpha}(a), 0\\right\\}\\right) \\geq \\mathbb{E}_{F}\\left(\\max \\left\\{u\\left(a^{\\prime}, \\omega\\right)-Q_{\\alpha}\\left(a^{\\prime}\\right), 0\\right\\}\\right) \\quad \\forall \\alpha \\in(0,1)\n$$\n\nEq. $(11) \\Longrightarrow \\rho^{R U M}$ is monotone. Assume $\\mathbb{E}_{F}\\left(\\max \\left\\{u(a, \\omega)-Q_{\\alpha}(a), 0\\right\\}\\right) \\geq$ $\\mathbb{E}_{F}\\left(\\max \\left\\{u\\left(a^{\\prime}, \\omega\\right)-Q_{\\alpha}\\left(a^{\\prime}\\right), 0\\right\\}\\right) \\geq 0$ holds for all $\\alpha \\in(0,1)$.\n\nWe now show that The CDF $\\Psi$ characterizing the choice of $a$ over $a^{\\prime}$ must be increasing when Eq. (11) holds. In particular, we know $\\rho^{R U M}\\left(a, a^{\\prime}\\right)=$ $\\Psi\\left(V_{\\alpha}(a)-V_{\\alpha}\\left(a^{\\prime}\\right)\\right)$. Then computing $\\frac{\\partial \\rho^{R U M}\\left(a, a^{\\prime}\\right)}{\\partial \\alpha}$ we find that:\n$\\frac{\\partial \\rho^{R U M}\\left(a, a^{\\prime}\\right)}{\\partial \\alpha}=\\frac{\\psi\\left(\\Delta V_{\\alpha}\\left(a, a^{\\prime}\\right)\\right)}{(1-\\alpha)^{2}}\\left(\\mathbb{E}_{F}\\left(\\max \\left\\{u(a, \\omega)-Q_{\\alpha}(a), 0\\right\\}\\right)-\\mathbb{E}_{F}\\left(\\max \\left\\{u\\left(a^{\\prime}, \\omega\\right)-Q_{\\alpha}\\left(a^{\\prime}\\right), 0\\right\\}\\right) \\geq 0\\right.$,\nwith $\\Delta V_{\\alpha}\\left(a, a^{\\prime}\\right)=V_{\\alpha}(a)-V_{\\alpha}\\left(a^{\\prime}\\right)$. Given that the term $\\frac{\\psi\\left(\\Delta V_{\\alpha}\\left(a, a^{\\prime}\\right)\\right)}{(1-\\alpha)^{2}>0}, \\rho^{R U M}\\left(a, a^{\\prime}\\right)$ being monotone implies that for all $\\alpha \\in(0,1)$ the following inequality must hold:\n\n$$\n\\mathbb{E}_{F}\\left(\\max \\left\\{u(a, \\omega)-Q_{\\alpha}(a), 0\\right\\}\\right) \\geq \\mathbb{E}_{F}\\left(\\max \\left\\{u\\left(a^{\\prime}, \\omega\\right)-Q_{\\alpha}\\left(a^{\\prime}\\right), 0\\right\\}\\right) \\geq 0)\n$$\n\n5.3. Proof of Corollary 2. We have defined the random variable influencing payoffs by $\\omega_{a} \\sim N\\left(0, \\omega_{a}^{2}\\right)$, and following our previous notation $\\omega_{a}$ 's $\\alpha$-quantile as $Q_{\\alpha}(\\omega)$. From here, we can define the random variable of potential utility outcomes corresponding with $u\\left(a, \\omega_{a}\\right)=u(a)-e^{-r \\omega_{a}}$. We denote the density function of this distribution as $P_{a}$, and note that it is continuous and strictly increasing in $\\omega_{a}$. Note that the WT value associated with action $a$ is given by:\n\n$$\n\\begin{aligned}\n& V_{\\alpha}(a)=\\mathbb{E}_{P_{a}}(u(a, \\omega) \\mid \\omega \\geq Q_{\\alpha}(\\omega)) \\\\\n& =\\frac{1}{1-\\alpha} \\int_{Q_{\\alpha}(\\omega)}^{\\infty} \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left(-\\frac{x^{2}}{2 \\sigma^{2}}\\right)(u(a)-\\exp (-r x)) d x \\\\\n& =q(a)-\\frac{1}{1-\\alpha} \\int_{Q_{\\alpha}(\\omega)}^{\\infty} \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left(-\\frac{x^{2}}{2 \\sigma^{2}}-r x\\right) d x \\\\\n& =q(a)-\\frac{1}{1-\\alpha} \\frac{1}{2}\\left[\\operatorname{erf}\\left(\\frac{r \\sigma^{2}+x}{\\sqrt{2} \\sigma}\\right) \\exp \\left(\\frac{1}{2} r^{2} \\sigma^{2}\\right)\\right]_{Q_{\\alpha}(\\omega)}^{\\infty} \\\\\n& =q(a)-\\frac{1}{1-\\alpha} \\frac{1}{2} \\exp \\left(\\frac{1}{2} r^{2} \\sigma^{2}\\right)\\left(1-\\operatorname{erf}\\left(\\frac{r \\sigma^{2}+x}{\\sqrt{2} \\sigma}\\right)\\right)\n\\end{aligned}\n$$\n\nFinally, making use of the fact that $\\operatorname{erf}(z / \\sqrt{2})=2 \\Phi(z)-1$, we get:\n\n$$\nV_{\\alpha}(a)=u(a)-\\frac{1}{(1-\\alpha)} \\exp \\left(\\frac{1}{2} r^{2} \\sigma^{2}\\right)\\left(1-\\Phi\\left(r \\sigma+\\frac{1}{\\sigma} Q_{\\alpha}\\left(\\omega_{a}\\right)\\right)\\right)\n$$\n\nSo the WT agent with optimism parameter $\\alpha$ solves:\n\n$$\n\\max _{a \\in A}\\left\\{u(a)-\\frac{1}{(1-\\alpha)} \\exp \\left(\\frac{1}{2} r^{2} \\sigma^{2}\\right)\\left(1-\\Phi\\left(r \\sigma+\\frac{1}{\\sigma} Q_{\\alpha}\\left(\\omega_{a}\\right)\\right)\\right)\\right\\}\n$$", "tables": {}, "images": {}}, {"section_id": 9, "text": "# Online Material: Closed-form expressions for \n\n$$\n\\mathbb{E}_{F_{a}}\\left(\\omega_{a} \\mid \\omega_{a} \\geq Q_{\\alpha}\\left(\\omega_{a}\\right)\\right)\n$$\n\nIn this section we describe several distributions that yield closed-form expressions for $\\mathbb{E}_{F_{a}}\\left(\\omega_{a} \\mid \\omega_{a} \\geq Q_{\\alpha}\\left(\\omega_{a}\\right)\\right)$. In doing so, we use the results in Norton et al. [2018].\n5.4. The Logistic distribution. For each $a \\in A$, assume that $\\omega_{a} \\sim \\operatorname{Logistic}\\left(\\mu_{a}, s_{a}\\right)$. Setting $\\mu_{a}=0$ and $s_{a}>0$, for all $a \\in A$, we obtain $\\mathbb{E}_{F_{a}}\\left(\\omega_{a}\\right)=0$ and $\\mathbb{V}\\left(\\omega_{a}\\right)=\\frac{s_{a} \\pi^{2}}{3}$. Accordingly,\n\n$$\nF_{a}\\left(\\omega_{a}\\right)=\\frac{1}{1+e^{-\\frac{\\omega_{a}}{s_{a}}}}\n$$\n\nThen $Q_{\\alpha}\\left(\\omega_{a}\\right)=\\ln \\left(\\frac{\\alpha}{1-\\alpha}\\right)$. From Proposition [Norton et al., 2018, Prop. 10] we know that\n\n$$\n\\mathbb{E}_{F_{a}}\\left(\\omega_{a} \\mid \\omega_{a} \\geq Q_{\\alpha}\\left(\\omega_{a}\\right)\\right)=s_{a} \\frac{H(\\alpha)}{1-\\alpha}\n$$\n\nwhere $H(\\alpha) \\triangleq-\\alpha \\ln (\\alpha)-(1-\\alpha) \\ln (1-\\alpha)$. Thus the problem (8) can be expressed as:\n\n$$\n\\max _{a \\in A}\\left\\{u(a)+s_{a} \\frac{H(\\alpha)}{1-\\alpha}\\right\\}\n$$\n\n5.5. The Student-t distribution. Assume $\\omega_{a} \\sim$ Student $-t\\left(\\nu_{a}, s_{a}, \\mu_{a}\\right)$. where $\\nu_{a}>0, s_{a}>0, \\mu_{a}>0$ with $\\mathbb{E}_{F_{a}}\\left(\\omega_{a}\\right)=\\mu_{a}$ and $\\mathbb{V}\\left(\\omega_{a}\\right)=\\frac{s_{a}^{2} \\nu_{a}}{v_{a}-2}$. Setting $\\mu_{a}=0$, the Student $t$ distribution corresponds to\n\n$$\nF_{a}\\left(\\omega_{a}\\right)=1-\\frac{1}{2} \\mathcal{I}_{g\\left(\\omega_{a}\\right)}\\left(\\frac{\\nu_{a}}{2}, \\frac{1}{2}\\right)\n$$\n\nwhere $f_{a}\\left(\\omega_{a}\\right)=\\frac{\\nu_{a}}{\\frac{s_{a}^{2}}{2}+\\nu_{a}} \\cdot \\mathcal{I}_{t}(a, b)$ is the regularized incomplete Beta function, and $\\Gamma(a)$ is the Gamma function.\n\nFrom [Norton et al., 2018, Prop. 12], we know that\n\n$$\n\\mathbb{E}_{F_{a}}\\left(\\omega_{a} \\mid \\omega_{a} \\geq Q_{\\alpha}\\left(\\omega_{a}\\right)\\right)=s_{a}\\left(\\frac{\\nu_{a}+T^{-1}(\\alpha)^{2}}{(v-1)(1-\\alpha)}\\right) l\\left(T^{-1}(\\alpha)\\right)\n$$\n\nwhere $T^{-1}(\\alpha)$ is the inverse of the standardized Student-t cumulative distribution function and $l(\\cdot)$ is the standardized Student-t probability density function.\n\nAccordingly, the DM's problem (8) can be rewritten as:\n\n$$\n\\max _{a \\in A}\\left\\{u(a)+s_{a}\\left(\\frac{\\nu_{a}+T^{-1}(\\alpha)^{2}}{(v-1)(1-\\alpha)}\\right) l\\left(T^{-1}(\\alpha)\\right)\\right\\}\n$$\n\n5.6. The generalized extreme value distribution. Next, we discuss the generalized extreme value (GEV) distribution case. Formally, we assume that $\\omega_{a}$ follows a GEV distribution, which we denote as $\\omega_{a} \\sim G E V\\left(\\mu_{a}, s_{a}, \\xi_{a}\\right)$. Recall that GEV parameters have range $\\mu_{a} \\in \\mathbb{R}, s_{a}>0, \\xi_{a} \\in \\mathbb{R}$. The parameters $\\mu_{a}, s_{a}, \\xi_{a}$ capture location, scale, and shape respectively. The cumulative distribution corresponds to:\n\n$$\nF_{a}\\left(\\omega_{a}\\right)= \\begin{cases}e^{-\\left(1+\\frac{\\xi_{a}\\left(\\omega_{a}-\\mu_{a}\\right)}{s_{a}}\\right)^{\\frac{-1}{\\xi_{a}}}} & \\xi_{a} \\neq 0 \\\\ e^{-e^{-\\left(\\frac{\\omega_{a}-\\mu_{a}}{s_{a}}\\right)}} & \\xi_{a}=0\\end{cases}\n$$\n\nFrom [Norton et al., 2018, Prop. 15] we know that\n\n$\\mathbb{E}_{F_{a}}\\left(\\omega_{a} \\mid \\omega_{a} \\geq Q_{\\alpha}\\left(\\omega_{a}\\right)\\right)= \\begin{cases}\\mu_{a}+\\frac{s_{a}}{\\xi_{a}(1-\\alpha)}\\left[\\Gamma_{L}\\left(1-\\xi_{a}, \\ln \\left(\\frac{1}{\\alpha}\\right)\\right)-(1-\\alpha)\\right] & \\xi_{a} \\neq 0 \\\\ \\mu_{a}+\\frac{s_{a}}{(1-\\alpha)}(y+\\alpha \\ln (-\\ln (\\alpha))-\\operatorname{li}(\\alpha)) & \\xi_{a}=0\\end{cases}$\nwhere $\\Gamma_{L}(a, b)=\\int_{0}^{b} p^{a-1} e^{-p} d p$ is the lower incomplete gamma function, $\\operatorname{li}(x)=$ $\\int_{0}^{\\alpha} \\frac{1}{\\ln p} d p$ is the logarithmic integral function, and $y$ is the Euler-Mascheroni constant.\n\nUsing the expression above we can rewrite the DM's problem (8) accordingly.\n5.7. The Generalized Pareto Distribution. Next, we discuss the generalized extreme value (GEV) distribution case. Formally, we assume that $\\omega_{a}$ follows a GEV distribution, which we denote as $\\omega_{a} \\sim G P D\\left(\\xi_{a}, \\beta_{a}\\right)$. The GPD is characterized by two parameters: $\\xi_{a} \\in \\mathbb{R}$ and $\\beta_{a}>0$, and the density function can be expressed as follows:\n\n$$\nF_{a}\\left(\\omega_{a}\\right)= \\begin{cases}1-\\left(1+\\frac{\\xi_{a} \\omega_{a}}{\\beta_{a}}\\right)^{-1 / \\xi_{a}} & \\xi_{a} \\neq 0 \\\\ 1-\\exp \\left(-\\frac{\\omega_{a}}{\\beta_{a}}\\right) & \\xi_{a}=0\\end{cases}\n$$\n\nwhere $\\omega_{a} \\in[0, \\infty)$ for $\\xi_{a} \\geq 0$ and $\\omega_{a} \\in\\left[0,-\\beta_{a} / \\xi_{a}\\right]$ for $\\xi_{a}<0$.\nThe parameter $\\beta_{a}$ acts to determine the scale of the distribution, while $\\xi_{a}$ determines the shape. In particular, when $\\xi_{a}=0$, the GPD reduces to an exponential distribution. When $\\xi_{a}>0, F_{a}$ represents a Pareto distribution as we explore in section 4.1, albeit with a slightly different parametrization. For the GPD with $\\xi_{a}>0$, the $k$ th moment does not exist when $k \\geq 1 / \\xi_{a}$, similar to the case of the Fr\u00e9chet distribution. Critically, for $\\xi_{a} \\geq 1$, the first moment does not exist and as such the superquantile is not defined. On the other hand, when $\\xi_{a}<0$, the density $F_{a}$ yields the Pareto Type II distribution. For $\\xi_{a}>1$, $\\mathbb{E}\\left(\\omega_{a}\\right)=\\infty$, so we focus on the case where $\\xi_{a} \\in(-\\infty, 0) \\cup(0,1)$. The optimal multiplier is given by\n\n$$\n\\lambda_{a}^{*}=\\frac{\\beta_{a}}{\\xi_{a}}\\left((1-\\alpha)^{-\\xi_{a}}-1\\right)\n$$\n\nBy one definition of the superquantile we know that $\\bar{Q}_{\\alpha}(a)=(1-\\alpha)^{-1} \\int_{\\alpha}^{1} Q_{\\theta}(a) d \\theta$, direct computation yields:\n\n$$\n\\bar{Q}_{\\alpha}(a)=\\frac{Q_{\\alpha}\\left(\\omega_{a}\\right)}{1-\\xi_{a}}+\\frac{\\beta_{a}}{\\xi_{a}}\\left(\\left(1-\\xi_{a}\\right)^{-1}-(1-\\alpha)^{-1}\\right)\n$$\n\nUsing the expression above we can rewrite the DM's problem (8) accordingly. And similar analysis yields the DM's problem when $\\xi_{a}=0$.", "tables": {}, "images": {}}], "id": "2402.01892v2", "authors": ["Jarrod Burgh", "Emerson Melo"], "categories": ["econ.TH"], "abstract": "We present a model elucidating wishful thinking, which comprehensively\nincorporates both the costs and benefits associated with biased beliefs. Our\nfindings reveal that wishful thinking behavior can be characterized as\nequivalent to superquantile-utility maximization within the domain of threshold\nbeliefs distortion cost functions. By leveraging this equivalence, we establish\nWT as driving decision-makers to exhibit a preference for choices characterized\nby skewness and increased risk. Furthermore, we discuss how our framework\nfacilitates the study of optimistic stochastic choice and optimistic risk\naversion.", "updated": "2025-01-28T04:48:59Z", "published": "2024-02-02T20:37:56Z"}