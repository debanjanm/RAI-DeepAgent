{"title": "Paying to Do Better: Games with Payments between Learning Agents", "sections": [{"section_id": 0, "text": "#### Abstract\n\nIn repeated games, such as auctions, players typically use learning algorithms to choose their actions. The use of such autonomous learning agents has become widespread on online platforms. In this paper, we explore the impact of players incorporating monetary transfer policies into their agents' algorithms, aiming to influence behavior in their favor through the dynamics between the agents. Our focus is on understanding when players have incentives to make use of monetary transfers, how such payments may affect learning dynamics, and what the implications are for welfare and its distribution among the players. We propose a simple and general game-theoretic model to capture such scenarios. Our results on general games show that in a very broad class of games, self-interested players benefit from letting their learning agents make payments to other learners during the game dynamics, and that in many cases, this kind of behavior improves welfare for all players. Our results on first- and second-price auctions show that in equilibria of the \"payment policy game,\" the agents' dynamics reach strong collusive outcomes with low revenue for the auctioneer. These results raise new questions and highlight a challenge for mechanism design in systems where automated learning agents can benefit from interacting with their peers in the digital ecosystem and outside the boundaries of the mechanism.", "tables": {}, "images": {}}, {"section_id": 1, "text": "## 1 Introduction\n\nAutonomous learning agents have become widespread on online platforms, playing an increasingly pivotal role in many markets and economic ecosystems. A prominent example is the multi-billion-dollar online industry of ad auctions, operated by major companies such as Google, Meta, Amazon, and Microsoft. Due, in part, to the speed and complexity of these auctions, automated bidding has emerged as the dominant approach, with bidding traffic managed by various automated agents, provided either directly by the platforms themselves, or by third-party platforms. Typically, these agents get some high-level instructions from their users about their objectives and allowed action space, and then they interact with other agents in long sequences of repeated games (which could include thousands or millions of auctions per hour), using some learning algorithm to optimize the long-term payoffs for their users.\nWe are interested in repeated interactions of this sort where players use learning agents to play a repeated game on their behalf. We take as a point of departure the observation that, in this setting, users may wish to allow their agents to make payments to other agents in order to influence the course of the game's dynamic in their favor. In this study, we model and analyze the effect of considering such payments between the agents on the long-term outcomes of the interaction.\n\n![table_0](table_0)\n\nFigure 1: A prisoner's dilemma game.\n\nThe idea that payments and other types of financial benefits outside of a mechanism can affect behavior in the mechanism has received considerable attention in areas ranging from blockchain fee markets, where it has become one of the guiding principles in the evolving design of these markets ${ }^{1}$ (see [28, 94] and $[11,12,29])$, to fair division $[78,80]$. We defer a more extended discussion of related work to Section 3.\n\nThe possibility that learning agents could transfer payments among themselves during their game dynamics raises several basic questions. First, when do players have incentives to let their agents use payments? Second, how do payments between the learning agents affect their dynamics? And third, what are the long-term implications of payments among the agents on the players' utilities and the social welfare? (And in the application of auctions, the revenue for the auctioneer?)\n\nAs in much of the prior literature (e.g., $[19,32,38,46,56,63,105]$ ), we model agents as no-regret learners; that is, they use learning strategies that result in outcomes satisfying the no-regret condition in the long term. Unfortunately, as is well known, in many games no-regret agents can end up playing strategies that yield low utility compared to cooperative outcomes that could potentially have been obtained in the game. E.g., in the prisoner's dilemma, they end up defecting, since that is the dominant strategy. This has led to a great deal of interest in designing mechanisms where we can get, in some sense, better outcomes. Notably, unlike the literature on mechanism design, where a platform or some external entity provides incentives or recommendations aiming to improve welfare $[10,13,76,103]$, in our case, there is no external entity. All payments are made at the expense of the players, who are solely interested in maximizing their own individual payoffs.\n\nBefore giving an example, let us sketch the general structure of the model we have in mind. As mentioned, there is an underlying game, and the model of what we call a payment policy game (or just a payment game) proceeds in two phases. In the first phase, each player $i$ chooses a payment policy, that determines, for each other agent $j$, how much agent $i$ will pay agent $j$ at each round in the agents' dynamics as a function of the outcome (i.e., the joint action profile performed by the agents) in the underlying game in that round. In the second phase, the agents play the underlying game repeatedly, choosing their actions according to their learning algorithm (taking the payments into account). See Section 2 for the formal description of the model.\n\nWarm-up example: With this background, consider the variant of the prisoner's dilemma ${ }^{2}$ game shown in Figure 1. As mentioned above, standard analysis shows that when both players use no-regret learning agents, each agent will quickly learn to play its dominant strategy, which is to defect (i.e., play strategy $D$ ); the dynamics will converge to the Nash equilibrium of the stage game where both agents always defect and each player gets an expected payoff of $1 / 3$.\n\nNow we ask what can player 1 achieve if she allows her agent to make payments to the other agent during the game dynamic? Consider the payment policy where player 1's agent pays player 2's agent $1 / 3+\\epsilon$ if player 2's agent cooperates, for some $\\epsilon>0$, and pays nothing if player 2's agent defects. It is easy to see\n\n[^0]\n[^0]:    ${ }^{1}$ While research in this area has focused on manipulations involving the auctioneer (the \"miner\" who allocates space for transaction in the next \"block\"), we study the scenario where payments take place among the bidding agents themselves.\n    ${ }^{2}$ Note that this variant is somewhat nonstandard, in that the payoffs are not symmetric.\n\nthat the game with these payments is dominance solvable: by repeatedly eliminating strictly dominated strategies, we are left only with the strategy $(D, C)$ as the unique equilibrium, and so the ensuing dynamics will converge to that outcome (see Appendix A), with payoffs $(2-1 / 3-\\epsilon, 1 / 3+\\epsilon)$ for the two players.\nIt turns out that this outcome can be obtained as an ( $\\epsilon$-)equilibrium ${ }^{3}$ of the payment game. There is also a second similar $\\epsilon$-equilibrium of the payment game, obtained by switching the roles of players 1 and 2, but due to the asymmetry in the payoffs of the underlying game, the social welfare in this second equilibrium is 1 , not 2 . Importantly, however, both equilibria are Pareto improvements over the Nash equilibrium of the underlying game, and the players' welfare significantly increases compared to the game without payments (note, though, that welfare is not necessarily optimal).\nWe show, using a similar analysis, that we get these equilibria and improvement in social welfare in general prisoner's dilemma games whenever the maximum welfare gap in the game is large (above a factor of 2). Moreover, while in the game without payments the price of anarchy (PoA) and price of stability (PoS)-the ratio between the social welfare obtained from the worst-case (respectively, best-case) Nash equilibrium and the optimal social welfare-are unbounded, with payments, both PoS and PoA are bounded by a factor of 2 in the symmetric case, and in the asymmetric case $P o S$ is bounded, but $P o A$ is not, due to the welfare gap between the two equilibria of the payment game. See Appendix A for more details.\nAlthough prisoner's dilemma is very simple (both players have strictly dominant strategies), the observations we made regarding this example apply more broadly. Specifically, in many games, players have incentives to use payments between their agents, and the use of payments can often enable players to reach more cooperative outcomes, with higher social welfare.\n\nOur contribution: We study the incentives of players to use payments with their learning agents and the potential impact of such payments among learning agents on learning dynamics and equilibrium outcomes.\nFrom a high-level perspective, our results highlight a challenge for auction design and market design more broadly: we show that users of learning agents quite generally have incentives to allow their automated agents to make payments during their interactions. When these incentives are coupled with the right technology-particularly, sophisticated AI agents and flexible transaction media, such as those on blockchain platforms-one can easily imagine an outlook where agents trade among themselves \"under the hood,\" and the associated markets change their behavior, equilibria, and outcomes. Our results demonstrate that these changes can be very significant, underlining, on the one hand, a potential improvement in efficiency, but on the other hand, the need to better understand the potential impact on concrete systems, to be able to design them accordingly.\nWe propose a model of these interactions for general games in Section 2. As our main case study, we analyze first- and second-price auctions in Section 4. In the following sections, we study general properties of payment games: Section 5 focuses on the incentives players have to initiate unilateral payments, and Section 6 focuses on the special case of two-player games. Our results in all these settings provide comparative statics between the outcomes of learning dynamics without payments and those obtained with learning agents in equilibria of the payment game between their users.\n\nSummary of main theorems: In second-price auctions, Theorem 1 shows that players have incentives to provide payment policies to their agents (i.e., using learning agents in the auction without using payments is not a Nash equilibrium), and that in an equilibrium of the payment game, in the long run, the players may reach full collusion, where they capture almost the entire welfare, leaving the auctioneer with vanishing revenue as $T \\rightarrow \\infty$. This result applies for any number of players with generic (i.e., not exactly equal) valuations.\n\n[^0]\n[^0]:    ${ }^{3}$ In an $\\epsilon$-equilibrium, no player can increase their payoff by more than $\\epsilon$ by altering their strategy.\n\nIn first-price auctions, Theorem 2 shows that also here, players have incentives to use payments. So using automated bidders without using payments is not an equilibrium. This first part of the theorem extends to any number of players (see Appendix B for further details). For the special case of two players, the theorem shows that equilibria of the payment game lead to low (but in this case, still positive) revenue. ${ }^{4}$\n\nIn Section 5, we show that under very broad conditions, players have incentives to use payments with their learning agents, also beyond auctions. Theorems 3 and 4 , show that in a broad class of finite games, ${ }^{5}$ there is at least some player who has the incentive to use payments, and we characterize cases where a payment policy applied by a single agent can drive the dynamics toward the optimal-welfare outcome while improving the payoff for the associated player as well.\nIn Section 6, we analyze the important case of bilateral interactions. Two-player games have unique properties in payment games, intuitively, stemming from the fact that any payment must be desirable to both players, as there are no other externalities on the associated agents from other interactions. Theorem 5 shows that in two-player games, payments always result in Pareto improvements compared to the game without payments. Furthermore, Theorem 6 demonstrates that in a broad class of games-extending even to those with strictly dominant strategies, as illustrated in our prisoner's dilemma example above-at least one player will strictly benefit from using payments. Consequently, not using payments is not a stable behavior.", "tables": {"table_0": "| Player 1 | $C$ | $D$ |\n| :--: | :--: | :--: |\n|  | $2 / 3,2 / 3$ | 0,1 |\n|  | $2,0$ | $1 / 3,1 / 3$ |"}, "images": {}}, {"section_id": 2, "text": "# 2 Model \n\nWe consider scenarios where we have players using learning agents in some repeated game, and study the setting where players can augment their agents by allowing them to make payments to other agents based on the actions of these agents during the game dynamics. The learning algorithms used by the agents are assumed to satisfy the regret-minimization property, ${ }^{6}$ but agents are not restricted to using any particular algorithm, and the players themselves are interested in their own long-term payoffs. As our analysis relies on the regret-minimization property itself and considers outcomes in the limit $T \\rightarrow \\infty$, where $T$ is the number of game rounds, our results apply regardless of the specific regret bounds or details of the learning algorithms used, as long as the agents achieve regret sublinear in $T$. Our model has the following components.\n\n- The game: There is an underlying game $\\Gamma=\\left\\{[n], S,\\left\\{u_{i}\\right\\}_{i=1}^{n}\\right\\}$, where $[n]$ is the set of players, $S$ is the space of joint actions, and $u_{i}: S \\rightarrow[0,1], i=1, \\ldots, n$ are the utility functions in that game.\n- Agents: Every player uses a no-regret agent to play the game on their behalf for $T$ rounds. Denote the set of these agents by $A$, where $A_{i} \\in A$ is the agent of player $i \\in[n]$. Agents choose actions using their no-regret algorithms. The action of agent $A_{i}$ at time $t \\in[T]$ is denoted $s_{i}^{t}$ and the action profile of all the agents is denoted $s^{t}$.\n- Payments: In addition to choosing actions, the agents make payments to other agents that depend on the actions $s^{t}$ chosen by the agents, according to payment policies defined by the associated players.\n- Payment policies: Each player $i$ chooses a policy for her own agent that determines, for each action profile $s \\in S$ and player $j \\in[n] \\backslash\\{i\\}$, the payment $p_{i j}(s) \\in \\mathbb{R}_{+}$from agent $i$ to agent $j$ when the\n\n[^0]\n[^0]:    ${ }^{4}$ En route, we present what is, to the best of our knowledge, the first simple dynamic that approaches the minimum-revenue coarse correlated equilibrium of the first-price auction as established in [41]; see Observation 1.\n    ${ }^{5}$ Finite games are games with discrete action sets and bounded payoffs. Note that in the general model of auctions, the bid space is continuous, and so our analysis in that setting is distinct from that of Theorems 3 and 4.\n    ${ }^{6}$ For completeness, we provide standard definitions in Appendix C.\n\noutcome in the most recent step is $s$. We assume that payments are bounded: $p_{i j}(s) \\in[0, M]$, where $M \\in \\mathbb{R}_{+}$is some large constant.\n\n- Agent utilities: In every step $t$, the agents play an action profile $s^{t} \\in S$ and observe the realized outcome and payments. The utility for agent $i$ at time $t$ when the action profile that was played was $s^{t}$ is $v_{i}^{t}=u_{i}\\left(s^{t}\\right)+\\sum_{j \\neq i}\\left(p_{j i}\\left(s^{t}\\right)-p_{i j}\\left(s^{t}\\right)\\right)$.\n- Player utilities: The players' utilities are their long-term average payoffs: $U_{i}^{T}=\\mathbb{E}\\left[\\frac{1}{T} \\sum_{t=1}^{T} v_{i}^{t}\\right]$; we are particularly interested in the limit $U_{i}=\\lim _{T \\rightarrow \\infty} U_{i}^{T}$.\n- Since in the analysis of long-term payoffs, finite-time costs vanish, we assume w.l.o.g. that if a player is asymptotically (in the limit $T \\rightarrow \\infty$ ) indifferent between making a payment and not making the payment, the player prefers not making the payment.\n\nThe model above defines a payment-policy game (in short, a payment game) between users of learning agents that is specified by $\\Gamma, A$, and $T$. In order to understand the basic properties of payment-policy games and how the incentives of players change compared to games without payments, our analysis of equilibria and potential deviations focuses on one-shot, full-information payment-policy games. A fundamental question that arises is: when would players have incentives to use payment policies? Conversely: what are the conditions for a game to be \"stable\" in the sense that players do not have incentives to use such manipulations?\n\nDefinition 1. A game $\\Gamma$ is stable for a set of learning agents if zero payments are an equilibrium of the payment-policy game associated with $\\Gamma$ with these agents. A game is stable if it is stable for any set of regret-minimizing agents for the players.", "tables": {}, "images": {}}, {"section_id": 3, "text": "# 3 Further Related Work \n\nLearning in games: This paper follows a long research tradition on learning and dynamics in games, from early work of Brown, Robinson, Blackwell, and Hannan in the 1950s [16, 23, 52, 91], through seminal work in the following decades $[47,48,54]$ and continuously since $[1,18,30,31,45,56,61,62,63,64,66,74,98]$. See $[27,55]$ for an overview of the foundations of the field. The notion of regret has been central throughout this work as a tool to define learning outcomes and objectives and design algorithms to achieve them.\n\nRegret minimization in auctions: No-regret learning has been widely studied in auctions, with two prominent lines of work focusing on the price of anarchy in various auction formats with regret-minimizing bidders $[17,25,32,56,92,95,99]$ and on the problem of inferring bidder preferences, where such bidder behavior is either assumed or empirically verified [49, 82, 83, 84]. Other work has studied automated bidding algorithms for auctions with more complex features, such as budget constraints [14, 34, 45, 44, 70], or learning reserve prices $[26,75,96]$. In [3, 87], regret minimization is used as a prediction model for bidder behavior. Importantly, [82, 87] provide empirical evidence from large auction datasets showing that bidder behavior in practice is, by and large, consistent with no-regret learning outcomes. Learning dynamics in first- and second-price auctions and their convergence properties have been studied in a broad range of work $[15,21,32,33,43,45,44,63,64,70]$.\n\nMetagames: A recent line of work, following [63, 64], studies metagames between users of learning agents, in which players set parameters for their agents, which then repeatedly interact in some underlying game (e.g., an auction, a market, or an abstract normal-form game). The utilities in the metagame are determined by the long-term outcomes of the agents' dynamics. These papers focus on analyzing the average outcomes of regret-minimizing agents and their implications on users' incentives to misreport their preferences to\n\ntheir own agents. Further research has explored metagames in randomized auctions [2] as well as strategic budget selection in auctions [4, 42, 73] and its implications to welfare and revenue.\nOur model is related to the metagame framework but addresses a distinct interaction type that has not been analyzed for learning agents: payments between agents. We show that payments between agents have a markedly different effect on the agents' dynamics, leading to different analyses and results in auctions and other games compared to the strategic parameter reports studied in prior work. For example, in both firstand second-price auctions, equilibrium bids and revenues are lower in our payment-based scenario than in prior metagame results [63, 2].\nOptimization against learning agents: An different line of research on interactions with learners considers scenarios where an optimizer interacts with a learning agent, such as an auctioneer optimizing auction rules against a learning buyer [22]. This has been extended to studying cases with multiple buyers [24], general two-player games [6, 35], Bayesian games [71], and repeated contracting [51]. While that line of work shares the premise of players committing to using learning algorithms, its focus is different: it does not study payments between the agents, and furthermore, it addresses an optimization problem where a single player solves for the best response to a fixed learning algorithm, while we study a game (where none of the players is a Stackelberg leader) and the equilibrium outcomes that arise from the long-term dynamics of multiple learning agents.\n\nCooperation in repeated games: The question of how distributed and self-interested players can achieve cooperative or efficient outcomes is a broad topic, studied across various, often separate, fields. A classic approach addresses this challenge through mechanism design [81, 85] and implementation theory [57, 72]. Somewhat closer to our work are papers that study how an external mechanism designer can minimize the exogenous payments she needs to make to the players in order to implement particular outcomes in the game (see, e.g., $[10,76,103]$ ). By contrast, we study the impact of payments that automated agents could make among themselves; our analysis does not consider a mechanism-design problem ${ }^{7}$ and there are no external funds or a directing hand. An additional strand of work from the reinforcement learning (RL) and artificial intelligence literature studies how distributed RL algorithms can jointly reach cooperative outcomes in sequential social dilemmas [9, 39, 60, 69, 102]. A third line of work considers the notion of program equilibrium [68, 88, 89, 100], in which each player declares a program and each program can read the commitments made in the other programs and condition actions in the game on those commitments. This model, however, is very different from our model.\nIn comparison to research on collaborative outcomes from the perspective of cooperative game theory [79], we note that while in our payment game the players do manage to share, to some extent, the welfare they obtain, the game is not cooperative. In particular, an equilibrium of the payment game is not necessarily an element of perhaps the most standard solution concept in cooperative games, the core [50]. This can be clearly seen, for instance, in our analysis of first-price auctions, where in equilibrium the bidders do not play an action profile in the core of their game (thinking of the auction mechanism as set, and the game as taking place only between the bidders).\n\nGames with monetary transfers: The concept of using payments to incentivize desired behaviors in games is a well-established idea. Payments between players have been studied in the context of social choice [53] and fair division [78, 80], and are a central concept in the broad literature on contract theory and principal-agent problems. For an introductory overview on this literature, we refer interested readers to $[20,36,67]$.\nMost work in this area involves a \"principal\" who provides incentives to agents, thereby facing a contract-\n\n[^0]\n[^0]:    ${ }^{7}$ Designing payment protocols to facilitate particular types of payments between the players to optimize social welfare is an interesting research avenue, but we do not pursue it here.\n\ndesign or optimization problem rather than acting as a strategic player in the game. Notable papers on contracts more closely related include [58], which studies multi-lateral payment contracts in one-shot interactions; [51, 104], which examine learning in repeated contracts; and [90], which explores scenarios where a player extracts fees from others by using binding contracts to alter the equilibrium of the game. Our model however, diverges significantly from the standard contract framework. Instead of focusing on principal-agent dynamics or external incentives injected into the game, we analyze scenarios where players choose to augment their learning agents with the capacity to make payments. Our primary interest lies in how these payments influence the agents' learning dynamics and, consequently, the outcomes of the games they play. Other work on games with payments related to ours include [37] and [65], who study sequential games with transfers in which players make sequential commitments, responding rationally to the commitments made by previous players. They study conditions where the sequential commitment structure leads to a unique subgame perfect equilibrium with full welfare. These works do not deal with learning agents and their setting and analysis differ significantly from ours.", "tables": {}, "images": {}}, {"section_id": 4, "text": "# 4 Auctions with Payments between Learning Agents \n\nTo gain a deeper understanding of the incentives of users in online platforms to use payments with their learning agents and the potential impact of such payments, we focus on one class of games that has already been widely analyzed: auctions with automated bidders. We consider the simplest model of first- and second-price auctions, where at each time $t \\in[T]$ a single identical item is sold. Each player $i$ has a value $v_{i}$ for the item, and we index the players in decreasing order of their values, $v_{1} \\geq v_{2} \\geq \\cdots \\geq v_{n}$. At round $t$, each agent submits a bid $b_{i}^{t}$ and the auction mechanism determines the identity of the winner and a price $p^{t}$. The payoff for the winning agent from the auction is $v_{i}-p^{t}$; the other agents get payoff zero. In addition to payoffs from the auction, agents get a payoff according to the payments between the agents (as defined in Section 2). Utilities are additive over game rounds. In the first-price auction, the payment is equal to the highest bid; in the second-price auction, the payment is the second-highest bid. In both cases, the highest bidder wins, and we assume tie-breaking according to the index of the agent (as is done, e.g., in [41]), so that if $i<j$ and $i$ and $j$ both have the same top bid, then $i$ is taken to be the winner. All our analyses are similar for arbitrary tie-breaking rules, but breaking ties in favor of the highest-value agent simplifies the presentation.", "tables": {}, "images": {}}, {"section_id": 5, "text": "### 4.1 Second-price auctions\n\nThe second-price auction has been widely studied [101] (see Section 3 for further references). While the auction is known to be incentive-compatible (or \"truthful\"), it is also known that truthful bidding forms only one out of many Nash equilibria of the stage game. In the context of learning dynamics, it has been shown that regret-minimizing agents in this auction do not converge to the truthful equilibrium; instead, they reach some degree of tacit collusion [63] with lower revenue to the auctioneer than that obtained under truthful bids.\nSpecifically, simplifying slightly, second-price auctions have two types of non-truthful equilibria. The first type is \"overbidding equilibria,\" where the high-value player bids anything above her value and the low-value player bids anything below the high value. The second type is \"low-revenue equilibria,\" where the high-value player bids anything above the low value and the low-value player bids anything below the low value. ${ }^{8}$ The latter type is especially interesting for our setting since any mixture of such equilibria\n\n[^0]\n[^0]:    ${ }^{8}$ Both types of equilibria arise for any number of players $n$; we describe the two-player case for ease of exposition.\n\nis consistent with regret minimization, but yields high welfare to the players. This suggests that when learning agents exchange payments, the high-valued agent may be able to use payments to influence the dynamics with the other agents to induce a better equilibrium for himself.\nWe show that, indeed, when agents \"trade outside of the mechanism\" in this way during their learning dynamics, this kind of collusion emerges from the agents' interaction in a strong way, potentially leading to zero revenue for the auctioneer.\n\nTheorem 1. The single-item second-price auction, where the values of the top two valued players are $v_{1}>v_{2}$, is not stable for any regret-minimizing agents for the players. Furthermore, the payment-policy game of this auction has an $\\epsilon$-equilibrium where the players capture the full welfare, and the auctioneer gets zero revenue.\n\nThe idea of the proof is, first, to construct a unilateral payment policy for player 1, parameterized by a single parameter $\\epsilon$ that determines the amount that agent 1 pays to the other agents, such that this policy induces a dynamic where player 1's (i.e., the high player's) agent bids its true value and all the other learning agents bid zero. We then show that for every other player, using the zero-payment policy is in fact a best response, and that the (net) payoff for the high-valued player can be arbitrarily close to the full welfare, so player 1 cannot improve her payoff by more than $\\epsilon$ for any $\\epsilon>0$. (Note that with the second-price payment rule, if the agents were not restricted to using finite payments, the players would be locked into a game without an equilibrium, where each player tries to commit to making the highest bid and incentivize the others to bid zero.)\n\nProof. (Theorem 1). Consider a repeated second-price auction with a single item sold in every step, and $n$ players with values $v_{1}>v_{2} \\geq \\cdots \\geq v_{n}$. Assume that the total payment that a player makes is bounded by some large constant $M>2 n v_{1}$. Consider the following profile of payment policies. Every player $j>1$ uses the policy of always paying zero. Choose $\\epsilon$ with $0<\\epsilon<\\left(v_{1}-v_{2}\\right) / n$. The payment policy for player 1 is specified by the following conditions. (1) Whenever $b_{1}=v_{1}$, make a payment $p_{1 j}$ to every player $j>1$ of $\\epsilon /(n-1)$ if $b_{j}=0$ and zero otherwise. (2) If agent 1 bids $b_{1} \\neq v_{1}$, then she pays $p_{1 j}=\\frac{M}{n-1}$ to every other player $j>1$. Note that the maximum payment according to these conditions is $M$, as required. We continue with the following claim.\n\nClaim 1. With these payments, bidding $v_{1}$ is a strictly dominant strategy for agent 1.\nProof. To see this, fix a bid profile for the other agents $2, \\ldots, n$, let $b_{0}$ denote the maximum bid of the other agents, and let $p$ denote the total payment to the other agents due to condition (1). We have the following cases.\n\nCase $1 b_{0} \\leq v_{1}$ : In this case, the bid $v_{1}$ gives agent 1 a utility of $v_{1}-b_{0}-p$. Every other bid $b \\neq v_{1}$ and $b \\geq b_{0}$ gives a utility of $v_{1}-b_{0}-M$, which is strictly less. Every losing bid $b<b_{0}$ gives a utility of $-M$, which is also strictly less.\n\nCase $2 b_{0}>v_{1}$ (if agents overbid): Here every winning bid for agent 1 gives a utility of $v_{1}-\\left(b_{0}+M\\right)$, every losing bid not equal to $v_{1}$ gives a utility of $-M$, and bidding exactly $v_{1}$ give a utility of $-p$, which is strictly higher. Therefore, bidding $v_{1}$ is a strictly dominant strategy, and agent 1 who is minimizing regret will learn to only use this strategy.\n\nNext, we claim that since agent 1 bids only $v_{1}$, every other agent has a strict best response, which is to bid zero. This is clear, since for every agent $j>1$, every winning bid gives negative utility, every losing bid $b \\leq v_{1}$ and $b \\neq 0$ gives zero utility, and bidding exactly zero give positive utility. Thus, with these payment policies, due to the regret-minimization property, agent 1 always bids $v_{1}$ and wins the auction, while the\n\nother agents bid zero and get a payment of $\\epsilon /(n-1)$ each. The utility for player 1 in the long term is $v_{1}-\\epsilon$, and the utility for every other player is $\\epsilon /(n-1)$.\nClaim 2. The policy of always paying zero is a best response for every player $j>1$.\nProof. We begin by looking at auctions with $n>2$. In every deviation by some agent $j>1$, in order to ensure that a bid $b<v_{1}$ is not dominated for agent 1 , agent $j$ must pay agent 1 an amount of at least $M-v_{1}$. The utility for player $j$ in this case is bounded from above by $v_{j}-\\left(M-v_{1}\\right)+\\frac{M}{n-1}<2 v_{1}-\\frac{n-2}{n-1} M<2 v_{1}\\left(1-\\frac{n(n-2)}{n-1}\\right)<0$. That is, in every deviation by agent $j$ in which $j$ can win and get a positive utility from the auction (by incentivizing agent 1 to bid below $v_{j}$ with some probability), the payment is too large, so the resulting utility is negative. So player $j$ prefers not to make payments and to get a utility of $\\epsilon /(n-1)$.\nThe case of $n=2$ requires a slightly different argument. In this case, agent 1 pays agent 2 an amount of $M$ whenever agent 1 bids $b \\neq v_{1}$. The fixed bid $v_{1}$ gives agent 1 a utility of at least $v_{1}-\\epsilon$. We claim that this implies that agent 1 almost always wins the auction.\n\nTo see this, notice that a bid for which player 2 pays agent 1 an amount less than $M$ is still dominated and therefore not played by agent 1 . Suppose that there is a bid $b$ for which agent 2 pays agent 1 an amount of $M$. When agent 1 loses with the bid $b$, she gets a utility of zero. When agent 1 wins, she has an expected payoff of $v_{1}-\\mathbb{E}\\left[b_{2} \\mid b>b_{2}\\right]$. Denote by $q$ the probability that $b$ is a winning bid for agent 1 . We have $v_{1}-\\epsilon \\leq q\\left(v_{1}-\\mathbb{E}\\left[b_{2} \\mid b>b_{2}\\right]\\right) \\leq q v_{1}$, so we have $q \\geq 1-\\frac{\\epsilon}{v_{1}}$. Without loss of generality, we set $v_{1}=1$, and so agent 1 wins at least $1-\\epsilon$ fraction of the time.\n\nNow, consider agent 2. By the argument above, agent 2's payoff from using bids that are above zero is at most $v_{2} \\cdot \\epsilon<\\epsilon$. Therefore, using such bids gives agent 2 positive regret compared to bidding zero (when she bids zero, she gets a payment of $\\epsilon$ ). Thus, agent 2 almost always bids zero. It follows that player 2 cannot make payments that increase her utility, so the policy of always paying zero is a best response.\n\nWe are now ready to complete the proof. With the policy profile that we have, player 1 gets a utility of $v_{1}-\\epsilon$. By taking a sufficiently small value of $\\epsilon$, player 1 gets a utility per time step that is arbitrarily close to $v_{1}$. Since $v_{1}$ is the highest possible welfare in the game and player 1 gets $\\epsilon$ close to it for all $\\epsilon>0$, this is an approximate best response for player 1 , and we have an $\\epsilon$-Nash equilibrium. The auctioneer's revenue in this equilibrium is zero, other than vanishing profits during the initial learning phase of the agents.", "tables": {}, "images": {}}, {"section_id": 6, "text": "# 4.2 First-price auctions \n\nIn contrast to the second-price auction, the first-price auction is known not to be incentive compatible. Intuitively, the direct dependence of the utility on the bid requires players to constantly optimize their responses to the bids of the other players. There has thus been significant interest in learning strategies, outcomes, and dynamics in this setting (see Section 3 for references). Interestingly, despite the significant difference from the truthful second-price auction, it is well known (and not hard to see) that the Nash equilibrium of the first-price auction yields the truthful outcome of the second-price auction. It has been shown that mean-based ([22], see Appendix C for the definition) regret-minimization dynamics [63], as well as best-response dynamics [86] can converge only to this outcome.\nIn [41], it was shown that the first-price auction also has \"collusive\" coarse correlated equilibria ${ }^{9}$ (CCE) with lower revenue for the auctioneer than the second-price outcome, and higher utility for the players. The existence of such equilibria poses an opportunity for players to try and reach cooperative outcomes\n\n[^0]\n[^0]:    ${ }^{9} \\mathrm{~A}$ generalization of the notion of correlated equilibrium, equivalent to all players having no external regret; also known as the Hannan set. See Appendix C for references.\n\nand increase their payoffs (at the expense of the auctioneer). However, to the best of our knowledge, no natural process has been described in nearly a decade since that result that attains any of these equilibria.\n\nMoreover, in [63], it is shown that even a scenario where players can manipulate the objective functions of their learning algorithms is not sufficient to reach any form of cooperation. In fact, convergence of standard no-regret agents to the second-price outcome induces a dominant strategy for users to provide the true objectives for their agents. To understand how cooperative outcomes could perhaps still be reached by learners, we observe that in the collusive equilibria described in [41], the low-value player wins in some fraction of the auctions and has positive utility, whereas under simple no-regret dynamics (as those studied in [63]), only a single player wins in the limit. This suggests that payments between the agents during their dynamics could enable the agents to share the welfare and reach cooperative outcomes.\n\nThe following theorem shows that players have an incentive to use payments in a first-price auction, and in equilibria of the payment game, the players reach cooperative outcomes, with a significant reduction in revenue for the auctioneer.\n\nTheorem 2. (1) The single-item first-price auction with two players and any mean-based no-regret bidding agents is not stable: players prefer to use payments. (2) Every equilibrium of the payment game is a strong Pareto improvement (i.e., both players are better off) and has lower revenue for the auctioneer compared to the game without payments.\nRemark. The first part of Theorem 2, showing that first-price auctions are not stable, extends to any number of players by a reduction to a game between the two top-valued players. In this reduction, all the lemmas extend with essentially no change in their proofs. See Appendix B for further details.\n\nWe break the proof into a sequence of lemmas. For ease of readability, we outline the proof here and defer the full formal details to Subsection 4.2.1 at the end of this section. The first part of the proof is the construction of a unilateral payment policy for the high-value player and the analysis of the resulting dynamics. Under this policy, the agent with the higher value pays $\\eta>0$ to the lower-value agent whenever the latter bids zero. We derive the (unique) mixed Nash equilibrium of the game with this payment policy, with $\\eta$ as a parameter (Lemma 1). We then evaluate the utilities of the players in that equilibrium and show that the optimal value of $\\eta$ for the high-value player is half the value of the second player (Lemma 2), and that in this case, the players have higher utilities than in the game without payments. We next prove that in the game between the agents, while the agents do not play a mixed equilibrium and their strategies are correlated, the marginal distributions and payoffs are nevertheless the same as in the mixed Nash equilibrium we derived (Lemma 3). Finally, using the fact that these utilities for the players are achieved through a unilateral payment by the high-value player, we show that they provide a lower bound on the utilities in any equilibrium of the payment-policy game. We now state the lemmas formally.\nLemma 1. Consider the single-item first-price auction with two players and player values $v_{1} \\geq v_{2}$, where player 1's payment policy is such that agent 1 pays $\\eta$ to agent 2 , where $0<\\eta<v_{2}$, whenever agent 2 bids zero. The resulting game between the agents has a unique Nash equilibrium where the cumulative density functions of the bids of agents 1 and 2 are $F_{1}(x)=\\frac{\\eta}{v_{1}-x}$ and $G_{2}(x)=\\frac{v_{1}-v_{2}+\\eta}{v_{1}-x}$, respectively (so the bid density functions are supported on $\\left.\\left[0, v_{2}-\\eta\\right]\\right)$.\nLemma 2. If the agents reach the Nash equilibrium outcomes, the optimal value of $\\eta$ for player 1 is $v_{2} / 2$. With this value of $\\eta$, the utilities for the players are $v_{1}-v_{2}+\\frac{v_{2}^{2}}{4 v_{1}}$ for player 1 and $\\frac{v_{2}}{2}$ for player 2 . The winning frequency of player 2 is in the interval $[0,3 / 8]$, with the lower bound attained as $v_{2} / v_{1} \\rightarrow 0$ and the upper bound attained as $v_{2} / v_{1} \\rightarrow 1$.\n\nThe result above is for Nash equilibrium. While, in principle, no-regret agents may play an arbitrary CCE and not necessarily this outcome, the next lemma shows that the family of Nash-equilibrium distributions\n\n![img-0.jpeg](img-0.jpeg)\n\nFigure 2: Dynamics of Hedge algorithms with payments between agents in first-price auctions.\nparameterized by $\\eta$ captures well the marginal distributions and utilities of the broad family of mean-based [22] no-regret agents in these games.\n\nLemma 3. Consider the game where player 1's agent pays $\\eta$ to player 2's agent whenever the latter agent bids zero. Fix a CCE with marginal distributions $F_{1}$ and $G_{2}$ to which the dynamics of mean-based agents converge with a positive probability. Then, $F_{1}(b)=F_{1}^{N E}(b)=\\frac{\\eta}{v_{2}-b}, G_{2}(b)=G_{2}^{N E}(b)=\\frac{v_{1}-v_{2}+\\eta}{v_{1}-b}$, and the players' utilities are the same as in the Nash equilibrium.\n\nFigure 2 shows simulation results with Hedge agents (a version of multiplicative weights [97]) in a sequence of 100,000 first-price auctions with payments between the agents. The left panel compares the Nash equilibrium theoretical prediction from Lemma 3 with the empirical CDF from the agents' dynamics with $v_{1}=1, v_{2}=0.5$, and agent 1 pays agent $2 \\eta=v_{2} / 2$ when the latter bids zero, as in Lemma 2. The right panel compares the theoretical winning frequencies of the players as specified in Lemma 2 with their empirical winning frequencies as a function of the ratio of values $v_{2} / v_{1}$ in multiple simulations. The long-term marginal bid distributions and winning frequencies are clearly consistent with the theoretical predictions. We observe similar results with other algorithm variants such as follow the perturbed leader and linear multiplicative weights [5]. There is very little variation between simulation instances.\n\nInterestingly, it turns out that these dynamics of the agents with payments recover, as a special case, the known collusive CCE distribution of the auction without payments from [41].\n\nObservation 1. For symmetric bidders with $v_{1}=v_{2}=1$ and payment of $\\eta=1 / e$, the Nash equilibrium bid distribution of the game with payment $\\eta$ is the same as that of the minimum-revenue coarse correlated equilibrium of the standard first-price auction (without payments) given in [41].\n\nNotice, however, that in our game, the players' utilities are different from those of the CCE without payments. In particular, the payment $\\eta$ that results in this CCE distribution is not optimal for player 1, so it is not an equilibrium of the payment-policy game.\n\nWe are now ready to conclude the proof of Theorem 2 by using the above lemmas to establish a lower bound on the utility of the high-value player in any Nash equilibrium of the payment game. The idea is\n\nto use the fact that the game analyzed in our proof is induced by a unilateral payment policy applied by the high-valued player. In any equilibrium, the player 1 can consider the deviation in which she rejects (pays back) all the payments she received and makes this unilateral payment, which leads to a utility of $v_{1}-v_{2}+v_{2}^{2} / 4 v_{1}$.\nTo evaluate the potential loss in welfare in the game considered above (as sometimes a player with a lower value wins), we can analyze the winning frequencies from Lemma 2. The reduction in welfare is equal to the difference $v_{1}-v_{2}$ times the fraction of times in which the low-value player wins. This reduction in welfare is maximized, as can be verified by numerical calculation, when $v_{2} / v_{1} \\approx 0.50959 \\ldots$, at which point the reduction is approximately $8.96 \\%$. When considering the reduction in revenue, since the support of the bids is between zero and $v_{2} / 2$, almost all the payments to the auctioneer are strictly less than $v_{2} / 2$, so the revenue is reduced to less than half the revenue of the outcome of the game without payments. Thus, the players manage to improve their utilities at the expense of the auctioneer, with a relatively small loss in efficiency.", "tables": {}, "images": {"img-0.jpeg": "data:image/jpeg;base64,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"}}, {"section_id": 7, "text": "# 4.2.1 Proof of Theorem 2 \n\nProof. (Lemma 1). We start by assuming that in the game between these agents, parameterized by $\\eta$, there is a mixed Nash equilibrium with continuous CDFs, PDFs with full support on $\\left[0, v_{2}-\\eta\\right]$, and player 2 has a positive probability of bidding zero. The validity of this ansatz will be verified shortly.\nConsider player 1's utility. In equilibrium, she is indifferent between bidding zero and bidding $v_{2}-\\eta$, giving us the size of the point mass for player 2 at zero:\n\n$$\nv_{1}-\\left(v_{2}-\\eta\\right)-G_{2}(0) \\eta=G_{2}(0)\\left(v_{1}-\\eta\\right) \\quad \\Rightarrow \\quad G_{2}(0)=1-\\frac{v_{2}-\\eta}{v_{1}}\n$$\n\nPlayer 1's utility when bidding $x$ is $u_{1}(x, y)=G_{2}(x)\\left(v_{1}-x\\right)-\\chi(y) \\eta$, where $\\chi(y)$ is an indicator which equals 1 if player 2 bids zero (i.e., if $y=0$ ) and equals zero otherwise. Importantly, it is independent of $x$. Player 1 is indifferent between all her bids, so $\\frac{\\partial u_{1}(x, y)}{\\partial x}=0$, which gives\n\n$$\nG_{2}^{\\prime}(x)\\left(v_{1}-x\\right)-G_{2}(x)=0\n$$\n\nWe have an ordinary differential equation with a unique solution of the form $G(x)=\\frac{c}{v_{1}-x}$. Given our initial assumption, we must have continuity at zero, so we get that\n\n$$\nc=v_{2} G_{2}(0)=v_{1}-v_{2}+\\eta\n$$\n\nVerifying the consistency of the support (the CDF must be equal to 1 at the top of the support):\n\n$$\nG_{2}\\left(v_{2}-\\eta\\right)=\\frac{v_{1}-v_{2}+\\eta}{v_{1}-\\left(v_{2}-\\eta\\right)}=1\n$$\n\nSince player 2 is indifferent between bidding $x>0$ and bidding zero and getting a utility of $\\eta$, we have\n\n$$\n\\eta=F_{1}(x)\\left(v_{2}-x\\right) \\quad \\Rightarrow \\quad F_{1}(x)=\\frac{\\eta}{v_{2}-x}\n$$\n\nThus, we have a mixed Nash equilibrium with CDFs\n\n$$\nF_{1}(x)=\\frac{\\eta}{v_{2}-x}, \\quad G_{2}(x)=\\frac{v_{1}-v_{2}+\\eta}{v_{1}-x}\n$$\n\nas stated in the lemma.\n\nProof. (Lemma 2). We start by computing the expected payoff of player 1, which is given by\n\n$$\n\\mathbb{E}\\left[u_{1}\\right]=\\int_{0}^{v_{2}-\\eta}\\left(G_{2}(x)\\left(v_{1}-x\\right)-\\eta G_{2}(0)\\right) f(x) d x\n$$\n\nwhere the PDF is $f(x)=\\frac{\\eta}{\\left(v_{2}-x\\right)^{2}}$. From the distributions we calculated, we get that\n\n$$\n\\mathbb{E}\\left[u_{1}\\right]=v_{1}-v_{2}+\\eta\\left(\\frac{v_{2}-\\eta}{v_{1}}\\right)\n$$\n\nA straightforward calculation by differentiating this expression with respect to $\\eta$ shows that the expectation is maximized when $\\eta=v_{2} / 2$, in which case its value is $v_{1}-v_{2}+v_{2}^{2} / 4 v_{1}$, as claimed. With this choice of $\\eta$, player 2's utility is $v_{2} / 2$.\nThe frequency at which the low agent (agent 2) wins is given by:\n\n$$\n\\operatorname{Pr}\\left[b_{2}>b_{1}\\right]=\\int_{0}^{v_{2}-\\eta} F(x) g(x) d x=\\frac{v_{2}\\left(2 v_{1}-v_{2}\\right)}{4\\left(v_{1}-v_{2}\\right)^{2}}\\left(\\ln \\left(\\frac{2 v_{1}-v_{2}}{v_{1}}\\right)-\\frac{v_{2}\\left(v_{1}-v_{2}\\right)}{v_{1}\\left(2 v_{1}-v_{2}\\right)}\\right)\n$$\n\nIf $v_{2}$ is small compared to $v_{1}$ (in the limit $v_{2} / v_{1} \\rightarrow 0$ ), agent 2 never wins. If $v_{2}$ is close to $v_{1}$ (in the limit $\\left.v_{2} / v_{1} \\rightarrow 1\\right)$, agent 2 will win $3 / 8$ of the time.\n\nProof. (Lemma 3) We begin by showing that the Nash equilibrium cumulative distributions bound the marginal distributions in our dynamics from below (i.e., the latter stochastically dominate the Nash equilibrium).\nClaim 3. The support of $F_{1}$ and $G_{2}$ is at most $v_{2}-\\eta$, and for all $b$ in the support, we have that $F_{1}(b) \\geq F_{1}^{N E}$, and $G_{2}(b) \\geq G_{2}^{N E}(b)$.\n\nProof. For agent 2, all bids above $v_{2}-\\eta$ are strictly dominated by bidding zero, and so are not in the support. For agent 1 , given the support of agent 2 , bids above $v_{2}-\\eta$ give strictly less utility than bidding $v_{2}-\\eta$, so a regret-minimizing agent will not play them.\nFor mean-based agents, we have that for all $b$ in the support, $u_{2}(b)=F_{1}(b)\\left(v_{2}-b\\right) \\geq u_{2}(0)=\\eta$ and $u_{1}(b)=G_{2}(b)\\left(v_{1}-b\\right)-\\eta G_{2}(0) \\geq v_{1}-v_{2}+\\eta-\\eta G_{2}(0)$. Hence we have $F_{1}(b) \\geq \\frac{\\eta}{v_{2}-b}=F_{1}^{N E}$, and $G_{2}(b) \\geq \\frac{v_{1}-v_{2}+\\eta}{v_{1}-b}=G_{2}^{N E}(b)$.\n\nContinuing the proof of Lemma 3, suppose, for contradiction, $F_{1}\\left(b^{\\prime}\\right)>F_{1}^{N E}\\left(b^{\\prime}\\right)$ for some $b^{\\prime}<v_{2}-\\eta$. We have that $F_{1}\\left(b^{\\prime}\\right)>F_{1}^{N E}\\left(b^{\\prime}\\right)$ implies $u_{2}\\left(b^{\\prime}\\right)=F_{1}\\left(b^{\\prime}\\right)\\left(v_{2}-b^{\\prime}\\right)>F_{1}^{N E}\\left(b^{\\prime}\\right)\\left(v_{2}-b^{\\prime}\\right)=\\eta=u_{2}(0)$. Therefore, bidding zero is not within the support of player 2 .\nHowever, if player 2 never bids zero, then there are no payments in our CCE. Since the agents minimize regret, it must be a CCE of the standard first-price auction.\nIn the standard first-price auction (without payments), mean-based agents can converge only to CCEs that include bids above $v_{2}-\\eta$ in their support; this follows from [63]. This is a contradiction to our assumption. Therefore, we have $F_{1}=F_{1}^{N E}$.\nNext, suppose for contradiction that $G_{2}\\left(b^{\\prime}\\right)>G_{2}^{N E}\\left(b^{\\prime}\\right)$ for some $b^{\\prime}<v_{2}-\\eta$. This implies $u_{1}\\left(b^{\\prime}\\right)=$ $G_{2}\\left(b^{\\prime}\\right)\\left(v_{1}-b^{\\prime}\\right)-\\eta G_{2}(0)>G_{2}^{N E}\\left(b^{\\prime}\\right)\\left(v_{1}-b^{\\prime}\\right)-\\eta G_{2}(0)=v_{1}-v_{2}+\\eta-\\eta G_{2}(0)=u_{1}\\left(v_{2}-\\eta\\right)$. That is, bidding $b^{\\prime}$ gives player 1 a higher utility than bidding $v_{2}-\\eta$, so the latter is not within the support of player 1 , which is a contradiction, since the marginal distribution of player 1 is $F_{1}$, which is supported on $\\left[0, v_{2}-\\eta\\right]$. Thus, overall, we have $F_{1}=F_{1}^{N E}$ and $G_{2}=G_{2}^{N E}$.\n\nProof. (Theorem 2.) To prove the theorem, we use the fact that the game analyzed in our lemmas is induced by a unilateral payment policy by the high-value player. In any equilibrium, player 1 can consider the deviation in which she rejects (pays back) all the payments she received and makes this unilateral payment, leading to a utility of $v_{1}-v_{2}+v_{2}^{2} / 4 v_{1}$. Therefore, in any equilibrium, player 1 gets at least this utility, which is higher than the utility of $v_{1}-v_{2}$ that she gets in the game without payments. As for the utility of the low-value player, since the high-value player's utility is above the second price, player 1 must use positive payments, otherwise the dynamics of mean-based agents could approach only the second-price outcome (as shown in [63]). Therefore, in the equilibrium of the payment-policy game, the low-value player has positive utility, an improvement over the game without payments.\nHaving established this. the fact that the revenue decreases in any equilibrium is now straightforward. To see this explicitly, suppose for contradiction that the revenue $R$ is at least the revenue $v_{2}$ of the game without payments. The total welfare (of the players and the auctioneer) is $w=u_{1}+R+u_{2} \\leq v_{1}$. We then get $v_{1}+\\eta\\left(\\frac{v_{1}-\\eta}{v_{1}}\\right)+u_{2} \\leq v_{1}$, which is a contradiction, since player 2 cannot get negative utility in equilibrium.\nBy Lemma 2 and Lemma 3, player 1 has a utility-improving deviation from the zero-payments profile for any mean-based regret-minimizing agents for the players, so the game is not stable for such agents; also, both players improve their utilities, and the revenue for the auctioneer decreases, as claimed.", "tables": {}, "images": {}}, {"section_id": 8, "text": "# 5 Manipulations by One Player \n\nWe now turn our attention to general games and focus on analyzing the effects of the simplest type of manipulations: payment policies where only a single agent pays. The question we aim to answer here is when does a player have an incentive to use payments with a learning agents? By making sufficiently high payments to all the other agents, clearly, an agent could induce any pure outcome in the game. The main questions are thus not about the power of payment policies, but about when are such policies also profitable, and what are the implications of such profitable payment policies for one player on the welfare of other players.\n\nNotation: Denote the welfare of an outcome $s$ by $w(s)$ and the best-response utility of player $i$ to action profile $s$ by $u_{i}^{R R}(s)=\\max _{s_{i}^{\\prime} \\in S_{i}} u_{i}\\left(s_{i}^{\\prime}, s_{-i}\\right)$. For the following analysis, it is useful to define a notion of regret that measures the opportunity cost per step for player $i$ of playing the game where the strategy profile $x$ is played compared to the benchmark of her best action in hindsight in the (different) game where $y$ (rather than $x$ ) is played by the other players. To avoid confusion with standard regret (which considers the benchmark of the best response in hindsight to $x$ ), we call this \"comparative regret.\" Intuitively, it measures the extent to which a player regrets not incentivizing others to play $y$ instead of $x$.\n\nDefinition 2. Let $x, y$ be two joint distributions on the players' joint action space $S$. The comparative regret of player $i$ under the distribution of play $x$ compared to best responding to an alternative distribution of play $y$ is $R_{i}(x, y)=u_{i}^{R R}(y)-u_{i}(x)$.\n\nAt time $T$, we have an expected distribution of play $x(T)$ with welfare $w(x(T))$, where $x(T)$ approaches the set of CCEs of $\\Gamma$ as $T \\rightarrow \\infty$. To simplify notation, we omit the dependence on $T$ and discuss it only when necessary. The optimal welfare is denoted $O P T=\\max _{s \\in S} w(s)$.\n\nThe following theorem characterizes the cases in which there is a player in the game who can gain from incentivizing the other agents to reach the optimal-welfare outcome.\n\nTheorem 3. Fix a finite game $\\Gamma$ and a set $A$ of regret-minimizing agents. Let the optimal welfare outcome ${ }^{10}$ of $\\Gamma$ be $y^{*}$. If $y^{*}$ is a Nash equilibrium, then there is a player $i$ such that $i$ increases her own payoff and the payoffs of all the other players by using a payment policy $p_{i}$ that induces $y^{*}$ as the unique long-term outcome of the agents' dynamics. If $y^{*}$ is not a Nash equilibrium, the same holds if there exists a player $i$ for which the welfare gap $O P T-w(x)$ is greater than $\\sum_{j \\neq i} R_{j}\\left(x, y^{*}\\right)$.\n\nAnalysis: To prove the theorem, we begin by establishing two lemmas that quantify the costs and gains for a player of pushing the agents' dynamics to an arbitrary pure outcome.\nTo assure the convergence of arbitrary no-regret agents to $y^{*}$, the payments must induce $y^{*}$ is the unique $\\mathrm{CCE},{ }^{11}$ which implies that it is also the unique Nash equilibrium. One way to do so is by making $y$ an equilibrium in dominant strategies. Although weaker requirements would be sufficient for our purpose (such as inducing a dominance-solvable game), using dominant strategies simplifies the analysis. Moreover, it turns out that it leads to the same payments and the same utilities for the players in the long term as inducing a unique CCE: [76] analyzed a mechanism-design scenario where a designer adds exogenous payments to the game, and they observed that the actual cost of inducing an outcome $s$ as an equilibrium in dominant strategies - which they called the optimal $k$-implementation of $s, k(s)$ - is equal to the cost of inducing that outcome as a Nash equilibrium. Combining this with the fact that an equilibrium in dominant strategies is also the unique CCE, we have that, indeed, the exogenous payments needed for inducing a unique CCE or an equilibrium in dominant strategies are the same. The intuition for this result is that further payments that are intended to assure dominant strategies are in fact made only off the equilibrium path, and are thus not actually made when the game is played. A similar effect was also used in [10] in the context of providing collateral contracts to mitigate strategic risk and incentivize investments.\n\nThis intuition also carries over, to some extent, to our endogenous setting, where one of the players uses a payment policy to manipulate the agents' dynamics. But our case is different in several ways. First, importantly, there are no external funds injected into the game. Instead, payments that a player allows her agent to make to other agents are taken from her own payoffs. Second, as we show below, the cost of inducing an outcome $s$ as an equilibrium is lower than $k(s)$, since the player who wishes to induce $s$ as the outcome of the agents' dynamics does not make payments to her own regret-minimizing agent. Third, since in our case the learning agents do not reason about payment policies but rather learn to respond over time, some agents will play dominated actions for some time, leading to additional short-term costs. This is formalized in the following lemma.\n\nLemma 4. Fix a player $i$ and pure outcome $y$. Player $i$ can incentivize $y$ as the unique long-term outcome of the dynamic with an expected cost per time step of $\\operatorname{cost}_{i}(y)=k(y)-R_{i}(y, y)+o(1)$.\n\nProof. (Lemma 4). We start constructing a payment policy for the agent of player $i$ by looking at the optimal $k$-implementation payments for inducing $y$ as a dominant strategy equilibrium; we will then adjust this payment profile to fit our setting in which there are no external payments and to minimize player $i$ 's cost. A key point is that the payment amount $k(y)$ includes payments to agent $i$ that an external designer would have made for inducing $y_{i}$ as the dominant strategy for agent $i$. These payments are not feasible and not needed in our case. Instead, we change the payment policy of agent $i$ in the following way: for any action $s_{i} \\neq y_{i}$, agent $i$ makes a payment of $\\max _{s \\in S} u_{i}(s)+1$, and distributes this payment equally to the other agents. These payments make all the other actions of agent $i$ strictly dominated by the action $y_{i}$. Thus, to calculate the cost for player $i$, we need to subtract from the $k$-implementation payments the payments\n\n[^0]\n[^0]:    ${ }^{10}$ To simplify the analysis, we consider the generic case of a unique optimal outcome. In games with equalities in utility, this can be obtained by considering infinitesimal perturbations of the utilities.\n    ${ }^{11}$ With multiple CCEs, no-regret dynamics may fail to converge even in the time average [64].\n\nmade to player $i, R_{i}(y, y)$, and add a learning-phase error term $\\tilde{c}$ that results from the additional payments that agent $i$ makes when playing its dominated strategies, as well as from other times during the learning dynamics when the other agents play their dominated strategies.\n\nClaim. The expected learning phase cost per time step $\\tilde{c}$ vanishes in the long term, that is, $\\tilde{c}=o(1)$.\nProof. $\\tilde{c}$ is the expected total payment per time step that player $i$ makes when agents play strictly dominated strategies. Assume for contradiction that $\\lim _{T \\rightarrow \\infty} \\tilde{c}>0$, or that the limit does not exist. Both cases imply that the frequency at which dominated strategies are played in the agents' dynamic is not vanishing, which contradicts the regret-minimization property of the agents.\n\nIt follows that $\\operatorname{cost}_{i}(y)=k(y)-R_{i}(y, y)+o(1)$ as $T \\rightarrow \\infty$, as stated in the lemma.\nThe next lemma specifies the condition under which, given a distribution $x$ to which the no-regret agents converge in expectation in $T$ rounds, there is a player who can use a payment policy to increase her payoff by pushing the dynamic to a different outcome.\n\nLemma 5. Fix a finite game $\\Gamma$ and a set of regret-minimizing agents for the players. If there exists a player $i$ and outcome $y$ such that $w(y)-w(x)>\\sum_{j \\neq i} R_{j}(x, y)$, then $i$ can increase her payoff by making payments that induce $y$ as the unique outcome of the agents' dynamics.\n\nIntuitively, the increase in welfare must be large enough to compensate the other players for their regret for playing $x$ compared to their best responses to the alternative outcome $y$. Before proving the lemma, we have the following corollary.\n\nCorollary 1. If the dynamics without payments approach a welfare $w(x)$ lower than the welfare of some Nash equilibrium $y$, then, since in equilibrium $R_{i}(y, y)=0$, there is a player who can increase her payoff by using a payment policy that induces $y$ as the long-term outcome of the dynamics.\n\nProof. (Lemma 5). We need to specify the requirement that player $i$ will increase her own utility after making the payments that induce $y$ as the unique outcome of the dynamics. That is, $\\operatorname{cost}_{i}(y)<u_{i}(y)-u_{i}(x)$. By Lemma 4 we have that for large enough $T$, player $i$ prefers making such payments if $u_{i}(y)-k(y)+R_{i}(y, y)>$ $u_{i}(x)$. Rewriting the left terms we have\n\n$$\nu_{i}^{B R}(y)-k(y)>u_{i}(x)=w(x)-\\sum_{j \\neq i} u_{j}(x)\n$$\n\nUsing the fact that by definition of $k(y)$ [76], it can be expressed as $k(y)=\\left[\\sum_{j} u_{j}^{B R}(y)\\right]-w(y)$, we can rewrite the left-hand side as $w(y)-\\sum_{j \\neq i} u_{j}^{B R}(y)$. Rearranging the terms, we have\n\n$$\nw(y)-w(x)>\\sum_{j \\neq i} u_{j}^{B R}(y)-\\sum_{j \\neq i} u_{j}(x)=\\sum_{j \\neq i} R_{j}(x, y)\n$$\n\nNote that all the steps in the proof of Lemma 5 hold in either direction. Thus, the lemma, and consequently the result of Theorem 3 for the case where the optimal welfare outcome is not an equilibrium, also hold in the other direction. That is, if player $i$ can increase her payoff by making payments that induce $y$ as the unique outcome, then $w(y)-w(x)>\\sum_{j \\neq i} R_{j}(x, y)$.\nThe lemmas above provide the basis for proving Theorem 3.\n\nProof. (Theorem 3). If the dynamics of the players' regret-minimizing agents converge to the optimal-welfare outcome, $\\lim _{T \\rightarrow \\infty} x=y^{*}$, then there is no room for improvement and the theorem holds trivially (although weakly) with payments of zero. In the following, we assume for simplicity that $w(x)$ is bounded away ${ }^{12}$ from $w\\left(y^{*}\\right)$, that is, there exists $\\epsilon>0$ and $T_{0}$ such that for all $T>T_{0}$, we have that $w(x)<w\\left(y^{*}\\right)(1-\\epsilon)$.\nSuppose that $y^{*}$ is a Nash equilibrium. By definition, if some profile $s$ is a Nash equilibrium, then $R_{i}(s, s)=0$ for all $i$. Thus, by Lemma 4, any player can construct a payment policy that induces $y^{*}$ as the unique outcome of the agents' dynamic with a cost-per-time-step of $o(1)$.\nTherefore, to have a player $i$ who increases her payoff by inducing $y^{*}$ as the outcome of the dynamics, we only need to have $u_{i}\\left(y^{*}\\right)>u_{i}(x)$. Assume for the purpose of contradiction that for all $i, u_{i}(x) \\geq u_{i}\\left(y^{*}\\right)$. Summing over the players, we have $\\sum_{i} u_{i}(x) \\geq \\sum_{i} u_{i}\\left(y^{*}\\right)$; that is, $w(x) \\geq w\\left(y^{*}\\right)$, a contradiction to the optimality of $y^{*}$. Thus, we have that for $T$ large enough such that the learning-phase costs are small, there exists a player $i$ who can increase her payoff by inducing the optimal-welfare outcome as the outcome of the agents' dynamics. If $y^{*}$ is a non-equilibrium outcome, the conditions for $i$ increasing her payoff are given by Lemma 5 , setting $y=y^{*}$. Notice also that since under this payment policy, the outcome $y^{*}$ dominates $x$ for all the agents, the utilities are a strict Pareto improvement compared to the game without payments.\n\nFrom the analysis above, we observe that in many cases, players can gain from using payment policies to divert the agents' dynamics to more favorable outcomes for them. The following theorem shows that this is true for a broad class of games. For games with a price of stability (PoS) of 1, this is already implied by Theorem 3, but the following result is more general.\n\nTheorem 4. A finite game in which there exists a coarse correlated equilibrium with lower welfare than the best Nash equilibrium is not stable. This is true, in particular, if PoA $\\neq$ PoS.\n\nRemark. The converse is not true in general: there are games with PoA $=$ PoS that are still not stable, so players prefer to use payments. One such example is the prisoner's dilemma game in Figure 1.\n\nProof. The result follows from combining the proof of Lemma 5 with general properties of regret-minimization dynamics. Let $\\Gamma$ be a game in which the Nash equilibrium with the highest welfare, denoted $\\bar{y}$, yields a welfare of $\\bar{w}$ (where the welfare in equilibrium $\\bar{w}$ is not necessarily equal to the optimal welfare $O P T$ ), and there exists a CCE $x$ with welfare $w(x)<\\bar{w}$.\nIt is known that for any CCE of a game, there are regret-minimizing agents that converge to that equilibrium [64, 77]. In particular, there are agents that converge arbitrarily close to $x .{ }^{13}$ By Lemma 5 (in particular, using Corollary 1), there exists a player who prefers using a payment policy that assures convergence to the highest welfare equilibrium $\\bar{y}$ compared to not making payments and reaching outcome $x$. Thus, we have a utility-improving deviation over the no-payments action profile and hence the game is not stable.", "tables": {}, "images": {}}, {"section_id": 9, "text": "# 6 Two-Player Games \n\nIn our prisoner's dilemma example presented in Section 1, we saw that the players had incentives to use payments between their agents, and in equilibria of the payment game, both players had higher gains than\n\n[^0]\n[^0]:    ${ }^{12}$ There is also the scenario where $x=y^{*}$ for some values of $T$ but not in the limit. For such values of $T$ the theorem holds trivially as well, and so the assumption is without loss of generality.\n    ${ }^{13}$ The proofs of this convergence result use cycles of pure actions to approximate the time average of joint distributions, and the arbitrarily close approximation is due to the density of the rational numbers. We disregard this detail in our analysis.\n\nin the game without payments. We now show that these phenomena apply quite generally to bilateral interactions where the players use learning agents.\n\nTheorem 5. Every equilibrium of a two-player payment-policy game is a Pareto improvement over the no-payments outcome of this game.\n\nProof. The intuition for proving this result is that in order to have any positive payment in equilibrium, some player must benefit from making the payment, while the other benefits from receiving it. If some player is worse off with the payments, then, since there are no considerations about other players, this player always has a deviation that effectively cancels the payments. With more than two players, there may be players who cannot profitably counteract such payments made among others that do not benefit them. Formally, consider a game $\\Gamma$, a set $A$ of regret-minimizing learning agents for the players, and a time horizon $T$. Suppose, for the sake of contradiction, that there exists an equilibrium $p^{*}$ of the payment-policy game associated with $\\Gamma, A, T$ where player $i$ has a lower utility than her expected utility over the $T$ rounds in the game without payments. Let $h$ denote the utility for player $i$ in the game without payments, and let $l$ denote the utility for player $i$ in the equilibrium $p^{*}$. By our assumption, we have $h>l$. Consider the following deviation from the payment policy $p^{*}$ : player $i$ matches her payments to zero out all payments made by the other player and, additionally, reduces all of her other payments to zero. As a result, the two agents now observe in her dynamics the utilities of the original game $\\Gamma$ without payments. Therefore, player $i$ has a utility of $h$. Since player $i$ has increased her utility from $l$ to $h$, we have a contradiction to $p^{*}$ being an equilibrium. Hence, the utilities of both players can only increase relative to the game without payments.\n\nThe next theorem addresses the question of incentives to use payments in a class if games in which no-regret dynamics converge to a single CCE, including games with an equilibrium in dominant strategies. The theorem shows that despite the simplicity of learning in these games and even with dominant strategies, in many cases players still have an incentive to use payment policies. One intuition for this is that in two-player interactions, players can utilize payments to effectively assume the role of a Stackelberg leader in the game.\n\nThis result is also related to a theorem in [64] that deals with games with dominant strategies in a metagame in which users misreport their utility parameters to their learning agents. In our context of payments between the agents, the argument is different and the result is more broad, applying to a larger family of games, including all dominance-solvable games, generic fully-mixed games, and socially-concave games [40] (a sub-class of concave games in which regret-minimization dynamics converge to Nash equilibria) with a unique equilibrium.\n\nTheorem 6. Any finite two-player game with a unique coarse correlated equilibrium and two different pure-strategy Stackelberg outcomes (depending on which player is the Stackelberg leader) is not stable for any regret-minimizing agents for the players.\n\nProof. Consider as our starting point the action profile where the players use zero payments. In the game without payments, any regret-minimization dynamic will converge to the unique coarse correlated equilibrium (which is also the unique Nash equilibrium). To show that the game is not stable for any set of regret-minimizing agents for the players, we need a utility-improving deviation from the zero-payment profile for one of the two players.\n\nWe use the fact that when the opponent does not make payments, a player has the ability to alter her policy so as to commit to playing a pure action in the long term; this can be obtained by making large payments whenever the agent plays different actions, inducing a dominant. Since for at least one of the players there\n\nis a Stackelberg-equilibrium outcome that is different from the (unique) Nash-equilibrium outcome, there exists a player who obtains a higher payoff as a Stackelberg leader in the game, so this player prefers making such a commitment. Since the other agent is also minimizing regret, this agent will eventually learn to best reply to the fixed action of the first player's agent, and the dynamics with these payments will converge to the Stackelberg outcome of the game. Thus, we have a utility-improving deviation from the zero-payment policy, so the game is not stable. Note that this is a different result from that of Theorem 4, since the Stackelberg outcome here is not a coarse correlated equilibrium of the game $\\Gamma$.", "tables": {}, "images": {}}, {"section_id": 10, "text": "# 7 Conclusion \n\nAutonomous learning agents are widely and increasingly used in many online economic interactions, such as auctions and other markets. The rapid advancement in large language models and their integration into a wide array of applications further lowers barriers to communication and interaction among autonomous agents. It is not difficult to envision a future digital landscape populated by a plethora of autonomous agents, endowed with access to financial assets or fiat currencies, trading among themselves to serve the interests of their users. Motivated by this transition to automated systems with sophisticated AI agents, we studied the scenario where users let their automated agents offer monetary transfers to other agents during their dynamics.\n\nOur results show that, in a very general sense, strategic users have incentives to use payments with their learning agents, which can have very significant implications for the overall outcomes. While focus in this work is on the general properties of payment games and their analysis in the context of auctions, studying payments between automated learners may also be of interest in a wide range of other strategic interactions, including Fisher markets, asset markets, and contracting games with multiple learning agents.\nMore Broadly, our findings highlight a challenge for mechanism design in the AI era, underlining the need to better understand both the dynamics of learning agents and the incentives of their users in automated markets.", "tables": {}, "images": {}}, {"section_id": 11, "text": "## Acknowledgments\n\nWe thank Noam Nisan for his valuable feedback on this project. \u00c9va Tardos was supported in part by AFOSR grant FA9550-23-1-0410, AFOSR grant FA9550-231-0068. Joe Halpern was supported in part by AFOSR grant FA23862114029, MURI grant W911NF-19-1-0217, ARO grant W911NF-22-1-0061, NSF grant FMitF-2319186, and a grant from the Cooperative AI Foundation.", "tables": {}, "images": {}}, {"section_id": 12, "text": "## References\n\n[1] Aggarwal, G., Fikioris, G., and Zhao, M. No-regret algorithms in non-truthful auctions with budget and roi constraints. arXiv preprint arXiv:2404.09832 (2024).\n[2] Aggarwal, G., Gupta, A., Perlroth, A., and Velegkas, G. Randomized truthful auctions with learning agents. arXiv preprint arXiv:2411.09517 (2024).\n[3] Alaei, S., Badanidiyuru, A., Mahdian, M., and Yazdanbod, S. Response prediction for low-regret agents. In International Conference on Web and Internet Economics (2019), Springer, pp. 31-44.\n\n[4] Alimohammadi, Y., Mehta, A., and Perlroth, A. Incentive compatibility in the auto-bidding world. arXiv preprint arXiv:2301.13414 (2023).\n[5] Arora, S., Hazan, E., and Kale, S. The multiplicative weights update method: A meta-algorithm and applications. Theory of Computing 8, 1 (2012), 121-164.\n[6] Arunachaleswaran, E. R., Collina, N., and Schneider, J. Pareto-optimal algorithms for learning in games. In Proceedings of the 25th ACM Conference on Economics and Computation (2024), pp. 490-510.\n[7] Auer, P., Cesa-Bianchi, N., Freund, Y., and Schapire, R. E. The nonstochastic multiarmed bandit problem. SIAM Journal on Computing, SICOMP 32, 1 (2002), 48-77.\n[8] Aumann, R. J. Subjectivity and correlation in randomized strategies. Journal of mathematical Economics 1, 1 (1974), 67-96.\n[9] Austerweil, J. L., Brawner, S., Greenwald, A., Hilliard, E., Ho, M., Littman, M. L., MacGlashan, J., and Trimbach, C. How other-regarding preferences can promote cooperation in non-zero-sum grid games. In AAAI Symposium on Challenges and Opportunities in Multiagent Learning for the Real World (2016).\n[10] Babaioff, M., Kolumbus, Y., and Winter, E. Optimal collaterals in multi-enterprise investment networks. In Proceedings of the ACM Web Conference 2022 (2022), pp. 79-89.\n[11] Bahrani, M., GARIMIDI, P., and RoughGarden, T. Transaction fee mechanism design with active block producers. arXiv preprint arXiv:2307.01686 (2023).\n[12] Bahrani, M., GARIMIDI, P., and RoughGarden, T. Transaction fee mechanism design in a post-mev world. Cryptology ePrint Archive (2024).\n[13] Balcan, M.-F., Blum, A., and Mansour, Y. Improved equilibria via public service advertising. In Proceedings of the twentieth annual ACM-SIAM symposium on Discrete algorithms (2009), SIAM, pp. $728-737$.\n[14] Balseiro, S. R., and Gur, Y. Learning in repeated auctions with budgets: Regret minimization and equilibrium. Management Science 65, 9 (2019).\n[15] Bichler, M., Lunowa, S. B., Oberlechner, M., Pieroth, F. R., and Wohlmuth, B. On the convergence of learning algorithms in bayesian auction games. arXiv preprint arXiv:2311.15398 (2023).\n[16] Blackwell, D. An analog of the minimax theorem for vector payoffs.\n[17] Blum, A., Hajiaghayi, M., Ligett, K., and Roth, A. Regret minimization and the price of total anarchy. In Proceedings of the fortieth annual ACM symposium on Theory of computing (2008), pp. 373-382.\n[18] Blum, A., and Mansour, Y. From external to internal regret. JMLR 8, 6 (2007).\n[19] Blum, A., and Monsour, Y. Learning, regret minimization, and equilibria.\n[20] Bolton, P., and Dewatripont, M. Contract theory. MIT press, 2004.\n[21] Borgs, C., Chayes, J., Immorlica, N., Jain, K., Etesami, O., and Mahdian, M. Dynamics of bid optimization in online advertisement auctions. In Proceedings of the 16th international conference on World Wide Web (2007), pp. 531-540.\n\n[22] Braverman, M., Mao, J., Schneider, J., and Weinberg, M. Selling to a no-regret buyer. In Proceedings of the 2018 ACM Conference on Economics and Computation (2018), pp. 523-538.\n[23] Brown, G. W. Iterative solution of games by fictitious play. Activity analysis of production and allocation 13, 1 (1951), 374-376.\n[24] Cai, L., Weinberg, S. M., Wildenhain, E., and Zhang, S. Selling to multiple no-regret buyers. Working paper available at https://arxiv.org/pdf/2307.04175.pdf, 2023.\n[25] Caragiannis, I., Kaklamanis, C., Kanellopoulos, P., Kyropoulou, M., lucier, B., Leme, R. P., and Tardos, E. Bounding the inefficiency of outcomes in generalized second price auctions. Journal of Economic Theory 156 (2015), 343-388.\n[26] Cesa-Bianchi, N., Gentile, C., and Mansour, Y. Regret minimization for reserve prices in secondprice auctions. IEEE Transactions on Information Theory 61, 1 (2014), 549-564.\n[27] Cesa-Bianchi, N., and Lugosi, G. Prediction, learning, and games. Cambridge university press, 2006.\n[28] Chung, H., Roughgarden, T., and Shi, E. Collusion-resilience in transaction fee mechanism design. arXiv preprint arXiv:2402.09321 (2024).\n[29] Dajan, P., Goldfeder, S., Kell, T., Li, Y., Zhao, X., Bentov, I., Breidenbach, L., and Juels, A. Flash boys 2.0: Frontrunning in decentralized exchanges, miner extractable value, and consensus instability. In 2020 IEEE symposium on security and privacy (SP) (2020), IEEE, pp. 910-927.\n[30] Daskalakis, C., Fishelson, M., and Golowich, N. Near-optimal no-regret learning in general games. Advances in Neural Information Processing Systems 34 (2021).\n[31] Daskalakis, C., and Panageas, I. Last-iterate convergence: Zero-sum games and constrained min-max optimization. In 10th Innovations in Theoretical Computer Science Conference (ITCS 2019) (2018), Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik.\n[32] Daskalakis, C., and Syrgkanis, V. Learning in auctions: Regret is hard, envy is easy. In 2016 ieee 57th annual symposium on foundations of computer science (focs) (2016), IEEE, pp. 219-228.\n[33] Deng, X., Hu, X., Lin, T., and Zheng, W. Nash convergence of mean-based learning algorithms in first price auctions. In Proceedings of the ACM Web Conference 2022 (2022), pp. 141-150.\n[34] Deng, Y., Mao, J., Mirrokni, V., and Zuo, S. Towards efficient auctions in an auto-bidding world. In Proceedings of the Web Conference 2021 (2021).\n[35] Deng, Y., Schneider, J., and Sivan, B. Strategizing against no-regret learners. In Annual Conference on Neural Information Processing Systems, NeurIPS (2019), pp. 1577-1585.\n[36] Duetting, P., and Talgam-Cohen, I. Contract theory: A new frontier for algorithmic game theory. ACM EC2019 tutorial (2019).\n[37] Dutta, P. K., and Siconolfi, P. Asynchronous games with transfers: uniqueness and optimality. Journal of Economic Theory 183 (2019), 46-75.\n[38] Dworczak, P. Mechanism design with aftermarkets: Cutoff mechanisms. Econometrica 88, 6 (2020), $2629-2661$.\n\n[39] Eccles, T., Hughes, E., Kram\u00e1r, J., Wheelwright, S., and Leibo, J. Z. Learning reciprocity in complex sequential social dilemmas. arXiv preprint arXiv:1903.08082 (2019).\n[40] Even-Dar, E., Mansour, Y., and Nadav, U. On the convergence of regret minimization dynamics in concave games. In ACM Symposium on Theory of Computing, STOC (2009), pp. 523-532.\n[41] Feldman, M., Lucier, B., and Nisan, N. Correlated and coarse equilibria of single-item auctions. In International Conference on Web and Internet Economics, WINE (2016), pp. 131-144.\n[42] Feng, Y., Lucier, B., and Slivkins, A. Strategic budget selection in a competitive autobidding world. In Proceedings of the 56th Annual ACM Symposium on Theory of Computing (2024), pp. 213-224.\n[43] Feng, Z., Guruganesh, G., Liaw, C., Mehta, A., and Sethi, A. Convergence analysis of no-regret bidding algorithms in repeated auctions. arXiv preprint arXiv:2009.06136 (2020).\n[44] Fikioris, G., Kleinberg, R., Kolumbus, Y., Kumar, R., Mansour, Y., and Tardos, \u00c9. Learning in budgeted auctions with spacing objectives. arXiv preprint arXiv:2411.04843 (2024).\n[45] Fikioris, G., and Tardos, \u00c9. Liquid welfare guarantees for no-regret learning in sequential budgeted auctions. In Proceedings of the 24th ACM Conference on Economics and Computation (2023), pp. 678-698.\n[46] Foster, D. J., Li, Z., Lykouris, T., Sridharan, K., and Tardos, E. Learning in games: Robustness of fast convergence. Advances in Neural Information Processing Systems 29 (2016).\n[47] Foster, D. P., and VOHRA, R. V. Calibrated learning and correlated equilibrium. Games and Economic Behavior 21, 1-2 (1997), 40-55.\n[48] Fudenberg, D., and Levine, D. K. Consistency and cautious fictitious play. Fournal of Economic Dynamics and Control 19, 5-7 (1995), 1065-1089.\n[49] Gentry, M. L., Hubbard, T. P., Nekipelov, D., Paarsch, H. J., et al. Structural econometrics of auctions: A review. now publishers, 2018.\n[50] Gillies, D. B. Solutions to general non-zero-sum games. Contributions to the Theory of Games 4, 40 (1959), 47-85.\n[51] Guruganesh, G., Kolumbus, Y., Schneider, J., Talgam-Cohen, I., Vlatakis-Gkaragkounis, E.-V., Wang, J. R., and Weinberg, S. M. Contracting with a learning agent. arXiv preprint arXiv:2401.16198 (2024).\n[52] Hannan, J. Approximation to Bayes risk in repeated play. In Contributions to the Theory of Games (AM-39), Volume III. Princeton University Press, 1957, pp. 97-139.\n[53] Harstad, B. Harmonization and side payments in political cooperation. American Economic Review 97, 3 (2007), 871-889.\n[54] Hart, S., and Mas-Colell, A. A simple adaptive procedure leading to correlated equilibrium. Econometrica 68, 5 (2000), 1127-1150.\n[55] Hart, S., and Mas-Colell, A. Simple adaptive strategies: from regret-matching to uncoupled dynamics, vol. 4. World Scientific, 2013.\n[56] Hartline, J., Syrgkanis, V., and Tardos, E. No-regret learning in bayesian games. Advances in Neural Information Processing Systems 28 (2015).\n\n[57] Jackson, M. O. A crash course in implementation theory. Social choice and welfare 18, 4 (2001), $655-708$.\n[58] Jackson, M. O., and Wilkie, S. Endogenous games and mechanisms: Side payments among players. The Review of Economic Studies 72, 2 (2005), 543-566.\n[59] Jafari, A., Greenwald, A., Gondek, D., and Ercal, G. On no-regret learning, fictitious play, and nash equilibrium. In ICML (2001), vol. 1, pp. 226-233.\n[60] Jaques, N., Lazaridou, A., Hughes, E., Gulcehre, C., Ortega, P., Strouse, D., Leibo, J. Z., and De Freitas, N. Social influence as intrinsic motivation for multi-agent deep reinforcement learning. In International Conference on Machine Learning (2019), PMLR, pp. 3040-3049.\n[61] Kalai, A., and Vempala, S. Efficient algorithms for online decision problems. Journal of Computer and System Sciences 71, 3 (2005), 291-307.\n[62] Kolumbus, Y., Levy, M., and Nisan, N. Asynchronous proportional response dynamics: convergence in markets with adversarial scheduling. Advances in Neural Information Processing Systems 36 (2024).\n[63] Kolumbus, Y., and Nisan, N. Auctions between regret-minimizing agents. In ACM Web Conference, WebConf (2022), pp. 100-111.\n[64] Kolumbus, Y., and Nisan, N. How and why to manipulate your own agent: On the incentives of users of learning agents. In Annual Conference on Neural Information Processing Systems, NeurIPS (2022).\n[65] Kosenko, A., and Neligh, N. L. Efficiency in dynamic games with sequential transfers. Available at SSRN 5088495.\n[66] Kumar, R., Schneider, J., and Sivan, B. Strategically-robust learning algorithms for bidding in first-price auctions. arXiv preprint arXiv:2402.07363 (2024).\n[67] Laffont, J.-J., and Maskin, E. The theory of incentives: An overview. Universit\u00e9 des sciences sociales, Facult\u00e9 des sciences \u00e9conomiques, 1981.\n[68] LaVictoire, P., Fallenstein, B., Yudkowsky, E., Barasz, M., Christiano, P., and Herreshoff, M. Program equilibrium in the prisoner's dilemma via l\u014db's theorem. In Workshops at the twenty-eighth AAAI conference on artificial intelligence (2014).\n[69] Leibo, J. Z., Zambaldi, V., Lanctot, M., Marecki, J., and Graepel, T. Multi-agent reinforcement learning in sequential social dilemmas. In Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems (2017), pp. 464-473.\n[70] Lucien, B., Pattathil, S., Slivkins, A., and Zhang, M. Autobidders with budget and roi constraints: Efficiency, regret, and pacing dynamics. In The Thirty Seventh Annual Conference on Learning Theory (2024), PMLR, pp. 3642-3643.\n[71] Mansour, Y., Mohri, M., Schneider, J., and Sivan, B. Strategizing against learners in Bayesian games. In Conference on Learning Theory, COLT (2022), pp. 5221-5252.\n[72] Maskin, E., and Sj\u00f6str\u00f6m, T. Implementation theory. Handbook of social Choice and Welfare 1 (2002), 237-288.\n\n[73] Mehta, A., and Perlroth, A. Auctions without commitment in the auto-bidding world. arXiv preprint arXiv:2301.07312 (2023).\n[74] Milionis, J., Papadimitriou, C., Piliouras, G., and Spendlove, K. An impossibility theorem in game dynamics. Proceedings of the National Academy of Sciences 120, 41 (2023), e2305349120.\n[75] Mohri, M., and Munoz, A. Optimal regret minimization in posted-price auctions with strategic buyers. In Advances in Neural Information Processing Systems (2014), pp. 1871-1879.\n[76] Monderer, D., and Tennenholtz, M. k-implementation. In Proceedings of the 4th ACM conference on Electronic Commerce (2003), pp. 19-28.\n[77] Monnot, B., and Piliouras, G. Limits and limitations of no-regret learning in games. The Knowledge Engineering Review 32 (2017), e21.\n[78] Moulin, H. An application of the shapley value to fair division with money. Econometrica: Journal of the Econometric Society (1992), 1331-1349.\n[79] Moulin, H. Cooperative microeconomics: a game-theoretic introduction. Princeton University Press, 1995.\n[80] Moulin, H. Fair division and collective welfare. MIT press, 2004.\n[81] Myerson, R. B. Mechanism design. Springer, 1989.\n[82] Nekipelov, D., Syrgkanis, V., and Tardos, E. Econometrics for learning agents. In Proceedings of the Sixteenth ACM Conference on Economics and Computation (2015), pp. 1-18.\n[83] Nisan, N., and Noti, G. An experimental evaluation of regret-based econometrics. In Proceedings of the 26th International Conference on World Wide Web (2017), International World Wide Web Conferences Steering Committee, p. 73-81.\n[84] Nisan, N., and Noti, G. A \"quantal regret\" method for structural econometrics in repeated games. In Proceedings of the 2017 ACM Conference on Economics and Computation (2017).\n[85] Nisan, N., and Ronen, A. Algorithmic mechanism design. In Proceedings of the thirty-first annual ACM symposium on Theory of computing (1999), pp. 129-140.\n[86] Nisan, N., Schapira, M., Valiant, G., and Zohar, A. Best-response auctions. In Proceedings of the 12th ACM conference on Electronic commerce (2011), pp. 351-360.\n[87] Noti, G., and Syrgkanis, V. Bid prediction in repeated auctions with learning. In ACM Web Conference, WebConf (2021), pp. 3953-3964.\n[88] Oesterheld, C. Robust program equilibrium. Theory and Decision 86, 1 (2019), 143-159.\n[89] Oesterheld, C., and Conitzer, V. Safe pareto improvements for delegated game playing. $A u$ tonomous Agents and Multi-Agent Systems 36, 2 (2022), 1-47.\n[90] Ramirez, M. A., Kolumbus, Y., Nagel, R., Wolpert, D., and Jost, J. Game manipulators-the strategic implications of binding contracts. arXiv preprint arXiv:2311.10586 (2023).\n[91] Robinson, J. An iterative method of solving a game. Annals of mathematics (1951), 296-301.\n\n[92] Roughgarden, T. The price of anarchy in games of incomplete information. In Proceedings of the 13th ACM Conference on Electronic Commerce (2012), pp. 862-879.\n[93] Roughgarden, T. Intrinsic robustness of the price of anarchy. Journal of the ACM (JACM) 62, 5 (2015), 1-42.\n[94] Roughgarden, T. Transaction fee mechanism design. ACM SIGecom Exchanges 19, 1 (2021), 52-55.\n[95] Roughgarden, T., Syrgkanis, V., and Tardos, E. The price of anarchy in auctions. Journal of Artificial Intelligence Research 59 (2017), 59-101.\n[96] Roughgarden, T., and Wang, J. R. Minimizing regret with multiple reserves. ACM Transactions on Economics and Computation (TEAC) 7, 3 (2019).\n[97] Slivkins, A., et al. Introduction to multi-armed bandits. Foundations and Trends\u00ae in Machine Learning 12, 1-2 (2019), 1-286.\n[98] Syrgkanis, V., Agarwal, A., Luo, H., and Schapire, R. E. Fast convergence of regularized learning in games. Advances in Neural Information Processing Systems 28 (2015), 2989-2997.\n[99] Syrgkanis, V., and Tardos, E. Composable and efficient mechanisms. In Proceedings of the forty-fifth annual ACM symposium on Theory of computing (2013), pp. 211-220.\n[100] Tennenholtz, M. Program equilibrium. Games and Economic Behavior 49, 2 (2004), 363-373.\n[101] Vickrey, W. Counterspeculation, auctions, and competitive sealed tenders. The Journal of finance 16, 1 (1961), 8-37.\n[102] Yang, J., Li, A., Farajtabar, M., Sunehag, P., Hughes, E., and Zha, H. Learning to incentivize other learning agents. Advances in Neural Information Processing Systems 33 (2020), 15208-15219.\n[103] Zhang, B. H., Farina, G., Anagnostides, I., Cacciamani, F., McAleer, S. M., Haupt, A. A., Celli, A., Gatti, N., Conitzer, V., and Sandholm, T. Steering no-regret learners to optimal equilibria. Working paper available at https://arxiv.org/pdf/2306.05221.pdf, 2023.\n[104] Zhu, B., Bates, S., Yang, Z., Wang, Y., Jiao, J., and Jordan, M. I. The sample complexity of online contract design. In ACM Conference on Economics and Computation, EC (2023), p. 1188.\n[105] Zinkevich, M. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the 20th international conference on machine learning (2003), pp. 928-936.\n\n![img-1.jpeg](img-1.jpeg)\n(a) The symmetric game: $x>y>1$.\n\n![table_1](table_1)\n\n(b) The asymmetric game: $x_{i}>y_{i}>1$.", "tables": {"table_1": "|  |  |  | Player 2 |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n|  |  | C | D |  |  |\n| Player 1 | C | $y, y$ | $0, x$ |  |  |\n|  | D | $x, 0$ | 1,1 |  |  |\n|  |  | $x_{1}, 0$ | 1,1 |  |  |"}, "images": {"img-1.jpeg": "data:image/jpeg;base64,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"}}, {"section_id": 13, "text": "# A Prisoner's Dilemma Games \n\nWe begin by stating a simple result for the class of dominance-solvable games (see, e.g., [59]) that is useful for the following analysis. A dominance-solvable game is a game in which iterated elimination of strictly dominated strategies leads to a unique outcome. In particular, this class includes games with a strictly dominant strategy equilibrium, such as the prisoner's dilemma game.\n\nProposition 1. In a dominance-solvable game, the empirical distribution of play of all types of regretminimization dynamics converge with high probability to the unique Nash equilibrium.\n\nProof. There are various ways to show this result. Consider the following induction argument. The game has at least one order of iterated elimination of strictly dominated strategies. Index the players according to one such order, such that player 1 has a dominant strategy, player 2 has a dominant strategy in the sub-game where player 1 plays her dominant strategy, and so on. Additionally, index the corresponding dominant strategies of the players using the same order, so that $a_{1}$ is the first action that is taken, $a_{2}$ is the second, and so on. Clearly, in any CCE, player 1 plays her dominant strategy $a_{1}$; otherwise she has positive regret. Our induction step is simple: Fix any CCE. Given that players $1, \\ldots, k-1$ play actions $a_{1}, \\ldots, a_{k-1}$, player $k$ has a strict best response to play $a_{k}$. By induction, this is true up to the last player $n$,so we have that our arbitrary CCE is the pure Nash equilibrium profile $\\left(a_{1}, \\ldots, a_{n}\\right)$. Therefore, regret-minimization dynamics converge to it with high probability.\n\nEquilibria of the game from Figure 1: To approach the outcome described in the introduction as an equilibrium, we need to adjust the payment policy of player 1 as follows. Player 1's agent pays player 2's agent the maximum payment whenever player 1's agent cooperates, and pays $1 / 3+\\epsilon$ when the outcome $(D, C)$ is obtained. Effectively, player 1 blocks player 2 from incentivizing player 1's agent to cooperate, so player 2's best response is not to pay anything and get $1 / 3+\\epsilon$. This is an $\\epsilon$-equilibrium for all $\\epsilon>0$, since player 1 incentivizes outcome $(D, C)$ in the limit $T \\rightarrow \\infty$, and she cannot improve her long-term payoff by more than $\\epsilon$. The other equilibrium, as mentioned, is the mirror image of the same equilibrium (replacing the payment policies of players 1 and 2 ).\n\nPrice of Stability and Price of Anarchy: Consider the symmetric game in Figure 3a, where in the prisoner's dilemma we have $x>y>1$. The equilibria of the game depend of the welfare gap between the game outcomes. There are two cases. If $x \\leq 2$, then the price of anarchy is trivially bounded by 2 , as this is the maximum utility gap in the game. If $x>2$, the payment game has two equilibria in which one agent pays the maximum amount when cooperating and pays $1+\\epsilon$ when the other agent cooperates, and the other agent does not make any payments. Each of these equilibria yields a welfare of $x$. Since $x>y$, we have $2 \\mathrm{~B} / \\mathrm{s}<2$, so the price of anarchy is at most 2 .\nIn the asymmetric game, we assume without loss of generality that $x_{1} \\geq x_{2}$. We have three cases to analyze. If $x_{1}, x_{2} \\leq 2$, then the players do not have profitable payment policies, so, as before, $P o A=P o S$ and both\n\nare trivially bounded by 2 . If $x_{1}>2$ and $x_{2} \\leq 2$, then only player 1 has a profitable payment policy and the payment game has a single equilibrium with the outcome $(D, C)$, which yields a welfare of $x_{1}$ Since $x_{1}>y_{1}, y_{2}$, we have $\\frac{y_{1}+y_{2}}{x_{1}}<2, P o A=P o S$, and both bounded by 2 . Finally, if $x_{1}, x_{2}>2$, as in the symmetric game, we have two equilibria for the payment game with outcomes $(D, C)$ or $(C, D)$. The $P o S$ in this case is at most 2 by the same argument as in the previous case. However, the ratio $x_{1} / x_{2}$ between the two equilibria can be unbounded, so the $P o A$ can be unbounded.", "tables": {}, "images": {}}, {"section_id": 14, "text": "# B Extension of Lemma 3 \n\nTo extend the lemmas of Theorem 2 to the case of $n$ players, consider the following analysis. Suppose we have $n$ players with values $v_{1}>v_{2}>v_{3}>\\cdots>v_{n}$, each using a regret-minimizing agent. If agent 2 bids $v_{3}$, agent 1 pays her $\\eta>0$. Lemma 3 and 2 have the following simple adjustments.\nAs in the proof of Lemma 1, we begin by assuming that in the game between these agents, parameterized by $\\eta$, there is a mixed Nash equilibrium with continuous CDFs, PDFs with full support on $\\left\\{v_{3}, v_{2}-\\eta\\right\\}$, and player 2 has a positive probability of bidding $v_{3}$. We start by looking at player 1's utility. In equilibrium, she is indifferent between bidding $v_{3}$ and bidding $v_{2}-\\eta$, giving us the (point-mass) probability that player 2 bids $v_{3}$ :\n\n$$\nv_{1}-\\left(v_{2}-\\eta\\right)-G_{2}\\left(v_{3}\\right) \\eta=G_{2}\\left(v_{3}\\right)\\left(v_{1}-v_{3}-\\eta\\right) \\quad \\Rightarrow \\quad G_{2}\\left(v_{3}\\right)=\\frac{v_{1}-v_{2}+\\eta}{v_{1}-v_{3}}\n$$\n\nPlayer 1's utility when bidding $x$ is $u_{1}(x, y)=G_{2}(x)\\left(v_{1}-x\\right)-\\chi(y) \\eta$, where $\\chi(y)$ is an indicator which equals 1 if player 2 bids zero and equals zero otherwise. As before, note that it is independent of $x$. Player 1 is indifferent between all her bids, so $\\frac{\\partial u_{1}(x, y)}{\\partial x}=0$, which gives $G_{2}^{\\prime}(x)\\left(v_{1}-x\\right)-G_{2}(x)=0$. We have an ordinary differential equation with a unique solution of the form\n\n$$\nG(x)=\\frac{c}{v_{1}-x}\n$$\n\nFrom continuity above $v_{3}$, we get that $c=v_{2} G_{2}(0)=v_{1}-v_{2}+\\eta$. Checking the consistency of the support (the CDF must be equal to 1 at the top of the support):\n\n$$\nG_{2}\\left(v_{2}-\\eta\\right)=\\frac{v_{1}-v_{2}+\\eta}{v_{1}-\\left(v_{2}-\\eta\\right)}=1\n$$\n\nSince player 2 is indifferent between bidding $x>v_{3}$ and bidding $v_{3}$ and getting a utility of $\\eta$, we have\n\n$$\n\\eta=F_{1}(x)\\left(v_{2}-x\\right) \\quad \\Rightarrow \\quad F_{1}(x)=\\frac{\\eta}{v_{2}-x}\n$$\n\nSo we have the CDFs\n\n$$\nF_{1}(x)=\\frac{\\eta}{v_{2}-x}, \\quad G_{2}(x)=\\frac{v_{1}-v_{2}+\\eta}{v_{1}-x}\n$$\n\nFor players $i>2$, since there is a positive probability that both players 1 and 2 bid $v_{3}$ at the same time, any bid above $v_{3}$ wins the auction with positive probability and gives negative expected utility, whereas any bid $b \\leq v_{3}$ gives a utility of zero. Therefore, any bid distribution for players $i>2$ that has zero weight on bids above $v_{3}$ forms a Nash equilibrium, together with the distributions $F_{1}, G_{2}$ for the first two players.\nThe expected payoff of player 1 is given by $\\mathbb{E}\\left[u_{1}\\right]=\\int_{0}^{v_{2}-\\eta}\\left(G_{2}(x)\\left(v_{1}-x\\right)-\\eta G_{2}(0)\\right) f(x) d x$, where the PDF is $f(x)=\\frac{\\eta}{\\left(v_{1}-x\\right)^{2}}$. Thus, we have\n\n$$\n\\mathbb{E}\\left[u_{1}\\right]=\\int_{0}^{v_{2}-\\eta}\\left(v_{1}-v_{2}+\\eta-\\eta\\left(1-\\frac{v_{2}-\\eta}{v_{1}}\\right)\\right) f(x) d x=v_{1}-v_{2}+\\eta\\left(\\frac{v_{2}-\\eta}{v_{1}}\\right)\n$$\n\nSo we see that in this equilibrium, player 1 manages to increase her payoff with a unilateral payment. The optimal payment is $\\eta^{*}=\\min \\left(v_{2} / 2, v_{2}-v_{3}\\right)$. The payoff for player 2 is $\\eta$.\nGiven the analysis above of Lemmas 1 and 2 with $n$ agents, the extension of Lemma 3 holds without any change to the proof, noticing the fact that since the minimum of the support is $v_{3}$, any player $j>2$ never wins the auction, so these agents can have arbitrary distributions with support at most $v_{3}$ with mean-based dynamics. Since this is a utility-improving deviation for player 1 from the zero-utility payment profile, the auction is not stable with $n$ players.", "tables": {}, "images": {}}, {"section_id": 15, "text": "# C Additional Definitions \n\nFor completeness, we provide here several standard definitions.\nRegret minimization: For a given sequence of action profiles $s^{1}, \\ldots, s^{T}$, the regret of agent $i$ is the difference in utility for $i$ between the actual utility in that sequence and the utility of the best fixed action in hindsight: Regret $_{i}\\left(s^{1}, \\ldots, s^{T}\\right)=\\max _{s \\in S_{i}} \\sum_{\\tau=1}^{T} u_{i}\\left(s, s_{-i}^{\\tau}\\right)-\\sum_{\\tau=1}^{T} u_{i}\\left(s_{i}^{\\tau}, s_{-i}^{\\tau}\\right)$. A no-regret agent minimizes this quantity in the long term. There are several formulations for this property, including high probability definitions; we give the following definition for completeness.\n\nDefinition 3. An algorithm satisfies the (external) regret-minimization property if, for a time horizon parameter $T$ and any $T$-sequence of play of the other players $\\left(s_{-i}^{1}, \\ldots, s_{-i}^{T}\\right)$, where $s_{i}^{t}$ and $s_{-i}^{t}$ denote the actions taken at time $t$ by the algorithm and by the other players, respectively, we have that in expectation over the actions taken by the algorithm, $\\max _{s \\in S_{i}} \\sum_{\\tau=1}^{T} u_{i}\\left(s, s_{-i}^{\\tau}\\right)-\\sum_{\\tau=1}^{T} u_{i}\\left(s_{i}^{\\tau}, s_{-i}^{\\tau}\\right)=o(T)$ as $T \\rightarrow \\infty$. An agent is regret-minimizing if it satisfies the regret-minimization property.\n\nCoarse correlated equilibria: Coarse correlated equilibria are a weaker notion than correlated equilibria [8], also known as the Hannan set or Hannan consistent distributions [52]. See also [93]. The simplest definition for our purpose is the following.\n\nDefinition 4. A joint distribution of play is a coarse correlated equilibrium if under this distribution all players have in expectation regret at most zero.\n\nMean-based learning algorithms: Mean-based learning algorithms [22] are a family of algorithms that play with high probability actions that are best responses to the history of play. This class was shown to include many standard no-regret algorithms, like multiplicative weights (see [5] and references therein), follow the perturbed leader [52,61], and EXP3 [7].\n\nDefinition 5. (From [22]). Let $\\sigma_{i, t}=\\sum_{t^{\\prime}=1}^{t} u_{i, t^{\\prime}}$, where $u_{i, t}$ is the utility of action $i$ at time $t$. An algorithm for the experts problem or the multi-armed bandits problem is $\\gamma(T)$-mean-based if it is the case that whenever $\\sigma_{i, t}<\\sigma_{j, t}-\\gamma(T) T$, then the probability that the algorithm pulls arm $i$ in round $t$ is at most $\\gamma(T)$. An algorithm is mean-based if it is $\\gamma(T)$-mean-based for some $\\gamma(T)=o(1)$.", "tables": {}, "images": {}}], "id": "2405.20880v2", "authors": ["Yoav Kolumbus", "Joe Halpern", "\u00c9va Tardos"], "categories": ["cs.GT", "cs.AI", "cs.MA", "econ.TH"], "abstract": "In repeated games, such as auctions, players typically use learning\nalgorithms to choose their actions. The use of such autonomous learning agents\nhas become widespread on online platforms. In this paper, we explore the impact\nof players incorporating monetary transfer policies into their agents'\nalgorithms, aiming to influence behavior in their favor through the dynamics\nbetween the agents. Our focus is on understanding when players have incentives\nto make use of monetary transfers, how such payments may affect learning\ndynamics, and what the implications are for welfare and its distribution among\nthe players. We propose a simple and general game-theoretic model to capture\nsuch scenarios. Our results on general games show that in a very broad class of\ngames, self-interested players benefit from letting their learning agents make\npayments to other learners during the game dynamics, and that in many cases,\nthis kind of behavior improves welfare for all players. Our results on first-\nand second-price auctions show that in equilibria of the ``payment policy\ngame,'' the agents' dynamics reach strong collusive outcomes with low revenue\nfor the auctioneer. These results raise new questions and highlight a challenge\nfor mechanism design in systems where automated learning agents can benefit\nfrom interacting with their peers in the digital ecosystem and outside the\nboundaries of the mechanism.", "updated": "2025-02-11T16:29:04Z", "published": "2024-05-31T14:55:11Z"}