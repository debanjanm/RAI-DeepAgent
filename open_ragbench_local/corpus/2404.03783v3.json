{
  "title": "Coherent risk measures and uniform integrability",
  "sections": [
    {
      "section_id": 0,
      "text": "#### Abstract\n\nWe establish a profound connection between coherent risk measures, a prominent object in quantitative finance, and uniform integrability, a fundamental concept in probability theory. Instead of working with absolute values of random variables, which is convenient in studying integrability, we work directly with random losses and gains, which have a clear financial interpretation. We introduce a technical tool called the folding score of distortion risk measures. The analysis of the folding score allows us to convert some conditions on absolute values to those on losses and gains. As our main results, we obtain three sets of equivalent conditions for uniform integrability. In particular, a set is uniformly integrable if and only if one can find a coherent distortion risk measure that is bounded on the set, but not finite on $L^{1}$.\n\n\nKeywords: Expected Shortfall, distortion risk measures, folding scores, law invariance, law of large numbers",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 1,
      "text": "## 1 Introduction\n\nCoherent risk measures, introduced by Artzner et al. (1999), have been a cornerstone of quantitative finance. The development on risk measures has proven prolific in both academic research and financial regulation; we refer to F\u00f6llmer and Schied (2016) and McNeil et al. (2015) for general treatments on risk measures and their applications. In particular, the Value-at-Risk (VaR) and the Expected Shortfall (ES, also known as CVaR, TVaR and AVaR) are the two most important risk measures in the financial industry; see the regulatory document of BCBS (2019) in the banking sector.\n\nOur main goal is to connect coherent risk measures to uniform integrability, an old concept in probability theory, useful in many domains of analysis. As an example of financial relevance, for a\n\n[^0]\n[^0]:    *Department of Statistics and Actuarial Science, University of Waterloo, Canada. m5huang@uwaterloo.ca.\n    ${ }^{\\dagger}$ Department of Statistics and Actuarial Science, University of Waterloo, Canada. wang@uwaterloo.ca.\n\nsequence of random variables that converges in distribution, e.g., estimated financial models from data that converge to the true model, uniform integrability guarantees convergence of many risk measures, including ES. Continuity of a risk measure with respect to distributional convergence is associated with robustness of the risk measure by Cont et al. (2010). See Kr\u00e4tschmer et al. (2014) and Embrechts et al. (2022) for recent developments on the robustness of risk measures. Uniform integrability is a useful condition in many financial models, especially in the context of martingales; see e.g., K\u00e4llblad et al. (2018) and Bayraktar et al. (2020).\n\nWe will study conditions on values of a coherent risk measure applied to random variables in a set $\\mathcal{S}$ that characterize uniform integrability of $\\mathcal{S}$. There is a subtle difference for conditions typically used in probability theory and those in the literature of risk measures. Due to the definition of uniform integrability, it is conventional to consider conditions on $|X|$ for $X \\in \\mathcal{S}$. Suppose that the random variable $X$ represents a financial position (an asset), with its positive realized values representing losses and negative ones representing gains, a convention used by McNeil et al. (2015) (a sign change from F\u00f6llmer and Schied (2016)). For a risk measure $\\rho$, the value $\\rho(X)$ has a concrete interpretation as regulatory capital requirement for a long position in the asset. Similarly, $\\rho(-X)$ also has a concrete meaning, as the regulatory capital requirement for a short position in the asset. In conic finance (see Madan and Cherny (2010)), $\\rho(-X)$ can also represent the price of the asset with payoff $-X$. In an insurance setting, $\\rho(X)$ would represent the price of the random loss $X$. On the other hand, $\\rho(|X|)$, which evaluates the risk of the absolute value of $X$, does not have a reasonable financial meaning. Recall that monotonicity of $\\rho$ has the natural interpretation of \"less loss is better\", but $X \\mapsto \\rho(|X|)$ is not monotone and loses such meaning. The quantity $\\rho(|X|)$ seems to be only relevant for technical analysis but it does not appear in any economic problems.\n\nAs a concrete example, in the optimal investment problem in Section 6, an upper bound on $\\rho(X)$ naturally appears as a risk constraint (see e.g., Basak and Shapiro (2001) and Rockafellar and Uryasev (2002) for using risk measures as risk constraints), and an upper bound on $\\rho(-X)$ naturally appears as a budget constraint (one can use a different $\\rho$ when both constraints exist). In such a context, $\\rho(|X|)$ is irrelevant.\n\nFor the above reasons, we would hope to formulate conditions using $\\rho(X)$ and $\\rho(-X)$, which are financially interpretable, instead of using $\\rho(|X|)$. Moreover, conditions on $\\rho(X)$ and $\\rho(-X)$ are easier to check for common financial models of $X$ than $|X|$; see McNeil et al. (2015, Chapter 2) for some existing formulas. To formulate conditions on $\\rho(X)$ and $\\rho(-X)$, we introduce a technical tool called the folding score of distortion risk measures in Section 3, which quantifies the supremum of $\\rho(|Y|) / \\max \\{\\rho(Y), \\rho(-Y)\\}$ over $Y \\in L^{1}$. A useful result on the folding score (Theorem 3.1) allows us to conveniently convert conditions on $\\rho(|X|)$ to those on $\\rho(X)$ and $\\rho(-X)$.\n\nIn particular, we show that for the class of coherent distortion risk measures, boundedness of $\\rho(|X|)$ for $X \\in \\mathcal{S}$ is equivalent to boundedness of $\\rho(X)$ and $\\rho(-X)$, unless $\\rho$ is the expectation.\n\nWith the help from the folding score, we obtain in Section 4 three different sets of equivalent conditions for uniform integrability, using ES, coherent distortion risk measures, or law-invariant coherent risk measures. As a particularly convenient result, in Theorem 4.2 we find that $\\mathcal{S}$ is uniformly integrable if and only if one can find a coherent distortion risk measure that is not finite on $L^{1}$ and bounded on $\\mathcal{S}$ and $-\\mathcal{S}$. This result closely resembles the classic characterization of uniform integrability via the de la Vall\u00e9e Poussin criterion; see e.g., Meyer (1966, Theorem T22). As intermediate results, we also obtain that a law-invariant coherent risk measure is finite on $L^{1}$ if and only if it is controlled by a constant times the expectation for positive random variables, and for coherent distortion risk measures this is equivalent to a bounded slope of its distortion function. These intermediate results are closely related to the recent results of Fr\u00f6hlich and Williamson (2024) in the context of rearrangement-invariant Banach norms. Further, we extend the boundedness condition of $\\rho$ on $\\mathcal{S}$ and $-\\mathcal{S}$ discussed above to a similar condition on two possibly different risk measures in Theorem 4.8.\n\nThree consequences of our main results on a law of large numbers, the convergence of ES values, and convergent sequences in 1-Wasserstein distance are presented in Section 5, and they direct follow from uniform integrability. As a financial application, in Section 6 we consider an investment problem, where a decision maker has an optimization problem subject to a risk constraint and a price constraint on the financial position, via two coherent risk measures. Applying Theorem 4.8, the two constraints imply uniform integrability of the set of possible positions, and this fact can be further leveraged to show the convergence of approximate optimizers to a true optimizer. Section 7 concludes the paper.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 2,
      "text": "# 2 Notation and preliminaries \n\nLet $\\mathcal{X}$ be the set of all random variables in an atomless probability space $(\\Omega, \\mathcal{F}, \\mathbb{P})$. Let $L^{\\infty}$ be the set of essentially bounded random variables in $\\mathcal{X}$ and $L^{1}$ be the set of integrable ones in $\\mathcal{X}$. Further, $L_{+}^{1}$ (resp. $L_{+}^{\\infty}$ ) is the set of nonnegative random variables in $L^{1}$ (resp. $L^{\\infty}$ ). Almost surely equal random variables are treated as identical. We write $X \\stackrel{\\mathrm{~d}}{=} Y$ if $X$ and $Y$ have the same distribution. We identify constant random variables with elements in $\\mathbb{R}$. Denote by $x \\vee y=\\max \\{x, y\\}$ and $x \\wedge y=\\min \\{x, y\\}$ for real values $x$ and $y$.\n\nA risk measure is a functional $\\rho: \\mathcal{L} \\rightarrow(-\\infty, \\infty]$ that is finite on $\\mathbb{R}$, where the domain $\\mathcal{L}$ is a convex cone of random variables in $\\mathcal{X}$ containing $\\mathbb{R}$; examples of $\\mathcal{L}$ are $\\mathcal{X}, L^{1}$ or $L^{\\infty}$. We take the interpretation that a random variable in $\\mathcal{L}$ represents loss/profit of a financial position\n\n(following e.g., McNeil et al. (2015)). A coherent risk measure is a risk measure $\\rho$ satisfying the following four properties (called axioms in the literature).\n\nMonotonicity: $\\rho(X) \\leqslant \\rho(Y)$ for all $X, Y \\in \\mathcal{L}$ with $X \\leqslant Y$.\nCash invariance: $\\rho(X+c)=\\rho(X)+c$ for all $X \\in \\mathcal{L}$ and $c \\in \\mathbb{R}$.\nConvexity: $\\rho(\\lambda X+(1-\\lambda) Y) \\leqslant \\lambda \\rho(X)+(1-\\lambda) \\rho(Y)$ for all $X, Y \\in \\mathcal{L}$ and $\\lambda \\in(0,1)$.\nPositive homogeneity: $\\rho(\\lambda X)=\\lambda \\rho(X)$ for all $X \\in \\mathcal{L}$ and $\\lambda>0$.\nMoreover, a convex risk measure is a risk measure that satisfies the first three properties in the above list (F\u00f6llmer and Schied (2002) and Frittelli and Rosazza Gianin (2002)), and a monetary risk measure is a risk measure that satisfies the first two properties in the above list. Coherent risk measures automatically satisfy normalization, that is, $\\rho(0)=0$. We refer to F\u00f6llmer and Schied (2016) for interpretations of these properties, which are nowadays standard in the field. Two further properties below are also standard and useful in this paper.\n\nLaw invariance: $\\rho(X)=\\rho(Y)$ for all $X, Y \\in \\mathcal{L}$ with $X \\stackrel{\\Delta}{=} Y$.\nLower semicontinuity (for $L^{1}$ convergence): $\\liminf _{n \\rightarrow \\infty} \\rho\\left(X_{n}\\right) \\geqslant \\rho(X)$ if $X_{n} \\rightarrow X$ in $L^{1}$ as $n \\rightarrow \\infty$.\n\nComonotonic additivity: $\\rho(X)+\\rho(Y)=\\rho(X+Y)$ whenever $X, Y \\in \\mathcal{L}$ are comonotonic, i.e., $X$ and $Y$ are both increasing functions of some random variable $U$.\n\nLower semicontinuity in the paper always refers to $L^{1}$-convergence (omitted), but this does not require $\\mathcal{L}=L^{1}$. Two popular classes of monetary risk measures in financial practice are VaR and ES, which are law-invariant, lower semicontinuous, and defined on $\\mathcal{X}$. VaR at level $p \\in(0,1)$ is defined as\n\n$$\n\\operatorname{VaR}_{p}(X)=\\inf \\{x \\in \\mathbb{R}: \\mathbb{P}(X \\leqslant x) \\geqslant p\\}, \\quad X \\in \\mathcal{X}\n$$\n\nand ES at level $p \\in(0,1)$ as\n\n$$\n\\mathrm{ES}_{p}(X)=\\frac{1}{1-p} \\int_{p}^{1} \\operatorname{VaR}_{q}(X) \\mathrm{d} q, \\quad X \\in \\mathcal{X}\n$$\n\nNote that $\\operatorname{ES}_{p}(X)$ is finite if and only if $\\mathbb{E}\\left[X_{+}\\right]<\\infty$. Either VaR or ES can be characterized by a few axioms; see Kou and Peng (2016) and Wang and Zitikis (2021).\n\nBoth VaR and ES belong to the more general class of distortion risk measures, which plays an important role in this paper. Let $\\mathcal{D}$ be the set of functions $h:[0,1] \\rightarrow[0,1]$ that are\n\nincreasing (in the non-strict sense) with $h(0)=0$ and $h(1)=1$. For $h \\in \\mathcal{D}$, the Choquet integral of a random variable $X$ with respect to $h \\circ \\mathbb{P}$ is given by\n\n$$\n\\int X \\mathrm{~d}(h \\circ \\mathbb{P})=\\int_{0}^{\\infty} h(\\mathbb{P}(X>x)) \\mathrm{d} x+\\int_{-\\infty}^{0}(h(\\mathbb{P}(X>x))-1) \\mathrm{d} x\n$$\n\nwhich may be undefined or infinite. If $X$ is nonnegative, then $\\mathbb{P}(X>x)=1$ for all $x \\in(-\\infty, 0]$ and we are left with only the first integral. For $h \\in \\mathcal{D}$, the distortion risk measure $\\rho_{h}$ is defined by\n\n$$\n\\rho_{h}(X)=\\int X \\mathrm{~d}(h \\circ \\mathbb{P}), \\quad X \\in \\mathcal{L}\n$$\n\nwhere $\\mathcal{L}$ is chosen such that $\\int X \\mathrm{~d}(h \\circ \\mathbb{P})$ takes values in $(-\\infty, \\infty]$, i.e., the second term in the Choquet integral is finite. The function $h$ is called the distortion functions of $\\rho_{h}$. The following properties of distortion risk measures and Choquet integrals are well known (see Wang et al. (2020) for a summary) and will be used frequently in the paper.\n(a) The Choquet integral $\\int X \\mathrm{~d}(h \\circ \\mathbb{P})$ is well-defined and finite on $L^{\\infty}$. Therefore, we will always assume $\\mathcal{L} \\supseteq L^{\\infty}$ below implicitly.\n(b) The class of distortion risk measures $\\rho_{h}$ on $L^{\\infty}$ is precisely the class of law-invariant, monotone, and comonotonic-additive mappings $\\rho: L^{\\infty} \\rightarrow \\mathbb{R}$ with $\\rho(1)=1$.\n(c) If $h$ is left-continuous, then we can write\n\n$$\n\\int X \\mathrm{~d}(h \\circ \\mathbb{P})=\\int_{0}^{1} \\operatorname{VaR}_{1-q}(X) \\mathrm{d} h(q), \\quad \\text { for each } X \\text { such that } \\int X \\mathrm{~d}(h \\circ \\mathbb{P}) \\text { is well-defined. }\n$$\n\n(d) If $h$ is concave, then we can choose $L^{1} \\subseteq \\mathcal{L}$ and $\\rho_{h}$ is lower semicontinuous.\n(e) The risk measure $\\rho_{h}$ is coherent if and only if $h$ is concave.\n(f) If $h$ is the identity on $[0,1]$, then $\\rho_{h}=\\mathbb{E}$; hence $\\rho_{h} \\geqslant \\mathbb{E}$ if $h$ is concave.\n(g) If $h(t)=(t /(1-p)) \\wedge 1$ for $p \\in(0,1)$, then $\\rho_{h}=\\mathrm{ES}_{p}$, which is a coherent risk measure.\n\nFor all coherent distortion risk measures in this paper, their domain will be chosen as $L^{1}$, although we initially formulated $\\mathrm{ES}_{p}$ on the larger set $\\mathcal{X}$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 3,
      "text": "# 3 Folding score \n\nIn this section, we introduce a technical tool and provide some results on distortion risk measures, which will be used in the proofs of our main results in Section 4 on uniform integrability.\n\nLet $\\rho$ be a risk measure on $\\mathcal{L}$. A new quantity $s_{\\rho}$ will be useful in our later analysis, which is defined by\n\n$$\ns_{\\rho}=\\sup _{X \\in \\mathcal{L}} \\frac{\\rho(|X|)}{|\\rho(X)| \\vee|\\rho(-X)|}=\\sup _{X \\in \\mathcal{L}} s_{\\rho}(X), \\quad \\text { where } s_{\\rho}(X)=\\frac{\\rho(|X|)}{|\\rho(X)| \\vee|\\rho(-X)|}\n$$\n\nwhere we set $\\infty / \\infty=1,0 / 0=1$, and $1 / 0=\\infty$. The quantity $s_{\\rho}$ will be called the folding score of $\\rho$. To explain the name, recall that the distribution of $|X|$ is the folded distribution of $X$. Intuitively, $s_{\\rho}$ measures how large $\\rho(|X|)$, the risk measure $\\rho$ applied to the \"folded\" random variable $X$, can be relative to $|\\rho(X)|$ and $|\\rho(-X)|$. Clearly, $s_{\\rho} \\geqslant 1$ for common risk measures, e.g., those satisfying $\\rho(x)=x$ for $x \\in \\mathbb{R}$. We are particularly interested in whether $s_{\\rho}$ is finite. If $\\rho=\\mathbb{E}^{Q}$ for a probability $Q$ (absolutely continuous with respect to $\\mathbb{P}$ ), then $s_{\\rho}$ is infinite, because the denominator can be 0 while the numerator is positive; for instance, this happens for any non-degenerate random variable symmetric about 0 . Thus, for a linear functional $\\rho=\\mathbb{E}^{Q}$, we have $s_{\\rho}=\\infty$.\n\nIf $\\rho$ is a normalized convex risk measure, then $\\rho(X)+\\rho(-X) \\geqslant 2 \\rho(0)=0$ for all $X \\in \\mathcal{L}$. Therefore, we can remove the absolute values in the denominator in the definition of $s_{\\rho}$ and $s_{\\rho}(X)$, that is,\n\n$$\ns_{\\rho}=\\sup _{X \\in \\mathcal{L}} \\frac{\\rho(|X|)}{\\rho(X) \\vee \\rho(-X)} \\quad \\text { and } \\quad s_{\\rho}(X)=\\frac{\\rho(|X|)}{\\rho(X) \\vee \\rho(-X)}\n$$\n\nWe will conveniently work with this formulation since most of our results are obtained for coherent risk measures.\n\nOur main result in this section is an upper bound on $s_{\\rho}$ for a coherent distortion risk measure $\\rho$. In particular, we would like to understand whether $\\rho=\\mathbb{E}$ is the only case where $s_{\\rho}=\\infty$ among distortion risk measures. This turns out to be true.\n\nTheorem 3.1. Suppose that $\\rho$ is a coherent distortion risk measure on $L^{1}$ with distortion function $h \\in \\mathcal{D}$. If $h$ is not the identity, then\n\n$$\n1 \\leqslant s_{\\rho} \\leqslant \\frac{h(1 / 2)+1 / 2}{h(1 / 2)-1 / 2}<\\infty\n$$\n\nAs a consequence, $s_{\\rho}=\\infty$ if and only if $\\rho$ is the mean.\nBefore proving the theorem, we first present a simple algebraic lemma.\nLemma 3.2. For $a, b \\in[0,1]$, we have\n\n$$\n\\max _{x, y>0} \\frac{x+y}{(x-a y) \\vee(y-b x)}=\\frac{2+a+b}{1-a b}\n$$\n\nProof. With the substitution $z=y / x$,\n\n$$\n\\max _{x, y>0} \\frac{x+y}{(x-a y) \\vee(y-b x)}=\\max _{z>0} \\frac{1+z}{(1-a z) \\vee(z-b)}\n$$\n\nIt suffices to maximize $f(z)$ defined by $f(z)=(1+z) /((1-a z) \\vee(z-b))$ for $z>0$. If $a b=1$ (i.e., $a=b=1$ ), then by taking $z=1$ we have $f(z)=\\infty$. Next, suppose $a b<1$. Let $z_{0}=(1+b) /(1+a)$. Note that $a b<1$ implies $z_{0}>b$, and we have\n\n$$\nf\\left(z_{0}\\right)=\\frac{2+a+b}{1-a b}\n$$\n\nIf $z \\leqslant z_{0}$ then $f(z)=(1+z) /(1-a z)$, which is increasing in $z$, yielding $f(z) \\leqslant f\\left(z_{0}\\right)$. If $z \\geqslant z_{0}$, then $f(z)=(1+z) /(z-b)=(1-b) /(z-b)+1$, which is decreasing in $z$, yielding $f(z) \\leqslant f\\left(z_{0}\\right)$. Therefore, $z=z_{0}$ maximizes $f(z)$.\n\nProof of Theorem 3.1. Note that if $h$ is concave and not the identity, then $h(q)>q$ for all $q \\in(0,1)$, and hence the third inequality in (3.1) is automatic. The first inequality $1 \\leqslant s_{\\rho}$ is also automatic. Below, we show the remaining inequality in (3.1), that is,\n\n$$\n\\frac{\\rho_{h}(|X|)}{\\rho_{h}(X) \\vee \\rho_{h}(-X)} \\leq \\frac{h(1 / 2)+1 / 2}{h(1 / 2)-1 / 2} \\quad \\text { for all } X \\in L^{1}\n$$\n\nTake $X \\in L^{1}$. If $X \\geqslant 0$ or $X \\leqslant 0$, then $\\rho_{h}(|X|)=\\rho_{h}(X) \\vee \\rho_{h}(-X)$, and the desired inequality holds. For a general $X$, define the following quantities,\n\n$$\n\\begin{aligned}\n& A=\\int_{0}^{\\infty} h(\\mathbb{P}(X>x)) \\mathrm{d} x \\\\\n& B=\\int_{0}^{\\infty} h(\\mathbb{P}(-X>x)) \\mathrm{d} x=\\int_{-\\infty}^{0} h(\\mathbb{P}(X<x)) \\mathrm{d} x \\\\\n& C=\\int_{-\\infty}^{0}(1-h(\\mathbb{P}(X>x))) \\mathrm{d} x \\\\\n& D=\\int_{-\\infty}^{0}(1-h(\\mathbb{P}(-X>x))) \\mathrm{d} x=\\int_{0}^{\\infty}(1-h(\\mathbb{P}(X<x))) \\mathrm{d} x\n\\end{aligned}\n$$\n\nNote that $A, B, C, D$ are all nonnegative, and $C$ and $D$ are bounded from above. Clearly,\n\n$$\n\\rho_{h}(X)=A-C \\text { and } \\rho_{h}(-X)=B-D\n$$\n\nMoreover, concavity of $h$ implies $h(s+t)=h(s+t)+h(0) \\leqslant h(s)+h(t)$ for $s, t \\in[0,1]$ and\n\n$s+t \\leqslant 1$. Since $\\mathbb{P}(|X|>x)=\\mathbb{P}(X>x)+\\mathbb{P}(X<-x)$ for $x \\geqslant 0$, we have\n\n$$\n\\begin{aligned}\n\\rho_{h}(|X|) & =\\int_{0}^{\\infty} h(\\mathbb{P}(X>x)+\\mathbb{P}(X<-x)) \\mathrm{d} x \\\\\n& \\leqslant \\int_{0}^{\\infty} h(\\mathbb{P}(X>x)) \\mathrm{d} x+\\int_{0}^{\\infty} h(\\mathbb{P}(X<-x)) \\mathrm{d} x=A+B\n\\end{aligned}\n$$\n\nIf one of $A$ and $B$ is infinite, then $\\rho_{h}(|X|) \\geqslant A \\vee B=\\infty=\\rho_{h}(X) \\vee \\rho_{h}(-X)$, and the desired inequality (3.1) holds. Below we assume that $A$ and $B$ are finite.\n\nLet $g \\in \\mathcal{D}$ be defined by $g(t)=1-h(1-t)$. Clearly, $g$ is convex. Noting that $t \\mapsto g(t) / t$ is increasing and $t \\mapsto h(t) / t$ is decreasing, we have that $g / h$ is increasing on $(0,1]$. Therefore, using the fact that $\\mathbb{P}(X=x)>0$ for at most countably many $x \\in \\mathbb{R}$, we have\n\n$$\n\\begin{aligned}\n\\frac{D}{A} & =\\frac{\\int_{0}^{\\infty}(1-h(\\mathbb{P}(X<x))) \\mathrm{d} x}{\\int_{0}^{\\infty} h(\\mathbb{P}(X>x)) \\mathrm{d} x} \\\\\n& =\\frac{\\int_{0}^{\\infty} g(\\mathbb{P}(X>x)) \\mathrm{d} x}{\\int_{0}^{\\infty} h(\\mathbb{P}(X>x)) \\mathrm{d} x} \\leqslant \\sup _{x \\geqslant 0} \\frac{g(\\mathbb{P}(X>x))}{h(\\mathbb{P}(X>x))}\n\\end{aligned}\n$$\n\nLet $z=\\mathbb{P}(X<0)$, we have\n\n$$\n\\frac{g(\\mathbb{P}(X>x))}{h(\\mathbb{P}(X>x))} \\leqslant \\frac{g(\\mathbb{P}(X>0))}{h(\\mathbb{P}(X>0))}=\\frac{g(1-z)}{h(1-z)}=: b\n$$\n\nand therefore $D / A \\leqslant b$. Analogous arguments also yield\n\n$$\n\\frac{C}{B} \\leqslant \\frac{\\int_{-\\infty}^{0} g(\\mathbb{P}(X<x)) \\mathrm{d} x}{\\int_{-\\infty}^{0} h(\\mathbb{P}(X<x)) \\mathrm{d} x} \\leqslant \\frac{g(z)}{h(z)}=: a\n$$\n\nNote that both $a$ and $b$ take values in $[0,1)$ since $g$ is convex and not the identity. The above inequalities yield\n\n$$\n\\frac{\\rho_{h}(|X|)}{\\rho_{h}(X) \\vee \\rho_{h}(-X)} \\leqslant \\frac{A+B}{(A-C) \\vee(B-D)} \\leqslant \\frac{A+B}{(A-a B) \\vee(B-b A)}\n$$\n\nUsing Lemma 3.2, we get\n\n$$\ns_{\\rho_{h}}(X) \\leqslant \\frac{2+a+b}{1-a b}\n$$\n\nNote that $a$ increases in $z$ and $b$ decreases in $z$. Denote by $c=g(1 / 2) / h(1 / 2)$. Since either $z \\leqslant 1 / 2$ or $z>1 / 2$, we have either $a \\leqslant c$ or $b \\leqslant c$. This gives $a+b \\leqslant 1+c$ and $a b \\leqslant c$. Therefore,\n\n$$\ns_{\\rho_{h}}(X) \\leqslant \\frac{3+c}{1-c}=\\frac{3-2 g(1 / 2)}{1-2 g(1 / 2)}=\\frac{h(1 / 2)+1 / 2}{h(1 / 2)-1 / 2}\n$$\n\nThe desired inequality (3.1) follows.\n\nNote that in Theorem 3.1, concavity of $h$ does not exclude the possibility that $h$ is discontinuous at 0 . The following proposition states a simple consequence of $s_{\\rho}<\\infty$. Our later results will mainly use this proposition.\n\nProposition 3.3. Let $\\mathcal{S}$ be a set of random variables and $\\rho$ be a normalized convex risk measure on $\\mathcal{L}$ satisfying $s_{\\rho}<\\infty$ such that $\\{X,-X,|X|\\} \\subseteq \\mathcal{L}$ for $X \\in \\mathcal{S}$. The following are equivalent.\n(i) $\\rho(X)$ and $\\rho(-X)$ are both bounded for $X \\in \\mathcal{S}$;\n(ii) $\\rho(|X|)$ is bounded for $X \\in \\mathcal{S}$.\n\nIn particular, this equivalence holds for $\\rho=\\rho_{h}$, where $h \\in \\mathcal{D}$ is concave and not the identity.\nProof. (i) $\\Rightarrow$ (ii). This follows from the definition of $s_{\\rho}$ : Note that\n\n$$\n\\infty>s_{\\rho} \\geqslant \\sup _{X \\in \\mathcal{S}} \\frac{\\rho(|X|)}{\\rho(X) \\vee \\rho(-X)}\n$$\n\nand hence boundedness of $\\rho(X) \\vee \\rho(-X)$ implies boundedness of $\\rho(|X|)$.\n(ii) $\\Rightarrow$ (i). Since the risk measure $\\rho$ is monotone, we have $\\rho(|X|) \\geqslant \\rho(X)$ and $\\rho(|X|) \\geqslant \\rho(-X)$; hence, both $\\rho(X)$ and $\\rho(-X)$ are bounded from above. Convexity of $\\rho$ gives $\\rho(X)+\\rho(-X) \\geqslant$ $2 \\rho(0)=0$. This guarantees that $\\rho(X)$ and $\\rho(-X)$ are bounded from below, noting that each of $\\rho(X)$ and $\\rho(-X)$ is bounded from above.\n\nThe last statement for $\\rho=\\rho_{h}$ follows from Theorem 3.1.\nThe condition $\\{X,-X,|X|\\} \\subseteq \\mathcal{L}$ for $X \\in \\mathcal{S}$ is needed for $s_{\\rho}(X)$ to be well-defined for $X \\in \\mathcal{S}$. In most results later, we often encounter the situation $\\mathcal{S} \\subseteq L^{1} \\subseteq \\mathcal{L}$, so that this condition is satisfied automatically.\n\nSharpness of the bound in Theorem 3.1 and its extensions to other risk measures are studied in Appendix A. In Section 4, we will use a pair of conditions involving $|X|$ and $\\pm X$ similar to Proposition 3.3 to characterize uniform integrability.\n\nRemark 3.4. Let $\\rho$ be a law-invariant coherent risk measure on $L^{\\infty}$. If\nthere exists a non-degenerate $X$ such that $\\rho(X)=-\\rho(-X)$,\nthen for $Y=X-\\rho(X)$, we have $\\rho(Y)=0=\\rho(-Y)$, but $\\rho(|Y|) \\geqslant \\mathbb{E}[|Y|]>0$. Therefore, $s_{\\rho}=\\infty$ in this case. Note that (3.2) is sufficient to force $\\rho$ to be the mean; see Castagnoli et al. (2004), Bellini et al. (2021) and Liebrich and Munari (2022) for related results and generalizations. Our Theorem 3.1 can be seen as a strengthening of this result for distortion risk measures, because $s_{\\rho}=\\infty$ is a weaker condition than (3.2).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 4,
      "text": "# 4 Uniform integrability\n### 4.1 Characterizing uniform integrability using ES\n\nA set $\\mathcal{S}$ of random variables is uniformly integrable if\n\n$$\n\\sup _{X \\in \\mathcal{S}} \\mathbb{E}\\left[|X| \\mathbb{1}_{\\{|X|>K\\}}\\right] \\rightarrow 0 \\text { as } K \\rightarrow \\infty\n$$\n\nIn our case, the random variables in $\\mathcal{S}$ are defined on an atomless probability space $(\\Omega, \\mathcal{F}, \\mathbb{P})$, and clearly any uniformly integrable set is a subset of $L^{1}$. Under this setting, uniform integrability of $\\mathcal{S}$ has the following characterization (see Meyer (1966, Theorem T19)):\n\nFor every $\\varepsilon>0$, there exists $\\delta>0$ such that\n\n$$\n\\int_{A}|X| \\mathrm{d} \\mathbb{P}<\\varepsilon \\text { for all } X \\in \\mathcal{S} \\text { and } A \\in \\mathcal{F} \\text { with } \\mathbb{P}(A) \\leqslant \\delta\n$$\n\nMoreover, we can safely replace $\\mathbb{P}(A) \\leqslant \\delta$ in (4.1) by $\\mathbb{P}(A)=\\delta$.\nWe have the following characterization theorem of uniform integrability. The equivalence of (i) and (ii) appeared in Wu et al. (2024, Lemma 7.3); here we supply a shorter proof. Statement (ii) below is easier to work with in technical analysis, whereas statement (iii) has clearer meaning for financial applications. For this result, we treat the domain of $\\mathrm{ES}_{p}$ for $p \\in(0,1)$ as $\\mathcal{X}$, thus allowing for infinite values of $\\mathrm{ES}_{p}(X)$.\n\nTheorem 4.1. Let $\\mathcal{S}$ be a set of random variables. The following statements are equivalent.\n(i) $\\mathcal{S}$ is uniformly integrable;\n(ii) $\\sup _{X \\in \\mathcal{S}}(1-p) \\mathrm{ES}_{p}(|X|)$ tends to 0 as $p \\uparrow 1$;\n(iii) both $\\sup _{X \\in \\mathcal{S}}(1-p) \\mathrm{ES}_{p}(X)$ and $\\sup _{X \\in \\mathcal{S}}(1-p) \\mathrm{ES}_{p}(-X)$ tend to 0 as $p \\uparrow 1$.\n\nProof. (i) $\\Leftrightarrow$ (ii). We will use the following well-known result on the representation of ES (e.g., Eq. (3.1) of Embrechts and Wang (2015)): For any random variable $X$ and $p \\in(0,1)$,\n\n$$\n\\mathrm{ES}_{p}(X)=\\sup \\{\\mathbb{E}[X \\mid A]: A \\in \\mathcal{F}, \\mathbb{P}(A)=1-p\\}\n$$\n\nGiven $\\varepsilon>0$, by letting $\\delta=1-p$ in (ii), using (4.2), we have\n\n$$\n\\sup _{X \\in \\mathcal{S}}(1-p) \\mathrm{ES}_{p}(|X|)=\\sup _{X \\in \\mathcal{S}} \\sup _{A \\in \\mathcal{F}_{\\delta}} \\delta \\mathbb{E}[X \\mid A]=\\sup _{X \\in \\mathcal{S}} \\sup _{A \\in \\mathcal{F}_{\\delta}} \\int_{A}|X| \\mathrm{d} \\mathbb{P}\n$$\n\nwhere $\\mathcal{F}_{\\delta}=\\{A \\in \\mathcal{F}: \\mathbb{P}(A)=\\delta\\}$. Since uniform integrability (i) is equivalent to (4.1), we know that it is also to equivalent to (ii).\n\n(ii) $\\Leftrightarrow$ (iii). For $p>1 / 2$ the ratio of $\\operatorname{ES}_{p}(|X|)$ to $\\operatorname{ES}_{p}(X) \\vee \\operatorname{ES}_{p}(-X)$ is bounded below by 1 and above by a constant from Theorem 3.1 (Example A. 1 shows this range is contained in $[1,3]$ ). As $p \\uparrow 1$, this uniform bound applies and hence (ii) and (iii) are equivalent.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 5,
      "text": "# 4.2 Uniform integrability and distortion risk measures \n\nUsing the equivalence of (i) and (ii) from Theorem 4.1, we have the following characterization of uniform integrability in terms of distortion risk measures. In what follows, let $\\mathcal{D}_{c}$ be the set of concave functions $h \\in \\mathcal{D}$ with $h(t) / t \\rightarrow \\infty$ as $t \\downarrow 0$. Recall that the domain of all coherent distortion risk measures $\\rho_{h}$ is chosen as $L^{1}$.\n\nTheorem 4.2. For any $\\mathcal{S} \\subseteq L^{1}$, the following are equivalent.\n(i) $\\mathcal{S}$ is uniformly integrable;\n(ii) there exists $h \\in \\mathcal{D}_{c}$ such that $\\rho_{h}(|X|)$ is bounded for $X \\in \\mathcal{S}$;\n(iii) there exists $h \\in \\mathcal{D}_{c}$ such that $\\rho_{h}(X)$ and $\\rho_{h}(-X)$ are bounded for $X \\in \\mathcal{S}$.\n\nProof. (ii) $\\Rightarrow$ (i). We proceed by contrapositive. Suppose that $\\mathcal{S}$ is not uniformly integrable. Then there exists $m>0$ and for each $n \\in \\mathbb{N}$, there exist $p_{n}$ and $X_{n}$ such that $\\left(1-p_{n}\\right) \\mathrm{ES}_{p_{n}}\\left(\\left|X_{n}\\right|\\right)>m$.\n\nWe show that $\\rho_{h}(|X|)$ is unbounded for $X \\in \\mathcal{S}$. That is, given $M>0$, we construct some $X$ such that $\\rho_{h}(|X|)>M$. Choose $p_{N}$ in the sequence $p_{n}$ such that $1-p<M / m$. Let $p=p_{N}$ and $X=X_{N}$. Denote by\n\n$$\nh_{p}(t)=(t /(1-p)) \\wedge 1\n$$\n\nthat is, the distortion function corresponding to $\\mathrm{ES}_{p}$. We have\n\n$$\n\\begin{aligned}\n\\rho_{h}(|X|) & =\\int_{0}^{\\infty} h(\\mathbb{P}(|X|>x)) \\mathrm{d} x \\\\\n& \\geqslant \\int_{0}^{\\infty} h(\\mathbb{P}(|X|>x) \\wedge(1-p)) \\mathrm{d} x \\\\\n& \\geqslant \\frac{M}{m} \\int_{0}^{\\infty} \\mathbb{P}(|X|>x) \\wedge(1-p) \\mathrm{d} x \\\\\n& \\geqslant \\frac{M}{m} \\int_{0}^{\\infty}(1-p) h_{p}(\\mathbb{P}(|X|>x)) \\mathrm{d} x \\geqslant \\frac{M}{m}(1-p) \\mathrm{ES}_{p}(|X|) \\geqslant M\n\\end{aligned}\n$$\n\nHence, $\\left\\{\\rho_{h}(|X|): X \\in \\mathcal{S}\\right\\}$ is not bounded.\n(i) $\\Rightarrow$ (ii). Using Theorem 4.1, (i) implies $\\sup _{X \\in \\mathcal{S}}(1-p) \\mathrm{ES}_{p}(|X|) \\downarrow 0$ as $p \\uparrow 1$. We can choose a sequence $\\left(p_{n}\\right)_{n \\in \\mathbb{N}} \\subseteq(0,1)$ such that $1-p_{n}<2^{-n}$ and $\\sup _{X \\in \\mathcal{S}}\\left(1-p_{n}\\right) \\mathrm{ES}_{p_{n}}(|X|)<2^{-n}$ for\n\neach $n$. Define for $t \\in[0,1]$, with $h_{p}$ defined in (4.3),\n\n$$\ng(t)=\\sum_{n=1}^{\\infty}\\left(1-p_{n}\\right) h_{p_{n}}(t)=\\sum_{n=1}^{\\infty} t \\wedge\\left(1-p_{n}\\right)\n$$\n\nIt is straightforward to verify that $g$ is finite as $g(t) \\leqslant g(1)=\\sum_{n=1}^{\\infty}\\left(1-p_{n}\\right) \\leqslant \\sum_{n=1}^{\\infty} 2^{-n}=1$ for $t \\in[0,1]$. It is concave, because it is the sum of concave functions. Moreover, $g(0)=0$ and $g(1)>0$. We further define\n\n$$\nh(t)=\\frac{g(t)}{g(1)}=\\frac{\\sum_{n=1}^{\\infty} t \\wedge\\left(1-p_{n}\\right)}{\\sum_{n=1}^{\\infty} 1 \\wedge\\left(1-p_{n}\\right)}\n$$\n\nwhich is simply the normalized version of $g$ to ensure $h(1)=1$. The properties for $g$ imply that $h$ is a distortion function that is concave. Moreover, we can verify that for any $N \\in \\mathbb{N}$,\n\n$$\n\\lim _{t \\downarrow 0} \\frac{g(t)}{t}=\\lim _{t \\downarrow 0} \\sum_{n=1}^{\\infty} 1 \\wedge \\frac{1-p_{n}}{t} \\geqslant \\lim _{t \\downarrow 0} \\sum_{n=1}^{N} 1 \\wedge \\frac{1-p_{n}}{t}=N\n$$\n\nTherefore, $\\lim _{t \\downarrow 0} g(t) / t=\\infty$. Finally,\n\n$$\n\\begin{aligned}\n\\rho_{h}(|X|) & =\\frac{1}{g(1)} \\int_{0}^{\\infty} g(\\mathbb{P}(|X|>x)) \\mathrm{d} x \\\\\n& =\\frac{1}{g(1)} \\int_{0}^{\\infty} \\sum_{n=1}^{\\infty} \\mathbb{P}(|X|>x) \\wedge\\left(1-p_{n}\\right) \\mathrm{d} x \\\\\n& =\\frac{1}{g(1)} \\sum_{n=1}^{\\infty}\\left(1-p_{n}\\right) \\mathrm{ES}_{p_{n}}(|X|) \\leqslant \\frac{1}{g(1)} \\sum_{n=1}^{\\infty} 2^{-n}=\\frac{1}{g(1)}<\\infty\n\\end{aligned}\n$$\n\nTherefore, (ii) holds.\n(ii) $\\Leftrightarrow$ (iii). This follows from Proposition 3.3.\n\nThe condition $\\mathcal{S} \\subseteq L^{1}$ is imposed only to make sure that $\\rho_{h}$ is properly defined on $\\mathcal{S}$. Indeed, for $\\mathcal{S}$ that is not contained in $L^{1}$, each statement in Theorem 4.2 fails hold, but to make sense of (ii) and (iii), we need to enlarge the domain $L^{1}$ of $\\rho_{h}$ to include the random variables $|X|, X,-X$ for all $X \\in \\mathcal{S}$.\n\nTheorem 4.2 closely resembles the classic de la Vall\u00e9e Poussin criterion on uniform integrability: A set $\\mathcal{S}$ is uniformly integrable if and only if there exists an increasing convex function $\\phi: \\mathbb{R}_{+} \\rightarrow \\mathbb{R}_{+}$with $\\phi(x) / x \\rightarrow \\infty$ as $x \\rightarrow \\infty$ such that $\\sup _{X \\in \\mathcal{S}} \\mathbb{E}[\\phi(|X|)]<\\infty$; see Meyer (1966, Theorem T22). This highlights a duality between $X \\mapsto \\rho_{h}(X)$ for a concave $h$ and $X \\mapsto \\mathbb{E}[\\phi(X)]$ for a convex $\\phi$. Indeed, $\\rho_{h}$ is called the dual utility model of Yaari (1987) in decision theory, and $X \\mapsto \\mathbb{E}[\\phi(X)]$ represents an expected utility model in the same context.\n\nRemark 4.3. For the implication in Theorem 4.2 (ii) $\\Rightarrow$ (i),\n\n$$\n\\rho_{h}(|X|) \\text { is bounded for } X \\in \\mathcal{S} \\subseteq L^{1} \\Longrightarrow \\mathcal{S} \\text { is uniformly integrable, }\n$$\n\nthe risk measure $\\rho_{h}$ satisfies convexity, cash invariance, and positive homoegeneity. It is clear that if we replace $\\rho_{h}$ by $\\rho=f \\circ \\rho_{h}$ where $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ is an increasing function that is unbounded from above, then (4.4) remains true for $\\rho$. Such $\\rho$ does not necessarily satisfy the properties of $\\rho_{h}$. Hence, for the implication (ii) $\\Rightarrow$ (i) in Theorem 4.2, the essential property that we need is how $\\rho_{h}$ integrates the tail probability, and (4.4) can hold for risk measures without convexity, cash invariance, or positive homoegeneity.\n\nThe condition $h \\in \\mathcal{D}_{c}$ in Theorem 4.2 allows for $h$ to have a jump at 0 , which makes $h(t) / t \\rightarrow \\infty$ automatically as $t \\downarrow 0$. Such $h$ is not interesting, because boundedness of $\\rho_{h}(|X|)$ over $X \\in \\mathcal{S}$ for such $h$ forces $\\mathcal{S}$ to be bounded, an obvious case of uniform integrability.\n\nIn part (ii) or (iii) of Theorem 4.2, $\\rho_{h}$ serves as a \"testing\" risk measure for uniform integrability of $\\mathcal{S}$. In the statement of Theorem 4.2, such a choice of $\\rho_{h}$ depends on $\\mathcal{S}$. One may wonder whether there is a single $\\rho_{h}$ that works for all sets $\\mathcal{S}$. To answer this question, we first obtain a result on the finiteness of coherent distortion risk measures, which may be of independent interest. For a risk measure $\\rho$ on $L^{1}$, we say that $\\rho$ is expectation-dominated if there exists $c>0$ such that $\\rho \\leqslant c \\mathbb{E}$ on $L_{+}^{1}$. For instance, $\\mathrm{ES}_{p}$ is expectation-dominated for each $p \\in(0,1)$, since $\\mathrm{ES}_{p}(X) \\leqslant(1-p)^{-1} \\mathbb{E}[X]$ for $X \\in L_{+}^{1}$.\n\nTheorem 4.4. Let $\\rho$ be a coherent distortion risk measure on $L^{1}$. The following are equivalent.\n(i) $\\rho$ is expectation-dominated;\n(ii) $\\rho$ is finite on $L^{1}$;\n(iii) the distortion function $h$ of $\\rho$ satisfies $\\lim _{t \\downarrow 0} h(t) / t<\\infty$.\n\nProof. (i) $\\Rightarrow$ (ii). Since $\\rho \\leqslant c \\mathbb{E}$ on $L_{+}^{1}$ for some $c>0$, we have $\\rho(|X|)<\\infty$ for all $X \\in L^{1}$. Since $\\rho$ is convex, $\\rho(-|X|)+\\rho(|X|) \\geqslant 2 \\rho(0)=0$, which implies $\\rho(-|X|)>-\\infty$. Monotonicity of $\\rho$ yields $-\\infty<\\rho(-|X|) \\leqslant \\rho(X) \\leqslant \\rho(|X|)<\\infty$, showing that $\\rho$ is finite on $L^{1}$.\n(ii) $\\Rightarrow$ (iii). Note that $\\lim _{t \\downarrow 0} h(t) / t$ exists since $h(t) / t$ is decreasing in $t$, due to concavity of $h$. Suppose $h(t) / t=\\infty$, and we will show that $\\rho$ cannot be finite on $L^{1}$. Let $U$ be uniformly distributed on $[0,1]$. For $t \\in(0,1)$, let $B_{t}=\\mathbb{1}_{\\{U<t\\}}$ and\n\n$$\nX_{t}=\\left(\\frac{1}{t h(t)}\\right)^{1 / 2} B_{t}\n$$\n\nNote that $\\mathbb{E}\\left[X_{t}\\right]=(t / h(t))^{1 / 2} \\leqslant 1$. It is straightforward to compute $\\rho\\left(X_{t}\\right)=(h(t) / t)^{1 / 2}$ for $t \\in(0,1)$, and hence\n\n$$\n\\lim _{t \\downarrow 0} \\rho\\left(X_{t}\\right)=\\lim _{t \\downarrow 0}\\left(\\frac{h(t)}{t}\\right)^{1 / 2}=\\infty\n$$\n\nLet $t_{n}>0$ be such that $\\rho\\left(X_{t_{n}}\\right)>2^{n}$. Define a random variable $X$ by\n\n$$\nX=\\sum_{n=1}^{\\infty} 2^{-n} X_{t_{n}}\n$$\n\nNote that $X$ is in $L_{+}^{1}$ since $X \\geqslant 0$ and $\\mathbb{E}[X]=\\sum_{n=1}^{\\infty} 2^{-n} \\mathbb{E}\\left[X_{t_{n}}\\right] \\leqslant 1$. Finally, we note that the random vector $\\left(X_{t_{n}}\\right)_{n \\leqslant k}$ is comonotonic for each $k \\in \\mathbb{N}$ because each $X_{t}$ is a decreasing function of $U$. Since any distortion risk measure is comonotonic-additive, monotone, and positively homogeneous, we have, for each $k$,\n\n$$\n\\rho(X)=\\rho\\left(\\sum_{n=1}^{\\infty} 2^{-n} X_{t_{n}}\\right) \\geqslant \\rho\\left(\\sum_{n=1}^{k} 2^{-n} X_{t_{n}}\\right)=\\sum_{n=1}^{k} 2^{-n} \\rho\\left(X_{t_{n}}\\right)>\\sum_{n=1}^{k} 1=k\n$$\n\nThis shows $\\rho(X)=\\infty$, and hence $\\rho$ is not finite on $L^{1}$.\n(iii) $\\Rightarrow$ (i). Let $c=\\lim _{t \\downarrow 0} h(t) / t<\\infty$. Since $h(t) / t$ is decreasing in $t$, we have $h(t) \\leqslant c t$ for $t \\in[0,1]$. Hence, $\\rho_{h}(X) \\leqslant c \\mathbb{E}[X]$ for $X \\in L_{+}^{1}$.\n\nTheorem 4.4 generalizes a special case of Proposition 1 of Wang et al. (2020), which states that if $h$ is concave and $\\rho_{h}$ is finite on $L^{1}$, then the right derivative $h^{\\prime}$ of $h$ has finite $L^{q}$-norm on $[0,1]$ with respect to the Lebesgue measure for all $q>0$. Theorem 4.4 further gives that $h^{\\prime}$ has finite $L^{\\infty}$-norm, which is a stronger condition.\n\nRemark 4.5. Theorem 4.4 (i) $\\Leftrightarrow$ (iii) can be derived from some results in the context of rearrangementinvariant Banach norms. In particular, we find Theorem 29 and Corollary 30 of Fr\u00f6hlich and Williamson (2024) the most relevant. Translating their results on Banach norms into our setting of distortion risk measures, it is shown that for $h \\in \\mathcal{D}$ with $h(0+)=0$, if $h^{\\prime}(0)<\\infty$ then the induced norm by $\\rho_{h}$ via $X \\mapsto \\rho_{h}(|X|)$ is equivalent to the $L^{1}$ norm; if $h^{\\prime}(0)=\\infty$ then the induced norm by $\\rho_{h}$ is not equivalent to the $L^{1}$ norm. Our proof uses an explicit construction to show the implication (ii) $\\Rightarrow$ (iii), not covered by Fr\u00f6hlich and Williamson (2024), and includes the case $h(0+)>0$. A similar observation can be made for Proposition 4.9 below, which characterizes the finiteness of law-invariant coherent risk measures on $L^{1}$.\n\nUsing Theorem 4.4, we can show that there does not exist a single $\\rho_{h}$ that works for all sets $\\mathcal{S}$ in Theorem 4.2.\n\nProposition 4.6. There is no coherent distortion risk measure $\\rho$ such that for all sets $\\mathcal{S} \\subseteq L^{1}$,\n\n$$\n\\sup _{X \\in \\mathcal{S}} \\rho(|X|)<\\infty \\quad \\Longleftrightarrow \\quad \\mathcal{S} \\text { is uniformly integrable. }\n$$\n\nProof. First, by Theorem 4.4, if $\\rho$ is finite on $L^{1}$, then it is expectation-dominated. Together with property (f) from Section 2, we have $\\mathbb{E} \\leqslant \\rho \\leqslant c \\mathbb{E}$ on $L_{+}^{1}$ for some $c \\geqslant 1$. In this case, $\\sup _{X \\in \\mathcal{S}} \\rho(|X|)<\\infty$ is equivalent to $\\sup _{X \\in \\mathcal{S}} \\mathbb{E}[|X|]<\\infty$, which is not sufficient for uniform integrability of $\\mathcal{S}$. Next, by Theorem 4.4 again, if $\\rho$ is not finite on $L^{1}$, then there exists $X \\in L^{1}$ such that $\\rho(|X|)=\\infty$, but $\\{X\\}$ is uniformly integrable. Hence, uniform integrability of $\\mathcal{S}$ does not guarantee $\\sup _{X \\in \\mathcal{S}} \\rho_{h}(X)<\\infty$.\n\nExample 4.7 (Integrated ES). Define the integrated ES (IES) for a random variable $X$ as\n\n$$\n\\operatorname{IES}(X)=\\int_{0}^{1} \\operatorname{ES}_{p}(X) \\mathrm{d} p=\\int_{0}^{1} \\int_{0}^{q} \\frac{1}{1-p} \\operatorname{VaR}_{q}(X) \\mathrm{d} p \\mathrm{~d} q=\\int_{0}^{1}-\\log (1-q) \\operatorname{VaR}_{q}(X) \\mathrm{d} q\n$$\n\nThe distortion function $h$ of IES is in $\\mathcal{D}_{c}$ because $\\lim _{t \\downarrow 0} h(t) / t=-\\lim _{t \\downarrow 0} \\log (t)=\\infty$. By Theorem 4.2, any set $\\mathcal{S}$ of random variables on which IES is bounded is uniformly integrable. Proposition 1 of Wang et al. (2020) implies that IES is finite on $L^{1+\\varepsilon}$ for any $\\varepsilon>0$, and by Theorem 4.4, IES is not finite on $L^{1}$. One specific example of $X \\in L^{1}$ with $\\operatorname{IES}(X)=\\infty$ is given below. Let $U$ be uniformly distributed on $[0,1 / 2]$ and let $X=U^{-1}(\\log U)^{-2}$. We can compute\n\n$$\n\\mathbb{E}[X]=2 \\int_{0}^{1 / 2}(-\\log u)^{-2} u^{-1} \\mathrm{~d} u=2 \\int_{\\log 2}^{\\infty} t^{-2} \\mathrm{~d} t=2(\\log 2)^{-1}<\\infty\n$$\n\nBy (4.5) and $\\operatorname{VaR}_{1-q}(X)=2 q^{-1}(\\log q-\\log 2)^{-2}$,\n\n$$\n\\operatorname{IES}(X)=\\int_{0}^{1}-\\log u \\frac{2}{u(\\log u-\\log 2)^{2}} \\mathrm{~d} u=\\int_{0}^{\\infty} \\frac{2 x}{(x+\\log 2)^{2}} \\mathrm{~d} x=\\infty\n$$\n\nWe can see that the set $\\{X\\}$ is uniformly integrable and $\\operatorname{IES}(X)=\\infty$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 6,
      "text": "# 4.3 Uniform integrability and coherent risk measures \n\nNext, we turn to the more general class of law-invariant coherent risk measures. Let $\\mathcal{R}$ be the set of all lower semicontinuous and law-invariant coherent risk measures on $L^{1}$ that are not finite on $L^{1}$. For instance, IES in Example 4.7 is in $\\mathcal{R}$.\n\nTheorem 4.8. For any $\\mathcal{S} \\subseteq L^{1}$, the following are equivalent.\n(i) $\\mathcal{S}$ is uniformly integrable;\n\n(ii) there exists $\\rho \\in \\mathcal{R}$ such that $\\rho(|X|)$ is bounded for $X \\in \\mathcal{S}$;\n(iii) there exists $\\rho \\in \\mathcal{R}$ such that $\\rho(X)$ and $\\rho(-X)$ are bounded for $X \\in \\mathcal{S}$;\n(iv) there exist $\\rho, \\rho^{\\prime} \\in \\mathcal{R}$ such that $\\rho(X)$ and $\\rho^{\\prime}(-X)$ are bounded from above for $X \\in \\mathcal{S}$.\n\nProof. Any coherent distortion risk measure $\\rho_{h}$ is lower semicontinuous. By Theorem 4.4, $\\rho_{h} \\in \\mathcal{R}$ if and only if $h \\in \\mathcal{D}_{c}$. Therefore, by using Theorem 4.2 and taking $\\rho=\\rho_{h}$, we get (i) $\\Rightarrow$ (ii) $\\Rightarrow$ (iii). The direction (iii) $\\Rightarrow$ (iv) is trivial. It remains to prove (iv) $\\Rightarrow$ (i).\n\nWe first show that for any coherent distortion risk measure $\\rho_{h}$ and $c>0$, we have\n\n$$\n\\rho_{h} \\leqslant c \\mathbb{E} \\text { holds on } L_{+}^{1} \\Longleftrightarrow \\lim _{t \\downarrow 0} h(t) / t \\leqslant c\n$$\n\nA weaker version of this equivalence was used in the proof of Theorem 4.4. Suppose $\\lim _{t \\downarrow 0} h(t) / t \\leqslant$ $c$. Since $h(t) / t$ is decreasing in $t$, we know $h(t) \\leqslant c t$ for $t \\in[0,1]$. Hence, $\\rho_{h}(X) \\leqslant c \\mathbb{E}[X]$ for $X \\in L_{+}^{1}$. Conversely, if $\\rho_{h} \\leqslant c \\mathbb{E}$ on $L_{+}^{1}$, then $\\rho_{h}\\left(B_{t}\\right) / t \\leqslant c$, where $B_{t}$ is a Bernoulli random variable with $\\mathbb{E}\\left[B_{t}\\right]=t$. This implies $h(t) / t$ is bounded above by $c$. Since $h(t) / t$ is decreasing in $t$, it has a finite limit bounded by $c$ as $t \\downarrow 0$.\n\nNote that a lower semicontinuous and law-invariant coherent risk measure $\\rho$ on $L^{1}$ admits a Kusuoka representation (Kusuoka (2001); see Filipovi\u0107 and Svindland (2012) for its extension to $L^{1}$ ), that is,\n\n$$\n\\rho=\\sup _{h \\in \\mathcal{H}_{\\rho}} \\rho_{h} \\text { for a set } \\mathcal{H}_{\\rho} \\text { of concave distortion functions. }\n$$\n\nSince $\\rho$ is not finite on $L^{1}$, it cannot be expectation-dominated; this follows by the same argument of (i) $\\Rightarrow$ (ii) in the proof of Theorem 4.4. That is, for every $c>0, \\rho \\leqslant c \\mathbb{E}$ on $L_{+}^{1}$ does not hold. Hence, for each $n$, there exists $h_{n} \\in \\mathcal{H}_{\\rho}$ such that $\\rho_{h_{n}} \\leqslant 2^{n} \\mathbb{E}$ on $L_{+}^{1}$ does not hold, and by using (4.6), this implies $\\lim _{t \\downarrow 0} h_{n}(t) / t>2^{n}$. Write $g=\\sum_{n=1}^{\\infty} 2^{-n} h_{n}$. Since $g$ is a convex combination of concave distortion functions, it is also a concave distortion function. Moreover, we can compute (via Fubini's theorem)\n\n$$\n\\lim _{t \\downarrow 0} \\frac{g(t)}{t}=\\sum_{n=1}^{\\infty} 2^{-n} \\lim _{t \\downarrow 0} \\frac{h_{n}(t)}{t} \\geqslant \\sum_{n=1}^{\\infty} 1=\\infty\n$$\n\nTherefore, $g \\in \\mathcal{D}_{c}$. Moreover, $\\rho \\geqslant \\rho_{g}$ since $\\rho \\geqslant \\rho_{h_{n}}$ for each $n \\in \\mathbb{N}$. Similarly, there exists $f \\in \\mathcal{D}_{c}$ such that $\\rho^{\\prime} \\geqslant \\rho_{f}$.\n\nTake $\\ell=g \\wedge f$. We can see that $\\ell$ is a concave distortion function, and $\\ell(t) / t=(g(t) \\wedge$ $f(t)) / t \\rightarrow \\infty$ as $t \\downarrow 0$. Therefore, $\\ell \\in \\mathcal{D}_{c}$. Moreover, $\\rho_{\\ell} \\leqslant \\rho_{g} \\wedge \\rho_{f}$ by definition of $\\ell$. Hence, the boundedness from above of $\\rho(X)$ and $\\rho^{\\prime}(-X)$ for $X \\in \\mathcal{S}$ implies that $\\rho_{\\ell}(X)$ and $\\rho_{\\ell}(-X)$ are\n\nboth bounded above; they are also bounded below because $\\rho_{\\ell}(X)+\\rho_{\\ell}(-X) \\geqslant 0$ for all $X \\in L^{1}$. By using Theorem 4.2, we know that $\\mathcal{S}$ is uniformly integrable.\n\nThe implication $(\\mathrm{iv}) \\Rightarrow(\\mathrm{i})$ will be useful in the application in Section 6 , where one of the risk measures represents a price functional.\n\nLet $\\rho$ be a lower semicontinuous and law-invariant coherent risk measure on $L^{1}$. In the direction (iii) $\\Rightarrow$ (i) of Theorem 4.8, it is required that $\\rho$ is not finite on $L^{1}$. It may be natural to ask whether this requirement is also necessary. Clearly, if $\\rho$ is expectation-dominated, then $\\sup _{X \\in \\mathcal{S}} \\rho(|X|)<\\infty$ for any $\\mathcal{S} \\subseteq L_{+}^{1}$ with bounded expectation, which is not sufficient for uniform integrability. Therefore, for the implication (iii) $\\Rightarrow$ (i), $\\rho$ is necessarily not expectation-dominated. It turns out that this is equivalent to requiring $\\rho$ to be not finite on $L^{1}$. The next result on the finiteness of such risk measures extends Theorem 4.4 to the larger class of law-invariant coherent risk measures. For other results on spaces that are finite for law-invariant risk measures, see Liebrich and Svindland (2017).\n\nProposition 4.9. A law-invariant coherent risk measures on $L^{1}$ is finite if and only if it is expectation-dominated.\n\nProof. The \"if\" statement follows from the same argument of (i) $\\Rightarrow$ (ii) in the proof of Theorem 4.4. Below we show the \"only if\" statement. Note that any law-invariant coherent risk measure that is finite on $L^{1}$ admits a Kusuoka representation in the form of (4.7). From the arguments in the proof of Theorem 4.8, we see that $\\rho \\geqslant \\rho_{g}$ for some $g \\in \\mathcal{D}_{c}$. By Theorem 4.4, this implies that $\\rho_{g}$ is not finite on $L^{1}$. Hence, we conclude that $\\rho$ is also not finite on $L^{1}$.\n\nLet $\\rho$ be a lower semicontinuous and law-invariant coherent risk measure. Proposition 4.9 implies that the set $\\mathcal{R}$ contains precisely such $\\rho$ that are not expectation-dominated. Moreover, the non-finiteness of $\\rho$ on $L^{1}$ is necessary and sufficient for the implication (iii) $\\Rightarrow$ (i).",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 7,
      "text": "# 5 Some consequences of the main results \n\nIn this section we present two applications, both following directly from the condition of uniform integrability. The first corollary concerns a weak law of large numbers.\n\nCorollary 5.1. Let $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ be a sequence of pairwise independent random variables with zero mean and $Y_{n}=\\left(X_{1}+\\cdots+X_{n}\\right) / n$ for each $n \\in \\mathbb{N}$. If $\\sup _{n \\in \\mathbb{N}}\\left(\\rho\\left(X_{n}\\right) \\vee \\rho^{\\prime}\\left(-X_{n}\\right)\\right)<\\infty$ for some $\\rho, \\rho^{\\prime} \\in \\mathcal{R}$, then $Y_{n} \\rightarrow 0$ in probability as $n \\rightarrow \\infty$.\n\nProof. For a sequence of pairwise independent random variables with zero mean, uniform integrability ensures the weak law of large numbers; see Landers and Rogge (1987). The statement then follows from Theorem 4.8.\n\nRemark 5.2. It is known that, for a sequence of independent random variables with zero mean, uniform integrablity is not sufficient for the strong law of large numbers; see the example in Landers and Rogge (1987). Since our condition in Corollary 5.1 is equivalent to uniform integrability, we cannot change the statement of convergence in probability to that of almost sure convergence. A remaining question is to find a stronger condition on $\\rho$ than $\\rho \\in \\mathcal{R}$ such that\n\n$$\n\\sup _{n \\in \\mathbb{N}}\\left(\\rho\\left(X_{n}\\right) \\vee \\rho\\left(-X_{n}\\right)\\right)<\\infty \\quad \\Longrightarrow \\quad \\frac{1}{n} \\sum_{i=1}^{n} X_{i} \\rightarrow 0 \\text { a.s. }\n$$\n\nfor an independent (or pairwise independent) sequence $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ with zero mean.\nThe second corollary concerns the convergence of ES under convergence in distribution.\nCorollary 5.3. Suppose that a sequence $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ converges to $X \\in L^{1}$ in distribution and satisfies $\\sup _{n \\in \\mathbb{N}}\\left(\\rho\\left(X_{n}\\right) \\vee \\rho^{\\prime}\\left(-X_{n}\\right)\\right)<\\infty$ for some $\\rho, \\rho^{\\prime} \\in \\mathcal{R}$. Then $\\operatorname{ES}_{p}\\left(X_{n}\\right) \\rightarrow \\operatorname{ES}_{p}(X)$ for all $p \\in(0,1)$.\n\nProof. Let $U$ be a uniform random variable on $[0,1]$. For $n \\in \\mathbb{N}$, denote by $Q_{n}(t)=\\operatorname{VaR}_{t}\\left(X_{n}\\right)$ and $Q(t)=\\operatorname{VaR}_{t}(X)$ for $t \\in(0,1)$. Note that $Q_{n}(U) \\stackrel{\\mathrm{d}}{=} X_{n}$ and $Q(U) \\stackrel{\\mathrm{d}}{=} X$. Using Theorem 4.8, we know that $\\left\\{X_{n}: n \\in \\mathbb{N}\\right\\}$ is uniformly integrable, so $\\left\\{Q_{n}(U): n \\in \\mathbb{N}\\right\\}$ is also uniformly integrable. The convergence $X_{n} \\rightarrow X$ in distribution as $n \\rightarrow \\infty$ implies that $Q_{n}(U) \\rightarrow Q(U)$ in probability. This and uniform integrability of $\\left\\{Q_{n}(U): n \\in \\mathbb{N}\\right\\}$ guarantee that $Q_{n}(U) \\rightarrow Q(U)$ in $L^{1}$. Hence, $\\int_{0}^{1}\\left|Q_{n}(u)-Q(u)\\right| \\mathrm{d} u \\rightarrow 0$, which implies $\\int_{p}^{1}\\left|Q_{n}(u)-Q(u)\\right| \\mathrm{d} u \\rightarrow 0$. Therefore, by law invariance of ES, we have $\\operatorname{ES}_{p}\\left(X_{n}\\right)=\\operatorname{ES}_{p}\\left(Q_{n}(U)\\right) \\rightarrow \\operatorname{ES}_{p}(Q(U))=\\operatorname{ES}_{p}(X)$.\n\nNext, we present a result that will be useful in the application in Section 6. Define the 1-Wasserstein distance between two distributions $F$ on a space $\\mathfrak{X}$ and $G$ on a space $\\mathfrak{Y}$ by\n\n$$\nW^{1}(F, G)=\\inf _{\\pi \\in \\Pi(F, G)} \\int_{\\mathfrak{X} \\times \\mathfrak{Y}}|x-y| \\pi(\\mathrm{d} x, \\mathrm{~d} y)\n$$\n\nwhere $\\Pi(F, G)$ is the set of distributuons on $\\mathfrak{X} \\times \\mathfrak{Y}$ with marginal distributions $F$ and $G$. The 1-Wasserstein distance belongs to the class of $p$-Wasserstein distances commonly used in optimal transport theory (e.g., R\u00fcschendorf (2013, Chapter 2)). When $F$ and $G$ are distributions on $\\mathbb{R}$, we identify them with the corresponding cumulative distribution functions. In this case, $W^{1}(F, G)$ has an explicit formula\n\n$$\nW^{1}(F, G)=\\int_{0}^{1}\\left|F^{-1}(t)-G^{-1}(t)\\right| \\mathrm{d} t\n$$\n\nwhere $F^{-1}$ is the quantile function of $F$, that is, $F^{-1}(t)=\\inf \\{x \\in \\mathbb{R}: F(x) \\geqslant t\\}$ for $t \\in(0,1)$.\n\nWe will denote by $w^{1}$ the corresponding pseudometric on $L^{1} \\times L^{1}$, that is,\n\n$$\nw^{1}(X, Y)=\\int_{0}^{1}\\left|\\operatorname{VaR}_{t}(X)-\\operatorname{VaR}_{t}(Y)\\right| \\mathrm{d} t=W^{1}(F, G)\n$$\n\nwhere $F$ and $G$ are the distributions of $X$ and $Y$, respectively. Note that $w^{1}(X, Y) \\leqslant \\mathbb{E}[|X-Y|]$ for any $X, Y$, and equality holds if $X$ and $Y$ are comonotonic. Using this fact and Durrett (2019, Theorem 4.6.3), one can check that, as $n \\rightarrow \\infty$,\n\n$$\n\\begin{aligned}\nw^{1}\\left(X_{n}, X\\right) \\rightarrow 0 & \\Longleftrightarrow X_{n}^{*} \\rightarrow X \\text { in } L^{1} \\\\\n& \\Longleftrightarrow X_{n} \\rightarrow X \\text { in distribution and }\\left(X_{n}\\right)_{n \\in \\mathbb{N}} \\text { is uniformly integrable, }\n\\end{aligned}\n$$\n\nwhere $X_{n}^{*}$ is identically distributed as $X_{n}$ and $X, X_{n}^{*}$ are comonotonic for each $n \\in \\mathbb{N}$; such $X_{n}^{*}$ can be constructed on the same probability space as $X$ as long as the space is atomless. Note that in (5.1), $\\mathbb{E}\\left[\\left|X_{n}^{*}-X\\right|\\right]=w^{1}\\left(X_{n}^{*}, X\\right) \\leqslant \\mathbb{E}\\left[\\left|X_{n}-X\\right|\\right]$ and thus the distribution of $\\left(X_{n}^{*}, X\\right)$ is a minimizer in the definition of the 1-Wasserstein distance.\n\nCorollary 5.4. Suppose that a sequence $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ satisfies $\\sup _{n \\in \\mathbb{N}}\\left(\\rho\\left(X_{n}\\right) \\vee \\rho^{\\prime}\\left(-X_{n}\\right)\\right)<\\infty$ for some $\\rho, \\rho^{\\prime} \\in \\mathcal{R}$. Then there exists a subsequence $\\left(X_{n_{k}}\\right)_{k \\in \\mathbb{N}}$ that converges in $w^{1}$.\n\nProof. First, Theorem 4.8 guarantees that that $\\left\\{X_{n}: n \\in \\mathbb{N}\\right\\}$ is uniformly integrable. Note that uniform integrability implies $x \\sup _{n \\in \\mathbb{N}} \\mathbb{P}\\left(\\left|X_{n}\\right|>x\\right) \\rightarrow 0$ as $x \\rightarrow \\infty$, which in term implies $\\sup _{n \\in \\mathbb{N}} \\mathbb{P}\\left(\\left|X_{n}\\right|>x\\right) \\rightarrow 0$ as $x \\rightarrow \\infty$. Therefore, the sequence $\\left\\{F_{n}: n \\in \\mathbb{N}\\right\\}$ of distributions of $\\left\\{X_{n}: n \\in \\mathbb{N}\\right\\}$ is tight. Hence, $\\left\\{F_{n}: n \\in \\mathbb{N}\\right\\}$ has a convergent subsequence to some distribution $F$; see e.g., Theorem 3.10.3 of Durrett (2019). Let $U$ be a uniformly distributed random variable on $[0,1]$ and $X=F^{-1}(U)$. Clearly, $F_{n}^{-1}(U) \\rightarrow F^{-1}(U)$ almost surely (this is implied also by the Skorokhod representation theorem; see Theorem 6.7 of Bilingsley (1999)), and the set $\\left\\{F_{n}^{-1}(U): n \\in \\mathbb{N}\\right\\}$ is uniformly integerable since $\\left\\{X_{n}: n \\in \\mathbb{N}\\right\\}$ is uniformly integrable. Therefore, $F_{n}^{-1}(U) \\rightarrow X$ in $L^{1}$ by Theorem 4.6.3 of Durrett (2019). This means $X_{n} \\rightarrow X$ in $w^{1}$ because $w^{1}\\left(X_{n}, X\\right)=W^{1}\\left(F_{n}, F\\right)=\\mathbb{E}\\left[\\left|F_{n}^{-1}(U)-X\\right|\\right]$.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 8,
      "text": "# 6 An application in investment optimization \n\nWe consider an investment problem where a decision maker tries to maximize an expected utility function $u$ of two variables subject to a risk constraint. We assume that the risk of random losses is assessed by a lower semicontinuous and law-invariant coherent risk measure $\\rho$ on $L^{1}$ that is not finite on $L^{1}$, i.e., $\\rho \\in \\mathcal{R}$. As an example, $\\rho$ may be a distortion risk measure $\\rho_{h}$ with a concave distortion function satisfying $\\lim _{t \\downarrow 0} h(t) / t \\rightarrow \\infty$, such as IES in Example 4.7. Moreover, we use another functional $P \\in \\mathcal{R}$ to represent the ask price of a financial asset; that is, $P(-X)$\n\nis the price to purchase a random loss $X$ with payoff $-X$. Using a coherent risk measure for the ask price of financial assets is a common setup in conic finance; see Madan and Cherny (2010) for an introduction. Coherent distortion risk measures in $\\mathcal{R}$, such as\n\n$$\nP(X)=\\rho_{h}(X)=\\alpha \\int_{0}^{1}(1-t)^{\\alpha-1} \\operatorname{VaR}_{t}(X) \\mathrm{d} t, \\text { with } h(t)=t^{\\alpha}\n$$\n\nare used as ask prices in Madan and Cherny (2010). To connect to our main results, we assume that both the price functional and the risk measure are law invariant, and thus we do not consider the pricing kernel. Note that $P \\geqslant \\mathbb{E}$ for $P \\in \\mathcal{R}$, and thus the ask price is more expensive than the mean payoff, a sensible assumption.\n\nLet $\\mathcal{G}$ and $\\mathcal{G}^{\\perp}$ be two independent sub- $\\sigma$-fields of $\\mathcal{F}$ such that $(\\Omega, \\mathcal{G}, \\mathbb{P})$ and $\\left(\\Omega, \\mathcal{G}^{\\perp}, \\mathbb{P}\\right)$ are atomless. A stylized investment optimization problem can be formulated as\n\n$$\n\\begin{array}{ll}\n\\operatorname{maximize} & \\mathbb{E}[u(-X, Y)] \\\\\n\\text { subject to } & X \\in L^{1}(\\mathcal{G}) ; \\rho(X) \\leqslant r_{0} ; P(-X) \\leqslant x_{0}\n\\end{array}\n$$\n\nwhere $Y \\in L^{1}\\left(\\mathcal{G}^{\\perp}\\right), f: \\mathbb{R}^{2} \\rightarrow \\mathbb{R}$ is measurable, and $r_{0}, x_{0} \\in \\mathbb{R}$. In the model (6.2),\n(a) $u$ represents a bivariate utility function that the decision maker aims to maximize;\n(b) $Y$ represents some independent background risk outside the control of the decision maker (e.g., risks outside the financial market, such as labour income risk, or insurance risk);\n(c) the decision variable $X$ is the risky position (random loss) that the decision maker takes in the financial market;\n(d) $r_{0}$ is the risk budget for the loss $X$ evaluated by the risk measure $\\rho$;\n(e) $x_{0}$ is the budget of the decision maker priced by $P$;\n(f) $\\mathcal{G}$ is the $\\sigma$-field of a complete financial market, so that every payoff $X \\in L^{1}(\\mathcal{G})$ is attainable.\n\nSee Basak and Shapiro (2001) for a similar utility optimization problem in a complete market with VaR and budget constraints. Independent background risk is common in decision problems; see Mu et al. (2024) for recent advances. In case $Y$ is continuously distributed, one may conveniently set $\\mathcal{G}^{\\perp}=\\sigma(Y)$.\n\nWe assume that $u$ is Lipschiz continuous; that is, there exists $c>0$ such that $\\mid u(x, y)-$ $u\\left(x^{\\prime}, y^{\\prime}\\right) \\mid \\leqslant c\\left(\\left|x-x^{\\prime}\\right|+\\left|y-y^{\\prime}\\right|\\right)$. For a concrete example, we can consider\n\n$$\nu(x, y)=v(a x+b y)\n$$\n\nfor a univariate utility function $v: \\mathbb{R} \\rightarrow \\mathbb{R}$ with bounded derivative and $a$ and $b$ are two constants. We do not assume other properties of $u$ than Lipschitz continuity, and the infinite-dimensional optimization problem (6.2) may be non-convex, non-monotone, and difficult to solve.\n\nIn practice, the stochastic background risk $Y$ may be subject to uncertainty. Instead, the decision maker can observe some approximations $Y_{n}$ of $Y$ through available data and statistical modeling. For example, if a simulation mechanism for $Y$ is available, then $Y_{n}$ may represent the simulated data up to step $n$. Another example is that $Y_{n}$ is an algorithmic approximation of $Y$ up to certain accuracy. We assume that $Y_{n}$ converges to $Y$ in $w^{1}$, because the Wasserstein distance is a common metric to quantify uncertainty in the distribution of a stochastic object; see e.g., Blanchet et al. (2022). Note that by (5.1), $Y_{n} \\rightarrow Y$ in $L^{1}$ is stronger than this assumption, which is equivalent to $Y_{n} \\rightarrow Y$ in distribution plus uniform integrability.\n\nSuppose that, with only access to $Y_{n} \\in L^{1}\\left(\\mathcal{G}^{\\perp}\\right)$, the decision can approximately solve the problem\n\n$$\n\\begin{array}{ll}\n\\text { maximize } & \\mathbb{E}\\left[u\\left(-X, Y_{n}\\right)\\right] \\\\\n\\text { subject to } & X \\in L^{1}(\\mathcal{G}) ; \\rho(X) \\leqslant r_{0} ; P(-X) \\leqslant x_{0}\n\\end{array}\n$$\n\nFor $\\varepsilon \\geqslant 0$, we say that $X^{*}$ is an $\\varepsilon$-optimizer of (6.3) if $\\mathbb{E}\\left[u\\left(-X^{*}, Y_{n}\\right)\\right] \\geqslant \\sup _{X \\in \\mathcal{A}} \\mathbb{E}\\left[u\\left(-X, Y_{n}\\right)\\right]-$ $\\varepsilon$, where $\\mathcal{A}=\\left\\{X \\in L^{1}(\\mathcal{G}): \\rho(X) \\leqslant r_{0} ; P(-X) \\leqslant x_{0}\\right\\}$ is the set of all feasible decision variables. Analogously, we define $\\varepsilon$-optimizer of (6.2). Our definition of $\\varepsilon$-optimizers allows for an additive error of $\\varepsilon$ on the optimal value. In practice, it can be much less costly to compute an approximate optimizer than an exact optimizer; see Vazirani (2001) and Ausiello et al. (2012) for general treatments of approximate optimizers and algorithms. Clearly, $\\varepsilon=0$ corresponds to true optimizers. Note that for any $\\varepsilon>0$, an $\\varepsilon$-optimizer of (6.3) exists.\n\nThe next result shows that any sequence of $\\varepsilon$-optimizers converges to an $\\varepsilon$-optimizer of the original problem (6.2), justifying the relevance of using the approximation (6.3).\n\nProposition 6.1. Suppose that $Y_{n} \\rightarrow Y$ in $w^{1}, X_{n}$ is an $\\varepsilon_{n}$-optimizer of (6.3) with $\\varepsilon_{n} \\geqslant 0$ for $n \\in \\mathbb{N}, u$ is Lipschitz continuous, and $\\rho, P \\in \\mathcal{R}$. Then any subsequence of $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ has a cluster point in $w^{1}$ that is an $\\varepsilon$-optimizer of (6.2), where $\\varepsilon=\\lim \\sup _{n \\rightarrow \\infty} \\varepsilon_{n}$. In particular, if $\\varepsilon_{n} \\rightarrow 0$, then any convergent (in $w^{1}$ ) subsequence converges to an optimizer of (6.2).\n\nProof. The constraints in (6.3) guarantee that $\\rho\\left(X_{n}\\right)$ and $P\\left(-X_{n}\\right)$ are bounded above. By Corollary 5.4, any subsequence of $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ has a convergent subsequence. Therefore, it suffices to consider the case $X_{n} \\rightarrow X^{*}$ in $w^{1}$. Moreover, we can choose $X^{*} \\in L^{1}(\\mathcal{G})$ because $w^{1}$ only concerns the distribution of $X^{*}$, and $(\\Omega, \\mathcal{G}, \\mathbb{P})$ is atomless.\n\nBy (5.1), we can construct $X_{n}^{\\prime} \\in L^{1}(\\mathcal{G})$ and $Y_{n}^{\\prime} \\in L^{1}\\left(\\mathcal{G}^{\\perp}\\right)$ for each $n$, such that\n\n$$\nX_{n} \\stackrel{\\mathrm{~d}}{=} X_{n}^{\\prime} ; Y_{n} \\stackrel{\\mathrm{~d}}{=} Y_{n}^{\\prime} ; X_{n}^{\\prime} \\rightarrow X^{*} \\text { and } Y_{n}^{\\prime} \\rightarrow Y \\text { in } L^{1}\n$$\n\nThe proof of Corollary 5.4 justifies $X_{n}^{\\prime} \\rightarrow X^{*}$ almost surely, and also in $L^{1}$ due to uniform integrability. By lower semicontinuity and law invariance of $\\rho$ and $P$,\n\n$$\n\\rho\\left(X^{*}\\right) \\leqslant \\liminf _{n \\rightarrow \\infty} \\rho\\left(X_{n}^{\\prime}\\right)=\\liminf _{n \\rightarrow \\infty} \\rho\\left(X_{n}\\right) \\leqslant r_{0}\n$$\n\nand similarly $P\\left(-X^{*}\\right) \\leqslant x_{0}$. Hence, $X^{*} \\in \\mathcal{A}$.\nTo see that $X^{*}$ is $\\varepsilon$-optimal, let\n\n$$\n\\delta_{n}=w^{1}\\left(X_{n}, X^{*}\\right) \\vee w^{1}\\left(Y_{n}, Y\\right)=\\mathbb{E}\\left[\\left|X_{n}^{\\prime}-X^{*}\\right|\\right] \\vee \\mathbb{E}\\left[\\left|Y_{n}^{\\prime}-Y\\right|\\right]\n$$\n\nwhich converges to 0 as $n \\rightarrow \\infty$. Using Lipschitz continuity of $f$ repeatedly and the fact that $\\mathbb{E}[f(Z, W)]$ for $Z \\in L^{1}(\\mathcal{G})$ and $W \\in L^{1}\\left(\\mathcal{G}^{\\perp}\\right)$ depends only on the laws of $Z$ and $W$, we have\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[f\\left(X^{*}, Y\\right)\\right] & \\geqslant \\mathbb{E}\\left[f\\left(X^{*}, Y_{n}^{\\prime}\\right)\\right]-\\mathbb{E}\\left[c\\left|Y-Y_{n}^{\\prime}\\right|\\right] \\\\\n& \\geqslant \\mathbb{E}\\left[f\\left(X^{*}, Y_{n}^{\\prime}\\right)\\right]-c \\delta_{n} \\\\\n& \\geqslant \\mathbb{E}\\left[f\\left(X_{n}^{\\prime}, Y_{n}^{\\prime}\\right)\\right]-\\mathbb{E}\\left[c\\left|X^{*}-X_{n}^{\\prime}\\right|\\right]-c \\delta_{n} \\\\\n& \\geqslant \\mathbb{E}\\left[f\\left(X_{n}^{\\prime}, Y_{n}^{\\prime}\\right)\\right]-2 c \\delta_{n} \\\\\n& =\\mathbb{E}\\left[f\\left(X_{n}, Y_{n}\\right)\\right]-2 c \\delta_{n} \\\\\n& \\geqslant \\sup _{X \\in \\mathcal{A}} \\mathbb{E}\\left[f\\left(X, Y_{n}\\right)\\right]-\\varepsilon_{n}-2 c \\delta_{n} \\\\\n& =\\sup _{X \\in \\mathcal{A}} \\mathbb{E}\\left[f\\left(X, Y_{n}^{\\prime}\\right)\\right]-\\varepsilon_{n}-2 c \\delta_{n} \\\\\n& \\geqslant \\sup _{X \\in \\mathcal{A}} \\mathbb{E}[f(X, Y)]-\\mathbb{E}\\left[c\\left|Y_{n}^{\\prime}-Y\\right|\\right]-\\varepsilon_{n}-2 c \\delta_{n} \\geqslant \\sup _{X \\in \\mathcal{A}} \\mathbb{E}[f(X, Y)]-\\varepsilon_{n}-3 c \\delta_{n}\n\\end{aligned}\n$$\n\nSince $\\delta_{n} \\rightarrow 0$, by taking a limit as $n \\rightarrow \\infty$, we conclude that $\\mathbb{E}\\left[f\\left(X^{*}, Y\\right)\\right] \\geqslant \\sup _{X \\in \\mathcal{A}} \\mathbb{E}[f(X, Y)]-$ $\\varepsilon$, and thus the desired $\\varepsilon$-optimality holds.\n\nUnder the stated conditions in Proposition 6.1, a true optimizer of (6.2) always exists, and this can be seen by setting $Y_{n}=Y$ for $n \\in \\mathbb{N}$, and using the fact that $(1 / n)$-optimizers exist. Proposition 6.1 also implies that all cluster points of $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ are $\\varepsilon$-optimizers of (6.3).\n\nTo interpret Proposition 6.1, the decision maker may use a low-cost algorithm to compute an $\\varepsilon_{n}$-optimizer of (6.3) for some $n$ according to available computational resources and information of $Y_{n}$. Proposition 6.1 guarantees that, by increasing $n$, any convergent subsequence provided by this procedure converges to an $\\varepsilon$-optimizer of (6.2), which the decision maker does not have access to.\n\nIn the proof of Proposition 6.1, our main results in Theorem 4.8 are used, through the conditions $\\rho(X) \\leqslant r_{0}$ and $P(-X) \\leqslant x_{0}$, to establish uniform integrability of $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$. This\n\nfurther allows the construction of $\\left(X_{n}^{\\prime}\\right)_{n \\in \\mathbb{N}}$ which has $L^{1}$ convergence, guaranteeing $X^{*} \\in \\mathcal{A}$ as well as its optimality. Without Theorem 4.8 or the conditions $\\rho(X) \\leqslant r_{0}$ and $P(-X) \\leqslant x_{0}$, the above arguments fail as $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ may not have any convergent subsequence.\n\nRemark 6.2. As we can see from the proof of Proposition 6.1, the advantages brought by uniform integrability in optimization rely on the condition that the value function exhibits $L^{1}$-type continuity properties. In particular, the Lipschitz continuity of $u$ excludes functions of the form $u(x, y)=v(a x+b y)$ where $v$ grows super-linearly. Admittedly, these assumptions appear to be quite restrictive, and they capture the additional guarantee that uniform integrability offers.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 9,
      "text": "# 7 Conclusion \n\nThe main contribution of this paper is to establish a connection between boundedness of risk measure values and uniform integrability. As a convenient technical tool, we obtained an upper bound on the folding score of each distortion risk measure (Theorem 3.1). Three different sets of equivalent conditions for uniform integrability are obtained, via ES (Theorem 4.1), via distortion risk measures (Theorem 4.2) and via law-invariant coherent risk measures (Theorem 4.8). Conditions in these results are stated both for the absolute value of the random variables involved and for the random variables themselves, facilitating easy interpretation in risk management. An application of investment optimization illustrates how our main results and the formulation with random losses instead of their absolute values are helpful to establish convergence of optimal decisions. These results form a bridge between two important concepts, one in probability theory and one in financial mathematics. Moreover, they highlight the symmetric roles played by the mappings $X \\mapsto \\rho_{h}(X)$ and $X \\mapsto \\mathbb{E}[\\phi(X)]$, well known in decision theory (Yaari (1987)). A mathematical duality between the distributional transforms underlying these two classes of mappings, in the sense that one class is characterized by commutation with the other, is recently obtained by Chambers et al. (2023).\n\nSome remaining questions concern boundedness of the folding score of general law-invariant coherent risk measures, and conditions on the \"testing\" risk measure for a strong law of large numbers. These two questions are discussed in Remarks 5.2 and A.6.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 10,
      "text": "## Acknowledgements\n\nThe authors thank the Editor, the Associate Editor, two anonymous referees, and Felix Liebrich for very helpful discussions and comments. RW acknowledges financial support from the Natural Sciences and Engineering Research Council of Canada (RGPIN-2018-03823 and",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 11,
      "text": "# Competing Interests \n\nThe authors declare no competing interests.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 12,
      "text": "## References\n\nArtzner, P., Delbaen, F., Eber, J.-M. and Heath, D. (1999). Coherent measures of risk. Mathematical Finance, 9(3), 203-228.\n\nAusiello, G., Crescenzi, P., Gambosi, G., Kann, V., Marchetti-Spaccamela, A. and Protasi, M. (2012). Complexity and Approximation: Combinatorial Optimization Problems and their Approximability Properties. Springer, Berlin.\n\nBasak, S. and Shapiro, A. (2001). Value-at-Risk based risk management: Optimal policies and asset prices. Review of Financial Studies, 14(2), 371-405.\n\nBayraktar, E., Dolinskyi, L. and Dolinsky, Y. (2020). Extended weak convergence and utility maximisation with proportional transaction costs. Finance and Stochastics, 24(4), 1013-1034.\n\nBCBS (2019). Minimum Capital Requirements for Market Risk. February 2019. Basel Committee on Banking Supervision. Basel: Bank for International Settlements. Available at https://www.bis.org/bcbs/publ/d457.htm\n\nBellini, F., Koch-Medina, P., Munari, C. and Svindland, G. (2021). Law-invariant functionals that collapse to the mean. Insurance: Mathematics and Economics, 98, 83-91.\n\nBillingsley, P. (1999). Convergence of Probability Measures, Second Edition, Wiley.\nBlanchet, J., Chen, L. and Zhou, X. Y. (2022). Distributionally robust mean-variance portfolio selection with Wasserstein distances. Management Science, 68(9), 6382-6410.\n\nCastagnoli, E., Maccheroni, F. and Marinacci, M. (2004). Choquet insurance pricing: a caveat. Mathematical Finance, 14(3), 481-485.\n\nChambers, C. P., Liu, P. and Wang, R. (2023). A duality between utility transforms and probability distortions. arXiv: 2309.05816.\n\nCont, R., Deguest, R. and Scandolo, G. (2010). Robustness and sensitivity analysis of risk measurement procedures. Quantitative Finance, 10(6), 593-606.\n\nEmbrechts, P., Schied, A. and Wang, R. (2022). Robustness in the optimization of risk measures. Operations Research, 70(1), 95-110.\n\nDurrett, R. (2019). Probability: Theory and Examples. Cambridge University Press. Fifth Edition.\n\nEmbrechts, P. and Wang, R. (2015). Seven proofs for the subadditivity of Expected Shortfall. Dependence Modeling, 3, 126-140.\n\nFilipovi\u0107, D. and Svindland, G. (2012). The canonical model space for law-invariant convex risk measures is $L^{1}$. Mathematical Finance, 22(3), 585-589.\n\nF\u00f6llmer, H. and Schied, A. (2002). Convex measures of risk and trading constraints. Finance and Stochastics, 6(4), 429-447.\n\nF\u00f6llmer, H. and Schied, A. (2016). Stochastic Finance: An Introduction in Discrete Time. Fourth Edition. Walter de Gruyter, Berlin.\n\nFrittelli, M. and Rosazza Gianin, E. (2002). Putting order in risk measures. Journal of Banking and Finance, 26,1473-1486.\n\nFr\u00f6hlich, C. and Williamson, R. C. (2024). Risk measures and upper probabilities: Coherence and stratification. Journal of Machine Learning Research, 25(207), 1-100.\n\nK\u00e4llblad, S., Ob\u0142\u00f3j, J. and Zariphopoulou, T. (2018). Dynamically consistent investment under model uncertainty: the robust forward criteria. Finance and Stochastics, 22(4), 879-918.\n\nKou, S. and Peng, X. (2016). On the measurement of economic tail risk. Operations Research, 64(5), 1056-1072.\n\nKr\u00e4tschmer, V., Schied, A. and Z\u00e4hle, H. (2014). Comparative and quantitiative robustness for law-invariant risk measures. Finance and Stochastics, 18(2), 271-295.\n\nKusuoka, S. (2001). On law invariant coherent risk measures. Advances in Mathematical Economics, 3, 83-95.\n\nLanders, D. and Rogge, L. (1987). Laws of large numbers for pairwise independent uniformly integrable random variables. Mathematische Nachrichten, 130(1), 189-192.\n\nLiebrich, F. B. and Munari, C. (2022). Law-invariant functionals that collapse to the mean: Beyond convexity. Mathematics and Financial Economics, 16(3), 447-480.\n\nLiebrich, F. B. and Svindland, G. (2017). Model spaces for risk measures. Insurance: Mathematics and Economics, 77, 150-165.\n\nMadan, D. B. and Cherny, A. (2010). Markets as a counterparty: An introduction to conic finance. International Journal of Theoretical and Applied Finance, 13(08), 1149-1177.\n\nMcNeil, A. J., Frey, R. and Embrechts, P. (2015). Quantitative Risk Management: Concepts, Techniques and Tools. Revised Edition. Princeton, NJ: Princeton University Press.\n\nMu, X., Pomatto, L., Strack, P. and Tamuz, O. (2024). Monotone additive statistics. Econometrica, 92(4), 995-1031.\n\nMeyer, P.A. (1966). Probability and Potentials. Blaisdell Publishing, New York.\nRockafellar, R. T. and Uryasev, S. (2002). Conditional value-at-risk for general loss distributions.\n\nJournal of Banking and Finance, 26(7), 1443-1471.\nR\u00fcschendorf, L. (2013). Mathematical Risk Analysis. Dependence, Risk Bounds, Optimal Allocations and Portfolios. Springer, Heidelberg.\n\nVazirani, V. V. (2001). Approximation Algorithms. Springer, Berlin.\nWang, Q., Wang, R. and Wei, Y. (2020). Distortion riskmetrics on general spaces. ASTIN Bulletin, 50(4), 827-851.\n\nWang, R. and Zitikis, R. (2021). An axiomatic foundation for the Expected Shortfall. Management Science, 67, 1413-1429.\n\nWu, Q., Mao, T. and Hu, T. (2024). Generalized optimized certainty equivalent with applications in the rank-dependent utility model. SIAM Journal on Financial Mathematics, 15(1), 55-294. Yaari, M. E. (1987). The dual theory of choice under risk. Econometrica, 55(1), 95-115.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 13,
      "text": "# A Technical discussions on folding score \n\nIn this appendix, we discuss some technical details related to the folding score and Theorem 3.1 in Section 3.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 14,
      "text": "## A. 1 Sharpness of the bound in Theorem 3.1\n\nLet us denote the upper bound in (3.1) by\n\n$$\ns_{\\rho_{h}} \\leqslant b_{h}=\\frac{h(1 / 2)+1 / 2}{h(1 / 2)-1 / 2}\n$$\n\nNote that $b_{h}$ is decreasing in $h(1 / 2)$, and its smallest value 3 is attained when $h(1 / 2)=1$. We provide two examples, first showing that the bound 3 cannot be improved, and second showing that it is not always sharp for a given $h$.\n\nExample A. 1 (The upper bound 3 is sharp for some $h$ ). Let $\\rho_{h}=\\mathrm{ES}_{p}$ for $p \\in[1 / 2,1)$. In this case, $h(1 / 2)=1$, and the upper bound in (3.1) is 3 . For $\\varepsilon \\in(0,1)$, we can construct $X$ such that $s_{\\rho_{h}}(X)$ is precisely $3-\\varepsilon$, and this shows $s_{\\rho_{h}}=3$. Thus, the bound 3 cannot be improved for $\\rho_{h}$. Let $X$ have a two-point distribution given by $\\mathbb{P}(X=-1)=1-w$ and $\\mathbb{P}(X=2(1-p) / w)=w$, where $w=\\varepsilon(1-p) /(4-\\varepsilon) \\in(0,1-p)$. We have\n\n$$\n\\mathrm{ES}_{p}(|X|)=2+(1-p-w) \\frac{1}{1-p}=3-\\frac{w}{1-p}=3-\\frac{\\varepsilon}{4-\\varepsilon}\n$$\n\nand\n\n$$\n\\mathrm{ES}_{p}(X) \\vee \\mathrm{ES}_{p}(-X)=(2-(1-p-w) \\frac{1}{1-p}) \\vee 1=1+\\frac{w}{1-p}=1+\\frac{\\varepsilon}{4-\\varepsilon}\n$$\n\nTherefore,\n\n$$\n\\frac{\\operatorname{ES}_{p}(|X|)}{\\operatorname{ES}_{p}(X) \\vee \\operatorname{ES}_{p}(-X)}=\\frac{3(4-\\varepsilon)-\\varepsilon}{(4-\\varepsilon)+\\varepsilon}=3-\\varepsilon\n$$\n\nExample A. 2 (The upper bound in (3.1) is not sharp for some $h$ ). Let $\\rho_{h}=\\mathrm{ES}_{p}$ for $p \\in(0,1 / 2]$. In this case, $h(1 / 2)=(2(1-p))^{-1}$, and the upper bound in (3.1) is $2 / p-1$. Note that this bound increases to $\\infty$ as $p \\downarrow 0$. This is intuitive, as $\\mathrm{ES}_{0}$ corresponds to the mean, whose folding score is infinity. The bound $2 / p-1$ is not sharp. Take $p=1 / 4$, and thus $2 / p-1=7$. However, for any $z \\in(0,1), a+b=g(z) / h(z)+g(1-z) / h(1-z) \\leqslant 1$, where $a, b$ are defined in the proof of Theorem 3.1. Hence, $s_{\\rho_{h}} \\leqslant(2+a+b) /(1-a b) \\leqslant 3 /(1-c)=6$.\n\nAlthough the bound in (3.1) is not always sharp, it suffices for our study in Section 4, where we only need $s_{\\rho}<\\infty$ as in Proposition 3.3.",
      "tables": {},
      "images": {}
    },
    {
      "section_id": 15,
      "text": "# A. 2 Other families of risk measures \n\nTheorem 3.1 shows that, for the large class of coherent distortion risk measures $\\rho$, we have\n\n$$\ns_{\\rho}=\\sup _{X \\in \\mathcal{L}} \\frac{\\rho(|X|)}{|\\rho(X)| \\vee|\\rho(-X)|}<\\infty \\text { unless } \\rho=\\mathbb{E}\n$$\n\nOne may naturally wonder whether (A.1) holds for other classes of risk measures, that is, whether the folding score is finite for non-linear risk measures. With a series of counter examples, we answer the question negatively for many classes of interesting risk measures. It suffices to construct examples in $L^{\\infty}$, which we will work with in all examples below.\n\nExample A. 3 (Law-invariant convex risk measures). Property (A.1) does not hold for lawinvariant convex risk measures in general, illustrated below. The entropic risk measures, indexed by parameter $\\beta>0$, are defined by\n\n$$\n\\mathrm{ER}_{\\beta}(X)=\\frac{1}{\\beta} \\log \\mathbb{E}[\\exp (\\beta X)], \\quad X \\in L^{1}\n$$\n\nThe entropic risk measures are a popular class of law-invariant convex risk measures (F\u00f6llmer and Schied (2016)). We will show that this class does not satisfy (A.1). Taking $X_{\\lambda}=\\lambda\\left(2 \\mathbb{1}_{A}-1\\right)$ where $\\lambda>0$ and $A \\in \\mathcal{F}$ with $\\mathbb{P}(A)=1 / 2$, we have $\\operatorname{ER}_{\\beta}\\left(\\left|X_{\\lambda}\\right|\\right)=\\lambda$ and\n\n$$\n\\operatorname{ER}_{\\beta}\\left(X_{\\lambda}\\right)=\\operatorname{ER}_{\\beta}\\left(-X_{\\lambda}\\right)=\\frac{1}{\\beta} \\log \\left(\\frac{1}{2} \\exp (\\beta \\lambda)+\\frac{1}{2} \\exp (-\\beta \\lambda)\\right) \\geqslant 0\n$$\n\nTherefore, we have\n\n$$\n\\lim _{\\lambda \\downarrow 0} \\frac{\\operatorname{ER}_{\\beta}\\left(X_{\\lambda}\\right)}{\\operatorname{ER}_{\\beta}\\left(\\left|X_{\\lambda}\\right|\\right)}=\\lim _{\\lambda \\downarrow 0} \\frac{\\frac{1}{\\beta} \\log \\left(\\frac{1}{2} \\exp (\\beta \\lambda)+\\frac{1}{2} \\exp (-\\beta \\lambda)\\right)}{\\lambda}=\\lim _{\\lambda \\downarrow 0} \\frac{\\log \\left(\\frac{1}{2} \\exp (\\lambda)+\\frac{1}{2} \\exp (-\\lambda)\\right)}{\\lambda}=0\n$$\n\nwhere we used the l'Hospital rule and\n\n$$\n\\frac{\\mathrm{d}}{\\mathrm{~d} \\lambda} \\log \\left(\\frac{1}{2} \\exp (\\lambda)+\\frac{1}{2} \\exp (-\\lambda)\\right)=\\frac{\\frac{1}{2} \\exp (\\lambda)-\\frac{1}{2} \\exp (-\\lambda)}{\\frac{1}{2} \\exp (\\lambda)+\\frac{1}{2} \\exp (-\\lambda)} \\rightarrow 0 \\text { as } \\lambda \\downarrow 0\n$$\n\nTherefore, $s_{\\rho}=\\infty$ for $\\rho=\\mathrm{ER}_{\\beta}$.\nA risk measure $\\rho$ on $L^{\\infty}$ is Fatou continuous if $\\liminf _{n \\rightarrow \\infty} \\rho\\left(X_{n}\\right) \\geqslant \\rho(X)$ for all uniformly bounded sequences $\\left(X_{n}\\right)_{n \\in \\mathbb{N}}$ with $X_{n} \\rightarrow X$ in probability. Note that Fatou continuity is slightly weaker than $L^{1}$-lower semicontinuity (confined to $\\mathcal{L}=L^{\\infty}$ ) due to the type of convergence; see R\u00fcschendorf (2013, Chapter 7).\n\nExample A. 4 (Coherent risk measures). Property (A.1) does not generalise to the class of Fatou-continuous coherent risk measures on $L^{\\infty}$. This class of risk measures can be represented by\n\n$$\n\\rho=\\sup _{Q \\in \\mathcal{Q}} \\mathbb{E}^{Q}\n$$\n\nwhere $\\mathcal{Q}$ is a set of probability measures absolutely continuous with respect to $\\mathbb{P}$. Consider $[0,1]$ with the Lebesgue measure $\\lambda$. Let $Q_{1}$ and $Q_{2}$ be defined by their Radon-Nikodym derivatives\n\n$$\n\\frac{\\mathrm{d} Q_{1}}{\\mathrm{~d} \\lambda}=\\frac{3}{4} \\mathbb{1}_{[0,1 / 3] \\cup[2 / 3,1]}+\\frac{3}{2} \\mathbb{1}_{(1 / 3,2 / 3)} \\text { and } \\frac{\\mathrm{d} Q_{2}}{\\mathrm{~d} \\lambda}=\\frac{3}{2} \\mathbb{1}_{[0,1 / 3] \\cup[2 / 3,1]}\n$$\n\nLet $X=\\mathbb{1}_{[0,1 / 3]}-\\mathbb{1}_{[2 / 3,1]}, \\mathcal{Q}=\\left\\{Q_{1}, Q_{2}\\right\\}$, and $\\rho=\\sup _{Q \\in \\mathcal{Q}} \\mathbb{E}^{Q}$. Then $s_{\\rho}(X)=1 / 0=\\infty$.\nExample A. 5 (Coherent Choquet risk measures). Property (A.1) does not hold for the class of coherent Choquet risk measures. A coherent Choquet risk measure has the form\n\n$$\n\\rho_{\\nu}(X)=\\int_{0}^{\\infty} \\nu(X>x) \\mathrm{d} x+\\int_{-\\infty}^{0}(\\nu(X>x)-1) \\mathrm{d} x, \\quad X \\in L^{\\infty}\n$$\n\nwhere $\\nu: \\mathcal{F} \\rightarrow[0,1]$ is increasing and satisfies $\\nu(N)=0$ for $N \\in \\mathcal{F}$ with 0 probability, $\\nu(\\Omega)=1$, and $\\nu(A \\cup B)+\\nu(A \\cap B) \\leqslant \\nu(A)+\\nu(B)$ for all $A, B \\in \\mathcal{F}$. If $\\nu=h \\circ \\mathbb{P}$ for a concave $h \\in \\mathcal{D}$, then $\\rho_{\\nu}=$ $\\rho_{h}$. Consider $S=[-1 / 3,1 / 3] \\times[-1,1]$ with Lebesgue measure $\\mu$. Denote $S^{+}=[-1 / 3,1 / 3] \\times[0,1]$ and $S^{-}=[-1 / 3,1 / 3] \\times[-1,0)$. Define $\\nu(A):=\\left(\\mu\\left(A \\cap S^{+}\\right) \\wedge 1 / 2\\right)+\\left(\\mu\\left(A \\cap S^{-}\\right) \\wedge 1 / 2\\right)$. Take $X=\\mathbb{1}_{S^{+}}-\\mathbb{1}_{S^{-}}$. Then $s_{\\rho_{\\nu}}(X)=1 / 0=\\infty$.\n\nRemark A.6. It remains an open question whether property (A.1) holds for the class of lawinvariant coherent risk measures. For this class, we did not find any example of $\\rho \\neq \\mathbb{E}$ satisfying $s_{\\rho}=\\infty$, although we could not prove $s_{\\rho}<\\infty$ for all $\\rho \\neq \\mathbb{E}$. By Kusuoka's representation (Kusuoka (2001)), any law-invariant coherent risk measure $\\rho$ on $L^{\\infty}$ can be represented as $\\rho=\\sup _{h \\in \\mathcal{H}_{\\rho}} \\rho_{h}$ where $\\mathcal{H}_{\\rho}$ is a set of concave distortion functions. If $\\mathcal{H}_{\\rho}$ is a finite set, then by using Theorem 3.1 we can obtain (A.1). For an infinite $\\mathcal{H}_{\\rho}$, this is not clear.",
      "tables": {},
      "images": {}
    }
  ],
  "id": "2404.03783v3",
  "authors": [
    "Muqiao Huang",
    "Ruodu Wang"
  ],
  "categories": [
    "q-fin.RM"
  ],
  "abstract": "We establish a profound connection between coherent risk measures, a\nprominent object in quantitative finance, and uniform integrability, a\nfundamental concept in probability theory. Instead of working with absolute\nvalues of random variables, which is convenient in studying integrability, we\nwork directly with random loses and gains, which have clear financial\ninterpretation. We introduce a technical tool called the folding score of\ndistortion risk measures. The analysis of the folding score allows us to\nconvert some conditions on absolute values to those on gains and losses. As our\nmain results, we obtain three sets of equivalent conditions for uniform\nintegrability. In particular, a set is uniformly integrable if and only if one\ncan find a coherent distortion risk measure that is bounded on the set, but not\nfinite on $L^1$.",
  "updated": "2025-04-05T01:10:39Z",
  "published": "2024-04-04T19:54:37Z"
}