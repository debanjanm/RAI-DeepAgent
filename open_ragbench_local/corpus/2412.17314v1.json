{"title": "Collaborative Optimization in Financial Data Mining Through Deep\n  Learning and ResNeXt", "sections": [{"section_id": 0, "text": "#### Abstract\n\nThis study proposes a multi-task learning framework based on ResNeXt, aiming to solve the problem of feature extraction and task collaborative optimization in financial data mining. Financial data usually has the complex characteristics of high dimensionality, nonlinearity, and time series, and is accompanied by potential correlations between multiple tasks, making it difficult for traditional methods to meet the needs of data mining. This study introduces the ResNeXt model into the multi-task learning framework and makes full use of its group convolution mechanism to achieve efficient extraction of local patterns and global features of financial data. At the same time, through the design of task sharing layers and dedicated layers, it is established between multiple related tasks. Deep collaborative optimization relationships. Through flexible multi-task loss weight design, the model can effectively balance the learning needs of different tasks and improve overall performance. Experiments are conducted on a real S\\&P 500 financial data set, verifying the significant advantages of the proposed framework in classification and regression tasks. The results indicate that, when compared to other conventional deep learning models, the proposed method delivers superior performance in terms of accuracy, F1 score, root mean square error, and other metrics, highlighting its outstanding effectiveness and robustness in handling complex financial data. This research provides an efficient and adaptable solution for financial data mining, and at the same time opens up a new research direction for the combination of multi-task learning and deep learning, which has important theoretical significance and practical application value.\n\n\nKeywords-ResNeXt, Multi-task Learning, Financial Data Mining, Feature Extraction", "tables": {}, "images": {}}, {"section_id": 1, "text": "## I. INTRODUCTION\n\nIn recent years, the rapid advancement of artificial intelligence has established deep learning as a pivotal tool in data mining. Financial data, characterized by high dimensionality, heterogeneity, and time-series nature, often challenges traditional data mining approaches. Deep learning, particularly Convolutional Neural Networks (CNNs) [1], offers\nrobust solutions for extracting features from complex and unstructured financial data. Beyond their established role in image analysis, CNNs, especially ResNeXt architectures, have demonstrated efficacy in time-series and structured data mining, effectively capturing local features and processing highdimensional data through group convolution [2].\n\nIn financial data mining, multi-task learning (MTL) addresses the limitations of single-task models by leveraging shared feature spaces to enhance learning efficiency and generalization [3]. Integrating ResNeXt into MTL frameworks enables the exploration of spatiotemporal characteristics and establishes deep inter-task associations, facilitating tasks like trend prediction [4], risk assessment, and asset pricing [5]. This shared representation design enhances data utilization and model performance. Compared to traditional feature engineering, the ResNeXt-based MTL framework offers notable advantages. Its group convolution mechanism reduces parameter complexity while maintaining robust modeling capabilities, and efficiently handling high-dimensional data [6]. The framework's multi-task design allows flexible adjustment of task weights and loss functions, capturing global features while addressing specific task characteristics. This adaptability suits the multimodal nature of financial data, enabling higherdimensional insights into market dynamics [7].\n\nResNeXt's residual block structure enhances gradient flow and feature reuse [8], addressing the volatility and complexity of financial data. Its grouping strategy preserves data diversity and information richness while capturing high-level semantic features, delivering comprehensive feature representations for financial tasks.\n\nThis study's ResNeXt-based MTL framework efficiently handles complex financial data and achieves collaborative optimization across tasks. Its innovative feature extraction and shared learning design provide a flexible, scalable solution for multi-task financial analysis. As financial data grows in scale and complexity, this framework offers robust support for\n\nintelligent financial analysis and broader applications of deep learning in other domains.", "tables": {}, "images": {}}, {"section_id": 2, "text": "## II. RELATED WORK\n\nIn The integration of deep learning techniques with multitask learning has enabled significant advancements in feature extraction, optimization, and prediction across complex datasets. The proposed framework leverages these advancements, particularly through the use of ResNeXt, to address challenges in financial data mining.\n\nGraph-based methods have contributed significantly to understanding relationships and dependencies in structured data, which aligns with the goal of extracting correlations in financial datasets. Wei et al. explored self-supervised Graph Neural Networks (GNNs) for enhanced feature extraction, demonstrating their ability to capture intricate data patterns [9]. Similarly, Zhang et al. presented robust GNN methodologies to handle dynamic data structures, emphasizing their capability for maintaining stability across tasks [10]. These approaches inform the collaborative optimization strategies in multi-task learning.\n\nHybrid deep learning architectures, such as CNN-LSTM models, have shown substantial promise in handling temporal and sequential data, making them particularly relevant for capturing the time-series nature of financial data. Yao et al. utilized a hybrid CNN-LSTM model to improve prediction accuracy in sequence data, showcasing the architecture's capability for combining local and global pattern recognition [11]. Wang et al. expanded on this by incorporating spatiotemporal prediction techniques, offering insights into managing dynamic patterns effectively [12].\n\nSelf-supervised learning frameworks provide a robust pathway for overcoming challenges in data sparsity and feature generalization, which are critical in financial datasets. Xiao's work on self-supervised learning highlights how these methods can enhance representation learning in low-data scenarios, a feature applicable to diverse financial tasks [13]. Similarly, Shen et al. demonstrated semi-supervised learning's potential to improve feature extraction and predictive accuracy, reinforcing the adaptability of these techniques in data-constrained environments [14].\n\nTransformer-based and encoder-decoder models have advanced contextual feature extraction, a vital component in analyzing multi-dimensional financial data. Chen et al. proposed a transformer-based framework for extracting coherent and high-quality features, which aligns with the extraction of high-dimensional patterns in financial data [15]. Additionally, Feng et al. combined data augmentation and fewshot learning strategies to tackle limited data scenarios effectively, a critical aspect of handling financial data with sparse labels [16].\n\nGenerative models and metric learning approaches have further enriched the ability to capture latent features in complex datasets. Liu et al. introduced calibration learning to improve the adaptation of few-shot learning models, providing insights into optimizing task-specific feature representation [17]. Luo et al. employed metric learning techniques to enhance model\nrobustness under sparse data conditions, which is highly relevant for financial data modeling [18].\n\nTechniques for large-scale feature extraction and adaptive modeling have also contributed significantly to understanding complex data patterns. Yang et al. investigated methods for adaptive feature extraction, which parallels the multidimensional feature modeling required in financial data analysis [19]. Additionally, Sun et al. optimized convolutional neural networks to improve pattern recognition, providing transferable techniques for enhancing deep feature extraction [20].\n\nGraph-based techniques for reasoning and relationship modeling have also informed the shared learning component of the proposed framework. Du et al. demonstrated the utility of GNNs for entity extraction and reasoning, highlighting their relevance for capturing task relationships in shared spaces [21]. These methodologies directly contribute to the collaborative optimization mechanism central to this work.", "tables": {}, "images": {}}, {"section_id": 3, "text": "## III. METHOD\n\nThis study proposes a multi-task learning framework based on ResNeXt, which aims to solve the problem of feature sharing and collaborative modeling between multiple tasks in financial data mining. The overall model is divided into three parts: feature extraction module, shared learning module, and task-specific head. The feature extraction module is built on ResNeXt and can fully capture the local patterns and global features of financial data; the shared learning module enhances the feature interaction between tasks through multi-task loss design [22]; the task-specific head generates the final prediction results for different tasks [23]. The main architecture of ResNext is shown in Figure 1.\n![img-0.jpeg](img-0.jpeg)\n\nFigure 1 Overall architecture of the model\nFirst, for the input financial data, it is represented in matrix form as $X \\in R^{T * F}$, where T represents the length of the time series and F represents the feature dimension. In the feature extraction module (Figure 1), '128-d' denotes the feature vector's dimensionality post-group convolution in ResNeXt.\n\nThis value, a tunable hyperparameter, balances the need for detailed feature representation against computational demands, ensuring efficient processing of high-dimensional financial data. The feature extraction module adopts the ResNeXt network and uses its group convolution design to effectively process high-dimensional financial data while enhancing the representation ability of features through residual connections. Each group convolution operation in ResNeXt can capture the feature patterns within different groups and finally aggregate the features in the channel dimension. After a series of nonlinear transformations of convolution, pooling, and activation functions, the extracted features are represented as $F_{\\text {shared }} \\in R^{T^{\\prime} \\times C}$, where $T^{\\prime}$ is the time dimension after downsampling and C is the number of feature channels. This shared feature serves as the basic representation of all tasks and provides support for subsequent multi-task learning.\n\nIn the shared learning module, a task weight-sharing mechanism is introduced to map the shared features to the specific space of each task. For the i-th task, its dedicated feature is expressed as:\n\n$$\nF_{i}=\\sigma\\left(W_{i} F_{\\text {shared }}+b_{i}\\right)\n$$\n\nWhere $W_{i}$ and $b_{i}$ are the learnable weights of task I, and $\\sigma$ represents the activation function. Through this mapping, the model can learn specific representations for each task based on shared features, avoiding interference between tasks while maintaining efficient feature sharing.\n\nThe design of the task-specific head uses a fully connected network to map task-specific features to the final output space. For classification tasks, its output is a probability distribution $y_{i}^{\\prime}$, calculated as:\n\n$$\ny_{i}^{\\prime}=\\operatorname{softmax}\\left(W_{m l p, i} F_{i}+b_{m l p, i}\\right)\n$$\n\nFor the regression task, the output is a scalar $y^{\\prime \\prime_{i}}$, and the calculation formula is:\n\n$$\ny_{i}^{\\prime \\prime}=W_{m l p, i} F_{i}+b_{m l p, i}\n$$\n\nThe above-mentioned dedicated head can be flexibly adjusted according to the needs of different tasks. For example, the classification task uses the cross entropy loss function, while the regression task uses the mean square error (MSE) loss function [24]. In order to achieve joint optimization of multiple tasks, the overall loss function is defined as the weighted sum of the losses of each task:\n\n$$\nL=\\sum_{i=1}^{N} \\alpha_{i} L_{i}\n$$\n\nWhere N is the number of tasks, and $a_{i}$ is the weight of the i-th task, which can be flexibly adjusted according to the importance of the task to ensure the balance between different tasks.\n\nThe model training adopts a phased optimization strategy. First, single-task pre-training is used to ensure that the\ndedicated head of each task can converge effectively; then, all tasks are jointly optimized in the multi-task framework to further improve the overall performance of the model. In order to accelerate convergence and improve the generalization ability of the model, data enhancement strategies are introduced during the training process, such as random cropping of time series data, smooth noise addition, etc., and the Adam optimizer and dynamic learning rate adjustment strategy are used.\n\nThe proposed multi-task learning framework based on ResNeXt not only utilizes the efficient feature extraction capability of ResNeXt but also realizes the collaborative optimization between tasks through the shared learning mechanism, providing an efficient and flexible solution for multi-task mining of financial data. The design of the model achieves a good balance between feature extraction, sharing and task optimization, providing technical support for dealing with complex financial data.", "tables": {}, "images": {"img-0.jpeg": "data:image/jpeg;base64,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"}}, {"section_id": 4, "text": "## IV. EXPERIMENT\n## A. Datasets\n\nThis study selected the S\\&P 500 stock market dataset as the data source for the experiment. This dataset is a widely used public dataset in the field of financial data mining, which contains historical trading data and market indicators of all constituent stocks in the S\\&P 500 index. The dataset records daily trading data since 2000, including key information such as opening price, closing price, highest price, lowest price, and trading volume. It also provides macroeconomic indicators (such as GDP growth rate, unemployment rate, interest rate, etc.) as additional features. These data can fully reflect the dynamic characteristics of the financial market and provide a reliable basis for tasks such as trend prediction and risk assessment.\n\nIn the data preprocessing stage, according to the time series characteristics of stock trading data, the data is divided into fixed-length time windows, each of which contains several days of trading data to capture short-term market trends. At the same time, the macroeconomic indicators in the data are aligned to the corresponding time windows to supplement the global market background information. In addition, considering the common missing values and noise problems in financial data, the study interpolated the missing data and standardized the features through Z-Score normalization to eliminate the influence of feature dimensions on model training. These steps, when implemented with linked data [25], ensure the integrity and consistency of the data and provide highquality input data for the model.\n\nThe dataset was finally divided into training set, validation set and test set. After cleaning, approximately 1.8 million samples remained for training ( $70 \\%$ ), validation ( $15 \\%$ ), and testing ( $15 \\%$ ). Preprocessing involved fixed-length time windows, interpolation of missing values, and Z-score normalization. The training set is used to optimize the model\n\nparameters, the validation set is used to adjust the hyperparameters and evaluate the generalization performance of the model, and the test set is used for the final model performance evaluation. In order to enhance the robustness of the model, this study introduced data enhancement strategies, such as random translation or scaling of time series data to increase the diversity of the data. These designs ensure that the use of the dataset can fully reflect the complexity of the financial market and provide a reliable basis for the verification of the multi-task learning model.", "tables": {}, "images": {}}, {"section_id": 5, "text": "## B. Experiments\n\nIn order to comprehensively evaluate the performance of the proposed ResNeXt-based multi-task learning framework in financial data mining, this study selected four classic deep learning models as comparison objects: Long Short-Term Memory (LSTM), as the mainstream model for processing time series data, is good at capturing the temporal dependency of financial data; Transformer model, due to its powerful global attention mechanism, can effectively model the long-range dependency in financial data; Deep Shared Network (DSN) based on multi-task learning, through the design of shared layers and task-specific layers, it improves the collaborative optimization ability between tasks; and Multi-Channel Convolutional Neural Network (MCCNN), which uses multichannel design to capture the correlation between different features and shows the ability to efficiently model multidimensional financial data. These models cover different strategies of sequence modeling, multi-task learning and multidimensional feature extraction, providing a sufficient comparison basis for verifying the superiority of the proposed method. The comparative experiments of the discriminant task and regression task of the multi-task model are shown in Tables 1 and 2.\n\nTable 1 Results of the discrimination task experiment\n\n![table_0](table_0)\n\nTable 2 Experimental results of regression task\n\n![table_1](table_1)\n\nThe proposed ResNeXt-based multi-task learning framework outperforms other models in both classification and regression tasks. In classification, it achieved an accuracy of $85.3 \\%$ and a macro F1 score of $83.7 \\%$, significantly higher than the second-ranked multi-channel convolutional neural network (MCCNN). In regression, the mean absolute error\n(MAE) was 0.025 , and the root mean square error (RMSE) was 0.043 , demonstrating excellent prediction capabilities. These results highlight the framework's strength in processing complex financial data with enhanced feature extraction and task collaboration.\n\nThe classification task reveals the differences in model performance based on financial data characteristics. LSTM, despite its temporal dependence modeling capabilities, has lower accuracy and macro-average F1 scores compared to other models. Transformer improves time series modeling and long-range dependencies but lacks the feature extraction module to fully utilize financial data diversity and local patterns, resulting in lower classification performance.\n\nThe DSN model in the multi-task learning framework further improved its performance in classification tasks, with an accuracy rate of $79.6 \\%$ and a macro-average F1 of $77.8 \\%$. This result shows that through the design of shared and dedicated layers, DSN can more effectively capture the potential correlations between different tasks, thereby improving the classification performance of the model. However, the feature extraction module of DSN is relatively simple and fails to fully mine the complex patterns in financial data, so its performance still lags behind MCCNN and proposed methods. MCCNN captures the relationship between different dimensions of financial features through multichannel design, and the classification performance is significantly improved, with an accuracy of $82.1 \\%$. However, its lack of in-depth modeling of time series and shared features between tasks limits further improvement.\n\nIn regression tasks, the advantages of the proposed method are particularly obvious. In comparison to other models, the proposed framework not only effectively captures local patterns and global features of financial data using ResNeXt, but also facilitates deep collaborative optimization between tasks through a multi-task learning mechanism, resulting in the lowest values for both MAE and RMSE. In contrast, although LSTM and Transformer have certain advantages in modeling time series, they lack an effective feature sharing mechanism, resulting in limited performance in multi-task environments. In addition, although MCCNN has made breakthroughs in multidimensional feature modeling, its regression performance is not as good as the proposed method due to its insufficient ability to capture time dependence and global features.\n\nOverall, the experimental results fully illustrate the wide applicability and excellent performance of the proposed ResNeXt-based multi-task learning framework in financial data mining. Through an efficient feature extraction mechanism and shared learning design, the model can not only achieve accurate predictions in classification tasks but also effectively reduce errors in regression tasks. These results verify the potential of ResNeXt combined with multi-task learning and also demonstrate its powerful ability to process complex and diverse financial data. In the future, this framework can be further extended to other financial scenarios, such as risk management and market monitoring, to help the development of intelligent financial analysis.", "tables": {"table_0": "| Model | Acc | Macro F1 |\n| :--: | :--: | :--: |\n| LSTM | 73.2 | 71.8 |\n| DSN | 76.4 | 74.2 |\n| MCCNN | 79.6 | 77.8 |\n| Transformer | 82.1 | 80.4 |\n| ours | 85.3 | 83.7 |", "table_1": "| Model | MAE | RMSE |\n| :--: | :--: | :--: |\n| LSTM | 0.041 | 0.063 |\n| DSN | 0.036 | 0.057 |\n| MCCNN | 0.033 | 0.052 |\n| Transformer | 0.029 | 0.048 |\n| ours | 0.025 | 0.043 |"}, "images": {}}, {"section_id": 6, "text": "## V. CONCLUSION\n\nThis study proposes a multi-task learning framework based on ResNeXt and conducts an in-depth exploration of feature extraction and multi-task collaborative optimization issues in financial data mining. Experimental results show that this framework can achieve significantly better performance than other models in classification and regression tasks, especially when processing complex time series features and multidimensional data patterns, showing powerful modeling capabilities. By combining ResNeXt's group convolution mechanism and the shared optimization design of multi-task learning, the model achieved optimal performance in terms of accuracy, F1 score, and error indicators, verifying the effectiveness and reliability of the method.\n\nIn addition, the framework is designed with good scalability and applicability, and can flexibly deal with high-dimensional features, nonlinear relationships, and noise problems in financial data. It improves the efficiency of multi-task learning through feature sharing between tasks and also enhances the model's ability to capture complex patterns in financial data. This research not only provides an efficient solution for financial data mining but also provides a strong reference for the application of multi-task learning frameworks in other fields, demonstrating the broad prospects of deep learning in complex data scenarios.\n\nFuture research can expand the capabilities of this framework in multiple directions. On the one hand, you can explore application scenarios for larger-scale financial data, such as adding real-time high-frequency data to enhance the dynamic prediction capabilities of the model; on the other hand, you can try to combine advanced models such as Graph Neural Network to better Model the complex correlations between different assets in financial markets. In addition, while optimizing the model, it will also be an important direction to study how to reduce computational complexity and improve operating efficiency so that it can operate in resourceconstrained environments. These efforts will further promote the application of intelligent financial analysis and inject new impetus into the development of financial technology.", "tables": {}, "images": {}}, {"section_id": 7, "text": "## References\n\n[1] S. Duan, Z. Wang, S. Wang, M. Chen, and R. Zhang, \"Emotion-Aware Interaction Design in Intelligent User Interface Using Multi-Modal Deep Learning\", arXiv preprint arXiv:2411.06326, 2024.\n[2] X. Yan, Y. Jiang, W. Liu, D. Yi, and J. Wei, \"Transforming Multidimensional Time Series into Interpretable Event Sequences for Advanced Data Mining\", arXiv preprint, arXiv:2409.14327, 2024.\n[3] T. Lee and J. Seok, \"Multi Task Learning: A Survey and Future Directions,\" 2023 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), pp. 232-235, 2023.\n[4] Z. Liu, X. Xia, H. Zhang and Z. Xie, \"Analyze the Impact of the Epidemic on New York Taxis by Machine Learning Algorithms and Recommendations for Optimal Prediction Algorithms,\" Proceedings of the 2021 3rd International Conference on Robotics Systems and Automation Engineering, pp. 46-52, May 2021.\n[5] M. S. Arunkumar, et al., \"Fashion Recommendation System for ECommerce using Deep Learning Algorithms\", Proceedings of the 2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT), 2024.\n[6] Y. Zi, \"Time-Series Load Prediction for Cloud Resource Allocation Using Recurrent Neural Networks\", Journal of Computer Technology and Software, vol. 3, no. 7, 2024.\n[7] S. Raya, et al., \"Multi-modal data clustering using deep learning: A systematic review\", Neurocomputing, p. 128348, 2024.\n[8] B. Chen, F. Qin, Y. Shao, J. Cao, Y. Peng and R. Ge, \"Fine-Grained Imbalanced Leukocyte Classification With Global-Local Attention Transformer,\" Journal of King Saud University - Computer and Information Sciences, vol. 35, no. 8, Article ID 101661, 2023.\n[9] J. Wei, Y. Liu, X. Huang, X. Zhang, W. Liu and X. Yan, \"SelfSupervised Graph Neural Networks for Enhanced Feature Extraction in Heterogeneous Information Networks,\" 2024 5th International Conference on Machine Learning and Computer Application (ICMLCA), pp. 272-276, 2024.\n[10] X. Zhang, Z. Xu, Y. Liu, M. Sun, T. Zhou, and W. Sun, \"Robust Graph Neural Networks for Stability Analysis in Dynamic Networks,\" arXiv preprint arXiv:2411.11848, 2024.\n[11] J. Yao, J. Wang, B. Wang, B. Liu, and M. Jiang, \"A Hybrid CNN-LSTM Model for Enhancing Bond Default Risk Prediction,\" Journal of Computer Technology and Software, vol. 3, no. 6, 2024.\n[12] X. Wang, X. Li, L. Wang, T. Ruan, and P. Li, \"Adaptive Cache Management for Complex Storage Systems Using CNN-LSTM-Based Spatiotemporal Prediction,\" arXiv preprint arXiv:2411.12161, 2024.\n[13] Y. Xiao, \"Self-Supervised Learning in Deep Networks: A Pathway to Robust Few-Shot Classification,\" arXiv preprint arXiv:2411.12151, 2024.\n[14] A. Shen, M. Dai, J. Hu, Y. Liang, S. Wang, and J. Du, \"Leveraging Semi-Supervised Learning to Enhance Data Mining for Image Classification under Limited Labeled Data,\" arXiv preprint arXiv:2411.18622, 2024.\n[15] J. Chen, S. Wang, Z. Qi, Z. Zhang, C. Wang, and H. Zheng, \"A Combined Encoder and Transformer Approach for Coherent and HighQuality Text Generation,\" arXiv preprint arXiv:2411.12157, 2024.\n[16] Y. Feng, A. Shen, J. Hu, Y. Liang, S. Wang, and J. Du, \"Enhancing Few-Shot Learning with Integrated Data and GAN Model Approaches,\" arXiv preprint arXiv:2411.16567, 2024.\n[17] Z. Liu, M. Wu, B. Peng, Y. Liu, Q. Peng, and C. Zou, \"Calibration Learning for Few-shot Novel Product Description,\" Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 1864-1868, July 2023.\n[18] Y. Luo, R. Wang, Y. Liang, A. Liang, and W. Liu, \"Metric Learning for Tag Recommendation: Tackling Data Sparsity and Cold Start Issues,\" arXiv preprint arXiv:2411.06374, 2024.\n[19] Y. Yang, I. Li, N. Sang, L. Liu, X. Tang, and Q. Tian, \"Research on Large Scene Adaptive Feature Extraction Based on Deep Learning,\" Preprints, doi: 10.20944/preprints202409.0841.v1, 2024.\n[20] Q. Sun, T. Zhang, S. Gao, L. Yang, and F. Shao, \"Optimizing Gesture Recognition for Seamless UI Interaction Using Convolutional Neural Networks,\" arXiv preprint arXiv:2411.15598, 2024.\n[21] J. Du, G. Liu, J. Gao, X. Liao, J. Hu, and L. Wu, \"Graph Neural Network-Based Entity Extraction and Relationship Reasoning in Complex Knowledge Graphs,\" arXiv preprint arXiv:2411.15195, 2024.\n[22] S. Lu, Z. Liu, T. Liu and W. Zhou, \"Scaling-up Medical Vision-andLanguage Representation Learning with Federated Learning,\" Engineering Applications of Artificial Intelligence, vol. 126, Article ID 107037, 2023.\n[23] J. Cao, R. Xu, X. Lin, F. Qin, Y. Peng and Y. Shao, \"Adaptive Receptive Field U-Shaped Temporal Convolutional Network for Vulgar Action Segmentation,\" Neural Computing and Applications, vol. 35, no. 13, pp. 9593-9606, 2023.\n[24] C. Tao, X. Fan, and Y. Yang, \"Harnessing LLMs for API Interactions: A Framework for Classification and Synthetic Data Generation,\" arXiv preprint arXiv:2409.11703, 2024.\n[25] Y. Li, X. Yan, M. Xiao, W. Wang and F. Zhang, \"Investigation of Creating Accessibility Linked Data Based on Publicly Available Accessibility Datasets\", Proceedings of the 2023 13th International Conference on Communication and Network Security, pp. 77-81, 2024.", "tables": {}, "images": {}}], "id": "2412.17314v1", "authors": ["Pengbin Feng", "Yankaiqi Li", "Yijiashun Qi", "Xiaojun Guo", "Zhenghao Lin"], "categories": ["cs.LG", "q-fin.CP"], "abstract": "This study proposes a multi-task learning framework based on ResNeXt, aiming\nto solve the problem of feature extraction and task collaborative optimization\nin financial data mining. Financial data usually has the complex\ncharacteristics of high dimensionality, nonlinearity, and time series, and is\naccompanied by potential correlations between multiple tasks, making it\ndifficult for traditional methods to meet the needs of data mining. This study\nintroduces the ResNeXt model into the multi-task learning framework and makes\nfull use of its group convolution mechanism to achieve efficient extraction of\nlocal patterns and global features of financial data. At the same time, through\nthe design of task sharing layers and dedicated layers, it is established\nbetween multiple related tasks. Deep collaborative optimization relationships.\nThrough flexible multi-task loss weight design, the model can effectively\nbalance the learning needs of different tasks and improve overall performance.\nExperiments are conducted on a real S&P 500 financial data set, verifying the\nsignificant advantages of the proposed framework in classification and\nregression tasks. The results indicate that, when compared to other\nconventional deep learning models, the proposed method delivers superior\nperformance in terms of accuracy, F1 score, root mean square error, and other\nmetrics, highlighting its outstanding effectiveness and robustness in handling\ncomplex financial data. This research provides an efficient and adaptable\nsolution for financial data mining, and at the same time opens up a new\nresearch direction for the combination of multi-task learning and deep\nlearning, which has important theoretical significance and practical\napplication value.", "updated": "2024-12-23T06:14:15Z", "published": "2024-12-23T06:14:15Z"}